1

Cyber-Physical Security and Safety of

Autonomous Connected Vehicles: Optimal

Control Meets Multi-Armed Bandit Learning

Aidin Ferdowsi, Student Member, IEEE, Samad Ali, Student Member, IEEE,

Walid Saad, Fellow, IEEE, and Narayan B. Mandayam, Fellow, IEEE

Abstract

Autonomous connected vehicles (ACVs) rely on intra-vehicle sensors such as camera and radar as

well as inter-vehicle communication to operate effectively. This reliance on cyber components exposes

ACVs to cyber and physical attacks in which an adversary can manipulate sensor readings and physically

take control of an ACV. In this paper, a comprehensive framework is proposed to thwart cyber and

physical attacks on ACV networks. First, an optimal safe controller for ACVs is derived to maximize

the street trafﬁc ﬂow while minimizing the risk of accidents by optimizing ACV speed and inter-ACV

spacing. It is proven that the proposed controller is robust to physical attacks which aim at making

ACV systems instable. To improve the cyber-physical security of ACV systems, next, data injection

attack (DIA) detection approaches are proposed to address cyber attacks on sensors and their physical

impact on the ACV system. To comprehensively design the DIA detection approaches, ACV sensors

are characterized in two subsets based on the availability of a-priori information about their data. For

sensors having a prior information, a DIA detection approach is proposed and an optimal threshold

level is derived for the difference between the actual and estimated values of sensors data which enables

ACV to stay robust against cyber attacks. For sensors having no prior information, a novel multi-armed

bandit (MAB) algorithm is proposed to enable ACV to securely control its motion. Collectively, the

proposed DIA detection approaches minimize the vulnerability of ACV sensors against cyber attacks

while maximizing the ACV system’s physical robustness. Simulation results show that the proposed

optimal safe controller outperforms current state of the art controllers by maximizing the robustness of

ACVs to physical attacks. The results also show that the proposed DIA detection approaches, compared

to Kalman ﬁltering, can improve the security of ACV sensors against cyber attacks and ultimately

improve the physical robustness of an ACV system.

This research was supported by the U.S. National Science Foundation under Grants OAC-1541105 and IIS-1633363.

Aidin Ferdowsi and Walid Saad are with Wireless@VT, Bradley Department of Electrical and Computer Engineering, Virginia

Tech, Blacksburg, VA, USA, {aidin, walids}@vt.edu. Samad Ali is with Centre for Wireless Communications

(CWC), University of Oulu, Finland, samad.ali@oulu.fi. Narayan B. Mandayam is with WINLAB, Dept. of ECE,

Rutgers University, New Brunswick, NJ, USA, narayan@winlab.rutgers.edu

8
1
0
2
c
e
D
3
1

]

Y
S
.
s
c
[

1
v
8
9
2
5
0
.
2
1
8
1
:
v
i
X
r
a

 
 
 
 
 
 
2

I. INTRODUCTION

Intelligent transportation systems (ITS) will encompass autonomous connected vehicles (ACVs),

roadside smart sensors (RSSs), vehicular communications, and even drones [1]–[4]. To operate

autonomously in future ITS, ACVs must process a large volume of data collected via sensors and

communication links. Maintaining reliability of this data is crucial for road safety and smooth

trafﬁc ﬂow [5]–[8]. However, this reliance on communications and data processing renders ACVs

highly susceptible to cyber-physical attacks. In particular, an attacker can possibly interject the

ACV data processing stage, inject faulty data, and ultimately induce accidents or compromise

the road trafﬁc ﬂow [9]. As demonstrated in a real-world experiment on a Jeep Cherokee in [10],

ACVs are largely vulnerable to cyber attacks that can control their critical systems, including

braking and acceleration. Naturally, by taking control of ACVs, an adversary can not only impact

the compromised ACV, but it can also reduce the ﬂow of other vehicles and cause a non-optimal

ITS operation. This, in turn, motivates a holistic study for joint cyber and physical impacts of

attacks on ACV systems.

Recently, a number of security solutions have been proposed for addressing intra-vehicle

network and vehicular communication cyber security problems [11]–[19]. In [11], the authors

showed that long-range wireless attacks on the current security protocols of ACVs can disrupt

their controller area network (CAN). Furthermore, the work in [12], proposed a data analytics

approach for the intrusion detection problem by applying a hidden Markov model. In [13],

the security vulnerabilities of current vehicular communication architectures are identiﬁed. The

work in [14] proposed the use of multi-source ﬁlters to secure a vehicular network against

data injection attacks (DIAs). Furthermore, the authors in [15] introduced a new framework

to improve the trustworthiness of beacons by combining two physical measurements (angle

of arrival and Doppler effect) from received wireless signals. In [16], the authors designed a

multi-antenna technique for improving the physical layer security of vehicular millimeter-wave

communications. Moreover, in [17], the authors proposed a collaborative control strategy for

vehicular platooning to address spooﬁng and denial of service attacks. The work in [18] developed

a deep learning algorithm for authenticating sensor signals. Finally, an overview of current

research on advanced intra-vehicle networks and the smart components of ITS is presented in

[19].

In addition to cyber security in ITSs, physical safety and optimal control of ACVs have been

3

studied in [20]–[26]. In [20], the authors identiﬁed the key vulnerabilities of a vehicle’s controller

and secured them using intrusion detection algorithms. The work in [21] analyzed the ACVs

as cyber-physical systems and developed an optimal controller for their motion. The authors

in [22] studied the safe operation of ACV networks in presence of an adversary that tries to

estimate the dynamics of ACVs by its own observations. The authors in [23] proposed centralized

and decentralized safe cruise control approaches for ACV platoons. A learning-based approach

is proposed in [24] to control the velocity of ACVs. Furthermore, in [25], the authors have

proposed a robust deep reinforcement learning (RL) algorithm which mitigates cyber attacks on

ACV sensors and maintains the safety of ACV system. In [26], the authors studied the essence

of secure and safe codesign for ACV systems.

However, despite their importance, the architecture and solutions in [11]–[26] do not take into

account the interdependence between the cyber and physical layers of ACVs while designing

their security solutions. Moreover, the prior art in [11]–[26], does not provide solutions that can

enhance the robustness of ACV motion control to malicious attacks. Nevertheless, designing an

optimal and safe ITS requires robustness to attacks on intra-vehicle sensors as well as inter-

vehicle communication. In addition, these existing works do not properly model the attacker’s

action space and goal (physical disruption in ITS) while providing their security solutions. In

this context, the cyber-physical interdependence of the attacker’s actions and goals will help

providing better security solutions. Finally, the existing literature lacks a fundamental analysis

of physical attacks as in the Jeep hijacking scenario [10] in which the attacker aims at disrupting

the ITS operation by causing non-optimality in a compromised ACV’s speed.

The main contribution of this paper is, thus, a comprehensive study of joint cyber-physical

security challenges and solutions in ACV networks which can be summarized as follows:

• To address both safety and optimality of an ACV system, ﬁrst an optimal safe controller is

proposed so as to maximize the trafﬁc ﬂow and minimize the risk of accidents by optimizing

the speed and spacing of ACVs. To the best of our knowledge, this work will be the ﬁrst

to analyze the physical attack on a ACV network and to prove that the proposed controller

can maximize the stability and robustness of ACV systems against physical attacks such as

in the Jeep hijacking scenario [10].

• To improve the cyber-physical security study of ACV systems, next, new DIA detection

approaches are proposed to address cyber attacks on ACV sensors and to analyze the

physical impact of DIAs on an ACV system. To efﬁciently design the DIA detection

4

approaches, ACV sensors are characterized in two subsets based on the availability of

a priori information about their readings.

• For the ﬁrst subset of sensors which have a priori information, a DIA detection approach is

proposed derive an optimal threshold level for sensor errors which enables ACV to detect

DIAs. For the second subset of sensors that lack a priori information, a novel multi-armed

bandit (MAB) algorithm is proposed to learn which sensors are attacked. The proposed

MAB algorithm uses the so-called Mahalanobis distance between the sensor data and an

a-posteriori prediction to calculate a regret value and optimize the ACV’s sensor fusion

process by applying an upper conﬁdence bound (UCB) algorithm. The proposed detection

approaches maximize both the cyber security and physical robustness of ACV systems

against DIAs.

Simulation results show that the proposed optimal safe controller has higher safety, optimality,

and robustness against physical attacks compared to other state-of-the-art approaches. In addition,

our results show that the proposed DIA detection approaches yield an improved performance

compared to Kalman ﬁltering in mitigating the cyber attacks. Therefore, the proposed solutions

improve the stability of ACV networks against DIAs.

The rest of the paper is organized as follows. Section II introduces our system model while

Section III derives the optimal safe controller. Section IV proves that the proposed optimal safe

controller is robust against physical attacks. Section V proposes approaches to mitigate cyber

attacks on ACV while reducing the risk of accidents. Finally, simulation results are shown in

Section VI and conclusions are drawn in Section VII.

A. ACV Physical Model

II. SYSTEM MODEL

Consider an ACV, f , that follows a leading ACV, l and tries to maintain a spacing from

ACV l as shown in Fig. 1. Maintaining a spacing between ACVs is important to maximize the

trafﬁc ﬂow and minimize the risk of accidents [9]. Let vf be ACV f ’s speed in m/s. Then, ACV
f ’s speed deviation can be written as ˙vf (t) = Ff (t)
(cid:44) uf (t), where Ff (t) is f ’s engine force
mf
in Newtons (N), mf is f ’s mass in kilograms (kg), and uf (t) is f ’s physical controller input

in N/kg . Moreover, letting vl be l’s speed, the spacing d(t) between f and l can be written
as ˙d(t) = vl(t) − vf (t). Note that this model can be easily generalized to multiple ACVs by

repeating the same set of equations for every pair of ACVs to capture any ACV network as

5

Fig. 1: Illustration of the considered ACV system model.

shown in Fig. 1. Due to discrete time sensor readings in ACVs, we convert the aforementioned

continuous system model to a discrete one using a linear transformation as follows [27]:

vf (t + 1) = vf (t) + T uf (t), d(t + 1) = d(t) + T vl(t) − T vf (t),

(1)

where T is the sampling period of the sensors in seconds. The model can be summarized as:

where

x(t + 1) = Ax(t) + Buf (t) + F vl(t),

x(t)=













vf (t)

d(t)

, A=







1

0

−T 1









, B=











T

0

, F =







0

T




.



(2)

(3)

To validate the practicality of the proposed system model, we need to show that uf (t) can control

the speed and spacing of f , i.e., uf can take state vector x(t0) to any desired state x(t1). The

following remark shows that uf can control system (2).

Remark 1. If T > 0, then the system in (2) is controllable. To illustrate the reason, we know

that the system (2) is controllable if the rank of controllability matrix C =

(cid:104)

B AB

(cid:105)

is 2

(number of state variables) [27]. Thus, we have:








C=






T

0



1

0

−T 1

 .









=












T

0

T

T

0 −T 2



.





(4)

Therefore, for any T > 0 the columns of C are linearly independent which implies that the rank

of C will be 2.

B. ACV cyber model

In order to navigate, as shown in Fig. 1, ACV f relies on nf , nl, and nd sensors which measure

vf (t), d(t), and vl(t), respectively. For instance, multiple intra-vehicle inertial measurement units

Roadside sensorV2VV2ILeading vehicle    with speedSpacing sensors measuring        sensors measuring sensors measuring Vulnerable to cyber attacksVulnerable to physical attacksUnder study vehicle   with speed Camera & LiDARRadar6

(IMUs) measure vf (t), multiple cameras, radars, and LiDAR can measure d(t), and roadside

sensors and ACV l measure vl(t) and transmit the measurements to ACV f using vehicle-to-

vehicle (V2V) and vehicle-to-infrastructure (V2I) communication links. Thus, we model the

sensor readings as follows:

zf (t) = hf vf (t) + ef (t), zl(t) = hlvl(t) + el(t), zd(t) = hdd(t) + ed(t),

(5)

where zf (t), zl(t), and zd(t) are sensor vectors with nf , nl, and nd elements which measure

vf (t), vl(t), and d(t), respectively. Also, hf , hl, and hd are vectors with nf , nl, and nd elements

equal to 1. Moreover as assumed in [27] and [28], ef (t), el(t), and ed(t) are noise vectors that
(cid:105)T

follow a white Gaussian distribution with zero mean and variance vectors σ2

, . . . , σ2

,

(cid:104)
σ2
f1

f =

fnf

(cid:104)

σ2

l =

σ2
l1

, . . . , σ2
lnl

(cid:105)T

, and σ2

d =

(cid:104)

σ2
d1

, . . . , σ2

dnd

(cid:105)T

. Since the sensor readings in (5) are noisy, we

need to optimally estimate vf (t), vl(t) and d(t) from zf (t), zl(t), and zd(t) by minimizing the
estimation error. To ﬁnd the optimal estimations ˆvf (t), ˆvl(t), and ˆd(t) (the estimations of vf (t),
vl(t), and d(t)), we use two types of estimators. A static estimator to estimate the variables at the

initial state, t0, (the time step that f starts following l) and a dynamic estimator to estimate ˆvf (t)
and ˆd(t) using the state equations in (1). We use a static estimator at the initial state because

ACV f does not follow the speed of ACV l using (1) before t0 and, hence, a dynamic estimator

cannot be used due to lack of information about the dynamics of f before t0. Moreover, for

ˆvl(t), we always use a static estimator since we do not have any information on the dynamics

of vl(t).

For the static estimator, we deﬁne a least-square (LS) cost function for each variable as follows:

Jf (ˆvf (t)) =

Jl(ˆvd(t)) =

Jd( ˆd(t)) =

1
2

1
2

1
2

∞
(cid:88)

t=0
∞
(cid:88)

(zf (t) − hf ˆvf (t))T R−1
f

(zf (t) − hf ˆvf (t)) ,

(zl(t) − hlˆvl(t))T R−1

l

(zl(t) − hlˆvl(t)) ,

t=0
∞
(cid:88)

(cid:16)

t=0

zd(t) − hd

ˆd(t)

(cid:17)T

(cid:16)

R−1
d

zd(t) − hf

ˆd(t)

(cid:17)

,

(6)

(7)

(8)

where Rf , Rl, and Rd are the measurement covariance matrices associated with sensors measure

vf (t), vl(t), and d(t), respectively. Moreover, since the sensors independently measuring the

three variables, they will not have any noise covariance and Rf , Rl, and Rd will be diagonal.

Therefore, explicit solution for the optimal estimation can be derived as:
nf
(cid:88)

nf
(cid:88)

(cid:17)−1

(cid:16)

ˆvf (t)=

f R−1
hT

f hf

f R−1
hT

f zf (t) =

zfi (t) = vf (t) +

wfi efi (t),

i=1

(9)

1
σ2
fi
(cid:80)nf
i=1

(cid:124)

(cid:123)(cid:122)
wfi

1
σ2
fi
(cid:125)

i=1

ˆvl(t)=

(cid:16)

l R−1
hT

l hl

(cid:17)−1

l R−1
hT

l zl(t) =

nl
(cid:88)

i=1

1
σ2
li

(cid:80)nl

i=1

zli (t) = vl(t) +

nl
(cid:88)

i=1

wli eli (t),

1
σ2
li
(cid:125)

ˆd(t)=

(cid:16)

d R−1
hT

d hd

(cid:17)−1

d R−1
hT

f zd(t) =

(cid:124)

nd
(cid:88)

i=1

(cid:123)(cid:122)
wli
1
σ2
di
(cid:80)nd
i=1

zdi (t) = d(t) +

nd
(cid:88)

i=1

wdi edi (t).

1
σ2
di
(cid:125)

(cid:124)

(cid:123)(cid:122)
wdi

7

(10)

(11)

For the dynamic estimator, we use a Kalman ﬁlter which uses the state equation in the estimation

process. To this end, we deﬁne an output equation as follows:

z(t) = Hx(t) + e(t), s.t. H =



 , z(t) =







hf

0nd×1

0nf ×1
hd



zf (t)

zd(t)





 , e(t) =





 . (12)

ef (t)

ed(t)

Note that we cannot apply the dynamic estimator on ˆvl(t) since we do not have a-priori
information about the dynamics of l. To dynamically estimate ˆd(t) and ˆvf (t), we use an a priori

estimation derived from the state equations as well as a weighted residual of output error to

correct the a priori estimation as follows [29]:

ˆx(t)
(cid:124)(cid:123)(cid:122)(cid:125)
estimation

= ˆx(−)(t)
(cid:124) (cid:123)(cid:122) (cid:125)
a priori estimation

+ K(t)
(cid:124)

residual
(cid:122)
(cid:125)(cid:124)
(cid:104)
z(t) − H ˆx(−)(t)

(cid:123)
(cid:105)
,

(cid:123)(cid:122)
correction

(cid:125)

(13)

where K(t) is the Kalman gain. By deﬁning an a posteriori error covariance matrix P (t) =
E (cid:2)r(t)rT (t)(cid:3), where r(t) = x(t) − ˆx(t), we can ﬁnd a K(t) to minimize trace [P (t)] =
E (cid:2)rT (t)r(t)(cid:3). The solution for such K(t) can be given by [29]:

ˆx(−)(t) = Aˆx(t − 1) + Buf (t − 1) + F ˆvl(t − 1),

P (−)(t) (cid:44) AP (t − 1)AT ,

K(t) = P (−)(t)H T (cid:104)

HP (−)(t)H T + R

(cid:105)−1

,

ˆx(t) = [I − K(t)H] ˆx(−)(t) + K(t)z(t),

P (t) = [I − K(t)H] P (−)(t).

(14)

(15)

(16)

(17)

(18)

where R =





Rf

0nf ×nd

0nd×nf

Rd


is a block diagonal matrix. As can be seen from (15), (16), and

(18), the update processes for P (t) and K(t) are independent of the states and controller. Thus,
P (t) and K(t) will converge to constant matrices, ˜P and ˜K.

For the studied system, we now deﬁne the cyber-physical security problems for ACV systems

that we will study next. We will address three main problems: 1) What is the optimal safe

ACV controller for the system in (2) that minimizes the risk of accidents while maximizing the

trafﬁc ﬂow on the roads? 2) Is the proposed optimal safe controller for ACV systems robust

8

and stable against physical attacks? and 3) How to securely fuse the sensor readings to mitigate

DIAs on ACVs and minimize the impact of such attacks on the control of ACVs? Addressing

these problems is particularly important because the model in (2) identiﬁes the microscopic

characteristics of an ACV network and, thus, to achieve large-scale security and safety in ACV

networks we must secure every ACV against cyber-physical attacks.

Addressing these three problem requires a comprehensive study of the interdependencies

between the cyber and physical characteristics of ACV systems. Such interdependent cyber-

physical study helps to ﬁnd the vulnerabilities of the ACV systems against both cyber and

physical attacks. Thus, we can derive an optimal controller that minimizes the risk of accidents

and we can design cyber attack detection approaches that not only take into account the cyber

characteristics of the ACV system, but also aims at minimizing the likelihood of collisions in

ACV networks. Unlike the works in [11]–[19], we consider the physical characteristics of ACV

systems while developing DIA detection approaches. Moreover, the combined optimal and safe

ACV controller design has not been studied previously in [20]–[26].

III. OPTIMAL SAFE ACV CONTROLLER

Our ﬁrst task is thus to derive an optimal safe controller for ACV systems. To analyze ACV
f ’s optimal control input uf (t), we deﬁne an optimal safe spacing value as o(vf (t)) (cid:44) v2
f (t)
2bf T ,
where bf is ACV f ’s maximum braking deceleration. This value is deﬁned so as to guarantee

that if the leading ACV l stops suddenly, the following ACV f will stop completely before

hitting ACV l as long as f starts braking immediately after observing l’s braking process. This

can be captured by the following energy equivalence condition:

mf
2

(cid:124)

(v2

f (t) − 0)
(cid:125)
(cid:123)(cid:122)
Kinetic Energy

= mf bf d(t)
(cid:124)
(cid:125)
(cid:123)(cid:122)
Potential Energy

⇒ o(vf (t)) =

v2
f (t)
2bf

.

(19)

Our goal here is to maintain an optimal safe spacing between ACVs f and l. Thus, we deﬁne

a physical regret R(t) as the square of difference between the optimal safe spacing and the

actual spacing. This regret quantiﬁes the safety and optimality of ACV motion by preventing

any collisions and minimizing the spacing between the ACVs and can be written as follows:

R(t) = (o(vf (t + 1)) − d(t + 1))2 =

=

(cid:18) (vf (t) + T uf (t))2
2bf

(cid:18) v2

f (t + 1)
2bf

(cid:19)2

− d(t + 1)

(cid:19)2

− d(t) − T vl(t) + T vf (t)

(20)

9

In addition, each ACV only have access to estimation of vf (t), vl(t), and d(t). Thus, ACV f

must design an input uf (t) to minimize an estimation of physical regret which is deﬁned as

follows:

ˆR(t) =

(cid:18) (ˆvf (t) + T uf (t))2
2bf

− ˆd(t) − T ˆvl(t) + T ˆvf (t)

(cid:19)2

.

(21)

This problem is challenging to solve because ˆvl(t) is an independent parameter and ACV f cannot

be sure about the future values of ˆvl(t). To solve this problem, we consider two scenarios: a)

ACV f has no prediction about ACV l’s future speed values (One-step ahead controller) and b)

ACV f has a predictor which can predict ACV l’s future speed value for N time steps (N -step

ahead controller)(such predictors have attracted recent attention in the transportation literature,

e.g., see [30] and [31]). Next, we propose an optimal controller for these two cases.

A. One-step ahead controller

To solve the one-step ahead controller problem, we consider some physical limitations on

the speed and the control input. We prohibit the speed from being greater than the free-ﬂow

speed of a road, ˜v. Moreover, due to the physical capabilities of the vehicle and for maintaining

passengers’ comfort, we must have a limitation on the control input and speed deviation. Thus,

the optimization problem of the ACV f can be written as follows:

u∗
f (t) = arg min

uf (t)

ˆR(t)

s.t. umin

f ≤ uf (t) ≤ umax

f

,

0 ≤ vf (t + 1) ≤ ˜v,

|uf (t) − uf (t − 1)| ≤ ∆u,

(22)

(23)

(24)

(25)

where umin

f < 0 and umax

f > 0 are the minimum and maximum allowable control input and ∆u

is the maximum allowable change in the controller to yield a comfortable ride.

Theorem 1. The one-step ahead optimal controller is:

(cid:40)

(cid:40)

u∗
f (t) = min

max

u1(t),

(cid:32)(cid:114)

1
T

(cid:16) ˆd(t) + T ˆvl(t) − T ˆvf (t)

(cid:17)

2bf

(cid:33)(cid:41)

(cid:41)

− ˆvf (t)

, u1(t)

(26)

where u1(t) (cid:44) max

(cid:110)−ˆvf (t)
T

,umin

f ,uf (t − 1) − ∆u

(cid:111)

and u1(t) (cid:44) min

(cid:110) ˜v−ˆvf (t)
T

, umax
f

, uf (t−1)+∆u

(cid:111)
.

Proof. See Appendix A.

(cid:4)

10

Theorem 1 derives the optimal controller for the ACV f when it only optimizes its action for

the next step without considering future actions. In the next subsection, we derive the ACV f ’s

optimal controller when it considers minimizing the regret for N step ahead.

B. N -step ahead controller

To ﬁnd the N -step ahead controller, ﬁrst we deﬁne a discount factor 0 ≤ γ ≤ 1 which speciﬁes

the level of future physical regret for the decision taken at each time step. Thus, by deﬁning
the N -step ahead total discounted physical regret R(t, N ) (cid:44) (cid:80)t+N −1
γτ −t ˆR(τ ), the controller

τ =t

optimization problem can be written as follows:

(cid:40)
u∗
]
f (t) = [1, 0, . . . , 0
(cid:124) (cid:123)(cid:122) (cid:125)
N −1

arg min
uN
f (t)

R(t, N )

(cid:41)
,

(27)

where the conditions in (23), (24), and (25) hold true. Moreover uN

f (t) = [uf (t), . . . , uf (t +
N − 1)]T , N is the number of future steps which is taken into account in ﬁnding the optimal

controller, and u∗

f (t) is the optimal controller at time step t.

Theorem 2. The solution of N -step ahead controller is equivalent to the one-step ahead con-

troller.

Proof. To solve the problem in (27), we use a so called indirect method. To this end, we start

by deﬁning an augmented physical regret using the following state equation:



R(cid:48)(t, N ) = R(t, N ) +

t+N −1
(cid:88)

τ =t

λT (τ + 1)


Aˆx(τ ) + Buf (τ ) + F vl(τ )
(cid:125)
(cid:123)(cid:122)
(cid:124)
g(τ )

−ˆx(τ + 1)






t+N −1
(cid:88)

(cid:104)

=

τ =t

γτ −t ˆR(τ ) + λT (τ + 1) [g(τ ) − ˆx(τ + 1)]

(cid:105)

,

(28)

where λ(τ ) = [λ1(τ ), λ2(τ )]T . Then, let Hamiltonian function deﬁned as H(τ ) (cid:44) γτ −t ˆR(τ ) +
λT (τ + 1)g(τ ). Thus, we can write (28) as follows:

R(cid:48)(t, N ) = λT (t + N )ˆx(t + N )
(cid:125)

(cid:124)

(cid:123)(cid:122)
terminal time

+

+ H(t)
(cid:124)(cid:123)(cid:122)(cid:125)
initial time

t+N −1
(cid:88)

τ =t+1
(cid:124)

(cid:2)H(τ ) − λT (τ )ˆx(τ )(cid:3)

.

(29)

(cid:123)(cid:122)
running time

(cid:125)

Thus, to ﬁnd critical points (candidate minima) we must solve ∇R(cid:48)(t, N ) = 0. First, we start

by ﬁnding the differential dR(cid:48)(t, N ) and then we identify the derivatives as follows:

dR(cid:48)(t, N ) = λT (t + N )dˆx(t + N ) + (cid:0)∇ˆx(t)H(t)(cid:1)T dˆx(t) +

t+N −1
(cid:88)

τ =t+1

(cid:0)∇x(τ )H(τ ) − λ(τ )(cid:1)T dˆx(τ )

t+N −1
(cid:88)

+

τ =t

(cid:0)∇u(τ )H(τ )(cid:1)T du(τ ) +

t+N
(cid:88)

τ =t+1

(cid:0)∇λ(τ )H(τ − 1) − ˆx(τ )(cid:1)T dλ(τ ).

Thus, to have dR(cid:48)(t) = 0 each of the terms in brackets must be equal to zero:

λ(t + N ) = 0,

∇ˆx(t)H(t) = 0, ⇒ ˆx(t) =

(cid:104)

ˆvf (t), ˆd(t)

(cid:105)T

,

11

(30)

(31)

(32)

λ(τ ) = ∇ˆx(τ )H(τ ) = ∇ˆx(τ )γt−τ ˆR(τ ) + ∇ˆx(τ )g(τ )λ(t + 1), ∀τ = t + 1, . . . , t + N − 1, (33)

0 = ∇u(τ )H(τ ) = ∇u(τ )γt−τ ˆR(τ ) + ∇u(τ )g(τ )λ(t + 1),

∀τ = t, . . . , t + N − 1, (34)

∇λ(τ +1)H(τ ) = ˆx(τ + 1) ⇒ ˆx(τ + 1) = g(τ ),

∀τ = t, . . . , t + N − 1. (35)

Now, using (33) we will have:

 γt−τ (cid:16) (ˆvf (τ )+T uf (τ ))2

ˆvf (τ )+T uf (τ )
bf

λ(τ ) =

+ T





2bf

−1

(cid:17)
− ˆd(τ ) − T ˆvl(τ ) + T ˆvf (τ )

+ AT λ(τ + 1).

Moreover, from (34) we will have:

0 = γt−τ

(cid:18) (ˆvf (τ ) + T uf (τ ))2
2bf

− ˆd(τ ) − T ˆvl(τ ) + T ˆvf (τ )

(cid:19) T (ˆvf (τ ) + T uf (τ ))
bf

(36)

+ BT λ(τ + 1).

(37)

Since λ(t + N ) = 0, then from (37), we derive:
(cid:114)

(cid:34)

uf (t + N − 1) = 1
T

±

2bf

(cid:17)
(cid:16)ˆd(t + N − 1) + T ˆvl(t + N − 1) − T ˆvf (t + N − 1)

(cid:35)
− ˆvf (t + N − 1)

.

(38)
By substituting uf (t+N −1) in (36), we obtain λ(t+N −1) = 0. This process can continue until
(cid:35)

(cid:34)

(cid:114)

τ = t where we obtain λ(t+1) = 0 and uf (t) = 1
T

±

2bf

(cid:16) ˆd(t) + T ˆvl(t) − T ˆvf (t)

(cid:17)

− ˆvf (t)

.

Moreover, considering the constraints (23), (24), and (25), we will end up having the optimal

controller as deﬁned in Theorem 1. Thus, we prove that the N -step ahead optimal controller is

equivalent to 1-step ahead optimal controller.

(cid:4)

From Theorem 2, we can observe that, if the ACV f minimizes its immediate physical regret,

it will also minimize its long-term physical regret. This result shows that the proposed optimal

safe controller does not require any information from future dynamics of ACV l as done in [30]

and [31].

12

IV. PHYSICAL ATTACK ON ACV SYSTEMS

As derived in the previous section, the proposed optimal controller is a function of ˆvl(t). This

makes ACV f vulnerable against a physical attack on ACV l. Thus, we now analyze whether an

attacker can cause instable dynamics at ACV f by controlling l. Consider an adversary who takes

the control of ACV l and tries to cause instability in ACV f ’s speed, vf (t), and spacing d(t).

Using our derived optimal controller, by ensuring uf (t) is not saturated (u1(t) ≤ uf (t) ≤ u1(t)),
and considering the estimated values to be close to the real values we will have:

vf (t + 1) =

(cid:113)

(cid:124)

,
2bf (d(t) + T vl(t) − T vf (t)
(cid:125)
(cid:123)(cid:122)
g1(x(t),vl(t))

d(t + 1) = d(t) + T vl(t) − T vf (t)
(cid:125)

(cid:124)

(cid:123)(cid:122)
g2(x(t),vl(t))

.






⇒ x(t + 1) = g(x(t), vl(t)),

(39)

where g = [g1(x(t), vl(t)), g2(x(t), vl(t))]T . (39) is designed such that ACV f will always

maintain an optimal safe spacing with l. However, from (39) we can see that the behavior of

the system is a function of vl. Thus, next, we will analyze the physical attack scenario that is

analogous to the Jeep hijacking case in [10].

A. Stability Analysis

To analyze the stability of (39), ﬁrst, we deﬁne some useful concepts.

Deﬁnition 1. [28] ¯x(vl) is said to be an equilibrium point for the system in (39) and a constant

input vl, if g(¯x(vl), vl) = ¯x(vl).

An equilibrium indicates a point at which the states will not change. From Deﬁnition 1 we

can derive the equilibrium point for (39) by considering a constant input vl and solving the

following set of equations:

¯vf (vl) =

(cid:113)

2bf ( ¯d(vl) + T vl − T ¯vf (vl), ¯d(vl) = ¯d(vl) + T vl − T ¯vf (vl),

(40)

which results in: ¯x(vl) =

(cid:105)T

(cid:104)
vl, vl
2bf

. The derived value for ¯x(vl) shows that in order to reach

an equilibrium, ACV f must maintain the optimal safe spacing from ACV l and its speed must

equal to vl. Thus, next, we show that our derived optimal controller is robust, i.e., under our

controller if an adversary hijacks ACV l, it cannot cause instability in vf (t) and d(t).

Deﬁnition 2. A system is called asymptotically stable around its equilibrium point if it satisﬁes

the following two conditions [28]: 1) Given any vl > 0 and ε > 0, ∃δ1 > 0 such that if

13

|x(ts) − ¯x(vl)|, then |x(t) − ¯x(vl)| < (cid:15), ∀t > ts and 2) ∃δ2 > 0 such that if |x(ts) − ¯x(vl)| < δ2,

then x(t) → ¯x(vl) as t → ∞.

The ﬁrst condition requires the state trajectory to be conﬁned to an arbitrarily small “ball”

centered at the equilibrium point and of radius ε, when released from an arbitrary initial condition

in a ball of sufﬁciently small (but positive) radius δ1. This is called stability in the Lyapunov

sense [28], [32]. It is possible to have Lyapunov stability without having asymptotic stability.

Next, we show how a Lyapunov function can help to analyze the stability of system (39) [28].

From [28], we know that if there exists a Lyapunov function for system (39), then x(t) = ¯x(vl) is

a stable equilibrium point in the sense of Lyapunov. In addition, if L(g(x(t), vl)) − L(x(t)) < 0

then x(t) = ¯x(vl) is an asymptotically stable equilibrium point. We can prove that the system

in (39) is asymptotically stable for the equilibrium point ¯x(vl), as follows.

Proposition 1. x(t) = ¯x(vl) is a stable equilibrium point in the Lyapunov sense.

Proof. Let L(x(t)) =

(cid:16) v2

f (t)
2bf

(cid:17)2

− d(t)

. Then we will have L(¯x(vl)) = 0. Moreover, we can show

that L(x(t)) ≥ 0, ∀x(t). Now, to check if L is a Lyapunov function we have:
(cid:18)(cid:113)

(cid:19)2

(cid:32)

L(g(x(t), vl)) − L(x(t)) =

2bf (d(t) + T vl − T vf (t)

− d(t) + T vl − T vf (t)

1
2bf

−

(cid:18) v2

f (t)
2bf

(cid:19)2

− d(t)

= −

(cid:18) v2

f (t)
2bf

(cid:19)2

− d(t)

≤ 0.

Thus, x(t) = ¯x(vl) is a stable equilibrium point in the sense of Lyapunov.

(cid:33)2

(41)

(cid:4)

From Proposition 1, we can see that, as long as f follows l using our proposed controller, its

speed and spacing from l will stay stable and will not be affected by the physical attack on l.

This shows that, not only our proposed controller maximizes the safety and optimality in ITS

roads, but also it is robust to physical attacks such as in the Jeep scenario [10].

However, as can be seen from Theorems 1 and 2, even though it is robust to physical attacks,
the derived optimal controller is largely dependent on the estimated values ˆvf (t), ˆvl(t), and ˆd.

Thus, an adversary can manipulate the sensor data to inject error in the estimation and ultimately

increase the ACV f ’s physical regret. Analyzing such attacks require a cyber-physical study of

the ACV system to derive approaches that mitigate attacks on sensors and minimize the effect of

such attacks on the physical regret. Thus, next, we analyze the cyber attack on the ACV system.

V. CYBER ATTACK ON ACV SYSTEMS

We now consider a cyber attacker that injects faulty data to sensor readings (cameras, LiDARs,

14

radars, IMUs, and roadside sensors) such that the attacked sensor vector can be written as:










¯z(t) (cid:44)



¯zf (t)

¯zd(t)














(cid:44)










+











zf (t)

zd(t)

zl(t)

¯zl(t)

af (t) (cid:44) [af1, . . . , afnf
ad(t) (cid:44) [ad1, . . . , adnd
al(t) (cid:44) [al1, . . . , alnl
]T

]T

]T



,






(42)

where af (t), ad(t), and al(t) are data injection vectors on sensors and ¯zf (t), ¯zd(t), and ¯zl(t)

are compromised sensor readings from vf (t), d(t), and vl(t), respectively. As we discussed in the

state estimation section, we have a-priory information about sensors which measure vf (t) or d(t),

but such information is lacking for sensors that collect data from vl(t). Thus, next, we consider

cyber attacks on sensors a) with a-priori information and b) without a-priori information.

A. Attack on sensors with a-priori information

As discussed in Subsection II-B, we use Kalman ﬁltering to estimate ˆvf (t) and ˆd(t). However,

Kalman ﬁltering is not robust to DIAs [33]. Thus, we propose a ﬁltering mechanism that can limit
the effect of the DIA on ˆvf (t) or ˆd(t). To this end, we use the a priori estimation ˆx(−)(t) at each
time step to ﬁnd an a priori sensor reading z(−)(t) (cid:44) H ˆx(−)(t). Then, the attack detection ﬁlter
(cid:35)T

checks the absolute value of the residual |µ(t)| (cid:44)
(cid:12)z(t) − z(−)(t)(cid:12)
(cid:12)
will be considered as a compromised sensor and will not be involved in Kalman ﬁlter update

(cid:12) < η, where η is the threshold vector. Any sensor which violates this inequality

(t)|, |µd1(t)|, . . . , |µdnd

(t)|

(cid:34)
|µf1(t)|, . . . , |µfnf

(cid:44)

procedure. To ﬁnd an optimal value for the threshold η, we next characterize the stochastic

behavior of residual µ(t) when the ACV is not under attack.

Theorem 3. The residual µ(t) follows a Gaussian distribution with zero mean and covariance

matrix as follows:

C µ = HC rH T + R − R ˜K

T

QT H T − HQ ˜KR,

(43)

and C r is the solution of following discrete Ricatti equation C r = QAC rAT QT + C ρ, where
(cid:20)

(cid:21)−1

C ρ = QF σ2

l F T QT + Q ˜KR ˜K

T

QT , and Q =

I +

(cid:104)
I − ˜KH

(cid:105)−1

˜KH

.

(cid:4)

Proof. See Appendix B.

Theorem 3 derives the distribution of µ(t) which we will use next to ﬁnd an optimal value for

the threshold level η. Fig. 2 and Fig. 3 show a comparison between simulation and analytical

15

Fig. 2: Analytical and simulation result for cumulative density function of ρ(t) and r(t).

Fig. 3: Analytical and simulation result for the mean and variance of µ(t).

results derived for the mean and covariance matrix of r(t), ρ(t), and µ(t). From Figs. 2 and 3

we can that the analytical results match the simulation results which validates Theorem 3.

We can now ﬁnd the probability with which µi(t) (element i of µ(t)) remains below the

threshold value ηi as Pr (|µi| ≤ ηi) = Pr (−ηi ≤ µi ≤ ηi) = Φµi(ηi) − Φµi(−ηi), where Φµi(.)

is the cumulative density function of µi which follows a Gaussian distribution with zero mean

and variance Cµ(i, i) (element in i-th row and i-th column of C µ). Thus, we can derive the

optimal value for eta by deﬁning Pr (|µi| ≤ ηi) for every sensor. For instance, choosing values

ηi = Cµ(i, i), 2Cµ(i, i), or 3Cµ(i, i) will result in Pr (|µi| ≤ ηi) = 0.68, 0.95, or 0.997. Even by

deﬁning the threshold value, the attacker might stay stealthy in some cases if it controls the

amount of injected data to the sensors. Next, we ﬁnd a relationship between the maximum value

of DIA and the probability of staying stealthy.

Proposition 2. The probability with which an attack vector ˜a (cid:44) [af , ad]T will not trigger the

i-th element of attack detection ﬁlter, µi, (stealthy attack) will be given by:

pi(˜a) (cid:44) Pr (|µi| ≤ ηi|˜a) = Φµi(Ψ i ˜a + ηi) − Φµi(Ψ i ˜a − ηi),

(44)

01524610108010-31010-3012-5-1200.050-0.05123105410-3506-21021312432543566778812345678-0.07-0.06-0.05-0.04-0.03-0.02-0.0100.01where Ψ i is the i-th row of Ψ =

(cid:104)

I − H [I − QA]−1 Q ˜K

(cid:105)

.

Proof. Suppose that the attacker initiates attack after the Kalman ﬁlter converges. Thus, from

16

(14) and (17) we have:

ˆx(t) =

(cid:104)
I − ˜KH

(cid:105)

ˆx(−)(t) + ˜K z(t)
(cid:124)(cid:123)(cid:122)(cid:125)
[Hx(t)+e(t)]

+ ˜K





af





ad
(cid:124) (cid:123)(cid:122) (cid:125)
˜a

(cid:104)

=

I − ˜KH

(cid:105) (cid:104)

Aˆx(t − 1) + Buf (t − 1)

(cid:105)
+ F ˆvl(t − 1)

+ ˜KH [ˆx(t) + r(t)] + ˜K [e(t) + ˜a] .

(45)

Thus, by simpliﬁcations analogous to the proof of Theorem 3, we can ﬁnd r(t) = QAr(t − 1) −
Q ˜K ˜a + ρ(t). The expectation of r(t) will be E {r(t)} = QA E {r(t − 1)} − Q ˜K E {˜a} . Since

the attack vector is constant, ˜a, and E {r(t)} = E {r(t − 1)} for t → ∞ we will have the steady
state expected estimation error as E {r(t)} (cid:44) ¯r = − [I − QA]−1 Q ˜K ˜a. Thus, considering such

steady state expected estimation error, ¯r, we can derive the mean of µ(t):

E {µ(t)} = E (cid:8)z(t) − z(−)(t)(cid:9) = E {Hr(t) + ˜a + e(t)} =

(cid:104)
I − H [I − QA]−1 Q ˜K
(cid:123)(cid:122)
Ψ

(cid:124)

(cid:105)

(cid:125)

˜a.

Since ad is constant, then σµ will not change. Therefore, we can ﬁnd the probability of not
(cid:4)

triggering the attack detection ﬁlter for µi as in (44).

Proposition 2 derives the probability of staying stealthy for any particular DIA vector. Next

we will ﬁnd how much our deﬁned attack detection ﬁlter is robust against a particular DIA. To
this end, ﬁrst we deﬁne a stealthy attack probability vector as p(˜a) = (cid:2)p1(˜a), . . . , pnf +nd(˜a)(cid:3)T
which is a vector that shows the probability of staying stealthy by initiating ˜a on all of the vf

,

and d type sensors. The attacker has to ﬁnd the optimal value of ˜a which maximizes the physical

regret while staying stealthy with probability below a deﬁned value, p, i.e., attack vector must

be chosen such that the physical regret is maximized and every sensor i stays stealthy with the

probability below the i-th element of p.

Corollary 1. The attacker’s optimal attack vector a∗ which maximizes the steady state physical

regret by attacking vf or d type sensors is the solution of following optimization problem:

arg max
˜a

˜θ2 (cid:44) (cid:2)¯rT Θ¯r + cT ¯r(cid:3)2

,

s.t. ¯r = − [I − QA]−1 Q ˜K ˜a,

(46)

(47)





1
2bf
0

0

0





 , c =



√
˜d

bf

+ T

−1



 ,

Θ (cid:44)

where ˜d is the average spacing between the ACVs.

p(˜a) ≥ p,

Proof. From the deﬁnition of physical regret we have:
(cid:32)(cid:0)vf (t) + T u∗

f (t)(cid:1)2

R(t)

(cid:12)
(cid:12)
(cid:12)u∗

f (t)

=

2bf

− d(t) − T vl(t) + T vf (t)

(cid:33)2



2



r2
f (t)
2bf








(cid:124)

=

+

rf (t)
bf

(cid:115) ˆd(t) + T ˆvl(t) − T ˆvf (t)
(cid:123)(cid:122)
(cid:125)
(cid:39) ˜d

(cid:124)

− rd(t) − T rl(t) + T rf (t)

(cid:123)(cid:122)
θ(t)

(cid:125)









17

(48)

(49)

(50)

,

Moreover, the steady state value of θ(t) can be derived by using the steady state expected value
of ¯r as ¯θ = ¯rT Θ¯r + cT ¯r. Also, the attacker must choose ad to satisfy (44). Thus, the attacker
(cid:4)

must solve the optimization problems in (46).

Corollary 1 derives a robustness level for our proposed attack detection ﬁlter. It allows us to

ﬁnd the maximum regret which is caused by any stealthy attack vector. This allows us to design

a secure cyber-physical ACV system since we take into account the physical regret of DIAs on

sensors. However, the proposed attack detection ﬁlter works for sensors with a-priori information

only. For ACV f ’s other sensors which measure vl(t) we do not have a-priori information. Thus,

we next address this case using MAB.

B. Multi-armed bandit learning for attack detection in sensors without a-priori information

To detect the attack on vl type sensors, we cannot use any a priori estimation for vl(t) as

done for vf and d type sensors because ACV f cannot have any information about evaluation of

vl(t) since it does not know how ACV l is being controlled. Such lack of a priori information

makes the attack detection challenging. To overcome this challenge, we propose to use a MAB

learning approach because such approach does not require a-priori information and ﬁnds the

optimal action (detecting attacked sensors) only by interacting with the sensors and ACV’s

dynamics. Before applying the MAB algorithm, we deﬁne an a posteriori estimation for vl(t):
ˆd(t + 1) − ˆd(t)
T

+ ˆvf (t).

v(+)
l

(t) =

(51)

Here, we also deﬁne an a posteriori residual as

(cid:12)
(cid:12)µ(+)
(cid:12)
(cid:12)
(cid:12). Next, we analyze the distribution of µ(+)
(cid:12)
zl(t)

l

l

18

(cid:104)

(cid:44)

(cid:12)
(cid:12)
(t)
(cid:12)

|µ(+)
l1

(t)|, . . . , |µ(+)
lnl

(cid:105)T

(t)|

(cid:44)

(cid:12)
(cid:12)hlv(+)
(cid:12)

l

(t)−

(t) to use it to design an attack detection ﬁlter.

(t) follows a Gaussian distribution with zero mean and covariance matrix C µl:

QT AT H T − HAQ ˜KR + R

Theorem 4. µ(+)

l
C µl = Υ RlΥ T + hlJ

where Υ = (cid:2)− s1

T hlwT

(cid:104)
HAC rAT H T − R ˜K
(cid:105) ˜K.
(cid:104)

l − I(cid:3) and J =

0 1

T

Proof. See Appendix C.

(cid:105)

J T hT
l ,

(52)

(cid:4)

Theorem 4 derives the covariance matrix for µ(+)

l

(t) which we will use to detect anomaly in

the vl(t) type sensors. To this end, ﬁrst, we deﬁne the squared Mahalanobis (SM) distance, a

measure which quantiﬁes the distance between the a posteriori residual of sensors in a subset L
of vl type sensors, µ(+)
Theorem 4. SM will help us ﬁnd how much every subset L deviates from its distribution.

(t, L), and the distribution of a posteriori residuals which is derived in

l

Deﬁnition 3. The squared Mahalanobis distance between subset L’s a posteriori residual at time
t and its distribution is deﬁned as DL(t) = µ(+)
subset L’s SM and C µl(L) is the covariance matrix associated with L.

(t, L), where DL(t) is the

(t, L)C −1
µl

(L)µ(+)

T

l

l

Next, we derive the expected value and variance of DL(t). We know from [34, (378)] that
(L)C µl(L)(cid:1) = Tr (I) = |L|, where
|L| is the number of sensors in L. In addition, for a subset L of vl type sensors and an attack

= Tr (cid:0)C −1
µl

E {DL(t)} = E

(t, L)C −1
µl

(L)µ(+)

µ(+)
l

(t, L)

(cid:110)

(cid:111)

T

l

vector al(t), we will have:

E {DL(t)} = E

(cid:110)

µ(+)
l

T

(t, L)C −1
µl

(L)µ(+)

l

(t, L) + aT

l (t)C −1
µl

(cid:111)

al(t)

(53)

= |L| + E (cid:8)aT

l (t, L)C −1
µl

(L)al(t, L)(cid:9) ,

where al(t, L) consists of only elements of al(t) which are in L. Since C µ(L) is positive semi
deﬁnite then C −1

µ (L) is also positive semi deﬁnite. Thus, we will have E

l (t, L)C −1
aT
µl

(L)al(t,

(cid:110)

≥ 0. Therefore, if there exists a subset L such that E {DL(t)} ≥ |L|, then there is at least

(cid:111)

L)

one sensor under attack in L. Hence, at each time step, to estimate ˆvl(t), ACV f must choose

a subset L which has the least divergence from |L|. To capture the security level of a subset,
we deﬁne a security divergence (SD) metric for a subset L as ςL(t) (cid:44) E{DL(t)}

|L| ≥ 1. Therefore,

a subset L with a lower ςL(t) value has a higher security level.

Moreover, any subset L of vl type sensors have a cost based on the estimation error induced

to ˆvl(t). Thus, we deﬁne the cost of L, as νL = E (cid:8)(vl(t) − ˆvl(t, L))2(cid:9), where ˆvl(t, L) is the
estimation of vl using the subset L. Thus, to ﬁnd νL we have:

19

E{(vl(t)−ˆvl(t,L))2}=E

(cid:110)((cid:80)

i∈L wli eli)2(cid:111)

=E











(cid:80)

i∈L

(cid:80)

i∈L

1
eli
σ2
li
1
σ2
li






2


=



(cid:80)

i∈L





1
σ4
li

(cid:40)

(cid:41)

E

e
l2
i
2 =




(cid:80)

i∈L

1
σ2
li

2 =



(cid:80)

i∈L



(cid:80)



i∈L

1
σ2
li

1

(cid:80)

i∈L

.

1
σ2
li



1
σ2
li
has a lower cost.

i∈L

1
σ2
li

Therefore, we have νL =

(cid:80)

1

i∈L

1
σ2
li

. Clearly, a subset L with a higher (cid:80)

While DL represents a security measure for a subset L, νL can be considered as an estimation

performance metric. Thus, at each time step, ACV f must choose a subset L which has the

minimum SD as well as the minimum cost. Thus, we have to ﬁnd the secure high performance

subset L∗(t) which is a subset that is secure and has the lowest estimation cost. To this end, a

minimization problem that ﬁnds the secure high performance subset can be deﬁned as L∗(t) =

arg minL ξL(t), where, ξL(t) = νLςL(t). Although νL is known for f , ςL(t) might change due
to an attack on vl type sensors. Thus, we propose an MAB learning algorithm which learns

the secure high performance subset L∗(t) [35], [36]. Our goal here is to choose a safe subset

of sensors out of all available sensors by efﬁciently exploring different subsets and effectively

exploiting the optimal subset, thus, we can apply an MAB framework to solve our problem.

In an MAB problem, a decision maker (ACV f ), pulls an arm from a set of available arms

(selects a subset L from vl type sensors). Each arm generates a cost after being played, based

on a distribution that is not known to the decision maker. The aim of ACV f is to minimize a

cumulative cyber regret. This regret is deﬁned as the difference between the reward of the best

possible arm at each step, and the generated reward of the arm that is played [35]–[37].

Let ξ∗(t) = ξL∗(t)(t) be the lowest cost that could be achieved at time t from vl type sensors.

Thus, the cyber regret from t = t0 up to a time t = te is deﬁned as:

Rc(t0, te) (cid:44) E

ξ∗(t)

,

(54)

(cid:34) te(cid:88)

t=t0

ξL(t) −

te(cid:88)

t=t0

(cid:35)

where the expectation is taken over the random choices of the L. Cyber regret implies choosing

non-optimal and non-secure subset of sensors. Thus, having a high cyber regret implies choosing

a subset of sensors with higher error and possibly higher injected data which can lead to an

estimation error for ˆvl(t). Since our proposed optimal controller which minimizes the physical

regret is a function of estimated value, ˆvl(t), thus, higher cyber regret results in a higher

estimation error and can introduce physical regret to ACV f . This clearly shows the cyber-

physical aspects of ACV security.

One of the most recognized methods for the MAB problem is to use the concept of UCB

20

[35]. In this method, the MAB algorithm at each time t chooses L such that:

I(t) = arg max

1
nL
where nL is the number of times that arm L was played before and tL,i is the time step when
L is selected for i-th time. Also, note that nL → ∞, 1
nL

i=1 DL(tL,i) → E {DL(t)} [35], [36].

DL(tL,i) +

−νL
|L|

(cid:80)nL

(55)

i=1

L

(cid:114) 2 ln t
nL

nL(cid:88)

The UCB algorithm has an expected cumulative regret of:

E {Rc(t0, te)} = 8

(cid:88)

L|ξL<ξ∗

ln(te − t0 + 1)
E [ξL] − E [ξ∗]

(cid:18)

+

1 +

π2
3

(cid:19) (cid:88)

L|ξL<ξ∗

E [ξL] − E [ξ∗] .

(56)

We use UCB algorithm because it has a logarithmic cyber regret and has been shown that there

exists no algorithm that can have a better cyber regret [36]. Thus, using the UCB algorithm and

the deﬁned cyber regret we can address the DIA detection problem for sensors which lack a

priori information.

VI. SIMULATION RESULTS AND ANALYSIS

For our simulations, we assume that ACV l has a sinusoidal speed pattern and ACV f ’s

initial speed and spacing from the ACV l are vf (0) = 90 km/h and d(0) = 100 m. We set
nf = nd = nl = 4, T = 0.1 s, bf = 2.5 m/s2, and umax

f = 0.25 N/kg, which are chosen

f = −umin

based on practical ACV characteristics [13].

A. Optimal Safe Controller

Fig. 4a shows an ACV which uses the proposed optimal controller. From Fig. 4a, we make

three observations: 1) The physical regret converges to zero and the actual spacing converges

to the optimal safe spacing after approximately 20 seconds which shows that the proposed

controller works properly, 2) The speed of ACV f , vf (t), exhibits, approximately, a 5 seconds

delay compared to the ACV l’s speed vehicle vl(t). This is because ACV f should ﬁrst observe

ACV l and then control its own speed, and 3) The estimated states match with the actual state

values which shows that applied state estimation estimation processes have an error close to

zero.

Fig. 4b shows a comparison between our proposed controller with Gipps [38] and the intelli-

gent driver model (IDM) [39] controllers, two of the well-known controllers for ACV leading-

following scenarios. From Fig. 4b, we can observe three key points: 1) Our proposed controller

can follow the speed of ACV l better compared to IDM as we can see that IDM converges

to an almost constant speed while our proposed controller can track vl(t), 2) The proposed

controller converges to the optimal safe spacing. However, the IDM model has a positive offset

from the optimal safe spacing and the Gipps controller always has a smaller spacing than the

21

(a) The proposed controller, physical regret, speed and

(b) Comparison of proposed controller, Gipps, and

spacing.

IDM.

Fig. 4: The proposed optimal controller’s effect on the physical regret.

optimal safe spacing. This shows that the Gipps model does not take into consideration the

safety as we can see from Fig. 4b that the spacing can admit small values close to 0 meters

which increases the risk of collision. On the other hand, the IDM model does not consider the

optimality of trafﬁc ﬂow as it always yields a higher spacing than the optimal spacing, and 3)

The cumulative physical regret for our proposed optimal safe controller outperforms the other

two models thus demonstrating that the proposed controller can jointly yield optimality and

safety in ACV systems.

B. Robustness Against Physical Attacks

Next, we simulate an attacker which takes control of ACV l and after 100 seconds suddenly

drops the speed of ACV l from 75 km/h to 5 km/h. Fig. 5 shows the effect of this attack on the

ACV f ’s speed, spacing and physical regret. Fig. 5 shows that our proposed controller always

maintains the optimal safe spacing even in presence of an attack. In contrast, the Gipps and IDM

controllers always have an offset from the optimal safe spacing. Hence, our proposed controller

is more robust against physical attacks. Note that, although Gipps can track the speed faster than

our proposed method, however, it does not optimize the spacing. In addition, we can see from

Fig. 5 that the proposed controller has a physical regret closed to zero while the cumulative

regret of IDM and Gipps grow linearly since they have a constant offset from the optimal safe

spacing in this attack scenario.

7075808590-0.2-0.100.10.26080100120140020406080100120140160180050010001500657075808590050100150020406080100120140160180200024610715016017018019020005010022

Fig. 5: A comparison of the proposed controller, Gipps, and IDM when ACV system is

C. Cyber Security of ACV Systems

physical attacked.

To illustrate the effectiveness of our proposed attack detection approaches, in Fig. 6, we analyze

the impact of DIA on physical regret and estimation errors. Fig. 6a shows the relationship between

the stealthy attack probability and maximum DIA when we apply our proposed attack detection

ﬁlter on the sensors with a priori information. Fig 6a shows that as the stealthy attack probability

increases the domain of the attack reduces. Moreover the DIA has higher value for the sensors

with higher noise variance. To stay stealthy with higher probability, the attacker must reduce

the domain of its injected faulty data to the sensors. In addition, Figs. 6b, 6c, and 6d show how

the physical regret and steady state errors are affected by the probability of staying stealthy.

From these ﬁgures, we can see that as the stealthy attack probability increases the regret and the

absolute value of steady state errors decrease because the attacker’s maximum DIA decreases.

Fig. 7 shows the estimation error after applying our proposed attack detection ﬁlter on sensors

with apriori estimation. From Fig. 7, we can see that, while the attack on vf (t) type sensor does

not affect signiﬁcantly the estimation, an attack on a d(t) type sensor can cause an estimation
error on ˆd(t). In addition, Fig. 7 shows that the designed attack detection mechanism for sensors

with a priori information mitigates DIAs and keeps the estimation error close to zero.

Fig. 8 shows how the increase on the number of under attack vl type sensors affects the cyber

regret. In this simulation, we use the same settings as for Fig. 4. From Fig. 8, we can ﬁrst

observe that irrespective of the number of under attack sensors, the attack can be detected in

under 4 seconds as the cyber regret goes to zero after 4 second which is acceptable for this

scenario as in 4 seconds ACV f travels for 80 meters while the optimal safe spacing is also 80

20406080testtesttesttesttesttesttesttest0501001500204060801001201401601802000123107test150160170180190200050100150160170180190200246823

(a) Attack detection ﬁlter

(b) Attack detection ﬁlter

(c) Attack detection ﬁlter

(d) Attack detection ﬁlter

applied on the cyber
attacks on ˆvf (t) and ˆd(t).

applied on the cyber
attacks on ˆvf (t) and ˆd(t).

applied on the cyber
attacks on ˆvf (t) and ˆd(t).

applied on the cyber
attacks on ˆvf (t) and ˆd(t).

Fig. 6: Attack detection ﬁlter applied on the cyber attacks on ˆvf (t) and ˆd(t).

Fig. 7: Attack detection ﬁlter applied on the cyber attacks on ˆvf (t) and ˆd(t).

meters, thus, there will be no collision even if ACV l stops suddenly , while ACV f ’s sensors are

attacked. Moreover, the growth rate of cyber regret for the three attacks is approximately equal

regardless of the number of attacked sensors. Furthermore, Fig. 8 shows that, as the number of

attacked sensors increases, the cumulative cyber regret increases faster thus the attack can be

detected earlier. This shows that having access to more sensors is not essentially beneﬁcial for

the attacker and thus, the attacker must also optimize its set of attacked sensors to stay stealthy

for a longer time.

Fig. 9 shows how the domain of attack can affect the cyber regret. We can see from Fig.

9 that, as the domain of injected data to the vl type sensor increases, the MAB algorithm can

chooses the optimal subset more efﬁciently. This means that injecting higher values to the sensor

increases the chance of detectability and thus, reduces the impact of the attack on the sensors. In

addition, we can see that the cumulative cyber regret for the highest DIA (2.5 m/s data injection)

0.10.20.30.40.50.60.70.80.900.511.522.530.10.20.30.40.50.60.70.80.92468101214161810-30.10.20.30.40.50.60.70.80.9-2-1.5-1-0.500.511.510-80.10.20.30.40.50.60.70.80.9-0.15-0.1-0.0500.050.10.15-202468-2-101230  20 40 60 80 100120140160180012302040608010012014016018024

Fig. 8: The cyber regret in MAB algorithm applied to vl type sensors.

Fig. 9: The best subset selection in MAB algorithm applied to vl type sensors.

is greater than other cases, at the beginning of the simulation. However, after almost 350 seconds,

the cumulative cyber regret of the highest DIA becomes the least compared to the other DIAs.

This is due to the fact that a larger DIA leads to a higher cyber regret at the beginning of the

attack which leads the MAB algorithm to detect it earlier than other DIA cases.

Fig. 10 shows a scenario in which the attacker attacks only the third sensor when nl = 4.

Note that, b4b3b2b1 shows the state of the sensors such that for i = 1, . . . , 4 if bi = 1 then

sensor i is under attack and otherwise, it is not. Obviously, when the attacker attacks the third

sensor, the ACV must only rely on the other sensors. The b4b3b2b1 on the x-axis indicates the

chosen subset by the MAB algorithm to use for estimation. Fig. 10 shows that using the MAB

algorithm, percentage of the times that subset {1011} is chosen by MAB is higher than other

cases, which means that the MAB algorithm can detect the attack on the vl type sensors.

Finally, to show that our proposed DIA detection approaches can reduce the physical regret

signiﬁcantly, in Fig. 11, we consider that the attacker attacks only one sensor of each type

with the lowest noise error variance (most valuable sensor) after 1000 seconds (after ensuring

that Kalman ﬁlter converged). Then, we compare the cumulative physical regret of the ACV

05010015020025030035040045050005101520250501001502002503003504004505000204060801001201401600510-50510152025300501001502002503003504004505000102030405060708090100050100150200250300350400450500050010001500200025003000350040004500500025

Fig. 10: Attack detection with MAB algorithm applied to vl type sensors.

(a) DIA on vf (t) type.

(b) DIA on d(t) type.

(c) DIA on vl(t) type.

Fig. 11: Comparison of the proposed DIA detection approaches with Kalman ﬁltering.

system for a case in which the ACV only uses a Kalman ﬁlter for estimation and another case

in which the ACV applies both of our proposed DIA detection ﬁlters. Moreover, in this attack,

we consider that the attacker increases the sensor readings by a factor of 50%. As can be seen

from Fig. 11, the proposed attack detection ﬁlter has lower physical regret compared to a simple

Kalman ﬁltering. We can see that while the physical regret increases linearly for Kalman ﬁlter,

our proposed DIA detection approach keeps the physical regret close to zero. This shows that,

our proposed DIA detection approach can successfully detect the attack, mitigate it, and keep

the ACV system safe and secure, however the Kalman ﬁlter fails to stay robust against the DIA.

VII. CONCLUSION

In this paper, we have comprehensively studied the cyber-physical security and safety of

ACV systems. We have proposed an optimal safe controller that maximizes the trafﬁc ﬂow

and minimizes the risk of accidents on the roads by optimizing the speed and spacing of

ACVs. In addition, the proposed optimal safe controller maximizes the stability of ACV systems

and improves their robustness against physical attacks. Moreover, we have improved cyber-

physical security of ACV systems by proposing two novel DIA detection approaches. The ﬁrst

approach detects DIAs using a priori information about the sensors. In the second approach,

0001001000110100010101100111100010011010101111001101111011110102030405060708095010001050110000.050.10.150.20.250.30.350.40.4595010001050110002040608010012014016018095010001050110001234567810526

we have proposed an MAB algorithm to learn secure subset of sensors when there exists no a

priori information about sensors. Simulation results have shown that the proposed optimal safe

controller yields better stability and robustness compared to current state of the art controllers.

In addition, the DIA detection approaches improve the security of the sensors and robustness of

the ACV system compared to Kalman ﬁltering.

A. Proof of Theorem 1

APPENDIX

First, using (1) and (24) we can ﬁnd that:

max

(cid:26)−vf (t)
T

,umin
f

(cid:26)−ˆvf (t)
T

, umin
f

max

(cid:124)

,uf (t − 1) − ∆u

≤ uf (t) ≤ min

(cid:27)

(cid:26) ˜v − vf (t)
T

, umax
f

, uf (t − 1) + ∆u

, (57)

(cid:27)

and since ACV f only has an estimation of vf (t), then we can rewrite (57) as follows:
(cid:27)

(cid:27)

, uf (t − 1) − ∆u

≤ uf (t) ≤ min

, umax
f

, uf (t − 1) + ∆u

. (58)

(cid:26)˜v − ˆvf (t)
T

(cid:123)(cid:122)
u1(t)

(cid:125)

(cid:124)

(cid:123)(cid:122)
u1(t)

(cid:125)

Now, we can deﬁne Lagrangian multipliers and apply the Karush Kuhn Tucker (KKT) conditions

to solve the optimization problem in (22). Then, we will have:
(cid:18) (ˆvf (t) + T uf (t))2
2bf

g(uf (t), λ1, λ2) =

− ˆd(t) − T ˆvl(t) + T ˆvf (t)

(cid:19)2

+ λ1(uf (t) − u1(t)

+ λ2(u1(t) − uf (t)),

(59)

with the ﬁrst order necessary conditions given by: ∂g
∂uf

= 0,

∂g
∂λ1

= 0, and ∂g
∂λ2

= 0. When λ1

and λ2 are not active (λ1 = 0 and λ2 = 0), we will have:
(cid:18) (ˆvf (t) + T uf (t))2
2bf

∂g
∂uf

4T
2bf

− ˆd(t) − T ˆvl(t) + T ˆvf (t)

=

(cid:19)

(ˆvf (t) + T uf (t)) = 0

⇒ u∗

f (t) =

(cid:18)

(cid:114)

(cid:32)

(cid:114)

±

2bf

1
T
(cid:16) ˆd(t) + T ˆvl(t) − T ˆvf (t)

(cid:17)

(cid:17)
(cid:16) ˆd(t) + T ˆvl(t) − T ˆvf (t)

(cid:19)

(cid:33)

− ˆvf (t)

, −

1
T

ˆvf (t).

(60)

−

2bf

and − 1

However, 1
T

− ˆvf (t)

T ˆvf (t) are not acceptable solu-
tions since they result in vf (t + 1) ≤ 0. The next step is to show that the third solution in (60)
is the global minimum. Thus, we apply the second-order condition on ˆR(t) as follows:
d2 ˆR(t)
du2
f (t)
d2 ˆR(t)
du2
f (t)

(cid:20)(cid:18)T (ˆvf (t) + T uf (t))2
bf
(cid:18) T (ˆvf (t) + T u∗

(cid:18) (ˆvf (t) + T uf (t))2
2bf

− ˆd(t) − T ˆvl(t) + T ˆvf (t)

4T
2bf

4T
2bf

f (t))2

> 0.

(61)

+ T

(cid:19)(cid:21)

bf

=

=

(cid:19)

(cid:19)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)u∗

f (t)

(cid:18)(cid:114)

2bf

(cid:16) ˆd(t) + T ˆvl(t) − T ˆvf (t)

(cid:17)

(cid:19)

− ˆvf (t)

is a global maximizer of ˆR(t).

Thus, u∗

f (t) = 1
T

Now, to consider the constraints in (57), if we activate λ1 or λ2 the ﬁrst order condition will

27

result in having u∗

f (t) = u1(t) or u1(t). Therefore, the optimal 1-step ahead controller can be

given by (26).

B. Proof of Theorem 3

We know that the Kalman gain converges to ˜K. Thus, from (14) and (17) we can ﬁnd the

state estimation ˆx(t) as a process which depends on estimation error r(t) as follows:

ˆx(t) =

=

(cid:104)

(cid:104)

I − ˜KH

I − ˜KH

(cid:105)

(cid:105)

ˆx(−)(t) + ˜K z(t)
(cid:124)(cid:123)(cid:122)(cid:125)
[Hx(t)+e(t)]

[Aˆx(t − 1) + Buf (t − 1) + F ˆvl(t − 1)]

(cid:104)
I − ˜KH

(cid:105)

⇒

+ ˜KH [ˆx(t) + r(t)] + ˜Ke(t),
(cid:105)

(cid:104)

ˆx(t) =

I − ˜KH

[Aˆx(t − 1) + Buf (t − 1) + F ˆvl(t − 1)] + ˜K [Hr(t) + e(t)] ,

⇒ ˆx(t) = Aˆx(t − 1) + Buf (t − 1) + F ˆvl(t − 1) +

(cid:104)
I − ˜KH

(cid:105)−1

˜K [Hr(t) + e(t)].

(62)

Now, by subtracting (62) from the system model deﬁned in (2), we will have:

r(t) = Ar(t − 1) + F rl(t) −

(cid:104)
I − ˜KH

(cid:105)−1

˜K [Hr(t) + e(t)] ,

(cid:20)

r(t) =

I +

(cid:104)
I − ˜KH

(cid:105)−1

˜KH

(cid:21)−1

(cid:20)

Ar(t − 1) +

I +

(cid:104)

I − ˜KH

(cid:105)−1

˜KH

(cid:21)−1(cid:104)

(cid:105)
F rl(t) − ˜Ke(t)

(cid:124)

(cid:123)(cid:122)
Q

(cid:125)

(cid:124)

(cid:123)(cid:122)
ρ(t)

(cid:125)

Moreover, we can see that ρ(t) is a linear combination of independent white Gaussian process

with zero mean. To ﬁnd the covariance matrix C ρ of ρ(t) we will have:

C ρ = E (cid:8)ρ(t)ρT (t)(cid:9) = E

(cid:110)(cid:104)

QF rl(t) − Q ˜Ke(t)

l (t)F T QT − eT (t) ˜K
rT

(cid:105) (cid:104)

T

QT (cid:105)(cid:111)

(cid:110)

= E

QF rl(t)rT

l (t)F T QT − Q ˜K e(t)rT
(cid:123)(cid:122)
0

(cid:124)

l (t)
(cid:125)

F T QT − QF rl(t)eT (t)
(cid:125)

(cid:124)

(cid:123)(cid:122)
0

T

˜K

QT

+ Q ˜Ke(t)eT (t) ˜K

T

QT (cid:111)

= QF σ2

l F T QT + Q ˜KR ˜K

T

QT .

(63)

Note that the fact that e(t) and rl(t) are independent leads to having e(t)rT

l (t) = 0 . Next, we

write the dynamic model for the estimation error as follows:

r(t) = QAr(t − 1) + ρ(t) = [QA]t−t0 r(tc) +

t−t0−1
(cid:88)

k=0

[QA]t−t0−k−1 ρ(tc + k),

(64)

where t0 is the time step where the Kalman ﬁlter converges. Thus, for t (cid:29) t0 and if QA

is asymptotically stable then we will have r(t) as a Gaussian process due to the central limit

theorem. Now, to ﬁnd the mean of r(t) we can write:

E {r(t)} = QA E {r(t − 1)} + E {ρ(t)} = QA E {r(t)} , ⇒ E {r(t)} = 0.

(65)

Next, since the mean is zero, then the covariance matrix of r(t), C r = E{r(t)rT (t)}. To ﬁnd
C r, we have:
E (cid:8)r(t)rT (t)(cid:9)= E

r(t − 1)AT QT + ρT (t)

[QAr(t − 1) + ρ(t)]

(cid:105)(cid:111)

(cid:110)

(cid:104)

28

(cid:110)

= E

QAr(t − 1)rT (t − 1)AT QT + QA r(t − 1)ρT (t)
(cid:125)

(cid:124)

(cid:123)(cid:122)
0

+ ρ(t)rT (t − 1)
(cid:123)(cid:122)
(cid:125)
0

(cid:124)

AT QT + ρ(t)ρT (t)

(cid:111)
.

Note that since r(t − 1) and ρ(t) are independent ρ(t)rT (t − 1) = 0. In addition, we know that
after convergence we will have E (cid:8)r(t)rT (t)(cid:9) = E (cid:8)r(t − 1)rT (t − 1)(cid:9) = C r then, we will
need to solve the following discrete Ricatti equation C r = QAC rAT QT + C ρ.

Now, the ﬁnal step is to ﬁnd the covariance matrix of the residual C µ. Since after Kalman

ﬁlter convergence we will have ˆx(−)(t) = ˆx(t) then:

z(t) − z(−)(t) = Hx(t) + e(t) − Hx(−)(t) = Hx(t) + e(t) − H ˆx(t) = Hr(t) + e(t). (66)

Thus, we will have:

E (cid:8)µ(t)µT (t)(cid:9) = E (cid:8)[Hr(t) + e(t)] (cid:2)rT (t)H T + eT (t)(cid:3)(cid:9)

= E (cid:8)Hr(t)rT (t)H T + e(t)rT (t)H T + Hr(t)eT (t) + e(t)eT (t)(cid:9)

= HC rH T + R + E (cid:8)e(t)rT (t)H T + Hr(t)eT (t)(cid:9) .

(67)




Now, we have:

e(t)rT (t)H T (cid:111)
(cid:110)

E

= E

E (cid:8)Hr(t)eT (t)(cid:9) = E

F T − eT (t) ˜K

T (cid:17)

QT H T






= −R ˜K

T

QT H T ,

(cid:16)
AT QT H T + e(t)

e(t)rT (t − 1)

(cid:124)
(cid:123)(cid:122)
(cid:125)
0



HQA r(t − 1)eT (t)
(cid:125)

(cid:124)

(cid:123)(cid:122)
0



(cid:124)

(cid:16)

+HQ

rl(t)
(cid:125)

(cid:123)(cid:122)
0

(cid:17)
− ˜Ke(t) +F rl(t)
(cid:124)
(cid:123)(cid:122)
0




eT (t)

(cid:125)

= −HQ ˜KR.

Thus, the covariance matrix can be given by (43).

C. Proof of Theorem 4

From (17), after Kalman ﬁlter convergence we obtain:

ˆx(t + 1) =

=

(cid:104)

(cid:104)

I − ˜KH

I − ˜KH

(cid:105)

(cid:105)

x(−)(t) + ˜K [Hx(t + 1) + e(t)]

[Aˆx(t) + Buf (t) + F ˆvl(t)] + ˜K [H [Ax(t) + Buf (t) + F vl(t)] + e(t)]

=Aˆx(t) + Buf (t) +

F ˆvl(t) + ˜KHF vl(t) + ˜K [HAr(t) + e(t)] . (68)

Due to the deﬁnition ofF =

(cid:104)

(cid:105)

(cid:104)
I − ˜KH
(cid:104)
(cid:105)T
I − ˜KH

,

0 T

(cid:105)

where the ﬁrst elements are zero. We deﬁne two parameters s1 and s2 as

and ˜KHF =





0

s2


 , and we will have s1 + s2 = T . Then using (51) and (68) the a posteriori

F and ˜KHF are vectors with two elements




(cid:104)

I − ˜KH

(cid:105)

F =





0

s1

29

[HAr(t) + e(t)] .Thus, we will have:

(cid:105) ˜K
(cid:125)

(cid:105)
(ˆvl(t) − vl(t))

− el(t) + hlJ [HAr(t) + e(t)]

1
(cid:123)(cid:122)
J

(cid:124)
(cid:104) s1
T

wlieli

− el(t)

+hlJ [HAr(t) + e(t)] .

(69)

estimation will be v(+)

l

(t) = s1

T ˆvl(t) + s2

T vl(t) +

(cid:104)

0

µ(+)
l

(t) = hlv(+)
(cid:34)

l

= −hl

s1
T

nl(cid:88)

i=1

(t) − hlvl(t) − el(t) = hl
(cid:35)

(cid:124)

(cid:123)(cid:122)
Υ el(t)
First, we derive the mean of a posteriori residual:
nl(cid:88)

(cid:111)

(cid:34)

(cid:125)

(cid:35)
wli E {eli}

(t)

= −hl

(cid:110)
µ(+)
l

E

s1
T

i=1
Since the mean is zero the covariance matrix of µ(+)
(cid:111)

(cid:40)

(cid:110)

T

l

C µl = E

µ(+)
l

(t)µ(+)
l

− E {el(t)} + hlJ [HA E {r(t)} + E {e(t)}] = 0. (70)

(t), C µl, can be derived as follows:

(t)

= E

[Υ el(t) + hlJ [HAr(t) + e(t)]]

× (cid:2)eT

l (t)Υ T + (cid:2)rT (t)AT H T + eT (t)(cid:3) J T hT

l

(cid:41)

(cid:3)

(cid:40)

= E

Υ el(t)eT

l (t)Υ T + Υ el(t) (cid:2)rT (t)AT H T + eT (t)(cid:3)
(cid:125)

(cid:124)

(cid:123)(cid:122)
0

+hlJ [HAr(t) + e(t)] eT

(cid:124)

(cid:123)(cid:122)
0

Υ T

l (t)
(cid:125)

+hlJ (cid:2)HAr(t)rT (t)AT H T + e(t)rT (t)AT H T + HAr(t)eT (t) + e(t)eT (t)(cid:3) J T hT

l

(cid:41)

=Υ RlΥ T + hlJ

(cid:104)

HAC rAT H T − R ˜K

T

QT AT H T − HAQ ˜KR + R

(cid:105)

J T hT
l .

(71)

REFERENCES

[1] A. Ferdowsi, U. Challita, and W. Saad, “Deep learning for reliable mobile edge analytics in intelligent transportation

systems,” IEEE Vehicular Technology Magazine, Accepted and to Appear, 2018.

[2] M. Mozaffari, W. Saad, M. Bennis, and M. Debbah, “Unmanned aerial vehicle with underlaid device-to-device communi-
cations: Performance and tradeoffs,” IEEE Transactions on Wireless Communications, vol. 15, no. 6, pp. 3949–3963, June
2016.

[3] T. Zeng, O. Semiari, W. Saad, and M. Bennis, “Joint communication and control for wireless autonomous vehicular platoon

systems,” arXiv preprint arXiv:1804.05290, 2018.

[4] U. Challita, A. Ferdowsi, M. Chen, and W. Saad, “Artiﬁcial intelligence for wireless connectivity and security of cellular-

connected UAVs,” IEEE Wireless Communications Magazine, Accepted and to Appear, 2018.

[6]

[5] M. Amoozadeh, A. Raghuramu, C. n. Chuah, D. Ghosal, H. M. Zhang, J. Rowe, and K. Levitt, “Security vulnerabilities
of connected vehicle streams and their impact on cooperative driving,” IEEE Communications Magazine, vol. 53, no. 6,
pp. 126–132, June 2015.
I. Parvez, A. Rahmati, I. Guvenc, A. I. Sarwat, and H. Dai, “A survey on low latency towards 5g: Ran, core network and
caching solutions,” IEEE Communications Surveys Tutorials, pp. 1–1, May 2018.

[7] M. Hus´ak, N. Neshenko, M. Safaei Pour, E. Bou-Harb, and P. ˇCeleda, “Assessing internet-wide cyber situational awareness
of critical sectors,” in Proceedings of the 13th International Conference on Availability, Reliability and Security. Hamburg,
Germany: ACM, August 2018, pp. 29:1–29:6.

[8] A. Ferdowsi, W. Saad, B. Maham, and N. B. Mandayam, “A Colonel Blotto game for interdependence-aware cyber-physical
systems security in smart cities,” in Proceedings of the 2Nd International Workshop on Science of Smart City Operations
and Platforms Engineering, ser. SCOPE ’17. New York, NY, USA: ACM, 2017, pp. 7–12.

[9] F. Kargl, P. Papadimitratos, L. Buttyan, M. Mter, E. Schoch, B. Wiedersheim, T. V. Thong, G. Calandriello, A. Held,
A. Kung, and J. P. Hubaux, “Secure vehicular communication systems: implementation, performance, and research
challenges,” IEEE Communications Magazine, vol. 46, no. 11, pp. 110–118, November 2008.

30

[10] A. Greenberg. Hackers remotely kill a jeep on the highway. [Online]. Available: https://www.wired.com/2015/07/

hackers-remotely-kill-jeep-highway/

[11] S. Woo, H. J. Jo, and D. H. Lee, “A practical wireless attack on the connected car and security protocol for in-vehicle

can,” IEEE Transactions on Intelligent Transportation Systems, vol. 16, no. 2, April 2015.

[12] S. N. Narayanan, S. Mittal, and A. Joshi, “OBD securealert: An anomaly detection system for vehicles,” in Proc. of IEEE

International Conference on Smart Computing (SMARTCOMP), May 2016, pp. 1–6.

[13] G. Calandriello, P. Papadimitratos, J. P. Hubaux, and A. Lioy, “On the performance of secure vehicular communication

systems,” IEEE Transactions on Dependable and Secure Computing, vol. 8, no. 6, pp. 898–912, Nov 2011.

[14] T. Kim, A. Studer, R. Dubey, X. Zhang, A. Perrig, F. Bai, B. Bellur, and A. Iyer, “Vanet alert endorsement using multi-
source ﬁlters,” in Proceedings of the Seventh ACM International Workshop on VehiculAr InterNETworking, Chicago, IL,
USA, September 2010, pp. 51–60.

[15] M. Sun, M. Li, and R. Gerdes, “A data trust framework for vanets enabling false data detection and secure vehicle tracking,”
in Proc. of IEEE Conference on Communications and Network Security (CNS), Las Vegas, NV, USA, Oct 2017, pp. 1–9.
[16] M. E. Eltayeb, J. Choi, T. Y. Al-Naffouri, and R. W. Heath, “Enhancing secrecy with multiantenna transmission in millimeter
wave vehicular communication systems,” IEEE Transactions on Vehicular Technology, vol. 66, no. 9, pp. 8139–8151, Sept
2017.

[17] A. Petrillo, A. Pescap, and S. Santini, “A collaborative approach for improving the security of vehicular scenarios: The

case of platooning,” Computer Communications, vol. 122, pp. 59 – 75, 2018.

[18] A. Ferdowsi and W. Saad, “Deep learning for signal authentication and security in massive Internet of Things systems,”

IEEE Transactions on Communications, October 2018.

[19] S. Tuohy, M. Glavin, C. Hughes, E. Jones, M. Trivedi, and L. Kilmartin, “Intra-vehicle networks: A review,” IEEE

Transactions on Intelligent Transportation Systems, vol. 16, no. 2, pp. 534–545, April 2015.

[20] P. Kleberger, T. Olovsson, and E. Jonsson, “Security aspects of the in-vehicle network in the connected car,” in Proc. of

IEEE Intelligent Vehicles Symposium (IV), Baden-Baden, Germany, June 2011, pp. 528–533.

[21] J. M. Bradley and E. M. Atkins, “Optimization and control of cyber-physical vehicle systems,” Sensors, vol. 15, no. 9,

pp. 23 020–23 049, September 2015.

[22] M. Xue, W. Wang, and S. Roy, “Security concepts for the dynamics of autonomous vehicle networks,” Automatica, vol. 50,

no. 3, pp. 852 – 857, 2014.

[23] S. Sadraddini, S. Sivaranjani, V. Gupta, and C. Belta, “Provably safe cruise control of vehicular platoons,” IEEE Control

Systems Letters, vol. 1, no. 2, pp. 262–267, Oct 2017.

[24] S. Lefvre, A. Carvalho, and F. Borrelli, “A learning-based framework for velocity control in autonomous driving,” IEEE

Transactions on Automation Science and Engineering, vol. 13, no. 1, pp. 32–42, Jan 2016.

[25] A. Ferdowsi, U. Challita, W. Saad, and N. B. Mandayam, “Robust deep reinforcement learning for security and safety in
autonomous vehicle systems,” in Proc. of IEEE International Conference on Intelligent Transportation Systems, Maui, HI,
November 2018.

[26] E. Schoitsch, C. Schmittner, Z. Ma, and T. Gruber, “The need for safety and cyber-security co-engineering and
standardization for highly automated automotive vehicles,” in Advanced Microsystems for Automotive Applications 2015,
T. Schulze, B. M¨uller, and G. Meyer, Eds. Cham: Springer International Publishing, 2016, pp. 251–261.

[27] R. L. Williams, D. A. Lawrence et al., Linear state-space control systems.
[28] H. K. Khalil, Nonlinear systems. Upper Saddle River, NJ : Prentice-Hall, 2002.
[29] T. Kailath, Linear systems. Prentice-Hall Englewood Cliffs, NJ, 1980, vol. 156.
[30] Y. Tian and L. Pan, “Predicting short-term trafﬁc ﬂow by long short-term memory recurrent neural network,” in Proc.

John Wiley & Sons, 2007.

IEEE International Conference on Smart City/SocialCom/SustainCom (SmartCity), Dec 2015, pp. 153–158.

[31] X. Ma, Z. Tao, Y. Wang, H. Yu, and Y. Wang, “Long short-term memory neural network for trafﬁc speed prediction using

remote microwave sensor data,” Transportation Research Part C: Emerging Technologies, vol. 54, pp. 187 – 197, 2015.

[32] A. Taleb Zadeh Kasgari and W. Saad, “Stochastic optimization and control framework for 5G network slicing with effective
isolation,” in Proc. 52nd Annual Conference on Information Sciences and Systems (CISS) (CISS 2018), Princeton, NJ, USA,
Mar. 2018.

[33] Q. Yang, L. Chang, and W. Yu, “On false data injection attacks against Kalman ﬁltering in power system dynamic state

estimation,” Security and Communication Networks, vol. 9, no. 9, pp. 833–849, August 2013.
[34] K. B. Petersen and M. S. Pedersen, The Matrix Cookbook. Technical University of Denmark, 2012.
[35] P. Auer, N. Cesa-Bianchi, and P. Fischer, “Finite-time analysis of the multiarmed bandit problem,” Machine Learning,

vol. 47, no. 2, pp. 235–256, May 2002.

[36] R. Kleinberg, A. Niculescu-Mizil, and Y. Sharma, “Regret bounds for sleeping experts and bandits,” Machine Learning,

vol. 80, no. 2, pp. 245–272, Sep 2010.

[37] S. Ali, A. Ferdowsi, W. Saad, N. Rajatheva, and J. Haapola, “Sleeping multi-armed bandit learning for fast uplink grant

allocation in machine type communications,” arXiv preprint arXiv:1810.12983, 2018.

[38] P. G. Gipps, “A behavioural car-following model for computer simulation,” Transportation Research Part B: Methodolog-

ical, vol. 15, no. 2, pp. 105–111, 1981.

[39] A. Kesting, M. Treiber, and D. Helbing, “Enhanced intelligent driver model to access the impact of driving strategies on
trafﬁc capacity,” Philosophical Transactions of the Royal Society of London A: Mathematical, Physical and Engineering
Sciences, vol. 368, no. 1928, pp. 4585–4605, 2010.

