1
2
0
2

r
p
A
7

]

Y
S
.
s
s
e
e
[

3
v
4
8
3
2
0
.
2
1
0
2
:
v
i
X
r
a

Cross-Layer Coordinated Attacks on Cyber-Physical Systems: A LQG
Game Framework with Controlled Observations

Yunhan Huang1, Zehui Xiong2 and Quanyan Zhu1

Abstract— This work establishes a game-theoretic framework
to study cross-layer coordinated attacks on cyber-physical
systems (CPSs). The attacker can interfere with the physical
process and launch jamming attacks on the communication
channels simultaneously. At the same time, the defender can
dodge the jamming by dispensing with observations. The
generic framework captures a wide variety of classic attack
models on CPSs. Leveraging dynamic programming techniques,
we fully characterize the Subgame Perfect Equilibrium (SPE)
control strategies. We also derive the SPE observation and
jamming strategies and provide efﬁcient computational methods
to compute them. The results demonstrate that the physical and
cyber attacks are coordinated and depend on each other.

On the one hand, the control strategies are linear in the
state estimate, and the estimate error caused by jamming
attacks will
induce performance degradation. On the other
hand, the interactions between the attacker and the defender
in the physical layer signiﬁcantly impact the observation and
jamming strategies. Numerical examples illustrate the exciting
interactions between the defender and the attacker through
their observation and jamming strategies.

I. INTRODUCTION

Recent progress in information and communications tech-
nologies (ICT) such as the Internet of Things (IoT) and 5G
high-speed cellular networks have enhanced the connectiv-
ity among physical systems and cyber systems. However,
the increasing connectivity also brings with these systems
heightened concern about trustworthiness. There is an urgent
need for understanding security, privacy, safety, reliability,
resilience, and corresponding assurance for CPSs. Due to
the multi-layer and multi-stage nature of CPSs, a cross-layer
cross-stage framework is a sine qua non to understand the
trustworthiness of CPSs. Most existing works on the security
of CPSs often focus independently on either the physical
system or the cyber system. One common assumption is that
adversaries can only launch one particular type of attack at
a time. For example, in [1]–[5], the authors have considered
DoS attacks that jam either the observation or the control
signals to deteriorate the performance of the underlying
system. [6] focuses only on data injection attacks on the
sensors of a control system. Studies in [7] pivot purely
on the replay attacks on the operator-to-actuator channel.
However, in CPSs, adversaries can leverage both cyber and
physical vulnerabilities to launch coordinated attacks [8],
[9]. For example, an advanced adversary can simultaneously

1 Y. Huang and Q. Zhu are with the Department of Electrical and
Computer Engineering, New York University, 370 Jay St., Brooklyn, NY.
{yh.huang, qz494}@nyu.edu

2 Z. Xiong is with the Pillar of Information Systems Technology
and Design, Singapore University of Technology and Design, Singapore.
zehui.xiong@ieee.org

compromise critical sensors and control units to damage
targeted CPS assets.

In this work, we build a dynamic game-theoretic frame-
work that can incorporate various attack models, where the
attacker conducts both physical interferences (e.g., through
intervention or cyber hacking/data
either direct physical
injection) and jamming attacks on observation channel. The
attacker has to intelligently coordinate her/his attacks across
both the physical and the cyber layers over a ﬁnite period
of time to maximize the system degradation with minimum
effort. The defender, e.g., the controller/operator, implements
her/his own control and has to, at each time, decide whether
to observe or not. Each observation request made by the
defender is associated with an observation cost. The cost
can capture the limited network resources, such as power,
communication, and bandwidth [10]. For example, radar
measurement requires megawatts of power for sensing in
military applications. Thus, the purposes of the defender not
observing are two fold: One is to save limited resources;
the other is to dodge the jamming. The physical process is
described by a linear dynamical system with additive white
noise. The observation is partial and noisy, whose availability
depends on the observation decisions of the defender and the
jamming policies of the attacker.

Dynamic games have long been used to capture the cross-
layer multi-stage nature of CPSs and the competing nature
between the system operator and the adversary [11]. At the
cyber layer of the CPSs, the dynamic games are used to
model the cyber kill chains of APTs that include reconnais-
sance, lateral movement, and command and control. These
games are often built over graphical models such as computer
networks [12], [13] and attack graphs [14]. At the physical
layer, the dynamic games are used to describe the interactions
between operational technologies (OT) and an adversary. The
game-theoretic description of the threat model at the OT
level guides the design of security monitoring, and control
strategies that aim to reduce the risks on the controlled
processes and assets [8], as well as the development of
resilient control mechanisms that mitigate the impact of
successful attacks [15].

Our work’s main contribution is the development of a
cross-layer over-stage game-theoretic framework that under-
pins the study of CPS under coordinated simultaneous cross-
layer attacks. The generic framework captures various attack
models. Its connections with existing attack models will be
discussed in Remark 1.

We study the SPE strategies of this dynamic game and
fully characterize the SPE strategies via two dynamic pro-

1

 
 
 
 
 
 
gramming equations. The theoretical results show that the
control strategies are linear in the state estimate. The control
gain can be computed ofﬂine, independent of the obser-
vation and the jamming strategies. The effect of jamming
attacks causes the estimation error and leads to signiﬁcant
system degradation. The capability of physical attacks also
affects the jamming and observation decisions. The SPE
strategies show that the defender does not observe when
the observation cost surpasses system degradation caused
by estimation error. When the attacker can deploy physical
attacks with low costs, there is no incentive for the defender
to observe even when the observation cost is zero. Otherwise,
the attacker can leverage the observation to launch more
accurate physical attacks. Besides, we show that the defender
makes an observation even when the defender anticipates the
jamming to incur a higher cost to the attacker. More results
regarding the jamming and the observation decisions will be
discussed in Section III-B and Section IV.

For the rest of the paper, Section II provides a mathe-
matical formulation of the problem. Section III presents the
theoretical results of the framework, their derivations, and
computational methods. In Section IV, we use case studies
to illustrate the structures of the observation and jamming
strategies.

II. PROBLEM FORMULATION

We consider a linear dynamical system given by

𝑥𝑛+1 = 𝐴𝑥𝑛 + 𝐵𝑑𝑢𝑑

𝑛 + 𝐵𝑎𝑢𝑎

𝑛 + 𝐶𝑤𝑛,

0 ≤ 𝑛 ≤ 𝑁 − 1,

(1)

𝑛 is the control of the defender while 𝑢𝑎

where 𝑥𝑛 ∈ R𝑞 is the 𝑞-dimensional state vector at time 𝑛;
𝑛, 𝑢𝑎
and 𝑢𝑑
𝑛, 𝑤𝑛 are vectors of dimensions less than or equal
to 𝑞. Here, 𝑢𝑑
𝑛 is that
of the attacker. The system noise at time 𝑛 is denoted by 𝑤𝑛.
Moreover, 𝐴, 𝐵𝑑, 𝐵𝑎, and 𝐶 are matrices with appropriate
dimensions. The capability of the attacker on affecting the
state dynamics can be captured by the adversarial control
matrix 𝐵𝑎. Here, we consider time-invariant system for
notational simplicity, but all results in Section III can be
extended to the time-varying case without much endeavor.
The associated observation system is

˜𝑦𝑛 = 𝐷𝑥𝑛 + 𝐸𝑣𝑛,
= ℎ𝑑 (𝑖𝑑
𝑦𝑑
𝑛

𝑛 , 𝑖𝑎

𝑛 ) · ˜𝑦𝑛, and 𝑦𝑎
𝑛

= ℎ𝑎 (𝑖𝑑

𝑛 , 𝑖𝑎

𝑛 ) · ˜𝑦𝑛,

(2)

where 𝑣 and 𝐷, 𝐸 are vectors and matrices with appropriate
dimensions. Here, 𝑖𝑑
𝑛 ∈ {0, 1} (resp. 𝑖𝑎
𝑛 ∈ {0, 1}) is the
observation (resp. jamming) decision made by the defender
(resp. the attacker). We call ˜𝑦𝑛 the information vector at
time 𝑛. Whether or not the vector ˜𝑦𝑛 is observed by the
defender and the attacker is decided by the observation
decision 𝑖𝑑
𝑛 according to the
rule ℎ : {0, 1} × {0, 1} → {0, 1}. We suppose, whenever
the attacker chooses to jam the observation, the defender
will receive no information. The attacker receives the same
observation information as the defender does. In this case,
ℎ𝑑 (𝑖𝑑
𝑛 · (1 − 𝑖𝑎
𝑛 , 𝑖𝑎
𝑛 and so
we use 𝑦𝑛 instead in later discussions.

𝑛 and the jamming decision 𝑖𝑎

𝑛). Hence, 𝑦𝑑
𝑛

𝑛 ) = ℎ𝑎 (𝑖𝑑

𝑛 ) = 𝑖𝑑

𝑛 , 𝑖𝑎

= 𝑦𝑎

2

𝑛, 𝑢𝑎

𝑛 for 𝑢𝑑

𝑛 , and 𝑌 𝑎

𝑛 , 𝐼 𝑎
𝑛 , 𝐼 𝑑
𝑛 , and 𝑦𝑎

We introduce the notation 𝑋𝑛 = {𝑥0, · · · , 𝑥𝑛} to denote the
history of state trajectory up to time 𝑛. Similarly, we deﬁne
𝑛 , 𝑊𝑛, 𝑉𝑛, 𝑌 𝑑
𝑛 , 𝑈 𝑎
𝑈 𝑑
𝑛 , 𝑤𝑛,
𝑣𝑛, 𝑦𝑑
𝑛, respectively. The sequences 𝑊𝑁 −1 and 𝑉𝑁 −1
are independent stochastic processes with a joint Gaussian
probability distribution described by E[𝑤𝑛] = E[𝑣𝑛] = 0,
E[𝑤𝑛𝑤𝑛′ ] = Σ𝑠𝛿(𝑛 − 𝑛′), and E[𝑣𝑛𝑣𝑛′] = Σ𝑜𝛿(𝑛 − 𝑛′),
where 𝛿(·) is the Kronecker delta. The initial condition 𝑥0,
independent from the system noise and the observation noise,
is Gaussian distributed with mean ¯𝑥0 and variance Σ0.

𝑛 , 𝑖𝑎

𝑛, 𝑖𝑑

Information: The control sequences 𝑈 𝑑

𝑁 −1)
and the observation/jamming sequence 𝐼 𝑑
𝑁 −1) are
to be generated by the defender (resp. attacker). At time 𝑛,
the observation 𝑖𝑑
𝑛 is made based on the information available
to the defender, which is denoted by

𝑁 −1 (resp. 𝑈 𝑎

𝑁 −1 (resp. 𝐼 𝑎

𝑛−1, 𝐼 𝑎

F𝑛 = {𝐼 𝑑

𝑛−1, 𝑈 𝑑

𝑛−1, 𝑈 𝑎

𝑛−1, 𝑌𝑛−1},
with F0 = ∅. So is the jamming decision 𝑖𝑎
𝑛 . The controls of
both defender and attacker are made based on the information
available at time 𝑛 after the observation, which is denoted
by

𝑛 ≥ 1,

(3)

¯F𝑛 = {F𝑛, 𝐼 𝑑

𝑛 , 𝐼 𝑎

𝑛 , 𝑌𝑛}.

(4)

We assume that the state evolution equations, observation
equations, noise statistics, cost functions of the controllers,
and information structures of the controllers are part of
common knowledge among the players. The game is hence
a complete information game.

Objectives/Targets: The cost functional of the defender
and the attacker, involving quadratic costs in state and their
controls, as well as the observation and cost, can be written
as

𝐹 𝑑 (𝜋𝑑, 𝜋𝑎) = E

𝑁 −1

"

Õ𝑛=0

where

𝑐𝑛 (𝑥𝑛, 𝑢𝑑

𝑛, 𝑢𝑎

𝑛, 𝑖𝑑

𝑛 , 𝑖𝑎

𝑛 ) + 𝑥 ′

𝑁 𝑄 𝑁 𝑥 𝑁

,

#

(5)

𝑛 − 𝑢𝑎
𝑛

′𝑅𝑎

𝑛𝑢𝑎
𝑛

𝑛, 𝑖𝑑

𝑛 , 𝑖𝑎

𝑛, 𝑢𝑎

𝑛 ) =𝑥 ′

𝑐𝑛 (𝑥𝑛, 𝑢𝑑

𝑅𝑑
𝑛𝑄𝑛𝑥𝑛 + 𝑢𝑑
𝑛 𝑢𝑑
𝑛
𝑛 𝑂 𝑎
𝑛 − 𝑖𝑎
𝑛 𝑂 𝑑
+ 𝑖𝑑
𝑛,
the instantaneous cost at

′

is
𝐹 𝑎 (𝜋𝑑, 𝜋𝑎) = −𝐹 𝑑 (𝜋𝑑, 𝜋𝑎). Here, the matrices 𝑅𝑑
positive deﬁnite, the matrix 𝑄𝑑
the scalars 𝑂 𝑑
𝑛, 𝑂 𝑎
Here, 𝑂 𝑑
while 𝑂 𝑎
indicates the transpose of 𝑀.

stage 𝑛, and we have
𝑛 are
𝑛 is positive semideﬁnite, and
𝑛 are nonnegative for 𝑛 = 1, 2, · · · , 𝑁 − 1.
𝑛 represents the observation cost for the defender
𝑛 denotes the jamming cost. For any matrix 𝑀, 𝑀 ′

𝑛 , 𝑅𝑎

Strategies: 𝜋𝑑 = (𝜇𝑑, 𝜈𝑑) is the strategies of the defender,
where 𝜇𝑑 denotes the observation strategy and 𝜈𝑑 denotes
the control strategy. The strategy of the attacker, including
the jamming strategy 𝜇𝑎 and the control strategy 𝜈𝑎, are
denoted by 𝜋𝑎 = (𝜇𝑎, 𝜈𝑎). Given 𝜋𝑑, at stage 𝑛, the control
and the observation decisions of the defender are generated
𝑛 ( ¯F𝑛).
as 𝑖𝑑
𝑛
The defender aims to stabilize the system with minimum
control effort and at the same time observe/sample economi-
cally. The attacker possesses an opposing objective, which is

𝑛 (F𝑛) and 𝑢𝑑
𝑛

= 𝜇𝑑

= 𝜈𝑑

to undermine the defender’s effort by cross-layer coordinated
attacks on both the physical layer and the communication
layer. Here, we consider a zero-sum game where the defender
and the attacker are strictly competitive. Our results in
Section III can be easily extended to a general sum setting.

Remark 1. The framework can also capture various attack
models. For example, 𝑅𝑎
𝑛 going to inﬁnity means zero phys-
ical attacks. Hence, the framework specializes to optimal
jamming attacks studied in [3], [4]; Letting 𝐵𝑎 = 𝐵𝑑, we
can model false data injection attacks in the operator-to-
actuator channel [16]; With ℎ(𝑖𝑑, 𝑖𝑎) = 1 − (1 − 𝑖𝑑) (1 − 𝑖𝑎),
the framework describes pursuit-evasion type of security
problems with controlled information [17], where detecting
your opponent’s location will expose your own location.

III. THEORETICAL RESULTS

The non-hierarchical decision making between the de-
fender and the attacker makes Nash equilibrium a natural
solution concept for this game. In a Nash equilibrium, none
of the players can get better off by unilaterally deviating
from the equilibrium.
Deﬁnition 1. A strategy pair (𝜋𝑑∗, 𝜋𝑎∗) is called a Nash
equilibrium of the zero-sum dynamic game described by
Equations (1) to (5) if
𝐹 𝑑 (𝜋𝑑∗

, 𝜋𝑎∗) ≤ 𝐹 𝑑 (𝜋𝑑, 𝜋𝑎∗),

, 𝜋𝑎) ≤ 𝐹 𝑑 (𝜋𝑑∗

for all 𝜋𝑑 ∈ Π𝑑 and 𝜋𝑎 ∈ Π𝑎, where Π𝑑(Π𝑎) is the strategy
space of the defender(attacker) that contains all possible
strategies.

The characterization and the computation of Nash equi-
librium involve solutions of individual optimization problem
for both the defender and the attacker. In a ﬁnite-horizon
dynamic game, the characterization and the computation of
the equilibrium are usually obtained by conducting backward
induction, which gives rise to the concept of Subgame
Perfect Nash Equilibrium (SPNE). The SPNE is a reﬁnement
of Nash equilibrium used in dynamic games with perfect
information. A game with perfect information is a game
where each player is perfectly informed of the history of what
has happened so far, up to the point where it is her turn to
move. Hence, this game is a game with perfect information.
The expected cost-to-go of the defender conditioned on the
information set from the beginning of time 𝑘 to its terminal
state at time 𝑁 is

𝑁 −1

𝑘 (F𝑘) = E
𝑓 𝑑

𝑐𝑛 (𝑥𝑛, 𝑢𝑑

𝑛, 𝑢𝑎

𝑛, 𝑖𝑑

𝑛 , 𝑖𝑎

𝑛 ) + 𝑥 ′

𝑁 𝑄 𝑁 𝑥 𝑁

F𝑘

,

(6)
for 𝑘 = 0, 1, · · · , 𝑁. The expected cost-to-go functional of
𝑘 (F𝑘) = − 𝑓 𝑑
the attacker is hence 𝑓 𝑎
𝑘 (F𝑘). For each stage
𝑘, the defender and the attacker, their cost-to-go functional
𝑓 𝑑
𝑘 and 𝑓 𝑎
𝑘 , together with the strategies for future stages
(𝜋𝑑
𝑘 , 𝜋𝑑
𝑘 , 𝜋𝑎
𝑁 −1) constitute a
subgame embedded in the original game in the original game.
The original game is a subgame of itself when 𝑘 = 0.

𝑁 −1) and (𝜋𝑎

𝑘+1, · · · , 𝜋𝑑

𝑘+1, · · · , 𝜋𝑎

#

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

"

Õ𝑛=𝑘

3

Deﬁnition 2. An equilibrium is an SPNE if and only if it is
a Nash equilibrium in every subgame of the original game.

An SPNE is a Nash equilibrium for the entire game since
the entire game of also a subgame when 𝑘 = 0. In this
paper, we focus on studying the SPNE of the game. The
complete characterization and the computation of the SPNE
are conducted via two steps. The ﬁrst is to characterize the
SPNE control strategies from backward induction for all
possible observation decision sequences. The second is to
ﬁnd the SPNE observation strategies based on the values
under the SPNE control strategies computed in the ﬁrst step.

A. Control Strategies

𝑁 −1 and a sequence of jamming decisions 𝐼 𝑎

Suppose that we are given a sequence of observation
decisions 𝐼 𝑑
𝑁 −1.
Under control strategies 𝜈𝑑 and 𝜈𝑎, the expected cost-to-
go starting from time 𝑘 conditioning on the information
available after the observation is

𝑁 −1

𝑘 (𝜈𝑑, 𝜈𝑎) = E
𝑉 𝑑

𝑐𝑛 (𝑥𝑛, 𝑢𝑑

𝑛, 𝑢𝑎

𝑛, 𝑖𝑑

𝑛 , 𝑖𝑎

𝑛 ) + 𝑥 ′

𝑁 𝑄 𝑁 𝑥 𝑁

¯F𝑘

.

"

Õ𝑛=𝑘

(cid:12)
#
(cid:12)
(7)
(cid:12)
∗( ¯F𝑘) =
(cid:12)
Let us deﬁne the SPNE cost-to-go value as 𝑉 𝑑
(cid:12)
𝑘
𝑘 (𝜈𝑑∗
𝑘 (𝜈𝑑, 𝜈𝑎∗), where 𝜈𝑎 = arg max 𝑉 𝑑
min𝑣 𝑑 𝑉 𝑑
, 𝜈𝑎). The
complete solution of this problem requires the knowledge
of 1) the SPNE control strategies at any stage 2) the SPNE
expected cost of proceeding from any state at any time to
the end. The main results for the SPNE control strategies are
summarized in the following theorem.

Theorem 1. For any given observation sequence 𝐼 𝑑
and jamming sequence 𝐼 𝑎
0, 1, · · · , 𝑁, the SPNE cost-to-go value to the end is

𝑁 −1, starting from any stage 𝑘 =

𝑁 −1

∗ =E

𝑉 𝑑
𝑘

𝑥 ′
𝑘 𝐿 𝑘𝑥𝑘

¯F𝑘

+

Tr Σ𝑠𝐶 ′𝐿𝑛+1𝐶

𝑁 −1

Õ𝑛=𝑘

(cid:3)

(cid:12)
(cid:12)

Tr 𝑃𝑛 ( ¯F𝑛)𝜑𝑛 + 𝑖𝑑

𝑛 𝑂 𝑑

𝑛 − 𝑖𝑎

𝑛𝑂 𝑎
𝑛

(cid:2)
𝑁 −1

+

Õ𝑛=𝑘 (cid:16)

where

(8)

,

(cid:17)

𝐿𝑛 = 𝑄𝑛 + 𝐴′

𝐿𝑛+1 − 𝐿𝑛+1

𝐵𝑑

𝐵𝑎

𝑀−1
𝑛

for 𝑛 = 1, 2 · · · , 𝑁 − 1 with 𝐿 𝑁 = 𝑄 𝑁 . The matrix

(cid:2)

(cid:3)

(cid:18)

𝐵𝑑 ′
𝐵𝑎 ′

(cid:20)

(cid:21)

𝐿𝑛+1

𝐴,

(9)

(cid:19)

𝑛 + 𝐵𝑑 ′𝐿𝑛+1 𝐵𝑑
𝑅𝑑
𝐵𝑎 ′𝐿𝑛+1 𝐵𝑑

𝑀𝑛 =

(cid:20)

is invertible provided that 𝑅𝑎
0, 1, · · · , 𝑁 − 1.

𝐵𝑑 ′𝐿𝑛+1 𝐵𝑎
𝐵𝑎 ′𝐿𝑛+1 𝐵𝑎 − 𝑅𝑎
𝑛 (cid:21)
𝑛 > 𝐵𝑎 ′𝐿𝑛+1𝐵𝑎 for 𝑘 =

(10)

At each stage 𝑛,

the
defender and the attacker take the form of the linear state
feedback control laws

the SPNE control strategies of

∗

∗

= −𝑀 −1
𝑛

𝑢𝑑
𝑛
𝑢𝑎
𝑛

𝐵𝑑 ′
𝐵𝑎 ′

𝐿𝑛+1 𝐴 ˆ𝑥𝑛,

(11)

(cid:21)

(cid:20)
(cid:20)
where the estimator ˆ𝑥𝑛 = E
𝑥𝑛
is given by a Kalman-
type linear ﬁlter [18] operating on the observation data 𝑌𝑛
(cid:2)

(cid:21)
¯F𝑛

(cid:3)

(cid:12)
(cid:12)

𝑛 and 𝐼 𝑎

decided by 𝐼 𝑑
𝑛 . The covariance of the estimation error
associated with the ﬁlter 𝑃𝑛 ( ¯F𝑛) = E [(𝑥𝑛 − ˆ𝑥𝑛) (𝑥𝑛 − ˆ𝑥𝑛) ′]
can be propagated as
𝑃𝑛 ( ¯F𝑛) =

𝐴𝑃𝑛−1 ( ¯F𝑛−1) 𝐴′ + 𝐶Σ𝑠𝐶 ′,
(Id −𝐺𝑛 𝐷)
(Id −𝐺𝑛 𝐷)′ + 𝐺𝑛𝐸Σ𝑜𝐸 ′𝐺 ′
𝑛,
(cid:0)

𝐴𝑃𝑛−1 ( ¯F𝑛−1) 𝐴′ + 𝐶Σ𝑠𝐶 ′

if ℎ(𝑖𝑑
𝑛 , 𝑖𝑎
×
𝑛 , 𝑖𝑎
if ℎ(𝑖𝑑
(cid:1)


where 𝐺𝑛 can be recognized as one of the usual Kalman

ﬁlter gains with


𝑛 ) = 1,

𝑛 ) = 0,

(12)

𝐺𝑛 =

(cid:0)

𝐴𝑃𝑛−1 ( ¯F𝑛−1) 𝐴′ + 𝐶Σ𝑠𝐶 ′
𝐷

𝐴𝑃𝑛−1 ( ¯F𝑛−1) 𝐴′ + 𝐶Σ𝑠𝐶 ′

𝐷 ′×

(cid:1)

𝐷 ′ + 𝐸Σ𝑜𝐸 ′

−1

.

Here, the observation effect coefﬁcients 𝜑𝑛 in Equation (8)
(cid:2)
is given as

(cid:3)

(cid:0)

(cid:1)

𝜑𝑛 = 𝐴′𝐿𝑛+1

𝐵𝑑 𝐵𝑎

𝑀 −1
𝑛

𝐵𝑑 ′
𝐵𝑎 ′

(cid:20)

(cid:21)

𝐿𝑛+1 𝐴.

(13)

(cid:2)

(cid:3)

Proof. The proof is conducted by backward induction. When
𝑘 = 𝑁, there are no control strategies involved at this stage.
Hence, we have

where ¯𝑥 = E [𝑥]. Applying this relation to the quadratic term
involving ˆ𝑥𝑛−1 Equation (16) yields

𝑉 𝑑

∗ =

𝑁 −1
𝑁 −1 𝐿 𝑁 −1𝑥 𝑁 −1 + (𝑥 𝑁 −1 − ˆ𝑥 𝑁 −1) ′ 𝐴′𝐿 𝑁
𝑥 ′

E

𝐵𝑑 𝐵𝑎

×

(cid:2)
+ 𝑖𝑑
𝑁 −1𝑂 𝑑

(cid:3)
𝑁 −1

(cid:21)

− 𝑖𝑎

¯F𝑁 −1

𝐿 𝑁 𝐴(𝑥 𝑁 −1 − ˆ𝑥 𝑁 −1)

𝐵𝑑 ′
h
𝑀 −1
𝐵𝑎 ′
𝑁 −1
(cid:20)
𝑁 −1 + Tr Σ𝑠𝐶 ′𝐿 𝑁 𝐶.
𝑁 −1𝑂 𝑎
Using the deﬁnition of 𝑃𝑁 −1 ( ¯F𝑁 −1) gives
+ 𝑖𝑑

∗ = E

(cid:12)
(cid:12)
(cid:12)

i

i

𝑁 −1

𝑉 𝑑

𝑁 −1𝑂 𝑎

𝑁 −1𝑂 𝑑

𝑁 −1
− 𝑖𝑎

𝑥 ′
𝑁 −1 𝐿 𝑁 −1𝑥 𝑁 −1

¯F𝑁 −1
𝑁 −1 + Tr Σ𝑠𝐶 ′𝐿 𝑁 𝐶 + Tr 𝑃𝑁 −1( ¯F𝑁 −1)𝜑𝑁 −1,
h

(cid:12)
(cid:12)
(cid:12)
which agrees with Equation (8), and 𝜑𝑁 −1 satisﬁes Equa-
tion (13). The propagation of 𝑃𝑛 ( ¯F𝑛) in Equation (12)
follows the results of [19]. Thus, we have shown that
Equations (8) to (13) hold for 𝑘 = 𝑁 − 1. Suppose that the
claims Equations (8) to (13) hold for an arbitrary 𝑘 + 1 ≤ 𝑁.
By deﬁnition of 𝑉 𝑑
𝑘 and the tower property of conditional
expectation [20], we have
𝑘 (𝜈𝑑, 𝜈𝑎) = E
𝑉 𝑑

𝑘𝑄 𝑘 𝑥𝑘 + 𝑢𝑑
𝑘

𝑘 − 𝑢𝑎
𝑘

𝑘 𝑢𝑑
𝑅𝑑

𝑘 𝑢𝑎
𝑘

′𝑅𝑎

(𝑥 ′

′

∗

𝑉 𝑑
𝑁

( ¯F𝑁 ) = 𝑉 𝑑

𝑁 ( ¯F𝑁 ) = E

𝑥 ′
𝑁 𝑄 𝑁 𝑥 𝑁

¯F𝑁

.

h
+ 𝑖𝑑

𝑘 𝑂 𝑑

𝑘 + 𝑖𝑎

𝑘 𝑂 𝑎

𝑘 ) + 𝑉 𝑑

𝑘+1( ¯F𝑘+1)

¯F𝑘

.

which agrees with Equation (8). We demonstrate that Equa-
tions (8) to (13) hold when 𝑘 = 𝑁 − 1. By deﬁnition, we
have

(cid:2)

(cid:3)

(cid:12)
(cid:12)

𝑉 𝑑

𝑁 −1

E

𝑥 ′
𝑁 −1𝑄 𝑁 −1𝑥 𝑁 −1 + 𝑢𝑑

𝑁 −1

′

𝑁 −1𝑢𝑑
𝑅𝑑

𝑁 −1

∗

𝑉 𝑑
𝑘
= min
𝑢𝑑
𝑘

( ¯F𝑘)

max
𝑢𝑎
𝑘

An application of dynamic programming techniques yields

(cid:21)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

E

𝑥 ′
𝑘𝑄 𝑘 𝑥𝑘 + 𝑢𝑑
𝑘

′

𝑅𝑑
𝑘 𝑢𝑑

𝑘 − 𝑢𝑎

𝑘

′𝑅𝑎

𝑘 𝑢𝑎

𝑘 + 𝑖𝑑

𝑘 𝑂 𝑑

𝑘

𝑁 −1𝑂 𝑑

𝑁 −1 − 𝑖𝑎

𝑁 −1𝑂 𝑎

𝑁 −1

h
𝑘 + 𝑉 𝑑
𝑘+1

+ 𝑖𝑎

𝑘 𝑂 𝑎

∗

( ¯F𝑘+1)

¯F𝑘

∗ = min
𝑢𝑑
𝑁 −1
− 𝑢𝑎

max
𝑢𝑎
𝑁 −1
′𝑅𝑎

𝑁 −1
𝑁 𝐿 𝑁 𝑥 𝑁

+ 𝑥 ′

h
𝑁 −1𝑢𝑎
¯F𝑁 −1

𝑁 −1 + 𝑖𝑑
.

i

(cid:12)
(cid:12)
(cid:12)

Substituting 𝑋𝑁 = 𝐴𝑥 𝑁 −1 + 𝐵𝑑𝑢𝑑
carrying out the expectation, minimizing over 𝑢𝑑
maximizing over 𝑢𝑎

(14)
𝑁 −1 + 𝐶𝑤 𝑁 −1,
𝑁 −1, and
𝑁 −1 yield the SPNE control for this stage
𝑑′

𝑁 −1 + 𝐵𝑎𝑢𝑎

𝑑′

𝑎

∗ = −(𝑅
𝑑
𝑁 −1 + 𝐵
𝐿𝑁 𝐵
∗ = −(𝐵𝑎 ′𝐿𝑁 𝐵𝑎 − 𝑅𝑎

𝑑 )−1 𝐵

𝐿𝑁 ( 𝐴 ˆ𝑥𝑁 −1 + 𝐵

𝑢
𝑁 −1)−1 𝐵𝑎′𝐿𝑁 ( 𝐴 ˆ𝑥𝑁 −1 + 𝐵𝑑𝑢𝑑

𝑎
𝑁 −1

𝑁 −1

∗),
∗

).

𝑑
𝑢
𝑁 −1
𝑢𝑎
𝑁 −1

Solving the two linear equations yields Equation (11) for
the case of 𝑛 = 𝑁 − 1. Substituting the SPNE control back
into Equation (14) gives

𝑉 𝑑

∗ =

𝑁 −1
𝑁 −1 (𝑄 𝑁 −1 + 𝐴′𝐿 𝑁 𝐴) 𝑥 𝑁 −1
𝑥 ′

E

h
− ˆ𝑥 ′

𝑁 −1 𝐴′𝐿 𝑁

𝐵𝑑 𝐵𝑎

𝑀 −1

𝑁 −1

𝐿 𝑁 𝐴 ˆ𝑥 𝑁 −1

𝐵𝑑 ′
𝐵𝑎 ′
+ Tr Σ𝑠𝐶 ′𝐿 𝑁 𝐶,

(cid:21)

(cid:20)
¯F𝑁 −1

(16)

+ 𝑖𝑑

(cid:3)
𝑁 −1

𝑁 −1𝑂 𝑎

𝑁 −1𝑂 𝑑

(cid:2)
𝑁 −1 − 𝑖𝑎
(cid:12)
i
=
where we have used the fact that E
(cid:12)
(cid:12)
Tr Σ𝑠𝐶 ′𝐿 𝑁 −1𝐶. The expectation in Equation (16) must still
be speciﬁed for the quadratic term involving ˆ𝑥𝑛−1. For any
random vector 𝑥 and any appropriately dimensioned matrix
𝑀, we have the relation

𝑁 −1𝐶 ′𝐿 𝑁 𝐶𝑤 𝑁 −1

𝑤′

(cid:2)

(cid:3)

E [𝑥 ′𝑀𝑥] = ¯𝑥 ′𝑀 ¯𝑥 + E [(𝑥 − ¯𝑥) ′𝑀 (𝑥 − ¯𝑥)] ,

4

𝑁 −1

=

Tr

(cid:12)
(cid:12)
(cid:12)
𝑃𝑛 ( ¯F𝑛)𝜑𝑛 + Σ𝑠𝐶 ′𝐿𝑛+1𝐶
(cid:12)

(cid:21)

+ 𝑖𝑑

𝑛 𝑂 𝑑

𝑛 − 𝑖𝑎

𝑛𝑂 𝑎
𝑛

Õ𝑛=𝑘+1
(cid:2)
(cid:0)
+ min
max
𝑢𝑎
𝑢𝑑
𝑘
𝑘

E

"

𝑥 ′
𝑘𝑄 𝑘𝑥𝑘 + 𝑢𝑑
𝑘

′

(cid:1)
𝑘 − 𝑢𝑎

𝑘

𝑅𝑑
𝑘 𝑢𝑑

′𝑅𝑎

𝑘 𝑢𝑎

𝑘 + 𝑖𝑑

(cid:3)
𝑘 𝑂 𝑑

𝑘

(15)

+ 𝑖𝑎

𝑘 𝑂 𝑎

𝑘 + 𝑥 ′

𝑘+1 𝐿 𝑘+1𝑥𝑘+1

¯F𝑘

.

i

(cid:12)
(cid:12)
(cid:12)

The remaining proof, which deals the minimax term, is iden-
tical to the proof for the case when 𝑘 = 𝑁 −1. Now it remains
𝑛 > 𝐵𝑎 ′𝐿𝑛+1 𝐵𝑎. The
to show that 𝑀𝑛 is invertible when 𝑅𝑎
matrix 𝑀𝑛 is invertible, provided that the Schur complement
[21],

𝑆𝐶 ≡𝐵𝑎 ′𝐿𝑛+1 𝐵𝑎 − 𝑅𝑎
𝑛 + 𝐵𝑑 ′

𝑛 − 𝐵𝑎 ′𝐿𝑛+1 𝐵𝑑×
𝐿𝑛+1 𝐵𝑎,

𝐿𝑛+1𝐵𝑑)−1𝐵𝑑 ′

(𝑅𝑑

is invertible. Clearly, the Schur complement 𝑆𝐶 is a real,
𝑛 > 𝐵𝑎 ′𝐿𝑛+1 𝐵𝑎 guarantees that the
symmetric matrix. And 𝑅𝑎
Schur complement 𝑆𝐶 is negative deﬁnite, hence invertible.
(cid:3)

Remark 2. It is required to calculate the matrix inverse 𝑀 −1
𝑛 .
The Schur complement of the bottom-right-corner block in
the 𝑀𝑛 matrix is the real, symmetric matrix
𝑛 + 𝐵𝑑 ′
𝐿𝑛+1 𝐵𝑑 + 𝐵𝑑 ′
𝑛 − 𝐵𝑎 ′𝐿𝑛+1 𝐵𝑎)−1𝐵𝑎 ′𝐿𝑛+1 𝐵𝑑,

𝑆𝐵 (𝐿𝑛+1) = 𝑅𝑑

𝐿𝑛+1 𝐵𝑎×

(𝑅𝑎

which is positive deﬁnite since 𝑅𝑎
invertible. Therefore, the matrix 𝑀 −1
𝑛
follows:

𝑛 > 𝐵𝑎 ′𝐿𝑛+1 𝐵𝑎, and hence
can be factored as

𝑀 −1
𝑛

= Ω𝑇Ω′

with

Ω′ =

𝑇 =

(cid:20)

(cid:20)

Id 𝐵𝑑 ′
0
𝑆−1
𝐵 (𝐿𝑛+1)
0

𝐿𝑛+1 𝐵𝑎

𝑛 − 𝐵𝑎 ′𝐿𝑛+1 𝐵𝑎
𝑅𝑎
Id

(cid:2)

0
𝑛 − 𝐵𝑎 ′𝐿𝑛+1 𝐵𝑎
𝑅𝑎

−

−1

(cid:3)

−1

(cid:21)

(17)

(18)

,

(cid:21)

.

This allows the defender and the attacker to compute their
SPNE control laws using explicit formulae,

(cid:2)

(cid:3)

∗ =𝜈𝑑

n
∗ =𝜈𝑑

𝑢𝑑
𝑛

𝑢𝑎
𝑛

×

𝐵 (𝐿𝑛+1)𝐵𝑑 ′
𝑛 ( ¯F𝑛) = −𝑆−1
−1𝐵𝑎 ′
𝑛 − 𝐵𝑎 ′𝐿𝑛+1 𝐵𝑎
Id +𝐿𝑛+1 𝐵𝑎
𝑅𝑎
𝑛 − 𝐵𝑎 ′𝐿𝑛+1 𝐵𝑎]−1𝐵𝑎 ′×
𝑎 ( ¯F𝑛) = [𝑅𝑎
(cid:2)
𝐵 (𝐿𝑛+1)𝐵𝑑 ′
Id −𝐿𝑛+1 𝐵𝑑𝑆−1

(cid:3)

(cid:18)

𝑛 − 𝐵𝑎 ′𝐿𝑛+1 𝐵𝑎
𝑅𝑎

−1 𝐵𝑎 ′

n
𝐿𝑛+1 𝐴 ˆ𝑥𝑛.

Id +𝐿𝑛+1 𝐵𝑎×

𝐿𝑛+1 𝐴 ˆ𝑥𝑛

o

(cid:3)

o(cid:19)

(cid:2)

𝑛 > 𝐵𝑎 ′𝐿𝑛+1 𝐵𝑎 is
Remark 3. The assumptions that 𝑅𝑎
in the setting of adversarial attacks since
not stringent
the cost of injecting malicious controls into the plant is
usually expensive, much higher than the normal controls
implemented by the defender.

Remark 4. If it is assumed that the initial state 𝑥0 is known
to both players, the following initial conditions must hold for
= 0 and 𝑃0 ( ¯F0) = 0. This
𝑃0( ¯F0) in Equation (12): 𝑖𝑑
= 𝑖𝑎
0
0
is because the exact knowledge of the initial state 𝑥0 at no
cost is preferable for the defender to a noisy and expensive
initial observation. Hence, this is no incentive to observe for
the defender, and as a result, there is no need to jam. If 𝑥0 is
Gaussian distributed with mean ¯𝑥0 and variance Σ0, whose
realization is unknown to both players but the statistics are
known to both, then the following initial conditions hold in
Equation (12):
𝑃0 ( ¯F0) =
Σ0,
Σ0 − Σ0𝐷 ′[𝐷 ′Σ0𝐷 + 𝐸 ′Σ𝑜𝐸]−1𝐷 ′Σ0,

if ℎ(𝑖𝑑
if ℎ(𝑖𝑑

𝑛 ) = 0,
𝑛 ) = 1.

𝑛 , 𝑖𝑎
𝑛 , 𝑖𝑎

(

,

∗

𝑁 −1,

Given 𝐼 𝑑

𝑁 −1 and 𝐼 𝑎

. The cost

the total expected cost condi-
tioned on ¯F0 for the defender with the SPNE control
strategies is 𝑉 𝑑
includes the quadratic term
0
¯F0
E
𝑥 ′
0 𝐿0𝑥0
induced by system
𝑁 −1
𝑛=0 Tr Σ𝑠𝐶 ′𝐿𝑛+1𝐶, the accumulated cost induced by
noise
(cid:12)
(cid:2)
𝑛=0 Tr 𝑃𝑛 ( ¯F𝑛)𝜑𝑛, where the estima-
(cid:12)
the estimation error
tion error relies heavily on the observation and the jamming
decisions, as well as the accumulated costs of observing

the accumulated cost

𝑁 −1

Í

(cid:3)

𝑛 𝑂 𝑑

𝑁 −1
𝑛=0 𝑖𝑑
Being aware of each other’s strategies as shown by
Í
Equation (15), the attacker and the defender deploy their
SPNE control strategies according to linear control laws
based on their estimate of the state. The jamming of the

𝑁 −1
𝑛=0 𝑖𝑎

𝑛𝑂 𝑎
𝑛.

Í

Í
𝑛 and that of jamming

5

defender’s observation can undermine the control perfor-
mance, but at the same time, it also impairs the attacking
performance at the physical layer since the attacker also
suffers from less information, let alone the jamming cost 𝑂 𝑎
𝑛.
Whether the defender should observe or not also depends on
multiple factors including the cost of observation 𝑂 𝑑
𝑛 , the
control performance degradation caused by the estimation
error Tr 𝑃𝑛 ( ¯F𝑛)𝜑𝑛, and the implicit cost of offering more
information to the attacker. We will shed more ligth on the
observation and the jamming strategies in Section III-B.

B. The Observation and the Jamming Strategies

In Section III-A, we have demonstrated that for any given
observation sequences, the expected cost-to-go of the game
under the SPNE control strategies after the observation and
the jamming decision have been taken at time 𝑘 is 𝑉 𝑑
. In
𝑘
this section, we derive the the procedures for ﬁnding the
SPNE observation and jamming strategies by leveraging the
results we have developed in Section III-A.

∗

𝑛 , and the control strategies 𝜈𝑑

Note that instead of the inner cost-to-go 𝑉 𝑑

𝑘 ( ¯F𝑘), the cost-
to-go before the observation and the jamming decisions are
made at stage 𝑘 is 𝑓 𝑑
𝑘 (F𝑘) deﬁned in Equation (6). The
strategies to be made are the observation strategy 𝜇𝑑
𝑛 , the
𝑛 and 𝜈𝑎
jamming strategy 𝜇𝑎
𝑛
𝑘 ( ¯F𝑘) in Equation (7), the
for all 𝑛 ≥ 𝑘. By the deﬁnition of 𝑉 𝑑
𝑘 in Equation (6) and the fact that F𝑘 ⊂ ¯F𝑘,
deﬁnition of 𝑓 𝑑
𝑘 ( ¯F𝑘)
𝑉 𝑑
we have 𝑓 𝑑
. The defender aims to
ﬁnd both the observation strategy and the control strategy
that minimize 𝑓 𝑑
𝑘 (F𝑘) at every stage 𝑘 given F𝑘 while the
attacker aims to do the opposite. Since the control at time
stage 𝑛 ≥ 𝑘 dose not alter the information F𝑘, with a slight
abuse of notation, we can write

𝑘 (F𝑘) = E

F𝑘

(cid:12)
(cid:12)

(cid:3)

(cid:2)

∗

𝑓 𝑑
𝑘

(F𝑘) = min
𝜋 𝑑

max
𝜋 𝑎

𝑘 (F𝑘) = min
𝑓 𝑑
𝜇𝑑

E

max
𝜇𝑎

∗

𝑉 𝑑
𝑘

F𝑘

(cid:12)
(cid:12)
(cid:12)
Using Equation (12), Equation (8) can be written

h

i

∗ =E

𝑉 𝑑
𝑘

𝑥 ′
𝑘 𝐿 𝑘𝑥𝑘

(cid:2)
𝑁 −1

+

Tr

𝑁 −1

¯F𝑘

+

Tr Σ𝑠𝐶 ′𝐿𝑛+1𝐶

Õ𝑛=𝑘
(cid:3)
𝑃𝑛−1 ( ¯F𝑛−1)

(cid:12)
(cid:12)
𝑍

− ℎ(𝑖𝑑

𝑛 , 𝑖𝑎

𝑛 )×

Õ𝑛=𝑘
(cid:2)
𝐻 (𝑃𝑛−1

(cid:0)
¯F𝑛−1)

for 𝑘 ≥ 1, where

(cid:0)

(cid:1) (cid:3)

(cid:1)
𝑛 𝑂 𝑑
𝜑𝑛 + 𝑖𝑑

𝑛 − 𝑖𝑎

𝑛 𝑂 𝑎
𝑛,

𝑍 (𝑃) = 𝐴𝑃𝐴′ + 𝐶Σ𝑠𝐶 ′,
𝐻 (𝑃) = 𝑍 (𝑃)𝐷 ′[𝐷 (𝑍 (𝑃))𝐷 ′ + 𝐸Σ𝑜𝐸 ′]−1𝐷𝑍 (𝑃).

We deﬁne 𝐹 𝑑
yields

𝑘 (F𝑘) = E

∗|F𝑘

𝑉 𝑑
𝑘

. Using the tower property

(cid:2)
𝑘 (F𝑘) = 𝐾 𝑑
𝑘 (F𝑘) + 𝐽 𝑑
𝐹 𝑑

(cid:3)

𝑘 (𝜇𝑑, 𝜇𝑎, F𝑘),

where

𝑘 (F𝑘) = E
𝐾 𝑑

𝑥 ′
𝑘 𝐿 𝑘𝑥𝑘

𝑘 (𝜇𝑑, 𝜇𝑎, F𝑘) =
𝐽 𝑑

(cid:2)
𝑁 −1

Tr

𝑍

𝑁 −1

F𝑘

+

Tr Σ𝑠𝐶 ′𝐿𝑛+1𝐶,

(cid:3)

Õ𝑛=𝑘
(cid:12)
(cid:12)
𝑃𝑛−1 ( ¯F𝑛−1)

− ℎ(𝑖𝑑

𝑛 , 𝑖𝑎

𝑛 )×

Õ𝑛=𝑘
(cid:2)
𝐻 (𝑃𝑛−1

(cid:0)
¯F𝑛−1)

(cid:1)
𝑛 𝑂 𝑑
𝜑𝑛 + 𝑖𝑑

𝑛 − 𝑖𝑎

𝑛𝑂 𝑎
𝑛.

(cid:1) (cid:3)

𝑘 (𝜇𝑑, 𝜇𝑎, F𝑘), which we write as 𝐽 𝑑

Therefore, to ﬁnd the SPNE observation strategies, one can
(cid:0)
only focus on 𝐽 𝑑
𝑘 (F𝑘) for
convenience in later discussion. Let us deﬁne the quantity
𝐽 𝑑
𝑘 (F𝑘).
𝑘

∗ (F𝑘) = min𝜇𝑑 max𝜇𝑎 𝐽 𝑑
If the SPNE observation and the jamming strategies have
been given for every possible F𝑘+1, then the rule for selecting
the Nash equilibrium at stage 𝑘,

∗

𝐽 𝑑
𝑘

(F𝑘) = min
𝑖𝑑
𝑘

max
𝑖𝑎
𝑘

Tr

𝑍

𝑃𝑘−1( ¯F𝑘−1)

− ℎ(𝑖𝑑

𝑘 , 𝑖𝑎

𝑘 )×

𝐻 (𝑃𝑘−1
∗
+ 𝐽 𝑑

(cid:2)
¯F𝑘−1)
(F𝑘+1).
(cid:0)

(cid:1) (cid:3)

(cid:0)

𝜑𝑘 + 𝑖𝑑

𝑘 𝑂 𝑑

(cid:1)
𝑘 − 𝑖𝑎

𝑘 𝑂 𝑎
𝑘

𝑘+1
for 𝑘 = 1, 2, · · · , 𝑁 − 1 and we have 𝐽 𝑑
𝑁

∗ = 0 by deﬁnition.

Proposition 1. Suppose that there is a sequence of SPNE
∗
∗), 𝑛 = 𝑘 +
observation and jamming strategies {(𝜇𝑑
𝑛
∗ can be expressed as a function
1, · · · , 𝑁 − 1}. Then 𝐽 𝑑
𝑃𝑘 ( ¯F𝑘). There exists no Nash equilibrium at stage 𝑘 if

, 𝜇𝑎
𝑛

𝑘+1

𝑂 𝑎

𝑘 ≤ Tr 𝐻 (𝑃𝑘−1)𝜑𝑘 + 𝐽 𝑑
𝑘+1
∗
(𝑍 (𝑃𝑘−1) − 𝐻 (𝑃𝑘−1)),

− 𝐽 𝑑

(𝑍 (𝑃𝑘−1))

𝑘+1

𝑂 𝑑

𝑘 ≤ Tr 𝐻 (𝑃𝑘−1)𝜑𝑘 + 𝐽 𝑑
𝑘+1
∗
(𝑍 (𝑃𝑘−1) − 𝐻 (𝑃𝑘−1)),

− 𝐽 𝑑

(𝑍 (𝑃𝑘−1))

∗

∗

𝑘+1
where 𝑃𝑘−1 ≔ 𝑃𝑘−1( ¯F𝑘−1) for simplicity.
Proof. At stage 𝑘 = 𝑁 − 1, we have

(19)

Tr

𝑍 (𝑃𝑁 −2) − ℎ(𝑖𝑑

𝑁 −1, 𝑖𝑎

𝑁 −1)×

∗

𝐽 𝑑
𝑁 −1

(F𝑁 −1) = min
𝑖𝑑
𝑁 −1
𝐻 (𝑃𝑁 −2)

max
𝑖𝑎
𝑁 −1

(cid:3)

𝑁 −1𝑂𝑎

𝑁 −1 − 𝑖𝑎

(cid:2)
𝜑𝑁 −1 + 𝑖𝑑
Since the observation decision 𝑖𝑑

𝑁 −1𝑂𝑑
𝑁 −1 and the jamming
decision 𝑖𝑎
𝑁 −1 are both binary, the game at stage 𝑁 − 1 can
be written in the form of a matrix game, which is given in
Table I. An simple analysis of the matrix game shows that
if 𝑂 𝑑
𝑁 −1 ≥ Tr 𝐻 (𝑃𝑁 −2)𝜑𝑁 −1, the Nash equilibrium of the
matrix game is 𝑖𝑑

∗ = 0, 𝑖𝑎

∗ = 0; if

𝑁 −1.

𝑁 −1

𝑁 −1
𝑁 −1 < Tr 𝐻 (𝑃𝑁 −2)𝜑𝑁 −1 ≤ 𝑂 𝑎

𝑂 𝑑

𝑁 −1,

there exists a Nash equilibrium of the matrix game; i.e.,
∗ = 0; there does not exist a Nash equilibrium
𝑖𝑑
𝑁 −1
if

∗ = 1, 𝑖𝑎

𝑁 −1

𝑂 𝑑
𝑂 𝑎

𝑁 −1 < Tr 𝐻 (𝑃𝑁 −2)𝜑𝑁 −1,
𝑁 −1 < Tr 𝐻 (𝑃𝑁 −2)𝜑𝑁 −1,

and

which aligns with Equation (19). Note that when the Nash
equilibrium does exist, 𝐽∗
𝑁 −1 (F𝑁 −1) depends only on 𝑃𝑁 −2
except other system parameters and cost coefﬁcients that are
common knowledge to both players. Suppose that the claims

in Proposition Proposition 1 hold for 𝑘 + 1. For stage 𝑘, we
have
𝐽 𝑑
𝑘

𝑍 (𝑃𝑘−1) − ℎ(𝑖𝑑

𝑘 )𝐻 (𝑃𝑘−1)

𝑘 , 𝑖𝑎

𝜑𝑘

∗

(F𝑘) = min
𝑖𝑑
𝑘
+ 𝑖𝑑
= min
𝑖𝑑
𝑘
+ 𝑖𝑑

Tr

max
𝑖𝑎
𝑘
(cid:2)
𝑁 −1𝑂 𝑑
𝑁 −1 − 𝑖𝑎
Tr
max
𝑖𝑎
𝑘
𝑁 −1𝑂 𝑑

∗

𝑁 −1𝑂 𝑎
𝑍 (𝑃𝑘−1) − ℎ(𝑖𝑑

𝑁 −1 + 𝐽 𝑑
(𝑃𝑘 )
𝑘+1
𝑘 , 𝑖𝑎
𝑘 )𝐻 (𝑃𝑘−1)

(cid:3)

(cid:3)

𝜑𝑘

𝑁 −1𝑂 𝑎

(cid:2)
𝑁 −1 − 𝑖𝑎
𝑁 −1
𝑍 (𝑃𝑘−1) − ℎ(𝑖𝑑

∗

+ 𝐽 𝑑

𝑘+1

𝑘 , 𝑖𝑎

𝑘 )𝐻 (𝑃𝑘−1)

.

(20)
The remaining proof follows the same procedures in the case
of 𝑘 = 𝑁 − 1.

(cid:17)

(cid:16)

TABLE I

THE PAYOFF MATRIX FOR THE ZERO-SUM GAME BETWEEN THE
DEFENDER AND THE ATTACKER AT STAGE 𝑁 − 1.

𝐽 𝑑
𝑁 −1

𝑖𝑑
𝑁 −1

1

1

0

Tr 𝑍 ( 𝑃𝑁 −2) 𝜑𝑁 −1
𝑁 −1 − 𝑂𝑎
+𝑂𝑑
𝑁 −1
Tr 𝑍 ( 𝑃𝑁 −2) 𝜑𝑁 −1
−𝑂𝑎

𝑁 −1

𝑖𝑎
𝑁 −1

0
Tr[𝑍 ( 𝑃𝑁 −2) − 𝐻 ( 𝑃𝑁 −2) ]×
𝜑𝑁 −1
+𝑂𝑑
𝑁 −1

Tr 𝑍 ( 𝑃𝑁 −2) 𝜑𝑁 −1

(cid:3)

We assume in the proof that when the margin is zero,
there is no incentive for both players to act. The defender
and the attacker have to decide at each stage whether to
observe and to attack respectively yet simultaneously. When
the conditions in Equation (19) hold, there is an incentive
to observe if the attacker does not jam but there always an
incentive for the attacker to jam if the defender observes.
Hence, there exists no Nash equilibrium in pure strategy.
Now, suppose that the defender announces its observation
decision ﬁrst, then the attacker chooses whether to jam. That
is to say at stage 𝑛 the observation and the jamming strategies
𝑛 ) and 𝜇𝑎
can be written as 𝜇𝑑

𝑛 ), where

𝑛 (F 𝑑
= F𝑛, F 𝑎
𝑛

𝑛 (F 𝑎
= F𝑛 ∪ 𝐼 𝑑
𝑛 .

F 𝑑
𝑛

Theorem 2. Under the information structure F 𝑑
𝑛 and F 𝑎
𝑛 ,
for any stage 𝑘 ≥ 1, there always exist a pair of Subgame
Perfect Equilibrium (SPE) strategies that depend only on
𝑃𝑘−1. The equilibrium at stage 𝑘 is (𝑖𝑑
𝑘
∗

∗) = (1, 1) if

∗, 𝑖𝑎
𝑘

𝑂 𝑑

𝑘 <𝑂 𝑎

𝑘 < Tr 𝐻 (𝑃𝑘−1)𝜑𝑘 + 𝐽 𝑑
𝑘+1
− 𝐽 𝑑

(𝑍 (𝑃𝑘−1) − 𝐻 (𝑃𝑘−1));

∗

𝑘+1

(𝑍 (𝑃𝑘−1))

The equilibrium is (𝑖𝑑
𝑘

∗

, 𝑖𝑎
𝑘

∗) = (1, 0) if

𝑂 𝑑

𝑘 < Tr 𝐻 (𝑃𝑘−1)𝜑𝑘 + 𝐽 𝑑
𝑘+1

∗

(𝑍 (𝑃𝑘−1))

∗

− 𝐽 𝑑

𝑘+1

(𝑍 (𝑃𝑘−1) − 𝐻 (𝑃𝑘−1)) ≤ 𝑂 𝑎
𝑘 ;

(21)

(22)

∗

and (𝑖𝑑
𝑘
solely on 𝑃𝑘−1.

, 𝑖𝑎
𝑘

∗) = (0, 0) otherwise. Hence, 𝐽 𝑑
𝑘

∗

also depends

Proof. It is easy to see the hypothesis holds at stage 𝑁 − 1.
Suppose that the hypothesis is true for stage 𝑘 + 1. Following

6

𝑘 , 𝑖𝑎

the same argument in the proof of Proposition 1, we can ar-
rive at the same matrix described by Table II except that now
the defender announces its observation decision ﬁrst, then the
defender reacts. In this circumstance, we have a Stackelberg
game and a Stackelberg equilibrium. When the defender
chooses not to observe, the best response of the attacker is
not to jam since jamming generates no beneﬁt but additional
𝑘 ) = (0, 0)
cost of jamming. This scenario gives (𝑖𝑑
∗ (𝑍 (𝑃𝑘−1)). When
= Tr 𝑍 (𝑃𝑘−1)𝜑𝑘+𝐽 𝑑
and cost-to-go 𝐽 𝑑
𝑘
the defender chooses to observe, the best response of the
∗ (𝑍 (𝑃𝑘−1)) −
attacker is to jam if 𝑂 𝑎
=
𝐽 𝑑
𝑘+1
∗ (𝑍 (𝑃𝑘−1)). The best re-
Tr 𝑍 (𝑃𝑘−1)𝜑𝑘 + 𝑂 𝑑
sponse becomes not jamming if 𝑂 𝑎
𝑘 ≥ Tr 𝐻 (𝑃𝑘−1)𝜑𝑘 +
∗ (𝑍 (𝑃𝑘−1)−𝐻 (𝑃𝑘−1)), which produces
∗ (𝑍 (𝑃𝑘−1))−𝐽 𝑑
𝐽 𝑑
𝑘+1
𝑘+1
∗ (𝑍 (𝑃𝑘−1)−
cost-to-go Tr[𝑍 (𝑃𝑘−1)−𝐻 (𝑃𝑘−1)]×𝜑𝑘+𝑂 𝑑
𝐻 (𝑃𝑘−1)). The defender then makes appropriate observation
decision that generates the least cost-to-go by anticipating
the best response of the attacker. Following this logic, we
∗) = (1, 1) if
obtain that the equilibrium at stage 𝑘 is (𝑖𝑑
, 𝑖𝑎
𝑘
𝑘
(𝑍 (𝑃𝑘−1))

∗ (𝑍 (𝑃𝑘−1) − 𝐻 (𝑃𝑘−1)), which gives cost-to-go 𝐽 𝑑

𝑘 < Tr 𝐻 (𝑃𝑘−1)𝜑𝑘 + 𝐽 𝑑
𝑘+1

𝑘 − 𝑂 𝑎

𝑘 +𝐽 𝑑
𝑘+1

𝑘 +𝐽 𝑑
𝑘+1

𝑂 𝑑

𝑘+1

𝑘

∗

∗

𝑘 <𝑂 𝑎

𝑘 < Tr 𝐻 (𝑃𝑘−1)𝜑𝑘 + 𝐽 𝑑
𝑘+1
− 𝐽 𝑑

∗

(𝑍 (𝑃𝑘−1) − 𝐻 (𝑃𝑘−1));
∗
∗) = (1, 0) if

𝑘+1

The equilibrium is (𝑖𝑑
𝑘

, 𝑖𝑎
𝑘

𝑂 𝑑

𝑘 < Tr 𝐻 (𝑃𝑘−1)𝜑𝑘 + 𝐽 𝑑
𝑘+1

∗

(𝑍 (𝑃𝑘−1))

∗

− 𝐽 𝑑

𝑘+1

(𝑍 (𝑃𝑘−1) − 𝐻 (𝑃𝑘−1)) ≤ 𝑂 𝑎
𝑘 ;

and (𝑖𝑑
𝑘

∗

, 𝑖𝑎
𝑘

∗) = (0, 0) otherwise.

TABLE II
THE PAYOFF MATRIX FOR THE ZERO-SUM GAME BETWEEN THE
DEFENDER AND THE ATTACKER AT STAGE 𝑘 ≥ 1.

𝐽 𝑑
𝑘

𝑖𝑑
𝑘

1

0

+𝑂𝑑
∗

1
Tr 𝑍 ( 𝑃𝑘−1) 𝜑𝑘
𝑘 − 𝑂𝑎
𝑘
(𝑍 ( 𝑃𝑘−1 ))

+𝐽 𝑑
𝑘+1
Tr 𝑍 ( 𝑃𝑘−1) 𝜑𝑘
−𝑂𝑎
𝑘
∗
(𝑍 ( 𝑃𝑘−1 ))

+𝐽 𝑑
𝑘+1

𝑖𝑎
𝑘

0
Tr[𝑍 ( 𝑃𝑘−1) − 𝐻 ( 𝑃𝑘−1) ]×
𝜑𝑘 + 𝑂𝑑
𝑘
(𝑍 ( 𝑃𝑘−1 ) − 𝐻 ( 𝑃𝑘−1))

∗

+𝐽 𝑑
𝑘+1

Tr 𝑍 ( 𝑃𝑘−1) 𝜑𝑘

∗

+𝐽 𝑑
𝑘+1

(𝑍 ( 𝑃𝑘−1))

∗

Hence, the strategies at stage 𝑘 depend solely on 𝑃𝑘−1.
And 𝐽 𝑑
is a function of 𝑃𝑘−1. Here, we assume that there
𝑘
is no incentive to act when the margin between two actions
(cid:3)
is zero.

Even though in some circumstances, the defender will be
better off if she/he can receive the observation, she/he will
not observe to avoid additional cost of observation since
she/he can anticipate the observation being jammed.

Corollary 1. Suppose that at each stage 𝑘, the attacker
announces her/his jamming decision ﬁrst, then the defender
= F𝑘 and F 𝑑
reacts; i.e., F 𝑎
𝑘 . The equilibrium at
𝑘
𝑘
∗, 𝑖𝑎
∗) = (0, 0) if
stage 𝑘 is (𝑖𝑑
𝑘
𝑘
𝑂 𝑑
𝑘 ≥ Tr 𝐻 (𝑃𝑘−1)𝜑𝑘 + 𝐽 𝑑
𝑘+1
∗
(𝑍 (𝑃𝑘−1) − 𝐻 (𝑃𝑘−1));

= F𝑘 ∪ 𝐼 𝑎

(𝑍 (𝑃𝑘−1))

− 𝐽 𝑑

∗

𝑘+1

the equilibrium is (𝑖𝑑
𝑘

∗

, 𝑖𝑎
𝑘

∗) = (0, 1)

𝑂 𝑑

𝑘 + 𝑂 𝑑

𝑘 < Tr 𝐻 (𝑃𝑘−1)𝜑𝑘 + 𝐽 𝑑
𝑘+1
∗
(𝑍 (𝑃𝑘−1) − 𝐻 (𝑃𝑘−1));

− 𝐽 𝑑

(𝑍 (𝑃𝑘−1))

𝑘+1

∗

and (𝑖𝑑
𝑘

∗

, 𝑖𝑎
𝑘

∗) = (1, 0) otherwise.

Here, we use the same notation 𝐽 𝑑
𝑘

different information structures.

∗

for games with

Remark 5. The dynamic programming equation in Equa-
tion (20) can be thought of as a dynamic programming
equation for a deterministic system with state 𝑃𝑘 and
𝑘 . The nonlinear state dynamics are 𝑃𝑘+1 =
𝑘 , 𝑖𝑎
controls 𝑖𝑑
𝑍 (𝑃𝑘 ) − ℎ(𝑖𝑑
𝑘 ) · 𝐻 (𝑃𝑘) with the stage cost being Tr 𝑃𝑘 𝜑𝑑
𝑘 , 𝑖𝑎
𝑘 +
𝑘 𝑂 𝑑
𝑖𝑑
𝑘 𝑂 𝑎
𝑘 − 𝑖𝑎
𝑘 .
Note that 𝑃𝑘 = 𝑍 (𝑃𝑘−1) − 𝐻 (𝑃𝑘−1) if the observation is
made and not jammed. Since 𝐻 (𝑃𝑘−1) is always positive
semi-deﬁnite, at stage 𝑘, if the observation is missing, i.e.,
𝑘 ) = 0 and 𝑃𝑘 = 𝑍 (𝑃𝑘−1), the covariance of estimate
ℎ(𝑖𝑑
error 𝑃𝑘 will be larger than the covariance when there is
an observation received. Here, by saying the covariance of
estimate error 𝑃𝑘 is larger than the covariance of estimate
error 𝑃′
𝑘. Note that the instantaneous cost
at stage 𝑘, is Tr 𝑃𝑘 𝜑𝑘 ≡ E [(𝑥𝑘 − ˆ𝑥𝑘) ′𝜑𝑘 (𝑥𝑘 − ˆ𝑥𝑘 )]. From
Equations (13) and (17), we know

𝑘 , we mean 𝑃𝑘 ≥ 𝑃′

𝑘 , 𝑖𝑎

𝜑𝑘 = 𝐴′𝐿 𝑘+1

𝐵𝑑 𝐵𝑎

Ω𝑇Ω′

𝐿 𝑘+1 𝐴,

𝐵𝑑 ′
𝐵𝑎 ′

(cid:20)

(cid:21)

(cid:2)

𝐵 (𝐿 𝑘+1) and −(𝑅𝑎

(cid:3)
where 𝑇, as we can see in Equation (18), is a block diagonal
𝑛 −𝐵𝑎 ′𝐿𝑛+1 𝐵𝑎)−1.
matrix with two blocks 𝑆−1
Since the former block is positive deﬁnite and the later
is negative deﬁnite, 𝜑𝑘
is neither positive semi-deﬁnite
nor negative semi-deﬁnite. That means Tr 𝑃𝑘 𝜑𝑘 could be
negative. The interpretation is that a larger estimate error
may not be always detrimental to the defender in the presence
of attacks since the observation can help the attacker inject
a better control into the physical plant. Thus, even when
𝑘 , 𝑘 = 0, 1, · · · , 𝑁 − 1 is zero, the
the cost of observation 𝑂 𝑑
defender will not have incentives to observe at each stage.
However, when 𝑅𝑎
𝑘 → ∞ which means that there will be no
attacks on the physical plant due to high costs, 𝜑𝑘 becomes
positive semi-deﬁnite and in this circumstance, the defender
will favor a smaller covariance.

A special case of our framework is when the defender
can obtain perfect observations. That is when 𝐷 = Id and
𝐸 = 0 or Σ𝑜 = 0. In this circumstance, the covariance of the
estimate error propagates as

𝑃𝑛 ( ¯F𝑛) =

𝐴𝑃𝑛−1 ( ¯F𝑛−1) 𝐴′ + 𝐶Σ𝑠𝐶 ′,
0,

(

with the initial condition

if ℎ(𝑖𝑑
if ℎ(𝑖𝑑

𝑛 , 𝑖𝑎
𝑛 , 𝑖𝑎

𝑛 ) = 0,
𝑛 ) = 1,

𝑃0 ( ¯F0) =

Σ0,
0,

(

if ℎ(𝑖𝑑
if ℎ(𝑖𝑑

0 , 𝑖𝑎
0 , 𝑖𝑎

0 ) = 0,
0 ) = 1.

The rest of the derivation will follow the results we have
developed for the noisy observation case.

7

C. Computation

From Section III-B, we know that the SPNE observation
strategies can be derived from a sequence of dynamic pro-
gramming equations. However, it is impossible to obtain a
∗
closed-form expression of the observation value function 𝐽 𝑑
𝑘
for all 𝑘 due to the nonlinearity of the covariance propagation
(12) and the discrete strategies of observing and jamming at
each stage. In this section, we consider two computational
methods the compute the SPNE observation and jamming
strategies. One is to use policy iteration type of algorithms
and another is to take decisions online by leveraging pre-
computed values. We focus on the case when the defender
announces her/his observation decision ﬁrst.

1) Policy Iteration Type of Algorithms: This computa-
tional method follows the idea of policy iteration [22]. The
SPNE observation solution can be obtained by the following
procedure.

1) Pick arbitrary observation and jamming sequences
𝑘 ) = (0, 1)(not
𝑁 −1 and ˜𝐼 𝑎
˜𝐼 𝑑
𝑁 −1 that do not contain (𝑖𝑑
an equilibrium for sure) for every 𝑘 = 0, 1, · · · , 𝑁 − 1.
𝑁 −1, generate a
𝑘 according to

2) Policy Evaluation: Given ˜𝐼 𝑑

sequence of value functions ˜𝐽 𝑑

𝑘 , 𝑖𝑎

𝑁 −1 and ˜𝐼 𝑎
𝑘 and ˜𝐽 𝑎
𝑘 − 𝑂 𝑎
𝑘 +𝐽 𝑑
𝑘+1
= 1;

∗

(𝑍 (𝑃)),

∗

𝐽 𝑑
𝑘

∗

𝐽 𝑑
𝑘

∗

𝐽 𝑑
𝑘

(𝑃) = Tr 𝑍 (𝑃)𝜑𝑘 + 𝑂 𝑑

When ˜𝑖𝑑
𝑘

= 1, ˜𝑖𝑑
𝑘
(𝑃) = Tr[𝑍 (𝑃) − 𝐻 (𝑃)]𝜑𝑘 + 𝑂 𝑑
𝑘

(𝑍 (𝑃) − 𝐻 (𝑃)),

∗

+𝐽 𝑑
𝑘+1
When ˜𝑖𝑑
𝑘
(𝑃) = Tr 𝑍 (𝑃)𝜑𝑘 +𝐽 𝑑

= 1, ˜𝑖𝑑
𝑘

(𝑍 (𝑃)),

= 0;
∗

𝑘+1
= 0.

When ˜𝑖𝑑
𝑘

= 0, ˜𝑖𝑑
𝑘

3) Policy update: Given the value functions

˜𝐽 𝑑
𝑘 com-
puted in 2), generate new sequences of observation
𝑁 −1 and 𝐼 𝑎
and jamming decisions 𝐼 𝑑
𝑁 −1 according to
Equations (21) and (22) in Theorem 2.

4) Replace ˜𝐼 𝑑

𝑁 −1 and ˜𝐼 𝑎
𝑁 −1 with 𝐼 𝑑
tively in 2), and continue until
˜𝐼 𝑎
𝑁 −1

𝑁 −1.

= 𝐼 𝑎

𝑁 −1 and 𝐼 𝑎
˜𝐼 𝑑
𝑁 −1

𝑁 −1 respec-
= 𝐼 𝑑
𝑁 −1 and

∗

No claim is made that the convergence of this procedure
is guaranteed. But if convergence does occur, the sequences
𝐼 𝑑
𝑁 −1 and 𝐼 𝑎
𝑁 −1 are equilibrium and the cost-to-go functions
𝐽 𝑑
𝑘

obey Equation (20).

2) Backward Enumeration Algorithm: Leveraging the re-
∗(𝑃) in the following

sults in Theorem 2, we can write 𝐽 𝑑
𝑘
manner.

𝑘 +𝐽 𝑑
𝑘+1

∗

(𝑍 (𝑃)),

𝑘 +𝐽 𝑑
𝑘+1

∗

(𝑍 (𝑃) − 𝐻 (𝑃)),

𝑘 − 𝑂𝑎
𝑘 < T𝑘 (𝑃);

Tr 𝑍 (𝑃)𝜑𝑘 + 𝑂𝑑
if 𝑂𝑑
𝑘 < 𝑂𝑎
Tr[𝑍 (𝑃) − 𝐻 (𝑃)]𝜑𝑘 + 𝑂𝑑
if 𝑂𝑑
𝑘 < T𝑘 (𝑃) ≤ 𝑂𝑎
𝑘 ;
Tr 𝑍 (𝑃)𝜑𝑘 +𝐽 𝑑
(𝑍 (𝑃)),
otherwise,

𝑘+1

∗

∗

𝐽 𝑑
𝑘

(𝑃) =




∗ = 0 and T𝑘 (𝑃) ≔ Tr 𝐻 (𝑃)𝜑𝑘 + 𝐽 𝑑
𝑘+1


∗(𝑍 (𝑃)) −
with 𝐽 𝑑
𝑁
∗ (𝑍 (𝑃) − 𝐻 (𝑃)). At any given stage 𝑘, there is only a
𝐽 𝑑
𝑘+1
ﬁnite number of distinct covariance 𝑃𝑘 for all possible 𝐼 𝑑
𝑘

and 𝐼 𝑎
𝑘 . Thus, it is sufﬁcient to ﬁnd the SPNE observations
and jamming strategies by computing and storing a ﬁnite
number of values to characterize the value functions in the
absence of a full characterization over the entire space of
symmetric positive semi-deﬁnite matrices. For example, at
stage 𝑘 = 0, we only have two possible 𝑃0 which are Σ0
and Σ0 − Σ0𝐷 ′[𝐷 ′Σ0𝐷 + 𝐸 ′Σ𝑜𝐸] 𝐷 ′Σ0. At stage 𝑘 = 𝑁 − 1.
there are 2𝑁 −1 possible values of 𝑃𝑁 −2 for all possible F𝑁 −1.
Hence, the total number of values needed to store for a given
game of horizon 𝑁 is

𝑁 −1

= 2𝑁 +1 − 2 ≤ 2𝑁 +1.

Õ𝑘=0

If the defender can obtain perfect observation, at stage 𝑘,
there are 𝑘 + 1 possible values 𝑃𝑘−1. The total number of
values needed is

𝑘 + 1 = 𝑁 (𝑁 − 1)

2

.

𝑁 −1

Õ𝑘=0

Remark 6. In order to compute the observation decision
online, we require that
the maximum number of values
needed to be stored is of order 𝑂 (2𝑁 ). When the defender
can receive perfect observation, i.e., 𝐷 = 𝐼 and 𝐸 = 0,
the maximum number of values needed to be stored is of
order 𝑂 (𝑛2). For 𝑁 = 30,
the total number of values
needed to be stored is approximately 1010. It is apparent
that if players receive noisy observation, for problems of any
appreciable size, the amount of storage required can easily
become prohibitive. One can resort to computational method
in Section III-C.1 to ﬁnd the SPNE strategies. However, if
players do have perfect observations, the backward enu-
meration approach can be done in polynomial time, which
becomes a better choice than the policy iteration type of
approach since it can guarantee the ﬁnding of the SPNE
strategies and support online decision making.

IV. NUMERICAL STUDY

It

is instructive to present some numerical studies of
the results in Section III. Our focus will be given to the
observation and the jamming strategies. A scalar case will
sufﬁce to illustrate the interesting nature of the observation
and the jamming sequences. A scalar case will even be
more illustrative in some way. Our results and computational
approaches can be effortlessly applied to higher dimensions.
Suppose that

𝑛 + 𝑤𝑛,

𝑛 ) ˜𝑦𝑛,

𝑛 + 𝑢𝑎

𝑥𝑛+1 = 𝑎𝑥𝑛 + 𝑢𝑑
˜𝑦𝑛 = 𝑥𝑛 + 𝑣𝑛,
𝑦𝑛 = 𝑖𝑑
𝑛 (1 − 𝑖𝑎
Σ𝑠 = 4; Σ0 = 1, Σ𝑜 = 𝜎,
𝑄𝑛 = 1, 𝑅𝑑
= 1, 𝑂 𝑑
𝑛
𝑛
𝑄 𝑁 = 8; , 𝑅𝑁 −1 = 10,
𝑅𝑎
𝑛

= 𝑟 𝑎,

0 ≤ 𝑛 ≤ 𝑁 − 2

= 𝑜𝑑, 𝑂 𝑑
𝑛

= 𝑜𝑎

0 ≤ 𝑛 ≤ 𝑁 − 1

We choose a total running time of 𝑁 = 30. The unassigned
parameters include system matrix parameter 𝑎, the cost of

8

Observing
Jamming

The physical attacking cost coefficient ra = 0.9

Observing
Jamming

A highly stable system a = 0.5

1
r
o
t
a
c
i
d
n

I

0

1
r
o
t
a
c
i
d
n

I

0

1
r
o
t
a
c
i
d
n

I

0

0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29
Stage n
The physical attacking cost coefficient ra = 1.5

0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29
Stage n
The physical attacking cost coefficient ra = 8.0

0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29
Stage n

1
r
o
t
a
c
i
d
n

I

0

1
r
o
t
a
c
i
d
n

I

0

1
r
o
t
a
c
i
d
n

I

0

0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29
Stage n
A slightly stable system a = 0.9

0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29
Stage n
An unstable system a = 1.1

0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29
Stage n

Fig. 1.
The observation decisions by the defender and the jamming
decisions by the attacker over 30 stages. Here, 𝑎 = 0.9, 𝑜𝑑 = 0, 𝑜𝑎 = 15,
and 𝜎 = 1 .

Fig. 2.
The Observation decisions by the defender and the jamming
decisions by the attacker over 30 stages. Here, 𝑟𝑎 = 1.5, 𝑜𝑑 = 0, 𝑜𝑎 = 15,
and 𝜎 = 1 .

physical attackers 𝑟 𝑎, the observation noise variance 𝜎, and
the observation 𝑜𝑑 and jamming cost 𝑜𝑎, which are subject
to change in the experiment. The computation follows the
policy iteration-based algorithm.

Figure 1 shows the observation decision sequences and
the jamming sequences for various costs of physical attacks.
Fixed values of 𝑎 = 0.9, 𝑜𝑑 = 0, 𝑜𝑎 = 15, and 𝜎 = 1
are used. They give a slight stable system with zero cost
of observation, cost of jamming being 15, and variance of
observation noise being 1. The experiments are conducted
for 𝑟 𝑎 = 0.9, 1.5, and 8.0. The cost of attacking the physical
plant has a strong impact on both the observation and the
jamming decisions. When the cost of physical attacks is low,
the defender does not observe at some stages even when
there is no cost of observation. This is because observations
at some stages will bring additional information that can be
leveraged by the attacker, who is powerful in the physical
side (i.e.,low cost of attacking), to compute her/his attacks on
the physical plant. As the cost of physical attacks increases,
undaunted by the additional information to the attacker, the
defender observes at each stage when 𝑟 𝑎 = 1.5. As the cost of
physical further increases to 𝑟 𝑎 = 8.0, the attacker enjoys less
beneﬁt from additional observations since her/his physical
attacks are constrained by high costs. Hence, the attacker
tends to jam more to prevent the defender from receiving
observations.

Figure 2 shows the observation decision sequences and the
jamming sequences under different system parameters. Fixed
values of 𝑟𝑎 = 1.5, 𝑜𝑑 = 0, 𝑜𝑎 = 15, and 𝜎 = 1 are used.
Sequences are shown for 𝑎 = 0.5, a highly stable system, 𝑎 =
0.9, a slightly stable system, and 𝑎 = 1.1, an unstable system.
In all three cases, the defender chooses to observe at every
stage because the attacks on the physical plant are limited by
the high cost of attacking. Additional information will beneﬁt
the defender more. A highly stable system, say 𝑎 = 0.5,
usually produces a very low-performance degradation when
an observation is missing. Hence, intimidated by the cost of
jamming, the attacker has no incentive to jam any of the
observations. A slightly stable system can be affected by the
attacker through jamming even if the cost of physical attacks

is high. The attacker tends to jam economically. That is to
jam near the end of the game to induce a considerable loss to
the defender because 𝑄 𝑁 = 8 is much higher than 𝑄𝑛 = 1 for
𝑛 ≤ 𝑁 −1. When the defender deals with an unstable system,
the attacker simply jams every stage so that the defender
cannot stabilize the system due to no received observation.
The defender could have chosen not to observe because the
observation will be jammed anyway. But this is a zero-sum
game, so the defender can at least gain a little from the
attacker’s cost induced by jamming.

Figure 3 shows the number of observations and jammings
as a function of observation noise variance 𝜎. Fixed values
𝑎 = 1.1, 𝑜𝑑 = 25, 𝑜𝑎 = 40, and 𝑟𝑎 = 20 are used. The cost of
physical attacks is set to be high which means the attacker
has limited capability at the physical side. When the cost of
jamming is also high 𝑜𝑎 = 6000, the game is degenerated
to resemble an optimal control problem with observations
that are costly and controlled. The curve regarding the
number of observations shows some unusual results. As
the observation noise variance 𝜎 increases, the observation
will be considered to be less valuable intuitively since it
will contain less useful information about the state of the
system. Grounded on this argument, one would expect the
number of observations goes down monotonically to zero as
𝜎 goes to inﬁnity. Economically, it means that we should
never pay for worthless information. However, the ﬁrst blue
curve of Figure 3 indicates that when the observation noise
variance grows from a small to a moderately large value,
it is better to actually increase the number of observations.
This means when the information content of each individual
observation is degraded slightly, it is better to pay the cost of
making extra observations in order to make a better estimate.
When the cost of jamming is lower, say when 𝑜𝑎 = 40,
the defender observes more frequently when the observation
noise variance is low because the defender knows that the
attacker will be jamming (if the attacker does not jam, the
defender will receive high-quality information to stabilize the
system while the attacker can do little with the information).
Doing so will render the attacker suffer more cost of jamming
due to the fact that 𝑂 𝑎
𝑛. As the observation noise

𝑛 > 𝑂 𝑑

9

[4] H. Zhang, P. Cheng, L. Shi, and J. Chen, “Optimal dos attack
scheduling in wireless networked control system,” IEEE Transactions
on Control Systems Technology, vol. 24, no. 3, pp. 843–852, 2015.
[5] Z. Xu and Q. Zhu, “A game-theoretic approach to secure control of
communication-based train control systems under jamming attacks,”
in Proceedings of the 1st International Workshop on Safe Control of
Connected and Autonomous Vehicles, 2017, pp. 27–34.

[6] Y. Mo, R. Chabukswar, and B. Sinopoli, “Detecting integrity attacks
on scada systems,” IEEE Transactions on Control Systems Technology,
vol. 22, no. 4, pp. 1396–1407, 2013.

[7] M. Zhu and S. Martinez, “On the performance analysis of resilient
networked control systems under replay attacks,” IEEE Transactions
on Automatic Control, vol. 59, no. 3, pp. 804–808, 2013.

[8] Q. Zhu and S. Rass, “On multi-phase and multi-stage game-theoretic
modeling of advanced persistent threats,” IEEE Access, vol. 6, pp.
13 958–13 971, 2018.

[9] S. Rass, A. Alshawish, M. A. Abid, S. Schauer, Q. Zhu, and
H. De Meer, “Physical intrusion games—optimizing surveillance by
simulation and game theory,” IEEE Access, vol. 5, pp. 8394–8407,
2017.

[10] Y. Huang, V. Kavitha, and Q. Zhu, “Continuous-time markov decision
processes with controlled observations,” in 2019 57th Annual Allerton
Conference on Communication, Control, and Computing (Allerton).
IEEE, 2019, pp. 32–39.

[11] Y. Huang, J. Chen, L. Huang, and Q. Zhu, “Dynamic games for secure
and resilient control system design,” National Science Review, vol. 7,
no. 7, pp. 1125–1141, 2020.

[12] M. A. Noureddine, A. Fawaz, W. H. Sanders, and T. Bas¸ar, “A
game-theoretic approach to respond to attacker lateral movement,” in
International Conference on Decision and Game Theory for Security.
Springer, 2016, pp. 294–313.

[13] K. Hor´ak, Q. Zhu, and B. Boˇsansk`y, “Manipulating adversary’s belief:
A dynamic game approach to deception by design for proactive
network security,” in International Conference on Decision and Game
Theory for Security. Springer, 2017, pp. 273–294.

[14] T. H. Nguyen, M. Wright, M. P. Wellman, and S. Baveja, “Multi-stage
attack graph security games: heuristic strategies, with empirical game-
theoretic analysis,” in Proceedings of the 2017 Workshop on Moving
Target Defense, 2017, pp. 87–97.

[15] J. Chen and Q. Zhu, “Control of multi-layer mobile autonomous
systems in adversarial environments: A games-in-games approach,”
IEEE Transactions on Control of Network Systems, 2019.

[16] A. Sargolzaei, K. Yazdani, A. Abbaspour, C. D. Crane III, and W. E.
Dixon, “Detection and mitigation of false data injection attacks in net-
worked control systems,” IEEE Transactions on Industrial Informatics,
vol. 16, no. 6, pp. 4281–4292, 2019.

[17] Y. Huang and Q. Zhu, “A pursuit-evasion differential game with
strategic information acquisition,” arXiv preprint arXiv:2102.05469,
2021.

[18] R. E. Kalman, “A New Approach to Linear Filtering and Prediction
Problems,” Journal of Basic Engineering, vol. 82, no. 1, pp. 35–45,
03 1960. [Online]. Available: https://doi.org/10.1115/1.3662552
[19] C. Cooper and N. Hahi, “An optimal stochastic control problem with
observation cost,” IEEE Transactions on Automatic Control, vol. 16,
no. 2, pp. 185–189, 1971.

[20] J. Jacod and P. Protter, Probability essentials.

Springer Science &

Business Media, 2012.

[21] F. Zhang, The Schur complement and its applications.

Springer

Science & Business Media, 2006, vol. 4.

[22] D. P. Bertsekas and J. N. Tsitsiklis, Neuro-dynamic programming.

Athena Scientiﬁc, 1996.

A high cost of jamming oa = 6000

f
o

r
e
b
m
u
N

5

0

101

103

105
observation noise variance σ

107

A lowe cost of jamming oa = 40

i

s
g
n
m
m
a
J
/
s
n
o
i
t
a
v
r
e
s
b
O

25

20

15

10

i

s
g
n
m
m
a
J
/
s
n
o
i
t
a
v
r
e
s
b
O

f
o

30

20

10

Observing
Jamming

109

Observing
Jamming

109

r
e
b
m
u
N

0

101

103

105
observation noise variance σ

107

Fig. 3.
Here, 𝑎 = 1.1, 𝑜𝑑 = 25, 𝑜𝑎 = 40, and 𝑟𝑎 = 20.

The number of observations and jamming attacks in 30 stages.

variance increases, the information becomes less useful. Only
at some stages, the attacker has incentives to observe but
most of these observations will be jammed since additional
information is favored less by the attacker than the defender
when the cost of physical attacks is high.

V. CONCLUSIONS

In this work, we have established a cross-layer multi-
stage framework to facilitate the study of CPSs under co-
ordinated cross-layer attacks. We have demonstrated that
the framework is generic and can be speciﬁed to several
classic attack models. The framework has been captured by
a zero-sum linear quadratic Gaussian game with controlled
observation. We have built solid theoretical underpinnings
for this framework which can be used to analyze a wide
variety of attacking settings. The theoretical results have
shown that control performance depends on the observation
and jamming strategies, which affects the quality of state
estimation. Hence, the observation and jamming decisions
can be carried out through dynamic equations that evolve
as the estimation error variance propagates. Beyond that,
the capability of altering the physical process will affect the
jamming and observation decisions.

Future works will focus on the study of mixed strategies of
observation and jamming, investigating the continuous-time
scenario, and inﬁnite-horizon problems.

REFERENCES

[1] S. Feng, A. Cetinkaya, H. Ishii, P. Tesi, and C. De Persis, “Networked
control under dos attacks: Trade-offs between resilience and data rate,”
IEEE Transactions on Automatic Control, 2020.

[2] H. S. Foroush and S. Martinez, “On event-triggered control of linear
systems under periodic denial-of-service jamming attacks,” in 2012
IEEE 51st IEEE Conference on Decision and Control (CDC).
IEEE,
2012, pp. 2551–2556.

[3] A. Gupta, C. Langbort, and T. Bas¸ar, “Optimal control in the presence
of an intelligent jammer with limited actions,” in 49th IEEE Confer-
ence on Decision and Control (CDC).
IEEE, 2010, pp. 1096–1101.

10

 
 
 
 
