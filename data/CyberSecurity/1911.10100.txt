FlipIn: A Game-Theoretic Cyber Insurance
Framework for Incentive-Compatible Cyber Risk
Management of Internet of Things

Rui Zhang and Quanyan Zhu

1

9
1
0
2

v
o
N
2
2

]

R
C
.
s
c
[

1
v
0
0
1
0
1
.
1
1
9
1
:
v
i
X
r
a

Abstract—Internet of Things (IoT) is highly vulnerable to
emerging Advanced Persistent Threats (APTs) that are often
operated by well-resourced adversaries. Achieving perfect secu-
rity for IoT networks is often cost-prohibitive if not impossible.
Cyber insurance is a valuable mechanism to mitigate cyber
risks for IoT systems. In this work, we propose a bi-level
game-theoretic framework called FlipIn to design incentive-
compatible and welfare-maximizing cyber insurance contracts.
The framework captures the strategic interactions among APT
attackers, IoT defenders, and cyber insurance insurers, and
incorporates inﬂuence networks to assess the systemic cyber
risks of interconnected IoT devices. The FlipIn framework
formulates a game over networks within a principal-agent
problem of moral-hazard type to design a cyber risk-aware
insurance contract. We completely characterize the equilibrium
solutions of the bi-level games for a network of distributed
defenders and a semi-homogeneous centralized defender and
show that the optimal
insurance contracts cover half of the
defenders’ losses. Our framework predicts the risk compensation
of defenders and the Peltzman effect of insurance. We study a
centralized security management scenario and its decentralized
counterpart, and leverage numerical experiments to show that
network connectivity plays an important role in the security
of the IoT devices and the insurability of both distributed and
centralized defenders.

Index Terms—Cyber Insurance, Internet of Things, Game-
Theoretic Design, FlipIt game, Inﬂuence Network, Principal-
agent Problem, Moral Hazard, Information Asymmetry, Risk
Compensation, Peltzman Effect, Network Effects

I. INTRODUCTION

The Internet of Things (IoT) has witnessed applications in
many areas such as smart cities, healthcare, and transportations
[1], [2]. However, IoT networks and devices can be highly
vulnerable to adversaries who can inﬂict huge ﬁnancial and
non-ﬁnancial losses on government, companies, and nonproﬁt
organization [3]–[7]. For example, Mirai botnet in 2016 has
compromised numerous IoT devices and knocked out popular
sites, such as Netﬂix, Spotify, Twitter, and GitHub, with massive
distributed denial-of-service (DDoS) attacks [8], [9].

One important class of sophisticated cyber-attacks called
advanced persistent threats (APTs) has posed severe threats to
IoT devices [10]–[14]. Different from traditional cyber-attacks,
APTs are executed by resourceful attackers, and they usually
involve multiple steps and persist for a long period of time.
For example, Stuxnet attack on Iran’s nuclear program has

R. Zhang and Q. Zhu are with Department of Electrical and Com-
puter Engineering, New York University, Brooklyn, NY, 11201 E-
mail:{rz885,qz494}@nyu.edu.

Fig. 1. Cyber Insurance for IoT against APTs.

compromised the target system’s logic controllers, and then
took control of the centrifuges, bringing them to failure [15],
[16].

The vulnerabilities of IoT devices to APTs arise from several
aspects [5], [17], [18]. First of all, security is not the primal
concern during their design and the manufacturing. Users
of the devices tend to adopt default or weak passwords. In
addition, users do not maintain and patch their devices unless
they stop working properly. Therefore, malicious activities
of APTs are often unnoticed on IoT devices before they
launch attacks and inﬂict signiﬁcant losses. It is challenging
to design effective defense methods and protect IoTs against
APTs due to the coexistence of multiple types of devices and
the lack of industrial standards. Moreover, the complexity of
the IoT networks makes it difﬁcult to investigate past cyber
incidents. The defense solutions are also constrained by limited
computational resources on IoT devices.

Cyber insurance becomes a new way to mitigate the risks
from APTs to complement technological solutions and plays
an important role when the technologies are imperfect [19]–
[21]. An illustration of cyber insurance for IoT is provided in
Fig. 1. A defender ﬁrst pays a premium to an insurer on his
IoT devices, and when the devices are compromised by APTs,
the insurer provides a ﬁnancial coverage on various types of
losses, such as data breaches, physical damages, and service
shutdown. The coverage and the ﬁnancial protection against
losses may prevent defenders from business discontinuities and
provide them un-deprived resources to take actions to recover
and defend themselves.

Traditional insurance frameworks are not completely sufﬁ-
cient to address challenges of cyber insurance as the risks from
APTs are caused by malicious attackers rather than accidents

 
 
 
 
 
 
2

[10], [11]. The design of effective cyber insurance contracts
should take into account the attacker’s behaviors and their
impacts on the IoT systems. Moreover, the impact of APTs
can propagate over IoT devices through network connections,
and thus the insurers may bear extra risks if they fail to take
into account the risk that arises from the interdependencies
among IoT devices [12]–[14].

In this paper, we propose a bi-level game-theoretic frame-
work called FlipIn to study the interactions among APT
attackers, IoT defenders, and cyber insurance insurers over
a network of IoT devices. In this framework, attackers and
defenders compete over the ownership of IoT devices. The
attackers aim to control longer periods so that they can conduct
various malicious activities which inﬂict huge losses on the
defenders. The defenders aim to reduce their losses by either
controlling longer periods or purchasing cyber-insurance from
insurers. With an objective of maximizing the revenue, the
insurers charge premiums to the defenders and provide ﬁnancial
coverage to them when they face cyberattack-induced losses.
As the impact of the attackers can propagate to other devices
through network connections, there is a need to quantify the
systemic risk of the whole network. To this end, we adopt linear
inﬂuence models to capture the impact of one node on the
others [22]–[24]. We further consider two scenarios of cyber
insurance. The ﬁrst one is a distributed scenario where each
defender owns an IoT device in a network while the second
one is its centralized counterpart where a centralized agent
owns the network of nodes and plans the network defense. In
both scenarios, there exists an attacker at each IoT device to
compete with the defender over its ownership.

FlipIt game has been broadly used to model the inter-
actions between one APT attacker and one defender [25]–
[28]. We capture the adversarial interactions over networks
by constructing local FlipIt games at each node in the
distributed scenario and developing a global FlipIt game
over a network in the centralized scenario. In the distributed
the local FlipIt games are composed into a
scenario,
network FlipIt game among multiple defenders and multiple
attackers, which can be viewed as a bottom-up approach. In
the centralized scenario, the proposed global FlipIt game
can be decomposed into local FlipIt games at each node,
which can be viewed as a top-down approach.

Our FlipIn framework captures several unique features of
IoT networks. Our framework does not require the networks to
be homogeneous or fully connected. It captures IoT networks
that are featured by various types of software, protocol, and
hardware. Attackers or defenders may have different costs to
attack or defend different IoT devices with unique physical
components, respectively. In our framework, we capture those
differences by the cost functions or parameters for the players
to claim or reclaim the ownership of the IoT devices. Moreover,
the failures of the IoT devices with sensitive information or
crucial missions inﬂict huge losses to defenders while the
failures of other devices may inﬂict less signiﬁcant losses.
Thus, defenders could encounter different losses on different
devices, which is captured by the different loss parameters
of defenders in our framework. Furthermore, IoT devices are
often managed by different entities, and such decentralized

ownership of IoT devices is investigated in the distributed
scenario.

Each defender interacts with an insurer, which is modeled
by a class of moral-hazard type of principal-agent problems
with incomplete information. The insurer acts as a principal
and announces the insurance contract to the defender, while
the defender acts as an agent and makes rational decisions. The
incomplete information comes from the fact that the insurer
cannot directly observe the interactions among defenders and
attackers but can indirectly measure the defenders’ losses as a
consequence of their actions as well as the attackers’ actions.
The principal-agent problem and the network-based FlipIt
games constitute a bi-level game among three parties, and
the equilibrium solution to this composed game enables us
to design effective cyber insurance contracts and mitigate
ﬁnancial impacts on the IoT networks and their operations.
We fully analyze the insurability of defenders by taking into
account the individual rationalities for both defenders and
insurers. We completely solve the insurance contract design
problems in the distributed scenario and the semi-homogeneous
centralized scenario. The optimal insurance contracts in both
cases cover half of the defenders’ losses when they are insurable.
With numerical experiments, we show that network effects
can damage the security of IoT networks and decrease the
insurability of defenders. Our numerical experiments further
indicate that nodes with more neighbors and networks with
lower connectivities are less insurable.

Our framework offers several insights on the best practices
for IoT defenders on cyber risk management. Firstly, when
the network inﬂuences are weak, defenders can successfully
mitigate their risks through cyber insurance; when the network
inﬂuences become stronger, defenders need to focus on
deploying local protections instead of adopting cyber insurance.
Secondly, the defenders who manage highly connected devices
or sparsely connected networks do not beneﬁt from cyber in-
surance. Thirdly, for weakly connected networks, decentralized
management outperforms its centralized counterpart and each
node is recommended to defend on its own while for strongly
connected networks, centralized management outperforms its
decentralized counterpart and a global defender is preferred to
be in charge of all devices.

A. Organization of the Paper

The rest of this paper is organized as follows. In Section
II, we discuss the related works. Section III formulates the
problems and outlines the bi-level games for both distributed
and centralized scenarios. Section IV provides an overview of
ﬁnding the equilibrium. Section V and Section VI analyze the
insurance contract design problems for two scenarios. Section
VII presents numerical experiments and Section VIII provides
concluding remarks. A summary of notations has been provided
in the following table.

II. RELATED WORKS
Cyber insurance has been devised to mitigate cyber-risks
by covering some of the losses caused by cyber-attacks [19]–
[21]. Various frameworks have been proposed to study cyber-
insurance from different perspectives. For example, Pal et

d, a
D, C
N , n
pd,n, pa,n
αn
Rn, Xn, βn
wmn, w∗
mn
η
γa,n, ca,n
γd,n, cd,n
sn, s
Tn, T

Summary of Notations

Defender, Attacker
Distributed Scenario, Centralized Scenario
Set of Nodes, Node n ∈ N
Defending Strategy/Frequency, Attacking Strategy/Frequency
Expected Proportion of the Attacker’s Controlling Time
Defender’s Risk, Direct Loss, Effective Loss
Network Inﬂuence
Discount Ratio of the Network Inﬂuence
Attacker’s Utility Parameter, Cost Parameter
Defender’s Loss Parameter, Cost Parameter
Insurance Coverage level
Insurance Premium

al., have proposed a supply-demand model and showed that
cyber insurance with client contract discrimination can improve
network security [29]; Khalili et al., have investigated the inter-
dependent nature of cyber security and proposed a pre-screening
method which is able to create proﬁt opportunities for insurers
[30]–[32]; B¨ohme et al., have proposed several market models
to study the information asymmetries between defenders and
insurers as well as the interdependent security and correlated
risks among defenders [20]; Vakilinia et al., have proposed a
coalitional insurance framework where organizations insure a
common platform instead of themselves under the consideration
of their security interdependency [33]. However, most of the
current frameworks have not considered that the risks of cyber-
attacks come from stealthy attackers with speciﬁc objectives
and malicious activities, which is different from traditional
insurance of mitigating risks from accidents.

Game theory has been applied extensively to capture various
types of cyber-attacks [34]–[36]. For example, zero-sum games
have been used to capture Jamming attacks and DoS/DDoS
cyber-attacks [37], [38]; Stackelberg games have been applied
to study moving target defense, honeypots, and correlated at-
tacks [39]–[41]; Signaling games have been used to investigate
deception and data integrity attacks [42], [43]; other applicable
games have also been introduced to model different cyber-
attack scenarios [44], [45]. Game theory provides a theoretical
analysis of cyber-attacks and offers valuable insights for cyber
security administrators and managers to design detection and
defense methods against them.

APTs are severe threats to cyber security with the stealthiness
and persistence nature [10]–[14]. Various papers have proposed
different game-theoretic frameworks to investigate APTs and
their impacts in different applications. In [46], Huang et al.,
have used a multi-stage Bayesian game to capture ATPs on
cyber-physical systems; in [47], Hu et al., have characterized
the interplay among defenders, APT attackers, and insiders
with a two-layer differential game; in [48], Xiao et al., have
applied prospect theory to investigate APTs on cloud storage
systems; in [49], Min et al. have captured the interactions
between an APT attacker and a defender in a cloud storage
system by a Colonel Blotto game; in [50], Rass et al., have
proposed a sequential game-theoretic framework to design
defense strategies against APTs.

The security aspect of IoT devices and their vulnerabilities to
cyber-attacks have been reviewed and summarized by a lot of
recent studies [3]–[7]. Several game-theoretic frameworks have
been proposed to investigate cyber-attacks towards IoT systems

3

[51]–[53]. For example, Hamdi et al., have devised a game-
theoretic model to study the adaptive security of eHealth IoT
systems [54]; Pouryazdan et al., have proposed a game-theoretic
framework for trustworthy cloud-centric IoT applications [55];
Namvar et al., have modeled the interaction between an IoT
access point and a jammer with a Colonel Blotto game and
proposed a centralized mechanism to address the jamming
problem in the IoT systems composed of resource-constrained
devices [56].

IoT systems could be extremely vulnerable to APTs because
of complex types of devices and network connections, lack of
detection and defense methods, and restricted computational
resources [5], [12], [13], [17], [18]. Game theory becomes
a valuable tool to study APTs in IoT systems and design
defense mechanisms against them. For example, in [14], Hu
et al., have proposed an expert system based APT detection
game and showed its effectiveness to increase the security
level of IoT systems; in [57], Lee et al., have proposed a
game-theoretic vulnerability quantiﬁcation method for social
IoT systems against cyber-attacks including APTs.

In this paper, we adopt FlipIt games to model APTs
on IoT systems [25]. The FlipIt games have been used
extensively to study APTs and investigate their impacts in
various applications. In [26], Bowers et al., have demonstrated
the application of FlipIt games to password reset policies,
key rotation, VM refresh, and cloud auditing; in [27], Pawlick
et al., have used FlipIt game to model the competition
between a defender and an attacker over the ownership of a
cloud server; in [58], Spyridopoulos et al., have proposed a
variant of FlipIt game to study malware proliferation. These
works have focused on the competition between one attacker
and one defender over one resource.

FlipThem games have been proposed to extend the
FlipIt games and study the interactions between one
defender and on attacker over multiple resources [59]–[62].
In [59], Laszka et al., have proposed an AND control model
where an attacker takes control of all resources to compromise
the system and an OR model where an attacker only needs to
take control of one resource to achieve that; in [60], Zhang
et al., have considered a situation where a defender and an
attacker have strict constraints on their actions across all the
resources; in [61] and [62], Leslie et al., have investigated a
scenario where an attacker compromises a defender’s resources
with a threshold. However, they have not considered situations
where multiple defenders and attackers interact in the same
network of resources. Moreover, they have not captured the
risk-dependencies between neighboring resources.

Inﬂuence networks have been used to capture the interdepen-
dencies among neighboring nodes in cyber risk management
[24]. For example, in [22], Miura-Ko et al., have adopted inﬂu-
ence networks to model interdependent security investments; in
[23], Nguyen et al., have presented an inﬂuence network model
to study the vulnerability correlations of security assets. In this
paper, we combine FlipIt games and inﬂuence networks and
devise two scenarios of networked FlipIt games to capture
the interactions between IoT defenders and APT attackers.

We further capture the interactions between defenders and
cyber insurance insurers by a moral-hazard type of principal-

agent problem with incomplete information. Moral hazard has
been discussed extensively in traditional insurance paradigm
[63], [64], and it has also been considered in cyber insurance
[65], [66]. Principal-agent problems have also been applied to
analyze cyber insurance [67], [68]. The principal-agent problem
and the nested FlipIt games constitute a bi-level game [69],
[70]. The game-of-games structure in bi-level games has been
presented in various recent studies on cyber security [45], [71].
Compared with the bi-level game-theoretic cyber insurance
framework proposed in [72], our framework captures the
interactions between defenders and attackers with FlipIt
games instead of zero-sum games to model APTs on IoT
systems. One of our main contributions is that we extend
the FlipIt game between one defender and one attacker
to a network of FlipIt games by incorporating inﬂuence
networks. We further consider both distributed and centralized
scenarios of IoT defenders and analyze their interactions
with both APT attackers and insurers. Our numerical experi-
ments investigate the impacts of homogeneous/heterogeneous
networks, homogeneous/heterogeneous players, and network
connectivities to the security management of IoT defenders and
the insurance contract designation of insurers, which have not
been addressed in [72]. The analysis offers several insights on
the best practices for IoT defenders on cyber risk management
and cyber insurance. Our framework further indicates that
the optimal insurance coverage level is 1/2 in the distributed
scenario and the semi-homogeneous scenario and we show
that an insurer can make a nonzero proﬁt by providing cyber
insurance.

III. PROBLEM FORMULATION

APTs are different from traditional cyber-attacks with the
stealthiness and persistence nature. APT attackers have very
speciﬁc objectives and compromise a system stealthily and
slowly to maintain a small footprint and reduce detection
risks. APTs, in general, could persist for long periods of
time in a system. Moreover, APT attackers may prefer to stay
anonymously and steal sensitive data or information instead of
completely destroying services or physical components, which
could inﬂict different types of ﬁnancial and nonﬁnancial losses
on defenders.

We use FlipIt game to capture the competition between
a defender and an APT attacker over the ownership of an IoT
device [25]. In this game, a player takes control of the IoT
device by moving with a cost and he only ﬁnds out about the
state of the IoT device when he moves. This stealthy aspect
of the game makes it suitable to capture APTs. The attacker
has a speciﬁc objective to maximize his expected controlling
time over the device. The attacker’s malicious activities during
the time that he controls the device could inﬂict various types
of losses on the defender. The objective of the defender is to
minimize his total expected losses caused the attacker.

An illustration of the FlipIt game is provided in Fig. 2:
the game starts at time 0 and the defender owns the device;
at time 1, the attacker attacks the device and then claims the
ownership of it; at time 6, the defender defends the device
and reclaims the ownership of it; the game continues and the

4

Fig. 2. The FlipIt game on Node n between a defender and an attacker.

ownership of the device switches between the defender and
the attacker. Note that when the defender defends and the
attacker attacks at the same time, e.g., time 4, we follow the
tie-breaking rule from [25] that their actions are “canceled”
and the ownership of the device does not change. Such a tie-
breaking rule considers that the current owner of the device has
the advantage to win the competition against the other player
with prior knowledge or both players prefer not to move at
the same time to avoid revealing themselves. This tie-breaking
rule makes the game fully symmetric and allows us to handle
ties smoothly.

Consider an IoT network modeled by a directed graph
G (N , E ) with N := {1, ..., N} and E denoting the set of
nodes and the set of edges, respectively. Each node n ∈ N
represents an IoT device which is controlled in turn by a
defender and an APT attacker. Let us denote the sequence of
the defender’s defending time or the attacker’s attacking time
at node n as an inﬁnite non-decreasing sequence which can be
speciﬁed as follows:

Defender: td,n,1,td,n,2, ...,td,n,k−1,td,n,k,td,n,k+1, ...

Attacker: ta,n,1,ta,n,2, ...,ta,n,k−1,ta,n,k,ta,n,k+1, ...

(1)

(2)

Let φd,n(td,n,k) or φa,n(ta,n,k) denote the feedback that the
defender or the attacker at node n receives when he defends or
attacks at td,n,k or ta,n,k, where φd,n ∈ Φd,n or φa,n ∈ Φa,n with
Φd,n or Φa,n denoting the set of all the possible forms of the
feedback of the defender or the attacker, respectively. Some of
the possible forms are listed here as examples [25].

• (Non-adaptive) a player obtains no information,

i.e.,

φd,n(td,n,k) = 0 or φa,n(ta,n,k) = 0;

• (Full

• (Last move) a player obtains the opponent’s last move time,
i.e., φd,n(td,n,k) = max{ta,n,k(cid:48)|ta,n,k(cid:48) ≤ td,n,k} or φa,n(ta,n,k) =
max{td,n,k(cid:48)|td,n,k(cid:48) ≤ ta,n,k};
history)
of

full
i.e.,
(cid:0)(td,n,1, ...,td,n,k), (ta,n,1, ...,ta,n,k(cid:48))(cid:1)
φa,n(ta,n,k) = (cid:0)(td,n,1, ...,td,n,k(cid:48)), (ta,n,1, ...,ta,n,k)(cid:1)
ta,n,k(cid:48) = max{ta,n,k(cid:48)|ta,n,k(cid:48) ≤ td,n,k}
or

history
φd,n(td,n,k)
or
where
td,n,k(cid:48) = max{td,n,k(cid:48)|td,n,k(cid:48) ≤ ta,n,k}.

the
moves,

a
both

players’

obtains

player

=

A player decides the time of his next move following a strategy
based on his current time of move and the received feedback.
Let pd,n : R≥0 × Φd,n → R≥0 and pa,n : R≥0 × Φa,n → R≥0
denote the defending strategy and the attacking strategy for
the defender and the attacker at node n, respectively, we have
• when the defender defends at time td,n,k and receives
feedback φd,n(td,n,k), his next defend will be at td,n,k+1 =
pd,n(td,n,k, φd,n(td,n,k));

• when the attacker attacks at

time ta,n,k and receives
feedback φa,n(ta,n,k), his next attack will be at ta,n,k+1 =
pa,n(ta,n,k, φa,n(ta,n,k)).

Let αn ∈ [0, 1] denote the expected proportion of the time
that the attacker controls node n when the defender adopts
a strategy of pd,n and the attacker adopts a strategy of pa,n.
While controlling the IoT devices, the attackers can beneﬁt
from conducting malicious activities, such as monitoring
sensitive operations, stealing private information, and injecting
ransomware. The objective of the attacker is to maximize the
expected proportion of the time that he controls the device,
which can be captured by the following optimization problem:

max
pa,n∈Sa,n

γa,nαn − ca,n(pa,n),

(3)

where γa,n ∈ R≥0 denotes the utility parameter of the attacker
and Sa,n = {pa,n} denotes the set of all possible strategies by
the attacker. Function ca,n : Sa,n → R≥0 captures the cost of
the attacker when he adopts a strategy of pa,n. Different γa,n
and ca,n capture the trade-offs between a larger proportion of
controlling time and a smaller cost of the attacker.

The attackers’ activities can inﬂict huge ﬁnancial and
nonﬁnancial losses on defenders. A defender at one node
may also face losses caused by the attackers at neighboring
nodes, for example, the attackers can denial the services, send
misleading information, or spread computer viruses to this node.
Moreover, the impacts of attackers could propagate through
network connections, such as computer worms and viruses, and
thus, the defender may even face losses caused by undirectly
connected nodes.

To measure the losses of defenders with respect to the
attackers’ controlling times, we ﬁrst deﬁne the defender’s risk
level at node n as

Rn = gn(α1, α2, ..., αN),
where gn : ([0, 1])N → R≥0 is a function of all the expected
proportions of attackers’ controlling times in this network.
We further assume that the defender’s loss Xn follows an
1
exponential distribution of
with its density function
γd,nRn
expressed as

(4)

f (xn|γd,nRn) = 1

γd,nRn

exp

(cid:16)

− 1

γd,nRn

(cid:17)

x

, ∀xn ∈ R≥0.

(5)

The parameter γd,n ∈ R>0 controls the level of the defender’s
losses, and a crucial IoT devices may have a larger γd,n. For
example, an IoT device which monitors or controls nuclear
reactors has a larger γd,n than an IoT device which records
the room temperature in a supermarket. The exponential
distribution has been widely applied to risk and insurance
analysis [73]–[75]. We can see from the exponential distribution
that the defender has a larger probability of facing a larger
loss when he has a higher risk level. Furthermore, the expected
loss satisﬁes that E(Xn) = γd,nRn, and the defender has a larger
expected loss with the increase of his risk level. An illustration
of the relations between pa,n, pd,n, αn, Rn, and Xn can be found
in Fig. 3.

Remark 1. When node n has no network connections to any
other nodes or there is only one node n in this network, we

5

Fig. 3.

Interactions among players at node n in Defender-D.

could assume that Rn = g(α1, α2, ..., αN) = αn, which indicates
that the defender at node n has a higher risk level or faces
a larger expected loss if the attacker at node n has a larger
expected proportion of controlling time.

The defenders can also purchase cyber-insurance to cover
their losses. After paying a premium to the insurer, a defender
receives a coverage from the insurer when he faces losses
caused by attackers. In this paper, we consider two different
scenarios of defenders, which are discussed separately in the
following subsections. In summary, Defender-D represents a
“distributed” case where each defender at each node only consid-
ers his own losses, while Defender-C indicates a “centralized”
case where a global defender considers the overall loss of this
IoT network. We present two examples to illustrate applications
of Defender-D and Defender-C.

Example 1 (Centralized Scenario). Consider a smart home
which contains IoT devices, such as laptops, wireless routers,
smart speakers, cameras, and sweeping robots. An APT
attacker could compromise a smart speaker and record private
conversions over days or months. The smart home owner could
hardly notice the existence of the attacker as the smart speaker
functions normally. The attacker could further leak the recorded
conversions to the public or blackmail the owner. Similarly,
APT attackers could record private videos from cameras or
steal sensitive documents from laptops. The smart home owner
could choose to insure his IoT devices with cyber insurance
and the insurer would provide ﬁnancial coverage to his losses
from the leakage of private information by APT attackers. It
is natural for the smart home owner to insure all the devices
together, which indicates a centralized scenario.

Example 2 (Distributed Scenario). In vehicular applications
and inter-networking technologies (VANET), a vehicle dynami-
cally adjusts its route to destinations by communicating with
different IoT devices, such as other vehicles, smart trafﬁc
lights, and phones owned by pedestrians. An APT attacker
could compromise the vehicle and hijack the data sent and
received by it. Different from traditional cyber-attacks, APTs
aim not to immediately damage the vehicle as it can be detected
by the security systems. With small modiﬁcations on the data
over a long period of time, the vehicle may arrive at the
desired destination by the attacker [76]–[78]. Moreover, an
APT attacker could even affect the route of a target vehicle
by sending misleading data from other vehicles and trafﬁc
lights. Cyber insurance could provide ﬁnancial coverage to the
passengers for their losses from arriving at a wrong destination.

In this case, the security status of the vehicle is also affected
by other IoT devices in this network.

A. Defender-D

In this case, there exist N defenders in this IoT network and
each IoT device is occupied by a defender. An illustration of
the interactions between an attacker, a defender, and an insurer
in one node is provided in Fig. 3. Note that each attacker
has no information about the players in other nodes and his
objective is to maximize his expected proportion of controlling
time αn as in (3). Each defender has no information about the
actions of the players in other nodes, however, he may face
losses caused by the attackers from other nodes.

After paying a premium to the insurer, the defender at node
n is entitled to receive a coverage snXn from the insurer when
he faces a loss of Xn, where sn ∈ (0, 1] denotes the coverage
level of the insurance. The defender now has an effective loss
of βn = Xn − snXn = (1 − sn)Xn. Note that sn = 0 indicates that
there is no insurance and the defender’s effective loss βn equals
to his direct loss Xn. As a result, the expected effective loss of
the defender can be described as

E[βn] = E[(1 − sn)Xn] = (1 − sn)γd,nRn.

(6)

The objective of each defender is to minimize his expected
effective loss, which can be captured by the following opti-
mization problem after plugging (4) into (6):

min
pd,n∈Sd,n

(1 − sn)γd,ngn(α1, ..., αN) + cd,n(pd,n),

(7)

where Sd,n = {pd,n} denotes the set of all possible strategies
by the defender. Function cd,n : Sd,n → R≥0 captures the cost
of the defender under the strategy pd,n. The parameter γd,n and
function cd,n capture the trade-offs between a smaller expected
effective loss and a higher cost.

By comparing (3) and (7), we can see that the attacker aims
to maximize the expected proportion of his controlling time
while the defender aims to minimize it. The conﬂicting interest
between the defender and the attacker constitutes a FlipIt-D
game in each IoT device, and its Nash equilibrium is deﬁned
as follows.
Deﬁnition 1. Let Sa,n and Sd,n denote the strategy sets
for the attacker and the defender at node n, respec-
tively; let Ja,n(pa,n, pd,n) and Jd,n(pd,n, pa,n; sn, {αm}m(cid:54)=n) de-
note the objective functions from (3) and (7), respec-
tively. A strategy proﬁle {p∗
d,n} is a Nash equilib-
the FlipIt-D game at node n deﬁned by
rium of
(cid:104){Attacker, Defender-D}, {Sa,n, Sd,n}, {Ja,n, Jd,n}(cid:105) if
d,n) ≥ Ja,n(pa,n, p∗

d,n), ∀pa,n ∈ Sa,n;

a,n, p∗

a,n, p∗

Ja,n(p∗
d,n, p∗

Jd,n(p∗

a,n; sn, {αm}m(cid:54)=n)

a,n; sn, {αm}m(cid:54)=n), ∀pd,n ∈ Sd,n.
≤ Jd,n(pd,n, p∗
a,n}, {p∗
Furthermore, a strategy proﬁle {{p∗
d,n}} is a global
the G-FlipIt-D game deﬁned by
Nash equilibrium of
(cid:104){Attackers, Defender-Ds}, {{Sa,n}, {Sd,n}}, {{Ja,n}, {Jd,n}}(cid:105)
if

Ja,n(p∗

a,n, p∗

d,n) ≥ Ja,n(pa,n, p∗

d,n), ∀pa,n ∈ Sa,n, n ∈ N ;

6

Fig. 4. The structure of the games in Defender-D. There are N defenders in
this case. The FlipIt-D game is played between a defender and an attacker
on one IoT device while the G-FlipIt-D game captures the interactions
among all defenders and all attackers over the IoT network. The FlipIn-D
game captures the interactions between a defender, an attacker and the insurer
while the G-FlipIn-D game describes the interactions between all defenders,
all attackers, and the insurer.

Jd,n(p∗

a,n; sn, {α ∗

d,n, p∗
≤ Jd,n(pd,n, p∗

m}m(cid:54)=n)
a,n; sn, {α ∗

m}m(cid:54)=n), ∀pd,n ∈ Sd,n, n ∈ N ,

where α ∗
m denotes the expected proportion of the time that the
attacker controls node m when the defender adopts a strategy
of p∗

d,m and the attacker adopts a strategy of p∗
An illustration of

a,m.
the FlipIt-D game

and the
G-FlipIt-D game is provided in Fig. 4. The Nash equi-
librium of the FlipIt-D game is affected by the strategies
of other players in the network, and it also affects the results
of other FlipIt-D games. The complex interactions among
all attackers and defenders constitute a G-FlipIt-D game,
whose Nash equilibrium is achieved when all the FlipIt-D
games in each node reach their Nash equilibriums. Note that
the Nash equilibrium of the FlipIt-D game is affected by
the coverage level sn through Jd,n, and the Nash equilibrium
of the G-FlipIt-D game is affected by the coverage levels
{sn} of all nodes.

The defender at node n has to pay a premium Tn ∈ R≥0 to
receive a coverage of his losses. A rational defender purchases
cyber insurance only when his total loss including the premium
under the insurance is lower than his total loss without the
insurance, which can be expressed as the following individual
rationality constraint for the defender:

(1 − sn)γd,ngn (α1, ..., α ∗

n (sn), ..., αN) + cd,n
n (0), ..., α (cid:48)

N) + cd,n

1, ..., α ∗

(cid:16)

(cid:17)
p∗
+ Tn
d,n(sn)
(cid:17)
(cid:16)
p∗
d,n(0)

.

≤ γd,ngn (α (cid:48)

(8)
Note that we have abused the notation with the purpose
of simplifying illustration: α ∗
n (0) denote the
equilibrium expected proportions of the attacker’s controlling
time at node n with the insurance of coverage level sn and
without the insurance, respectively; p∗
d,n(0) denote
the equilibrium defending strategies of the defender at node

n (sn) and α ∗

d,n(sn) and p∗

7

n with the insurance of coverage level sn and without the
insurance, respectively. Specially, αm and α (cid:48)
m represent the
expected proportions at node m (cid:54)= n given the coverage level
sn and sn = 0 at node n, respectively.

The insurer receives a premium Tn from the defender and
provides coverage snγd,ngn (α1, ..., α ∗
n (sn), ..., αN) to him. Thus,
the insurer has a proﬁt of Tn − snγd,ngn (α1, ..., α ∗
n (sn), ..., αN).
The insurer insures the defender only when he can make a
proﬁt, which can be expressed as the following individual
rationality constraint for the insurer:

Tn − snγd,ngn (α1, ..., α ∗

n (sn), ..., αN) ≥ 0.

(9)

Fig. 5.

Interactions among players in the IoT network in Defender-C.

The objective of the insurer is to make a larger proﬁt from
providing the insurance, which can be captured as the following
optimization problem:

whose Nash equilibrium is achieved when all the FlipIn-D
games reach their Nash equilibriums.

max
{sn,Tn}
s.t.

Tn − snγd,ngn (α1, ..., α ∗

n (sn), ..., αN)

(8), (9).

B. Defender-C

(10)

We can see that the solution of (10) depends on both the
outcome of the FlipIt-D game at node n and the expected
proportions of the attackers’ controlling times at other nodes.
An effective insurance contract must satisfy both (8) and (9).
The interactions between the defender and the insurer constitute
a moral-hazard type of principal-agent problem where the
insurer as a principal announces the insurance contract and the
defender as an agent makes rational decisions on purchasing
the insurance. Note that the insurer has incomplete information
about the defender as he decides the insurance contract based
on the outcome of the FlipIt-D game.

In this case, there exists only one global defender in this
IoT network. The interactions between the defender, attackers,
and an insurer are illustrated in Fig. 5. Similar to the case of
Defender-D, each attacker has no information about the players
in other nodes. The insurer offers one insurance contract {s, T }
to the defender which covers the losses of all the IoT devices.
The defender’s expected effective loss β in this case can be
expressed as
(cid:18)

(cid:19)

E(β ) = E

(1 − s)

Xn

= (1 − s)

N
∑
n=1

γd,ngn (α1, ..., αN) .

(11)

N
∑
n=1

The complex interactions between an attacker, a defender,
and an insurer constitute a bi-level FlipIn-D game whose
Nash equilibrium is deﬁned as follows.

The defender aims to minimize his overall expected effective
losses, which can be captured by the following optimization
problem:

for

the

n, T ∗

denote

Jd,n,
a,n, p∗

the action set

the
function

objective
Ja,n
n, T ∗
d,n, {s∗

2. Let Si,n = {{sn, Tn}|sn ∈ (0, 1], Tn ∈
insurer;
from
from Deﬁnition
n }} is a Nash
the bi-level FlipIn-D game deﬁned
(cid:10){Attacker, Defender-D, Insurer}, {Sa,n, Sd,n, Si,n},
n } solves (10) and {p∗
d,n} is
the FlipIt-D game deﬁned in

Deﬁnition
R≥0, (8), (9)} denote
let
Ji,n(sn, Tn)
(10). Recall Sd,n, Sa,n,
1, a strategy proﬁle {p∗
equilibrium of
by
{Ja,n, Jd,n, Ji,n}(cid:11) if {s∗
a Nash equilibrium of
n, T ∗
Deﬁnition 1 under {s∗

n }.
proﬁle
a
{{p∗
n}, {T ∗
n }}} is a global Nash equilibrium
G-FlipIn-D
of
by
game
(cid:10){Attackers, Defender-Ds, Insurer}{{Sa,n}, {Sd,n}, {Si,n}},
{{Ja,n}, {Jd,n}, {Ji,n}}(cid:11) if {s∗
for all
n ∈ N and {{p∗
d,n}} is a Nash equilibrium of
the G-FlipIt-D game deﬁned in Deﬁnition 1 under
{{s∗

Furthermore,
a,n}, {p∗
the

d,n}, {{s∗
bi-level

n } solves

a,n}, {p∗

strategy

a,n, p∗

deﬁned

n, T ∗

(10)

the FlipIn-D game

and the
G-FlipIn-D game has been provided in Fig. 4. The Nash
equilibrium of the FlipIn-D game is affected by the other
FlipIn-D games through αm in (10). The complex inter-
actions among all players constitute a G-FlipIn-D game,

n }}.

n}, {T ∗
An illustration of

(1 − s)

min
{pd,n}

N
∑
n=1

γd,ngn (α1, ..., αN) +

N
∑
n=1

cd,n

(cid:0)pd,n

(cid:1) .

(12)

The interactions between the defender and N attackers in
this IoT network constitute a global FlipIt-C game, which
is deﬁned as follows.
Deﬁnition 3. Let Sa,n and Sd denote the strategy sets for
the attacker and the defender, respectively; let Ja,n(pa,n, pd,n)
and Jd({pd,n}, {pa,n}; s) denote the objective functions from
(3) and (12), respectively. A strategy pair {{p∗
d,n}}
is a Nash equilibrium of the FlipIt-C game deﬁned by
(cid:104){Attackers, Defender-C}, {{Sa,n}, Sd}, {{Ja,n}, Jd}(cid:105)) if
d,n), ∀pa,n ∈ Sa,n, n ∈ N ;

a,n}, {p∗

Ja,n(p∗

a,n, p∗
d,n}, {p∗

d,n) ≥ Ja,n(pa,n, p∗
a,n}; s) ≤ Jd({pd,n}, {p∗

Jd({p∗

a,n}; s), ∀{pd,n} ∈ Sd.

Note that the Nash equilibrium of the FlipIt-C game is
affected by the coverage level s through Jd. In the previous
subsection, we have shown that N FlipIt-D games constitute
a global G-FlipIt-D game, while in this subsection, we
show that the FlipIt-C game may be decentralized into N
local L-FlipIt-C games under certain conditions.

defender’s individual rationality constraint in this case can be
written as
N
∑
n=1

1 (s), ..., α ∗

N(s)) +

(1 − s)

cd,n

+ T

(cid:16)

N
∑
n=1
N(0)) +

(cid:17)
p∗
d,n(s)
(cid:16)

N
∑
n=1

cd,n

(cid:17)
p∗
d,n(0)

.

γd,ngn (α ∗
N
∑
n=1

≤

γd,ngn (α ∗

1 (0), ..., α ∗

(14)
The insurer’s individual rationality constraint can be written
as

T − s

gn (α ∗

1 (s), ..., α ∗

N(s)) ≥ 0.

N
∑
n=1

The insurer aims to maximize the proﬁt as follows:

max
{s,T }
s.t.

T − s

N
∑
n=1
(14), (15).

γd,ngn (α ∗

1 (s), ..., α ∗

N(s))

8

(15)

(16)

Similar to the case in the previous subsection, the interactions
between the defender and the insurer constitute a principal-
agent problem with incomplete information;
the complex
interactions between the defender, the attackers, and the insurer
constitute a bi-level FlipIn-C game whose Nash equilibrium
is deﬁned as follows.

Deﬁnition 5 (Equilibrium Concept for FlipIn-C). Let
Si = {{s, T }|s ∈ (0, 1], T ∈ R≥0, (14), (15)} denote the
action set for the insurer; let Ji(s, T ) denote the objective
function from (16). Recall Sd, Sa,n, Jd, Ja,n from Deﬁnition
3, a strategy proﬁle {{p∗
d,n}, {s∗, T ∗}} is a global
a,n}, {p∗
Nash equilibrium of the bi-level FlipIn-C game deﬁned
(cid:104){Attackers, Defender-C, Insurer}, {{Sa,n}, Sd, Si},
by
{{Ja,n}, Jd, Ji}(cid:105) if {s∗, T ∗} solves (16) and {p∗
d,n} is
the FlipIt-C game deﬁned in
a Nash equilibrium of
Deﬁnition 3 under {s∗, T ∗}.

a,n, p∗

An illustration of the FlipIn-C game has been provided
in Fig. 6. Compared with the G-FlipIn-D game,
the
FlipIn-C game contains only one principal-agent problem
and there is only one defender who competes with each
attacker on the ownership of each IoT device. Moreover,
the G-FlipIn-D game can be considered as a bottom-up
approach on a distributed scenario as the distributed games
constitute a centralized game, while the FlipIn-C game can
be considered as a top-down approach on a centralized scenario
as the centralized FlipIt-C game can be decentralized into
distributed L-FlipIt-C games.

IV. OVERVIEW OF FINDING THE EQUILIBRIUM

It is challenging to directly compute the equilibrium of the
bi-level FlipIn games in both the distributed case and the
centralized case due to the complex relations among three
networked parties of players and the various strategy choices
of defenders and attackers. In this paper, we consider that both
defenders and attackers adopt non-adaptive periodic strategies.
The periodic strategy could be viewed as a routine security
examination of the defender or programmed attacks of the
attacker. Moreover, we incorporate linear inﬂuence models
to capture the risk dependencies between neighboring nodes,

Fig. 6. The structure of the games in Defender-C. There is only one defender in
this case. The FlipIt-C game captures the interactions between a defender
and all attackers in the IoT network while the L-FlipIt-C game captures
the interactions between the defender and an attacker on one IoT device. The
FlipIn-C captures the interactions between the defender, all attackers, and
the insurer.

Remark 2 (Decentralization). If gn(α1, ..., αN) is additively
separable
i.e., gn(α1, ..., αN) =
∑N
n=1 γd,ngn (α1, ..., αN) =
∑N
Thus,
m=1 γd,mgm,n (αn).
solving the global problem (12) is equivalent to solving the
following N sub-problems at each node:

for all 1 ≤ n ≤ N,
∑N
n=1 ∑N

we
have
m=1 γd,ngn,m (αm) = ∑N

m=1 gn,m(αm),
n=1 ∑N

(1 − s)

min
pd,n

N
∑
m=1

γd,mgm,n (αn) + cd,n

(cid:0)pd,n

(cid:1) .

(13)

With Remark 2, the interactions between the attacker and the
defender at node n constitute a L-FlipIt-C game, which is
deﬁned as follows.
Deﬁnition 4. Let Sa,n and Sd,n denote the strategy
the attacker and the defender at node n,
for
sets
respectively;
let Ja,n(pa,n, pd,n) and Jd,n(pd,n, pa,n; s) de-
note the objective functions from (3) and (13), respec-
tively. A strategy proﬁle {p∗
d,n} is a Nash equilib-
the L-FlipIt-C game at node n deﬁned by
rium of
(cid:10){Attacker, Defender-C}, {Sa,n, Sd,n}, {Ja,n, Jd,n}(cid:11) if

a,n, p∗

Ja,n(p∗

a,n, p∗

d,n) ≥ Ja,n(pa,n, p∗

d,n), ∀pa,n ∈ Sa,n;

Jd,n(p∗

d,n, p∗

a,n; s) ≤ Jd,n(pd,n, p∗

a,n; s), ∀pd,n ∈ Sd,n.

An illustration of

the FlipIt-C game

and the
L-FlipIt-C games is provided in Fig. 6. We can see that
all the L-FlipIt-C games are independent of each other
as (3) and (13) do not depend on the outcomes of other
L-FlipIt-C games. However, the L-FlipIt-C game at
node n takes the parameters {γm} from other nodes into
consideration. Note that when gn(α1, ..., αN) is not additively
separable, we cannot decentralize the FlipIt-C game and
obtain the L-FlipIt-C games.

The defender pays a premium T ∈ R≥0 to insure the IoT
network and receive a coverage when he faces losses from
any devices. Following similar steps in Section III.A., the

9

captures the risks caused by neighboring nodes. The parameter
η ∈ [0, 1] denotes the discount ratio of the network inﬂuence,
and a larger η denotes a stronger inﬂuence from neighboring
nodes and indicates that the network is strongly connected;
the parameters wmn ∈ [0, 1] denote the probability that node n
is attacked by the attacker at its neighboring node m and they
satisfy

wnn = 0,

N
∑
n=1
Note that we have wnn = 0 as the inﬂuence of the attacker at
node n has been captured by αn.

wmn = 1.

(19)

With linear inﬂuence models, we could achieve the following

remark from Proposition 6 in [72].

Remark 4. Let W denote the network matrix with the m-th
row and n-th column being wmn and let IN denote an identity
matrix of size N, we have

Rn = gn(α1, α2, ..., αN) =

N
∑
m=1

w∗

nmαm,

(20)

where w∗
nm is the element at the n-th row and m-th column of
matrix W∗ = (IN − ηWT )−1 with scalar η ∈ [0, 1] being the
discount ratio of the network inﬂuence. The matrix W∗ is valid
as the inverse of IN − ηWT exists. Furthermore, w∗
nm satisﬁes
nn > 1 and w∗
(i) w∗
N
mn = 1
w∗
∑
m=1

nm ≥ 0 for all n, m ∈ N ;

1−η for all n ∈ N .

(ii)

Remark 4 indicates that the defender’s risk level at one
node is also affected by αm in other nodes. The defender’s
risk level is higher when any attacker in this network has a
larger expected proportion of controlling time, which captures
a negative impact of the network inﬂuence on cyber security.

Remark 5. From (17) and Remark 4, the defender at node n
has a higher risk level or faces a larger expected loss if

of controlling time, i.e., αn is larger;

• the attacker at node n attacks more frequently, i.e., the

attacker has a larger pa,n;

• the defender at node n defends less frequently, i.e, the

defender has a smaller pd,n;

• the attackers at other nodes have larger expected propor-
tions of controlling time, i.e., αm is larger for m (cid:54)= n.

The players’ problems in both Defender-D and Defender-C
under periodic strategies and linear inﬂuence models could
be obtained by plugging (17) and (20) into the corresponding
problems. Since solving the insurer’s problem relies on the
results of the FlipIt games, we ﬁrst solve the lower-level
FlipIt games and obtain the reactions of both defenders
and attackers to the insurance contracts. Then, we solve the
insurer’s problem and obtain optimal insurance contracts. Note
that we consider linear costs of defenders and attackers in the
following sections, and we abuse the notations of cd,n and ca,n
to denote the corresponding cost parameters. The attacker’s
problem (3) can now be written as

max
pa,n

γa,nαn − ca,n pa,n.

(21)

(17)

• the attacker at node n has a larger expected proportion

Fig. 7. The FlipIt game on Node n between a defender and an attacker
with both players adopting non-adaptive periodic strategies.

which have been used extensively to study risk propagation
over networks [22]–[24]. The periodic strategy and linear
inﬂuence model enable us to solve the lower-level security
games and further analyze the higher-level insurance problems.
The obtained results yield critical insights on network topology
and insurance contract designation, and they provide valuable
baselines for future analysis on both FlipIt games and cyber
insurance.

and pa,n = 1
τa,n

Both the defender and the attacker adopt non-adaptive
periodic strategies,
i.e., both players have ﬁxed intervals
τd,n ∈ R>0 and τa,n ∈ R>0 between two consecutive moves
as shown in Fig. 7, respectively. In the following sections, we
abuse the notations of strategies pd,n = 1
to
τd,n
denote the defending frequency and the attacking frequency,
respectively. We can compute αn, i.e., the expected proportion
of the time that the attacker controls node n by following
the arguments in Section 4.1 in [25]. When pd,n ≥ pa,n,
i.e., τd,n ≤ τa,n, the probability that the attacker moves in a
given defender’s move interval τ (cid:48)
d,n is pa,n/pd,n; moreover,
he moves exactly once within τ (cid:48)
d,n since τd,n ≤ τa,n and his
move is uniformly distributed at random within τ (cid:48)
d,n. Thus,
we obtain αn = pa,n
. Similarly, when pd,n < pa,n, we obtain
2pd,n
pd,n
αn = 1 −
2pa,n

. As a result, we have

αn =






0,
pa,n
2pd,n
1 −

,
pd,n
2pa,n

,

pa,n = 0;
pd,n ≥ pa,n > 0;
pa,n > pd,n ≥ 0.

Note that when pa,n = 0, i.e., there is no attacker or the
attacker chooses not to attack, we have αn = 0 for pd,n ≥ 0
which indicates that the IoT device is always controlled by the
defender. We can see from (17) that the attacker has a larger
αn with the increase of his frequency pu,n and the decrease
of the defender’s frequency pd,n. We could also see that αn is
continuous in both pa,n and pd,n as pa,n
2 when
2pd,n
pa,n = pd,n.

pd,n
2pa,n

= 1 −

= 1

We capture the risk dependencies between neighboring nodes
with linear inﬂuence models. We use the following remark to
illustrate linear inﬂuence models.

Remark 3 (Linear Inﬂuence Models). The defender’s risk level
at node n can be expressed as

Rn = αn + η

N
∑
m=1

wmnRm.

(18)

The ﬁrst term is the expected proportion of the attacker’s
controlling time at node n, and a higher proportion indicates a
higher risk level of the defender at this node. The second term

Different γa,n and ca,n ∈ R≥0 capture the trade-offs between a
larger proportion of time and a smaller attacking frequency of
the attacker.

We could obtain the following problem after plugging (20)

into the defender’s problem (7) in Defender-D.

10

min
pd,n

(1 − sn)γd,n

N
∑
m=1
The parameters γa,n and cd,n ∈ R≥0 capture the trade-offs
between a smaller expected effective loss and a larger defending
frequency of the defender.

nmαm + cd,n pd,n.

(22)

w∗

Remark 6 (Distributed Computations). Since αm is a constant
with respect to pd,n if m (cid:54)= n, problem (22) can be simpliﬁed
further into the following problem
(1 − sn)γd,nw∗

nnαn + cd,n pd,n.

(23)

min
pd,n

Problem (23) indicates that the defender’s decision on pd,n
in one FlipIt-D game is not affected by results of other
FlipIt-D games given the coverage level sn. However, the
expected loss of the defender E[Xn] is still affected by the
outcomes of other FlipIt-D games.

We could obtain the following problem after plugging (20)

into the defender’s problem (12) in Defender-C.

(1 − s)

min
{pd,n}

N
∑
n=1

N
∑
m=1

γd,nw∗

nmαm +

N
∑
n=1

cd,n pd,n.

(24)

Note that gn(α1, ..., αN) in (20) is additively separable for
all 1 ≤ n ≤ N, thus, the L-FlipIt-C games exist under
periodic strategy and linear inﬂuence model and problem (24)
is equivalent to the following N sub-problems from Remark 2.

(1 − s)

min
pd,n

N
∑
m=1

γd,mw∗

mnαn + cd,n pd,n.

(25)

Note that the FlipIt-D games and the L-FlipIt-C
games share similar structures: the attackers in both cases solve
the same optimization problems (21); the defenders’ problems
(23) and (25) can be written into one uniﬁed optimization
problem as

where

min
pd,n

(1 − ˜sn) ˜γd,nαn + cd,n pd,n,

˜sn =

(cid:26) sn, Defender-D;
Defender-C,

s,

˜γd,n =






nn,
γd,mw∗

γd,nw∗
N
∑
m=1

Defender-D;

mn, Defender-C.

(26)

(27)

(28)

Remark 7. Problem (26) can be interpreted that the defender
aims to minimize the expected proportion of the attacker’s
controlling time. Thus, given the same coverage level on an IoT
device, the defender in Defender-C cares more about reducing
the impacts from the attackers compared with the defenders in
Defender-D as ∑N
mn ≥ γd,nw∗
nn.
We can further deﬁne an uniﬁed local FlipIt game as

m=1 γd,mw∗

follows.

(a)

γa,n
2ca,n

≥

(1− ˜sn) ˜γd,n
2cd,n

(b)

γa,n
2ca,n

<

(1− ˜sn) ˜γd,n
2cd,n

Fig. 8. Equilibrium of the local FlipIt game at node n. p∗
a,n(pd,n) denotes
the best response of the attacker given the defender’s defending frequency pd,n
while p∗
d,n(pa,n) denotes the best response of the defender given the attacker’s
attacking frequency pa,n.

Deﬁnition 6. Let Sa,n = {pa,n|pa,n ∈ R≥0} and Sd,n =
{pd,n|pd,n ∈ R≥0} denote the action sets for the attacker and
the defender at node n, respectively; let Ja,n(pa,n, pd,n) and
Jd,n(pd,n, pa,n; ˜sn) denote the objective functions from (3) and
(26), respectively. A strategy proﬁle {p∗
d,n} is a Nash
equilibrium of the local FlipIt game at node n deﬁned by
(cid:10){Attacker, Defender}, {Sa,n, Sd,n}, {Ja,n, Jd,n}(cid:11) if
d,n) ≥ Ja,n(pa,n, p∗
a,n; ˜sn) ≤ Jd,n(pd,n, p∗

d,n), ∀pa,n ∈ Sa,n;
a,n; ˜sn), ∀pd,n ∈ Sd,n.

Jd,n(p∗

Ja,n(p∗

a,n, p∗

a,n, p∗

d,n, p∗

We can obtain the solutions of the FlipIt-D games and
the L-FlipIt-C games by plugging (27) and (28) into the
solution of the local FlipIt game deﬁned in Deﬁnition 6.
The solutions of the G-FlipIt-D game and the FlipIt-C
game can be further obtained by their Deﬁnitions 1 and 3,
respectively. Thus, we can solve all FlipIt games in both
Defender-D and Defender-C by solving the local FlipIt
game.

The local FlipIt game deﬁned in Deﬁnition 6 is different
from the original FlipIt game presented in [25] as the
defender here aims to minimize the losses caused by the attacker
while the defender in the original FlipIt game aims to
maximize the proportion of his controlling time. Following
similar steps as in [25], we can obtain the equilibrium of the
local FlipIt game deﬁned in Deﬁnition 6 by ﬁnding the
intersection of the players’ best responses as shown in Fig. 8.

Proposition 1. The Nash equilibrium of the local FlipIt
game deﬁned in Deﬁnition 6 can be summarized into two
different cases as shown in Fig. 8.
(1− ˜sn) ˜γd,n
2cd,n

, the equilibrium (FlipIt-E1) is achieved

≥

• If γa,n
2ca,n
at

p∗
d,n =

d,nca,n

(1 − ˜sn)2 ˜γ 2
2γa,nc2

d,n

, p∗

a,n =

(1 − ˜sn) ˜γd,n
2cd,n

;

(29)

• If γa,n
2ca,n
at

<

(1− ˜sn) ˜γd,n
2cd,n

, the equilibrium (FlipIt-E2) is achieved

p∗
d,n =

γa,n
2ca,n

, p∗

a,n =

γ 2
a,ncd,n
2(1 − ˜sn) ˜γd,nc2
a,n

.

(30)

Proof. The equilibrium can be obtained by ﬁnding the inter-
section between the best responses as shown in Fig. 8.

Note that p∗

d,n = 0 and p∗

a,n = 0 are also the intersection of
the best responses. However, we exclude them in this paper as
there are no defender and attacker when p∗
a,n = 0.
We can see from Proposition 1 that the equilibrium is affected
by the coverage level ˜sn, and we have the following remarks
regarding the relations between them.

d,n = 0 and p∗

Remark 8 (Equilibrium Shift). If γa,ncd,n ≥ ˜γd,nca,n, we have
(1− ˜sn) ˜γd,n
γa,n
for 0 < ˜sn ≤ 1, and thus the equilibrium is
2cd,n
2ca,n
FlipIt-E1 for 0 < ˜sn ≤ 1.

≥

If γa,ncd,n < ˜γd,nca,n, we note that

γa,n
2ca,n
, and thus the equilibrium is FlipIt-E2. However,

˜sn < 1 − γa,ncd,n
˜γd,nca,n
we have γa,n
≤ ˜sn ≤ 1, and thus
≥
2ca,n
the equilibrium is FlipIt-E1. As a result, the equilibrium shifts
from FlipIt-E2 to FlipIt-E1 as the coverage level increases.

when 1 − γa,ncd,n
˜γd,nca,n

(1− ˜sn) ˜γd,n
2cd,n

when 0 <

(1− ˜sn) ˜γd,n
2cd,n

<

Remark 9 (Risk Compensation and Peltzman Effect). At
FlipIt-E1, both the defender and the attacker reduce their
frequencies as the coverage level increases. The defender’s
reckless behavior under the insurance in this case is referred
as risk compensation [79]. The proportion of the attacker’s
controlling time α ∗
increases with the
coverage level, as a result, the defender faces a higher risk, and
such phenomena under the insurance is referred as Peltzman
effect [80].

(1− ˜sn) ˜γd,nca,n
2γa,ncd,n

n = 1 −

However, at FlipIt-E2, the defender does not change his
frequency while the attacker increases his frequency as the
coverage level increases. The proportion of the attacker’s
controlling time α ∗
increases with the coverage
level. Thus, at FlipIt-E2, there is no risk compensation, but we
can observe Peltzman effect.

γa,ncd,n
2(1− ˜sn) ˜γd,nca,n

n =

With the results of the local FlipIt game, we can solve the
insurer’s problems and obtain the optimal insurance contracts.
In the following sections, we discuss cyber insurance separately
for Defender-D and Defender-C.

V. CYBER INSURANCE: DEFENDER-D

In this section, we aim to solve the insurer’s problem (10)
in Defender-D. We can obtain the results of the FlipIt-D
game by plugging ˜sn = sn and ˜γd,n = γd,nw∗
nn into Proposition
1. Let us abuse the notations p∗
a,n(sn), and α ∗
d,n(sn), p∗
n (sn)
to denote the equilibrium results under the coverage level sn;
let K∗
d,n, p∗
a,n; sn) from Deﬁnition 6. Note that
sn = 0 indicates the results under no insurance.

d,n(sn) = Jd,n(p∗

Remark 10. The defender’s decision on pd,n is not affected
by the players’ decisions at other nodes from Remark 6 while
the attacker’s decision on pa,n is also not affected by the
players’ decisions at other nodes from (3). Thus, we have
α (cid:48)
m = αm, ∀m (cid:54)= n in (8). As a result, (8) can be rewritten as

Since the insurer aims to maximize his proﬁt, he sets highest

11

possible premium at
Tn,max = K∗

d,n(0) − K∗

d,n(sn) + snγd,n ∑
m(cid:54)=n

w∗

nmαm.

(32)

As a result, solving the insurer’s problem (10) is equivalent to
solving the following problem after plugging (32) into (10):

n (sn)

d,n(sn) − snγd,nw∗
d,n(0) − K∗
s∗
K∗
n = arg max
0<sn≤1
d,n(sn) − snγd,nw∗
nnα ∗
d,n(0) − K∗
s.t. K∗
n can be achieved by plugging s∗
and the premium T ∗
n into
(32). Since we have achieved the equilibrium results of the
FlipIt-D game in the previous section, we can directly solve
(33).

nnα ∗
n (sn) ≥ 0,

(33)

A. High-Risk Regime: γa,ncd,n ≥ γd,nw∗

nnca,n

In this case, the FlipIt-D game between the defender and
the attacker achieves FlipIt-E1 as in Remark 8. After plugging
the results of FlipIt-E1, problem (33) can be expressed as

s∗
n = arg max
0<sn≤1
d,nw∗2
γ 2
nnca,n
2γa,ncd,n

s.t.

d,nw∗2
γ 2
nnca,n
2γa,ncd,n

(1 − sn)sn

(1 − sn)sn ≥ 0.

(34)

d,nw∗2
γ 2
nnca,n
2γa,ncd,n

is constant for sn and the constraint is
Note that
satisﬁed for 0 < sn ≤ 1. Thus, we only need to ﬁnd s∗
n that
minimizes the objective function to obtain the optimal insurance
contract.
Lemma 1. If γa,ncd,n ≥ γd,nw∗
contract is

nnca,n, the optimal insurance

s∗
n =

1
2

,

T ∗
n =

γd,nw∗

nn + γd,n ∑m(cid:54)=n w∗
2

nmαm

.

(35)

The insurer’s proﬁt under this contract is

d,nw∗2
γ 2
nnca,n
8γa,ncd,n

.

Proof. We can achieve that s∗
plugging s∗
n into (32).

n = 1

2 . T ∗

n can be achieved by

In this case,

B. Low-Risk Regime: γa,ncd,n < γd,nw∗

nnca,n
the equilibrium of the FlipIt-D game
shifts from FlipIt-E2 to FlipIt-E1 as the coverage level
increases from Remark 8. When 0 < sn < 1 − γa,ncd,n
, the
nnca,n
FlipIt-D game achieves FlipIt-E2 and we have Tn,max =
K∗
nnα ∗
d,n(0) − K∗
n (sn) < 0.
Thus, the insurer does not provide any insurance contracts with
0 < sn < 1 − γa,ncd,n
nnca,n
When 1 − γa,ncd,n
nnca,n

≤ sn ≤ 1, the FlipIt game achieves
FlipIt-E1 under the insurance and FlipIt-E2 without
the
insurance, and after plugging the results of FlipIt-E1 and FlipIt-
E2 into (33), we have

n (sn) = −snγd,nw∗

d,n(sn) − snγd,nw∗

nnα ∗

γd,nw∗

γd,nw∗

γd,nw∗

.

s∗
n ∈ arg max
sn
γa,ncd,n
ca,n

s.t.

γa,ncd,n
ca,n

− γd,nw∗
nn +
d,nw∗2
γ 2
nnca,n
2γa,ncd,n

nn +

− γd,nw∗

d,nw∗2
γ 2
nnca,n
2γa,ncd,n

(1 − sn)sn ≥ 0.

(1 − sn)sn

(36)

Tn ≤ K∗

d,n(0) − K∗

d,n(sn) + snγd,n ∑
m(cid:54)=n

w∗

nmαm.

We ﬁrst obtain the following proposition regarding the insura-
bility of the defender.

(31)

12

, p∗

a,n =

γd,nw∗
nn
4cd,n

;

p∗
d,n =

nnca,n

d,nw∗2
γ 2
8γa,nc2

d,n

• if

γa,ncd,n

γd,nw∗

2 +
defender and the attacker have

nnca,n

< 1

√
2
4 , the equilibrium does not exist. The

p∗
d,n =

γa,n
2ca,n

, p∗

a,n =

γ 2
a,ncd,n
2γd,nw∗
nnc2
a,n

.

Proof. This proposition follows from combining Proposition
1, Lemma 1, Proposition 2, and Lemma 2.

We can see that when the defender is insurable, the optimal

insurance contract provides a coverage level of 1
2 .

Remark 12. The Nash equilibrium of the G-FlipIn-D game
deﬁned in Deﬁnition 2 could be obtained with Proposition 3
by combing the results of all the FlipIn-D games.

We could also obtain the Nash equilibrium of the FlipIn-D
game when there are no network connectivities by following
the similar steps in this section. In this case, all the IoT devices
are not connected with each other or there is only one IoT
device in this network.

Corollary 1. When the network is not connected, the Nash
equilibrium of the FlipIn-D game can be summarized into
the following three cases:

≥ 1, the equilibrium is achieved at s∗

n = 1

2 , T ∗

n =

• if γa,ncd,n
γd,nca,n
γd,n
2 , p∗
2 +
n = 1
s∗
• if γa,ncd,n
γd,nca,n

;

;

d,n

d,n

, p∗

, p∗

d,n =

2 , T ∗

• if 1

2 , p∗

a,n = γd,n
4cd,n

defender and the attacker have p∗

a,n = γd,n
4cd,n
< 1, the equilibrium is achieved at
− γd,n

γ 2
d,nca,n
d,n =
8γa,nc2
√
4 ≤ γa,ncd,n
2
γd,nca,n
γ 2
d,nca,n
n = γa,ncd,n
8γa,nc2
ca,n
√
2
< 1
4 , the equilibrium does not exist. The
2 +
a,ncd,n
d,n = γa,n
.
2γd,nc2
2ca,n
a,n
nm ≥ 0 from Remark 4. By com-
paring Proposition 3 and Corollary 1, we can see that the
network effect decreases the insurability as the insurable
defender could be uninsurable because of network effects
4 ≤ γa,ncd,n
when
. Moreover, the premium
γd,nca,n
of the optimal insurance contract is also higher with network
≥ 1.
connectivity when

nn > 1 and w∗

a,n = γ 2

Recall w∗

γa,ncd,n

γa,ncd,n

2 +

γd,nw∗

< 1

nnca,n

, p∗

√
2

γd,nw∗

nnca,n

VI. CYBER INSURANCE: DEFENDER-C

Proposition 2 (Insurability). The defender is not insurable, i.e.,
there exists no effective insurance contract and the equilibrium
of the FlipIn-D game does not exist, if
√
2
4

γa,ncd,n

(37)

0 <

1
2

+

<

γd,nw∗

nnca,n

.

Proof. See Appendix A.

Proposition 2 comes from the individual rationality con-
straints of both insurer and defender, and it reﬂects situations
that the insurer has no incentive to provide insurance to the
defender as he cannot make a proﬁt from it or the defender
has no incentive to accept any insurance as he has larger costs
with it. We can further achieve the following remark regarding
the condition (37).

Remark 11. The defender is not insurable if:
(i) γd,n is high, i.e., the attacker inﬂicts large losses on the

defender;

(ii) cd,n is low, i.e., the defender has a low cost to control the

device frequently;

(iii) γa,n is low, i.e., the attacker has a low beneﬁt of controlling

the device;

(iv) ca,n is high, i.e., the attacker has a high cost to control

the device frequently;

(v) w∗

nn is high, i.e., the network effect is high.

We have that the following proposition regarding the optimal

insurance contracts when the defender is insurable.
4 ≤ γa,ncd,n
γd,nw∗
nnca,n

2 +

√
2

Lemma 2. If 1
contract is

< 1, the optimal insurance

s∗
n =

1
2

,

T ∗
n =

γa,ncd,n
ca,n

−

γd,nw∗
nn
2

+

γd,n ∑m(cid:54)=n w∗

nmαm

2

.

(38)

.

The insurer’s proﬁt under this contract is γa,ncd,n
ca,n
d,nw∗2
γ 2
nnca,n
8γa,ncd,n
Proof. We can achieve that s∗
the constraint 1 − γa,ncd,n
nnca,n
plugging s∗

n = 1
≤ sn ≤ 1. T ∗

γd,nw∗

n into (32).

2 from (36), and it satisﬁes
n can be obtained by

− γd,nw∗

nn +

With Lemma 1, Proposition 2, and Lemma 2, we have
the following proposition regarding the equilibrium of the
FlipIn-D game deﬁned in Deﬁnition 2.

Proposition 3. The Nash equilibrium of the FlipIn-D game
deﬁned in Deﬁnition 2 can be summarized into the following
three cases:

• if

γa,ncd,n

γd,nw∗

nnca,n

≥ 1, the equilibrium is achieved at

s∗
n =

1
2

, T ∗

n =

p∗
d,n =

+

γd,nw∗
nn
2
d,nw∗2
γ 2
8γa,nc2

nnca,n

d,n

γd,n ∑m(cid:54)=n w∗
2
γd,nw∗
nn
4cd,n

a,n =

, p∗

nmαm(sm)

In this section, we analyze the insurer’s problem (16) for
the FlipIn-C game. Following similar steps in the previous
section, let K∗
d,n, p∗
a,n; s) from Deﬁnition 6. The
defender’s individual rationality constraint (14) indicates that:

d,n(s) = Jd,n(p∗

,

;

T ≤

N
∑
n=1

(cid:16)

d,n(0) − K∗
K∗

(cid:17)
d,n(s)

.

(39)

• if 1

2 +

s∗
n =

1
2

√
2

4 ≤ γa,ncd,n
γd,nw∗
nnca,n
γa,ncd,n
ca,n

n =

, T ∗

< 1, the equilibrium is achieved at

Thus, the highest premium that the insurer can charge is

−

γd,nw∗
nn
2

+

γd,n ∑m(cid:54)=n w∗
2

nmαm(sm)

,

Tmax =

N
∑
n=1

(cid:16)

K∗
d,n(0) − K∗

(cid:17)
d,n(s)

.

(40)

13

n (s)

≥ 0.

(a)

(b)

(c)

(d)

As a result, solving the insurer’s problem (16) is equivalent to
solving the following problem after plugging (40) into (16):
(cid:19)

(cid:18)

s∗ = arg max
0<s≤1
(cid:18)
N
∑
n=1

s.t.

N
∑
n=1
d,n(0) − K∗
K∗

d,n(s) − s

N
∑
m=1

d,n(0) − K∗
K∗

d,n(s) − s

N
∑
m=1
mnα ∗
γd,mw∗

γd,mw∗
mnα ∗
(cid:19)

n (s)

(41)
Problem (41) is a nonlinear programming problem and it is
challenging to ﬁnd the analytical solution. We can leverage
numerical methods to compute s∗ and obtain T ∗ with (40). We
a,n by plugging s∗ into Proposition 1,
can then ﬁnd p∗
and further obtain the solution of the FlipIn-C game deﬁned
in Deﬁnition 5.

d,n and p∗

A. Semi-homogeneous Case

Problem (41) can be directly solved in a semi-homogeneous
case following similar steps in the previous section. In this
semi-homogeneous case, we consider that all players in one
party are homogeneous with the same parameters, i.e., cd,n = cd,
γd,n = γd, ca,n = ca, and γa,n = γa for n ∈ N . Note that the
network can be heterogeneous, i.e., each node may have a
different number of neighbors with different wmn.

m=1 w∗

m=1 γd,mw∗

mn = γd ∑N

Recall (28), we have ˜γd,n = ∑N
mn =
γd
1−η for n ∈ N from Remark 4. Since the equilibrium of the
L-FlipIt-C game only depends on cd,n, ˜γd,n, ca,n, γa,n, and
˜sn, which are same for each node, all nodes have the same re-
n = α ∗, and
sults at the equilibrium, i.e., p∗
Jd,n(p∗
d, p∗
a; s),
the insurer’s problem can be simpliﬁed into the following
problem

a, α ∗
d (s) = Jd(p∗

a; s). Thus, let K∗

a,n; s) = Jd(p∗

d,n = p∗

a,n = p∗

d,n, p∗

d, p∗

d, p∗

s∗ = arg max
d (0) − K∗
K∗
0<s≤1
d (s) − s γd
d (0) − K∗
s.t. K∗

d (s) − s γd
1−η α ∗(s) ≥ 0.

1−η α ∗(s)

(42)

d (0)−K∗

Note that the premium T ∗ = N(K∗
d (s∗)), where N is the
number of nodes. We note that the structure of the games in this
subsection is similar to the structure of the games in Defender-
D, and we can obtain the equilibrium of the FlipIn-C game
in this semi-homogeneous case using the results from Section
V.

Corollary 2. The Nash equilibrium of the FlipIn-C game
deﬁned in Deﬁnition 2 of a semi-homogeneous case can be
summarized into the following three cases:

γ 2
d ca
8(1−η)2γac2
d

≥ 1, the equilibrium is achieved at s∗ =
, p∗

4(1−η)cd

a = γd
< 1, the equilibrium is achieved
− Nγd

2(1−η) , p∗
d =
4 ≤ (1−η)γacd
γd ca
2 , T ∗ = Ncd γa
ca

2(1−η) , p∗

γ 2
d ca
8(1−η)2γac2
d

d =

a =

, p∗

;

1

√
2

• if

• if 1

(1−η)γacd
γd ca
2 , T ∗ = Nγd
2 +
at s∗ = 1
γd
;
4(1−η)cd
• if (1−η)γacd

γd ca

< 1

2 +
defender and the attacker have p∗

√
2
4 , the equilibrium does not exist. The
a = (1−η)γ 2
a cd
d = γa
.
2γd c2
2ca
a
the equilibrium results of the semi-
homogeneous FlipIn-C game do not depend on the network
topology. We could also obtain the equilibrium results of the
FlipIn-D games of Defender-D in this semi-homogeneous

We can see that

, p∗

Fig. 9. Networks.

γd ca

as w∗

< γacd
γd w∗
nnca

case by Proposition 3. Note that (1−η)γacd
nn <
1
1−η from Remark 4, thus, the defender in Defender-C is less
insurable than the defenders in Defender-D. Moreover, both the
defender and the attacker act more frequently in Defender-C
than in Defender-D when the defenders in both Defender-D
and Defender-C are insurable. The defender defends at the
same rate in Defender-D and in Defender-C while the attacker
attacks more frequently in Defender-D than in Defender-C
when the defenders in both Defender-D and Defender-C are
not insurable.

VII. NUMERICAL ANALYSIS

In this section, we present three numerical experiments
and compare the results in Defender-D and the results in
Defender-C. In the ﬁrst and second experiments, we consider
homogeneous players and investigate the impacts of network
topology. The ﬁrst experiment compares the results of homo-
geneous networks with different levels of connectivity, while
the second experiment compares the results of nodes with
different numbers of neighbors in a heterogeneous network. In
the last experiment, we consider heterogeneous players in a
homogeneous network and compare the results of defenders
with different cost parameters.

These three experiments are inspired by real-world IoT
applications. The ﬁrst and second experiments consider homo-
geneous IoT devices, such as thermal controllers, surveillance
cameras, and unmanned aerial vehicles (UAVs). It is important
for both defenders and insurers to know how network topology
affects the security of IoT networks. The third experiment
considers heterogeneous IoT devices in a network. One example
is that a smart home may contain laptops, wireless routers,
smart speakers, cameras, and sweeping robots. Different devices
may have distinct vulnerabilities and require different protection
methods. Moreover, some devices, such as laptops and cameras,
contain sensitive information of the household, and they
may inﬂict higher losses on the defenders once they are
compromised. Thus, it is also crucial to study cyber insurance
on different devices in a network.

All the results in three experiments have been plotted with
respect to the network discount ratio η as shown in Figs. 10,
11, and 12. A larger η indicates that the network is strongly
connected and an attacker can inﬂict larger losses on the
neighboring IoT devices. We plot the losses of defenders as
Ld,n or Ld, utilities of attackers as La,n or La, and proﬁts of
insurers as Li,n or Li. Note that Ld,n in Defender-D is computed
through (7) instead of (23) as there are also losses caused by the
attackers in neighboring nodes. In all ﬁgures, T = 0 or Tn = 0
indicate that the defender is not insurable and there exists no

14

(a)

(b)

(c)

(d)

Fig. 11. Numerical results of a heterogeneous network with homogeneous IoT
devices in Fig. 9(c). The x-axis is the network discount ratio η. “D” and “C”
represent Defender-D and Defender-C, respectively. Note that nodes 1, 2, 3, and
4 have 3, 2, 2, and 1 neighbors, respectively, thus, w12 = w13 = w14 = 0.3333,
w21 = w23 = w31 = w32 = 0.5, and w41 = 1. All nodes satisfy γd,n = 1.0,
γa,n = 1.0, cd,n = 1.2, and ca,n = 0.8. Different line colors indicate results of
different nodes while different line styles indicate different variables. Note
that we plot the global results of Defender-D in Fig. 11(d) to compare with
the results of Defender-C.

than the defenders in Defender-D for both networks, which
indicates that a defender who controls the whole network is
less insurable than a defender who controls a single device.

The results of the second experiment are presented in Fig. 11.
Note that all nodes reach the same L-FlipIt-C equilibrium
in Defender-C as discussed in Section VI.A., and thus we only
need to plot the results of one node for Defender-C. We also
plot Ld = ∑n∈N Ld,n, La = ∑n∈N La,n, and Li = ∑n∈N Li,n for
Defender-D in Fig.11(d). Comparing the results of different
nodes in Defender-D, we note that node 1 has a higher premium
than nodes 2-4 and node 1 becomes uninsurable at a smaller
η from Fig. 11(a). Thus, nodes with more neighbors are less
insurable and they should be charged with higher premiums.
Moreover, the defender at node 1 has a higher loss than the
defenders at nodes 2-4, which indicates that nodes with more
neighbors are more vulnerable.

The results of the third experiment are presented in Fig.
12. Note that the defenders have different cost parameters in
different nodes, thus, we need to solve problem (41) with
numerical methods to ﬁnd the optimal insurance contracts
in Defender-C. Comparing the results of different nodes in
Defender-D, we can see that node 1 is always not insurable
and node 2 becomes uninsurable at a smaller η than nodes
3-4, which indicates that a defender who has a lower cost to
protect his or her device is less insurable. Different from the
ﬁrst and second experiments, the defender switches between
insurable statuses and uninsurable statuses with the increase of
η in Defender-C, and the coverage level is not 1
2 . We can see
that both the coverage level and the premium increase with

Fig. 10. Numerical results of homogeneous networks with homogeneous
players in Fig. 9(ab). The x-axis is the network discount ratio η. “D” and “C”
represent Defender-D and Defender-C, respectively. “(a)” and “(b)” represent
networks (a) and (b) in Fig. 9, respectively. Note that each node in (a) and
(b) has 2 and 5 neighbors, respectively. All nodes in both graphs satisfy
γd,n = 1.0, γa,n = 1.0, cd,n = 1.0, and ca,n = 0.8. Each link in (a) and (b)
satisﬁes wnm = 0.5 and 0.2, respectively. Different line styles indicate results
in different networks while different line colors indicate different variables.
Note that there are only one insurer and one defender for the case Defender-C,
and we plot Tn = T /N and Ld,n = Ld /N instead of T and Ld to compare with
the results in Defender-D.

effective insurance contract. In the ﬁrst and second experiments,
the coverage level of the optimal insurance contract is 1
2 in both
Defender-C and Defender-D when the defenders are insurable.
We have two important observations from all experiments.
We can see that the premiums in both Defender-D and Defender-
C have an upward trend with the increase of η, which
indicates that defenders are required to pay higher premiums
on strongly connected networks. However, when η is too large,
the premiums drop to 0, i.e., the defenders are not insurable.
As a result, we can conclude that the network effect decreases
the insurability of defenders. The insurers should either charge
higher premiums or provide no insurance to defenders while
the defenders should improve local protections instead of
purchasing insurance on strongly connected networks.

We can also see from all experiments that when η is
small and defenders are insurable, the defender’s total loss
in Defender-C is higher than the defenders’ global loss in
Defender-D, however, when the η is large and defenders
are not insurable, the defender’s total loss in Defender-C is
lower than the defenders’ global loss in Defender-D. This
phenomenon provides guidance for IoT defenders to decide
between centralized management or decentralized management:
for weakly connected networks, decentralized management
is better than centralized management and each defender
should monitor his or her own device; for strongly connected
networks, centralized management outperforms decentralized
management and a global defender should in charge of all
devices.

The results of the ﬁrst experiment are presented in Fig.
10. Since all players are homogeneous and all networks are
homogeneous, we only plot the results of one node for either
network. Since all players are homogeneous, we can achieve the
same results for both networks in Defender-C as discussed in
Section VI.A.; thus, we only plot the results of one network in
Defender-C. Comparing the results of network (a) and network
(b) in Defender-D, we can see that nodes in network (a) become
uninsurable at a smaller η, which indicates that networks with
lower connectivities are less insurable. Moreover, the global
defender in Defender-C becomes uninsurable at a smaller η

00.20.40.60.8101234500.20.40.60.8100.10.20.30.40.50.60.70.800.20.40.60.8100.511.522.5300.20.40.60.8100.10.20.30.40.50.60.700.20.40.60.81-1012345600.20.40.60.810510152015

optimal contract design under the time-varying cyber risks with
imperfect measurements.

APPENDIX A PROOF OF PROPOSITION 2

From the constraint in (36), we have

d,nw∗2
γ 2
nnca,n
2γa,ncd,n
(cid:1)2

− γd,nw∗
(cid:1)2

nn +
≤ 2 (cid:0)δn − 1

(1 − sn)sn ≥ 0
− 1
4 ,

γa,ncd,n
ca,n
⇔ (cid:0)sn − 1
2
where δn = γa,ncd,n
nnca,n
representations in this proof. Note that γa,ncd,n < γd,nw∗
indicates δn < 1 and 1 − γa,ncd,n
γd,nw∗
nnca,n
sn ≤ 1.

has been introduced to simplify the
nnca,n
≤ sn ≤ 1 indicates 1 − δn ≤

γd,nw∗

2

There exists sn only when 2 (cid:0)δn − 1
2
√
2
4 < δn < 1
2 +
2 −

sn is not feasible if 1

(cid:1)2
− 1
√
2
4 .

We can further obtain that sn should satisfy

4 ≥ 0. As a result,

(cid:113)

(cid:1)2

2 (cid:0)δn − 1

− 1

1
2 −

4 ≤ sn ≤ 1
Note that sn should also satisfy 1 − δn ≤ sn ≤ 1. Thus, sn is
feasible only when

− 1
4 .

2 +

2

2

2 (cid:0)δn − 1

(cid:1)2

(cid:113)

(cid:113)

2 (cid:0)δn − 1
1
2 − δn ≤
√
4 , we have that (cid:0) 1
2

2

(cid:1)2

− 1
4 .
≤ 2 (cid:0) 1
(cid:1)2

(cid:1)2

2 −

2 − δn

2 − δn

If 0 < δn ≤ 1

− 1
2 −
4 .
Thus, δn should satisfy δn ≥ 1 or δn ≤ 0, which contradicts
√
2
to 0 < δn ≤ 1
4 . As a result, sn is not feasible if 0 < δn ≤
√
2
1
2 −
4 .
1
1
2 − δn < 0 ≤
2 +
If
√
2 (cid:0)δn − 1
2
4 . As a result, sn is feasible if 1
4 ≤ δn < 1.
2 +
After summarizing everything, we can obtain that sn is not

√
2
4 ≤ δn < 1, we have that
(cid:1)2

− 1

(cid:113)

2

√
2
4 , thus, Proposition 2 holds.

Fig. 12. Numerical results of a homogeneous network with heterogeneous
IoT devices in Fig. 9(d). “D” and “C” represent Defender-D and Defender-C,
respectively. All nodes satisfy γd,n = 1.0, γa,n = 1.0, and ca,n = 1.0; all links
satisfy wnm = 0.5. Note that cd,1 = 0.5, cd,2 = 1, cd,3 = 2, and cd,4 = 4. Note
that we plot the global results of Defender-D in the last subﬁgure of Fig. 12
to compare with the results of Defender-C.

the increase of η when the defender is at one insurable status.

feasible if 0 < δn < 1

2 +

VIII. CONCLUSION
In this paper, we have established the framework of FlipIn
by composing FlipIt games and principal-agent problems to
describe the complex interactions among defenders, attackers,
and insurers over IoT networks. The framework has provided
a theoretical underpinning for the quantitative assessment of
cyber risks, the development of cross-layer defense mechanisms,
and the design of cyber insurance policies. Through the analysis
of the composed games, we have investigated the Peltzman
effect of IoT owners and studied the fundamental concept
of insurability. We have completely characterized the optimal
insurance contracts for the case with a network of distributed
defenders and the case with a centralized defender over a semi-
homogeneous network. It has been shown that the optimal
incentive-compatible insurance contract is to cover half of the
defender’s losses. Observations from numerical experiments
have provided design guidelines and insights for designing
policies for security management. There exists a nonlinear
relationship between the level of connectivity and insurability.
Nodes with low insurability need to invest in local cyber
defense instead of counting on cyber insurance. One of the
future directions would be the investigation of the dynamic
FlipIn framework with partial observations that explores the

REFERENCES

[1] L. Atzori, A. Iera, and G. Morabito, “The internet of things: A survey,”

Computer networks, vol. 54, no. 15, pp. 2787–2805, 2010.

[2] J. Gubbi, R. Buyya, S. Marusic, and M. Palaniswami, “Internet of things
(iot): A vision, architectural elements, and future directions,” Future
generation computer systems, vol. 29, no. 7, pp. 1645–1660, 2013.
[3] R. H. Weber, “Internet of things–new security and privacy challenges,”
Computer law & security review, vol. 26, no. 1, pp. 23–30, 2010.
[4] H. Suo, J. Wan, C. Zou, and J. Liu, “Security in the internet of things:
a review,” in Computer Science and Electronics Engineering (ICCSEE),
2012 international conference on, vol. 3, pp. 648–651, IEEE, 2012.
[5] K. Zhao and L. Ge, “A survey on the internet of things security,” in
Computational Intelligence and Security (CIS), 2013 9th International
Conference on, pp. 663–667, IEEE, 2013.

[6] Q. Jing, A. V. Vasilakos, J. Wan, J. Lu, and D. Qiu, “Security of
the internet of things: perspectives and challenges,” Wireless Networks,
vol. 20, no. 8, pp. 2481–2501, 2014.

[7] S. Sicari, A. Rizzardi, L. A. Grieco, and A. Coen-Porisini, “Security,
privacy and trust in internet of things: The road ahead,” Computer
networks, vol. 76, pp. 146–164, 2015.

[8] M. Antonakakis, T. April, M. Bailey, M. Bernhard, E. Bursztein,
J. Cochran, Z. Durumeric, J. A. Halderman, L. Invernizzi, M. Kallitsis,
et al., “Understanding the mirai botnet,” in USENIX Security Symposium,
pp. 1092–1110, 2017.

[9] C. Kolias, G. Kambourakis, A. Stavrou, and J. Voas, “Ddos in the iot:
Mirai and other botnets,” Computer, vol. 50, no. 7, pp. 80–84, 2017.

[10] C. Tankard, “Advanced persistent threats and how to monitor and deter

them,” Network security, vol. 2011, no. 8, pp. 16–19, 2011.

[11] E. Cole, Advanced persistent threat: understanding the danger and how

to protect your organization. Newnes, 2012.

00.20.40.60.8100.10.20.30.40.500.20.40.60.8100.511.522.5300.20.40.60.8100.511.5200.20.40.60.8100.511.500.20.40.60.8100.20.40.60.8100.20.40.60.810510152016

[12] M. Abomhara and G. M. Køien, “Cyber security and the internet of
things: vulnerabilities, threats, intruders and attacks,” Journal of Cyber
Security, vol. 4, no. 1, pp. 65–88, 2015.

[13] A. Hassanzadeh, S. Modi, and S. Mulchandani, “Towards effective
security control assignment in the industrial internet of things,” in Internet
of Things (WF-IoT), 2015 IEEE 2nd World Forum on, pp. 795–800, IEEE,
2015.

[14] Q. Hu, S. Lv, Z. Shi, L. Sun, and L. Xiao, “Defense against advanced
persistent threats with expert system for internet of things,” in Interna-
tional Conference on Wireless Algorithms, Systems, and Applications,
pp. 326–337, Springer, 2017.

[15] R. Langner, “Stuxnet: Dissecting a cyberwarfare weapon,” IEEE Security

& Privacy, vol. 9, no. 3, pp. 49–51, 2011.

[16] D. Kushner, “The real story of stuxnet,” ieee Spectrum, vol. 3, no. 50,

pp. 48–53, 2013.

[17] Z.-K. Zhang, M. C. Y. Cho, C.-W. Wang, C.-W. Hsu, C.-K. Chen, and
S. Shieh, “Iot security: ongoing challenges and research opportunities,”
in Service-Oriented Computing and Applications (SOCA), 2014 IEEE
7th International Conference on, pp. 230–234, IEEE, 2014.

[18] R. Mahmoud, T. Yousuf, F. Aloul, and I. Zualkernan, “Internet of things
(iot) security: Current status, challenges and prospective measures,” in
Internet Technology and Secured Transactions (ICITST), 2015 10th
International Conference for, pp. 336–341, IEEE, 2015.

[19] R. P. Majuca, W. Yurcik, and J. P. Kesan, “The evolution of cyberinsur-

ance,” arXiv preprint cs/0601020, 2006.

[20] R. B¨ohme, G. Schwartz, et al., “Modeling cyber-insurance: Towards a

unifying framework.,” in WEIS, 2010.

[21] A. Marotta, F. Martinelli, S. Nanni, A. Orlando, and A. Yautsiukhin,
“Cyber-insurance survey,” Computer Science Review, vol. 24, pp. 35–61,
2017.

[22] R. A. Miura-Ko, B. Yolken, N. Bambos, and J. Mitchell, “Security
investment games of interdependent organizations,” in Communication,
Control, and Computing, 2008 46th Annual Allerton Conference on,
pp. 252–260, IEEE, 2008.

[23] K. C. Nguyen, T. Alpcan, and T. Basar, “Stochastic games for security
in networks with interdependent nodes,” in Game Theory for Networks,
2009. GameNets’ 09. International Conference on, pp. 697–703, IEEE,
2009.

[24] T. Alpcan and T. Bas¸ar, Network security: A decision and game-theoretic

approach. Cambridge University Press, 2010.

[25] M. Van Dijk, A. Juels, A. Oprea, and R. L. Rivest, “Flipit: The game of
“stealthy takeover”,” Journal of Cryptology, vol. 26, no. 4, pp. 655–713,
2013.

[26] K. D. Bowers, M. Van Dijk, R. Grifﬁn, A. Juels, A. Oprea, R. L. Rivest,
and N. Triandopoulos, “Defending against the unknown enemy: Applying
ﬂipit to system security,” in International Conference on Decision and
Game Theory for Security, pp. 248–263, Springer, 2012.

[27] J. Pawlick, S. Farhang, and Q. Zhu, “Flip the cloud: cyber-physical
signaling games in the presence of advanced persistent threats,” in
International Conference on Decision and Game Theory for Security,
pp. 289–308, Springer, 2015.

[28] J. Chen and Q. Zhu, “Security as a service for cloud-enabled internet
of controlled things under advanced persistent threats: a contract design
approach,” IEEE Transactions on Information Forensics and Security,
vol. 12, no. 11, pp. 2736–2750, 2017.

[29] R. Pal, L. Golubchik, K. Psounis, and P. Hui, “Will cyber-insurance
improve network security? a market analysis,” in INFOCOM, 2014
Proceedings IEEE, pp. 235–243, IEEE, 2014.

[30] M. M. Khalili, P. Naghizadeh, and M. Liu, “Designing cyber insurance
policies: Mitigating moral hazard through security pre-screening,” in
International Conference on Game Theory for Networks, pp. 63–73,
Springer, 2017.

[31] M. M. Khalili, P. Naghizadeh, and M. Liu, “Designing cyber insurance
policies in the presence of security interdependence,” in Proceedings
of the 12th workshop on the Economics of Networks, Systems and
Computation, p. 7, ACM, 2017.

[32] M. M. Khalili, P. Naghizadeh, and M. Liu, “Designing cyber insurance
policies: The role of pre-screening and security interdependence,” IEEE
Transactions on Information Forensics and Security, vol. 13, no. 9,
pp. 2226–2239, 2018.

[33] I. Vakilinia and S. Sengupta, “A coalitional cyber-insurance framework
for a common platform,” IEEE Transactions on Information Forensics
and Security, 2018.

[34] S. Roy, C. Ellis, S. Shiva, D. Dasgupta, V. Shandilya, and Q. Wu, “A
survey of game theory as applied to network security,” in System Sciences
(HICSS), 2010 43rd Hawaii International Conference on, pp. 1–10, IEEE,
2010.

[35] A. Ferdowsi, W. Saad, B. Maham, and N. B. Mandayam, “A colonel
blotto game for interdependence-aware cyber-physical systems security
in smart cities,” in Proceedings of the 2nd International Workshop on
Science of Smart City Operations and Platforms Engineering, pp. 7–12,
ACM, 2017.

[36] Z. Han, D. Niyato, W. Saad, and T. Bas¸ar, Game Theory for Next
Generation Wireless and Communication Networks: Modeling, Analysis,
and Design. Cambridge University Press, 2019.

[37] Y. Li, L. Shi, P. Cheng, J. Chen, and D. E. Quevedo, “Jamming attacks
on remote state estimation in cyber-physical systems: A game-theoretic
approach,” IEEE Transactions on Automatic Control, vol. 60, no. 10,
pp. 2831–2836, 2015.

[38] T. Spyridopoulos, G. Oikonomou, T. Tryfonas, and M. Ge, “Game
theoretic approach for cost-beneﬁt analysis of malware proliferation
prevention,” in IFIP International Information Security Conference,
pp. 28–41, Springer, 2013.

[39] S. G. Vadlamudi, S. Sengupta, M. Taguinod, Z. Zhao, A. Doup´e,
G.-J. Ahn, and S. Kambhampati, “Moving target defense for web
applications using bayesian stackelberg games,” in Proceedings of the
2016 International Conference on Autonomous Agents & Multiagent
Systems, pp. 1377–1378, International Foundation for Autonomous
Agents and Multiagent Systems, 2016.

[40] C. Kiekintveld, V. Lis`y, and R. P´ıbil, “Game-theoretic foundations for
the strategic use of honeypots in network security,” in Cyber Warfare,
pp. 81–101, Springer, 2015.

[41] M. Zhu and S. Martinez, “Stackelberg-game analysis of correlated attacks
in cyber-physical systems,” in American Control Conference (ACC), 2011,
pp. 4063–4068, IEEE, 2011.

[42] T. E. Carroll and D. Grosu, “A game theoretic investigation of deception
in network security,” Security and Communication Networks, vol. 4,
no. 10, pp. 1162–1172, 2011.

[43] A. Teixeira, G. Dan, H. Sandberg, R. Berthier, R. B. Bobba, and A. Valdes,
“Security of smart distribution grids: Data integrity attacks on integrated
volt/var control and countermeasures,” in American Control Conference
(ACC), 2014, pp. 4372–4378, IEEE, 2014.

[44] Y. Wang, F. R. Yu, H. Tang, and M. Huang, “A mean ﬁeld game theoretic
approach for security enhancements in mobile ad hoc networks,” IEEE
transactions on wireless communications, vol. 13, no. 3, pp. 1616–1627,
2014.

[45] Q. Zhu and T. Basar, “Game-theoretic methods for robustness, security,
and resilience of cyberphysical control systems: games-in-games principle
for optimal cross-layer resilient control systems,” IEEE control systems,
vol. 35, no. 1, pp. 46–65, 2015.

[46] L. Huang and Q. Zhu, “Analysis and computation of adaptive defense
strategies against advanced persistent threats for cyber-physical systems,”
in International Conference on Decision and Game Theory for Security,
pp. 205–226, Springer, 2018.

[47] P. Hu, H. Li, H. Fu, D. Cansever, and P. Mohapatra, “Dynamic defense
strategy against advanced persistent threat with insiders,” in Computer
Communications (INFOCOM), 2015 IEEE Conference on, pp. 747–755,
IEEE, 2015.

[48] L. Xiao, D. Xu, C. Xie, N. B. Mandayam, and H. V. Poor, “Cloud
storage defense against advanced persistent threats: A prospect theoretic
study,” IEEE Journal on Selected Areas in Communications, vol. 35,
no. 3, pp. 534–544, 2017.

[49] M. Min, L. Xiao, C. Xie, M. Hajimirsadeghi, and N. B. Mandayam,
“Defense against advanced persistent threats in dynamic cloud storage: A
colonel blotto game approach,” IEEE Internet of Things Journal, vol. 5,
no. 6, pp. 4250–4261, 2018.

[50] S. Rass and Q. Zhu, “Gadapt: a sequential game-theoretic framework for
designing defense-in-depth strategies against advanced persistent threats,”
in International Conference on Decision and Game Theory for Security,
pp. 314–326, Springer, 2016.

[51] M. H. Manshaei, Q. Zhu, T. Alpcan, T. Bacs¸ar, and J.-P. Hubaux, “Game
theory meets network security and privacy,” ACM Computing Surveys
(CSUR), vol. 45, no. 3, p. 25, 2013.

[52] N. Abuzainab and W. Saad, “Dynamic connectivity game for adversarial
internet of battleﬁeld things systems,” IEEE Internet of Things Journal,
vol. 5, no. 1, pp. 378–390, 2017.

[53] Y. Hu, A. Sanjab, and W. Saad, “Dynamic psychological game theory
for secure internet of battleﬁeld things (iobt) systems,” IEEE Internet of
Things Journal, vol. 6, no. 2, pp. 3712–3726, 2019.

[54] M. Hamdi and H. Abie, “Game-based adaptive security in the internet of
things for ehealth,” in Communications (ICC), 2014 IEEE International
Conference on, pp. 920–925, IEEE, 2014.

[55] M. Pouryazdan, C. Fiandrino, B. Kantarci, D. Kliazovich, T. Soyata, and
P. Bouvry, “Game-theoretic recruitment of sensing service providers for

17

trustworthy cloud-centric internet-of-things (iot) applications,” in IEEE
Global Communications Conference (GLOBECOM) Workshops: Fifth
International Workshop on Cloud Computing Systems, Networks, and
Applications (CCSNA), 2016.

[56] N. Namvar, W. Saad, N. Bahadori, and B. Kelley, “Jamming in the internet
of things: A game-theoretic perspective,” in Global Communications
Conference (GLOBECOM), 2016 IEEE, pp. 1–6, IEEE, 2016.

[57] S. Lee, S. Kim, K. Choi, and T. Shon, “Game theory-based security vul-
nerability quantiﬁcation for social internet of things,” Future Generation
Computer Systems, vol. 82, pp. 752–760, 2018.

[58] T. Spyridopoulos, G. Karanikas, T. Tryfonas, and G. Oikonomou, “A game
theoretic defence framework against dos/ddos cyber attacks,” Computers
& Security, vol. 38, pp. 39–50, 2013.

[59] A. Laszka, G. Horvath, M. Felegyhazi, and L. Butty´an, “Flipthem: Mod-
eling targeted attacks with ﬂipit for multiple resources,” in International
Conference on Decision and Game Theory for Security, pp. 175–194,
Springer, 2014.

[60] M. Zhang, Z. Zheng, and N. B. Shroff, “A game theoretic model for
defending against stealthy attacks with limited resources,” in International
Conference on Decision and Game Theory for Security, pp. 93–112,
Springer, 2015.

[61] D. Leslie, C. Sherﬁeld, and N. P. Smart, “Threshold ﬂipthem: When
the winner does not need to take all,” in International Conference on
Decision and Game Theory for Security, pp. 74–92, Springer, 2015.
[62] D. Leslie, C. Sherﬁeld, and N. P. Smart, “Multi-rate threshold ﬂipthem,”
in European Symposium on Research in Computer Security, pp. 174–190,
Springer, 2017.

[63] M. V. Pauly, “The economics of moral hazard: comment,” The American

Economic Review, pp. 531–537, 1968.

[64] S. Shavell, “On moral hazard and insurance,” in Foundations of Insurance

Economics, pp. 280–301, Springer, 1979.

[65] L. A. Gordon, M. P. Loeb, and T. Sohail, “A framework for using
insurance for cyber-risk management,” Communications of the ACM,
vol. 46, no. 3, pp. 81–85, 2003.

[66] L. Bailey, “Mitigating moral hazard in cyber-risk insurance,” JL & Cyber

Warfare, vol. 3, p. 1, 2014.

[67] R. Pal, Improving network security through cyber-insurance. Citeseer,

2014.

[68] R. Pal, L. Golubchik, K. Psounis, and P. Hui, “Security pricing as enabler
of cyber-insurance a ﬁrst look at differentiated pricing markets,” IEEE
Transactions on Dependable and Secure Computing, 2017.

[69] E. Ghotbi and A. K. Dhingra, “A bilevel game theoretic approach to
optimum design of ﬂywheels,” Engineering Optimization, vol. 44, no. 11,
pp. 1337–1350, 2012.

[70] M. Jenabi, S. M. T. F. Ghomi, and Y. Smeers, “Bi-level game approaches
for coordination of generation and transmission expansion planning
within a market environment,” IEEE Transactions on Power systems,
vol. 28, no. 3, pp. 2639–2650, 2013.

[71] R. Zhang and Q. Zhu, “A game-theoretic approach to design secure
and resilient distributed support vector machines,” IEEE Transactions
on Neural Networks and Learning Systems, 2018.

[72] R. Zhang, Q. Zhu, and Y. Hayel, “A bi-level game approach to attack-
aware cyber insurance of computer networks,” IEEE Journal on Selected
Areas in Communications, vol. 35, no. 3, pp. 779–794, 2017.

[73] A. Dassios and P. Embrechts, “Martingales and insurance risk,” Com-
munications in Statistics. Stochastic Models, vol. 5, no. 2, pp. 181–217,
1989.

[74] P. Cizek, W. K. H¨ardle, and R. Weron, Statistical tools for ﬁnance and

insurance. Springer Science & Business Media, 2005.

[75] K. Balakrishnan, Exponential distribution: theory, methods and applica-

tions. Routledge, 2018.

[76] R. G. Engoulou, M. Bella¨ıche, S. Pierre, and A. Quintero, “Vanet security

surveys,” Computer Communications, vol. 44, pp. 1–13, 2014.

[77] D. Gantsou, “On the use of security analytics for attack detection in
vehicular ad hoc networks,” in 2015 International Conference on Cyber
Security of Smart Cities, Industrial Control System and Communications
(SSIC), pp. 1–6, IEEE, 2015.

[78] T. Zhang and Q. Zhu, “Strategic defense against deceptive civilian gps
spooﬁng of unmanned aerial vehicles,” in International Conference on
Decision and Game Theory for Security, pp. 213–233, Springer, 2017.
[79] F. Ewold, “Insurance and risk,” The Foucault effect: Studies in govern-

mentality, pp. 197–210, 1991.

[80] S. Peltzman, “The effects of automobile safety regulation,” Journal of

political Economy, vol. 83, no. 4, pp. 677–725, 1975.

