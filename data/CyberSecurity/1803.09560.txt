8
1
0
2

r
a

M
6
2

]

R
C
.
s
c
[

1
v
0
6
5
9
0
.
3
0
8
1
:
v
i
X
r
a

1

Forecasting Cyber Attacks with Imbalanced
Data Sets and Different Time Granularities

Ahmet Okutan∗, Shanchieh Jay Yang∗, Katie McConky†
∗Computer Engineering, Rochester Institute of Technology, Rochester, NY, USA.
†Industrial and Systems Engineering, Rochester Institute of Technology, Rochester, NY, USA.

Abstract—If cyber incidents are predicted a reasonable amount of time before they occur, defensive actions to prevent their
destructive effects could be planned. Unfortunately, most of the time we do not have enough observables of the malicious activities
before they are already under way. Therefore, this work suggests to use unconventional signals extracted from various data sources
with different time granularities to predict cyber incidents for target entities. A Bayesian network is used to predict cyber attacks where
the unconventional signals are used as indicative random variables. This work also develops a novel minority class over sampling
technique to improve cyber attack prediction on imbalanced data sets. The results show that depending on the selected time
granularity, the unconventional signals are able to predict cyber attacks for the anonimyzed target organization even though the signals
are not explicitly related to that organization. Furthermore, the minority over sampling approach developed achieves better
performance compared to the existing ﬁltering techniques in the literature.

Index Terms—Cyber security, Bayesian networks, forecasting, unconventional signals.

(cid:70)

1 INTRODUCTION

The number and diversity of cyber attacks have increased
recently compared to the previous years. Denial of Service
(DOS), Malware, attack on Internet facing service (Deface-
ment), malicious Email, and malicious URL are some of the
attack types that organizations and Internet users commonly
observe. PwC reports that the number of security incidents
increased by 38% in 2015 across all industries [1]. Prediction
of cyber attacks before they are executed is very important
to take necessary defensive actions beforehand. This work
proposes to forecast cyber attacks towards an entity by
using unconventional signals from various data sources
that may or may not be related to that target entity. For
unconventional signals, this paper uses social media, i. e.,
Twitter and the open source GDELT [2] project that follows
the media from almost every corner of the world, in over
100 languages, and almost every moment of each day.

The idea of using unconventional signals to forecast
cyber events is based on the premise that the signals are not
directly linked to speciﬁc exploits or vulnerabilities within
the targeted organization. There might be many potentially
useful unconventional signals, but each signal may not
be particularly effective by itself. Furthermore, continuous
enhancement to condition or aggregate these signals is not
trivial and requires a signiﬁcant amount of research. This
work proposes a methodology based on Bayesian networks
that can treat a variety of unconventional signals to forecast
events that do not necessarily have balanced positive and
negative ground truth instances. The feasibility of the pro-
posed approach is demonstrated using the selected uncon-
ventional signals. Additional and potentially better signals
may be used in conjunction with the method presented in
this paper.

The main motivation behind this work is to address three

important cyber security problems: Use unconventional sig-
nals rather than the direct cyber observables to forecast
cyber attacks, research the signiﬁcance of changing time
granularities for signals, and improve the performance of
cyber attack forecasting on imbalanced cyber data sets. First,
unlike some cyber attack prediction techniques which ana-
lyze the results of cyber incidents or suggest approaches to
react to the attacks already underway, this research focuses
on unconventional signals that have a potential to be indica-
tive of a cyber incident towards a target entity. Bakdash et
al. [3] emphasize the importance of moving from reactive
and passive defense systems to more proactive ones and
show that the frequency of attacks from the previous week
can be used to predict the number of attacks for the next
week. Ramakrishnan et al. [4] develop an automated and
continuously running system named EMBERS (Early Model
Based Event Recognition using Surrogates) to forecast civil
unrest events. They use open source indicators such as
tweets, news sources, blogs, economic indicators, and other
data sources as evidence and show that EMBERS is able to
successfully forecast signiﬁcant public unrest events across
10 countries of Latin America.

While using unconventional signals to forecast future
cyber incidents, one needs to decide on the aggregation
period of each signal and the entity ground truth, in order to
generate training and test sets for target entities. Assuming t
represents a time stamp and tx and tg represent time granu-
larities for the unconventional signals and the entity ground
truth respectively, we investigate if signals aggregated over
a period of time between t − tx and t could be indicative
of cyber events for the succeding time period starting at t
and ending at t + tg. For instance, if tx is one week and tg is
24 hours, signals averaged over the last week could be used
to predict attacks that will occur in the next 24 hours. Our
previous study [5] calculated unconventional signals on a

 
 
 
 
 
 
daily basis and used them with the ground truth data of
the following day to predict cyber attacks before they are
observed. This paper uses different time granularities for
the unconventional signals (tx) and the entity ground truth
(tg) and shows that the performance of a prediction model
is dependent on the selected tx and tg.

Depending on the update frequency of a particular
data source, choosing a very small or large tx affects the
indicative power or quality of a speciﬁc signal. Similarly,
contingent upon the type or reputation of an entity, the
number and frequency of cyber incidents observed for that
entity could be different. Moreover, some attack types could
be observed more frequently compared to some other types
within an entity. Therefore, the training and test data sets
of each attack type could be more balanced or imbalanced
depending on the chosen tg value. If a malicious email
attack is observed a couple of times per week, then training
a classiﬁer with the ground truth data of each day (or 2 or
3 days) could be a better approach compared to training
with the ground truth of a week. Similarly, if an attack
type is seen each and every day consistently, training a
model with attacks observed in 6 or 12 hours of granularity
might be better. Based on this intuition, this work develops
a general cyber attack forecasting framework for entities,
i. e., organizations and industries that uses different tx and
tg time granularities to forecast cyber attacks for different
attack types.

The infrequency of certain types of attacks may cause
challenges where the positive instances are much fewer
compared to the negative instances (no attack). Dealing with
imbalanced data sets is challenging, because it is not often
possible for a classiﬁer to learn the minority class. There
are several approaches to deal with imbalanced data sets.
Apart from choosing a proper performance metric or clas-
siﬁer, other approaches include changing the distribution of
the instances, which is a very delicate process. Moreover,
there are many accompanying questions that need to be
answered, like which instances to under or over sample
and how to generate synthetic new instances? This work
proposes a new approach to improve cyber attack forecast-
ing performance on imbalanced data sets. The proposed
algorithm is a modiﬁed version of the Synthetic Minor-
ity Over-sampling Technique (SMOTE) [6], where some of
the majority instances are under sampled before applying
SMOTE. We show that this algorithm improves the predic-
tion performance of the proposed method on imbalanced
data sets.

The unconventional signals used to predict cyber attacks
are not directly related to the target entity for which the
prediction is made. There is no explicit relationship between
these signals and the target entity. In fact, it is not easy
to measure the level of correlation between any of the un-
conventional signals and the ground truth events. Bayesian
networks are probabilistic graphical models that are more
successful in marginalizing the unknown uncertainties com-
pared to other models. They are helpful in accounting for
the uncertainty among the variables whose distribution or
dependencies are unknown and also extracting the inﬂuen-
tial or causal relationships among features if any. Therefore,
Bayesian approach is used to predict cyber attacks with
unconventional signals, as the relationship of these signals

2

and the target entities is not straightforward.

This paper is organized as follows: Section 2 presents
a brief review of the previous approaches in cyber attack
prediction. In Section 3, the problem is formulated by
giving a background on Bayesian networks and deﬁning
the different time granularities used for signal and ground
truth calculation. Section 4 explains the proposed approach,
Section 5 gives the experiment results and Section 7 presents
conclusions and future work.

2 PREVIOUS WORK

Traditional
intrusion detection systems rely on a mis-
use based approach where monitored events are matched
against the signatures of the previously observed incidents
[7], [8], [9], [10], [11]. One of the drawbacks of such systems
is their inability to detect new events whose signatures are
not known to the detection systems. Furthermore, deploying
the signatures of the new attacks across the whole network
takes some time and may not be effective. Anomaly detec-
tion aims at detecting deviations from normal behaviour
and labels them as malicious [12], [13], [14], [15], [16]. These
approaches typically have a high false alarm rate, because
they may label normal but previously unseen behaviors as
anomalies.

Yang et al. [17] describe several attack projection frame-
works which model how an attack might transpire over
time. This modeling is broader than the traditional deﬁni-
tion of the intrusion detection systems where observables
of ongoing attacks are used to predict the next malicious
actions based on system vulnerabilities and attacker behav-
ior. In attack projection, the focus is on the footprints of
the multistage cyber attacks. Extracted footprints and the
sequence or causal dependencies among these footprints
are used to generate hypothesized attack strategies that
represent a multistage attack. These attack strategies are
then modeled to project future actions of ongoing attacks.
Wang et al. [18] suggest that efﬁcient algorithms are needed
for multi-step intrusions to correlate isolated alerts into
attack scenarios and propose to use attack graphs. They
use attack graphs to identify possible cases where vulner-
abilities can be exploited in a network and show that their
method is more successful in correlating isolated attacks
into attack scenarios compared to the traditional intrusion
detection systems. Similarly, Qin and Lee [19] suggest to use
probabilistic inference with a dynamic Bayesian Network
approach to correlate attacks. Using the Grand Challenge
Problem (GCP) data set of the Defense Advanced Research
Projects Agency, they show that their method is successful
in correlating isolated attacks, identifying attack strategies,
and predicting future attacks.

A broad range of Machine Learning techniques have
been used so far for intrusion detection and cyber attack
prediction. Artiﬁcial Neural Networks [7] [13], Clustering
[14], Decision Trees [8] [15], Ensemble Learning [9], Support
Vector Machines [10] are some of the methods that have
been used in the cyber security literature. Besides the tra-
ditional approaches, there are some studies that elaborate
on the prediction of multi stage cyber attacks. For example,
Cheng et al. [20] use a novel method that is based on the
Longest Common Subsequence (LCS) technique to measure

the similarities between attack progressions, correlate secu-
rity alerts with speciﬁc patterns, and predict multi stage
attacks. They show that their method is able to project
possible attacks better when compared to the previous LCS
based approaches. Furthermore, Fava et al. [21] present
the use of a variable-length Markov model (VLMM) that
captures the sequential properties of attacks to project future
activities of ongoing cyber attacks and show that the method
they propose is able to adapt to the newly observed attack
sequences.

In most of the existing intrusion detection or projection
systems, the observables are direct outcomes of the mali-
cious activities on the computing systems. These observ-
ables may be referred to as conventional signals. However,
our research uses unconventional signals that are observed
before any malicious activity occurs. They may be due to in-
creasing negative tones toward an organization or news re-
ports, and sometimes may not have explicit relations to the
future victim of the cyber attacks. Preliminary studies have
shown the viable concept of using unconventional signals
to forecast cyber attacks [5] and attack intensities [22]. Silver
[23] investigates how a true signal can be distinguished from
a universe of noise data and states that most predictions fail
due to a poor understanding of probability and uncertainty.
He believes that as the appreciation of uncertainty improves,
better prediction results could be achieved. Furthermore,
Tetlock and Gardner [24] state that creating good forecast
involves gathering evidence from a variety of sources rather
than using very powerful computing resources or arcane
techniques.

Bayesian methods have also been used in the cyber
security literature to a limited extent [11], [16]. Dua and Du
[25] state that the false alarm rate of the rule based misuse
detection systems are high since the signature of a malicious
and normal user might overlap to activate a rule. As an
alternative solution they suggest to use Bayesian networks
and state that Bayesian approaches have a relative resilience
in conditional probability table parametrization and allow
the anomalousness of an event to be directly related to its
probability.

3

Knowing that Xi is independent from the variables other
than its parents πi

P (X) =

n
(cid:89)

i=1

P (Xi|πi)

(2)

Consider the Bayesian network in Figure 1. Bayesian infer-

Fig. 1. An example Bayesian Network showing a hypothetical relation-
ship among the Entity Mentions (EM), Cyber Mentions (CM) and Attack
(A)

ence can be used to calculate the probability of observing
an attack towards an entity based on all possible values
of Entity Mentions (EM) and Cyber Mentions (CM). For
example, assuming that EM and CM can take values either
Low (L) or High (H),

P (A|EM = H) = P (A|EM = H, CM = H)P (CM = H|EM = H)
+ P (A|EM = H, CM = L)P (CM = L|EM = H)

P (CM = H|EM = H) is P (CM = H) and P (CM =
L|EM = H) is P (CM = L), because the variables EM
and CM are independent. Then,

P (A|EM = H) = P (A|EM = H, CM = H)P (CM = H)
+ P (A|EM = H, CM = L)P (CM = L)

Consider a set of target entities composed of organizations
or industries E = {E1, E2, ...Et}, a set of cyber attack
signals X = {X1, X2, ...Xn}, and a set of attack types
A = {A1, A2, ...Am}. For any given entity Ei, if the set
of attack types is deﬁned as A(Ei) where A(Ei) ⊆ A and
the set of cyber attack signals is deﬁned as X(Ei) where
X(Ei) ⊆ X, Bayesian inference is used to calculate the
probability of each attack type Ai ∈ A(Ei) based on the
cyber attack signals in X(Ei).

3 PROBLEM FORMULATION
A Bayesian network is deﬁned as a directed acyclic graph
(DAG) that is composed of n random variables (nodes) and
e edges that represent the conditional dependencies among
these variables. Let X = {X1, X2, ...Xn} be n random
variables (unconventional signals) with nominal or numeric
values for a Bayesian network B where n >= 1. Assuming
πi represents the parents of node Xi, the probability dis-
tribution of Xi is calculated by P (Xi|πi). Each node Xi
in the Bayesian network is associated with a conditional
probability table that shows the probabilities for each value
of Xi based on all combinations of values of its parent nodes
and is represented as PXi = P (Xi|πi).

To calculate the joint probability distribution of X, the

chain rule is used, i. e.,
P (X) = P (X1|X2, X3, ..., Xn)P (X2, X3, ..., Xn)

= P (X1|X2, ..., Xn)P (X2|X3, ..., Xn)P (X3, ..., Xn)
= P (X1|X2, ..., Xn)P (X2|X3, ..., Xn)...P (Xn−1|Xn)P (Xn)

=

n
(cid:89)

i=1

P (Xi|Xi+1, ..., Xn)

(1)

3.1 Signal and Ground Truth Time Granularity

Depending on how frequent cyber incidents are observed
for an entity Ei, making predictions using different ground
truth granularities could be helpful. If a couple of cyber
attacks of a certain type are observed almost every day
consistently, it would not be beneﬁcial to train and test a
classiﬁer to predict attacks for each day. Instead, one may
make predictions for 6 or 12 hours of granularity. On the
other hand, depending on the availability, quality or update
frequency of the unconventional signals, one may think to
calculate signals for different time granularities, i. e., the last
couple of days, weeks or months. If the data source is not
being updated on a daily basis, it might not be beneﬁcial to
calculate signals on a daily basis. Different time granularities
are used to calculate the unconventional signals and the
ground truth. The time granularity of signals is deﬁned as tx
and ﬁve cases are considered where each signal is calculated
by averaging its previous values observed in the last three
days (3d), one week (1w), one month (1m), three months
(3m), and six months (6m).

Similarly, the time granularity of the ground truth is
deﬁned as tg and four cases are evaluated where tg takes a
value of 6, 12, 24, or 48 hours (The tg values are represented
as 6hr, 12hr, 24hr, and 48hr respectively in the following
sections). Taking tg less than 6 hours leads to a very sparse
data set, since a typical organization may not see certain
cyber attacks every hour of the day. Similarly, taking tg
larger than 48 hours causes the training data set to have
positive ground truth for the vast majority of instances.
Depending on how frequent cyber incidents are observed
for an entity or attack type, different tg values may be
assessed for various entities and attack types.

For each attack type of an entity Ei, each of the tx
values deﬁned above is used to calculate the unconventional
signals in X(Ei). Similarly, to train a Bayesian classiﬁer for
each attack type, different tg time granularities (6, 12, 24,
and 48 hours) are used to consider real cyber incidents for
Ei. For example, if tx is selected as one week and tg as 24
hours, then for a given time t, signals calculated for the last
week are used together with the ground truth of the next 24
hours (tg) to train a Bayesian classiﬁer. A Bayesian classiﬁer
is built for each attack type Ai ∈ A(Ei) of a target entity Ei,
considering all possible combinations of the deﬁned tx and
tg values.

4 PROPOSED METHOD

Bayesian inference is used to calculate the probability of
cyber attacks towards a speciﬁc target entity using uncon-
ventional signals that may or may not be related to that
target entity. These signals are pulled from various data
sources, including social media (Twitter) and open source
global event tracking projects like GDELT.

The prediction is regarded as a classiﬁcation problem
where the value of the target class is either 1 or 0 depending
on having a cyber attack or not. For each entity Ei and
its attack type Ai ∈ A(Ei), the unconventional signals in
X(Ei) are used as random variables and the ground truth
of Ei for Ai as target class to train a Bayesian classiﬁer for
different tx and tg pairs. For a given time t, the training set
of each Ai is represented as SAi and includes the unconven-
tional signals calculated for the time period (t − tx, t) and
the real cyber incidents reported for the period (t, t + tg).
For each attack type Ai of a target entity Ei and for each
tx and tg time granularity pair, we learn the structure of
the Bayesian network for Ai using the previously observed
unconventional signals in (t − tx, t) and the ground truth
incidents observed in (t, t + tg). Then, for a given time t
unconventional signals are calculated for the time period
(t − tx, t) to predict the cyber incidents for the upcoming
time period, i. e., (t, t + tg).

4.1 Unconventional Signals Used

Increased discussion of past or potential cyber attacks may
be due to a signiﬁcant change in the intent or capability of
attackers or software vulnerabilities. Similarly, an increase in
the number of mentions of a target entity might be due to an
increase in the surveillance towards it, and may lead to an
increase in the probability of a cyber attack for that target
entity. Furthermore, the number of mentions of negative

4

events, the tone of the negativity of these events or the
number of source documents referring to them might be in-
dicative of a cyber incident. These example unconventional
signals are used to predict cyber attacks for an anonymized
private company nicknamed KNOX. These unconventional
signals are by no means comprehensive, but are good ex-
amples to test our methodology. These signals are described
below, which are fed into a Bayesian classiﬁer for each tx
and tg time granularity pair, to predict attacks for each
attack type deﬁned for KNOX: Defacement, Malware, DOS,
and Malicious Email/URL (MEU).

• Twitter Cyber Mentions (TCM): Given a time t and
a signal time granularity tx, a set of cyber keywords
including Hack, Malware, DDOS, and Malicious are
used to count the number of mentions of these key-
words on Twitter for each signal calculation period,
i. e., (t − tx, t).

• Twitter Entity Mentions (TEM): The number of
mentions of KNOX related keywords in Twitter is
counted for each signal calculation period (t − tx, t)
to check if these mentions are indicative of a cyber
incident towards KNOX.

• GDELT Event Mentions (GEM): GDELT keeps track
of the media from every country, in over 100 lan-
guages. As a measure of event signiﬁcance it counts
the total number of mentions of speciﬁc events across
all of its source documents. GDELT also attaches an
average tone value for each mentioned event. The
value of the average tone could be between -100 and
+100 and it indicates the degree of the negativity
of the associated event. For each signal calculation
period (t − tx, t), the total mentions of events that
have a negative average tone are calculated.

• GDELT Event Articles (GEA): GDELT counts the
total number of source documents containing one or
more mentions of an event for assessing the “impor-
tance” of an event. The more an event is discussed,
the more likely it is regarded as signiﬁcant. For a
given time t, the total number of source documents
mentioning events with an average negative tone are
counted in the signal calculation period (t − tx, t).
• GDELT Event Tone (GET): Given a time t and a
signal granularity tx, the average tone of the negative
events is calculated for the time period (t − tx, t).

4.2 Signal and Ground Truth Calculation

For a given time t, the signals for the past period (t − tx, t)
are aggregated to predict the cyber attacks for the next tg
hours. Most of the signals are general and not speciﬁc to
KNOX. The ground truth data of KNOX was available be-
tween April 1 and October 30 2016, therefore the prediction
models are trained and tested in this period. Step by step
details of the signal and ground truth generation process are
provided in Algorithm 1. The variables gtStartT ime and
gtEndT ime are set to 04.01.2016 and 10.30.2016 respectively.
For each attack type and time granularity pair (tx and tg), a
separate data set is generated. All ground truth counts that
are greater than 1 are set to 1 to perform binary prediction.
In the inner most while loop, the unconventional signals are

aggregated over a time period of length tx, i. e., starting at
signalStartT ime and ending at currentT ime.

Algorithm 1: The signal and ground truth calculation
process for different tx and tg.

Function GenerateDataSets (gtStartT ime, gtEndT ime)
attackT ypes := [Malware,Defacement,DOS,MEU];
signalGranularity := [6m,3m,1m,1w,3d];
groundT ruthGranularity := [48hr,24hr,12hr,6hr];
foreach ai ∈ attackT ypes do

foreach tx ∈ signalGranularity do

foreach tg ∈ groundT ruthGranularity do

currentT ime := gtStartT ime;
while currentT ime <= gtEndT ime − tg do
signalStartT ime := currentT ime − tx;
(cid:46) Calculate average of signals

TCM, TEM, GEM, GEA, GET

let signals be the signals calculated for

time period
(signalStartT ime, currentT ime);

(cid:46) Calculate ground truth
gtEnd := currentT ime + tg;
let gt be number of cyber incidents

observed in the time period
(currentT ime, gtEnd);

if gt > 1 then
gt := 1;

end
(cid:46) signal and gt is appended to

the file for ai
write(ai, signals, gt);
currentT ime := currentT ime + tg;

end

end

end

end

4.3 Working with Imbalanced Cyber Data Sets

Cyber incidents towards a speciﬁc entity are rare events that
can be marked as anomalies especially when ﬁltered for a
speciﬁc attack type. Therefore, the data sets for cyber inci-
dents could be highly skewed towards negative instances
that have a ground truth value of zero. Sometimes it might
be very difﬁcult for a classiﬁer to predict positive instances
with a cyber attack based on such data sets. There are
several approaches to overcome the imbalanced data set
problem, including:

• Using different performance metrics like F-Measure
or AUC (the area under the ROC curve) rather than
accuracy.

• Using different classiﬁers like decision tree based
algorithms that could perform well on imbalanced
data sets.

• Over sampling the minority class.
• Under sampling the majority class.
•

Introducing new synthetic instances for the minority
class.

A new algorithm named SMOTE++ is proposed to improve
the cyber attack prediction performance on imbalanced data
sets. It is a hybrid approach where the under sampling,
instance weighing, and over sampling techniques are used
together.

5

It is highly desirable for a classiﬁer to have the negative
and positive instances apart from each other. In other words,
if it is easier to separate the negative and positive instances
with a line, plane or hyperplane, one may expect a classi-
ﬁer to perform better. Unconventional signals that are not
explicitly related to the target entity are used. Therefore,
some of the training instances may not be sufﬁcient in
explaining the relationship of the unconventional signals
and the cyber event ground truth. To be able to distinguish
the negative and positive instances better, we suggest to
remove a certain percentage of the majority class (negative)
instances that are near to the minority class (positive) in-
stances. To ﬁnd such instances, a simple approach could be
to ﬁlter out the negative instances that are near to the mean
of the positive instances. k-Means clustering algorithm is
used to ﬁnd the main cluster of the positive instances and
remove some portion of the negative instances that are
near to that mean where the percentage to remove is a
conﬁgurable parameter in the algorithm. In case there is
no cluster for the positive instances, i. e., they are scattered
around, the mean of all positive (minority) instances is
used to remove negative (majority) instances. Removing
some of the negative instances causes a change in the total
weight of the negative classes. To compensate for that, the
remaining negative instances are reweighed to maintain
the same total weight for the negative instances. On the
other hand, to make the class weights of the negative and
positive classes equal, a hybrid approach is followed where
the weights of the existing positive instances are reweighed
and new synthetic positive instances with a lower weight
are introduced. This is done to differentiate the existing
minority instances from the newly genareted synthetic ones.
Assume that we need to introduce three more instances for
each positive instance to achieve an equal weight for the
negative and positive classes. We ﬁrst multiply the weight
of each existing positive instance by two and then introduce
two new synthetic instances for every positive instance. To
introduce new synthetic instances k −N N algorithm is used
in the same way it is used in SMOTE [6]. A step by step
description of the proposed method is shown in Algorithm
2.

5 EXPERIMENTS AND RESULTS

The unconventional signals deﬁned in Section 4.1 that are
extracted from various data sources and are not explicitly
related with KNOX are used to predict the probability of
different attack types for KNOX. For each attack type, a sep-
arate data set is created for every tx and tg time granularity
pair. Using ﬁve tx and four tg time granularity values, a total
of 20 different data sets are created for each attack type. It is
always desirable for a classiﬁer to have a high true positive
(TP) and a low false positive (FP) rate at the same time. The
area under the ROC curve (AUC) gets higher, when TP is
high and FP is low. Therefore, AUC is used to compare the
performance of the proposed model on different data sets.
Moreover, the BayesNet classiﬁer in Weka [26] is used with
10 × 10 folds cross validation to calculate the average AUC
value for each attack type and the tx and tg time granularity
pair.

6

highly imbalanced for all tg values. However, the data sets
for the Malware attack type are more balanced compared to
the DOS and MEU attack types. Moreover, the data sets of
the MEU and Defacement attack types are skewed when tg
is low.

TABLE 1
The percentage (%) of the positive instances for the data sets of
different attack types for different tg time granularities: 6, 12, 24, and 48
hours. A positive instance corresponds to an instance with a cyber
attack.

Malware
Defacement
DOS
MEU

6 hr
36
15
2
10

12 hr
51
26
4
17

24 hr
72
48
9
32

48 hr
80
64
15
50

5.2 Using Different tx and tg Time Granularities
The average AUC values for each attack type for different
tx and tg pairs are shown in Figures 2, 3, 4, and 5. We
present the AUC values when tx is three days (3d), one
week (1w), one month (1m), three months (3m), and six
months (6m) for different tg. Each line in these ﬁgures
shows the AUC values when tg is 6, 12, 24, and 48 hours
respectively. First, we observe that when an optimum tx
and tg time granularity is chosen, it is possible to achieve
an AUC value of at least 0.70 for all attack types deﬁned for
KNOX, using unconventional signals that are not directly
related with KNOX. The results suggest that if a prediction
model calculates signals for different time granularities and
keeps track of the best performing granularity pair, it might
be possible to achieve a better performance to predict cyber
incidents for different attack types.

Algorithm 2: SMOTE++ algorithm.

Input

: An imbalanced data set denoted as allInstances
Percentage of majority instances to remove, i. e., p
The number of nearest neighbors to consider to
generate synthetic minority instances, i. e., k2

Output

: A new data set with a uniform majority and

minority class distribution

Function SMOTE++ (allInstances, p, k2)

let majInstances be the set of majority instances in

allInstances;

let minInstances be the set of minority instances in

allInstances;

let sM in be the size of the minInstances;
let sM aj be the size of the majInstances;
(cid:46) Find the first minority cluster using

k−Means Clustering with Euclidian distance

k := 2;
minorityClusterF ound := f alse;
while minorityClusterF ound (cid:54)= true do

let clusters be the ﬁrst k clusters in allInstances;
if clusters includes a minority cluster then

let cM in be the centroid of the minority cluster in

clusters;

minorityClusterF ound := true;

else

k := k + 1;

end
if k = sM in then

break;

end
(cid:46) If a minority class cluster is not found

then use the mean of all minority instances

if minorityClusterF ound (cid:54)= true then

let cM in be the mean of all minority instances in

minInstances;

(cid:46) Filter majority instances
remove p percent of majInstances that are nearest to

cM in;

let majInstancesN ew be the remaining instances in

majInstances;

(cid:46) Reweigh majority instances
majW eight := 100/(100 − p);
set the weight of each instance in majInstancesN ew to

majW eight;

(cid:46) Reweigh existing minority instances
minW := sM aj/sM in / 2;
set weight of each instance in minInstances to minW ;
(cid:46) Generate new synthetic minority instances
generate minW ∗ sM in synthetic minority instances using

k−NN with k := k2 [6];

let minInstancesSyn be the set of created synthetic

minority instances;

return

majInstancesN ew ∪ minInstances ∪ minInstancesSyn;

5.1 Data Sets Used

Fig. 2. Average AUC values for the Malware attack type for different tx
and tg signal and ground truth time granularities.

We create a separate data set for each attack type and the tx
and tg time granularity pair. The distribution of the negative
and positive classes in these data sets are different for dif-
ferent tg values. For each attack type, as tg gets lower, fewer
ground truth incidents are observed for KNOX, therefore
the data sets become more imbalanced. Similarly, as tg gets
larger more cyber incidents are observed and the ratio of the
positive instances with a cyber attack increases. The list of
the created data sets and their negative and positive class
distribution for each attack type and tg are shown in Table
1. For example, the data sets for the DOS attack type are

A data set might be more imbalanced for speciﬁc attack
types (like DOS or MEU in our case) or when created
with a lower tg value. For example, when tg is 24 hours,
the rate of the positive instances with a cyber attack and
the negative instances with no attack are different for each
attack type. One might expect a lower performance on an
imbalanced data set compared to a data set that has a
uniform class distribution. Although the skewness of data
sets are different for each attack type when tg is 24 hours, a
higher classiﬁcation performance is observed for all attack
types for tg = 24 hours. For example, except for Malware,

the performance of the prediction model is better when tg
is 24 hours for almost all attack types and tx values. For
Malware, a comparable performance is observed when tg is
24 and 48 hours.

7

Fig. 3. Average AUC values for the Defacement attack type for different
tx and tg signal and ground truth time granularities.

Fig. 4. Average AUC values for the DOS attack type for different tx and
tg signal and ground truth time granularities.

Similarly, the performance of the classiﬁer is also im-
pacted by the choice of tx. For example, for the MEU and
DOS attack types the AUC value of the classiﬁer is higher
when tx is one month. However, Malware and Defacement
follow a different pattern. For the Defacement attack type,
a higher AUC value is observed when tx is three months
and the performance is comparable when tx = 6 months.
Similarly, for the Malware data set, although the perfor-
mance of the model is slightly better when tx is six months,
a comparable performance is observed when tx is three
months.

5.3 Relationships of the Signals and Cyber Incidents

To explore the relationship of each unconventional signal
and the cyber incidents, we take a closer look at the
Bayesian networks generated. Twenty Bayesian networks
are trained for each attack type considering each possible
pair of deﬁned tx and tg values. One of the best performing
granularity pairs is used for each attack type where tg is 24
hours and tx is either one month or three months depending
on the average AUC value found. Therefore, the Bayesian
network for tx = 1m is used for the DOS and MEU attack
types, and the Bayesian network for tx = 3m is used for the
Malware and Defacement attack types.

Fig. 5. Average AUC values for the MEU attack type for different tx and
tg signal and ground truth time granularities.

Using a Bayesian network, assuming a dependency ex-
ists between a signal and the target class, we can ﬁnd out
the probability of having a high or low signal value when
an attack is observed or not. Furthermore, by looking at the
probability values in the conditional probability tables for
the low and high values of each signal, one may comment
on the importance of a speciﬁc signal. If a signal has a
relationship with the target class and the probabilities for its
high and low values are different for cases with and without
a cyber attack, that signal might be regarded as important.
Similarly, if the probabilities for its high and low values are
close to each other for cases with and without a cyber attack,
it has less discriminative power. For a signal to be more
discriminative, if the probability of observing its high value
is higher when a cyber attack is seen, it is expected to be
lower when there is no cyber attack.

We look at the conditional probability tables of each
signal in the Bayesian networks learned for each attack
type. For the Malware attack type, a relationship is observed
between each unconventional signal and the cyber attacks.
The values in the conditional probability table when tx is
3 months and tg is 24 hours is shown in Figure 6. When
an attack is observed, the probability of having a higher
value of TCM, TEM, GEM, GET, and GEA signal is much
higher. However, for the TCM signal, when there is no
attack, the probability of having a high and low signal value
is equal, therefore TCM is less predictive compared to other
signals when the ground truth is zero. On the other hand,
GEA tends to be lower when the ground truth is zero and
higher when the ground truth is one, therefore it is more
discriminative for the Malware attack type compared to
other signals.

The relationship of the signals and the target class for the
Defacement, DOS, and MEU attack types is shown in the
corresponding graphs in Figure 6. The tg time granularity
is 24 hours for each of the data sets used for these attack
types. The tx time granularity is one month for the DOS,
MEU, and 3 months for the Defacement attack type. Only
the unconventional signals that have a relationship with the
target class are included in the graphs. We ﬁnd that when
a Defacement attack is observed, the value of the TCM,
TEM, GEM, and GEA signals tend to be higher. For the
DOS and MEU attack types, there are fewer signals that
have a relationship with the target attack class. For the

8

Fig. 6. The probability (p) of having a low or high value of a signal when there is an attack or not. All probabilities in each graph are based on the
conditional probability tables of the Bayesian networks learned for the corresponding attack types

DOS attack type, GEM is more discriminative compared to
the GET signal, as its probabilities for the low and high
signal values are very much different when the ground
truth is 0 and 1. A similar case is observed for the MEU
attack type with the GEA signal. GEA tends to have a
lower value when the ground truth is zero, and a higher
value when the ground truth is one. Although GEM is
marked as an important signal for the MEU attack type, it is
less discriminative compared to GEA. The analysis above
provides a means to assess the quality of the signals to
discriminate positive and negative instances. This is made
possible with the use of Bayesian networks. Similar analyses
with additional unconventional signals could be helpful to
explore other important signals for different attack types.

Fig. 7. The probability (p) of observing a DOS attack depending on the
high or low values of the unconventional signals for different tx values
when tg is 24 hours.

example, to show how the quality or importance of each
signal changes with different tx. The probabilities of the
high or low values of each signal is shown in Figure 7.
GEA signal seems to be important when tx is three and
six months and it is more discriminative when tx is three
months. However, GEA is not among the signals that have
a dependency with the target class when tx is one month.
Therefore, we use the GEA signal calculated for tx = 3m
and other signals calculated for tx = 1m, to repeat the
experiment for tx = 1m. As a result, the AUC value of the
BayesNet classiﬁer increases from 0.806 to 0.824 for tx = 1m,
when GEA signal calculated with tx = 3m is used (See Table
2).

Similarly, the quality of each signal calculated with dif-
ferent tx granularities is analyzed for other attack types. For
example, when tx = 3m and tg = 24hr the AUC value
is 0.696 for the Defacement attack type (See Figure 3). The
conditional probability tables for each signal in the Bayesian
networks learned for Defacement for different tx show that
the GEM signal is more powerful when tx = 1m (See Figure
8). Therefore, the GEM signal (calculated with tx = 1m) is
used together with the remaining signals calculated with
tx = 3m and this increases the AUC value from 0.696
to 0.714. On the other hand, for the Malware and MEU
attack types, all signals that have a dependency with the
target class seem to be more predictive when tx = 3m and
tx = 1m respectively. The AUC values found when picking
up a more predictive signal with a different tx is shown in
the “Variable tx” column of Table 2 for each attack type. We
ﬁnd that depending on an entity or attack type, there might
be a beneﬁt if more discriminative signals with different tx
are used to built the Bayesian prediction model.

For a given attack type, having a higher AUC value
for a speciﬁc tx may not mean that all unconventional
signals are more discriminative for that tx. The importance
or discriminative power of a signal might also be changing
for different tx values. We use the DOS attack type as an

To cross check our ﬁndings about the importance of each
unconventional signal for each attack type, feature selection
technique is applied to the same data sets with 10 × 10 folds
cross validation. The CfsSubsetEval algorithm [27] is used
with the BestFirst search method to select more predictive

9

Fig. 8. The probability (p) of observing a Defacement attack depending on the high or low values of the unconventional signals for different tx values
when tg is 24 hours.

TABLE 2
The AUC values for the Defacement and DOS when using signals with
ﬁxed and variable tx

Defacement
DOS

Fixed tx
0.696
0.806

Variable tx
0.714
0.824

TABLE 3
The number of times each signal is selected in the 10-fold cross
validation experiment of each attack type.

Malware
Defacement
DOS
MEU

TCM TEM GEM GET GEA
0
9
0
0

2
5
10
0

1
10
0
3

10
4
10
8

1
10
1
0

signals in each data set. CfsSubsetEval selects the subsets
of signals that are highly correlated with the class in each
fold. The results for the CfsSubsetEval is shown in Table 3.
For each attack type, the number of folds a signal is selected
by CfsSubsetEval is shown for each signal. For the Malware
attack type, the GEM signal is selected in all folds and the
GET, TEM, and GEA signals are selected in at least one
fold. Similarly, signals that are differentiative according to
the conditional probability tables of the Bayesian classiﬁer
are selected by the CfsSubsetEval for other attack types.
For example, for the DOS attack type only the GEM and
GET signals are selected. Similarly, CfsSubseteval selects
the GEM and GEA signals for the MEU attack type. As
a summary, we show that the feature selection technique
conﬁrms our previous observations with the conditional
probability tables, with regards to the importance of the
unconventional signals.

one needs to use a smaller tg. In addition to DOS, which
is inherently imbalanced, other attack types may also suffer
from the imbalanced ground truth for smaller tg values. It is
always more difﬁcult for a classiﬁer to classify instances in
a highly imbalanced data set. Notice the poor performance
of the Bayesian classiﬁer (lower AUC values) for lower tg.
For instance, when tg is 6 hours, a lower AUC value is
observed for the skewed Defacement, DOS, and MEU data
sets in the Figures 3, 4, and 5. Therefore, any technique that
has a potential to improve the performance of a classiﬁer
on the imbalanced data sets is valuable. We use the widely
used techniques in the literature together with the proposed
SMOTE++ method, to check if the performance of the
Bayesian classiﬁer gets better on the imbalanced data sets.
Unless a data set has a completely uniform class distribution
it can be regarded as imbalanced, therefore existing ﬁltering
techniques and SMOTE++ are applied to all data sets for all
attack types. Some of the widely used approaches to combat
the imbalanced data set problem are:

• SMOTE: This technique generates synthetic minority
instances using k − N N algorithm [6]. One can
specify the percentage of the minority instances to
generate, to convert a highly imbalanced data set to
a completely balanced one. During our experiments,
we choose the proper percentage parameter for each
data set to make the distribution of the positive and
negative classes equal.

• Spread Sub Sample: This technique randomly sub
samples the majority class to decrease the number of
the majority instances. During our experiments, the
distribution parameter of the method is chosen to
be 1, to achieve an equal positive and negative class
distribution in the data sets.

5.4 Working with Imbalanced Cyber Data Sets
As tg gets lower, the percentage of the positive instances
decreases in all data sets. For instance, when tg is 6 hours,
only 2% and 10% of the instances are positive in the data
sets for the DOS and MEU attack types. In fact the DOS
data set is still highly imbalanced when tg is 48 hours.
Observation of a cyber incident is an abnormal situation
for a target entity, therefore most of the time the cyber data
sets are highly imbalanced. There might also be cases where

In addition to the

existing ﬁltering approaches,
SMOTE++ is used to achieve a uniform class distribution
before applying the Bayesian classiﬁer. In the SMOTE++
approach, a certain percentage of the majority instances
that are nearest to the minority instances are removed. To
visualize the changes made on a data set by SMOTE++, the
scattered view of the MEU data set instances is shown in
Figure 9.A, before any ﬁlter is applied (when tx is one month
and tg is 6 hours). Then, the scattered view of the same data
set is shown after the SMOTE ﬁlter is applied in Figure 9.B.

10

classiﬁer when tg is 6, 12, or 48 hours. For the DOS attack
type, SMOTE++ achieves a better performance compared to
SMOTE for all tx and tg values, but the differences in the
AUC are not signiﬁcant. Both methods lead to a signiﬁcant
improvement in the AUC value of the Bayesian classiﬁer for
all tg values and for almost all tx except when tx = 1m
and tg = 24hr. Although the RandomSubsample method
improves the prediction performance of the Bayesian clas-
siﬁer in some cases, in some other cases its AUC value is
comparable with the AUC value of the ordinary Bayesian
classiﬁer (See Figure 11).

For the Defacement attack type, SMOTE++ achieves the
best AUC scores in almost all cases compared to other
ﬁltering techniques but the differences are not signiﬁcant
except the cases when tg = 48hr and tx is three days or
one week. When compared to the Bayesian classiﬁer with
no ﬁltering, SMOTE and SMOTE++ leads to a signiﬁcant
improvement in the AUC values when tg is 12 and 48 hours
(See Figure 12). Similar to our ﬁndings for other attack types,
SMOTE++ achieves the highest AUC for the Malware attack
type with most of the tx and tg combinations. For some
data sets like when tx is one week and tg is 12 or 24 hours,
the improvement is signiﬁcant compared to the ordinary
BayesNet classiﬁer as it is seen in Figure 13.

6 TYPICAL RISKS FOR RESEARCH VALIDITY
In research studies there are three types of validity risks, i. e.,
internal, construct, and external that should be considered.
Below we explain the measures taken to mitigate each of
these validity risks.

If causal relationships between a dependent target and
its independent variables are not deﬁned properly in an
experiment, then its internal validity is low. Although we
use unconventional signals that are not directly related to
the target entity, we still observe a similar and encouraging
performance for all attack types with different skewness.
Observing similar promising results for all attack types
with different skewness and ground truth is important to
mitigate the internal validity threats. In addition to that,
using Bayesian networks clariﬁes the probabilistic relation-
ships between each model variable and the target class
better compared to other models, and supports the internal
validity of the experiments further. Depending on how well
an experiment or a tool measures the intended construct,
a construct validity threat might be observed. To mitigate
construct validity threats, the unconventional signal gen-
eration process is automated. External validity is related
to the consistency of the claims made in a research study.
It is hard to conclude that the results observed in this
research could be generalized. Therefore, further research
with additional unconventional signals and target entities is
needed to justify our observations.

7 CONCLUSION
This paper uses unconventional signals extracted from the
Twitter and GDELT data sources and shows that they can
be used to predict various cyber attacks for the anonymized
target entity KNOX. Furthermore, different time granulari-
ties (deﬁned as tx and tg) are used to calculate the uncon-
ventional signals and the entity ground truth for KNOX.

Fig. 9. A 2-D view of the data set for the MEU attack type before and
after the SMOTE and SMOTE++ ﬁlters are applied. The plot of the MEU
data set before any ﬁlters are applied is shown in (A). (B) shows the data
set after the SMOTE ﬁlter is applied, and (C) shows the data set after
the SMOTE++ ﬁlter is applied.

Similarly, the status of the data is shown in Figure 9.C, after
the SMOTE++ technique is applied.

We observe that the number of positive instances (dark
ones) increased after the SMOTE ﬁlter is applied, compared
to the original data set shown in Figure 9.A. A similar
situation is observed for the data set when SMOTE++ is
applied too. But, an important difference exists between
the two approaches when the highlighted parts of Figure
9.B and 9.C are considered. With SMOTE, the generated
synthetic positive instances are mixed with the existing
negative majority instances. However, when SMOTE++ is
applied, the main cluster of the positive instances does not
include that many negative majority instances.

Does cleaning the main cluster of the positive (minor-
ity) instances from the negative (majority) ones help the
Bayesian classiﬁer to separate the positive and negative
instances better? SMOTE++ is applied in parallel with other
ﬁltering techniques in the literature, to see if the perfor-
mance of the Bayesian classiﬁer is improved. During each
ﬁltering, the BayesNet classiﬁer is used with the Filtered-
Classiﬁer algorithm in Weka [26] to ensure that the test
set is not touched when a ﬁlter is applied on each data
set. Furthermore, the percentage parameter is tuned before
applying SMOTE++ to a data set. The average AUC values
of different methods, for different attack types and tx and
tg values are shown in Figures 10, 11, 12, and 13. The AUC
values of the SMOTE++, SMOTE, and the RandomSubsam-
ple are shown with dark solid (blue), light solid (green)
and dotted (blue) lines respectively. Additionally, the AUC
values of the BayesNet without any ﬁlters is shown with a
dashed (red) line in Figures 10, 11, 12, and 13.

SMOTE++ performs better than other techniques in
terms of AUC in almost all cases for all attack types and all
tx and tg time granularities. To compare different methods
and check if a difference of AUC between these methods is
signiﬁcant or not, a two tailed t-test is used with a p-value of
0.05 in all experiments. For the MEU attack type, the AUC
value of the BayesNet is around 0.5 when tg is 6, 12, or
48 hours before any ﬁlter is applied. Although we do not
observe a consistent and signiﬁcant improvement with other
ﬁltering techniques, using SMOTE++ a signiﬁcant increase
is observed in the average AUC value of the BayesNet

11

Fig. 10. Average AUC values for the data sets of the MEU attack type with different tx and tg values when SMOTE++ (S++), RandomSubsample
(SS), and SMOTE (S) ﬁlters are applied before BayesNet classiﬁer. The dashed line shows the AUC values with an ordinary BayesNet classiﬁer (B)
and the Density shows the percentage of positive instances in each data set.

Fig. 11. Average AUC values for the data sets of the DOS attack type with different tx and tg values when SMOTE++ (S++), RandomSubsample
(SS), and SMOTE (S) ﬁlters are applied before BayesNet classiﬁer. The dashed line shows the AUC values with an ordinary BayesNet classiﬁer (B)
and the Density shows the percentage of positive instances in each data set.

Each time the signals are averaged over a period of time of
length tx, to predict the cyber incidents for the succeeding
period of time of length tg. Although the extracted signals
are not explicitly related with the target entity KNOX, this
paper shows that if appropriate tx and tg time granularities
are chosen, the combined use of unconventional signals
is able to achieve 70 % AUC (Area Under ROC Curve)
performance for Malware, Defacement, DOS, and Mali-
cious Email/URL attack types for KNOX between April to
November 2016. Although the set of signals that are related

to the target attack class is different for each attack type,
GEM, GET, and GEA signals seem to be more indicative of
cyber incidents when compared to other signals used in this
study. Moreover, this work also shows that using a different
version of the same signal calculated with a different tx
could improve the overall prediction model.

Furthermore, common Machine Learning ﬁltering meth-
ods like SMOTE and RandomSubsample are used to see
if the attack prediction performance is improved when
is balanced. This work developed
a skewed data set

12

Fig. 12. Average AUC values for the data sets of the Defacement attack type with different tx and tg values when SMOTE++ (S++), RandomSub-
sample (SS), and SMOTE (S) ﬁlters are applied before BayesNet classiﬁer. The dashed line shows the AUC values with an ordinary BayesNet
classiﬁer (B) and the Density shows the percentage of positive instances in each data set.

Fig. 13. Average AUC values for the data sets of the Malware attack type with different tx and tg values when SMOTE++ (S++), RandomSubsample
(SS), and SMOTE (S) ﬁlters are applied before BayesNet classiﬁer. The dashed line shows the AUC values with an ordinary BayesNet classiﬁer (B)
and the Density shows the percentage of positive instances in each data set.

SMOTE++ that uses a hybrid approach where under sam-
pling, synthetic minority instance generation and reweigh-
ing techniques are used together to balance the distribution
of the majority and minority instances in an imbalanced
data set. We show that the performance of the Bayesian
classiﬁer on a skewed data set could be improved by making
the data set balanced. We also show that the proposed
SMOTE++ technique improves the prediction performance
for most of the data sets for different attack types and
the improvement amount is signiﬁcant in some of these

cases. As a future work we plan to use more signals from
several other open data sources and include ground truth of
different target entities. The proposed approach can be used
with additional unconventional signals to achieve a higher
forecast performance.

ACKNOWLEDGMENTS

This research is supported by the Ofﬁce of the Director of
National Intelligence (ODNI) and the Intelligence Advanced

Research Projects Activity (IARPA) via the Air Force Re-
search Laboratory (AFRL) contract number FA875016C0114.

REFERENCES

[1] PwC, “The global state of information security survey 2016,”
[Online]. Available:

[Online; accessed 6-February-2017].

2016,
http://www.pwc.ru/gsiss2016

[2] GDELT, “The gdelt project,” 2017, [Online; accessed 6-February-

[3]

2017]. [Online]. Available: http://www.gdeltproject.org/
J. Z. Bakdash, S. Hutchinson, E. G. Zaroukian, L. R. Marusich
et al., “Malware in the future? forecasting analyst detection
of cyber events,” CoRR, vol. abs/1707.03243, 2017.
[Online].
Available: http://arxiv.org/abs/1707.03243

[4] N. Ramakrishnan, P. Butler, S. Muthiah, N. Self et al., “’beating
the news’ with embers: Forecasting civil unrest using open source
indicators,” in Proceedings of the 20th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining, ser. KDD
’14. New York, NY, USA: ACM, 2014, pp. 1799–1808. [Online].
Available: http://doi.acm.org/10.1145/2623330.2623373

[5] A. Okutan, S. J. Yang, and K. McConky, “Predicting cyber attacks
with bayesian networks using unconventional signals,” in Proceed-
ings of the Cyber and Information Security Research (CISR) Conference,
2017, pp. 1–4.

[6] N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer,
“Smote: Synthetic minority over-sampling technique,” Journal Of
Artiﬁcial Intelligence Research, vol. 16, no. 1, pp. 321–357, Jun. 2002.
[Online]. Available: http://dl.acm.org/citation.cfm?id=1622407.
1622416
J. Cannady, “Artiﬁcial neural networks for misuse detection,” in
Proceedings of National Information Systems Security Conference, 1998,
pp. 443–456.

[7]

[9]

[8] C. Kruegel and T. Toth, Using Decision Trees to Improve Signature-
Berlin, Heidelberg: Springer Berlin

Based Intrusion Detection.
Heidelberg, 2003, pp. 173–191.
J. Zhang, M. Zulkernine, and A. Haque, “Random-forests-based
network intrusion detection systems,” IEEE Transactions on
Systems, Man, and Cybernetics, Part C, vol. 38, no. 5, pp.
649–659, Sep. 2008.
[Online]. Available: http://dx.doi.org/10.
1109/TSMCC.2008.923876

[10] Y. Li, J. Xia, S. Zhang, J. Yan et al., “An efﬁcient intrusion detection
system based on support vector machines and gradually
feature removal method,” Expert Systems with Applications,
vol. 39, no. 1, pp. 424–430,
[Online]. Available:
http://dx.doi.org/10.1016/j.eswa.2011.07.032

Jan. 2012.

[11] C. Livadas, R. Walsh, D. Lapsley, and W. T. Strayer, “Using ma-
chine learning techniques to identify botnet trafﬁc,” in Proceedings
of 31st IEEE Conference on Local Computer Networks, Nov 2006, pp.
967–974.

[12] D. E. Denning, “An intrusion-detection model,” IEEE Transactions

on Software Engineering, vol. SE-13, no. 2, pp. 222–232, Feb 1987.

[13] R. P. Lippmann and R. K. Cunningham, “Improving intrusion
detection performance using keyword selection and neural net-
works,” Computer Networks, vol. 34, p. 2000, 2000.

[14] M. Blowers and J. Williams, Machine Learning Applied to Cyber
Operations. New York, NY: Springer New York, 2014, pp. 155–
175.

[15] L. Bilge, S. Sen, D. Balzarotti, E. Kirda, and C. Kruegel, “Exposure:
A passive dns analysis service to detect and report malicious
domains,” ACM Transactions on Information and System Security,
vol. 16, no. 4, pp. 14:1–14:28, Apr. 2014. [Online]. Available:
http://doi.acm.org/10.1145/2584679

[16] C. Kruegel, D. Mutz, W. Robertson, and F. Valeur, “Bayesian event
classiﬁcation for intrusion detection,” in Proceedings of 19th Annual
Computer Security Applications Conference, Dec 2003, pp. 14–23.
[17] S. J. Yang, H. Du, J. Holsopple, and M. Sudit, “Attack projection,”
in Cyber Defense and Situational Awareness, 2014, pp. 239–261.

[18] L. Wang, A. Liu, and S.

Jajodia, “Using attack graphs for
correlating, hypothesizing, and predicting intrusion alerts,”
Computer Communications, vol. 29, no. 15, pp. 2917–2933, Sep.
2006. [Online]. Available: http://dx.doi.org/10.1016/j.comcom.
2006.04.001

[19] X. Qin and W. Lee, “Attack plan recognition and prediction
using causal networks,” in Proceedings of the 20th Annual Computer
Security Applications Conference, Dec 2004, pp. 370–379.

13

[20] B. C. Cheng, G. T. Liao, C. C. Huang, and M. T. Yu, “A novel
probabilistic matching algorithm for multi-stage attack forecasts,”
IEEE Journal on Selected Areas in Communications, vol. 29, no. 7, pp.
1438–1448, August 2011.

[21] D. S. Fava, S. R. Byers, and S. J. Yang, “Projecting cyberattacks
through variable-length markov models,” IEEE Transactions on
Information Forensics and Security, vol. 3, no. 3, pp. 359–369, Sept
2008.

[22] G. Werner, S. Yang, and K. McConky, “Time series forecasting of
cyber attack intensity,” in Proceedings of the 12th Annual Conference
on Cyber and Information Security Research, ser. CISRC ’17. New
York, NY, USA: ACM, 2017, pp. 18:1–18:3. [Online]. Available:
http://doi.acm.org/10.1145/3064814.3064831

[23] N. Silver, The Signal and the Noise: Why So Many Predictions Fail-but

Some Don’t. Penguin Publishing Group, 2012.

[24] P. E. Tetlock and D. Gardner, Superforecasting: The Art and Science of
Prediction. New York, NY, USA: Crown Publishing Group, 2015.
[25] S. Dua and X. Du, Data Mining and Machine Learning in Cybersecu-
rity, 1st ed. Boston, MA, USA: Auerbach Publications, 2011.
[26] M. Hall, E. Frank, G. Holmes, B. Pfahringer et al., “The
weka data mining software: An update,” SIGKDD Explorations,
vol. 11, no. 1, pp. 10–18, Nov. 2009.
[Online]. Available:
http://doi.acm.org/10.1145/1656274.1656278

[27] M. A. Hall, “Correlation-based feature subset selection for ma-
chine learning,” Ph.D. dissertation, University of Waikato, Hamil-
ton, New Zealand, 1998.

Ahmet Okutan Dr. Ahmet Okutan received
his B.S.degree in Computer Engineering from
Bosphorus University, Istanbul, Turkey in 1998.
He received his M.S. and Ph.D. degrees in
Computer Engineering from Isik University, Is-
tanbul, Turkey in 2002 and 2008 respectively.
Dr. Okutan is currently a Post Doctoral Re-
search Fellow in the Computer Engineering De-
partment at Rochester Institute of Technology.
He worked as analyst, architect, developer, and
project manager in more than 20 large scale
software projects. He has professional experience regarding software
design and development, mobile application development, database
management systems, and web technologies for more than 18 years.
His current research interests include cyber attack forecasting, software
quality prediction and software defectiveness prediction.

Shanchieh Jay Yang Dr. S. Jay Yang received
his B.S. degree in Electronics Engineering from
National Chiao-Tung University, Hsin-Chu, Tai-
wan in 1995, and his M.S. and Ph.D. degrees
in Electrical and Computer Engineering from
the University of Texas at Austin in, 1998 and
2001, respectively. He is currently a Professor
and the Department Head for the Department
of Computer Engineering at RIT. He and his
research group has developed several systems
and frameworks in the area of cyber attack mod-
eling for predictive situation, threat and impact assessment. He has
published more than sixty papers and was invited as a keynote speaker,
a panelist, and a guest speaker in various venues. He was a co-chair for
IEEE Joint Communications and Aerospace Chapter in Rochester NY
in 2005, when the chapter was recognized as an Outstanding Chapter
of Region 1. He has also contributed to the development of two Ph.D.
programs at RIT, and received Norman A. Miles Award for Academic
Excellence in Teaching in 2007.

Katie McConky Dr. Katie McConky received her
B.S. and M.S. degrees in Industrial Engineering
from Rochester Institute of Technology in 2005
and 2007 respectively, and her Ph.D. in Industrial
Engineering from SUNY Buffalo in 2013. Dr. Mc-
Conky is currently an Assistant Professor in the
Industrial and Systems Engineering Department
at Rochester Institute of Technology, and has
seven years of industry experience working in
the ﬁelds of information fusion and predictive
data science prior to joining RIT. Currently Dr.
McConky‘s research work focuses on applying operations research and
data analytic techniques to energy and security applications, including
cyber security.

