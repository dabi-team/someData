1
2
0
2

t
c
O
9
1

]

R
C
.
s
c
[

1
v
5
6
7
1
1
.
0
1
1
2
:
v
i
X
r
a

MOTENS: A PEDAGOGICAL DESIGN MODEL FOR SERIOUS
CYBER GAMES

Stephen Hart∗

Electronics and Computer Science
University of Southampton
University Road
Southampton
United Kingdom
SO17 1BJ
stephen.hart@soton.ac.uk

Basel Halak
Electronics and Computer Science
University of Southampton
University Road
Southampton
United Kingdom
SO17 1BJ
Basel.Halak@soton.ac.uk

Vladimiro Sassone
Electronics and Computer Science
University of Southampton
University Road
Southampton
United Kingdom
SO17 1BJ
vsassone@soton.ac.uk

October 25, 2021

ABSTRACT

In the last few years, serious games have become popular, with a consensus of the beneﬁts for
teaching cyber security awareness and education. However, there is still a lack of pedagogical
driven methodologies and tools to support serious games design to ensure they achieve the learning
objectives. This paper proposes MOTENS, a pedagogical model, to design serious cyber games based
on the gaps we identiﬁed in the current games design models and the lessons learnt from creating a
serious tabletop game called Riskio, designed to teach cyber security awareness and education. The
MOTENS model has six high-level components. Five components are linked to the games/design
mechanics, and one component, ‘Theory’, that supports the design’s cognitive principles, including
players’ motivation. The model is used to design serious cyber games and goes through ﬁve stages,
from identifying and segmenting target players, steps to creating game mechanics linked to pedagogy
instruction and then to testing to create a serious game that is designed to achieve the games learning
objectives.

Keywords Serious gaming · Cyber security education · Gamiﬁcation · Design · Training effectiveness

1

Introduction

In the last few years, serious games have become popular based on gamiﬁcation principles, which is about applying
game mechanics to non-gaming activities, for example, training to make the activity more engaging [Routledge, 2016].
Serious games use these techniques to provide a fun, enjoyable educational environment where the game participants
learn by playing the game. Using serious games has become a technique used in various contexts to motivate people to
engage in mainly targeted behaviours [Landers, 2014]. Serious games as an approach that can complement instruction-
led or computer-based cyber security education training [Hart et al., 2020]. For example, there have been many media

∗Corresponding author.

 
 
 
 
 
 
MOTENS: A Pedagogical Design Model

reports of attacks against large and small organisations, causing ﬁnancial losses and reputational damage as a response
to increasing cyber attacks [Buil-Gil et al., 2021]. Organisations invest in professional training courses for their
employees to raise awareness of cyber attacks and related defences. However, these traditional courses have failed in
effectively educating employees, as testiﬁed by the increasing number of successful cyber attacks exploiting human
factors [Angafor et al., 2020]. The traditional approach to education does not present problems to students but presents
contents to resolve problems. In 1994 research survey with academic staff (n = 65) found that only 27% gave high
rating in considering the ‘learner’, where content scored 65% [Seng Tan*, 2004]. It is fundamental for organisations to
ensure that all employees are educated on cyber security concepts and aware of the risks posed by even the simplest
cyber attacks, e.g. phishing emails. Organisations have used tailored training and awareness programs to improve the
resilience to cyber attacks against their employees’. Serious cyber games can only do this if designed to create an
adaptive learning experience such as role-playing, simulations, and self-paced or team-based exercises [Greitzer et al.,
2007] and move to problem-based learning. The main drive to problem-based is an emphasis on solving real-world
problems [Seng Tan*, 2004]. Threat actors are continuously improving their cyber weapons to timely and effectively
exploit vulnerabilities [Hart et al., 2020]. Problem-based learning has been criticised for its emphasis on Bloom’s
[Bloom et al., 1956] higher order thinking skills at the expense of lower-order skills and knowledge acquisition [Hung
et al., 2008]. Serious cyber games can provide a good environment for self-learning. However, they must be designed
using cognitive principles for effective learning [Greitzer et al., 2007].

There is consensus on the beneﬁts to the potential use of serious cyber games for awareness and education [Arnab et al.,
2015]. However, there is still a lack of pedagogical driven methodologies and tools to support serious games [Arnab
et al., 2015]. Some of the critical issues with pedagogical models: they do not link game mechanics to the learning
objectives; high-level model and will not assist in the selection of game mechanics to achieve serious game objectives;
or are mainly assessed in terms of the quality of their content, not in terms of their intention-based design [Mitgutsch
and Alvarado, 2012]. For example, the GOM Model [Amory, 2007] describes a relationship between the pedagogical
dimensions of learning and game elements but has no concept for the design principles of education games [Amory
and Seagram, 2003]. The SGDAF model [Mitgutsch and Alvarado, 2012] does not link learning mechanics to game
mechanics and LM-GM [Arnab et al., 2015], which proved to be effective at mapping the pedagogical principles for
serious cyber games. Still, it is complex to understand and proven to take time to learn.

This paper proposes a new pedagogical model to design serious cyber games for awareness and education called
MOTENS. This was created based on the gaps identiﬁed in the current games and experience of lessons learnt from the
creation of Riskio [Hart et al., 2020]. The model was designed to assist design serious cyber games for education and
awareness rather than other categories of serious games, for example, secure software development.

The rest of this paper is organised as follows.
section 2 outlines the cognitive principles that support gamiﬁ-
cation. section 3 proposes a new pedagogical model for serious cyber games design based on gaps identiﬁed in section 2.
section 4 is an illustrative case study to test the efﬁcacy of the MOTENS Model. section 5 is a second case study is
comparative case study to validate the proposed model against another model. Finally, section 6 concludes the paper.

2 Cognitive Principles

In this section we present the cognitive principles that supports gamiﬁcation and learning theory and then identify gaps
in current models and use game we created called Riskio [Hart et al., 2020] to map to serious games design models.

2.1 Essentials for learning

Robsen et al proposed a psychology model behind the promise of gamiﬁcation, which includes three principles for
creating gamiﬁcation experiences: mechanics, dynamics, and emotions (MDE) [Robson et al., 2015]. Mechanics (i.e.,
the goals, rules, and rewards), dynamics (i.e., how players interact with the game mechanics), and emotions (i.e., how
players feel toward the game playing experience). The game mechanics requirements can change based on games
players, for example, in the Riskio study students wanted more game-like play in the game mechanics and wanted the
attack suit to be random. In contrast, employees were happy with game mechanics, where they were allowed to select
the attack suit [Hart et al., 2020]. The dynamics are about how the player progresses in the game mechanics and how
they feel about the interaction. In-game design, ‘aesthetics’ describes the desirable emotional response [Robson et al.,
2015]. The graphic design, quality of illustration, can signiﬁcantly affect the initial emotional reception of the game.
The players’ emotional positive response when players played the Riskio card game with a professionally printed card
deck opposed to early home printed versions. It was noticed by the players who played with the previous versions
of the game, who commented quality of the professional designed and printed card decks over previous quality of
the card decks. Serious cyber games can create positive and negative emotions of players. However, there is little

2

MOTENS: A Pedagogical Design Model

guidance on how to create these emotional experiences [Mullins and Sabherwal, 2020] and how gamiﬁcation can
enhance user engagement remains unclear [Suh et al., 2018]. In the 1970s, several research pieces into intrinsic and
extrinsic motivation found that students paid to perform some task were less likely to complete the task in free time
[Sansone and Harackiewicz, 2000]. A person is said to be intrinsically motivated in an activity when they receive no
reward and only satisfaction in the activity and for extrinsic motivation to obtain a reward or to avoid punishment [Enzle
and Ross, 1978]. Cognitive evaluation theory (CET) is a sub-theory of the self-determination theory (SDT) [Deci and
Ryan, 2008] and explains how individuals’ intrinsic motivations are affected by external factors [Suh et al., 2018, Enzle
and Ross, 1978]. In the context of gamiﬁcation for cyber security awareness and education, if players feel forced by
external factors, they have to play the game, affecting the players’ intrinsic motivation. The work of cognitively oriented
learning theorists argues the importance of intrinsic motivation [Malone and Lepper, 2005]. The serious game intrinsic
motivation that the players value the knowledge they obtain playing the game, as can be seen, must help the players’
extrinsic motivation.

2.2 Constructivism learning theory

Cognitive constructivism learning theory considers that “we construct our perspective of worlds through individual
experiences and schema.” [Ros et al., 2020]. That is a cognitive framework of thought or behaviour that organises
categories of information and their relationships. The game players will choose their learning routes and compete against
each other to reach higher levels of knowledge [Bíró, 2014]. There is no single constructivist theory of instruction, rather
a multitude of approaches, and it can be seen as providing an alternative set of values to instructional theory [Driscoll,
2000]. Gagné’s theory of instruction [Driscoll, 2000] is made up of three components: 1) Taxonomy of learning
outcomes: There is a distinction between declarative and procedural knowledge. Declarative knowledge refers to the
facts you remember, which is Bloom’s lower order think skills [Bloom et al., 1956] as opposed to procedural, which
refers to cognitive skills and Bloom’s higher-order thinking skills, which should be the objective of gamiﬁcation to
achieve higher-order thinking. 2) Conditions for learning: The learning conditions are critically linked to the learning
outcomes, and for each objective, the conditions required must be considered to achieve the objective. 3) Nine events of
instruction: Gagné’s nine events for instruction is the same as methods for instruction in constructivism. Not all nine
instructional events need to be deployed. This would depend on the objective, but some may always be required, for
example, feedback. See Table 1, the nine events and Gagné belief most lessons should follow the sequence, but he
recognised not absolute [Gagne and Driscoll, 1988].

Internal Process

Instructional Event

Action

Reception

Expectancy

Retrieval to
working memory

1. Gaining attention
2. Information learners of the
objective
3. Stimulating recall of prior
learning

Selective perception

4. Presenting the content

5. Providing “Learning
guidance”
6. Eliciting performance
7. Providing feedback

8. Assessing performance

Semantic encoding

Responding
Reinforcement
Retrieval and
reinforcement
Retrieval and
generalisation

Use abrupt stimulus change
Tell learners what they will do after
learning
Ask for recall of previously learned
knowledge
Display the content with distinctive
features
Suggest a meaningful organisation

Ask learner to perform
Give information feedback
Require additional learner
performance with feedback
Provide varied practice and spaced
reviews

9. Enhancing retention
and transfer
Table 1: Gagné’s Nine Events for Instruction

In conclusion, gamiﬁcation learning theory views the learner as one of the most important actors in the learning
process [Bíró, 2014]. The cognitive principle of the learner motivation can be addressed by using Self Determination
Theory (SDT) [Deci and Ryan, 2008] which presents motivation as intrinsic motivation that emerges from the enjoyment
of the game, and extrinsic motivation created outside of the game by workplace rules etc. [Unkelos-Shpigel and Hadar,
2015]. Constructivism theory could be used for instruction methods; learning objectives; and conditions for instruction
to pedagogical approach to serious games design. It is using cognitive principles to create a pedagogical model for the
design of serious cyber games.

3

MOTENS: A Pedagogical Design Model

Figure 1: GOM Model

Figure 2: SGDAF Model

2.3 Gaps in current design models

This section uses three current serious games assessment models to explain the limitations in these models in creating
serious cyber games and how to verify the game can achieve stated learning objectives. We select one model for further
assessment using a serious cyber game called Riskio. The ﬁrst step was to select a published model to apply to Riskio
to verify the serious game meets the learning objectives. Three models were considered, the Game Object Model
(GOM) [Amory, 2007], The Serious Game Design Assessment Framework (SGDAF) [Mitgutsch and Alvarado, 2012]
and LM-GM Model [Arnab et al., 2015].

The GOM model, see Figure 1 is based on a constructivist theoretical framework to support serious educational games
development. The GOM model’s ﬁve components do not show how they inﬂuence each other [Arnab et al., 2015]
and how the components link to the game mechanics and, therefore, the serious game learning objectives. The GOM
is a high-level model and will not assist in the selection of game mechanics to achieve serious game objectives and
therefore, this model was excluded from the next stage testing model with Riskio game.

The SGDAF model in Figure 2, requires going through all the seven steps: 1) Purpose; 2) Content / Information; 3)
Mechanic; 4) Fiction / Narrative; 5) Aesthetics Graphics; 6) Framing; and 7) Cohesiveness & Coherence of Game.
While applying the SGDAF model to Riskio, many elements were useful when reviewing against Riskio lessons learnt
in the game design. For example, in step ﬁve, the aesthetics and graphics in so far, the quality of cards affected the
players’ enjoyment. Early versions of the game did not have professionally designed and printed cards, and players
noted this in comments. This is an example where design was identiﬁed in (step 5, aesthetics & graphics) the SGDAF
Model but not in the GOM Model. However, SGDAF had a similar problem to the GOM model as in step 3 the model
provides no mechanism to map the game mechanics to the learning objectives and excluded from the next stage.

Both the GOM Model and the SGDAF Model were rejected because of the lack of methodology linking game mechanics
back to the learning mechanics and the serious educational objectives of a serious cyber game. The LM-GM model was
selected to create an illustrative case study using Riskio.

The LM-GM Model, see Figure 3 was created on the assumption of the fundamental design of serious games relies
on the translation of learning goals into the mechanical element of the gameplay [Arnab et al., 2015]. The LM-GM
was created to overcome the missing descriptive relationship between learning mechanics and game mechanics. The
LM-GM Model also maps the game mechanics to Bloom´s ordered thinking skills. The initial review of LM-GM Model
against the components identiﬁed in the literature review showed that the LM-GM model had the potential to cover all
the areas identiﬁed in the review.

The LM-GM model is viewed as having two axes. The horizontal axis links learning mechanics analogous to game
mechanics. The vertical axis run down two root nodes learning mechanics and game mechanics, each with side
leaf nodes. The model is descriptive rather than prescriptive and allows users to relate learning mechanics to game
mechanics. The abstract game elements (Game Mechanics) can be mapped many-to-one to the concrete game elements,

4

MOTENS: A Pedagogical Design Model

Figure 3: LM-GM Model

and single-game Learning Objective can be achieved through different learning activities (Learning Mechanics). A
single game dynamic/learning objective can be achieved through several game mechanics. Arnab et el (2014) tested
the LM-GM model with a second model Amory’s GOM [Amory, 2007] to evaluate how effective the models were
at enabling users to analyse the game. Arnab et al [Arnab et al., 2015] second analysis with 26 individuals with a
mixture of academics, students and game developers tested perceptions on usefulness of LM-GM and GOM models.
The participants were asked to complete a suitability usability scale (SUS) which comprised of 10 questions. The
overall SUS average score for LM-GM was 67.3 and GOM SUS average was 46.7. The second study with 25 ﬁnal
year engineering students with no gaming experience for LM-GM average SUS 71.4 and GOM average SUS 43.7.
Participants found GOM easier to use than LM-GM but GOM did not identify basic pedagogical game patterns.
However, the LM-GM model should be made easier to use. Participants in the Arnab et al study conﬁrmed our view that
the GOM model does not address how to implement learning objectives or map learning mechanics to game mechanics
as the LM-GM does. The participants found the GOM model was much easier to understand that LM-GM model should
be made easier to understand.

The LM-GM Model was selected for the next stage to map against the Riskio game to verify the model and test with
selected University staff who understand pedagogical frameworks to verify the proposed LM-GM Model using an
illustrative case study.

Riskio LM-GM Model illustrative case study. We started by mapping LM-GM Model using one learning objective
from the Riskio game to show the complicated relationship between learning mechanics and game mechanics. Riskio
is a game where players identify threats on a game board, and we used this learning objective to map to the LM-GM
model, see Figure 4 for an example of one Riskio game objective.

Using the LM-GM model to test the evaluation of the Riskio game, it took several hours to reﬁne the evaluated model
before it was to an acceptable level. Figure 5 which links Riskio gameplay/mechanics to the LM-GM Model and
Figure 6 shows the Riskio game play/mechanics linked to the LM-GM Model. The Riskio game mapped to the LM-GM
model was put into an illustrative case study to test the model’s understanding with University lecturers in cyber security
and cyber professionals. The feedback was they found the LM-GM model difﬁcult to understand. There seemed to be

5

MOTENS: A Pedagogical Design Model

Figure 4: Links between model components

confusion over the nodes and leafs in the model and the horizontal relationship between learning and game mechanics.
Other issues noted with the mapping Riskio gameplay, see Figure 5 and 6, the mapping does not link the gameplay to
the cognitive theory.

Figure 5: Riskio Game Play and Links to LM-GM Model

Conclusions on Assessment of Three Pedagogical Models. Some of the pedagogical models do not link game
mechanics to the learning objectives, for example, GOM and SGDAF. Using the LM-GM Model, we were able to link
learning objective to game mechanics and the learning objective, see Figure 4. Although the LM-GM Model proved
useful in mapping the pedagogical principles for serious cyber games, it took considerable time to learn the model or
even explain it. The next step we try to create a model that can map pedagogical principles and link game mechanics.

3 MOTENS Model

In this section, we propose a new pedagogical model called MOTENS for serious cyber games and how the model can
be linked from the game mechanics to the pedagogical theory of learning.

6

MOTENS: A Pedagogical Design Model

Figure 6: Riskio Game Play

3.1 MOTENS Model

The MOTENS model, see Figure 7 was created based on the gaps identiﬁed in the current games for pedagogical for
design of serious games for cyber security awareness and education and experience of lessons learnt from the creation

7

MOTENS: A Pedagogical Design Model

of Riskio. The model is designed for the assessment of serious cyber games rather than other types of serious games for
education.

The MOTENS model is made up of six high-level components, ﬁve of the components can be directly linked to the
games design/mechanics and one component ‘Theory’ which is the supporting the cognitive principles of the design,
including players’ motivation.

Figure 7: MOTENS Model

Multiple Modes of Learning The game mechanics that provide opportunities to learn a wide range of attacks

and defences with players from different backgrounds.

Ownership Self-Learning

Provide different game scenarios to meet learning objectives.

Theory

Environment

Negotiation

Self-Learning

The theory that supports the design.

Create a game play for players in a game setting they understand and appropriate
learning environment.

Change the role from teacher to coaching not lecturing and from content delivery
to problem-based learning.

To create self-learning by use of problem-based learning; learning hierarchy; and
build on players current knowledge.

3.2 MOTENS Design Stages

To design and create a serious cyber game the proposed model takes you through the following design stages:

Stage 1: Target Game Players to identify and segment your target players into non-gamers and gamers. For example,
Riskio primary target for game was Students, identiﬁed as gamers, with secondary group employees as non-gamers.

Stage 2: What game you want to create, decide category either Secure Software development or Security Awareness
and Education and then decide the types of serious game: Card Games, Computer Games; Board/Table Games; or
Speciality Games. Decide if your game will have a games master.

8

MOTENS: A Pedagogical Design Model

Stage 3: Create initial MOTENS Design/Mechanics map. For example, it was noted that in mapping Riskio difference
between Students and Employees with D11) Players Current Knowledge. Students’ intrinsic motivation to accomplish
and play the game was to want a high gamiﬁcation level with a random selection of the attack card category. In contrast,
employees wanted to learn and low gamiﬁcation and select the attack category.

Stage 4: Design the Game, create the game using MOTENS model. Go through ﬁve steps to design the game. Step 1,
the initial design decisions. Step 2, decide the pre-game process. Step 3, design game play. Step 4, design end of game
process, and Step 5 review and test gameplay. Brief examples using Riskio: Step 1, Use Microsoft STRIDE for threat
model and for the defence cards NIST [National Institute of Standards and Technologies (NIST)] and NCSC [NCSE,
2020] frameworks . Step 2, before playing Riskio tutorial on Microsoft STRIDE for all players. Step 3, identiﬁed
different requirement to allow employees to select the attack card category. Step 4, allow time for players to discuss
the game at the end of each round. Step 5, players had difﬁculty holding all cards, change the design to print attack
category on the back of the card and only select one card at a time.

Stage 5: Test and Evaluate by testing the game by playing with target players and changing design/mechanics if
required from player feedback.

3.3 Pedagogical Principles - MOTENS Model (Theory)

In this section, we explain the pedagogical principles of the MOTENS Model. It is acknowledged that serious cyber
games can provide an environment, that motivates player’s to learn, however, an entertaining and fun serious game
does not necessarily mean playing the game meets the objectives of the game [Rooney, 2012]. For this reason, the
pedagogical model must integrate the gameplay supported by theory to ensure the games learning objectives are met.
This section explains using Riskio game how the MOTENS Model supports both the serious game design and how this
is supported by pedagogical learning theory.

T1) Learning Hierarchy. Learners will sometimes memorise information without understanding the concept. For
example, they may be able to recite what a Distributed Denial Service Attack (DDoS) is but not comprehend its meaning,
and this would be an example of Bloom’s taxonomy of lower-level thinking, [Bloom et al., 1956]. Gagné’s proposed a
‘learning hierarchy a set of component skills that must be learned before the complex skill can be learned’ [Gagne and
Briggs, 1992]. Using the DDoS example, learners understand the issues around the ‘availability’ of systems, understand
what a distributed attack is, and understand what a denial of service attack is. Learning these three components should
join together to understand a DDoS attack and example in Bloom’s taxonomy of higher-order thinking skills.

T2) Accountability Versus Responsibility.
In serious games, accountability is the opposite of responsibility [Mayer
et al., 2014]. For players to be accountable, they must know the reason for playing the game and the effects or
consequences of playing the game. In contrast, responsibility is to critically reﬂect on the short and long-term value
and consequences for playing. [McGonigal, 2011] and this is important in getting the players thinking from Bloom’s
lower-order thinking skills of retention through high-order skills of understanding, applying, and evaluating to creating.
For accountability the games rules and learning objectives must be clear to the players and for responsibility the players
must value the learning objectives.

T3) Constructivism. Constructivist learning theory states that the learning process is unique by the learner and
gamiﬁcation theory looks at the learning process, which is from two different points of view at the same time, the
ﬁrst view uses individual perspective and second view from community-based learning [Bíró, 2014]. Any theory of
instruction needs to include: methods of instruction; learning objectives; and conditions for instruction [Driscoll, 2000]
and consider both these perspectives.

Methods of Instruction. The constructivism theory is based on the belief that learning occurs as learners are actively
involved in the process of meaning and knowledge construction as opposed to passively receiving information [Fosnot
and Perry, 1996], constructivist-oriented approach concentrates on the learners constructing their understanding during
social interactions [Maor, 1999]. Therefore, the use of gamiﬁcation, to teach cyber security awareness and education
the game must promote the interactions that increase the discourse and personal construction. In the design of Riskio
game we followed the principles of constructivism [Hart et al., 2020], which has been the predominant learning theory
used in education programs for young children, college and university students [Fosnot and Perry, 1996, Rolloff, 2010].

In a constructivist learning environment, learners work primarily in groups and learning and knowledge are interactive,
and facts and knowledge change with experience [Bada and Olusegun, 2015]. There are a signiﬁcant focus and emphasis
on social and communication skills and collaboration and exchange of ideas. This is contrary to the traditional learning
environments where learners work primarily alone. Learning is achieved through repetition. The subjects are strictly

9

MOTENS: A Pedagogical Design Model

adhered to and guided by a textbook. Driscoll [Driscoll, 2000] summarised the ﬁve conditions for instruction for
constructivism are: (C1) complex and relevant learning environment; (C2) social negotiation; (C3) multiple perspectives
and multiple modes of learning; (C4) ownership in learning; and (C5) self-awareness and knowledge construction, see
Table 2 an example links between, constructivist ﬁve conditions, MOTENS Model and Riskio game mechanics.

Link to MOTENS Model

Example in Riskio

Constructivist
Conditions
C1: Complex and relevant
learning

C2: Social negotiation

Environment: D5) Security
Defences

Negotiation: D10)
Opportunity to Discuss
Game Play

C3: Multiple perspectives
and multiple modes of
learning

Multiple Modes of Learning:
D1) Game Mechanics

C4: Ownership in learning

Ownership Self-Learning:
D2) Different Game
Scenarios

C5: Self-awareness and
knowledge construction

Negotiation: D7) Role of
Games Master

Players using Riskio defence
deck can learn complex and
basic defences
End of each round of attack
and defence games master
encourages players to
discuss and learn from other
players
Each Riskio game board can
provide multiple metaphors
and analogies and multiple
interpretations, the hallmark
of Cognitive Flexibility
Theory [Spiro et al., 2003]
this can be done in Riskio
with different case studies
that support the game board
to give different perspectives
Riskio can be played with
different game scenarios,
having contextualised game
objectives players are
encouraged to self-learn,
however concern not all
students achieve "buy-in"
[Perkins, 1991]
Games master helping
players become aware of
thinking process, what
theorist call metacognition
[Driscoll, 2000]

Table 2: Constructivist Conditions linked to MOTENS with Riskio Example

Game Learning Objectives. The constructivist approach to identifying the learning goals, emphasises the learning
context it is not to assure that students know particular things, but rather to show them how to construct plausible
interpretations [Bednar et al., 1992]. Using the constructivist approach the following objectives were identiﬁed for the
pedagogical model for serious cyber games: Transfer Knowledge (TK) - Applying knowledge to other acquired skills;
Serious Games Types (SGT) - The model can be used for desired game types; Authentic Learning (AL) - Linked to
real-world learning; Ownership Self-Learning (OSL) - Active Self learning; Game Environment (GE) - Game scenarios
appropriate learning environment; Intrinsic Motivation (IM) - Ability to play game (Gamers) or provides learning
(non-gamers); and Extrinsic Motivation (EM) - Knowledge that is valued.

Conditions of Instruction. We proposed using hypermedia designs, collaborative learning, problem scaffolding, and
problem-based learning to create constructivist conditions for instruction. Examples of how implemented in Riskio game:
Hypermedia Designs the use of game boards that are a small but complete subset of real environments; Collaborative
Learning provide an opportunity for players to discuss at the end of each round the attack and various different defences
used; Problem Scaffolding interactions between the payers and the games master can provide different levels of support
and Problem Based Learning case studies supporting games board can state problems that players need to decide how
to defend.

Link to Gagné Nine Instructional Events. The nine instructional events can be mapped to the MOTENS model, using
Riskio gameplay as an example. 1) gaining attention, 2) Inform learners of objective: Tutorial at start of the game;

10

MOTENS: A Pedagogical Design Model

3) Simulate recall of prior learning: Discussion at the end of each round and end of the game; 4) Presenting content:
Using graphics and icons on game board understood by players; 5) Proving learning guidance: Using games board that
are relevant to the players; 6) Eliciting performance: Players try to ﬁnd most economical defence; 7) Proving feedback:
Games master giving feedback on attacks and defence; 8) Assessing performance: and 9) Enhancing retention and
transfer: Games master can act as an attacker using information deck.

T4) Gamiﬁcation. Gamiﬁcation is about applying game mechanics to non-gaming activities, for example, training to
make the activity more engaging [Routledge, 2016]. Serious games use these techniques to provide a fun, enjoyable
educational environment where the game participants learn by playing the game. Gamiﬁcation does not mean game
design requires designers to concentrate on competitive features in the design between players. Studies have proven a
positive inﬂuence of serious games using gamiﬁed cooperation to create meaningful connections amongst players, and
it facilitates similar learning, and motivational outcomes as gamiﬁed competition [Dindar et al., 2021]. In MOTENS
design stage 3 (see subsection 3.2) creates a design/mechanics map to consider selecting the correct gamiﬁed content
for the game to meet target players requirements.

T5) Self-Determination Theory. Deci and Ryan [Deci and Ryan, 2008] proposed a macro-theory called Self-
Determination Theory (SDT). although the work started on SDT in the 1970s it can be applied today to gamiﬁcation.
SDT presents motivation as extrinsic motivation, the external factors, and intrinsic motivation, the internal factors. SDT
also presents three basic psychological needs: Competence - Can perform activity well; Autonomy - Feeling you are in
control; and Relatedness - Sense of belonging. To be intrinsically motivated all three needs to be satisﬁed and extrinsic
motivation needs at least competence and relatedness must be satisﬁed [Conejo et al., 2019]. Conejo & Hounsell
[Conejo et al., 2019] propose a modiﬁcation to the existing framework to assist designers of games. They suggest that
some game design frameworks address motivation superﬁcially, while others focus exclusively on motivation. Table 3
shows example of links between SDT theory, MOTENS Model, see Figure 8 and the Riskio game.

SDT Theory

Competence

Autonomy

Relatedness

Link to MOTENS Model
Multiple Modes or Learning:
D11) Players Current
Knowledge
Negotiation: D8) Role Play as
Attacker; D9) Role Play as
Defender
Ownership Self-Learning: D2)
Different Game Scenarios

Example in Riskio

Riskio game difﬁculty levels,
enables all players to be able to
ﬁnd attacks and defences
Players are able to select the
category of attack and defence
cards
Games boards can be changed
to relate to players work
learning objectives

Table 3: SDT linked to MOTENS with Riskio Example

3.4 MOTENS Game Mechanics

In this section, we explain the ﬁve components of the MOTENS Model linked to games design/mechanics.

D1) Game Mechanics.
In design stage 1 of the design you segment the players into gamers and non-gamers and
important that you select the correct level gamiﬁed content for target players. For example, students (identiﬁed as
gamers) might want random selection of threat category by throwing a dice, whereas non-gamers will want to select
threat category.

D2) Different Game Scenarios. You can select different game scenarios, for example in Riskio [Hart et al., 2020] we
used University Fees Ofﬁce as this proved most popular with player but could use network diagrams or other ﬁctional
settings.

D3) Threat Modeling. This is where you select a threat model for example in Riskio we used Microsoft STRIDE as
suited our learning objectives, but you might want to use different model for example serious game about hardware
supply chain use CIST [Halak, 2021] a threat model created for hardware supply chain.

D4) Security Threats. The game must expose the players to the most common threats and for example for Riskio we
identiﬁed in cyber security reports (e.g. by SANS and Symantec), security guidance (e.g. by NCSC or NIST), and
security practices (e.g. by OWASP).

11

MOTENS: A Pedagogical Design Model

Figure 8: MOTENS Model Linked to Theory and Game Mechanics

D5) Security Defences. The game defences should be based on a wide range of attacks and countermeasures.
Published frameworks should be used to build on players knowledge for example: NCSC Cyber Essentials [NCSE,
2020], and 10 Steps to Cyber Security [NCSC, 2021].

12

MOTENS: A Pedagogical Design Model

D6) Design and Graphics.
In design stage 4 you should not only test the game mechanics and game play but verify
the design and graphics. The quality of design of logos, cards and icons etc. can affect the players’ enjoyment of
the game and this was noted in playing early version of Riskio with home printed cards. All graphics should be
professionally designed, created, and high quality printed where required.

D7) Role of Games Master.
If the game has a games master, their role is not to provide knowledge to the learners,
but to prompt and facilitate discussion. This can be done by designing stages in game play that facilitate discussion.
The games master encourage learners inquiry by asking thoughtful, open-ended questions and encouraging learners to
ask questions of each other; seek elaboration of learners’ initial responses; encourage learners to engage in dialogue,
both with the games master and with one another (C4: Ownership in learning, see Table 2).

D8) Role play as Attacker. The design should convey the breadth of vulnerabilities and attack methodologies that
can be exploited by attackers.

D9) Role play as Defender. The design should improve the understanding of the diversity of possible countermeasures
that can be considered to prevent, detect, or mitigate cyber attacks. Players should learn the different defence strategies
and not all attacks can be prevented.

D10) Opportunity to discuss game play. The game should enable the players to cooperate and prompt and facilitate
discussion about attacks and defences to create meaningful connections amongst players [Dindar et al., 2021].

D11) Players current knowledge. The selection of some of game mechanics can build on players current knowledge.
For example, if they already use a threat model consideration to use this in games design to build on players knowledge.

D12) Related to Players Role. The designer can choose between creating a serious game where player plays a
work-related role or can be given a speciﬁc role, for example as attacker.

D13) Real World Problems. The emphasis on solving should be on real-world problems [Seng Tan*, 2004] and
move problem based learning [Seng, 2000].

3.5 Assessment of MOTENS Model.

The next stage is to develop the MOTENS model into an illustrative case study and then test the case study with
cyber professionals in higher education, researchers in cyber security and cyber professionals to test the model. The
testing of perception will be for perceived ease of use (PEOU); perceived usefulness (PU); intention to use (ITU); and
efﬁcacy of the new model, see Figure 9 which is based on TAM model by Yusoff [Yusoff, 2010]. The TAM Model
in Figure 9, maps serious games learning objectives to the TAM Model. Studies have revealed a lack of methods of
measuring the effectiveness of information security training [Nguyen and Pham, 2020], and many surveys ask questions
focusing mainly on the knowledge and not the change in behaviour [Khan et al., 2011]. The case study will be able to
verify the MOTENS Model has the potential to assist in the design of serious cyber games. However, there is still a
lack of psychological theories to demonstrate increasing players’ knowledge and changing security behaviours which
is the ultimate objective of any security awareness and education training program. Using the MOTENS Model to
design serious cyber games can link player motivations using SDT and use constructivism to link instruction; learning
objectives; and conditions for instruction. The last part in testing the game with players can link serious game objectives
to the TAM Model to verify the perceived ease of use, perceived usefulness, and intention to use, see Figure 9.

4

Illustrative Case Study for Efﬁcacy of MOTENS

This section sets out the illustrative case study used to evaluate the MOTENS model. The case study’s goal was to
demonstrate that the proposed framework is effective to design serious cyber games. The target audience for the case
study is not users who would play serious cyber games rather people working in universities, research, PhD students
and cyber educators who would be involved in designing serious cyber games for awareness and education or working
in research of cyber security.

4.1 Study Design

The design of the study based on the Technology Acceptance Model (TAM) that uses three constructs predict the user
acceptance of new technology [Davis, 1989, Yusoff et al., 2010]. 1) perceived ease of use (PEOU), the degree to which

13

MOTENS: A Pedagogical Design Model

Figure 9: TAM Model linked to Assessment of MOTENS Model

a person believes that using a particular technology is free of effort; 2) perceived usefulness (PU), person’s subjective
probability that using a particular system would enhance his or her job performance; 3) intention to use (ITU), the
extent to which a person intends to use a particular system. The participants were also asked three background questions
and two questions on the level of expertise in cyber security technologies and cyber security awareness and education.

The participants were emailed a link to a short video explaining the MOTENS model and given a case study explaining
the background of the MOTENS model and using Riskio serious cyber game [Hart et al., 2020] as an example how the
model can be applied to create a serious cyber game. The participants’ were then asked to complete a questionnaire
with ﬁve background questions, see Table 4 and eight on their perceptions of the MOTENS serious games design model,
see Table 5.

Background

Q1 Which team/function area do you work in at your organisation?
Q2 What is your knowledge of Riskio game? (Tick all that apply)
Q3 What is your interest in serious cyber security games? (Tick all that

apply)

Expertise

Q4 How would you describe your level of expertise in cyber security

technologies?

Q5 How would you describe your level of expertise in cyber security

awareness and education?

Table 4: Participant Background & Expertise Questionnaire

4.2 Case Study Questionnaire

The questionnaire see Table 5 was used to collect impressions about the proposed MOTENS pedagogical design model
for serious cyber games. For the analysis the results were aligned to 1 being negative answer and 5 being positive
answer. The hypothesis was formulated using the TAM model as follows to evaluate the MOTENS model:

• PU: The participants found the MOTENS model covered all types of serious cyber games and useful (Q1, Q2).

• PEOU: The participants found that the MOTENS model would be easy to use and able to use it to match to

learning objectives (Q3, Q4).

14

MOTENS: A Pedagogical Design Model

• PU: The participants agree the value in using MOTENS to design serious cyber games to achieve desired

learning outcomes (Q5).

• PU: The participants agree the value in using serious cyber games to achieve desired learning outcomes (Q6).
• ITU: The participants would use or recommend the use of MOTENS to design serious cyber games (Q7, Q8).

Q Category

Q1
Q2

PU
PU

Q3
Q4

PEOU
PEOU

Q5

PU

Q6

PU

Q7

Q8

ITU

ITU

Serious Cyber Games Types (SGT)

Question

I found the model covered all types of serious cyber games I expected.
Using the I feel that the model would be useful in the design of the all
the types of games: Card Games; Computer Games; Board Games; and
Speciality Games (Education & awareness only for this type), see
Figure I5 in Case Study.

Games Environment (GE)
I found the MOTENS model would be easy to use.
I found the MOTENS model was able to match learning objectives to
serious games mechanics.

Authentic Learning (AL)

I think using the MOTENS model to design serious cyber games will
improve learning outcomes and give greater chance to meet desired
learning objectives of serious cyber games design.
Transfer Knowledge (TK)

I feel playing serious cyber games is an effective method to teach cyber
security awareness and education and secure software development.

Intrinsic Motivation (IM) & Extrinsic Motivation (EM)

I would recommend the MOTENS model to anyone designing a serious
cyber game.
Overall, I think the MOTENS model will be useful to design cyber
games to meet intended objectives and I would use it to help to design
serious cyber games.

Table 5: Questionnaire MOTENS Serious Cyber Games Design Model

4.3 Threats to Validity

In this section, we discuss the main threats to the validity of our case study: construct, reliability, internal and external
validity [Wohlin et al., 2012].

Construct validity This aspect is to what extent the research questions represent what was in mind. The threat
identiﬁed was anyone in the target participants who don’t feel playing serious cyber games is an effective method
and will have a negative bias in the MOTENS questions. This was mitigated by asking one generic question on the
effectiveness of serious games to teach cyber security awareness and education (see question 6, Table 5).

Reliability This is the aspect concerned with the extent to which the data and the analysis are dependent on the
speciﬁc researchers. The participants were required to have an overview of the MOTENS model before they answered
the questionnaire. The identiﬁed risk that the MOTENS presentation may vary in content and delivery even from the
same presenter and affect the participants’ questionnaire’s answers. This was mitigated by recording the MOTENS
presentation to ensure it was independent of the researcher presentation.

Internal validity This is of concern when causal relations are examined whether one factor investigated is a risk that
the investigated factor is also affected by a third factor. We identiﬁed that participants who played the Riskio game
used as an example in the MOTENS case study might be biased and to mitigate against this we asked a question about
participants knowledge of Riskio game, and so any possible bias could be analysed in the results.

External validity This is concerned with the extent to which it is possible to generalise the ﬁndings beyond the case
study settings. A potential threat could have been to select the wrong people to participate in the study. Although the
questionnaire was anonymous, this was mitigated by asking a background question and excluding any questionnaires
that don’t meet the target audience.

15

MOTENS: A Pedagogical Design Model

4.4 Analysis of Case Study

For the analysis the results of the questions from Table 5 responses have been aligned from 1 the lowest participant
perception (strongly disagree) to 5 the highest participant perception (strongly agree) and displayed in Figure 10 in a
box-plot diagram and the outliers plotted as individual points. The calculation for the outliers was based on Interquartile
Range (IQR) to set the minimum and maximum values to be considered:

IQR = Q3 − Q1

Q1 − 1.5IQR

Q3 + 1.5IQR

Background Participants. The case study involved 21 respondents, 7 working as university professor, associate
professor or lecturer, 2 working in University Research Department, 5 PhD students, 1 MSc student and 6 from
commercial organisations working in cyber awareness and education. Only 9 of the participants had read the Riskio
published paper [Hart et al., 2020]. The participants were asked two background questions to scale their expertise in
cyber technologies and awareness and education. Both questions had similar means, expertise technologies 3.6 and
expertise in education 3.2.

Threats to Validity Question 6 used to test the construct validity that participants have a general perception of the
use of serious games with a mean score of 4.71. All respondents were scoring either 4 or 5 as a clear indication all
participants have a high perception of beneﬁts using serious cyber games. Background question on knowledge of Riskio
game was used to test internal validity and the mean score of all eight questions in Figure 10 of the 9 participants
with knowledge of Riskio game mean score was 4.1 and the 12 respondents with no knowledge mean score of 4.0 and
showed no signiﬁcant difference. All the respondents met the required target for participation in the case study and no
identiﬁed risks to external validity.

Figure 10: All Questions post review MOTENS Model

Overall Perception. The results show the overall perception mean 4.07. There were some outliers whereas example
one participant on question 1 on the MOTENS model covering all types of games commented “I did not come into
the exercise with an expectation”. The overall interquartile range (IQR) for all 8 questions being between 4 and 5.

16

MOTENS: A Pedagogical Design Model

Figure 11: MOTENS Questions by TAM Category

Excluding question 6, which was the generic question to test validity, the mean score was 4.71 and same IQR between 4
and 5.

Perceived Ease of Use. The mean score for questions 3 and 4 to test the PEOU was the lowest at 3.71. Question
3 regarding MOTENS model would be easy to use had the broadest range of answers with an IQR between 3 and
4. Question 4 on MOTENS’s ability to match learning objectives to game mechanics the participants having similar
positive perception with a mean score of 3.86 with the IQR of 4. We can conclude that participants can see how
MOTENS can match learning objectives to serious games mechanics but feel it may not be easy to use.

Perceived Usefulness. The perceived usefulness of MOTENS model mean score was 4.07, including generic question
6. The mean was 3.97 when excluding generic question 6, the IQR range was between 4 and 5. The participants’
feedback was they thought the MOTENS model could be useful in the creation of serious cyber games.

Intention to Use. The overall intention to use mean score was 4.33 with all participants scoring either 4 or 5 for both
the question 7 on a recommendation to use and question 8 useful to meet intended objectives. Feedback from one
external University proposed they would consider using the model for MSc students developing cyber games.

4.5 Conclusion

The IQR for PU and ITU was 4 to 5, whereas IQR PEOU was 3 to 4 (see Figure 11), and we decided to create a
second case study and target students who would use the model to design serious cyber games to test the PEOU in a
comparative case study against another model to test the PEOU against another model.

5 Comparative Case Study

This section uses a quasi-experimental comparison between the LM-GM and our new proposed MOTENS model. This
study was to verify the MOTENS model ease of use by establishing the game mechanics’ pedagogical intent in the
model. This study was targeted at students who are currently designing serious cyber games or interested in designing
serious cyber games.

17

MOTENS: A Pedagogical Design Model

5.1 Study Design & Questionnaire

To evaluate the LM-GM against the MOTENS model, we used both models to map the Riskio gameplay. However,
the LM-GM model has no concept of numbering notation. In the evaluation of Arnab et al. [Arnab et al., 2015], the
participants used their numbering to map from the gameplay they identiﬁed back to the relevant model they were
evaluating. The MOTENS model components are numbered, and to ensure validity, we added a notation to the LM-GM
model for the comparison to MOTENS. The experiment involved an online presentation to MSc students on serious
game design models of the LM-GM and MOTENS model using the Riskio game to apply the model principles and
other presentations. The participants were then given an extract of Riskio gameplay applied to both models and given
a questionnaire to score each model. As with the illustrative study in section 4 we used the Technology Acceptance
Model (TAM) to test the difference between the new MOTENS and the LM-GM model. Participants were asked three
questions about each model (see Table 6). Q1: perceived usefulness (PU); Q2: perceived ease of use (PEOU); and Q3:
intention to use (ITU). The participants scores were aligned 1 to 5, and this enabled us to compare with the illustrative
case study for MOTENS in section 4.

Q Category
Q1

PU

Q2

PEOU

Q3

ITU

Question Asked for both LM-GM and MOTENS
It will be useful to use the model to help designing serious cyber games
that are effective for players to learn desired cyber educational
objectives.
Using the model to design serious cyber games, I can see it will be easy
to map gameplay to the game mechanics and support the pedagogical
educational theory and learning, not just creating a fun game to play.
Overall, I think the model will help design serious cyber games to meet
intended learning objectives and educational effectiveness. I would use
it or recommend using it to help design serious cyber games.
Table 6: Questionnaire LM-GM versus MOTENS

5.2 Analysis of the Study

The results of the analysis to the three questions is shown in Figure 12 with 11 participants. First comparison of TAM
scores illustrative case study in section 4 and the second is the comparison between MOTENS and LM-GM model.

Comparison to MOTENS in the illustrative case study The ﬁrst case study (see Figure 11) and this study showed
comparable results by the TAM category. PU mean as 4.07 and 4.45 and both have IQR 4 to 5. However, the PU
median is 4 on illustrative study, compared to PU median 5 testing differences between models. PEOU had similar
means of 3.79 and 4.09, with only a difference in IQR of 3 to 4 in the ﬁrst study compared to IQR 4 in this study. ITU
in both studies have the same IQR and similar means of 4.33 and 4.18. The overall perception in the illustrative study
of MOTENS excluding generic question 6 was a mean 3.97 compare to the mean of 4.24 in this case study. The overall
results of the testing comparative study showed similar results as the illustrative study.

Comparison of MOTENS and LM-GM Model The difference between the LM-GM and MOTENS models using
the TAM constructs (see Figure 12) showed MOTENS scoring a consistently higher score than the LM-GM model. The
IQR of LM-GM for PU and ITU is 2 to 4, whereas MOTENS PU and ITU has IQR of 4 to 5. The LM-GM PEOU
IQR is 2.5 to 3.5, whereas MOTENS is 4. The overall perception of LM-GM has a mean of 3.15 with IQR of 2 to 4,
compared to MOTENS means of 4.24 and IQR 4 to 5.

18

MOTENS: A Pedagogical Design Model

Figure 12: LM-GM versus MOTENS by TAM Category

6 Summary and Conclusions

This paper proposes a new pedagogical model called MOTENS to design serious cyber games to address current
pedagogical models’ limitations in designing and creating serious cyber games. The ﬁrst illustrative case study (see
section 4) the participants were people who would be involved in designing serious cyber games or working in research
of cyber security. The results of evaluating the scores were higher for perceived usefulness (PU) and intention to use
(ITU) than the perceived ease of use (PEOU) and required a second study to test PEOU. The second case study (see
section 5) targeted students who would use design models to create serious cyber games using a comparative case study
between the LM-GM model and the MOTENS model. The PEOU in the second case study improved with IQR of 3 to
4 for MOTENS in the ﬁrst illustrative case study and IQR 4 in the second comparative case study. The authors note
more work needs to be done to improve the PEOU of the MOTENS model. In the creation of the MOTENS model, we
identiﬁed three key areas in which the MOTENS model has improved on current models: 1) they do not link game
mechanics to the learning objectives; 2) high-level model and will not assist in the selection of game mechanics to
achieve serious game objectives; 3) are mainly assessed in terms of the quality of their content, not in terms of their
intention-based design. We feel the improvements in these three areas using the MOTENS model: 1) Can link the
game’s mechanics to the target players and select the appropriate game’s mechanics to meet the learning objectives,
supported by pedagogical learning theory; 2) MOTENS has a ﬁve-step process to assist in the game design in stage 4;
3) Learning objectives are built into all six components of the MOTENS model and through the ﬁve stages in designing
serious games. The case study showed that the participants using the Riskio serious game as an example of using the
MOTENS model goes through the ﬁve design stages, which will assist you in selecting game mechanics. The ﬁrst
detailed case study also showed how the serious game design can be linked to pedagogical methodology, both the
design of the serious game and how this is supported by pedagogical learning theory. The second study a comparison
between the LM-GM and our new proposed MOTENS model showed correlated results with similar means, median
and IQR. However, the authors suspect that the simple addition of notation for the evaluation against MOTENS might
have helped in the participants scoring the LM-GM model. We plan to continue researching the MOTENS model to
create serious cyber games for education and verify the MOTENS model educational effectiveness by evaluating the
serious games designed using the MOTENS model.

19

MOTENS: A Pedagogical Design Model

References

Helen Routledge. Why games are good for business: How to leverage the power of serious games, gamiﬁcation and

simulations. Springer, 2016. https://link.springer.com/book/10.1057%2F9781137448989.

Richard N Landers. Developing a theory of gamiﬁed learning: Linking serious games and gamiﬁcation of learning.

Simulation & gaming, 45(6):752–768, 2014. doi:https://doi.org/10.1177%2F1046878114563660.

Stephen Hart, Andrea Margheri, Federica Paci, and Vladimiro Sassone. Riskio: A serious game for cyber security
awareness and education. Computers & Security, 95:101827, 2020. doi:http://dx.doi.org/10.1016/j.cose.2020.101827.
https://www.riskio.co.uk.

David Buil-Gil, Fernando Miró-Llinares, Asier Moneva, Steven Kemp, and Nacho Díaz-Castaño. Cybercrime and
shifts in opportunities during covid-19: a preliminary analysis in the uk. European Societies, 23(sup1):S47–S59,
2021. https://doi.org/10.1080/14616696.2020.1804973.

Giddeon N Angafor, Iryna Yevseyeva, and Ying He. Bridging the cyber security skills gap: Using tabletop exercises
to solve the cssg crisis. In Joint International Conference on Serious Games, pages 117–131. Springer, 2020.
https://doi.org/10.1007/978-3-030-61814-8_10.

Oon Seng Tan*.

Students’ experiences in problem-based learning:

three blind mice episode or ed-
Innovations in Education and Teaching International, 41(2):169–184, 2004.

ucational
doi:https://doi.org/10.1080/1470329042000208693.

innovation?

Frank L Greitzer, Olga Anna Kuchar, and Kristy Huston. Cognitive science implications for enhancing training
effectiveness in a serious gaming context. Journal on Educational Resources in Computing (JERIC), 7(3):2–es, 2007.
doi:https://doi.org/10.1145/1281320.1281322.

Benjamin S Bloom et al. Taxonomy of educational objectives. vol. 1: Cognitive domain. New York: McKay, 20:24,

1956.

Woei Hung, David H Jonassen, Rude Liu, et al. Problem-based learning. Handbook of research on educational
communications and technology, 3(1):485–506, 2008. https://www.routledgehandbooks.com/doi/10.4324/
9780203880869.ch38.

Sylvester Arnab, Theodore Lim, Maira B Carvalho, Francesco Bellotti, Sara De Freitas, Sandy Louchart, Neil Suttie,
Riccardo Berta, and Alessandro De Gloria. Mapping learning and game mechanics for serious games analysis.
British Journal of Educational Technology, 46(2):391–411, 2015. doi:https://doi.org/10.1111/bjet.12113.

Konstantin Mitgutsch and Narda Alvarado. Purposeful by design?: a serious game design assessment framework. In
Proceedings of the International Conference on the Foundations of Digital Games, pages 121–128. ACM, 2012.
doi:https://doi.org/10.1145/2282338.2282364.

Alan Amory. Game object model version ii: a theoretical framework for educational game development. Educational
Technology Research and Development, 55(1):51–77, 2007. https://link.springer.com/article/10.1007/
s11423-006-9001-x.

Alan Amory and Robert Seagram. Educational game models: conceptualization and evaluation: the practice of higher
education. South African Journal of Higher Education, 17(2):206–217, 2003. https://hdl.handle.net/10520/
EJC36981.

Karen Robson, Kirk Plangger, Jan H Kietzmann, Ian McCarthy, and Leyland Pitt. Is it all a game? understanding the
principles of gamiﬁcation. Business horizons, 58(4):411–420, 2015. doi:https://doi.org/10.1016/j.bushor.2015.03.006.

Jeffrey K Mullins and Rajiv Sabherwal. Gamiﬁcation: A cognitive-emotional view. Journal of Business Research, 106:

304–314, 2020. doi:https://doi.org/10.1016/j.jbusres.2018.09.023.

Ayoung Suh, Christian Wagner, and Lili Liu. Enhancing user engagement through gamiﬁcation. Journal of Computer

Information Systems, 58(3):204–213, 2018. doi:https://doi.org/10.1080/08874417.2016.1229143.

Carol Sansone and Judith M Harackiewicz. Intrinsic and extrinsic motivation: The search for optimal motivation and per-
formance. Elsevier, 2000. https://www.elsevier.com/books/intrinsic-and-extrinsic-motivation/
sansone/978-0-12-619070-0.

Michael E Enzle and June M Ross.

A test of cognitive evaluation theory.
doi:https://doi.org/10.1016/0022-1031(78)90052-5.

Increasing and decreasing intrinsic interest with contingent rewards:
Journal of Experimental Social Psychology, 14(6):588–597, 1978.

Edward L Deci and Richard M Ryan. Self-determination theory: A macrotheory of human motivation, development,
and health. Canadian psychology/Psychologie canadienne, 49(3):182, 2008. doi:https://doi.org/10.1037/a0012801.

20

MOTENS: A Pedagogical Design Model

Thomas Malone and Mark Lepper. Making learning fun: A taxonomy of intrinsic motivations for learning. Making

Learning Fun: A Taxonomy of Intrinsic Motivations for Learning, 3, 01 2005.

S Ros, S González, A Robles, LL Tobarra, A Caminero, and JESUS Cano. Analyzing students’ self-perception
of success and learning effectiveness using gamiﬁcation in an online cybersecurity course. IEEE Access, 2020.
doi:http://dx.doi.org/10.1109/ACCESS.2020.2996361.

Gábor István Bíró. Didactics 2.0: A pedagogical analysis of gamiﬁcation theory from a comparative perspective
with a special view to the components of learning. Procedia-Social and Behavioral Sciences, 141:148–151, 2014.
doi:https://doi.org/10.1016/j.sbspro.2014.05.027.

Marcy P Driscoll. Psychology of learning for instruction. Boston, Allyn and Bacon, pages 373–396, 2000.
Robert M Gagne and Marcy P Driscoll. Essentials of learning for instruction. New Jersey: Prentice Hall, Inc, 1988.
Naomi Unkelos-Shpigel and Irit Hadar. Gamifying software development environments using cognitive principles. In

CAiSE Forum, pages 9–16, 2015. http://ceur-ws.org/Vol-1367/paper-02.pdf.

National Institute of Standards and Technologies (NIST). Cyber security framework. https://www.nist.gov/

cyberframework.

NCSE. National Cyber Security Centre: Cyber Essentials scheme and certiﬁcation, 2020. https://www.ncsc.gov.

uk/cyberessentials/overview.

Pauline Rooney. A theoretical framework for serious game design: exploring pedagogy, play and ﬁdelity and their
implications for the design process. International Journal of Game-Based Learning (IJGBL), 2(4):41–60, 2012.
https://arrow.tudublin.ie/ltcart/28/.

Robert M Gagne and Wager W Briggs, Leslie J. Principles of instructional design. Harcourt Brace College Publishers,

1992.

Igor Mayer, Geertje Bekebrede, Casper Harteveld, Harald Warmelink, Qiqi Zhou, Theo Van Ruijven, Julia Lo, Rens
Kortmann, and Ivo Wenzler. The research and evaluation of serious games: Toward a comprehensive methodology.
British journal of educational technology, 45(3):502–527, 2014. doi:https://doi.org/10.1111/bjet.12067.

Jane McGonigal. Reality is broken: Why games make us better and how they can change the world. Penguin, 2011.
Catherine Twomey Fosnot and Randall Stewart Perry. Constuctivism: A psychological theory of learning.

In

Constructivism: Theory, Perspectives. and Practice, chapter 2, pages 9–38. Teachers College Pres, 1996.

Dorit Maor. A teacher professional development program on using a constructivist multimedia learning environment.
Learning Environments Research, 2(3):307–330, 1999. https://link.springer.com/article/10.1023/A:
1009915305353.

Mary Rolloff. A constructivist model for teaching evidence-based practice. Nursing Education Perspectives, 31(5):

290–293, 2010.

Steve Olusegun Bada and Steve Olusegun. Constructivism learning theory: A paradigm for teaching and learning.
Journal of Research & Method in Education, 5(6):66–70, 2015. https://vulms.vu.edu.pk/Courses/EDU201/
Downloads/EDU%20201%20(Assignment%202).pdf.

Rand J Spiro, Brian P Collins, Jose Jagadish Thota, and Paul J Feltovich. Cognitive ﬂexibility theory: Hypermedia for
complex learning, adaptive knowledge application, and experience acceleration. Educational technology, 43(5):5–10,
2003. https://www.jstor.org/stable/44429454?seq=1#metadata_info_tab_contents.

David N Perkins. What constructivism demands of the learner. Educational technology, 31(9):19–21, 1991. https:

//www.jstor.org/stable/44401693.

Anne K Bednar, Donald Cunningham, Thomas M Duffy, and J David Perry. Theory into practice: How do
https:

we link. Constructivism and the technology of instruction: A conversation, 8(1):17–34, 1992.
//www.routledge.com/Constructivism-and-the-Technology-of-Instruction-A-Conversation/
Duffy-Jonassen/p/book/9780805812725.

Muhterem Dindar, Lei Ren, and Hanna Järvenoja. An experimental study on the effects of gamiﬁed cooperation
and competition on english vocabulary learning. British Journal of Educational Technology, 52(1):142–159, 2021.
doi:https://doi.org/10.1111/bjet.12977.

Gabriel Guebarra Conejo, Isabela Gasparini, and Marcelo da Silva Hounsell. Detailing motivation in a gamiﬁcation pro-
cess. In 2019 IEEE 19th International Conference on Advanced Learning Technologies (ICALT), volume 2161, pages
89–91. IEEE, 2019. https://slejournal.springeropen.com/articles/10.1186/s40561-019-0106-1.
Basel Halak. Hardware Supply Chain Security: Threat Modelling, Emerging Attacks and Countermeasures. Springer

Nature, 2021. https://www.springer.com/gp/book/9783030627065.

21

MOTENS: A Pedagogical Design Model

NCSC. National Cyber Security Centre: 10 Step to Cyber Security: Guidance on how organisations can protect
themselves in cyberspace, 2021. https://www.ncsc.gov.uk/collection/10-steps-to-cyber-security.
TO Seng. Reﬂecting on innovating the academic architecture for the 21st century. Educational Developments, 1:8–10,

2000.

Amri Yusoff. A conceptual framework for serious games and its validation. PhD thesis, University of Southampton,

2010. https://eprints.soton.ac.uk/171663/.

Tuan Anh Nguyen and Hiep Pham. A design theory-based gamiﬁcation approach for information security training. In
2020 RIVF International Conference on Computing and Communication Technologies (RIVF), pages 1–4. IEEE,
2020. doi:https://doi.org/10.1109/RIVF48685.2020.9140730.

Bilal Khan, Khaled S Alghathbar, Syed Irfan Nabi, and Muhammad Khurram Khan. Effectiveness of information
security awareness methods based on psychological theories. African Journal of Business Management, 5(26):
10862–10868, 2011. https://api.semanticscholar.org/CorpusID:154298999.

Fred D Davis. Perceived usefulness, perceived ease of use, and user acceptance of information technology. MIS

Quarterly, pages 319–340, 1989. doi:https://doi.org/10.2307/249008.

Amri Yusoff, Richard Crowder, and Lester Gilbert. Validation of serious games attributes using the technology
acceptance model. In 2010 Second International Conference on Games and Virtual Worlds for Serious Applications,
pages 45–51. IEEE, 2010. doi:https://doi.org/10.1109/VS-GAMES.2010.7.

Claes Wohlin, Per Runeson, Martin Höst, Magnus C Ohlsson, Björn Regnell, and Anders Wesslén. Experimentation in
software engineering. Springer Science & Business Media, 2012. ISBN 3642290434. https://www.springer.
com/gp/book/9783642290435.

22

