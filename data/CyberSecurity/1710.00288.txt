7
1
0
2

t
c
O
1

]
T
G
.
s
c
[

1
v
8
8
2
0
0
.
0
1
7
1
:
v
i
X
r
a

A Moving-Horizon Hybrid Stochastic Game for Secure
Control of Cyber-Physical Systems (cid:63)

Fei Miao a, Quanyan Zhu c, Miroslav Pajic d, George J. Pappas b

a University of Connecticut, Storrs, CT, USA

b University of Pennsylvania, Philadelphia, PA, USA

c New York University, Brooklyn, NY, USA

dDuke University, Durham, NC, USA

Abstract

In this paper, we establish a zero-sum, hybrid state stochastic game model for designing defense policies for cyber-physical
systems against diﬀerent types of attacks. With the increasingly integrated properties of cyber-physical systems (CPS) today,
security is a challenge for critical infrastructures. Though resilient control and detecting techniques for a speciﬁc model of
attack have been proposed, to analyze and design detection and defense mechanisms against multiple types of attacks for CPSs
requires new system frameworks. Besides security, other requirements such as optimal control cost also need to be considered.
The hybrid game model we propose contains physical states that are described by the system dynamics, and a cyber state
that represents the detection mode of the system composed by a set of subsystems. A strategy means selecting a subsystem
by combining one controller, one estimator and one detector among a ﬁnite set of candidate components at each state. Based
on the game model, we propose a suboptimal value iteration algorithm for a ﬁnite horizon game, and prove that the algorithm
results an upper bound for the value of the ﬁnite horizon game. A moving-horizon approach is also developed in order to
provide a scalable and real-time computation of the switching strategies. Both algorithms aims at obtaining a saddle-point
equilibrium policy for balancing the system’s security overhead and control cost. The paper illustrates these concepts using
numerical examples, and we compare the results with previously system designs that only equipped with one type of controller.

Key words: Stochastic Game, Secure Control, Saddle-Point Equilibrium

(cid:63) This material is based on research sponsored by DARPA
under agreement number FA8750-12-2-0247. The U.S. Gov-
ernment is authorized to reproduce and distribute reprints
for Governmental purposes notwithstanding any copyright
notation thereon. The views and conclusions contained
herein are those of the authors and should not be interpreted
as necessarily representing the oﬃcial policies or endorse-
ments, either expressed or implied, of DARPA or the U.S.
Government. This work was also supported in part by NSF
CNS-1505701, CNS-1505799 grants, and the Intel-NSF Part-
nership for Cyber-Physical Systems Security and Privacy.
This paper was not presented at any IFAC meeting. Part of
the results in this work appeared at the 52nd Conference of
Decision and Control, Florence, Italy, December 2013 Miao
et al. (2013) and the 53rd Conference of Decision and Con-
trol, Los Angeles, CA, USA, December 2014 Miao & Zhu
(2014). Corresponding author F. Miao. Tel. 2154216608.
Email addresses: fei.miao@uconn.edu (Fei Miao),

quanyan.zhu@nyu.edu (Quanyan Zhu),
miroslav.pajic@duke.edu (Miroslav Pajic),

1 Introduction

Cyber-Physical Systems (CPS) feature a tight integra-
tion of embedded computation, networks, controlled
physical processes, and provide the foundation of critical
infrastructures such as transportation systems, smart
grids, water service systems and so on (Kim & Kumar
(2012)). However, the integration structures also result
in vulnerability under malicious attacks (Cardenas et al.
(2009)). Recoded incidents caused by attacks show that
CPS attacks can disrupt critical infrastructures and
lead to undesirable, catastrophic consequences (Slay &
Miller (2007)). While cyber security tools have focused
on prevention mechanisms, there are still challenges on
how to leverage the ability of control systems to keep
system resilient under a smart adversary.

pappasg@seas.upenn.edu (George J. Pappas).

Preprint submitted to Automatica

3 October 2017

 
 
 
 
 
 
Detection methods for various types of attacks have
been analyzed in the literature. Pasqualetti et al. (2013)
propose a framework for attacks and monitors of CPS
perspectives. Mo et al. (2012) analyze security chal-
lenges and countermeasures in smart grids. Pajic et al.
(2014) present resilient state estimators for systems
with noise and modeling errors. Humphreys (2013) ana-
lyzes spooﬁng attacks against cryptographically-secured
Global Navigation Satellite System (GNSS) signals and
detection strategies. Miao et al. (2016) design a cod-
ing scheme for sensor outputs to detect stealthy data
injection attacks over the communication channel.

In general, attack models are used as parameters to de-
sign defense schemes. However, a speciﬁc detection ap-
proach alone is not suﬃcient, when the system does not
have knowledge which attack will happen among vari-
ous types of potential attacks. CPS are usually resource
constrained systems, which prevents running all avail-
able modules at the same time. Besides security, other
requirements like optimal cost need to be addressed dur-
ing control systems design. Consequently, considering
control and defense costs with the eﬀects of multiple at-
tacks, strategic methods that balance the system perfor-
mance and security requirements are necessary. In this
work, we consider the case that at each time instant,
only one detector is active because of the limits of re-
sources. Our approach can be generalized to more than
one detector being active at every time instance.

The application of game theory to security problems has
raised a lot of interest in recent years. Selected works that
apply game-theoretic approaches in computer networks
security and privacy problems are summarized by Man-
shaei et al. (2013). Zhu & Martinez (2011) propose a
receding-horizon dynamic Stackelberg game model for
systems under correlated jamming attacks. Zhu & Basar
(2015) propose game-theoretic methods for robust and
resilient control of CPSs. However, none of these works
have considered switching policies under multiple types
of attacks, with payoﬀs as functions of system dynamics
and probabilistic detection rate.

Building a framework that captures the hybrid system
dynamics and interactions with attacks is pivotal for se-
curity analysis and design of CPS. To achieve this goal,
our ﬁrst step is to establish a zero-sum hybrid stochastic
game model. The hybrid state of the game model con-
tains a dynamic system state that captures the evolution
of the physical processes, and discrete cyber modes that
represent diﬀerent security states of the CPS according
to information provided by the detector. Then a sub-
optimal value iteration algorithm is developed for the
ﬁnite horizon hybrid stochastic game. Compared with
our previous game model (Miao et al. (2013)) that only
switches between two controllers against replay attacks
and needs strategy history to calculate a strategy, in this
work the hybrid state stochastic game strategy calcula-
tion process does not depend on the strategy history.

then propose a moving-horizon computation
We
methodology to reduce the computational complexity
of ﬁnding a saddle-point equilibrium for the hybrid
stochastic game. This is a scalable and computationally
eﬃcient algorithm. At each stage, the system selects
a window of ﬁnite length for the physical state, and
computes the stationary saddle-point strategies for the
associated ﬁnite stochastic game, with the game state
reformulated as the joint cyber and physical states. A
preliminary result of the moving-horizon algorithm ap-
peared in the conference paper Miao & Zhu (2014); in
this journal version, we have included more detail about
diﬀerent types of attacks and each element of the game
model, revised analysis of the moving horizon algorithm
compared with the suboptimal algorithm, and added
more simulation results. The cost comparison with the
suboptimal algorithm shows that the real-time algo-
rithm does not sacriﬁce system performance much. The
contributions of this work are summarized as follows:

(1) We formulate a zero-sum, hybrid stochastic game
framework for designing a switching policy for a
system under various types of attacks.

(2) We design a suboptimal algorithm for the ﬁnite
horizon hybrid stochastic game, and prove that the
algorithm provides an upper bound for the optimal
cost of the system.

(3) We develop a real-time algorithm to reduce the

computation overhead of the game model.

This paper is organized as follows. We describe the sys-
tem, attack models, and motivation of game-theoretic
techniques for switching policies in Section 2. In Sec-
tion 3, we formulate a zero-sum, hybrid stochastic game
between the system and the attacker. A suboptimal al-
gorithm for the ﬁnite horizon game is developed in Sec-
tion 4. The moving horizon algorithm and its computa-
tional complexity are analyzed in Section 5. Section 6
compares the complexity and system performance of the
ﬁnite horizon and the receding horizon algorithms. Fi-
nally, Section 7 provides concluding remarks.

2 Switched System and Attack Model

We consider the CPS security problem when both the
system and attacker have limited knowledge about the

Fig. 1. Switching system diagram, where the system is
equipped with N1 controllers, N2 estimators and N3 detec-
tors and switches among N subsystems. A subsystem (con-
troller N1, estimator N2, and detector N3) is chosen here.

2

Plantukuk-1S1S2Sp...controller N1detector 1detector N3u'ka1a2amCANBusyky'k...controller 1estimator 1estimator N2SensorAttackCAN BusActuatorAttackopponent. The system is equipped with multiple con-
trollers/estimators/detectors, such that each combina-
tion of these components constitute a subsystem. A sub-
system has a probability to detect speciﬁc types of at-
tacks with diﬀerent control and detection costs. To bal-
ance the security overhead and the control cost under
various attacks, we consider switching among subsys-
tems (choose a model for every component) according
to the system dynamics and detector information. A
switched system model is shown in Figure 1, and the
model of each component is described with a concrete
example in the rest of this section. It is worth noting
that the set of subsystems is not restricted and can be
further generalized.

LTI plant and sensor attack model: Consider a class
of LTI plants described by:

xk+1 = Axk + Buk + wk, yk = Cxk + vk,

(1)

where xk ∈ Rn, uk ∈ Rp and yk ∈ Rm denote the
discrete time state, input and output vectors respec-
tively, and wk ∼ N (0, Q), vk ∼ N (0, R) are indepen-
dent and identically distributed (IID) Gaussian random
noise. The initial state is x0 ∼ N (¯x0, Σ). Sensors or the
communication between sensors and estimators are vul-
nerable, and attacker can change values yk that sent
from sensors of system (1), and the compromised sensor
measurements are deﬁned as y(cid:48)
k according to the types
of attacks we consider. For instance, if the attacker can
inject arbitrary data ya
k; for re-
play attacks, the attacker can choose the replay window
size T2, let y(cid:48)
k = yk−T2 and decide whether to send the
delayed plant outputs at k.

k to sensors, y(cid:48)

k = yk + ya

Estimators: The physical dynamical state of the sys-
tem is provided by an estimator, for instance, attack re-
silient estimator (Pajic et al. (2014)), l1 norm state esti-
mator (Pajic et al. (2015)), fault detection ﬁlter Zhong
et al. (2003), or the widely applied Kalman ﬁlter. When
(A, B) is stabilizable, (A, C) is detectable, a steady state
Kalman ﬁlter exists.

Controllers: A state feedback control law is described
as uk = L(ˆxk|k), where L(·) is a linear function, ˆxk|k
is the estimated state. Mo & Sinopoli (2009) increase
the detection rate by adding an IID Gaussian signal
∆uk ∼ N (0, L) to u∗
k to an optimal LQG controller as
uk = u∗
k + ∆uk, and increase the control cost. Then al-
ways applying the non-optimal controller for detecting a
replay attack is not cost optimal, especially when there
is no replay at all during a long time.

Detectors: We assume that every detector of the sub-
system provides a detection rate for a speciﬁc type of at-
tack, and a system is equipped with several detectors in
order to deal with multiple types of attacks. Researchers
have designed probabilistic detectors with respect to dif-
ferent attacks. For instance, Zhong et al. (2003) design a

3

fault detection ﬁlter, including a residual estimator and
a threshold and a decision logic unit. Hypothesis test-
ing strategies such as maximum likelihood (MLE), max-
imum a posteriori (MAP), and minimum mean square
error (MMSE) account for GPS spooﬁng attack is pre-
sented by Humphreys (2013).

Cyber state – discrete modes of the system: We de-
note the modes of a vulnerable system as three constants
S = {δ1, δ2, δ3}. State δ1 = saf e describes that the sys-
tem has already successfully detected an attack; δ2 =
no detection speciﬁes that the alarm is not triggered; ﬁ-
nally, the system enters state δ3 = f alse alarm trigger
when the alarm is triggered while no attack has yet oc-
curred. The mode depends on the probability detection
rate. We assume that once the alarm is triggered, the
system will stop the execution and decide whether to
react to occurred attacks or it is a false alarm.

3 A Hybrid Stochastic Game Model

To obtain a switching policy that minimizes the ex-
pected real-time worst case payoﬀ for the given subsys-
tems, we formulate a zero-sum, hybrid stochastic game
between the system and the attacker. System dynam-
ics knowledge are combined with the game deﬁnition,
and the quantitative process for the game parameters
will be introduced in this section. We assume that one
game stage k is also one time step of the physical sys-
tem. The total stage number is K. The hybrid game
state space (X[k−T,k] × S) contains information about
both the system dynamics xk and the discrete modes
δl, l = 1, 2, 3. Here, T is the window size of system
dynamics needed to keep the state transition between
stages k and (k + 1) Markov. The joint state includes in-
formation we need to compute the game strategy at the
current stage. This is the main diﬀerence compared with
the previous work (Miao et al. (2013)), while the latter
is not Markov since it needs to consider all the possible
histories of strategies for deciding the physical dynamics
and getting a strategy. At each stage k ∈ {T, · · · , K+T },
parameters include the action space for the attacker (sys-
tem) At (As), the state transition probability matrix Pk,
and the immediate payoﬀ matrix rk. The solution set of
the game is mixed strategies Fk for the attacker, and
Gk for the system. Formally, the game is deﬁned as a se-
quence of tuples: {(X[k−T,k] × S), At, As, Fk, Gk, P, r}.

Game State Space: The joint state of the system at
stage k is described by the pair skl = (x[k−T,k], δl), where
x[k−T,k] = (xk−T , xk−T +1, · · · , xk) ∈ X[k−T,k]
is the discrete-time dynamics of the physical process pro-
vided to the system–the state estimations ˆxk−T , · · · , ˆxk,
δl ∈ S = {δ1, δ2, δ3} denote the cyber state of the sys-
tem. We assume that once the game reach δ1, the sys-
tem wins and will not enter other modes till next game,
i.e., δ1 is an absorbing state. The moving-horizon tran-
sition of the joint states on stage axis is shown as Fig-

Figure 1) are determined priorly. For example, a sub-
system can be the plant with a given optimal LQG con-
troller, a Kalman ﬁlter and a χ2 detector. A subsystem
can also be the plant with an optimal LQG controller, a
resilient state estimator Pajic et al. (2014) and its cor-
responding estimation residual checking component. We
assume that the attacker’s action space is deﬁned, with
corresponding system’s action or a subsystem that the
detection rate is greater than 0. A switched system does
not ensure performance under the attack outside the ac-
tion space of the game.

k(skl) (gj

Mixed Strategy: Let f i
k(skl)) be the prob-
(system) chooses action
the attacker
ability that
ai(x[k−T,k) ∈ At (uj(x[k−T,k) ∈ As) at state skl ∈
(X[k−T,k] × S). Deﬁne Fk and Gk as the mixed strat-
egy sets of the attacker and the system for stage k:
Fk := {fk = [fk(sk1), fk(sk2), fk(sk3)]|f i
k(skl) ≥ 0, fk ∈
[0, 1]M ×3, (cid:80)
k(skl) = 1, fk(skl) ∈ RM , ∀skl ∈
f i

aik∈Atk

ujk∈Ask

(X[k−T,k]×S)}, Gk := {gk = [gk(sk1), gk(sk2), gk(sk3)]|
k(skl) ≥ 0, gk ∈ [0, 1]N ×3, (cid:80)
gj
gj
k(skl) = 1, gk(skl) ∈
RN , ∀skl ∈ (X[k−T,k] × S)}. Note that x[k−T,k] provides
exogenous information for the strategy fk(gk), since for
every l, fk(skl)(gk(skl)) is the strategy at mode δl for
the same x[k−T,k] at stage k. Hence, gk and fk are ﬁnite
dimensional vectors, that the stationary strategy chosen
by each player at stage k depends on the cyber state.

System and Subsystem Dynamics under game
framework: Given the subsystem and attack models in
Section 2 and the game deﬁnition, we show the dynamics
at stage k given an action pair (ai(x[k−T,k), uj(x[k−T,k))
(assume initial ˆx1|0 = ¯x0, x1 = x0). Each action
pair (ai(x[k−T,k]), uj(x[k−T,k])) deﬁnes the correspond-
ing system dynamics at k. For instance, when we
focus on sensor attacks (like replay or false data in-
jection), let γk(ai(x[k−T,k]), uj(x[k−T,k])) be the con-
trol
input with (ai(x[k−T,k]), uj(x[k−T,k])), a subsys-
tem uj(x[k−T,k]) with a Kalman ﬁlter, an optimal
LQG controller has the following dynamics (we denote
(ai(x[k−T,k]), uj(x[k−T,k])) as (aik, ujk) for convenience):

xk = Axk−1 + Buk−1 + wk−1,

yk =

(cid:26)a1k = Cxk + vk, without attack
aik, i = 2, · · · , M, with attack,

ˆxk|k−1 = Aˆxk−1|k−1 + Buk−1,
ˆxk|k(aik) = ˆxk|k−1 + K(aik − Cˆxk|k−1),
ˆxk+1|k(aik, ujk) = Aˆxk|k(aik) + Bγk(aik, ujk),
γk(aik, ujk) = Lˆxk|k(aik),
zk+1(aik, ujk) = aik − Cˆxk+1|k(aik, ujk).

(2)

State Transition Probability: Given a set of subsys-
tem models, deﬁne the state transition probability P as

Fig. 2. Joint state transition of the hybrid stochastic game
when moving the horizon of game state one step ahead. When
the state transits from stage k to k + 1, we slice the window
of the sequence of physical dynamics one step ahead, add
xk+1 and remove xk−T , thus x[k−T,k] → x[k−T +1,k+1]. The
piecewise constant modes δl, δh describe the cyber states
provided by the detector at stage k, respectively.

ure 2. The window size of system dynamics T keeps the
state transition between time k and k + 1 Markov. For
instance, if the detector of the system requires system
dynamics ˆx[k−T1,k], and we consider sensor data injec-
tion attacks and replay attacks with replay windows less
than T2 steps, then T = max{T1, T2}.

Attacker’s Action Space: We assume that the system
is vulnerable to diﬀerent attack models described by the
action space At, where

At = {a1(x[k−T,k]), a2(x[k−T,k]), · · · , aM (x[k−T,k])}
is the attacker’s action space at stage k, and a1 means
no attack. Here we only consider discretized action space
of the attacker for computational eﬃciency. For the LTI
system dynamics considered in this work, the distance of
a continuous point to its nearest discrete point in action
space is bounded. With bounded error of the dynamics
by discretized continuous action space, the quality of
game solutions under diﬀerent conditions is analyzed by
work Kroer & Sandholm (2015).

k −ya

k = yk + ya

The actions can describe both multiple types of attacks
and the same type attack with diﬀerent values. For in-
stance, when considering only sensor data injection at-
tacks with diﬀerent norms of injection value, we will
denote ai(x[k−T,k]), i = 2, 3, . . . as changing the sensor
value from yk = Cxk + vk to y(cid:48)
k,i, where
any injection ya
k is classiﬁed as ai(x[k−T,k]), i = inf {i :
(cid:107)ya
k,i(cid:107)2} in attacker’s action space. Similarly, for re-
play attack only, the action space is discretized as chang-
ing sensor values from yk = Cxk + vk to y(cid:48)
k = yk−Ti for
action index ai(x[k−T,k]), where any replay time length
Ta is classiﬁed as ai(x[k−T,k]), i = inf {i : |Ta − Ti|}.
Considering multiple types of attacks, we assume that
the system is valnerable under ma types of attacks, and
attack type Ai is corresponding to Ma,i discretized ac-
tions in the action space, then there are (cid:80)ma
i=1 Ma,i + 1
actions in total within the attacker’s action space At.

System’s Action Space: The system’s action space at
stage k is deﬁned as

As = {u1(x[k−T,k]), u2(x[k−T,k]), · · · , uN (x[k−T,k])},
where uj is the index for the jth subsystem. We assume
that the N subsystems (a model for each component in

4

(x[k-T+1,k+1],kk+1k-Tk-T+1(x[k-T,k],))Stage axisa function of the state of the game and both players’ ac-
tions P : (X[k−T,k] × S) × At × As → [0, 1], where

P (s(k+1)h|skl, aik, ujk), h = 1, 2, 3
is the probability that system transits from state skl to
state s(k+1)h at stage k + 1, given both players’ action
(aik, ujk) at stage k. Given the current game state skl =
(x[k−T,k], δl) and an action pair (aik, ujk), the dynamics
of the system at stage k + 1 is described as x[k−T +1,k+1]
for all possible cyber modes δh ∈ S, hence the dimension
of state transition probability P (s(k+1)h|skl, aik, ujk) is
determined by the number of cyber modes of the game.
We denote P (s(k+1)h|skl, aik, ujk) as P ij(s(k+1)h|skl) for
short. As a state transition probability, this function
should also satisfy

δh∈S P ij(s(k+1)h|skl) = 1,
∀(aik, ujk) ∈ At × As,
s(k+1)h ∈ (X[k−T +1,k+1] × S), skl ∈ (X[k−T,k] × S).
The transition probability is provided by intrusion de-
tectors of the subsystem.

(cid:80)

Immediate Payoﬀ Function: The immediate payoﬀ
matrix at stage k is a RM ×N matrix for given game state
and every action pair (aik, ujk). We deﬁne the immedi-
ate payoﬀ function as a continuous, convex function of
the hybrid game state and the actions of both players
r : (X[k−T,k] × S) × At × As → RM ×N ,
where r(skl, aik, ujk) (cid:62) 0 is the payoﬀ at joint state skl
given action pair (aik, ujk). For deﬁnition convenience,
we denote r(skl, aik, ujk) as rij(skl) for short, since it is
the element on the i-th row and j-th column of the payoﬀ
matrix r(skl). It is a zero-sum game between the system
and the attacker, and we assume the system is the mini-
mizer and the attacker is the maximizer, hence the pay-
oﬀ function for the attacker and the system is deﬁned as

rij(skl) = rij

t (skl) = −rij

s (skl).

For instance, when the linear quadratic cost is a metric
of system performance, let γk(aik, ujk) be the control in-
put given action pair (aik, ujk), then the payoﬀ function
is deﬁned as

the probability distribution. Then, the control input
and sensor value for calculating expectation cost are:

uk =

p(skl)f i

k(skl)gj

k(skl)γk(aik, ujk),

3(cid:80)
l=1

N
(cid:80)
j=1
M
(cid:80)
i=1

M
(cid:80)
i=1
3(cid:80)
l=1

yk =

p(skl)f i

k(skl)aik.

The probability that system is at state s(k+1)h for k + 1
is:

p(s(k+1)h) =

p(skl)[fk(skl)]T Pk(s(k+1)h|skl)gk(skl).

3(cid:80)
l=1

4 Existence of An Optimal Strategy and Subop-

timal Algorithm for A Finite Game

Based on the game formulation, in this section we discuss
the existence of an optimal solution for the ﬁnite form
of the hybrid stochastic game, and present an algorithm
to compute a suboptimal system strategy.

4.1 Existence of the System’s Optimal Strategy

We deﬁne the concatenation of strategies for K-stage
game of each player (f for attacker and g for system) as
f = f1 · · · fK,
gk ∈
Gk,

g ∈ G, k = 1, 2, . . . , K.

f ∈ F, g = g1 · · · gK,

fk ∈ Fk,

Deﬁnition 1 Let the random variable ζk describe the
discrete state of the hybrid game at stage k, we deﬁne the
conditional expected total payoﬀ till ˜K for any f , g as

R ˜K(s, f , g)
˜K
(cid:80)3
(cid:80)
k=1

=

l=1 p(ζk = δl|ζ1 = s)[fk(skl)]T ˜rk(skl)gk(skl),
where p(ζk = δl|ζ1 = s) is the probability that the discrete
state of the hybrid game is δl at stage k given its initial
discrete state ζ1 = s.

rij(sk1) =E[ˆxT
rij(sk2) =E[ˆxT
rij(sk3) =pf ,

k ]WE[ˆxk] + E[γT
k ]WE[ˆxk] + E[γT

k (a1k, ujk)]UE[γk(a1k, ujk)],
k (aik, ujk)]UE[γk(aik, ujk)],

(3)

where pf is the false alarm trigger penalty, the cost that
the system needs to stop execution, check the reason of
an alarm, and restart later; xk is the physical state under
the game framework. At mode δ1 the system wins, so
the payoﬀ is a normal system payoﬀ with correct sensor
data. The larger pf is, the less probable it is for the
system to choose a strategy to transit to state sk3.

Since the immediate payoﬀ of each stage satisﬁes that
0 ≤ ˜rij
k (skl) < ∞, for all k, i, j, we have that R ˜K(s, f , g)
is a nonnegative real-valued, nondecreasing function
with ˜K. Furthermore, for ﬁnite K

RK(s, f , g) < ∞, ∀s ∈ S, f ∈ F, g ∈ G.

(4)

Similarly as the deﬁnition of value and optimal strategy
for a zero-sum, ﬁnite discrete state, ﬁnite stage stochas-
tic game, we deﬁne the value and optimal strategy for
the hybrid state stochastic game deﬁned in this work as
the following.

System dynamics update with strategies at stage
k: Let p(skl) be the probability system is at state skl
at stage k. The initial state distribution p(s1l) is given.
With a strategy fk, gk, the attacker and the system
randomly sample an action pair (aik, ujk) according to

Deﬁnition 2 A two-person zero-sum K-stage stochas-
tic game is said to have a value vector v∗
K if v∗
K,s =
vK,s = ¯vK,s, for any initial cyber state s ∈ S, where

vK,s = supf ∈F inf g∈G RK(s, f , g),
¯vK,s = inf g∈G supf ∈F RK(s, f , g).

5

For the ﬁnite value K-stage stochastic game, strate-
gies g∗ and f ∗ are called optimal at the saddle-point
equilibrium for player two (the system) and player
for all s ∈ S,
one (the attacker), respectively,
RK(s, f , g∗).

RK(s, f ∗, g),

if
v∗
K,s = sup
f ∈F

v∗
K,s = inf
g∈G

The game deﬁned in this paper has ﬁnite action spaces,
ﬁnite strategy space, ﬁnite discrete cyber modes and
satisﬁes (4) with bounded total payoﬀ in ﬁnite horizon.
Therefore, there exists the value of the considered game
and an saddle-point equilibrium or optimal strategy for
the system shown in Basar & Olsder (1998).

4.2 Suboptimal algorithm for the ﬁnite game

Existing value iterative algorithms or dynamic program-
ming algorithms for ﬁnite stochastic games cannot be
used to solve the ﬁnite hybrid stochastic game deﬁned
in this work, since the discrete time dynamics x[k−T,k] of
the game at stage k depends on that of the stage k − 1,
which is only available in the future algorithm iterations.
Hence, we design a suboptimal algorithm based on the
value iteration method for a ﬁnite horizon, ﬁnite dis-
crete state stochastic game (Kearns et al. (2000)) and
robust game techniques (Aghassi & Bertsimas (2006)).
The value iteration algorithm for a ﬁnite horizon, dis-
crete state stochastic game (with ﬁxed payoﬀ r and state
transition probability P at every stage) works in the way
that if a player knew how to play in the game optimally
from the next stage on, then, at the current stage, he
would play with such strategies. The value of K-stage
game is ﬁnally provided by the last step of iteration.

For a multi-stage game, to calculate the game value,
we deﬁne the auxiliary matrix at stage k for every cy-
ber state δl with system dynamics x[k−T,k] as Q(skl) ∈
Qk ⊂ RM ×N , and each element of Q(skl) for action pair
(aik, ujk) is deﬁned as

Qij(skl)
=rij(skl) +

(cid:88)

δh∈S

P ij(s(k+1)h|skl) · vk+1(s(k+1)h),

(5)

where vk+1(s(k+1)h) is the game value from stage k + 1,
state s(k+1)h (with cyber mode δh) to the ﬁnal stage K.
For the ﬁnal stage K, we deﬁne Q(sKl) = r(sKl). We
deﬁne a one-shot game at stage k as a ﬁnite action space,
zero-sum game between the system and the attacker with
payoﬀ matrix Q(skl), i.e., Qij(skl) is the payoﬀ for action
pair (aik, ujk) of stage k. In each one-shot game, the
system only consider a strategy fk(skl) to minimize the
worst case payoﬀ caused by the attacker according to
matrix Q(skl). Here Q(skl) is deﬁned based on the the
system dynamics and the state transition probability
provided by the detector. An alternative algorithm with
unknown transition matrix or payoﬀs will be our future
work.

Similarly as the value iteration algorithm for a discrete
state stochastic game (Kearns et al. (2000)), Algorithm 1
of the ﬁnite hybrid state stochastic game starts from
the last stage, then gets the optimal one-stage strategy
and the upper bound of game value at each stage. By
calculating values of all stages until backwards to the
ﬁrst stage, Algorithm 1 returns an upper bound for the
value of the total payoﬀ in K-stages.

To estimate the values at each step, we consider the im-
mediate payoﬀ r(skl), the state transition probability
P (s(k+1)h|skl) and the game value estimated at the pre-
vious step uncertain parameters for the one shot robust
game (Aghassi & Bertsimas (2006)). Then approximate
each iteration value as the value of the robust one shot
zero sum game. Algorithm 1 provides an upper bound
for the game value and the corresponding suboptimal
strategy for the system. The idea is to solve a robust
game at each iteration step – i.e., minimize the worst-
case caused by extreme points of the set of auxiliary ma-
trix Qk deﬁned for all possible dynamics x[k−T,k].

To quantify the boundary of the set of auxiliary ma-
trix Qk we need the expected values of system dynamics
xk, uk, yk, k = 1, · · · , K deﬁned in equations (2), which
is determined by the strategies from stage 1 till stage
k. We ﬁrst analyze the uncertain sets of the immediate
payoﬀ function at stage k, and the extreme points for the
uncertain set Qk depend on pure strategies . Let f p
k−1,
gp
k−1 be the concatenation of previous pure strategies
of the attacker and the system till stage k (cid:62) 2, respec-
tively, where

f p
k−1 = f p
1 · · · gp
satisﬁes that all f p
t (s)) for t = 1, 2, . . . , k have
only one non-zero element, i.e., the player chooses the
corresponding action or the pure strategy.

k−1,
t (s) (gp

gp
k−1 = gp

1 · · · f p

k−1

Deﬁne a pure strategy auxiliary matrix Qp(skl) ∈ Qp

k as:

Qp(skl)
=rp(skl) +

(cid:88)

δh∈S

P p(s(k+1)h|skl) · ¯vp

k+1(s(k+1)h),

(6)

for stages k = 1, . . . , K −1, and for the ﬁnal stage k = K,

Qp(sKl) = rp(sKl).

For each stage k, ¯vp

k(skl) is deﬁned as

¯vp
k(skl) = max

Qp(skl)∈Qp
k

v∗[Qp(skl)],

(7)

(8)

where v∗ is the function that yields the value of a zero-
sum matrix game. Then the value ¯vp
k+1(s(k+1)h) ≥ 0 to
calculate the auxiliary matrix 6 is the upper bound of
robust game value from stage k +1 till stage K, resulting
from the iteration at stage k + 1. This value iteration
process is the key idea of the following Algorithm 1.

6

Algorithm 1 : Suboptimal Algorithm for A Finite
Hybrid Stochastic Game
Input: System model parameters and game parameters.
Initialization: Compute the set of Qp
k for every stage
k = T, . . . , T + K given ˆx[0,T ]; get the robust game value
and corresponding strategies at stage K: Qp(s(K+T )l) =
rp(s(K+T )l), f ∗(s(K+T )l), g∗(s(K+T )l), ¯vp
K+T (s(K+T )l) ←
π(Qp(s(K+T )l)).
Iteration: For k = (K + T − 1), · · · , T , obtain a set of
k for all f p
auxiliary matrices Qp
k, where each matrix
is deﬁned in (6), then calculate:

k , gp

f ∗(skl), g∗(skl), ¯vp

k(skl) ← π(Qp(skl)).

k = [f ∗(skl), l = 1, 2, 3], g∗
f ∗

k = [g∗(skl), l = 1, 2, 3].

Return:strategies fa = f ∗
and the value upper bound ¯vp

T · · · f ∗

K+T , ga = g∗
1(s1l), l = 1, 2, 3.

T · · · g∗

K+T

Now consider the iteration for calculating ¯vp
k(skl) from
all matrix games Qp(skl) ∈ Qp
k applying Algorithm 1.
We deﬁne any strategy concatenations to stage k − 1
with at most one non-pure strategy at stage (k − 1) as

f np
k−1 = f p
k−1 = gp
gnp

k−2fk−1,
k−2gk−1,

fk−1 ∈ Fk−1,
gk−1 ∈ Gk−1,

(9)

k−2, gp

where f p
k−2 are concatenations of pure strategies
to stage (k − 1). We denote the corresponding auxiliary
matrix as ˜Q(skl) ∈ ˜Qk for cyber state δl, the one shot
game value based on payoﬀ matrix ˜Q(skl) as ˜vk(skl), i.e.,

˜Q(skl)
=˜r(skl) +

(cid:88)

δh∈S

˜P (s(k+1)h|skl) · ˜vk+1(s(k+1)h).

(10)

Here each possible hybrid state skl for time instant k
is calculated from a none pure strategy deﬁned as (9).
Similarly, the value is deﬁned as

˜vk(skl) = max

˜Q(skl)∈ ˜Qk

v∗[ ˜Q(skl)].

(11)

The following theorem shows that at every stage k,
¯vp
k(skl) is greater than or equal to ˜vk(skl).

Theorem 3 Consider the value iteration for stage k as
a one shot robust game. Based on ¯vp
k(skl) ≥ 0 of previous
iteration, we deﬁne the robust game value obtained at
k as (8). Then for k = 2, · · · , K, ˜vk(skl) (11) is upper
bounded by ¯vp

k(skl), i.e., ˜vk(skl) (cid:54) ¯vp

k(skl).

PROOF. Since ¯vp
k+1(s(k+1)h) is a nonnegative scalar
value, the extreme points of the set Qk is a subset of

7

the extreme points of set Qp
k. Hence, by considering the
value of matrix game Qp(skl) ∈ Qp
k deﬁned in (6), we
will get the upper bound of the maximum game value
from extreme points of Qk.

Consider the following optimization problem for the sys-
tem with constraint inequality (13) for any possible at-
tacker’s strategy vector f at each stage k

min
g

z

subject to z ≥ max

˜Q(skl)∈ ˜Qk

f T [ ˜Q(skl)]g.

(12)

(13)

As proven by Lemma 5 in Aghassi & Bertsimas
(2006), (13) is equivalent to the following constraint
that considers only the extreme points

z ≥ max

Qp(skl)∈Qp
k

f T [Qp(skl)]g,

(14)

For the worst-case f , the above is also true. Hence, let

vp
k(skl) = max

Qp(skl)∈Qp
k

min
g

max
f

f T [Qp(skl)]g.

(15)

For optimal policies f ∗(skl) and g∗(skl), the above opti-
mization problem (15) results in a cost
v∗[Qp(skl)].

max
Qp(skl)∈Qp
k

However, (f ∗(skl), g∗(skl)) can be non-pure strategies,
meaning that when we apply (f ∗(skl), g∗(skl)) to calcu-
late system dynamics such as equations (2), they will
not result in any extreme point of set Qk+1.

Now consider the ﬁnal stage K, we have

Qp(sKl) = rp(sKl), ˜Q(sKl) = ˜r(sKl),
and use the Qp(sKl) and ˜Q(sKl) in the above proof,
value ˜vk(sKl) from ˜Q(sKl) is smaller than ¯vp
k(sKl) from
the extreme points auxiliary matrix Qp(sKl), i.e., for K,
the following inequality holds

˜vk(sKl) (cid:54) ¯vp

k(sKl).

Then, by induction, with the value ˜vk+1(s(k+1)h) of it-
eration for stage k + 1, 2 (cid:54) k (cid:54) K − 1 satisﬁes
˜vk+1(s(k+1)h) (cid:54) ¯vp

k+1(s(k+1)h),

(cid:62) 0 and ˜P ij
k

and nonnegative payoﬀ and state transition probabil-
ity rij
(cid:62) 0, replacing ˜vk+1(s(k+1)h) by
k
vp
k+1(s(k+1)h) in (6) will make every entry of matrix
˜Q(skl) smaller than matrix Qp(skl). With a similar ar-
gument in the next iteration for stage k − 1, we have
˜vk(skl) (cid:54) ¯vp

k(skl).

Based on the above observation, we arrive at the subop-
timal algorithm to compute the equilibrium solutions,
illustrated in the Algorithm 1. Note that for keeping the
physical state x[k−T,k] of the ﬁrst stage of the game starts
at ˆx0, in the above Algorithm 1 the K-stage game starts

at k = T . This does not aﬀect our proofs in this section
for considering k = 1, . . . , T . According to Theorem 3,
we use Algorithm 1 to compute an upper bound of the
value and the corresponding suboptimal strategy for ev-
ery step. The function π computes the strategy and ro-
bust value as deﬁned in (8).

The values of the ﬁnite stage game ˜vk(skl) and ¯vp
k(skl)
resulting from two auxiliary matrices ˜Q(skl) Qp(skl) are
based on strategy concatenations that only diﬀer at stage
k − 1 (i.e., the same and pure strategies from stages
1 to (k − 2)). By value iteration backward to stage 1,
we compare the game value for all possible strategies
and the robust game value ¯vp
1(s1l) of Algorithm 1 in the
following theorem.

Corollary 4 Algorithm 1 yields an upper bound v1(s1l)
for the value of the K-stage game, together with subopti-
mal strategies fa and ga.

P ij(s2h|s1l)vp

Qij(s1l) = rij(s1l) + (cid:80)
δh∈S

The strategies fa, ga of Algorithm 1 are possibly not
pure. According to Theorem 3, we obtain ˜vk(skl) (cid:54)
¯vp
k(skl), and the proof holds for every k = 2, · · · , K. Con-
sider the value iteration for k = 1, with ˜v2(s2l) (cid:54) ¯vp
k(s2l),
2(s2h) (cid:54)
and
Qp,ij(s2l), thus the true value of the K-stage game
v∗[Q(s1l)] (cid:54) ¯vp
1(s1l). The iterative value based on pure
strategy auxiliary matrix sets Qp
k, k = 1, · · · , K, ob-
tained from Algorithm 1 is an upper bound for the
game value. Let v∗[Q(sna)] represent the minimum
total payoﬀ of the system when the strategy is calcu-
lated given that there is no attack at all in K stages,
then ¯vp
1(s1l) − v∗[Q(sna)], since
v∗[Q(sna)] (cid:54) v∗[Q(s1l)] when the system operates in
normal state without sacriﬁcing any control cost to play
against attacks. The sub-optimality of value ¯vp
1(s1l) cal-
culated from Algorithm 1 is then bounded though we
do not know the true value v∗[Q(s1l)] of the game.

1(s1l) − v∗[Q(s1l)] (cid:54) ¯vp

5 A Moving-Horizon Approach for Hybrid

Stochastic Game

In this section, we propose a moving-horizon algorithm
to compute the saddle-point equilibrium strategy at each
stage of the hybrid stochastic game. A saddle-point equi-
librium strategy is computed at each stage k by predict-
ing anticipated future cost based on the hybrid state of
the system (x[k−T,k], δl). We develop Algorithm 2 based
on this concept, provides a scalable and a computation-
ally tractable process, and compare the computational
costs with Algorithm 1. The saddle-point equilibrium
strategy and the value of the moving-horizon game at
each stage involves solving ﬁnite zero-sum matrix games.
By looking one stage ahead of the game state at k, pre-
dicting the physical dynamics xk+1 given any action
pair, we obtain an objective function that reﬂects the

8

payoﬀ of the current stage and future expectation for
computing the strategies at k.

Given any action pair (aik, ujk) at stage k, we ﬁrst up-
date the state space form of the system dynamics xk+1
based on x[k−T,k] as (2). We view xk+1 as a function
of (x[k−T,k], aik, ujk), the immediate payoﬀ function
rij(s(k+1)h) (for stage k + 1) deﬁned as (3) is also a
function of the current game state and players’ actions.
We denote this relation as rk+1(x[k−T,k], aik, ujk, δh) in
the following algorithms to distinguish it between deﬁ-
nition (3), where the latter is the payoﬀ results from the
action of two players’ at stage k + 1. Then, we compute
the value of the matrix game at stage k + 1, by looking
one stage ahead and consider stage k + 1 as the termi-
nal stage of the game, the value of game stage k + 1 is
now directly calculated via for rij(x[k−T,k], aik, ujk, δh),
h = 1, 2, 3, i ∈ {1, · · · , M }, j ∈ {1, · · · , N } as (16):

vij
k+1(x[x−T,k], δh) = min

g

max
f

(r(x[k−T,k], aik, ujk, δh)),

(16)

where vk+1(x[k−T,k], δh) ∈ RM ×N is the value matrix
of stage k + 1 estimated at stage k based on the cur-
rent game state and all possible action pairs. With the
predicted value from the next stage, deﬁne the moving-
horizon auxiliary matrix for stage k as:

Qk(skl)

=r(skl) +

(cid:88)

sh∈S

Pk(s(k+1)h|skl) · vk+1(x[k−T,k], δh),

(17)

The dot products of matrices Pk(s(k+1)h|skl), vk+1(x[k−T,k],
δh) is an element-wise product of two elements at the
same position of the two matrices. The value and sta-
tionary equilibrium strategies that Algorithm 2 calcu-
lates at each stage k is deﬁned as following.

Deﬁnition 5 Given skl, vk+1(x[k−T,k], δh) as (16), and
auxiliary matrix Qk(skl) as (17), the value and equilib-
rium strategies at k are deﬁned as the following equation:

v(skl) = min
gk(skl)

max
fk(skl)

fk(skl)T Qk(skl)gk(skl),

(18)

where we treat the auxiliary matrix Qk(skl) as the payoﬀ
matrix of a zero-sum game of stage k.

At each stage k, we repeat calculating Qk(skl) and the
corresponding value and equilibrium strategies, then up-
date the system dynamics by the strategies for computa-
tion of next stage. The complete process is summarized
as Algorithm 2.

Algorithm 2 : Moving-Horizon Algorithm for A
Hybrid Stochastic Game

f (skl)T Qk(skl)g(skl),

Input: System model parameters and game parameters.
Initialization: ˆx[0,T ].
Iteration: For k = T, · · · , K+T −1, skl = (x[k−T,k], δl),
l = 1, 2, 3: get the auxiliary matrix (17); compute the
value and equilibrium strategies of every matrix game:
v(skl) = min
g(skl)

max
f (skl)
f ∗
k (skl) = arg max
fk(skl)
k (skl)]T Qk(skl)gk(skl).
[f ∗
g∗
k(skl) = arg min
gk(skl)
Update the system dynamics with strategies f ∗
l = 1, 2, 3 as described in 2 for the next stage.
Return: the concatenation of strategies for both players
f = {f ∗
k(skl)} and the value sequence
vk(skl), k = T, · · · , K + T, l = 1, 2, 3.

k (skl)}, g = {g∗

fk(skl)T Qk(skl)g∗

k (skl), g∗

k(skl),

k(skl),

To get the total payoﬀ till stage k by Algorithm 2, we
plug the strategies f , g into the system dynamics and
calculate the sum of payoﬀ for all stages. It is worth not-
ing that Algorithm 2 reduces the computational over-
head for the hybrid stochastic game. The complexity
of Algorithm 2 is equivalent to the complexity of solv-
ing (KM N ) times of minimax problem with an M × N
payoﬀ matrix, while the complexity of suboptimal Al-
gorithm 1 is equivalent to the complexity of solving
((M N )K) times of minimax problem with an M × N
payoﬀ matrix.

Remark 6 The system dynamics are deﬁned by a se-
quence of action pairs (aik, ujk) randomly chosen by
the attacker and the system, and are equivalent with
a system that randomly switches among N subsystems
according to the stochastic game strategies fk(skl). The
strategy sequences f ∗
k(skl) of the stochastic game
converge to fl, gl, l = 1, 2, 3, i.e.,
k (skl), gl = lim
f ∗
k→∞

g∗
k(skl), l = 1, 2, 3,

fl = lim
k→∞

k (skl), g∗

if updating system dynamics at stage k + 1 by (fl, gl)
results in:
lim
k→∞

Qk(s(k+1)l), l = 1, 2, 3.
Qk(skl) = lim
k→∞
f ∗
k (skl),
This is because according to Algorithm 2,
g∗
k(skl), l = 1, 2, 3 are the saddle-point equilibrium
strategies for the auxiliary matrices Qk(skl), l = 1, 2, 3.
When the strategy sequences of both players converge,
the switched system dynamics converge to a discrete-
time Markov jump linear system (with delays when the
attacker’s strategies include replay attacks), and the sta-
bility properties of the system that switches among stable
and unstable subsystems is analyzed by Zhang et al.
(2008) and Zhai et al. (2001).

6 Comparison of Algorithms

One advantage of the moving horizon Algorithm 2 is its
faster computation speed. Table 1 shows Matlab simula-
tion time for diﬀerent K-stage games, all with the same
size of action space for the system and attacker. When

9

K

20

50

100

real time algorithm suboptimal algorithm

1.8054s

4.9968s

8.3827s

6.7346s

58.6144s

2073.2928s

41.0342s

500
Table 1
Elapsed time comparison of two algorithms

20h

K increases, the diﬀerence between algorithm speed also
increases. We compare the cost of the strategies provided
by the suboptimal Algorithm 1 and Algorithm 2. The
example studied is an unstable batch reactor, a four di-
mensional system (see Walsh et al. (2002), Section IV.A
for model parameters).

We ﬁrst show the case under replay attacks, when the
system is equipped with two controllers, one steady state
Kalman ﬁlter, and the corresponding χ2 detector. An
optimal LQG controller u∗
K is denoted as controller 1,
and a non-optimal controller (u∗
k +∆uk) (Mo & Sinopoli
(2009)) with higher replay detection rate as controller
2. System’s action space includes: subsystem u1k with
controller 1 and subsystem u2k with controller 2. For
illustration, we show the case when the attacker’s ac-
tion space are discretized replay attack time window size
{10s, 20s, 30s, 40s} in simulation. We design switched
control policy for the system under replay attacks with
initial mode δ2, (i.e., p(δ1
2) = 1), we compare the sys-
tem’s strategies and total payoﬀ when applying subop-
timal strategies of Algorithm 1 and real-time receding
horizon Algorithm 2 in a ﬁnite game of stage K = 50.

Figure 3 shows the probability of switching to Con-
troller 2 at every stage according to diﬀerent algorithms.
Three cases are shown in Figure 4–when the system ap-
plies the strategy of Algorithm 1, the strategy of Algo-
rithm 2, and only the subsystem 2 with higher replay
detection rate through all stages. Figure 5 shows the
probability that system being at mode δ1 (successfully
detected an attack), when applying strategies obtained
from the two algorithms and always choosing subsys-
tem 2. Applying a game strategy, randomly switching
between subsystems results in a lower cost, while not
sacriﬁcing the detection rate signiﬁcantly.

For game strategies designed for multiple types of attack,
Figure 6 shows the case when attacks are successfully
detected and the system reaches the cyber mode δ1 =
saf e, the quadratic cost of the system converge. When
replay ﬁnally occurs at T2 = 100s, with a game-theoretic
strategy, the cost of the system is smaller than the cost
when system always applies a controller with higher cost
and higher detection rate. Data injection attacks shown
in Figure 6 appear during k = 30, 31, . . . , 50.

These ﬁgures illustrate that the real-time strategy re-
sults a higher cost than the suboptimal system strat-

egy, and they both provide lower control costs com-
pared to the non-game-theoretic approach. The non-
game-theoretic approach provides only a slightly higher
probability of being at the safe mode in K stages. By
introducing the game strategy, i.e., switching between
multiple subsystems, we do not sacriﬁce the payoﬀ of
the system while providing an acceptable detection rate,
even we discretize the attacker’s action space in the
game framework. For instance, Figures 4 and 5 show
the result when the actual replay attack occurs at T2 =
25s, and the game strategies are calculated with action
space At = {10s, 20s, 30s, 40s}. Since 25 is in between
[20, 30], and the error of the action space discretization
is bounded, a game strategy calculated via ﬁnite action
space improves the system’s performance.

7 Conclusion

In this work, we have proposed a zero-sum hybrid
stochastic game model to capture the interactions
between a cyber-physical system and an attacker —
switching policy for the system under diﬀerent types of
sensor attacks. This framework allows us to ﬁnd a con-
trol policy by calculating stationary strategy of the game
with information of the system’s physical dynamics and
cyber modes. We design a suboptimal value iteration
algorithm for a ﬁnite horizon game, which considers a
saddle-point equilibrium of a robust stochastic game at
each iteration. To reduce the computational complexity,
a real-time moving-horizon algorithm is then developed.
Based on the concept of saddle-point equilibrium for
the hybrid stochastic game, at each stage, we look one

Fig. 3. Strategies comparison of two algorithms for system
under replay attack–the probability of switching to subsys-
tem 2 at mode δ2 of every k.

Fig. 4. Cost comparison of system applying diﬀerent strate-
gies at mode δ2. Applying the suboptimal strategy provides
the smallest cost, and the strategy of the real time algorithm
is better than the one of a non-game approach.

10

Fig. 5. Comparison of the probability of the system being
at mode δ1 for diﬀerent strategies. Game strategies provide
similar detection rate with the non-switching policy.

Fig. 6. Cost comparison when system and the attacker apply
diﬀerent strategies. The replay attack occurs at T2 = 100s.

stage ahead to calculate anticipated future value. The
stability conditions of the system under multiple types
of attacks based on the stochastic game framework,
and an alternative algorithm with unknown transition
matrix or payoﬀs will be our future work.

References

Aghassi, M. & Bertsimas, D. (2006), ‘Robust game theory’,

Math. Program. 107(1), 231–273.

Basar, T. & Olsder, G. J. (1998), Dynamic Noncooperative
Game Theory, 2nd Edition, Society for Industrial and Ap-
plied Mathematics.

Cardenas, A., Amin, S., Sionpoli, B., Perrig, A. & Sastry, S.
(2009), Challenges for securing cyber physical systems, in
‘Workshop on future directions in cyber-physical systems
security’, DHS.

Humphreys, T. (2013), ‘Detection strategy for cryptographic
gnss anti-spooﬁng’, IEEE Transactions on Aerospace and
Electronic Systems pp. 1073–1090.

Kearns, M., Mansour, Y. & Singh, S. (2000), Fast planning in
stochastic games, in ‘Proceedings of the 16th Conference
on Uncertainty in Artiﬁcial Intelligence’, pp. 309–316.
Kim, K. & Kumar, P. (2012), ‘Cyber-physical systems: A
perspective at the centennial’, Proceedings of the IEEE
100(Special Centennial Issue), 1287–1308.

Kroer, C. & Sandholm, T. (2015), Discretization of contin-
uous action spaces in extensive-form games, in ‘Proceed-
ings of the 2015 International Conference on Autonomous
Agents and Multiagent Systems’, Richland, SC, pp. 47–56.
Manshaei, M., Zhu, Q., Alpcan, T., Basar, T. & Hubaux, J.
(2013), ‘Game theory meets network security and privacy’,
ACM Comput. Surv. 45(3), 25:1–25:39.

Miao, F., Pajic, M. & Pappas, G. J. (2013), Stochastic game
approach for replay attack detection, in ‘53th IEEE Con-
ference on Decision and Control’.

Miao, F. & Zhu, Q. (2014), A moving-horizon hybrid stochas-

0102030405000.20.40.60.8Timeprobabilityofapplyingcontroller2Strategiescomparisonwhensystembeingatcybermodeδ2  Suboptimal Algorithm 1 Real Time Algorithm 2010203040500100200300400TimeSystem’stotalcostSystemcostcomparisonwithinitialmodeδ2  System always applies controller−2Suboptimal strategyReal time strategy of algorithm 20102030405000.20.40.60.81TimeProbabilityofmodeδ1Probabilityofbeingatmodeδ1withdiﬀerentalgorithms  Always applies controller−2Suboptimal strategyStrategy Algorithm 2050100150200050010001500TimeSystem’s costCost comparison with different players’ strategies  Replay attack, non−game strategyReplay attack, game strategyData injections, game strategyReplay occurstic game for secure control of cyber-physical systems, in
‘IEEE 53rd Annual Conference on Decision and Control
(CDC)’, pp. 517–522.

Miao, F., Zhu, Q., Pajic, M. & Pappas, G. (2016), ‘Cod-
ing schemes for securing cyber-physical systems against
stealthy data injection attacks’, IEEE Transactions on
Control of Network Systems 4(1), 106–117.

Mo, Y., Kim, T.-H., Brancik, K., Dickinson, D., Lee, H.,
Perrig, A. & Sinopoli, B. (2012), ‘Cyber- physical security
of a smart grid infrastructure’, Proceedings of the IEEE
100(1), 195–209.

Mo, Y. & Sinopoli, B. (2009), Secure control against replay
attacks, in ‘47th Annual Allerton Conference on Commu-
nication, Contro, and Computing’, pp. 911–918.

Pajic, M., Tabuada, P., Lee, I. & Pappas, G. J. (2015),
Attack-resilient state estimation in the presence of noise,
in ‘2015 54th IEEE Conference on Decision and Control
(CDC)’, pp. 5827–5832.

Pajic, M., Weimer, J., Bezzo, N., Tabuada, P., Sokolsky, O.,
Lee, I. & Pappas, G. (2014), Robustness of attack-resilient
state estimators, in ‘ACM/IEEE International Conference
on Cyber-Physical Systems (ICCPS)’, pp. 163–174.

Pasqualetti, F., Dorﬂer, F. & Bullo, F. (2013), ‘Attack detec-
tion and identiﬁcation in cyber-physical systems’, Auto-
matic Control, IEEE Transactions on 58(11), 2715–2729.
Slay, J. & Miller, M. (2007), Lessons learned from the
maroochy water breach, in ‘Critical Infrast. Protection’,
pp. 73–82.

Verdu, S. & Poor, H. (1984), ‘On minimax robustness: A
general approach and applications’, IEEE Transactions on
Information Theory 30(2), 328–340.

Walsh, G., Ye, H. & Bushnell, L. (2002), ‘Stability analy-
sis of networked control systems’, IEEE Transactions on
Control Systems Technology 10, 438–446.

Xu, W., Trappe, W., Zhang, Y. & Wood, T. (2005), The
feasibility of launching and detecting jamming attacks in
wireless networks, in ‘Proceedings of the 6th ACM in-
ternational symposium on Mobile ad hoc networking and
computing’, pp. 46–57.

Zhai, G., Hu, B., Yasuda, K. & Michel, A. N. (2001), ‘Sta-
bility analysis of switched systems with stable and unsta-
ble subsystems: An average dwell time approach’, Inter-
national Journal of Systems Science 32, 1055–1061.

Zhang, L., Boukas, E. & Lam, J. (2008), ‘Analysis and syn-
thesis of markov jump linear systems with time-varying
delays and partially known transition probabilities’, IEEE
Transactions on Automatic Control 53(10), 2458–2464.
Zhong, M., Ding, X., Lam, J. & Wang, H. (2003), ‘An LMI
approach to design robust fault detection ﬁlter for uncer-
tain LTI systems’, Automatica 39(3), 543 – 550.

Zhu, M. & Martinez, S. (2011), Stackelberg-game analysis of
correlated attacks in cyber-physical systems, in ‘American
Control Conference (ACC), 2011’, pp. 4063–4068.

Zhu, Q. & Basar, T. (2015), ‘Game-theoretic methods for
robustness, security, and resilience of cyberphysical con-
trol systems: Games-in-games principle for optimal cross-
layer resilient control systems’, Control Systems, IEEE
35(1), 46–65.

11

