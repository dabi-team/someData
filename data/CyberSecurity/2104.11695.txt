1
2
0
2

r
p
A
3
2

]

G
L
.
s
c
[

1
v
5
9
6
1
1
.
4
0
1
2
:
v
i
X
r
a

A Framework for Unsupervised Classiﬁcation and Data Mining of Tweets about
Cyber Vulnerabilities

Kenneth Alperin∗

Emily Joback†

Leslie Shing‡

Gabe Elkin§

Abstract

Many cyber network defense tools rely on the National
Vulnerability Database (NVD) to provide timely information
on known vulnerabilities that exist within systems on a
given network. However, recent studies have indicated
that the NVD is not always up to date, with known
vulnerabilities being discussed publicly on social media
like Twitter and Reddit, months before they
platforms,
are published to the NVD. To that end, we present a
framework for unsupervised classiﬁcation to ﬁlter tweets
for relevance to cyber security. We consider and evaluate
two unsupervised machine learning techniques for inclusion
in our framework, and show that zero-shot classiﬁcation
using a Bidirectional and Auto-Regressive Transformers
(BART) model outperforms the other technique with 83.52%
accuracy and a F1 score of 83.88, allowing for accurate
ﬁltering of tweets without human intervention or labelled
data for training. Additionally, we discuss diﬀerent insights
that can be derived from these cyber-relevant tweets, such as
trending topics of tweets and the counts of Twitter mentions
for Common Vulnerabilities and Exposures (CVEs), that can
be used in an alert or report to augment current NVD-based
risk assessment tools.

1

Introduction

The NVD publishes open source information about cy-
ber vulnerabilities as they are reported, and many net-
work defense tools use the NVD as a data source to
update organizations of risks and threats to a given
network. For example, if a network contains comput-
ers that use Windows operating systems, a tool might
reference the NVD to alert users on known weaknesses
in Windows that a hacker could potentially use as a
foothold to access the network. Such alerts will inform
network security analysts to patch the system before
a malicious actor can exploit the vulnerability. There-
fore, it is critical that the NVD is updated as soon as a
vulnerability is discovered in order to give security an-
alysts an advantage against cyber attackers. However,

∗MIT Lincoln Laboratory, kenneth.alperin@ll.mit.edu
†MIT Lincoln Laboratory
‡MIT Lincoln Laboratory
§MIT Lincoln Laboratory

research shows the NVD is not always updated in a
timely manner, and that information about vulnerabili-
ties is often openly discussed on social media platforms
months before it is published by the NVD [16, 17, 1].
These social media platforms, such as Twitter, Reddit,
and GitHub, have become proﬁlic sources of informa-
tion due to the wide access and reach of these mediums
[19, 7]. These platforms can be leveraged as open source
threat intelligence (OSINT) for use by cyber operators.
Vulnerabilities are given a Common Vulnerabilities
and Exposures identiﬁer (CVE ID) when entered into
the NVD. However, social media platforms, like Twitter,
may often exclude the CVE ID in their discussions
of vulnerabilities that have not yet been published to
the NVD. Even after a vulnerability is in the NVD,
related discussions on Twitter may still lack the CVE
ID. Therefore, the data gathered for analysis of tweets
with trending vulnerability discussions should not be
limited to tweets that contain CVE IDs, but encompass
all tweets related to cyber vulnerabilities. To address
this, we present a framework for unsupervised relevance
ﬁltering of ‘vulnerability’ tweets and insights that can
be gained from mining cyber-relevant tweets. The
contributions of our work include:

• An implementation of two unsupervised meth-
ods evaluated on a labelled ‘vulnerability’ Twitter
dataset, with the zero-shot BART classiﬁer yielding
an 83.52% accuracy. To our knowledge, prior ma-
chine learning (ML) techniques for cyber-relevance
ﬁltering require labelled data for supervised meth-
ods or ﬁne-tuning on a cyber-relevant dataset;

• Unique insights that can be gained from cyber-
relevant tweets, including topic analysis and counts
of tweets per CVE, and a use case showing how
tweet counts can prioritize CVEs with low Common
Vulnerability Scoring System (CVSS3) [24] scores.

Together, this relevance ﬁltering and data mining frame-
work allows for real-time situation awareness (SA) of
vulnerability information from Twitter that can sup-
plement existing tooling. Finally, we discuss ways to
extend this work into operational use.

We ﬁrst provide an overview of prior work related

Copyright © 2021 by SIAM
Unauthorized reproduction of this article is prohibited

 
 
 
 
 
 
to our analysis in Section 2. In Section 3, we discuss
our approach to implementing and evaluating diﬀerent
unsupervised ML methods for relevance ﬁltering.
In
Section 4, we discuss insights gained from mining cyber-
relevant tweets with examples. In Section 5, we discuss
our ﬁndings and limitations, and highlight future re-
search directions to build on this work.

2 Related Work

Prior work exists in applying ML to ﬁlter for cyber-
relevant tweets. To our knowledge, they all require la-
belled data for training in supervised methods or ﬁne-
tuning on a cyber-relevant dataset. Supervised classiﬁ-
cation has been used on tweets related to IT assets [4],
tweets containing at least one security keyword from cer-
tain user accounts [2], tweets from cyber experts with
n-grams extracted [13], and social media threats from
multiple platforms [10]. Mittal et al. use a trained
named entity recognizer to extract security terms from
tweets, and then label tweets with at least two security
terms as cyber-relevant [12]. On the labelled dataset we
use, Behzadan et al. achieve 94.72% accuracy [3] and
Simran et al. get 89.3% with word embeddings [20], but
these methods requires training and labelled data. Shin
et al. use word embeddings and ﬁne-tune with cyber se-
curity positive and negative data, but do not speciﬁcally
focus on tweets [18]. Iorga et al. classiﬁed news articles
as cyber-relevant using a ﬁne-tuned BERT model [8].

There is also prior work in mining features for anal-
ysis from cyber-relevant tweets. Rodriguez et al. use
keywords to ﬁlter for cyber-relevance and active learn-
ing to update the keywords, and use tweet sentiment as
a feature over time [15]. Zong et al. study the connec-
tion of severity of cyber threats with how they are dis-
cussed online [22]. Hoppa et al. visualize cyber-relevant
tweets in Kibana for end users [6]. Alves et al. cluster
cyber-relevant tweets, select exemplar tweets for each
cluster, enrich those tweets with extracted CVEs, asso-
ciated CVSS impact scoring and publish date, [2], and
count Twitter mentions per CVE [1]. There is also re-
search in generating alerts and indicators of compromise
(IoCs) from tweets [12, 4]. Sabottke et al. analyze ex-
ploits associated with vulnerabilities from Twitter [16].

3 Relevance Filtering

The goal of relevance ﬁltering is to reduce the large cor-
pus of topically-varied tweets down to a more manage-
able and cyber-relevant set for downstream data min-
ing and analysis. In this section, we describe two un-
supervised ML methods considered for inclusion in our
pipeline, evaluate their performances in correctly clas-
sifying tweets as cyber-relevant or not using a labelled
dataset, and discuss tradeoﬀs of the methods.

3.1 Classiﬁcation Techniques We considered two
unsupervised classiﬁcation techniques for relevance ﬁl-
tering. We focused exclusively on unsupervised meth-
ods for a couple reasons. First, we wanted to develop
a ﬁltering pipeline that could be used in a real-time
operational setting and be resilient to the addition of
new data points. The performance of supervised ML
models tends to degrade over time when the distribu-
tion of new data points diﬀers widely from that of the
model’s training data. In particular, Twitter topics can
trend in varying degrees over diﬀerent time periods, so
it is important to have a robust classiﬁcation model that
can account for this variation. Second, supervised ML
models require labelled data to train the models. These
datasets are not readily available and labelling is a time-
intensive and manual process. Thus, to overcome these
short-comings, we investigated the inclusion of k-means
clustering and zero-shot classiﬁcation into our pipeline.
k-means clustering is a widely used technique for
identifying subgroups of ”similar” points within a larger
dataset [5]. The number of clusters, k, is set by the
user. The algorithm then determines the groupings by
identifying k cluster centroids such that the sum of the
squared Euclidean distance between points within each
cluster and the corresponding centroid is minimized.
For this method, we ﬁrst used Term Frequency-Inverse
Document Frequency (TF-IDF) to convert each tweet
to a vector representation for the numeric importance
of each term to each document [14]. Then those vectors
were inputted into the k-means algorithm. To identify
a cluster as cyber-relevant, we assumed there must be
at least one tweet in the cluster with a CVE mentioned.
One of the more recent advances in language mod-
eling is zero-shot classiﬁcation. This method applies
language models, such as BART [9], to associate in-
put text with a user-speciﬁed hypothesis, such as ‘This
text is related to cyber security’ (the prompt used for
our analysis), and generates a likelihood of the hypoth-
esis being correct.
In this way, the language model
acts as a classiﬁer and does not require any training
by the user since the model comes pre-trained on large
amounts of sentence/hypothesis pairs. Speciﬁcally, we
tested two diﬀerent BART models. The bart-large-mnli
model comes pre-trained on the Multi-Genre Natural
Language Inference (MultiNLI) corpus [21], which con-
tains 433,000 sentences paired with hypotheses. The
distilbart-mnli-12-3 model is distilled from the bart-
large-mnli model, containing fewer parameters and runs
faster, but is slightly less accurate.

3.2 Dataset In this experiment, the unsupervised
techniques were evaluated on a labelled dataset of
tweets from Behzadan et al [3]. The dataset contains

Copyright © 2021 by SIAM
Unauthorized reproduction of this article is prohibited

21,368 tweets collected over four days using common
cyber security keywords, and were labelled as ‘threat’,
‘business’, ‘unknown’, and ‘irrelevant’. Since we focus
on vulnerabilities, we ﬁrst ﬁltered the dataset for tweets
that contain the term ‘vulnerability’, which came out to
9,963 tweets. Tweets labelled as ‘business’, ‘unknown’
and ‘threat’ were replaced with a ‘cyber-relevant’ label
as they also appeared to be relevant to cyber security,
and comprised 54.5% of the ﬁltered dataset.

Table 1: Relevance Filtering Classiﬁcation Results

Method
k-means
k-means
k-means
Zero-Shot
Zero-Shot

Parameter
k=2
k=5
k=10
bart-large-mnli
distilbart-mnli-12-3

Acc.
55.21
54.01
53.46
83.52
83.40

F1
70.74
70.06
68.62
83.88
83.53

3.3 Results Table 1 shows the accuracy and F1 score
for each method evaluated against the labelled dataset.
For the k-means pipeline, we evaluated values 2, 5, and
10 for k, and used the previously described method for
labelling clusters as cyber-relevant. All the methods
are over 99% accurate in classifying tweets with ex-
plicit CVE mentions as cyber-relevant, which comprises
12.49% of the dataset. However, on all ‘vulnerability’
tweets, the zero-shot classiﬁcation models signiﬁcantly
outperform the k-means clustering approach, with the
bart-large-mnli model resulting in the highest accuracy
of 83.52% and the highest F1 score of 83.53. On the
set of tweets with no CVE mention, the bart-large-mlni
model is 81.29% accurate with a F1 score of 78.85. On
a Volta GPU, the distilbart-mnli-12-3 takes 2.18 min-
utes to classify the dataset, whereas the bart-large-mnli
model takes 3.64 minutes. Overall, the BART model
can accurately predict cyber-relevance without any ﬁne-
tuning or supervised training, making it useful in a
framework for classifying tweets in real-time.

4 Data Mining of Cyber-Relevant Tweets

With the ability to ﬁlter tweets for cyber-relevance in
real-time using an unsupervised ML method, the next
step is to mine the corpus for insights that could be
useful for a cyber operator. In this section, we discuss
the use of word embeddings to identify key topics and
trends in our collected Twitter dataset, and the metric
developed to identify the most discussed vulnerabilities
based on CVE mention counts.

4.1 Dataset To create a new dataset for analysis,
we used the Twitter API to collect tweets in real-
time that contained the keyword ‘vulnerability’, which
we hypothesized was a suitable term for producing
tweets related to cyber vulnerabilities in our initial

Figure 1: Most common phrases in tweets containing
the term ‘vulnerability’ from 2/19/20−3/18/20

data collection. These tweets were collected from
2/19/20−3/18/20, and statistics for these are in Table
2. Figure 1 is a word cloud of the most common
phrases across this corpus. The zero-shot bart-large-
mnli classiﬁer ﬁltered out 76.83% of tweets, producing
77,979 tweets classiﬁed as cyber-relevant for analysis.

Table 2: Characteristics of Collected Tweets

Statistic
Number of Tweets
Avg. Tweets per Day
Avg. Words per Tweet
% English Tweets
% Tweets with URL

Value
337,468
12,052
29
92%
45%

4.2 Topic Analysis Word embeddings were used as
an alternative to TF-IDF to numerically represent the
text. While TF-IDF is useful at capturing a few key
terms describing a given text, it does not account for
words based on their relationships or contexts. For
example, the terms ‘vulnerability’ and ’vector’ may
seem unrelated when observed as a bag-of-words by TF-
IDF but in context are actually related to a cyber attack
surface. A word embedding model, like Word2Vec [11],
detects this relationship and meaning by considering
the surrounding words. Word2Vec is a neural network
that learns a vector of weights for each term in a text
corpus. Given two diﬀerent words contained in nearly
identical phrases, the weights learned for that word
will be similar, and thus the two words will be close
to each other in the vector space representation. The
terms in each tweet were inputted to Word2Vec without
any pre-processing, which created a word embedding.
Clustering can then be applied to the word embeddings
to yield topics within the full set of text data.

Figure 2 shows our topic analysis pipeline. We
used the elbow method in plotting the sum of squared
errors (SSE) for diﬀerent k values to select the optimal
k, which ended up being 10. There are 31,821 unique

Copyright © 2021 by SIAM
Unauthorized reproduction of this article is prohibited

Figure 2: Topic Analysis Pipeline

tweets in this corpus, but clustering only those showed
little diﬀerence. Table 3 shows three of the clusters
generated with the number of tweets and most common
key terms.
In particular, we see a cluster centered
around the KR00K CVE [23], and two clusters for
diﬀerent types of Microsoft vulnerabilities. These initial
clusters show promise in topic identiﬁcation, but further
analysis is warranted to determine optimal clustering
parameters. These clusters allow for quick triaging
of vulnerability information and enable an analyst to
eﬃciently focus on certain topics.

Table 3: Topic Analysis Keywords for Example Clusters

ID Total Tweets
1
5
7

8,701
4,414
4,995

Keywords
patch, Microsoft, SMBv3
devices, Wi-Fi, KR00K
remote, code, Microsoft

4.3 CVE Tweet Counts In addition to trending
topics, we also implemented metrics to determine the
degree of importance of certain vulnerability mentions
extracted from our curated cyber-relevant Twitter cor-
pus. In particular the ‘tweet count‘ for a CVE observes
the number of times a CVE is mentioned in the tweets
across a speciﬁed time period. The tweet count can in-
dicate public interest in the vulnerability, and serve as
a potential proxy to measuring the exploitability of the
vulnerability. For instance, if many users are discussing
a CVE, it is possibly an active threat on their networks.

Table 4: Most Mentioned CVEs on Collected Tweets

CVSS3 Tweet Count

CVE ID
CVE-2020-0688
CVE-2020-1938
CVE-2020-8597
CVE-2020-8794
CVE-2019-15126

8.8
N/A
9.8
9.8
3.1

1621
1014
741
349
279

tools

Many vulnerability management

rely on
CVSS3 scoring to prioritize vulnerabilities on a network,
since cyber defenders do not have time and resources to
patch every vulnerability. Table 4 shows the ﬁve most
mentioned CVEs from the tweets we collected, along
with their CVSS3 scores and tweet counts during the
time period. We also calculated the correlation of the
tweet counts and the CVSS3 scores for the CVEs in
our corpus, which came out to .04, indicating no cor-
relation. The ﬁfth most mentioned vulnerability, CVE-

2019-15126, is called the KR00K CVE, and allows unau-
thorized decryption in WiFi chips. Even though it has
a low CVSS3 score of 3.1, the CVE has aﬀected over 1
billion devices from companies such as Amazon, Apple,
and Google, and has a known exploit [23]. The tweet
count metric can detect exploited CVEs otherwise not
prioritized by traditional risk management metrics.

5 Discussion and Future Work

The zero-shot classiﬁcation pipeline was able to accu-
rately ﬁlter out a large percentage of tweets and re-
tain the cyber-relevant samples, without any labelled
training data. Future work on the pipeline includes ex-
panding the Twitter data collection to include other key
terms, such as ‘exploit’, and expand to data collected
from Reddit. Tweets about cyber vulnerabilities can
be mined for useful insights, such as the tweet count
per CVE. This metric can detect some highly exploited
CVEs otherwise not prioritized by other risk manage-
ment metrics. Future work includes identifying other
attributes about authors of tweets, such as their country
of origin and association with security organizations, to
weight the validity and importance of collected tweets,
and analyzing the diﬀerence in chatter around vulnera-
bilities before and after they are published in the NVD.
We plan to incorporate these metrics and analyses
into a reporting dashboard or alerting tool that opera-
tors can use in real-time for improved SA. The informa-
tion from tweets can augment current risk assessment
tools that rely on the NVD, since social media enrich-
ment reporting provides analysts additional CVE infor-
mation and additional patch actions not possible before
through links shared in the posts. Future work includes
developing a user interface to generate reports.

6 Conclusion

In this paper, we show how unsupervised zero-shot clas-
siﬁcation using the BART language model allows for
accurate prediction of cyber-relevance for tweets con-
taining the term ‘vulnerability’, with an accuracy of
83.52%. This is signiﬁcant since this method does not
require any manual labelling of data for training or ﬁne-
tuning of a model. Cyber-relevant tweets can be mined
to extract information and insights that are useful in
cyber SA. One such insight is the tweet count metric,
and we show how it prioritizes vulnerabilities that other-
wise would not be highlighted using traditional ranking
methods such as CVSS3. Social media data can aug-
ment current risk management tooling, and we plan to
incorporate our ﬁndings from this paper into a reporting
dashboard or alerting tool that would provide cyber op-
erators with real-time SA of information disseminated
on social media platforms.

Copyright © 2021 by SIAM
Unauthorized reproduction of this article is prohibited

7 Acknowledgments

DISTRIBUTION STATEMENT A. Approved for pub-
lic release. Distribution is unlimited. This material
is based upon work supported by the Federal Aviation
Administration under Air Force Contract No. FA8702-
15-D-0001. Any opinions, ﬁndings, conclusions or rec-
ommendations expressed in this material are those of
the author(s) and do not necessarily reﬂect the views of
the Federal Aviation Administration. Delivered to the
U.S. Government with Unlimited Rights, as deﬁned in
DFARS Part 252.227-7013 or 7014 (Feb 2014). Notwith-
standing any copyright notice, U.S. Government rights
in this work are deﬁned by DFARS 252.227-7013 or
DFARS 252.227-7014 as detailed above. Use of this
work other than as speciﬁcally authorized by the U.S.
Government may violate any copyrights that exist in
this work.

References

[1] F. Alves, A. Andongabo, I. Gashi, P. M. Ferreira, and
A. Bessani, “Follow the blue bird: A study on threat
data published on twitter,” in European Symposium on
Research in Computer Security, pp. 217–236, Springer,
2020.

[2] F. Alves, A. Bettini, P. M. Ferreira, and A. Bessani,
“Processing tweets for cybersecurity threat awareness,”
Information Systems, vol. 95, p. 101586, 2021.

[3] V. Behzadan, C. Aguirre, A. Bose, and W. Hsu, “Cor-
pus and deep learning classiﬁer for collection of cy-
ber threat indicators in twitter stream,” in 2018 IEEE
International Conference on Big Data (Big Data),
pp. 5002–5007, IEEE, 2018.

[4] N. Dion´ısio, F. Alves, P. M. Ferreira, and A. Bessani,
“Cyberthreat detection from twitter using deep neural
networks,” in 2019 International Joint Conference on
Neural Networks (IJCNN), pp. 1–8, IEEE, 2019.
[5] J. A. Hartigan and M. A. Wong, “Ak-means clustering
algorithm,” Journal of the Royal Statistical Society:
Series C (Applied Statistics), vol. 28, no. 1, pp. 100–
108, 1979.

[6] M. A. Hoppa, S. M. Debb, G. Hsieh, and B. KC, “Twit-
terosint: Automated open source intelligence collec-
tion, analysis & visualization tool,” Annual Review of
Cybertherapy and Telemedicine, vol. 17, p. 121–128,
2019.

[7] S. Horawalavithana, A. Bhattacharjee, R. Liu,
N. Choudhury, L. O. Hall, and A. Iamnitchi, “Men-
tions of security vulnerabilities on reddit, twitter and
github,” in IEEE/WIC/ACM International Confer-
ence on Web Intelligence, pp. 200–207, 2019.

[8] D. Iorga, D. Corl˘atescu, O. Grigorescu, C. S˘andescu,
M. Dasc˘alu, and R. Rughini¸s, “Early detection of vul-
nerabilities from news websites using machine learning
models,” in 2020 19th RoEduNet Conference: Network-

ing in Education and Research (RoEduNet), pp. 1–6,
2020.

[9] M. Lewis, Y. Liu, N. Goyal, M. Ghazvininejad, A. Mo-
hamed, O. Levy, V. Stoyanov, and L. Zettlemoyer,
“Bart: Denoising sequence-to-sequence pre-training for
natural language generation, translation, and compre-
hension,” arXiv preprint arXiv:1910.13461, 2019.
[10] R. P. Lippmann, J. P. Campbell, D. J. Weller-Fahy,
A. C. Mensch, and W. M. Campbell, “Finding ma-
licious cyber discussions in social media,” tech. rep.,
MASSACHUSETTS INST OF TECH LEXINGTON
LEXINGTON United States, 2016.

[11] T. Mikolov, K. Chen, G. Corrado, and J. Dean,
“Eﬃcient estimation of word representations in vector
space,” arXiv preprint arXiv:1301.3781, 2013.

[12] S. Mittal, P. K. Das, V. Mulwad, A. Joshi, and
T. Finin, “Cybertwitter: Using twitter to gener-
ate alerts for cybersecurity threats and vulnerabili-
ties,” in 2016 IEEE/ACM International Conference
on Advances in Social Networks Analysis and Mining
(ASONAM), pp. 860–867, IEEE, 2016.

[13] A. Queiroz, B. Keegan, and F. Mtenzi, “Predicting
software vulnerability using security discussion in so-
cial media,” in European Conference on Cyber Warfare
and Security, pp. 628–634, Academic Conferences In-
ternational Limited, 2017.

[14] J. Ramos et al., “Using tf-idf to determine word rele-
vance in document queries,” in Proceedings of the ﬁrst
instructional conference on machine learning, vol. 242,
pp. 29–48, Citeseer, 2003.

[15] A. Rodriguez and K. Okamura, “Social media data
mining for proactive cyber defense,” Journal of Infor-
mation Processing, vol. 28, pp. 230–238, 2020.

[16] C. Sabottke, O. Suciu, and T. Dumitras,, “Vulnera-
bility disclosure in the age of social media: Exploit-
ing twitter for predicting real-world exploits,” in 24th
{USENIX} Security Symposium ({USENIX} Security
15), pp. 1041–1056, 2015.

[17] C. Sauerwein, C. Sillaber, M. M. Huber, A. Mussmann,
and R. Breu, “The tweet advantage: An empirical
analysis of 0-day vulnerability information shared on
twitter,” in IFIP International Conference on ICT
Systems Security and Privacy Protection, pp. 201–215,
Springer, 2018.

[18] H.-S. Shin, H.-Y. Kwon, and S.-J. Ryu, “A new
text classiﬁcation model based on contrastive word
embedding for detecting cybersecurity intelligence in
twitter,” Electronics, vol. 9, no. 9, p. 1527, 2020.
[19] P. Shrestha, A. Sathanur, S. Maharjan, E. Saldanha,
D. Arendt, and S. Volkova, “Multiple social plat-
forms reveal actionable signals for software vulnerabil-
ity awareness: A study of github, twitter and reddit,”
Plos one, vol. 15, no. 3, p. e0230250, 2020.

[20] K. Simran, P. Balakrishna, R. Vinayakumar, and
K. Soman, “Deep learning approach for enhanced cyber
threat indicators in twitter stream,” in International
Symposium on Security in Computing and Communi-
cation, pp. 135–145, Springer, 2019.

Copyright © 2021 by SIAM
Unauthorized reproduction of this article is prohibited

[21] A. Williams, N. Nangia, and S. Bowman, “A broad-
coverage challenge corpus for sentence understanding
through inference,” in Proceedings of the 2018 Confer-
ence of the North American Chapter of the Associa-
tion for Computational Linguistics: Human Language
Technologies, Volume 1 (Long Papers), pp. 1112–1122,
Association for Computational Linguistics, 2018.
[22] S. Zong, A. Ritter, G. Mueller, and E. Wright,
“Analyzing the perceived severity of cybersecurity
threats reported on social media,” arXiv preprint
arXiv:1902.10680, 2019.

[23] “Kr00k: A serious vulnerability deep inside wi-ﬁ en-

cryption.” Accessed: 2021-02-09.

[24] “Common Vulnerability Scoring System v3.1: Speciﬁ-
cation Document.” Accessed: February 9, 2021.

Copyright © 2021 by SIAM
Unauthorized reproduction of this article is prohibited

