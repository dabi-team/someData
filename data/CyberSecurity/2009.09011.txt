Experimental Review of Neural-based approaches
for Network Intrusion Management

Mario Di Mauro, Member, IEEE, Giovanni Galatro, Antonio Liotta, Senior Member, IEEE

1

0
2
0
2

p
e
S
8
1

]
I

N
.
s
c
[

1
v
1
1
0
9
0
.
9
0
0
2
:
v
i
X
r
a

Abstract—The use of Machine Learning (ML) techniques in
Intrusion Detection Systems (IDS) has taken a prominent role in
the network security management ﬁeld, due to the substantial
number of sophisticated attacks that often pass undetected
through classic IDSs. These are typically aimed at recognizing
attacks based on a speciﬁc signature, or at detecting anomalous
events. However, deterministic, rule-based methods often fail to
differentiate particular (rarer) network conditions (as in peak
trafﬁc during speciﬁc network situations) from actual cyber
attacks. In this paper we provide an experimental-based review
of neural-based methods applied to intrusion detection issues.
Speciﬁcally, we i) offer a complete view of the most promi-
nent neural-based techniques relevant to intrusion detection,
including deep-based approaches or weightless neural networks,
which feature surprising outcomes; ii) evaluate novel datasets
(updated w.r.t. the obsolete KDD99 set) through a designed-from-
scratch Python-based routine; iii) perform experimental analyses
including time complexity and performance (accuracy and F-
measure), considering both single-class and multi-class problems,
and identifying trade-offs between resource consumption and
performance. Our evaluation quantiﬁes the value of neural
networks, particularly when state-of-the-art datasets are used to
train the models. This leads to interesting guidelines for security
managers and computer network practitioners who are looking
at the incorporation of neural-based ML into IDS.

Index Terms—Network Intrusion Detection, Neural Networks,

Deep Learning, Network and Security Management

I. INTRODUCTION

Over the past few years, the adoption of Machine Learning
(ML) techniques to the ﬁeld of network security has become
prominent [1], [2]. This is mainly due to the possibility of
tackling a range of ever more sophisticated attacks able to cir-
cumvent security-based systems which rely on classic features
inspection (e.g. port-control, signature-based ﬂow detection,
IPs black-listing, etc.). It is useful to recall that, especially in
encrypted trafﬁc analysis, the difference between deterministic
and stochastic features is crucial. Deterministic ones pertains
to “static” information embodied in security protocols such
as TLS (e.g. record length, handshake types, cipher suites,
etc.) [3], or IPSec (ISAKMP SPI Initiator/Responder, payload
length, etc. ). On the other hand, stochastic features exploit the
probabilistic nature (hard to hide in encrypted ﬂows as well) of
some trafﬁc characteristics (e.g. the distribution of inter-arrival
times). On behalf of ML-based techniques, it becomes quite

M. Di Mauro

and G. Galatro

are with

and Electrical Engineering

Information
(DIEM), University
of
mdimauro@unisa.it,giovanni.galatro@gmail.com).

Salerno,

84084,

the Department

of
and Applied Mathematics
(E-mail:

Fisciano,

Italy

A. Liotta is with the Free University of Bozen-Bolzano, Italy (E-mail:

Antonio.Liotta@unibz.it)

straightforward to manage stochastic features which, coupled
with the deterministic ones, allow to characterize as accurately
as possible an encrypted data ﬂow.

Moreover, new network intrusion detection systems (NIDS)
[4], [5] can actually interact with ML-based engines in order
to learn the statistical features that characterize the various
trafﬁc ﬂows and, in turn, classify them according to spe-
ciﬁc performance/time efﬁciency trade-offs. Among various
possibilities of interaction, the Simple Network Management
Protocol (SNMP) offers a ﬂexible and standardized way to
collect trafﬁc data from a number of agents, by relying on
Management Information Base (MIB) objects which provide
information about some features to be managed [6]–[8].

This notwithstanding, one of the biggest problems is to
deal with the jungle of ML techniques which, depending
on the underlying strategy, can exhibit completely different
performance when applied in the intrusion detection ﬁeld.

In fact, most attempts at surveying ML-based trafﬁc clas-
siﬁcation problems have resulted in non-homogeneous com-
parisons and often unfair outcomes. Another ﬂaw found in
existing literature concerns the choice of a valid dataset. Most
of studies, in fact, rely on the obsolete KDD99 dataset [9],
or its evolved version NSL-KDD [10]. These datasets either
do not contemplate essential features of modern data trafﬁc
(e.g. voice, video), or contain outdated signatures of network
attacks [11].

In this paper we address the aforementioned shortcomings,
i) We survey
providing the following main contributions.
neural-based techniques, which have recently taken promi-
nence thanks to deep-based methods, in the speciﬁc context of
trafﬁc classiﬁcation problems; we provide a critical compari-
son of algorithms that share a common paradigm (e.g. deep
neural networks, linear vector quantization, etc.), including
also techniques that are not typically applied to intrusion de-
tection, such as weightless neural networks, whose results are
quite unexpected. ii) We go beyond a traditional survey, pro-
viding an experimental-based assessment; we take into account
novel trafﬁc datasets (such as CIC-IDS-2017/2018), where
both single-class cases (namely benign vs. malign) and multi-
class cases (namely benign vs. malign1 ... vs. malignk) are
considered; we perform both performance analysis (through
accuracy/F-measure ﬁgures) and time-complexity analysis.

The paper is organized as follows. Section II presents an
excursus of related literature and, by means of a comparative
table, we highlight differences and commonalities with other
surveys. In Sect. III we review the most credited neural-
based methods. Section IV presents details about the novel
considered datasets, where trafﬁc features are grouped ac-
cording to a similarity criterion. In Sect. V we provide an

 
 
 
 
 
 
experimental-based comparison, where different neural-based
techniques are juxtaposed through performance and time-
complexity analyses. Finally, Section VI concludes this work
by also indicating some promising research directions.

II. RELATED WORK ON ML TECHNIQUES APPLIED TO
NETWORK INTRUSION DETECTION

ML-based intrusion detection is becoming attractive for a
variety of network environments including service providers
[12], sensor networks [13], Internet of Things [14], and
automotive [15]. This notwithstanding, a great part of scientiﬁc
literature, which faces the problem of data trafﬁc classiﬁcation
through machine learning techniques, suffers from the datasets
obsolescence issue. For many years, the only dataset available
to the scientiﬁc community was the so-called KDD99, which
is still broadly used today to validate ML-based algorithms
and techniques when dealing with trafﬁc classiﬁcation prob-
lems. Unfortunately, this is an outdated 20-years-old dataset
involving network attacks that have already been mitigated.
An example is satan probing, an attack aimed at probing a
computer for security loophole, based on the satan tool that
was created at the end of the 1990s, but is today no longer
documented as a Web page.

Other examples include: warezmaster/warezclient, which
exploits some old vulnerabilities of the anonymous FTP pro-
tocol, and smurf attacks, aimed at attaining default router
settings that allowed directed broadcasts. Yet, currently, router
vendors simply deactivate this functionality. An ameliorated
version of KDD99 is known as NSL-KDD. However, despite
providing some improvements (e.g. no redundant records, bet-
ter balancing between training and test set), NSL-KDD is still
not taking into account crucial information that characterizes
novel cyber attacks.

This notwithstanding, both KDD99 and NSL-KDD datasets
are still broadly used to test some functionalities of NIDS
systems that implement neural-based techniques. For instance,
in [16]–[18] the authors show the effectiveness of using an
NIDS in conjunction with an artiﬁcial neural network (ANN)
to improve the quality of trafﬁc detection, where a validation
stage onto the KDD99 dataset is performed. A deep learning
approach is used in [19], based on KDD99, to verify accuracy
against an SVM methodology. A novel approach based on
ANN (referred to as self-taught learning) is applied in [20] to
enable an NIDS to detect previously unseen attacks via recon-
structions made on unlabeled data. This work provides tests
on both KDD99 and NSL-KDD. In [21] and [22] the authors
adopt neural-based methods exploiting Self-Organizing Maps.
In [23] and [24], Learning Vector Quantization is coupled with
SVM and k-Nearest Neighbor, respectively, to detect trafﬁc
anomalies. In [25]–[28] deep neural networks concepts are
applied to intrusion detection systems.

The KDD99 and NSL-KDD datasets have also been used
to test a variety of non neural-based techniques such as Sup-
port Vector Machine [29]–[33], Principal Component Analysis
[34]–[38], Decision Trees [39]–[42], [42], [43], and various
unsupervised approaches [44]–[49].

By contrast

to the aforementioned works, some recent
datasets are emerging from new testbeds which adhere more

2

strictly to real-world network scenarios. For instance,
the
Cyber Range Lab of the Australian Centre for Cyber Security
provides two recent datasets: the UNSW-NB15 dataset [50]
which includes a mix of legitimate network activities and
synthetic attacks, and the Bot-IoT dataset [51] which embeds
normal and simulated network trafﬁc gathered in an IoT-
compliant testbed, along with various types of attacks.

Again, the datasets recently released by the Canadian Insti-
tute for Cybersecurity (CIC) [52] represent the state-of-the-art,
in terms of both complexity and novelty of network attacks.
These datasets have been created starting from an experimental
testbed under controlled conditions [11], whereby an attack
network (including a router, a switch, and four PCs equipped
with Kali Linux OS, which is a popular Linux distribution
to perform penetration testing) is counterposed to a victim
network (including routers, ﬁrewalls, switches, and various
PCs equipped with Windows, Linux, and MacOS operating
systems). An evolved version of this testbed has been designed
to run on Amazon AWS [53]. In this case, the attacking
infrastructure includes 50 PCs, and the victim network in-
cludes 420 PCs and 30 servers. The implemented attacks
encompass Distributed Denial of Service (DDoS), Portscan,
Bruteforce, along with some typical Android-based network
attacks injecting malicious codes such as adwares, malwares,
and ransomwares.

The interest for such novel datasets is proven by novel
works as detailed in the following. In [54], authors validate an
artiﬁcial neural network system onto a CIC-released dataset to
detect the malicious trafﬁc generated by a botnet, out of the
regular trafﬁc. A hybrid neural network to detect anomalies
in network trafﬁc is proposed in [55], where the CIC-IDS-
2017 dataset has been exploited. Speciﬁcally focused on DDoS
detection is the work in [56], where a neural-based approach
relying on the implementation of a simple Multi-Layer Per-
ceptron is contrasted to the Random Forest technique. Again
focused on DDoS detection is [57], where some classic ML-
based techniques (e.g. Na¨ıve Bayes and Logistic Regression)
are used to distinguish regular trafﬁc from malicious one.

Going more precisely into the set of papers that share with
the proposed work the purpose of surveying and/or comparing
ML techniques for intrusion detection, we have gathered the
prominent papers in Table I. The ﬁrst column contains a
pointer to the source; the second column reports the type of
experimental analysis (if any); the third column highlights the
type of datasets utilized (single/multi-class); the last column
provides a brief description of the surveyed material, whereby
the qualiﬁcation “non-homogeneous” refers to a comparison
among techniques belonging to different families, thus, hardly
comparable.

Going beyond the adoption of novel datasets, we want to
highlight the two most signiﬁcant differences arising between
the proposed review and the technical
to
avoid dispersions, we prefer to focus on a speciﬁc fam-
ily of ML techniques, namely the neural networks, so to
guarantee more fair comparisons among outcomes. Such a
focus allows us to better reveal the surprising behavior of
weightless neural networks (traditionally exploited in the ﬁeld
of image classiﬁcation) which exhibits an extraordinary advan-

literature: First,

TABLE I: Prominent Related Work surveying ML techniques applied to Network Intrusion Detection.

Authors

Experiments

Single/Multi Class Description

3

Nguyen et al. [58]

N/A

Boutaba et al. [59]

N/A

Hindy et al. [60]

N/A

Khraisat et al. [61]

N/A

Aldweesh et al. [62]

N/A

Fernandes et al. [63] N/A

Buczak et al. [64]

N/A

Tidjon et al. [65]

N/A

N/A

N/A

N/A

N/A

N/A

N/A

N/A

N/A

Azwar et al. [66]

Performance analysis

Single Class

Moustafa et al. [67]

Performance analysis

Single Class

Meena et al. [68]

Time analysis

Single Class

Rama et al. [69]

Performance
analysis,
Time analysis (partial)

Single Class

Yin et al. [70]

Performance analysis

Single/Multi Class

This work

Performance
Time analysis

analysis,

Single/Multi Class

Classic survey on ML-based techniques with
pointers to other works but with no experi-
ments.

Survey on ML-based techniques applied to var-
ious networking-related problems (from trafﬁc
classiﬁcation to routing or QoS/QoE manage-
ment).

Survey on IDS techniques taking into account
ML algorithms such as ANN, K-means and
SVM.

Survey on Signature and Anomaly-based IDS
techniques applying ML methods on NSL-
KDD dataset.

Survey on Deep Learning techniques for IDSs
with pointers to other works but with no ex-
periments.

Survey on various techniques (ML, Statistical,
Information Theory) for intrusion detection
with pointers to other works but with no ex-
periments.

Survey on Data Mining and ML methods for
intrusion detection with pointers to other works
but with no experiments.

Survey on various techniques (mainly ML-
based) to be applied in intrusion detections
with pointers to other works but with no ex-
periments.

Non-homogeneous comparisons among vari-
ous approaches (trees, NN) by using modern
CIC-IDS17 dataset.

Holistic Survey on ML methods with experi-
ments on feature reduction techniques (ARM,
PCA, ICA).

Non-homogeneous comparisons between J48
and Na¨ıve Bayes techniques on KDD and
NSL-KDD datasets.

Non-homogeneous comparisons among vari-
ous algorithms (e.g. J48, Na¨ıve Bayes, Bag-
ging) on KDD and NSL-KDD datasets.

Non-homogeneous comparisons among vari-
ous and different approaches (e.g. J48, ANN,
SVM) on KDD99 dataset.

Homogeneous comparisons among neural-
(Deep, Weightless NN,
based approaches
LVQ, SOM) performed on modern CIC-IDS-
2017/2018 datasets.

tageous accuracy/time complexity trade-off w.r.t. other NN-
based methods. Then, we carry out an experimental analysis
including performance and time complexity (this latter of-
ten neglected in technical literature) about all the described
NN techniques; this effort overcomes the limit of gathering
ﬁndings from various works (where different authors exploit
different testbeds exhibiting different performance), thus, it
results in a uniform vision of neural methods in the ﬁeld
of intrusion detection. Accordingly, Table I helps pinpointing
such novel aspects of the present paper, as per last row.

III. NEURAL-BASED TECHNIQUES UNDER SCRUTINY

In this section we offer a brief recap of neural-based
techniques that we then employ in Section V to perform our
comparative assessment. We start with Multi-Layer Perceptron
(MLP) which represents the basis for implementing ANNs and
deep neural networks (DNN). Then, we consider WiSARD,
one of the most representative algorithms of weightless neural
networks. These typically provide interesting performance
results, but have traditionally been applied in domains such
as image classiﬁcation rather than intrusion detection. We

4

examine Learning Vector Quantization (LVQ) methods (with
3 variants), where the notion of codebook vector will be
introduced. Finally, we take into account the Self-Organizing
Maps (SOM) technique.

A. Multi-Layer Perceptron

The Multilayer Perceptron is one of the most representative
type of feedforward-based ANNs, whereby there are no cycles
arising in the connections among nodes. MLPs exhibit a fully
connected structure of neurons, where each individual neuron
calculates the weighted sum of n inputs, adds a bias term b,
and then applies an activation function φ(·) to produce the
output s, namely

(0, 1) used to weight the inﬂuence of each iteration. It is
worth noting that, since derivative operations are involved in
the backpropagation algorithm, non-linear activation functions
(e.g. Sigmoid, ReLU) have to be exploited, whose derivative
functions exist and are ﬁnite.

In our MLP-based experiment we use two types of activa-
tion functions: ReLU for all the layers except for the output,
and Softmax for the neurons in the output layer. ReLU has
been proven to be one of the most effective activation functions
when dealing with deep neural networks [73], [74] since it
allows the whole network to converge rapidly. Conversely,
Softmax is particularly suited for handling multiple classes
in the output stage [75].

s = φ

(cid:33)

wi xi + b

.

(cid:32) n
(cid:213)

i=1

(1)

B. Evolved Deep architectures

Figure 1 depicts i) (left panel) the model of a single neuron
(or single-unit perceptron) implementing (1), and ii) (middle
panel) a simpliﬁed structure of a typical MLP model with
5 neurons in the input layer, 3 neurons in the hidden layer,
and 1 neuron in the output layer. In case of multiple hidden
layers, MLP implements a Deep Neural Network (DNN) [71]
as reported in the right panel.

The basic MLP functioning is described next. Input In (see
Fig. 1 - middle panel) activates the hidden layer (or layers)
by following the forward activation direction, which is what
justiﬁes the term feed-forwarding neural network. Similarly,
neurons in the hidden layers feed forward into output neurons,
thus, an output value is obtained. It is useful to recall that
the activation function is aimed at deciding whether or not a
neuron would be activated, introducing some non-linearity into
the neuron output. A variety of activation functions exist [72]
including: step function, linear, sigmoid, hyperbolic tangent,
ReLU (Rectiﬁed Linear Unit), Softmax and many others.

The MLP training stage is achieved through backpropa-
gation, a mechanism exploited to adjust weights of neurons
aimed at progressively minimizing the error through Gradient
Descent (GD), an iterative optimization algorithm useful to
ﬁnd local minima. Precisely, the purpose is to minimize an
error function (e.g. least squares):

E = (cid:213)

p ∈ P

||tp − sp ||2,

(2)

where P is the set of training patterns, tp is the target, and sp
is the output for the example pattern p. The weight-updating
rule, used to progressively compute the new weight wnew, is
derived by evaluating the gradient ∂E/∂w, so that:

wnew = w + ∆w,

∆w = −η

∂E
∂w

+ α∆wprev,

(3)

where: i) η is the learning rate, namely a hyperparameter
lying in the range (0, 1) associated to the step size of the GD
procedure (N.B.: too small η implies difﬁculty of convergence,
whereas too large η could result in indeﬁnite oscillations);
ii) α is deﬁned as the momentum, a term lying in the range

Deep learning approaches allow to face a problem in a
hierarchical way. Lower layers of the model are associated
to a basic representation of the problem, whereas higher
layers encode more complex aspects. Inputs feeding each
layer of a DNN are manipulated through transformations
which are parametrized by a number of weights. Although
deep approaches are very promising, two main issues remain
opened: ﬁrst, training these architectures requires a signiﬁcant
computational power, and, then, the huge number of hyperpa-
rameters makes the tuning process very hard. In the following,
we brieﬂy discuss the most recent architectures relying on a
deep-based approach.

Convolutional Neural Networks (CNNs): Such a tech-
nique [76] takes inspiration from the human visual cortex,
which embodies areas of cells responsive to particular regions
of the visual ﬁeld. This structure makes CNNs exceptionally
suited for applications such as images classiﬁcation or objects
detection. Two main stages characterize the CNN lifecycle:
feature extraction and classiﬁcation. In the ﬁrst stage, the so-
called convolutional ﬁlters extract multiple features from the
input and encode them in feature maps. The “convolution”
is the mathematical operation consisting in an element-wise
product and sum between two matrices, and has the main
drawback of being hugely time consuming. The output of each
convolutional layer feeds the activation function layer (e.g.
ReLU) which produces an activation map by starting from
a feature map. Finally, an optional pooling layer keeps only
signiﬁcant data. On the other hand, the classiﬁcation stage is
composed of a number of fully connected (or dense) layers
followed by a Softmax output layer.

Recurrent Neural Networks (RNNs): It is a class of DNNs
conceived on the basis of a work of Rumelhart [77], explicitly
designed to deal with sequential data. Thus, RNNs are well
suited for modelling language (intended as a sequence of
interconnected words) in the ﬁeld of the so-called natural
language processing (NLP). The key concept
in RNNs is
the presence of cycles, which represent the internal memory
exploited to evaluate current data with respect to the past. Such
a temporal dependency calls for the introduction of time-based
hidden states obeying to:

h(t) = φ(h(t − 1), x(t)),

(4)

5

Fig. 1: Single Neuron model (left panel). MLP model (middle panel). Deep NN model (right panel)
.

with the meaning that an internal state h at time t can be
represented in terms of the input at time t and the previous
hidden state at time t − 1. In this way, an RNN is helpful to
predict the next element of a time series, or the next word in
a sentence based on the number of the previous words. One
of the main drawbacks of RNNs is dealing with long-term
dependencies connected with transferring information from
earlier to later times steps across too long sequences. To tackle
this issue, two more sophisticated variants of RNNs have been
introduced: LSTM and GRU.

Long Short-Term Memory (LSTM): It is a special RNN
architecture [78] conceived to learn long-term dependencies,
namely, to store information for a long period of time. Basi-
cally, an LSTM unit (replacing an ordinary node in the hidden
layer) is represented by a cell state in charge of carrying the
information, and by three different gates aimed at regulating
the information ﬂow: forget, input, and output gates. The forget
gate decides what information keep or discard on the basis of
a forgetting coefﬁcient calculated by input data x(t) and the
previous hidden state h(t − 1); the input gate decides how to
update the cell state; the output gate decides which information
has to be passed to the next unit, on the basis of input data and
the previous hidden state. For the i-th LSTM unit, the hidden
state at time t can be expressed as:

hi(t) = outi(t) · tanh(ci(t)),

(5)

where outi(t) is an output gate which tunes the amount of
memory, and ci(t) represents the cell state of LSTM unit i at
time t.

Gated Recurrent Unit (GRU): It is a lightweight version
of LSTM [79] and has only two gates: update gate and reset
gate. The former plays a similar role of forget and input gates
of LSTM; the latter is exploited to decide how many past
data to forget. In the GRU model, the hidden state hi(t),
corresponding to the i-th GRU unit, can be expressed as a
linear interpolation between the hidden state at time t − 1 and
the candidate activation (or hidden state) (cid:101)hi(t) viz.

hi(t) = (1 − zi(t))hi(t − 1) + zi(t) (cid:101)hi(t),

(6)

where zi(t) is the update gate which decides about the updating
amount of its candidate activation.

Fig. 2: Model of a single class discriminator for the WiSARD
algorithm.

C. WiSARD

WiSARD1 is a supervised method [80], [81] that was origi-
nally conceived for image classiﬁcation, but has recently been
proven to be effective in more general multi-class problems.
WiSARD falls under the class of weightless neural networks
(WNNs) since it exploits lookup tables, instead of weights,
to store the functions evaluated by the individual neurons.
WNNs rely on a mechanism inspired to the random access
memory (RAM) encoding functionalities, since input data are
transformed into binary. This process has a noteworthy beneﬁt
in terms of time complexity due to the use of Boolean logic,
which can be further improved by exploiting pipelining and
parallelism. In short, WiSARD is composed of a set of classi-
ﬁers (or discriminators), each one in charge of learning binary
patterns associated to a particular class. In turn, a discriminator
is composed of a set of neurons, referred to as RAM neurons
as depicted in Fig. 2. Similarly to conventional RAM circuits,
a RAM neuron (a.k.a. n-tuple neuron) can be interpreted as
a RAM having 2n memory locations addressed by n address
lines (inputs) representative of neuron connectivity.

During the training stage, each RAM neuron learns the oc-
currences of n-tuple vectors extracted from a training pattern,
and stores them in a memory cell (equivalent to a RAM writing

1Wilkes, Stonham and Aleksander Recognition Device

x2w2ΣφActivationFunctionsOutputx1w1xnwnWeightsBiasbInput!"#$%&’(&)*+#,+-&%InputlayerHiddenlayer(s)OutputlayerInput1Input2Input3Input4Input5OutputInput LayerHiddenLayerOutput Layer!"#$!%&’(Input LayerHiddenLayer1HiddenLayer2HiddenLayer3Output LayerOutput 1 Output 2 Output 3 Input 1 Input 2 Input 3 !""#$%&"’!"#!"#$%&’!"!#!$!%$&"’!%$&#’!#$!($$%&’()*+(+()*+,-.!"/$%0102&!,-.+//*0/-1020%+(31)")!"#$%#)!"#$%(*+,!"#$%3&4*5364*5314*5operation). Precisely, given µa,i the memory cell with address
a in the i-th RAM (initially empty), the following update rule
holds:

the learning rate. This algorithm admits also an optimized
version (a.k.a. OLVQ1), where an individual learning rate αi is
assigned to mi, thus, basic mv(t +1) equation in (12) becomes:

6

µa,i = θ (cid:169)
(cid:173)
(cid:171)

(cid:213)

p ∈ P

δa,ai (p)(cid:170)
(cid:174)
(cid:172)

,

(7)

where: function θ(z) amounts to z if 0 ≤ z ≤ 1 and to 1 if
z > 1; p is a pattern deﬁned in the training set P; ai(p) is the
address generated starting from pattern p; δ is the Kronecker
delta function, amounting to 1 if a = ai(p) and 0 elsewhere.
The classiﬁcation stage (equivalent to a RAM reading oper-
ation) consists of classifying an unseen pattern s by assigning
s to a class c, provided that the correspondent discriminator
exhibits the highest output, namely

(cid:32) K
(cid:213)

(cid:33)

µai (s),i

,

(8)

arg max
c

i=1
whereas, the response of the c-th class discriminator on pattern
s is:

rc(s) = 1
K

K
(cid:213)

i=1

µai (s),i.

(9)

Accordingly, since WiSARD is made of a set of discriminators,
the overall response of a set of discriminators trained on N
classes produces a response vector r(s) = [rc1(s), . . . , rcN (s)].

D. Learning Vector Quantization

Learning Vector Quantization (LVQ) [82] directly stems
from classical Vector Quantization, a signal-approximation
method aimed at representing the input data vectors x ∈ Rn
through a ﬁnite number of codebook vectors mi ∈ Rn, i =
1, 2, . . . , k. The goal is to ﬁnd the codebook vector mv that
best approximates x, usually in terms of Euclidean distance,
namely:

mv(t + 1) = [1 − c(t)αv(t)] mv(t) + c(t)αv(t)x(t),
where c(t) = +1[−1] if the classiﬁcation is correct [wrong].

(13)

2) LVQ2: Differently from the standard procedure imple-
mented in LVQ1, here two codebook vectors mi and mj
(belonging to the correct and to the wrong class, respectively)
are simultaneously updated. In this case, x must fall within
a “window” deﬁned around the hyperplanes of mi and mj.
The correspondent algorithm is deﬁned by the following set
of equations:

mi(t + 1) = mi(t) − α(t) [x(t) − mi(t)] ,
mj(t + 1) = mj(t) − α(t) (cid:2)x(t) − mj(t)(cid:3) ,

(14)

(15)

where (14) holds when x and mi belong to the same class,
(15) holds when x and mi belong to different classes, and
with mi and mj being the two closest codebook vectors to x.
Moreover, x has to fall within a window of relative width w
if

min

(cid:19)

(cid:18) ei
ej

,

ej
ei

> k,

(16)

where ei and ej represent, respectively, the Euclidean distances
of x from mi and mj, and k = 1−w
1+w .

3) LVQ3: This variant of LVQ2 admits the same set of
equations (14), (15), with the difference that the learning rate
is weighted with a parameter (cid:15), whose best values are found
empirically to lie in the [0.1-0.5] interval of values:

mh(t + 1) = mh(t) + (cid:15)α(t) [x(t) − mh(t)] ,

(17)

v = arg min

||x − mi ||.

(10)

for k ∈ i, j if x, mi, and mj belong to the same class.

i

it

The main purpose of LVQ is to deﬁne class regions (over
the input data space), each one containing a subset of a
similarly labeled codebook. Accordingly,
is possible to
pinpoint hyperplanes between neighboring codebook vectors
deﬁning the so-called quantization regions. By assuming that
all samples of x derive from a ﬁnite set of classes Sk, the idea
is to i) assign a subset of codebook vectors to each class Sk,
and ii) search for mv having the smallest Euclidean distance
from x. Different versions of LVQs have been introduced
in the literature with slight differences, as introduced in the
following.

1) LVQ1: Assume that x(t) is an input sample and mi(t)
contains sequential values of mi (t = 0, 1, 2, . . . ). The LVQ1
algorithm allows to ﬁnd values of mi in (10) that asymptoti-
cally minimize errors, and is deﬁned by the following set of
equations:

mv(t + 1) = mv(t) + α(t) [x(t) − mv(t)] ,
mi(t + 1) = mi(t),

(11)

(12)

where (11) refers both for cases that x and mv belong to the
same or different classes, (12) holds for i (cid:44) v, and α(t) is

E. Self-Organizing Maps

SOM takes inspiration from a particular adaptive character-
istic that allows the human brain to empower the experience.
Speciﬁcally, given a physical stimulus (namely, the input)
which activates multiple neurons of a certain brain area in
parallel, those neurons that are more sensitive to the input
stimulus will go about inﬂuencing all other neighboring neu-
rons.

This biological mechanism has led to designing SOM as
input data onto
a nonlinear mapping of high-dimensional
lattice) [83],
elements of a low-dimensional array (a.k.a.
according to a principle known as competitive learning. This is
different from the classic ANN-based approach, where weights
are updated to iteratively minimize errors. In competitive
learning, several neurons are fed with the same input (in
parallel) and compete to become the possible “winner” in
relation to that particular input.

According to this strategy, and assuming that the weight
vector of neurons has the same dimensionality as the input,
the output neuron activation increases with larger similarity
between the weight vector of the neuron and the input [84].

Precisely, by considering a network composed of k neurons
(with k << n being n the data set size), an input vector
x = [x1, x2, . . . , xn]T ∈ Rn and a reference (or weight) vector
mi = [mi1, mi2, . . . , min]T ∈ Rn associated with neuron i, the
competitive approach can be summarized according to the
following steps:

i) Compute the smallest Euclidean distance d = arg mini
|| ∀i ∈ (1, . . . , m) having the meaning of the
|| x − mi
activation value for the i-th neuron. The neuron having d
is declared as winner.
ii) The i-th neuron is updated according to the following
rule: mi(t + 1) = mi(t)h(t) [x(t) − mi(t)] where t =
(0, 1, . . . ) is an integer discrete time reference, whereas
h(t) is the neighborhood function deﬁned over the lattice
points that is typically implemented through a Gaussian
kernel (the same as then one exploited for the present
experimental analysis):

h(t) = α(t) · exp

(cid:18)

−

||(cid:96)c − (cid:96)i ||2
2σ2(t)

(cid:19)

,

(18)

where: α(t) is the learning rate factor, (cid:96)c ∈ R2 and (cid:96)i ∈
R2 are, respectively, the location vectors of neurons c
and i mapped on the lattice structure (supposed to be
bi-dimensional), and σ(t) represents the kernel width.
Although SOM may be considered as the unsupervised coun-
terpart version of LVQ, a common way to exploit SOM for
classiﬁcation purposes is to consider a supervised version
(sometimes dubbed as LVQ-SOM [83] and implemented in
our analysis) relying on the following consideration: once
we know that each training sample x(t) and mi(t) have been
assigned to speciﬁc classes, h(t) has to be set to positive if
x(t) and mi(t) belong to the same class, and negative if they
belong to different classes, by taking into account that such
a rule is applied for each mi(t) in the neighborhood of the
winner.

IV. THE EXPERIMENTAL DATASETS

In this section we present further details about datasets
employed in our experimental analysis. As already remarked
in Section II, the datasets must convey the most recent infor-
mation about a variety of cyber attacks across data networks.
We adopted datasets released from CIC [52], and precisely: the
DDoS dataset, containing trafﬁc relating to distributed denial
of service attacks designed to saturate network resources; the
Portscan dataset, including attempts of Portscan, a technique
used to discover open ports on network devices; the WebAttack
dataset which encompasses various malicious trafﬁc ranging
from Cross-Site Scripting to Sql Injection; the TOR dataset,
a collection of network trafﬁc traversing the anonymous TOR
circuit often conveying malicious information; and the Android
dataset, embedding a number of mobile (Android-based) ad-
wares.

These datasets have been used to perform two kinds of
neural-based analyses: a single-class analysis, aimed at clas-
sifying the network trafﬁc as benign or malign (binary infor-
mation); and a multi-class analysis, aimed at distinguishing
more classes of attacks. Each dataset has been cleaned and

7

TABLE II: Synthetic description of adopted features

Family

List of features

Coarse-Grained

1. Source IP Address
2. Destination IP Address
3. Source Port
4. Destination Port
5. Transport Protocol Type

6. Flow duration
7. Average inter-arrival times (IAT) between two ﬂows
8. IAT standard deviation (std) between two ﬂows
9. IAT max between two ﬂows
10. IAT min between two ﬂows
11. IAT tot between two pkts sent in fwd direction
12. IAT avg between two pkts sent in fwd direction
13. IAT std between two pkts sent in fwd direction
14. IAT max between two pkts sent in fwd direction
15. IAT min between two pkts sent in fwd direction
16. IAT tot between two pkts sent in bwd direction
17. IAT avg between two pkts sent in bwd direction
18. IAT std between two pkts sent in bwd direction
19. IAT max between two pkts sent in bwd direction
20. IAT min between two pkts sent in bwd direction
21. Avg time a ﬂow was active before becoming idle
22. Std time a ﬂow was active before becoming idle
23. Min time a ﬂow was active before becoming idle
24. Max time a ﬂow was active before becoming idle
25. Avg time a ﬂow was idle before becoming active
26. Std time a ﬂow was idle before becoming active
27. Min time a ﬂow was idle before becoming active
28. Max time a ﬂow was idle before becoming active

29. Flow byte rate
30. Flow pkt rate
31. Avg no. of pkts in a sub-ﬂow in fwd direction
32. Avg no. of pkts in a sub-ﬂow in bwd direction
33. Avg no. of bytes in a sub-ﬂow in fwd direction
34. Avg no. of bytes in a sub-ﬂow in bwd direction

35. Tot pkts in the fwd direction
36. Tot length of pkts in the fwd direction
37. Avg length of pkts
38. Std length of pkts
39. Variance length of pkts
40. Avg length of pkts in the fwd direction
41. Std length of pkts in the fwd direction
42. Max length of pkts in the fwd direction
43. Min length of pkts in the fwd direction
44. Tot pkts in the bwd direction
45. Tot length of pkts in the bwd direction
46. Avg length of pkts in the bwd direction
47. Std length of pkts in the bwd direction
48. Max length of pkts in the bwd direction
49. Min length of pkts in the bwd direction
50. Avg no. of pkt bulk rate in fwd direction
51. Avg no. of pkt bulk rate in bwd direction
52. Fwd pkt rate
53. Bwd pkt rate
54. Min segment size in fwd direction

55. Avg no. of byte rate in fwd direction
56. Avg no. of byte rate in bwd direction
57. No. of bytes sent in init win in fwd direction
58. No. of bytes sent in init win in bwd direction
59. Tot bytes used for headers in fwd direction
60. Tot bytes used for headers in bwd direction

61. No. of times URG ﬂag set in fwd direction
62. No. of times PSH ﬂag set in fwd direction
63. No. of times FIN ﬂag set in fwd direction
64. No. of times SYN ﬂag set in fwd direction
65. No. of times RST ﬂag set in fwd direction
66. No. of times ACK ﬂag set in fwd direction
67. No. of times URG ﬂag set in bwd direction
68. No. of times PSH ﬂag set in bwd direction
69. No. of times FIN ﬂag set in bwd direction
70. No. of times SYN ﬂag set in bwd direction
71. No. of times RST ﬂag set in bwd direction
72. No. of times ACK ﬂag set in bwd direction
73. PSH ﬂag count
74. FIN ﬂag count
75. SYN ﬂag count
76. RST ﬂag count
77. ACK ﬂag count
78. ECE ﬂag count

Time-Based

Flow-Based

Packet-Based

Byte-Based

Flag-Based

8

TABLE III: Optimized hyperparameters for the exploited algorithms.

Algorithm

MLP-1, Deep-2,
Deep-3

Convolutional

Recurrent-type

WiSARD

LVQ(1,2,3)

SOM

Optimized hyperparameters and models info
· Stochastic Gradient Descent with adaptive hyperparams.
(Adam version - [85])
· LR (learn. rate)=0.001
· Number of weights=2000
· Exp. Decay (ﬁrst moment estimate)=0.9
· ReLU activation function
· Neurons per hidden layer: MLP-1(26); Deep-2(23,10); Deep-
3(20,16,11)
· 7 ﬁlters (4x1), 8 neurons fully connected
· 1 Pooling layer with Pooling size = 2
· 1 Dropout layer with Dropout rate = 0.3
· ReLU activation function
· 18 Recurrent units (RNN), 10 neurons fully connected
· 6 LSTM units, 8 neurons fully connected
· 8 GRU units, 10 neurons fully connected
· Batch Size=100
· Resolution (in bit) per neuron: 8
· Batch Size=100
· LR=0.3
· Codebook Vectors=20
· Window Size (for LVQ2 and LVQ3)=0.3
· (cid:15) (for LVQ3)=0.1
· Batch Size=100
· LR=0.3
· Hexagonal Topology with Neighborhood Size = 8
· Neighborhood Function: Gaussian

re-balanced through a Python routine designed from scratch,
and contains 2 · 104 instances and 78 features, which are then
grouped in 6 macro-classes, as indicated in the following (refer
to the Table II for an exhaustive list of features):

• Coarse-grained features: Source and Destination Port,

Protocol Type, Source and Destination IP Address;

• Time-based features: Backward/Forward inter-arrival
times between two ﬂows, duration of active ﬂow (mean,
std, min, max), duration of an idle ﬂow (mean, std, min,
max), etc.;

• Flow-based features: Length of a ﬂow (mean, min, max,

etc.);

• Packet-based features: Backward/Forward number of
packets in a ﬂow, Backward/Forward length of packets
in a ﬂow (mean, std, min, max, etc.);

• Byte-based features: Backward/Forward number of
bytes in a ﬂow, Backward/Forward number of bytes used
for headers, etc.;

• Flag-based features: Number of packets with active
TCP/IP ﬂags (SYN, FIN, PUSH, RST, URG, etc.). Please
note that, for example, feature 62 (68) indicates the no.
of times the PSH ﬂag is set in the forward (backward)
direction, whereas feature 73 indicates the overall number
of packets containing such a ﬂag.

These features allow to derive statistical
information that
cannot be hidden in a possible malicious ﬂow. Let us consider,
for instance, a DDoS attack. This is typically designed to
overwhelm the resources of a target network [86], [87] by
conveying legitimate information (e.g. trivial HTTP requests
in case of an application-layer DDoS attack) which would
pass unnoticed to a classic signature-based detection systems.
However, DDoS attacks are designed to be a coordinated
effort where multiple, malicious entities (a.k.a. bots) send
few, tiny packets to the target. Similarly, the structure of a
Portscan attack, characterized by a very quick scan of the
victim’s destination port by the network attacker, can be
learned by crossing information of destination port and time-
based information.

V. EXPERIMENTAL-BASED ASSESSMENT

The main purpose of our experimental analysis is to com-
pare the neural techniques introduced in Sect. III across the
datasets described in Section IV. Aimed at a fair comparison,
we adopt a 10-fold cross validation for each experiment.
The model structure for each algorithm and the pertinent
hyperparameters are summarized in Table III.
The whole assessment comprises:

9

(a)

(c)

(b)

(d)

Fig. 3: Performance in terms of Accuracy/F-Measure for different single-class datasets: (a) DDoS; (b) Portscan, (c) WebAttack,
(d) TOR.

• Performance analysis: obtained by evaluating two met-
rics typically used in the ﬁeld of trafﬁc classiﬁcation [88],
[89], viz.

- Accuracy : ratio of correctly predicted observations to

the total, calculated by

T P + T N
T P + T N + FP + F N

;

(19)

• Time complexity analysis: derived by measuring the
whole classiﬁcation process (including training time) as
the number of instances grows from 103 to 2 · 104.

We perform the overall analysis on a PC equipped with
Intel CoreTM i5-7200U CPU@ 2.50GHz CPU and 16 GB of
RAM. For the sake of convenience, we split our analysis in
two: the single-class and the multi-class cases.

- F-Measure : an indicator of a per-class performance,

A. Single-Class Analysis

calculated by

2 ·

Precision · Recall
Precision + Recall

,

(20)

where Precision is the ratio of correctly classiﬁed trafﬁc
over the total predicted trafﬁc in a class, and Recall is the
ratio of correctly classiﬁed trafﬁc over all ground truth
trafﬁc in a class.

We start by evaluating the performance of the differ-
ent neural-based techniques by considering four single-class
datasets (DDoS, Portscan, WebAttack, and TOR), reporting
accuracy and F-measure in Figures 3(a), 3(b), 3(c), and 3(d),
respectively. The choice of four completely different datasets
(representative of four substantially different network attacks)
is useful to verify the effectiveness of the tested algorithms
and their relationships with the data.

MLP-1DP-2 DP-3 CNN  RNN  LSTM GRU  WIS. LVQ1 LVQ2 LVQ3 SOM  0.20.30.40.50.60.70.80.911.1Single-Class (DDoS Dataset)Accuracy (DDoS)Accuracy (Benign)F-Measure (DDoS)F-Measure (Benign)MLP-1DP-2 DP-3 CNN  RNN  LSTM GRU  WIS. LVQ1 LVQ2 LVQ3 SOM  0.20.30.40.50.60.70.80.911.1Single-Class (Portscan Dataset)Accuracy (Portscan)Accuracy (Benign)F-Measure (Portscan)F-Measure (Benign)MLP-1DP-2 DP-3 CNN  RNN  LSTM GRU  WIS. LVQ1 LVQ2 LVQ3 SOM  0.20.30.40.50.60.70.80.911.1Single-Class (WebAttack Dataset)Accuracy (WebAttack)Accuracy (Benign)F-Measure (WebAttack)F-Measure (Benign)MLP-1DP-2 DP-3 CNN  RNN  LSTM GRU  WIS. LVQ1 LVQ2 LVQ3 SOM  0.20.30.40.50.60.70.80.911.1Single-Class (TOR Dataset)Accuracy (TOR)Accuracy (Non-TOR)F-Measure (TOR)F-Measure (Non-TOR)10

(a)

(c)

(b)

(d)

Fig. 4: Single-class (DDoS): (a) Average Accuracy vs. dataset size; (b) Classiﬁcation Time vs. dataset size; Single-class
(Portscan): (c) Average Accuracy vs. dataset size; (d) Classiﬁcation Time vs. dataset size.

Among classic ANN-based algorithms we distinguish be-
tween deep versions (Deep-2, Deep-3) and non-deep ones
(MLP-1) whose detailed structure is reported in Table III.
MLP-1 refers to a standard MLP with 3 layers: 1 input layer,
1 hidden layer, and 1 output layer. On the other hand, deep
versions are indicated by Deep-2 (1 input layer, 2 hidden
layer, 1 output layer) and Deep-3 (1 input layer, 3 hidden
layer, 1 output layer). In order to compare algorithms with
similar performances, MLP-1, Deep-2 and Deep-3 have been
set with the same number of weights (2k). This is about one
order of magnitude smaller than the dataset size, according
to what is recommended in the literature [90], [91]. We also
note that the number of weights for MLP-1, Deep-2 and Deep-
3 directly results from the different number of neurons chosen
per each hidden layer, namely: 26 neurons for MLP-1, 23 and
10 neurons for the two hidden layers of Deep-2, and 20, 16,
and 11 neurons for the 3 hidden layers of Deep-3 (see also
Table III). As concerns the evolved deep models (CNN, RNN,

LSTM, GRU), details about their structures are available in
Table III. Also for these approaches, the choice of a particular
structure (e.g. the number of ﬁlters in CNN, the number of
recurrent units in RNN, and so forth), is aimed at obtaining
a number of weights comparable with MLP-1, Deep-2, and
Deep-3 so to have a fair comparison.

In our analysis, the MLP-based versions (MLP-1, Deep-2
and Deep-3) and the evolved deep techniques (CNN, RNN,
LSTM, GRU) exhibit good values of average accuracy (all
around 0.99) for all the four examined datasets (panels of Fig.
3). Similarly, for all the aforementioned algorithms and for
each dataset, F-measure exhibits high values, indicating a very
negligible fraction of false positives and false negatives. Simi-
lar high performance is exhibited by Wisard for all the datasets
with a slight exception of Portscan Dataset. By contrast, LVQs
and SOM methodologies have lower performance and seem
to suffer from the presence of more false positives and false
negatives. This is visible for the Portscan dataset (Fig. 3(b))

00.20.40.60.811.21.41.61.82DatasetSize×1040.80.850.90.951AverageAccuracyDDoS DatasetMLP-1Deep-2Deep-3CNNRNNLSTMGRUWisardLVQ1LVQ2LVQ3SOM00.20.40.60.811.21.41.61.82DatasetSize×104100101102103104ClassiﬁcationTime(sec)DDoS DatasetMLP-1Deep-2Deep-3CNNRNNLSTMGRUWisardLVQ1LVQ2LVQ3SOM00.20.40.60.811.21.41.61.82DatasetSize×1040.60.650.70.750.80.850.90.951AverageAccuracyPortscan DatasetMLP-1Deep-2Deep-3CNNRNNLSTMGRUWisardLVQ1LVQ2LVQ3SOM00.20.40.60.811.21.41.61.82DatasetSize×104100101102103104ClassiﬁcationTime(sec)PortScan DatasetMLP-1Deep-2Deep-3CNNRNNLSTMGRUWisardLVQ1LVQ2LVQ3SOMthat exhibits an oscillating F-measure, which can be ascribed
to the different codebook vectors obtained when considering
input datasets. In particular, competitive learning
different
methods seem suffer from the particular type of attack dataset.
In fact, the Euclidean distance (which is used as the main
metric within the discussed competitive learning approaches)
may not perfectly capture the properties of various datasets,
being they structurally different. This is due to the fact that
Euclidean distance is a not scale invariant measure, thus, it
has difﬁculty to deal with vector components having different
dynamic range. This is also the reason why the 3 variants of
LVQ can behave slightly differently when considering diverse
datasets.

Another useful analysis is aimed at evaluating the impact
of dataset size on performance. For the sake of compactness,
we choose DDoS and Portscan as benchmark datasets, being
DDoS and Portscan representative of two completely different
and well structured network attacks. Precisely, we evaluate the
average accuracy (between DDoS/Portscan and benign classes)
against an interval of dataset size varying between 103 and
2 · 104 instances. The results shown in Figures 4(a) and 4(c)
provide a clear indication that: i) both ANNs and WiSARD
exhibit very stable performance as dataset size varies; ii) LVQ
shows some minor ﬂuctuations, with an average accuracy that
is just slightly under 0.9 in few cases. In this case, ﬂuctuations
can be ascribed to the codebook size that would require
heuristical adjustments as the dataset size varies.

For the sake of fairness, the performance comparison must
be complemented by a time-complexity analysis, as shown in
Figs. 4(b-d). Therein, classiﬁcation time (in seconds) is plotted
against the number of instances (from 103 to 2 · 104). For both
experiments (DDoS dataset in 4(b) and Portscan dataset in 4
(d)) we can reasonably recognize three slots in the Y axis: the
ﬁrst one, ranging from 103 to 15 · 104 seconds, where MLP-1,
Deep-2, 3 and evolved deep architectures (CNN, RNN, LSTM,
GRU) operate (slowest algorithms); the second one, ranging
from about 10 to 102 seconds which includes WiSARD
(medium-fast algorithm); the third one, ranging from about 1
to 5 seconds, including LVQ1, LVQ2, LVQ3, and SOM (faster
algorithms).

We are not surprised that deep networks are up to 2 orders
of magnitude slower w.r.t. other techniques, due to the fully
connected neurons between each layer. As regards the evolved
deep architectures, time complexity is typically associated to
the adoption of more sophisticated structures such as the
convolutional
layers (CNNs), or mechanisms to retain the
internal memory states (RNN, LSTM, GRU).

On the other hand, approaches based on competitive learn-
ing (LVQs, SOM) are faster since only the winner neurons
are enabled to update their weights, although this comes at
the cost of a lower accuracy. Surprisingly, the best trade-off
between accuracy and time complexity is offered by WiSARD.
Its RAM-based structure, in fact, allows a fast learning stage
since it deals with binary information regardless on data
dimension. In terms of time complexity,
the feed-forward
incremental learning scheme implemented in WiSARD is more
advantageous than classic backpropagation, requiring many
iterations to converge.

11

B. Multi-Class Analysis

Multi-class analysis is useful to analyze how the various
algorithms react when dealing with different classes of trafﬁc.
With this aim, we built a 4-class dataset by mixing (in
a balanced way) three malicious classes (DDoS, Portscan,
and Adware) with a Benign class. The rationale behind this
choice is to take into account a mix of peculiar threats. As
regards the performance analysis, for the sake of readiness,
we show multi-class accuracy and F-measure separately in
trend, we
Figs. 5(a) and 5(b), respectively. As a general
observe a satisfactory classiﬁcation performance by MLP
and Deep algorithms. WiSARD exhibits good performance in
classifying DDoS and Portscan (0.9957 and 0.9952 accuracy,
respectively), but is poor in classifying Adware and Benign
classes (0.784 and 0.782 accuracy, respectively). The reason
is to be found behind the structural difference between those
different types of attacks. DDoS and Portscan are both highly
“structured” attacks. The former can be characterized in terms
of high rate of messages that a bot sends to a victim; Portscan
hides continuous ping-based requests towards a target in order
to unveil possible open ports. By contrast, Adwares can be
easily confused within a benign ﬂow, since they just convey
annoying banners, as often occurs also within legitimate web
portals. The situation changes drastically when we look at the
remaining algorithms (LVQs and SOM), where false positives
have high weight especially for Portscan, Adware, and Benign
classes, as shown in Fig. 5(b). Also, the F-measure is often
below 0.4 in case of Adware and Benign classes. With
respect to the single-class case, here, the effects produced by
the codebook class assignment and peculiarity of Euclidean
measure are ampliﬁed.

Finally, among competitive-based approaches, LVQ-3 ex-
hibits the best performance, due to the introduction of the
empirical parameter (cid:15) (see Sect. III-D3), which helps to better
regulating the distance between the data and the pertinent
codebook vectors. This notwithstanding, all the considered
techniques exhibit fairly stable accuracy averages, across the
whole range of dataset sizes (from 103 to 2 · 104 instances),
as revealed by Fig. 6(a). As expected, the average accuracy
in all cases pertaining the multi-class experiment is slightly
lower than their single-class counterpart, due to the fact that
classifying more than two classes is a more challenging task.
Let us now discover if the multi-class analysis has an
impact on the time complexity of
the considered algo-
rithms. Figure 6(b) shows how the order of magnitude in
classiﬁcation times per algorithm is similar w.r.t. the case
of single-class analysis. As to be expected,
in-
crease in classiﬁcation time going from single to multi-class
cases can be ascribed to the higher number of different
trafﬁc ﬂows to be classiﬁed. For example, along the vary-
ing dataset size (cid:2)103, 2 · 103, 5 · 103, 104, 2 · 104(cid:3), WiSARD
exhibits the following (approximated) classiﬁcation times:
[8.047, 12.24, 30.731, 53.474, 104.783] seconds in the single
class case, and [8.389, 15.058, 31.831, 61.958, 119.848] sec-
onds in the multi-class case. Once again, WiSARD appears
to provide the optimal trade-off between performance needs
and time complexity issues.

the slight

12

(a)

(b)

Fig. 5: Performance analysis for a 4-classes dataset: (a) Accuracy, (b) F-Measure.

(a)

(b)

Fig. 6: Multi-class dataset: (a) Average Accuracy vs. dataset size;

(b) Classiﬁcation Time vs. dataset size.

C. General Considerations

A number of interesting considerations may be derived from
our comparative analysis. First, not all neural-based techniques
are equally applicable to network intrusion detection, particu-
larly when performance is the key issue.

ANN approaches (including modern deep-based methods)
tend to offer noteworthy accuracy, both in single-class and
multi-class datasets. Unfortunately, though, accuracy comes at
the expenses of time complexity, which will demand for deep-
based techniques to rely on specialized GPU-based hardware.
Moreover, as an auxiliary investigation pertaining the deep
approach, we evaluate the impact of the updating weight
mechanism on the overall performance, expressed through
the Mean Square Error (MSE). The behavior is shown in

Figs. 7(a) and 7(b) for the single and multi-class datasets,
respectively, evaluated over 100 epochs. Such analysis reveals
that most techniques exhibit limited ﬂuctuations around the
median value of MSE and a quite low MSE value. The
only exception is given by CNN where the higher MSE is
reasonably due to the complexity of the convolution operation.
Similar considerations raised in a bio-informatic study [92]
where only MLP and CNN techniques have been compared.
Detailed values are reported in Table IV, in terms of median
and inter-quartile range (difference between third and ﬁrst
quartile) values. On average, the most “stable” techniques are
the classic Deep-2 and Deep-3 architectures. The addition of
a bit more sophisticated structure (e.g. convolutional layer for
CNN, LSTM/GRU units, and so forth) can translate into MSE

MLP-1DP-2 DP-3 CNN  RNN  LSTM GRU  WIS. LVQ1 LVQ2 LVQ3 SOM  0.10.20.30.40.50.60.70.80.911.1Multi-Class Dataset - AccuracyDDoSPortscanAdwareBenignMLP-1DP-2 DP-3 CNN  RNN  LSTM GRU  WIS. LVQ1 LVQ2 LVQ3 SOM  0.10.20.30.40.50.60.70.80.911.1Multi-Class Dataset - F-MeasureDDoSPortscanAdwareBenign00.20.40.60.811.21.41.61.82DatasetSize×1040.40.50.60.70.80.91AverageAccuracyMLP-1Deep-2Deep-3CNNRNNLSTMGRUWisardLVQ1LVQ2LVQ3SOM00.20.40.60.811.21.41.61.82DatasetSize×104100101102103104ClassiﬁcationTime(sec)MLP-1Deep-2Deep-3CNNRNNLSTMGRUWisardLVQ1LVQ2LVQ3SOM13

(a)

(b)

Fig. 7: MSE analysis when introducing more sophisticated deep models (CNN, RNN, LSTM, GRU). Single-class (DDoS
benchmark dataset) (a), Multi-class (DDoS-Portscan-Adware-Benign dataset) (b).

ﬂuctuations due to the presence of additional hyperparameters
to tune. Obviously, such ﬂuctuations directly reﬂect the inter-
nal structure of each deep technique and can be more (e.g.
CNN) or less (e.g. RNN) pronounced.

TABLE IV: Median and IQR values (MSE analysis) for deep-
based techniques

Median

IQR

Technique

Single-Class Multi-Class

Single-Class Multi-Class

Deep-2
Deep-3
CNN
RNN
LSTM
GRU

1.5· 10−3
7.4· 10−4
1.74 · 10−2
1.4 · 10−3
1.8 · 10−3
2.4 · 10−3

2.02 · 10−2
1.45 · 10−2
6.2 · 10−2
2.06 · 10−2
3.02 · 10−2
2.45 · 10−2

1.8· 10−3
1.6· 10−3
4.1· 10−3
2.1· 10−3
2.9· 10−3
2· 10−3

7 · 10−3
6.1· 10−3
1.19· 10−2
6.6· 10−3
6.7 · 10−3
8.1 · 10−3

Remarkably, deep-learning techniques could ﬁnd interesting
application in the network intrusion management ﬁeld when
the training set exhibits slow time dynamics. In this case, the
training operation (being time/resource consuming) could be
performed only once (or performed rarely across the time).

As regards competitive learning techniques (LVQ in the 3
variants and SOM), pros and cons are (almost) reversed w.r.t.
ANN algorithms. In the case of single-class analysis, a depen-
dency on the type of dataset is highlighted (better performance
in DDoS dataset than in Portscan). This is reasonably due to
the fact that different inputs produce different mappings with
codebook vectors. As to be expected, this effect is further
ampliﬁed in multi-class datasets, where false positives and
false negatives lead to unstable f-measure ﬁgures (Fig. 5 (b)).
However, the competitive learning algorithms exhibit very
appealing time complexity ﬁgures (up to 3 orders of magnitude
lower than ANNs), thanks to their approach to taking into
account only the “winner” neurons during the whole classiﬁ-
cation process. Accordingly, cooperative techniques could ﬁnd
useful application in highly time-variant intrusion detection

settings, where it is crucial to quickly adapt to the dataset
variations. Possibly, they can operate an early (even rough)
detection to be reﬁned later by means of other algorithms.

Finally, an unexpected ﬁnding is offered by WiSARD that,
through its weightless mechanism, provides the best trade-
off between performance (accuracy/F-measure) and time com-
plexity, in both single and multi-class cases. This outstanding
behavior is mainly due to two aspects: ﬁrst, the binariza-
tion scheme (jointly with the RAM-like neurons structure)
adopted by WiSARD allows to handle multivariable data in
a fast way. Then, the training stage follows an incremental
approach since each sample reinforces the past knowledge in
updating the network state; this implies a fast convergence
and makes WiSARD particularly suitable in domains where
online learning is crucial. What is even more interesting is
that WiSARD has hardly ever been considered in the ﬁeld
of trafﬁc ﬂow classiﬁcation, while it appears to be a very
interesting candidate to be exploited in intrusion detection.
This WNN-based approach should certainly be considered as
a promising alternative to existing methods, particularly for
its potential to meet the near-real-time constraints involved in
NIDS classiﬁcation problems.

VI. CONCLUSION

This work explores the applicability of prominent neural-
based techniques in network intrusion detection. We carry out
an experiment-based comparison to quantify performance and
trade-off achievable with each solution. Our aim to perform
a fair comparison has directed our investigation to focus
on artiﬁcial neural networks (ANN). This was to avoid the
typical issues arising when comparing ML methods relying on
different rationale (e.g. ANN vs. SVM vs. Decision Trees).

In the related work section, we have provided pointers to
numerous other surveys, illustrating similarities (in aims) and

Deep-2Deep-3  CNN    RNN   LSTM    GRU  00.0050.010.0150.020.0250.03MSESingle-Class Dataset!"#$%&’"()*+,+#)’-./($%&’"()*+0)-1’*&+0’2$1’*&+345Deep-2Deep-3  CNN    RNN   LSTM    GRU  00.010.020.030.040.050.060.070.080.090.1MSEMulti-Class Datasetdifferences (in methodologies). The key peculiarity of our pa-
per is its experimental-based approach to reviewing alternative
ANN options. We based our evaluation on modern datasets
(CIC-IDS-2017/2018), while most of the earlier experimental
results are based on the outdated KDD99 dataset (reﬂecting
network attack issues that have largely been solved). Our
review provides useful performance (in terms of accuracy
and F-measure) and time complexity data, providing the basis
for a trade-off analysis across different ANNs such as deep
networks or competitive learning-based networks. To add value
to our study, we wanted to consider also methods that have
not typically been employed in intrusion detection, particularly
the weightless neural networks (WNNs).

The outcomes reveal a number of interesting ﬁndings. i)
ANN-based approaches (including deep networks) are charac-
terized by outstanding performance in almost all cases (as to be
expected). Yet, they suffer the drawback of being slow due to
the underlying backpropagation algorithm, which is typically
slow to converge. ii) Neural-based techniques relying on a
competitive learning approach (LVQ1, LVQ2, LVQ3, SOM)
overturn this perspective, thanks to a much reduced time com-
plexity (due to the winner-neuron mechanism). However, this
comes with a lower performance when different datasets are
considered (due to the different mapping mechanism between
iii) The WiSARD algorithm
input and codebook vectors).
(representative of WNNs) exhibits a surprisingly best trade-
off in terms of performance and time complexity, making it
an appealing candidate to operate in conjunction with intrusion
detection systems.

The proposed analysis could be extended in several ways.
The ﬁrst (and perhaps natural) direction is to better investigate
the potential of weightless neural networks in the context of
network intrusion detection. Beyond WiSARD, in fact, other
WNN algorithms such as Probabilistic Logic Node (PLN),
Goal Seeking Neuron (GSN), or General Neural Unit (GNU)
could reveal noteworthy properties when applied in this ﬁeld.
Then, we would suggest to explore how the addition of a
feature selection (FS) pre-processing stage would reduce time
complexity. This could be particularly advantageous for deep
techniques (the most critical in terms of time constraints),
even if the adoption of a non well designed FS strategy
could result
in a further computational overhead. Finally,
having identiﬁed pros and cons of neural-based techniques
in the ﬁeld of intrusion detection, an engine which allows
to automatically select (or combine) the NN-based strategies
best ﬁtting the underlying network environment (e.g. hugely
vs. scarcely time-variant trafﬁc proﬁles) can be designed. This
latter point could have intriguing implications onto prospective
6G scenarios which, according to the network experts, will
be characterized by automatic service provisioning, intelligent
resource management, and smart network adjustments.

REFERENCES

[1] I. Possebon, A. Santos da Silva, L. Zambenedetti Granville, A Schaeffer-
Filho, and A.K. Marnerides.
Improved network trafﬁc classiﬁcation
using ensemble learning. In 2019 IEEE Symposium on Computers and
Communications, pages 1–6, 2019.

14

[2] F. Grando, L. Zambenedetti Granville, and L.C. Lamb. Machine learning
in network centrality measures: Tutorial and outlook. ACM Comput.
Surv., 51(5):102:1–102:32, 2018.
[3] Cisco Encrypted Trafﬁc Analysis.

https://www.cisco.com/c/dam/en/
us/solutions/collateral/enterprise-networks/enterprise-network-security/
nb-09-encrytd-traf-anlytcs-wp-cte-en.pdf. Accessed: 2020-02-25.
[4] L. P. Gaspary, E. Meneghetti, and L. R. Tarouco. An SNMP agent
In IFIP/IEEE Eighth International
for stateful intrusion inspection.
Symposium on Integrated Network Management, 2003., pages 3–16,
2003.

[5] L. P. Gaspary, R. N. Sanchez, D. W. Antunes, and E. Meneghetti. A
SNMP -based platform for distributed stateful intrusion detection in en-
terprise networks. IEEE Journal on Selected Areas in Communications,
23(10):1973–1982, 2005.

[6] W. Cerroni, G. Moro, R. Pasolini, and M. Ramilli. Decentralized
detection of network attacks through p2p data clustering of SNMP data.
Computers & Security, 52:1 – 16, 2015.

[7] W. Cerroni, G. Moro, R. Pasolini, and M. Ramilli. Network attack
In Lecture

detection based on peer-to-peer clustering of SNMP data.
Notes of the Institute for Computer Sciences, volume 22, 2009.

[8] W. Cerroni, G. Moro, T. Pirini, and M. Ramilli. Peer-to-peer data mining
classiﬁers for decentralized detection of network attacks. In Proceedings
of the Twenty-Fourth Australasian Database Conference - Volume 137,
pages 101–107, 2013.
[9] Kdd cup 1999 data.

http://kdd.ics.uci.edu/databases/kddcup99/

kddcup99.html. Accessed: 2020-02-25.

[10] M. Tavallaee, E. Bagheri, W. Lu, and A. A. Ghorbani. A detailed
In 2009 IEEE Symposium on
analysis of the KDD CUP 99 data set.
Computational Intelligence for Security and Defense Applications, pages
1–6, 2009.

[11] Sharafaldin I., Habibi Lashkari A., and Ghorbani A.A. Toward generat-
ing a new intrusion detection dataset and intrusion trafﬁc characteriza-
tion. In 4th International Conference on Information Systems Security
and Privacy, 2018.

[12] M. Di Mauro and C. Di Sarno.

Improving siem capabilities through
an enhanced probe for encrypted Skype trafﬁc detection. Journal of
Information Security and Applications, 38:85–95, 2018.

[13] F. Cauteruccio, G. Fortino, A. Guerrieri, A. Liotta, D.C. Mocanu,
C. Perra, G. Terracina, and M. Torres Vega. Short-long term anomaly
detection in wireless sensor networks based on machine learning and
multi-parameterized edit distance. Information Fusion, 52:13 – 30, 2019.
IoT-keeper:
Detecting malicious IoT network activity using online trafﬁc analysis
at the edge. IEEE Transactions on Network and Service Management,
pages 1–1, 2020.

[14] I. Hafeez, M. Antikainen, A. Y. Ding, and S. Tarkoma.

[15] M. Casillo, S. Coppola, M. De Santo, F. Pascale, and E Santonicola.
Embedded intrusion detection system for detecting attacks over can-
bus. In 4th International Conference on System Reliability and Safety,
pages 136–141, 2019.

[16] R. U. Khan, X. Zhang, M. Alazab, and R. Kumar. An improved
convolutional neural network model for intrusion detection in networks.
In 2019 Cybersecurity and Cyberforensics Conference, pages 74–77,
2019.

[17] S. T. F. Al-Janabi and H. A. Saeed. A neural network based anomaly
intrusion detection system. In Developments in E-systems Engineering,
pages 221–226, 2011.

[18] K. A. Taher, B. Mohammed Yasin Jisan, and M. M. Rahman. Net-
work intrusion detection using supervised machine learning tech-
In 2019 International Conference on
nique with feature selection.
Robotics,Electrical and Signal Processing Techniques (ICREST), pages
643–646, 2019.

[19] S. Kumar and A. Yadav. Increasing performance of intrusion detection
In IEEE International Conference on
system using neural network.
Advanced Communications, Control and Computing Technologies, pages
546–550, 2014.

[20] D. Papamartzivanos, F. Gomez Marmol, and G. Kambourakis.

Intro-
ducing deep learning self-adaptive misuse network intrusion detection
systems. IEEE Access, 7:13546–13560, 2019.

[21] Z. T. Fernando, I. S. Thaseen, and C. A. Kumar. Network attacks iden-
tiﬁcation using consistency based feature selection and self organizing
maps. In First International Conference on Networks Soft Computing,
pages 162–166, 2014.

[22] S. McElwee and J. Cannady.

Improving the performance of self-
organizing maps for intrusion detection. In SoutheastCon 2016, pages
1–6, 2016.

[23] C. Li-ying, Z. Xiao-xian, L. He, and C. Gui-fen. A network intrusion
detection method based on combined model. In International Conference

15

on Mechatronic Science, Electric Engineering and Computer, pages
254–257, 2011.

2018 International Conference on Information and Computer Technolo-
gies (ICICT), pages 128–134, 2018.

[24] Z.N.Al-Sultani R.S.Naoum. Learning vector quantization (lvq) and k-
nearest neighbor for intrusion classiﬁcation. World of Computer Science
and Information Technology Journal, 2(3):105–109, 2012.

[25] J. Woo, J. Song, and Y. Choi. Performance enhancement of deep
neural network using feature selection and preprocessing for intrusion
detection. In 2019 International Conference on Artiﬁcial Intelligence in
Information and Communication (ICAIIC), pages 415–417, 2019.
[26] Y. Jia, M. Wang, and Y. Wang. Network intrusion detection algorithm
based on deep neural network. IET Information Security, 13(1):48–53,
2019.

[27] A. Nagisetty and G. P. Gupta. Framework for detection of malicious
In
activities in IoT networks using Keras deep learning library.
2019 3rd International Conference on Computing Methodologies and
Communication (ICCMC), pages 633–637, 2019.

[28] F. A. Khan, A. Gumaei, A. Derhab, and A. Hussain. A novel two-stage
IEEE
deep learning model for efﬁcient network intrusion detection.
Access, 7:30373–30385, 2019.

[29] Z. Zhang and P. Pan. A hybrid intrusion detection method based
In 2019
on improved fuzzy c-means and support vector machine.
International Conference on Communications, Information System and
Computer Engineering (CISCE), pages 210–214, 2019.

[30] W. Wang, X. Du, and N. Wang. Building a cloud ids using an efﬁcient

feature selection method and svm. IEEE Access, 7:1345–1354, 2019.

[31] X. Tang, S. X. . Tan, and H. Chen. SVM based intrusion detection using
nonlinear scaling scheme. In 2018 14th IEEE International Conference
on Solid-State and Integrated Circuit Technology (ICSICT), pages 1–4,
2018.

[32] S. Sun, Z. Ye, L. Yan, J. Su, and R. Wang. Wrapper feature selection
based on lightning attachment procedure optimization and support vector
machine for intrusion detection. In (IDAACS-SWS), pages 41–46, 2018.
[33] S. Teng, N. Wu, H. Zhu, L. Teng, and W. Zhang. Svm-dt-based adaptive
and collaborative intrusion detection. IEEE/CAA Journal of Automatica
Sinica, 5(1):108–118, 2018.

[34] A. Hadri, K. Chougdali, and R. Touahni. A network intrusion detection
In 2018 IEEE 5th
based on improved nonlinear fuzzy robust PCA.
International Congress on Information Science and Technology (CiSt),
pages 636–641, 2018.

[35] F. Meng, Y. Fu, F. Lou, and Z. Chen. An effective network attack
In 2017
detection method based on kernel PCA and LSTM-RNN.
International Conference on Computer Systems, Electronics and Control
(ICCSEC), pages 568–572, 2017.

[36] K. Ibrahimi and M. Ouaddane. Management of intrusion detection
systems based-KDD99: Analysis with LDA and PCA. In 2017 Inter-
national Conference on Wireless Networks and Mobile Communications
(WINCOM), pages 1–6, 2017.

[37] S. M. Almansob and S. S. Lomte. Addressing challenges for intrusion
detection system using naive Bayes and PCA algorithm. In 2017 2nd
International Conference for Convergence in Technology (I2CT), pages
565–568, 2017.

[38] A. A. Aburomman and M. B. I. Reaz. Ensemble of binary SVM
classiﬁers based on PCA and LDA feature extraction for intrusion
detection. In IEEE (IMCEC), pages 636–640, 2016.

[39] R. Primartha and B. A. Tama. Anomaly detection using random forest:
A performance revisited. In 2017 International Conference on Data and
Software Engineering (ICoDSE), pages 1–6, 2017.

[40] X. Gao, C. Shan, C. Hu, Z. Niu, and Z. Liu. An adaptive ensemble
machine learning model for intrusion detection. IEEE Access, 7:82512–
82521, 2019.

[41] N. Kumar, H. Akash, R. A. Prataap, G. Srinath, and C. Mala. Intelligent
intrusion detection system using decision tree classiﬁer and bootstrap
aggregation. In ISED, pages 199–203, 2018.

[42] M. Bitaab and S. Hashemi. Hybrid intrusion detection: Combining
decision tree and gaussian mixture model. In 2017 14th International
ISC (Iranian Society of Cryptology) Conference on Information Security
and Cryptology (ISCISC), pages 8–12, 2017.

[43] M. A. Jabbar and S. Samreen. Intelligent network intrusion detection
In 2016 International Conference on
using alternating decision trees.
Circuits, Controls, Communications and Computing (I4C), pages 1–6,
2016.

[44] Z. Rustam and A. S. Talita. Fuzzy kernel robust clustering for anomaly
In 2018 Third International Conference on

based intrusion detection.
Informatics and Computing (ICIC), pages 1–4, 2018.

[45] K. Alrawashdeh and C. Purdy. Fast hardware assisted online learning
In
using unsupervised deep learning structure for anomaly detection.

[46] M. Z. Alom and T. M. Taha. Network intrusion detection for cyber
In 2017 IEEE
security using unsupervised deep learning approaches.
National Aerospace and Electronics Conference (NAECON), pages 63–
69, 2017.

[47] W. Chen, F. Kong, F. Mei, G. Yuan, and B. Li. A novel unsupervised
In 3rd
anomaly detection approach for intrusion detection system.
International conference on big data security on cloud, pages 69–73,
2017.

[48] S. Seo, S. Park, and J. Kim. Improvement of network intrusion detection
accuracy by using restricted Boltzmann machine. In 2016 8th Interna-
tional Conference on Computational Intelligence and Communication
Networks (CICN), pages 413–417, 2016.

[49] F. Amiri, M. Rezaei Youseﬁ, C. Lucas, A. Shakery, and N. Yazdani.
Cluster ensemble with link-based approach for botnet detection. Journal
of Network and Systems Management, 26(3):616 – 639, 2018.

[50] N. Moustafa and J. Slay. UNSW-NB15: a comprehensive data set for
network intrusion detection systems (UNSW-NB15 network data set).
In 2015 Military Communications and Information Systems Conference
(MilCIS), pages 1–6, 2015.

[51] N.Koroniotis, N.Moustafa, E. Sitnikova, and B.Turnbull.

Towards
the development of realistic botnet dataset in the Internet of Things
for network forensic analytics: BoT-IoT dataset. Future Generation
Computer Systems, 100:779–796, 2019.

[52] Canadian institute for cybersecurity. https://www.unb.ca/cic/. Accessed:

2020-02-25.

[53] A realistic cyber defense dataset.

https://registry.opendata.aws/

cse-cic-ids2018/. Accessed: 2020-02-25.

[54] V. Kanimozhi and T. P. Jacob. Artiﬁcial intelligence based network
intrusion detection with hyper-parameter optimization tuning on the
realistic cyber dataset cse-cic-ids2018 using cloud computing. In 2019
International Conference on Communication and Signal Processing,
pages 33–36, 2019.

[55] C. Ma, X. Du, and L. Cao. Analysis of multi-types of ﬂow features based
on hybrid neural network for improving network anomaly detection.
IEEE Access, 7:148363–148380, 2019.

[56] S. Wankhede and D. Kshirsagar. DoS attack detection using machine
In Fourth International Conference on
learning and neural network.
Computing Communication Control and Automation, pages 1–5, 2018.
[57] J. Lee, J. Kim, I. Kim, and K. Han. Cyber threat detection based on
artiﬁcial neural networks using event proﬁles. IEEE Access, 7:165607–
165626, 2019.

[58] T. T. T. Nguyen and G. Armitage. A survey of techniques for internet
IEEE Communications

trafﬁc classiﬁcation using machine learning.
Surveys Tutorials, 10(4):56–76, 2008.

[59] R. Boutaba, M. A. Salahuddin, N. Limam, S. Ayoubi, N. Shahriar,
F. Estrada-Solano, and O. M. Caicedo. A comprehensive survey on
machine learning for networking: evolution, applications and research
opportunities. Journal of Internet Services and Applications, 9(1):16,
2018.

[60] H. Hindy, D. Brosset, E. Bayne, A. Seeam, C. Tachtatzis, R. Atkinson,
and X. Bellekens. A taxonomy and survey of intrusion detection system
design techniques, network threats and datasets. CoRR, abs/1806.03517,
2018.

[61] A. Khraisat, I. Gondal, P. Vamplew, and J. Kamruzzaman. Survey
techniques, datasets and challenges.

of intrusion detection systems:
Cybersecurity, 2(1):20, 2019.

[62] A. Aldweesh, A. Derhab, and A. Emam. Deep learning approaches for
anomaly-based intrusion detection systems: A survey, taxonomy, and
open issues. Knowledge-based Systems, 189:105–124, 2020.

[63] G. Fernandes, J. J. P. C. Rodrigues, L. F. Carvalho, J. F. Al-Muhtadi, and
M. L. Proena. A comprehensive survey on network anomaly detection.
Telecommunication Systems, 70(3):447–489, 2019.

[64] A. L. Buczak and E. Guven. A survey of data mining and machine
learning methods for cyber security intrusion detection. IEEE Commu-
nications Surveys Tutorials, 18(2):1153–1176, 2016.

[65] L. N. Tidjon, M. Frappier, and A. Mammar. Intrusion detection systems:
IEEE Communications Surveys Tutorials,

A cross-domain overview.
21(4):3639–3681, 2019.

[66] H. Azwar, M. Murtaz, M. Siddique, and S. Rehman. Intrusion detection
in secure network for cybersecurity systems using machine learning and
data mining. In 2018 IEEE 5th International Conference on Engineering
Technologies and Applied Sciences (ICETAS), pages 1–9, 2018.
[67] N. Moustafa, J. Hu, and J. Slay. A holistic review of network anomaly
detection systems: A comprehensive survey. Journal of Network and
Computer Applications, 128:33–55, 2019.

[68] G. Meena and R. R. Choudhary. A review paper on IDS classiﬁcation
using KDD99 and NSL-KDD dataset in Weka. In 2017 International
Conference on Computer, Communications and Electronics (Comptelix),
pages 553–558, 2017.

[69] R. Ravipati and A. Munther. A survey on different machine learning
algorithms and weak classiﬁers based on KDD and NSL-KDD datasets.
International Journal of Artiﬁcial Intelligence & Applications, 10:01–11,
2019.

[70] C. Yin, Y. Zhu, J. Fei, and X. He. A deep learning approach for intrusion
detection using recurrent neural networks. IEEE Access, 5:21954–21961,
2017.

[71] H. Bengio. Learning deep architectures for AI. Found. Trends Mach.

Learn., 2(1):1–127, 2009.

[72] X. Glorot, A. Bordes, and Y. Bengio. Deep sparse rectiﬁer neural
In Proceedings of the Fourteenth International Conference

networks.
on Artiﬁcial Intelligence and Statistics, pages 315–323, 2011.

[73] G. E. Dahl, D. Yu, L. Deng, and A. Acero. Context-dependent
pre-trained deep neural networks for large-vocabulary speech recogni-
tion. IEEE Transactions on Audio, Speech, and Language Processing,
20(1):30–42, 2012.

[74] M. Ravanelli, P. Brakel, M. Omologo, and Y. Bengio. Light gated
recurrent units for speech recognition. IEEE Transactions on Emerging
Topics in Computational Intelligence, 2(2):92–102, 2018.

[75] H. Le, I. Oparin, A. Allauzen, J. Gauvain, and F. Yvon. Structured output
IEEE
layer neural network language models for speech recognition.
Transactions on Audio, Speech, and Language Processing, 21(1):197–
206, 2013.

[76] Y. Lecun and Y. Bengio. Convolutional networks for images, speech

and time series. The MIT Press, pages 255–258, 1995.

[77] D.E. Rumelhart, G.E. Hinton, and R.J. Williams. Learning representa-

tions by back-propagating errors. Nature, 323(6088):533–536, 1986.

[78] S. Hochreiter and J. Schmidhuber. Long Short-Term Memory. Neural

Computation, 9(8):1735–1780, 1997.

[79] K. Cho, B. van Merrienboer, C¸ . G¨ulc¸ehre, D. Bahdanau, F. Bougares,
H. Schwenk, and Y. Bengio. Learning phrase representations using
RNN encoder-decoder for statistical machine translation. In Proceedings
of the 2014 Conference on Empirical Methods in Natural Language
Processing, pages 1724–1734, 2014.

[80] P. Bowden I. Alexander, W. Thomas. Learning deep architectures for

ai. Sensor Review, 4(3):120–124, 1984.

[81] M. De Gregorio and M. Giordano. An experimental evaluation of
weightless neural networks for multi-class classiﬁcation. Applied Soft
Computing, 72:338 – 354, 2018.

[82] T. Kohonen. Learning vector quantization. In The Handbook of Brain
Theory and Neural Networks (Arbib ed.), pages 631–635, 2003.
[83] T. Kohonen. Self-Organizing Maps, 3rd ed. Springer-Verlag, Berlin,

Heidelberg, 2001.

[84] C. C. Aggarwal. Neural Networks and Deep Learning. Springer-Verlag,

Gewerbestrasse 11, 6330 Cham, Switzerland, 2018.

[85] D.P. Kingma and L.J. Ba. Adam: A method for stochastic optimization.

In ICLR2015, 2015.

[86] V. Matta, M. Di Mauro, and M. Longo. Botnet

identiﬁcation in
randomized DDoS attacks. In Proceedings of the 24th European Signal
Processing Conference, pages 2260–2264, 2016.

[87] M. E. Ahmed, S. Ullah, and H. Kim. Statistical application ﬁngerprinting
for DDoS attack mitigation. IEEE Transactions on Information Forensics
and Security, 14(6):1471–1484, 2019.

[88] J. Zhang, Y. Xiang, Y. Wang, W. Zhou, Y. Xiang, and Y. Guan. Network
trafﬁc classiﬁcation using correlation information. IEEE Transactions on
Parallel and Distributed Systems, 24(1):104–117, 2013.

[89] A. Alsirhani, S. Sampalli, and P. Bodorik. Ddos detection system: Using
a set of classiﬁcation algorithms controlled by fuzzy logic system in
Apache Spark. IEEE Transactions on Network and Service Management,
16(3):936–949, 2019.

16

[90] P. S. Szczepaniak P. J.G. Lisboa, E. C. Ifeachor. Artiﬁcial Neural

Networks in Biomedicine. Springer Science, London, 2000.

[91] V. Prasad and S.D. Gupta. Applications And Potentials Of Artiﬁcial

Neural Networks In Plant Tissue Culture. Springer, Dordrecht, 2008.

[92] S.J. Kim, C. Wang, B. Zhao, H. Im, J. Min, H.J. Choi, J. Hee, J. Tadros,
N.T. Choi, C.M. Castro, R. Weissleder, H. Lee, and K. Lee. Deep
transfer learning-based hologram classiﬁcation for molecular diagnos-
tics. Scientiﬁc Reports, 8:01–12, 2018.

Mario Di Mauro received the Laurea degree in elec-
tronic engineering from the University of Salerno
(Italy) in 2005, the M.S. degree in networking from
the University of L’Aquila (Italy) jointly with the
Telecom Italia Centre in 2006, and the PhD. degree
in information engineering in 2018 from University
of Salerno. He was a Research Engineer with CoRi-
Tel (Research Consortium on Telecommunications,
led by Ericsson Lab, Italy) and then a Research
Fellow with University of Salerno. He has authored
several scientiﬁc papers, and holds a patent on a
telecommunication aid for impaired people. His main ﬁelds of interest include:
network security, performance and availability, data analysis, ML techniques.

Giovanni Galatro received the Laurea degree
(summa cum laude) in information engineering from
the University of Salerno (Italy) in 2018, and has
been a visiting student at Dept. of Computer Science
at Groningen University (Netherlands). In 2017 he
got a scholarship with Telecommunication and Ap-
plied Statistics groups, focused on the availability
analysis of modern telecommunication systems. His
main ﬁleds of interest include: network availability
and machine learning.

Antonio Liotta (SMEEE15) is Full Professor at
the Faculty of Computer Science, Free University
of Bozen-Bolzano (Italy), where he teaches Data
Science and Computer Networks. Previously, he was
full professor at Eindhoven University of Technol-
ogy (NL), University of Derby (UK), and Edinburgh
Napier University (UK). He has also held academic
positions at University of Surrey (UK) and Essex
University (UK), in addition to Visiting and Dis-
tinguished Professorships in the UK, Australia and
China. His team is at the forefront of inﬂuential
research in data science and artiﬁcial intelligence, speciﬁcally in the context
of smart cities, Internet of Things, and smart sensing. He is renowned for his
contributions to miniaturized machine learning, particularly in the context of
the Internet of Things. He has led the international team that has recently
made a breakthrough in artiﬁcial neural networks, using network science
to accelerate the training process. Antonio is a Fellow of the U.K. Higher
Education Academy. He has 6 patents and over 350 publications to his credit,
and is the Editor-in-Chief of the Springer Internet of Things book series.

