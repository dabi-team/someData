Highlights

Jasmine: a New Active Learning Approach to Combat Cybercrime

Jan Klein, Sandjai Bhulai, Mark Hoogendoorn, Rob van der Mei

• Jasmine is a novel hybrid Active Learning method for Network Intrusion

Detection

• Jasmine queries uncertain, anomalous and randomly selected observations

• Jasmine can dynamically adjust the balance between these query types

• Jasmine can learn the best strategy during the labeling process

• Jasmine is the ﬁrst Active Learning method with dynamic updating

• Jasmine performs better than existing static Active Learning methods

1
2
0
2

g
u
A
3
1

]

R
C
.
s
c
[

1
v
8
3
2
6
0
.
8
0
1
2
:
v
i
X
r
a

 
 
 
 
 
 
Jasmine: a New Active Learning Approach to Combat
Cybercrime

Jan Kleina,∗, Sandjai Bhulaib, Mark Hoogendoornc, Rob van der Meia

aDepartment of Stochastics, Centrum Wiskunde & Informatica, Science Park
123, 1098XG, Amsterdam, The Netherlands
bDepartment of Mathematics, Vrije Universiteit, De Boelelaan
1111, 1081HV, Amsterdam, The Netherlands
cDepartment of Computer Science, Vrije Universiteit, De Boelelaan
1111, 1081HV, Amsterdam, The Netherlands

Abstract

Over the past decade, the advent of cybercrime has accelarated the research
on cybersecurity. However, the deployment of intrusion detection methods falls
short. One of the reasons for this is the lack of realistic evaluation datasets,
which makes it a challenge to develop techniques and compare them. This is
caused by the large amounts of eﬀort it takes for a cyber analyst to classify
network connections. This has raised the need for methods (i) that can learn
from small sets of labeled data, (ii) that can make predictions on large sets
of unlabeled data, and (iii) that request the label of only specially selected
unlabeled data instances. Hence, Active Learning (AL) methods are of interest.
These approaches choose speciﬁc unlabeled instances by a query function that
are expected to improve overall classiﬁcation performance. The resulting query
observations are labeled by a human expert and added to the labeled set.

In this paper, we propose a new hybrid AL method called Jasmine. Firstly,
it determines how suitable each observation is for querying, i.e., how likely it
is to enhance classiﬁcation. These properties are the uncertainty score and
anomaly score. Secondly, Jasmine introduces dynamic updating. This allows
the model to adjust the balance between querying uncertain, anomalous and
randomly selected observations. To this end, Jasmine is able to learn the best
query strategy during the labeling process. This is in contrast to the other AL
methods in cybersecurity that all have static, predetermined query functions.
We show that dynamic updating, and therefore Jasmine, is able to consistently
obtain good and more robust results than querying only uncertainties, only
anomalies or a ﬁxed combination of the two.

Keywords: active learning, dynamic query function, network intrusion
detection, human oracle, partially labeled

∗Corresponding author
Email addresses: j.g.klein@cwi.nl (Jan Klein), s.bhulai@vu.nl (Sandjai Bhulai),

m.hoogendoorn@vu.nl (Mark Hoogendoorn), r.d.van.der.mei@cwi.nl (Rob van der Mei)

1. Introduction

The ﬁght against cybercrime has become a priority for many countries. This
is with good reason, because the average cost of a single cyberattack in Europe
is around 50 thousand euros, as estimated by Forrester Consulting and Hiscox
in 2020 [1]. Most common attacks were found to be DDoS attacks, malware
infections and phishing, and these were mostly targeted on companies and even
governmental institutes. For example, 68% of Dutch ﬁrms reported at least
one cyber incident in 2019. Therefore, the amount of money that the surveyed
European companies invested in cybersecurity has increased by 39% from 1.3
million to 1.8 million euros.
In academia, the awareness for research in the
ﬁeld of cybersecurity has also grown. For instance, Mouloua et al. analyzed
the articles published in the Proceedings of the Human Factors and Ergonomics
Society (HFES) from 1980 to 2018 [2]. They showed that 73% of articles related
to cybersecurity published in that almost 40-year span were written in the last
nine years.

Since most cyberattacks are aimed at companies and countries, it is im-
portant to know how networks of computers can be protected. A Network
Intrusion Detection System (NIDS) is software designed to detect unusual, ma-
licious events in a computer network. There are several types of systems with
each having their own set of challenges for which several solutions have been
proposed [3, 4, 5]. However, there are some broader challenges in cybersecurity
research. Most importantly, Xin et al. and Yang et al. argue that not much con-
sideration is given to deployment eﬃciency [6, 7]. This means that not much
is practically done with published research, because of time complexity of the
techniques and the eﬃciency of detection in actual networks. The latter is due
to the lack of realistic datasets, since it takes a lot of time and eﬀort for a hu-
man to classify network connections correctly. Moreover, cyber analysts have
to label many redundant connections just to construct a representative dataset.
This loads the experts with tedious work and leads to an underuse of their capa-
bilities. Therefore, it would be beneﬁcial to only present ‘informative’ network
connections to the cyber analyst. This can be realized in Active Learning (AL),
in which the model chooses from which unlabeled data instances it wants to
learn and then queries their labels [8, 9].

Several AL methods have been proposed in intrusion detection research.
Many of them focus on querying uncertain data, i.e., requesting the label of ob-
servations about which the model is not sure how to classify them [10, 11, 12].
Adding these observations with their correct label is expected to enhance classi-
ﬁcation performance more quickly than randomly selecting observations. Other
studies consider diﬀerent query strategies or combine several query approaches
to make the AL procedure more robust [13]. Stokes et al. query both uncertain
and anomalous instances [14]. The latter are observations that behave vastly
diﬀerently than expected and that could indicate malicious activities. Although
combining query types increases prediction performance, the optimal balance of

2

the types depends on, for example, the dataset. Moreover, the balance has to
be determined beforehand and is still up for debate.

In our research, we propose a novel AL method called Jasmine that in-
troduces α-dynamic updating. This allows our method to adjust the balance
between querying diﬀerent types of observations such that the right types are
proposed to the human expert at the right time. This makes sense, because the
structure of the labeled set (on which the classiﬁer is trained) changes during the
labeling procedure. Hence, Jasmine is able to learn the best query strategy dur-
ing the process. The types of instances that Jasmine considers potentially infor-
mative are uncertain, anomalous and randomly selected observations. Querying
uncertain and anomalous unlabeled data is inspired by the AL method of Stokes
et al. that queries these observations types in a ﬁxed 50/50 split [14]. Jasmine
is able to dynamically change the balance to ensure that the most informative
observations to the intrusion detection model are queried. This sets our method
apart from existing AL methods, because (to our knowledge) Jasmine is the
only method that allows for this. Our contributions are:

• We propose a new AL method called Jasmine that introduces dynamic
updating of the balance between querying uncertain, anomalous and ran-
domly selected unlabeled data.

• We present the mathematical formulation of Jasmine and explain why it

can ﬁnd a good balance given the current labeling state.

• We apply Jasmine to two commonly used network intrusion detection
datasets and use them in diﬀerent experimental settings. We show that
Jasmine obtains good results and is more robust than static query ap-
proaches. Therefore, Jasmine is more reliable to use, because it can adapt
itself to diﬀerent situations.

The rest of the paper is organized as follows. In Section 2, we explain the
AL paradigm and what methods have been proposed in intrusion detection.
Section 3 introduces the mathematical notation used in the AL framework. In
Section 4, we propose our method Jasmine and explain how it works. The ex-
periments that we execute to validate our method are discussed in Section 5.
Section 6 subsequently shows the results of these experiments and their inter-
pretations. Finally, in Section 7, we draw conclusions about this study and
make suggestions for further research.

2. Related Work

Active Learning is a subﬁeld of machine learning in which the premise is
that only a small part of the data is labeled, while the labels for the rest of
the data are not speciﬁed. The AL procedure is illustrated in Figure 1. Firstly,
an ML model is trained on the labeled set and applied to the unlabeled obser-
vations to obtain output predictions. Then, interesting observations from the
unlabeled part are selected and an oracle is asked to provide the actual labels.

3

Figure 1: Illustration of Active Learning framework (taken from Settles [8]).

Subsequently, these query observations are added to the labeled set and the
procedure continues. An important advantage of AL is that the model needs
less train data to learn better [8, 9]. This is especially beneﬁcial in domains in
which it is laborious to label data. Examples of such ﬁelds are speech recog-
nition, information extraction (person names from texts, annotation of genes,
etc.) and classiﬁcation of ﬁles (relevant or irrelevant documents, images, etc.).
Network intrusion detection is one of the ﬁelds in which it is burdensome to
label the huge number of network connections.

2.1. Query Strategies

There are multiple ways to query the oracle, but we focus on pool-based
sampling. Here, speciﬁc observations are selected to be queried from the unla-
beled pool. The decision is based on some informativeness measure, which is
determined for all instances in the pool (or a subset thereof). This approach
to querying has been applied to many real-world problems, including the ﬁelds
mentioned in the previous paragraph. It works well with a human oracle and
when it is relatively easy to compute the informativeness of all observations at
once.

As we mentioned before, a commonly used informativeness measure is the
uncertainty score. This measure is used to query observations about which the
model is the least certain on how to predict their label [15]. This is a simple
informativeness measure, because no new models have to be trained and only
the output of the classiﬁer is required to determine the uncertainty of each
observation.

2.2. Active Learning in Network Intrusion Detection

Which speciﬁc query strategy, informativeness measure(s) and ML tech-
niques are used depends on the AL application.
In network intrusion detec-
tion, several AL methods have been proposed. These approaches mostly rely
on uncertainty sampling. Li et al. use Transductive Conﬁdence Machines for
K-Nearest Neighbors for supervised intrusion detection with uncertainty sam-
pling and query by committee [10]. Guerra Torres et al. make use of Random

4

Forests for prediction and query uncertain observations. [11] G¨ornitz et al. use
a Support Vector Domain Description (SVDD) for anomaly detection with un-
certainty sampling as the AL component [12]. All these studies show that a
method with AL obtains better results than one without it, or that the pro-
posed query strategy performs better than randomly presenting observations to
the oracle. However, they are rather limited in the sense that they only consider
one informativeness measure for query selection.

Though, there are studies that incorporate two measures to improve clas-
siﬁcation performance. Yin et al. use an SVDD for prediction, and combine
the uncertainty informativeness measure with density information as the query
approach. More speciﬁcally, the distance of an observation to its nearest neigh-
bor is calculated and instances residing in high density areas are more likely
to be queried [13]. Stokes et al. propose to combine uncertainty sampling with
querying anomalous data, thus presenting instances that behave vastly diﬀer-
ently than expected to the oracle [14]. These studies show that using multiple
informativeness measures further improves performance, because more charac-
teristics of the data are used to determine which unlabeled observations would
improve predictions the most if they were labeled.

The common factor of the aforementioned research is that all proposed query
functions are static in nature. From the start, it is exactly known how the set
of query observations is constructed and this approach cannot be changed. This
means the contribution of each informativeness measure in the selection of the
query observations has to be ﬁxed beforehand. However, the optimal balance of
these contributions depends on the overall structure of the data and also on the
current state of the labeling process. Therefore, we consider a dynamic query
approach in this research to address these problems. To this end, the balance
can be adapted during the procedure to best ﬁt the data. More speciﬁcally,
the method learns the distribution of query types that is expected to increase
prediction performance the most given the current state.

2.3. ALADIN

The AL methodology for network intrusion detection that we use as a start-
ing point for our research was developed by Stokes et al. and is called AL-
ADIN [14]. It was chosen because it combines two important informativeness
measures: the (i) uncertainty score and (ii) anomaly score. On the one hand,
by querying selected anomalies, new classes of network traﬃc can be found
within the data. On the other hand, by querying uncertainties, the accuracy of
the classiﬁer should increase in the next time step when the correct classes have
been provided by the human expert. ALADIN combines both Pelleg’s algorithm
for anomaly detection [16] and Almgren’s algorithm for intrusion detection [17].
In the ﬁrst algorithm, an anomaly detection model is constructed for each data
class, so one for the benign class and one for the malicious class in the binary
case. How unlikely an unlabeled observation is according to the model of its
(predicted) class, determines how anomalous it is. The less likely an instance
is, the more interesting it is for querying.
In the second algorithm, observa-
tions that lie close to the decision boundary of the trained classiﬁer are deemed

5

Figure 2: Schematic representation of an ALADIN iteration. Taken from Stokes et al. [14].

uncertain, and hence, interesting for querying. The description of ALADIN is
illustrated in Figure 2.

On the 1999 KDD-Cup dataset [18], Stokes et al. show that ALADIN achieved
high accuracy in predicting known traﬃc classes. Moreover, it was able to detect
previously unknown categories quickly. The authors also applied their method
on real corporate network logs containing about 13 million observations. Inter-
estingly, ALADIN discovered a new trojan, which was not found by the rule-
based NIDS that the company used. This shows that incorporating anomalous
and uncertain observations in the query set led to favorable results.

ALADIN uses simple machine learning techniques such as logistic regression
and naive Bayes to be able to scale well. However, the authors mention that the
benign class in the KDD-Cup dataset is very diverse, meaning that this class
may not be easily predicted with the logistic regression classiﬁer. In our research,
we consider more advanced machine learning techniques that are better able to
capture the diversity of network traﬃc. More importantly, in ALADIN, half of
the queried observations are anomalous, while the other half is uncertain. This
ﬁxed 50/50 split is not motivated by the authors. Hence, model performance
can improve when the proportion between querying anomalies and uncertainties
is changed depending on the considered dataset and within the process. This
leads to our α-dynamic updating.

3. Preliminaries

Before we provide the mathematical formulation of Jasmine, we introduce
some notation to describe the AL framework in general. Firstly, we assume to
have a dataset X ∈ RM ×K, with M ∈ N the number of observations and K ∈ N
the number of features or attributes. Let xi ∈ RK be the feature vector of
observation i ∈ {1, . . . , M } and let yi ∈ {0, 1, ∗} be its corresponding response

6

value. Here, ‘0’ represents the benign class and ‘1’ the malicious class. The
symbol ‘*’ means that the class or label is missing. In AL, it is assumed that only
a (possibly small) part of the data is labeled, while the rest is unlabeled. The set
of labeled observations L(t) and the set of unlabeled observations U(t) depend
on the iteration or time step t = 1, . . . , T , where T ∈ N is a predetermined
maximum number of iterations. Since more labels become available when the
iteration procedure progresses, the vector of response values of all the instances
y(t) = (y1(t), . . . , yM (t)) is dependent on time. Now, for all iterations it holds
that L(t) and U(t) are disjoint and their union is the complete dataset (X, y(t))
with labels up to time t. Let L(t) := |L(t)| be the number of labeled observations
and U (t) := |U(t)| the number of unlabeled instances at time t. Note that
L(t+1) > L(t), while U (t+1) < U (t), because every iteration the human expert
adds labels to previously unlabeled observations. L(0) contains the instances
that are labeled from the start, while U(0) consists of all initially unlabeled
observations. In iteration t, a supervised machine learning technique ft : RK →
[0, 1] is trained on L(t − 1). This classiﬁer ft is then applied to U(t − 1) to
obtain predictions for the actual classes of the unlabeled observations. Then,
a query function ψ determines which instances from U(t − 1) are selected to
be queried to the human expert. Let Q(t) ⊆ U(t − 1) be the constructed set
of query observations. Usually, this set has ﬁxed size Q := |Q(t)|. Then, the
expert provides the labels yq(t) ∈ {0, 1} for the observations q ∈ Q(t). Note
that in the previous iteration their labels were still unknown: yq(t − 1) = ‘*’.

4. Methods

In this section, we introduce our Active Learning method Jasmine. Its key
component is α-dynamic updating, which allows the model to dynamically ad-
just the balance between querying anomalous, uncertain and random observa-
tions during the procedure. The adjustment of the balance comes in two ﬂavors.
Firstly, the initial proportions of the three types of query observations are de-
termined. Based on the available initially labeled data L(0), it can be beneﬁcial
to start with querying 60% anomalous, 15% uncertain and 25% random obser-
vations, for example. Secondly, the balance between the types can be changed
during the labeling process, because it may be better to query increasingly
more anomalous instances when more and more labels are provided by the ora-
cle. This leads to dynamically updating the query fractions. Moreover, we also
consider querying random observations. This may seem counter-intuitive in the
AL setting, because its premise is not to bother the human expert with labeling
redundant observations. However, when L(0) is not a good representation of
the entire dataset, querying some random observations could be beneﬁcial.

The complete Jasmine procedure is illustrated in Figure 3.

It consists of
two consecutive phases. In Phase 2, the actual Active Learning component of
Jasmine is executed given the results of Phase 1. More speciﬁcally, the clas-
siﬁer is trained on L(t) and applied to U(t) to obtain malicious probabilities
(Section 4.3). Then, the informativeness measures of the unlabeled observa-
tions are calculated (Section 4.4) and the query sample is constructed based

7

Figure 3: Schematic representation of complete Jasmine procedure.

on these measures (Section 4.5). Next, the actual labels are provided by the
human oracle. Then, the crucial part of Jasmine is performed by updating the
query fractions based on the results obtained during the iteration (Section 4.6).
Consequently, the query set of the next iteration should have a better balance
of anomalous, uncertain and random observations. Finally, the labeled query
observations are added to L(t + 1) (Section 4.7) and the procedure continues.
In Phase 1, good values of the hyperparameters of the classiﬁer are determined
(Section 4.2). Also, good values of the Jasmine-speciﬁc parameters are chosen
in this phase (Section 4.8). Since tuning of the Jasmine parameters is a reduced
version of the second phase, we explain the latter ﬁrst in this section.

4.1. Classiﬁcation and anomaly detection techniques

4.1.1. Gradient Boosting Machine

The supervised machine learning technique used as the classiﬁer in Jasmine
is the Gradient Boosting Machine (GBM), which was designed by Friedman [19].
As described by Natekin et al. [20], Ogutu et al. [21], and Carauna et al. [22],
one of the main merits of the GBM is its ﬂexibility and robustness with respect
to the number of hyperparameters.
It can easily be customized for diﬀerent
practical purposes. Another advantage of the GBM is its interpretability. Since
the technique is an ensemble of multiple simple models, it can be understood
more easily than a black box model. This is of great value to practitioners (in our
case cybersecurity analysts). The authors do mention that one of the drawbacks
of the GBM is its memory-consumption for large datasets. In cybersecurity, the

8

datasets are rather big, so it may seem counter-intuitive to use such a tree-based
ensemble method. However, the datasets on which the classiﬁer is actually
trained are in fact relatively small because of the Active Learning framework.

4.1.2. Isolation Forest

The anomaly detection method used in Jasmine is the Isolation Forest (IF),
which was developed by Liu et al. [23]. Just as the GBM, it is a tree-based
ensemble machine learning technique. Most anomaly detection models try to
construct a representation of normal behavior, but the IF aims to isolate the
anomalous observations. The authors use two important properties of anoma-
lies: (i) there are few of them, and (ii) they have distinctly diﬀerent charac-
teristics than the majority of observations. Because these properties hold, it
is relatively easy to isolate them from the rest. The main advantage of the IF
technique is that it is fast and relatively easy to interpret [24].

4.2. Tuning GBM hyperparameters

The GBM has hyperparameters that are determined beforehand.

In Jas-
mine, good values are found via hyperparameter tuning. This is done on the set
L(0), because by deﬁnition the observations in this set are the only ones with
labels from the start. For each iteration of tuning, the set of hyperparameters
is assigned a certain value. Then, the machine learning technique is trained on
L(0) given this set and returns some performance metric [25]. In Jasmine, k-fold
cross validation is used for training, such that each observation in L(0) is both
utilized for training and evaluating the model. This is desirable, because L(0) is
usually rather small, so we want to eﬀectively use each provided label. During
tuning, also the computation time is taken into account, because the GBM is
retrained each AL iteration and relatively large training times quickly stack. We
want to ﬁnd hyperparameters that yield good performance in both predictive
ability and computation time. To this end, assume there are H hyperparameter
combinations yielding a sequence of performance metrics h1, . . . , hH and a se-
quence of computation times t1, . . . , tH . Let h∗ := max{h1, . . . , hH } be the best
performance and let j∗ := arg max{h1, . . . , hH } be the combination yielding this
performance. If there are several combinations resulting in the best performance
metric, then j∗ is the one with the smallest computation time tj∗ . Also, if there
is a combination yielding a performance of almost h∗, but with a much smaller
computation time than tj∗ , then we prefer to go for that combination. In that
case, combination j is chosen as the optimal one whenever

dj :=

hj∗ − hj
tj∗ − tj

< ε,

where ε > 0 is some predeﬁned threshold. If several j satisfy this requirement,
then the one with the smallest dj is chosen.

9

4.3. Training, evaluating and predicting

The classiﬁcation is done by means of a GBM, which we described in Sec-
tion 4.1. The hyperparameters for this technique are determined by the method
that we described in Section 4.2. In iteration t, the GBM is trained with k-fold
cross validation on L(t − 1), yielding the classiﬁer ft and some threshold prob-
ability θ ∈ (0, 1). This θ represents the border between predicting an instance
as 0 (benign) or as 1 (malicious), and is the value that maximizes some perfor-
mance metric on L(t−1). In Jasmine, we are interested in how conﬁdent ft is in
its predictions. The closer the predicted probability is to θ, the less certain the
model is. Intuitively, a value of 0.5 can be seen as the least certain probability
for a binary classiﬁer, because it is precisely between 0 and 1. Therefore, θ is
transformed to be 0.5 and the probabilities are changed accordingly. We provide
more reasoning why this is done in Section 4.4. The function ϕθ : [0, 1] → [0, 1],
deﬁned as

ϕθ(y) =

(1 − θ)y
(1 − 2θ)y + θ

,

is applied to all predicted probabilities to transform them. We chose this func-
tion, because it has the following desirable properties: (i) ϕ is continuously dif-
ferentiable, (ii) ϕθ(0) = 0, (iii) ϕθ(θ) = 0.5, (iv) ϕθ(1) = 1, and (v) ϕ(cid:48)
θ(y) ≥ 0.
Note that the probabilities do not change when θ is already 0.5: ϕθ=0.5(y) = y
for all y ∈ [0, 1].

After this, ft is applied to the unlabeled set U(t − 1) to obtain predicted
probabilities ˆyu(t) ∈ [0, 1] (which have been transformed by ϕθ) for each u ∈
U(t − 1). Consequently, the predicted class ˆcu(t) is 0 if ˆyu(t) < 0.5 and 1 if
ˆyu(t) ≥ 0.5.

4.4. Calculating certainty score and anomaly score

In the next step, the measures needed for the query function ψJas to de-
termine which unlabeled observations to present to the expert are calculated.
These measures are the certainty score and anomaly score.

4.4.1. Certainty score

The certainty score zu(t) ∈ [0, 1] is deﬁned as

zu(t) := 2

(cid:12)
(cid:12)
(cid:12)
(cid:12)

ˆyu(t) −

(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
2

,

(1)

for each u ∈ U(t − 1). The lower this score, the more uncertain the trained
model ft is about the predicted label of u. Equation (1) is the commonly used
deﬁnition for the certainty score in AL methods, such as in ALADIN. It also
shows why we transformed the raw predicted probabilities by ϕθ. Now, the
distance from 1
2 can be at most 0.5 in both the benign direction (corresponding
to ˆyu(t) ↓ 0) and the malicious direction (ˆyu(t) ↑ 1), making zu(t) a symmetric
score.

10

4.4.2. Anomaly score

The IF technique that we described in Section 4.1 is used to determine the
anomaly score au(t) for each u ∈ U(t − 1). Firstly, the class-speciﬁc observation
sets are deﬁned for each c ∈ {0, 1} by

L(c)(t − 1) := {l ∈ L(t − 1) : yl = c},

U (c)(t) := {u ∈ U(t − 1) : ˆcu(t) = c}.

(2)

Now, one IF is trained on the set L(0)(t − 1) ∪ U (0)(t) and one on the set
L(1)(t − 1) ∪ U (1)(t), yielding a benign IF I (0)
: RK → [0, 1] and a malicious
IF I (1)
: RK → [0, 1], respectively. Then, the anomaly score of u ∈ U(t − 1) is
t
deﬁned as

t

au(t) := I (ˆcu(t))

t

(xu).

(3)

This is the output value that the appropriate IF produces when the feature
vector xu is fed into it.

4.5. Constructing query sample Q(t)

An important component of Jasmine is the way in which the query function
ψJas determines how the query sample Q(t) is constructed. There are three
types of query observations: anomalies, uncertainties and random instances.
Which part of Q(t) should be allocated to which type is given by the anomaly
fraction αa(t), uncertainty fraction αz(t) and randomness fraction αr(t).

4.5.1. Anomalous query observations

For each class c ∈ {0, 1}, the unlabeled observations in U (c)(t) (see (2))
are sorted from most anomalous to least anomalous. Then, the top 1
2 αa(t) · Q
observations are taken as the anomalous query instances for predicted class c.

4.5.2. Uncertain query observations

The uncertainties are selected in a similar way: the observations in U (c)(t) are
sorted from least certain to most certain for each class c. Then, the top 1
2 αz(t)·Q
instances are selected for the uncertain query observations for predicted class c.

4.5.3. Random query observations

The random query observations are selected in a simple way: a sample of
size αr(t) · Q is taken from U(t) (without the already selected anomalous and
uncertain observations).

4.5.4. Corrections

First of all, some rounding corrections are applied when the values 1

2 αa(t)·Q,
1
2 αz(t) · Q and/or αr(t) · Q are not integer. Secondly, it is possible that there
are not enough observations for a speciﬁc class. Then, observations from the
other class are added to reach the number of required anomalies or uncertainties.
Thirdly, there can be an overlap between the most anomalous and least certain

11

instances: some observations can be both anomalous and uncertain, and hence,
we select them for both query types.

Finally, when the query observations are determined, the query set Q(t)
is shown to the human expert and they provide the correct label yq for each
q ∈ Q(t).

4.6. α-dynamic update
4.6.1. Constructing update parameters

The query set Q(t) obtained in Section 4.5 can be decomposed in Qa(t),
Qz(t) and Qr(t), which are the sets of anomalous, uncertain and random queries,
respectively. Also, let Qa(t), Qz(t) and Qr(t) be their respective sizes. Further-
more, let yq ∈ {0, 1} be the real label of query observation q, ˆyq(t) ∈ [0, 1] its
predicted malicious probability and ˆcq(t) ∈ {0, 1} its predicted label. In prac-
tice, the real label is available since the cyber expert provides it. We want to
construct a metric for the anomalous queries and one for the uncertain queries
that describe how much information the observations of those types can poten-
tially add to the model. We do this by looking at the false negatives (FNs)
and false positives (FPs) in Q(t). The reasoning is that when there are many
FNs and FPs, then the model was bad at predicting the real classes of those
unlabeled observations. Hence, adding these observations to the labeled set L(t)
could yield a lot of information for the classiﬁer trained in the next iteration.
In short, we consider the fraction of FPs and FNs in Q(t), but also take a look
at how convincing they are. If the model is fairly certain that an observation is
malicious while it is in fact benign, then this FP obtains a larger weight than
if the model is not that sure. Consequently, we deﬁne the anomaly information
metric δβ

a (t) as follows:

δβ
a (t) :=

(cid:80)

q∈Qa(t) |ˆyq(t) − yq| · (cid:0)β · 1{ˆcq=0,yq=1} + 1{ˆcq=1,yq=0}
Qa(t) + (β − 1) · |{q ∈ Qa(t) : yq = 1}|

(cid:1)

.

(4)

Note that the ﬁrst indicator function in (4) corresponds to an FN: the real label
is 1, but the predicted label is 0. Equivalently, the second indicator function
corresponds to an FP. If the query observation q is an FN, it gets weighted by
some parameter β > 0. This enables us to put more (β > 1) or less (β < 1)
emphasis on the FNs compared to the FPs. Thus, if q is an FN, then it obtains
value β|ˆyq(t)−yq|; if it is an FP, it obtains |ˆyq(t)−yq|. The farther the predicted
probability ˆyq(t) is from 0 or 1 (thus the less certain the model is about the
prediction), the larger the assigned value for q becomes. The denominator
ensures that the value of δβ
a (t) is at most 1. When there are no FPs and FNs,
then the value of the metric is 0. Consequently, δβ
a (t) ∈ [0, 1]. The larger
δβ
a (t) is, the more information the anomalies convey, because we expect that
incorrectly predicted observations add relevant information to the model if they
are added to the train set with the correct labels.

Similarly, we deﬁne the uncertainty information metric

δβ
z (t) :=

(cid:80)

q∈Qz(t) |ˆyq(t) − yq| · (cid:0)β · 1{ˆcq=0,yq=1} + 1{ˆcq=1,yq=0}
Qz(t) + (β − 1) · |{q ∈ Qz(t) : yq = 1}|

(cid:1)

,

(5)

12

as a measure on how much information the uncertain observations in the query
set add on average. Also, δβ

z (t) ∈ [0, 1].

Next, the diﬀerence between the information metrics that we deﬁned in (4)
and (5) describes whether anomalies or uncertainties could add more informa-
tion to the model. We deﬁne this diﬀerence ∆(t) as

∆(t) := δβ

a (t) − δβ

z (t) ∈ [−1, 1].

It is used to determine how the query fractions of anomalies and uncertainties are
updated. If ∆(t) > 0, then the queried anomalies could add more information on
average, and hence, preferably, more anomalies are selected the next iteration.
If ∆(t) < 0, then the uncertainties could add more information, and so, more
uncertainties are selected.

Now, we want the possibility to put more or less emphasis on bigger or
smaller values of ∆(t). Hence, we introduce a non-linearity governed by γ > 0
to obtain ∆γ(t). To this end, we deﬁne the update factor as

∆γ(t) := sgn(∆(t)) · |∆(t)|1/γ.

(6)

When γ = 1, then (6) reduces to the linear case ∆γ(t) = ∆(t). If 0 < γ < 1,
then |∆γ(t)| ≤ |∆(t)|, so the update factor is relatively smaller. On the other
hand, if γ > 1, then |∆γ(t)| ≥ |∆(t)| and the factor is relatively larger.

4.6.2. Deﬁning αa(t + 1) and αz(t + 1)

The update factor ∆γ(t) is used to determine whether more anomalies or
uncertainties should be queried in the next iteration such that we obtain a better
predictive model. The updates αa(t + 1) and αz(t + 1) have the forms

αa(t + 1) = λt+1

(cid:16)

αa(t) + w(1)

a (t) · max{0, ∆γ(t)} + w(2)

(cid:17)
a (t) · min{0, ∆γ(t)}

,

(7)

and

αz(t+1) = λt+1

(cid:16)
αz(t) + w(1)

z (t) · max{0, −∆γ(t)} + w(2)

z (t) · min{0, −∆γ(t)}

(cid:17)

,

(8)
respectively. Here, the w variables are non-negative constants that we need
to ensure that the fractions stay within the correct bounds for time step t.
Moreover, λt+1 denotes a linear function which guarantees that the updated
fractions are also within the bounds for time step t + 1. Let us examine (7) in
a bit more detail: the new fraction αa(t + 1) is based on the old value αa(t)
plus some value when ∆γ(t) > 0 or minus some value when ∆γ(t) < 0.
In
other words, when the anomalies add more information on average than the
uncertainties, then αa(t + 1) becomes larger. Otherwise, αa(t + 1) becomes
smaller. The update dynamics are the other way around for (8). We provide
the explicit mathematical deﬁnitions of the w variables and λt+1 in Appendix
A. It is important to mention that they depend on the hyperparameters α(0)
a
and α(0)
z , which are the initial query fractions of anomalies and uncertainties,
respectively.

13

4.6.3. Deﬁning αr(t + 1)

The fraction of random observations that we want to query relates to the
number of available labeled observations L(t).
If L(0) is small, then L(0) is
less likely to be a good representation of the complete labeled dataset (X, y).
In that case, we want to query relatively more random instances at the start
to be able to obtain a representative train set for the GBM classiﬁer to learn
from. As L(t) increases, we want to query less and less random observations
and let Active Learning take over in the sense of querying anomalies and uncer-
tainties. Therefore, let αr(t) be an exponentially decreasing function in t. More
speciﬁcally,

αr(t) = αmax

r

· 2−τ ·L(t),

(9)

with τ > 0 the decrease speed and L(t) = L(0) + Q · t. Note that this function
is determined beforehand. Hence, how the fraction of randomly queried obser-
vations changes, is ﬁxed during the Jasmine procedure. The value of αmax is
directly determined by the hyperparameters α(0)

a and α(0)
z .

4.6.4. Computation time

It is important to see that executing the α-dynamic update step does not
take much computation time. No additional machine learning models have to
be trained and only relatively simple operations are performed to determine the
values of the query fractions for the next time step.

4.7. Final iteration updates

The last steps that Jasmine has to perform are rather simple, the labeled
query set Q(t) is added to the current labeled set L(t − 1) and removed from
the current unlabeled set U(t − 1). More speciﬁcally, L(t) := L(t − 1) ∪ Q(t)
and U(t) := U(t − 1) \ Q(t).

4.8. Tuning Jasmine hyperparameters

Chronologically speaking, tuning of the Jasmine-speciﬁc hyperparameters
takes place in Phase 1 before the actual Active Learning procedure in Phase 2,
as we illustrated in Figure 3. To be more speciﬁc, Jasmine tuning occurs after
tuning the hyperparameters for the GBM, and thus, directly after Section 4.2.
Recall that the hyperparameters are (i) α(0)
z , the starting fractions
a
of querying anomalous and uncertain observations, respectively; (ii) β, the pa-
rameter assigning a certain weight to an FN compared to an FP, given in (4)
and (5); (iii) γ, the update magnitude, given in (6); and (iv) τ , the decrease
speed in querying random observations, given in (9). Using normalization, α(0)
a
and τ completely determine α(0)

z , so the latter does not have to be tuned.

and α(0)

To determine appropriate values for these hyperparameters, the initially la-
beled set L(0) is randomly partitioned into the sets LJ (0), UJ (0) and EJ . During
Jasmine tuning, LJ (0) is taken as the initially labeled set, UJ (0) as the initially
unlabeled set and EJ as the evaluation set. Let J be the set with hyperparam-
eter values that we want to consider for tuning. Thus, an element j ∈ J is a

14

four-dimensional vector of the form (α(0)
a , β, γ, τ ). Let QJ be the number of un-
labeled observations that should be queried in each iteration. Ideally, the value
of QJ is close to Q, but we do want to perform some iterations before LJ (t)
reaches the size of L(0). The number of iterations in Jasmine tuning is given
by TJ := (cid:100) UJ (0)
(cid:101) − 1, where UJ (0) := |UJ (0)|. The minus one is because the
QJ
last unlabeled observations are the least informative, and hence, not of interest
to query.

Let j ∈ J be some hyperparameter combination. Then a GBM model is
trained on LJ (0), similar to what we described in Section 4.3. This model
is then applied to the evaluation set EJ resulting in some performance metric
pj(0). Then the rest of the AL procedure, as we described in Section 4.4 to
4.7, is executed. After all iterations are performed, the sequence of performance
measures {pj(t − 1)}{t=1,...,TJ } is obtained. We use this sequence to determine
which hyperparameter combination works best, since such a sequence is obtained
for each j ∈ J .

Because stochasticity is involved, we repeat Jasmine tuning SJ times. Each
simulation, the set L(0) is randomly divided in the sets LJ (0), UJ (0) and EJ .
Also, each simulation yields a sequence of performance metrics for each hyper-
parameter combination. Then the combination that yields the best performance
over the simulations is taken as (relatively) optimal for α(0)

a , β, γ and τ .

4.9. Summary of Jasmine

Algorithm 1 Jasmine procedure

Require: Labeled set L(0), unlabeled set U(0), number of iterations T , query

function ψJas

1: Tune parameters of GBM on L(0) (Section 4.2)
2: Tune Jasmine-speciﬁc hyperparameters (α(0)

a , β, γ, τ ) on L(0) (Section 4.8)

z by normalization

Train GBM ft with tuned parameters on L(t − 1)

and determine α(0)
3: for t = 1 to T do
4:
5: Apply ft to U(t − 1) to obtain predictions ˆyu(t)
6: Assign each u ∈ U(t − 1) to its most likely class
7:
8:
9:
10:
11: Obtain actual classes yq of q ∈ Q(t) by human expert
12: Use yq and predictions ˆyq(t) to determine δβ

Calculate each zu(t) as deﬁned in (1)
Construct one IF for each class (Section 4.4).
Compute each au(t) as deﬁned in (3)
Compose Q(t) using query function ψJas as described in Section 4.5

a (t), δβ

z (t) and ∆γ(t)

with (4), (5) and (6), respectively.
Update query fractions to obtain αa(t + 1) and αz(t + 1) (Section 4.6)
L(t) ⇐ L(t − 1) ∪ Q(t) and U(t) ⇐ U(t − 1) \ Q(t)

13:
14:
15: end for
16: return

15

The complete Jasmine procedure is summarized in Algorithm 1.

5. Experimental Setup

We conducted several experiments to determine whether our AL method
Jasmine performed better than ALADIN and to decide if α-dynamic updating
yielded signiﬁcant improvements over baseline query functions. In this section,
ﬁrstly, we discuss the datasets on which the experiments were performed. These
sets are fully labeled, so the labels for the observations in the ‘unlabeled’ set
were hidden until they were queried by Jasmine. After that, we explain the
steps taken to execute the procedures. These include which hyperparameters
were tuned over which ranges and how the diﬀerent AL methods were evaluated.

5.1. Data

Yavanoglu et al. [26] and Ferrag et al. [27] provided overviews of publicly
available security-related datasets commonly used in intrusion detection re-
search. The sets that were discussed span from 1999 to 2018, showing that
even old network datasets are still used to benchmark intrusion detection tech-
niques. However, this is mostly due to the lack of public data, as discussed
in Section 1. Here, ﬁrstly, we used the NSL-KDD dataset for assessing the
considered AL methods, since it is the most used for evaluation in the ﬁeld of
cybersecurity. Ferrag et al. state that this data was cited at least 1,630 times as
of June 22, 2019. Also, Stokes et al. made use of the NSL-KDD dataset to as-
sess their ALADIN method. Secondly, we considered the UNSW-NB15 dataset.
This set is cited often too, namely 202 times, and it is much more recent than
the popular NSL-KDD data. Moreover, it has several more realistic aspects,
which are discussed later. Henceforth, these datasets were used to assess the
performance of the discussed AL methods and to compare the obtained results
for diﬀerent data.

5.1.1. NSL-KDD

The NSL-KDD dataset was developed by Tavallaee et al. in 2009 [28] and
is an improvement on the KDD-Cup-99 dataset. The latter was prepared by
Stolfo et al. [29] and consists of a train set and a test set. These two sets were
constructed such that they do not have the same underlying distribution. Each
observation in KDD-Cup-99 is made up of a 41-dimensional feature vector and
an output label with the attack type. There are four global types of actual
attacks and a ‘normal’ type, indicating a benign connection. Within the attack
types, there can be several distinct attack scenarios. The test set contains sce-
narios from the train set as well as new scenarios. As mentioned before, the
NSL-KDD dataset is a revision of the KDD-Cup-99 data. Firstly, redundant
and invalid records were removed to ensure learning algorithms do not get bi-
ased towards frequent records. Secondly, speciﬁc records were selected from the
resulting set to construct a more challenging dataset. How this was done is de-
scribed by Tavallaee et al. [28]. Finally, the total number of train observations

16

in NSL-KDD is 125,972 and the number of test instances is 22,544. We removed
the categorical features Protocol type, Service, Flag, Diﬃculty level, because Jas-
mine is based on numerical techniques. Moreover, since Jasmine expects binary
output labels, all attack types obtained value 1 (the malicious class), while the
normal type obtained value 0 (the benign class). 46.5% of the train instances
are malicious, while 56.9% are malicious in the test set.

5.1.2. NSL-KDD-rand

Besides considering the NSL-KDD data as provided by Tavallaee et al., we
also considered the dataset we call NSL-KDD-rand. We constructed this set by
combining the train and test set of the NSL-KDD dataset. Now, 48.1% of all
observations are malicious. During the experiments, each time a new train and
test set were chosen. These new sets are expected to have the same underlying
distribution, in contrast to the provided train and test set of the NSL-KDD
data.
It is interesting to see how the considered AL methods performed on
diﬀerently structured data.

5.1.3. UNSW-NB15

The UNSW-NB15 dataset was constructed by Moustafa et al. in 2015 [30],
partially to address some problems of the NSL-KDD data. The authors used the
so-called IXIA PerfectStorm tool to generate a mix of realistic modern benign
network behaviors and synthetic malicious connections. The dataset contains
2,540,047 observations with each connection consisting of a 47-dimensional fea-
ture vector and two output attributes. The ﬁrst output is the speciﬁc attack
type and the second is a binary value indicating whether the observation is be-
nign (0) or malicious (1). Nine attack types are present in the dataset, but we
only used the second output attribute, since Jasmine expects a binary output
label. We reduced the number of predictive features from 47 to 36 by removing
srcip, sport, dstip, dsport, proto, state, service, stcpb, dtcpb, Stime and Ltime,
because they directly determine the output label, are categorical or have no
predictive use. Furthermore, there are several missing values in UNSW-NB15
which we chose from context to be 0. Finally, 12.6% of the observations corre-
spond to attacks. This lower fraction of malicious traﬃc is one of the reasons
why this dataset is closer to reality than the NSL-KDD data. Another reason
is that this data does contain modern attack styles and modern benign traﬃc
behavior. More information about UNSW-NB15 is given by Moustafa et al. [30].

5.2. Experiments

5.2.1. Query functions

We considered several query functions in the experiments. First of all, we
regarded Jasmine with its characteristic α-dynamic query function ψJas (as de-
scribed in Section 4.5) as the main focus of this research (jas.main). Further-
more, we also examined some simpler query functions for the Jasmine procedure:
only querying anomalies (jas.anom), only querying uncertainties (jas.uncert), and
only querying random observations (jas.rand). Note that for these three query

17

functions α-dynamic updating is not involved, meaning that the corresponding
procedures are incomplete versions of Jasmine. It is interesting to see what the
results were for only querying one speciﬁc type of query observations compared
to querying a mix of them. Naturally, we also considered the full ALADIN pro-
cedure of Stokes et al. (ala.main), just as the incomplete Jasmine procedure with
ALADIN’s query function of querying anomalies and uncertainties in a ﬁxed
50/50 split (jas.basic). Consequently, we executed six diﬀerent AL methods.

5.2.2. Global parameters

The global parameters are the variables deﬁned before any computation took
place. These include the initial size of the labeled set L(0), the initial size of the
unlabeled set U (0), the size of the evaluation set E and the query set size Q.
Moreover, N is the maximum number of observations that were to be queried
to the human expert during the process. Since the goal of AL is to label as
few observations as possible, we were not interested in querying every unlabeled
observation. Together with Q, the parameter N determines the total number
of iterations: T := (cid:98)N/Q(cid:99). Finally, since Jasmine is an inherently stochastic
procedure, we repeated the experiments S times. This was done to analyze how
our method behaved on average and in what range its performances resided.
Note that, for each repetition, the sets L(0) and U(0) were newly constructed.
For the NSL-KDD-rand and UNSW-NB15 datasets, the evaluation set E was
also freshly sampled. This was not necessary for the NSL-KDD data, since E is
a provided ﬁxed set.

The values chosen for the global parameters for the experiments are pre-
sented in Table 1 and 2. As the tables show, two diﬀerent initial labeled data
set sizes were considered, because we were interested in how L(0) inﬂuenced
the performance of the AL methods. Furthermore, we chose Q to be 40, as
we deemed this a good balance between allowing for the query fractions to
update not too erratically (needing Q to be large) and allowing for relatively
small updates to the classiﬁer (needing Q to be small). Also, we chose N to
be 15,000 because we saw from exploratory studies that the models do not
drastically change anymore when more labels were provided. Finally, for the
NSL-KDD-rand and UNSW-NB15 datasets, we chose E to be 5,000, to obtain a
representative test set without using too many observations only for evaluation.

Table 1: Values for global parameters on NSL-KDD

L(0)
125
250

U (0)
125,848
125,723

E
22,544
22,544

Q
40
40

N
15,000
15,000

S
30
30

5.2.3. Hyperparameter tuning GBM

As mentioned in Section 4.2, good values for the GBM were found by tuning
on the initially labeled set L(0) with k-fold cross validation. We used the study

18

Table 2: Values for global parameters on NSL-KDD-rand and UNSW-NB15

L(0)
125
250

U (0)
146,392
146,267

E
5,000
5,000

Q
40
40

N
15,000
15,000

S
30
30

by Tama et al. [31] and exploratory research to determine which hyperparam-
eters to tune and over what range to tune them. The parameters that were
not selected for tuning obtained their default settings as given by the h2o.gbm
function of the H2O.ai package, which we used in the R programming language.
The values or tuning ranges of the parameters are shown in Table 3. Since
the number of possible hyperparameter combinations is large (more than 177
thousand), tuning was performed using a random search over all combinations
for a maximum of 4 hours. The combination with the best trade-oﬀ between
performance metric and computation time was chosen. We considered the F1
score as the performance metric and we chose the threshold ε to be 10−4.

Table 3: Tuning ranges for hyperparameters in h2o.gbm (csr = ‘col sample rate’)

distribution
Bernoulli
max depth
{6, 12, 24}
nbins
{10, 16, 25}
min rows
{6, 8, 10}

histogram type
RoundRobin
sample rate
{0.60, 0.78, 1.0}
nbins cats
{16, 32, 64}
csr
{0.84, 0.92, 1.0}
csr per tree
{0.40, 0.64, 1.0}

learn rate annealing
{0.95, 0.99, 0.999}
ntrees
{250, 500, 1,000}
learn rate
{0.02, 0.05, 0.125}
csr change per level
{0.94, 1.0, 1.06}

Table 4: Tuning ranges for Jasmine parameters

α(0)
a
(cid:8) 1
2 , 3
4 , 1

4

(cid:9)

β
2 , 1, 2(cid:9)
(cid:8) 1

γ
2 , 1, 2(cid:9)
(cid:8) 1

(cid:8) 1
800 , 1

τ
400 , 1

200 , 1

100

(cid:9)

SJ
4

5.2.4. Jasmine tuning

The relevant hyperparameters for the Jasmine tuning phase, as we described
in Section 4.8, are the initial anomaly query fraction α(0)
a , the FN weight factor
β, the update magnitude γ and the decrease speed in querying random instances
τ . The ranges that the parameters were tuned over are shown in Table 4,
yielding 108 possible combinations. We chose the ranges for α(0)
a , β and γ

19

to be symmetric around the ‘unity value’. For α(0)
2 , since then the
initial number of anomalous observations was equal to the number of uncertain
instances. For β, this is 1, because then the FNs and FPs were weighed equally.
For γ, this is also 1, since then ∆(γ)(t) reduced to the linear diﬀerence ∆(t).

a , this is 1

During Jasmine tuning, we wanted to choose QJ as close to Q as possible,
but also perform at least three iterations. Hence, we deﬁned the tuning query
size as QJ := min{UJ (0)/4, Q}. The initially unlabeled set size was divided by
4 (= 3 + 1), since the last iteration was not performed. This is because we deem
the last unlabeled observations the least informative. Each Jasmine parameter
combination j yielded a performance metric for every time step. This produced
the sequence {pj(t)}{t=0,...,TJ −1}. Again, this metric was the F1 score. After the
iterations were performed, the area underneath the (t, pj(t)){t=0,...,TJ −1}-‘curve’
was calculated. This is an example of a learning curve, which is commonly used
in the AL paradigm to assess the quality of a method [8, 9]. The larger this
area, the better parameter combination j is. As there is stochasticity in the
techniques used in Jasmine, the tuning phase was repeated SJ times. The
combination with the largest average area was chosen as the hyperparameter
setting for Jasmine in the actual AL procedure. Note that the Jasmine-speciﬁc
parameters were tuned on L(0), and so, Jasmine did not get an unfair advantage
by seeing more data in advance than the other AL methods, which did not need
to execute Jasmine tuning.

5.2.5. Evaluation of AL methods

To evaluate the six diﬀerent AL methods, we utilized the evaluation set E
that was set aside each simulation. The quality of the predictions of an AL
method on E was determined by the performance metric p(t) (in this case the
F1 score) for every iteration t. After some reference value tref of iterations were
performed (0 ≤ tref ≤ T ), a sequence of performance metrics {p(t)}{t=0,...,tref}
was obtained. Similar to Jasmine tuning, we took the area A(tref) underneath
the (t, p(t)){t=0,...,tref}-learning curve as a measure of performance. Brieﬂy said,
the higher A(tref), the better the method is up to the iteration step tref. How-
ever, since there is stochasticity involved, we repeated each complete AL pro-
cedure S times. During simulation s, L(0) and U(0) were randomly chosen (for
NSL-KDD-rand and UNSW-NB15 also E was randomly sampled) and all six
procedures were provided the same initial sets. Consequently, this led to the
vector (A(1)
s (tref)) of paired area metrics. Next, we statistically
compared the area metrics of the Jasmine α-dynamic method with the metrics
of the other methods. This was done by the Wilcoxon signed-rank test (with
signiﬁcance threshold of 0.05) to determine whether

s (tref), . . . , A(6)

H (m)
0

(tref) : median
s=1,...,S

(cid:110)

A(1)

s (tref)

(cid:111)

< median
s=1,...,S

(cid:110)

A(m)
s

(cid:111)

(tref)

(10)

could be rejected for method m = 2, . . . , 6. When this was the case, then
α-dynamic querying performed signiﬁcantly better than the other considered
query functions and AL techniques.

20

6. Results

In this section, the results of our research are presented. They were obtained
by performing the steps explained in Section 5 on the NSL-KDD, NSL-KDD-
rand and UNSW-NB15 data. First of all, the learning curve of F1 scores is
shown for each of the six AL methods that we considered. This curve gives an
insight in how well the classiﬁer of a speciﬁc method performed on the evaluation
set throughout the AL process. Secondly, the p-values of the Wilcoxon signed-
rank test are presented for predetermined speciﬁc iteration steps. Thirdly, the
dynamics of the query fractions αa(·), αz(·) and αr(·) are shown to illustrate
how Jasmine adjusted the balance between querying anomalous, uncertain and
random observations. Finally, we discuss the implications of these results per
dataset.

6.1. Results on NSL-KDD

6.1.1. Learning curves

(a) L(0) = 125

(b) L(0) = 250

Figure 4: Learning curves on NSL-KDD-E for diﬀerent initial sizes L(0).

Figure 4 shows the average learning curves for each of the six AL methods
on the ﬁxed evaluation set NSL-KDD-E for initially labeled set sizes L(0) = 125

21

and L(0) = 250. Each simulation yielded a learning curve, hence we took the
average of the curves over all simulations. The blue dashed line (jas.ﬁn) is the
average ﬁnal performance on E of the GBM trained on the complete train set
with all labels available. This performance metric was F1 ≈ 0.760 for Figure 4a
and F1 ≈ 0.759 for Figure 4b. The value of the line is approximately the same
for both plots, because the evaluation set E is ﬁxed and independent of L(0).
However, each GBM was tuned diﬀerently, leading to small diﬀerences. Since
all labels of the NSL-KDD dataset are technically available, we included the
ﬁnal performance to show how quickly the Jasmine-based AL methods reached
this value. The purple dashed line (ala.ﬁn) is the ﬁnal performance on E of
the logistic regression classiﬁer of the ALADIN procedure (F1 ≈ 0.720). This
ﬁnal performance was constant during the simulations and for both settings of
L(0), since the classiﬁer of ALADIN is deterministic. Finally, the gray dashed
line (coin 1) is the expected performance on E (F1 ≈ 0.725) of the best dummy
classiﬁer, which classiﬁes each evaluation observation as malicious.

6.1.2. Statistical tests

Table 5: p-values Wilcoxon test jas.main vs. . . . with L(0) = 125

tref L(tref)
9
16
22
34
47
122
247
372

485
765
1005
1485
2005
5005
10005
15005

jas.basic
0.992
0.991
0.975
0.855
0.786
0.0131
3.46 · 10−6
7.10 · 10−7

jas.rand
0.000172
1.52 · 10−5
5.96 · 10−7
5.00 · 10−7
5.00 · 10−7
2.99 · 10−6
3.96 · 10−5
0.000190

jas.anom
1.00
1.00
1.00
0.971
0.388
1.28 · 10−7
1.86 · 10−9
1.86 · 10−9

jas.uncert
0.0155
0.0249
0.00983
0.000729
0.000932
0.131
0.908
0.975

ala.main
0.894
0.381
0.0571
0.000128
4.99 · 10−7
1.30 · 10−8
1.57 · 10−7
2.86 · 10−7

Table 6: p-values Wilcoxon test jas.main vs. . . . with L(0) = 250

tref L(tref)
9
16
22
34
47
122
247
372

610
890
1130
1610
2130
5130
10130
15130

jas.basic
0.924
0.958
0.963
0.915
0.897
0.122
9.43 · 10−5
1.89 · 10−6

jas.rand
0.000128
2.57 · 10−6
4.99 · 10−7
1.28 · 10−7
1.02 · 10−7
4.00 · 10−8
4.16 · 10−7
1.90 · 10−6

jas.anom
0.994
1.00
1.00
0.999
0.967
0.00233
8.20 · 10−8
2.79 · 10−9

jas.uncert
0.0790
0.118
0.122
0.388
0.556
0.997
1.00
1.00

ala.main
0.516
0.0502
0.00530
3.14 · 10−5
1.38 · 10−6
9.31 · 10−9
8.20 · 10−8
1.62 · 10−6

To determine whether Jasmine performed signiﬁcantly better than the other
ﬁve AL methods, we determined the p-value of the test in (10) for each method

22

m = 2, . . . , 6 and for diﬀerent values of tref. Table 5 and 6 show the results
for the experiments with L(0) = 125 and L(0) = 250, respectively. A green
value indicates that Jasmine (jas.main) performed signiﬁcantly better than the
method in the corresponding column for the labeled set size L(tref). A red value,
however, means that Jasmine performed signiﬁcantly worse (by interchanging
the sides of (10)). A black value means that the test was indecisive and could
not conclude whether Jasmine was better or worse.

6.1.3. α-dynamic updating

(a) L(0) = 125

(b) L(0) = 250

Figure 5: Progress of query fractions for diﬀerent initial sizes.

Finally, Figure 5 presents the α-dynamic updating procedure of Jasmine for
L(0) = 125 and L(0) = 250. Similar to the ﬁgure with the learning curves, every
simulation resulted in a α-dynamic curve for each of the query fractions αa(·)
(a.anom), αz(·) (a.uncert) and αr(·) (a.rand). We took the average of the query
fractions to obtain the average α-dynamic curves. A shaded region indicates
the interval in which 80% of the observed fractions with matching color resided,
and therefore, shows the spread of the values. Since S = 30 simulations were
performed, each region contains the 24 ‘middle’ fraction values.

6.1.4. Implication of Results on NSL-KDD

The ﬁrst thing that we observe in Figure 4 is that the average F1 score rapidly
increased in the ﬁrst iterations for the Jasmine (jas.main), jas.anom, jas.uncert
and jas.basic procedures. This means that by using the corresponding query
approaches, valuable unlabeled observations were queried to the oracle, because
the GBMs were able to make better predictions on the evaluation set NSL-KDD-
E. This increase is most notable for jas.anom and then especially for L(0) = 250.
This makes sense, because NSL-KDD-E contains new anomalous attack scenar-
ios that are not found in the train set. Remarkably, the performance of jas.anom
went higher than the ﬁnal (average) F1 score. For several iteration steps, also
the other three methods obtained scores higher than the ﬁnal performance for
both settings of L(0). This means that a carefully constructed smaller dataset
led to better predictions on the evaluation set than the complete train set did.
Even though jas.anom performed better than the other methods at the start
of the iterations, its eﬀectiveness decreased when more anomalous observations

23

were added to the labeled set. The decrease of eﬀectiveness is also visible in
Table 5 and 6: for small values of tref querying only anomalies performed better
than Jasmine, but later Jasmine obtained signiﬁcantly better results. It could
be that the labeled set became more and more abnormal when more anomalous
observations were added, resulting in impaired training of the GBM classiﬁer in
later iterations after it had improved before.

Furthermore, it is clear that Jasmine performed better than only querying
uncertainties, as the p-values show.
It appears that also querying anomalies
is important. However, when time progresses, its performance is not signiﬁ-
cantly better anymore and eventually becomes signiﬁcantly worse. It should be
stressed, though, that the learning curves show that both jas.main and jas.uncert
have converged to the ﬁnal score and only diﬀer a little.

Only querying random observations, as done by jas.rand, performed signiﬁ-
cantly worse than Jasmine for all reference iterations. This shows that specif-
ically choosing anomalous or uncertain observations works better than only
querying random observations.

Also interesting to note is that Jasmine was on par with or worse than jas.basic
at the start of the iteration procedure. However, when the size of L(·) grew,
Jasmine became signiﬁcantly better, as the p-values in both Table 5 and 6 show.
This means that dynamically adjusting the query balance in a later stadium has
an advantage over querying anomalies and uncertainties in a ﬁxed 50/50 fashion.
Combining this with the progress of the query fractions in Figure 5 and with the
fact that jas.anom’s performance worsens over time shows that Jasmine found
the right balance between querying uncertainties and anomalies. Nonetheless,
since anomalies appeared to be better at the start, it is curious why Jasmine
did not query more anomalies in that stage. Hence, the information metrics
as deﬁned in (4) and (5) could have a preference for uncertain over anomalous
observations.

Lastly, Jasmine performed fairly quickly signiﬁcantly better than ALADIN
as the p-values show. This is partly due to the simpler ML techniques in the
latter, as it took Jasmine less eﬀort to obtain better results than ALADIN than
it took to perform better than jas.basic.

In general, there do not seem to be large diﬀerences between the experiments
with L(0) = 125 and with L(0) = 250. However, the α-dynamic curves in Fig-
ure 5 show that the average initial random query fraction αr(0) was noticeably
bigger for L(0) = 125 than for L(0) = 250, since the brown curve (a.rand) starts
higher in the former. This makes sense, because L(0) was randomly constructed,
and hence, it became less essential to query random instances when we chose
L(0) larger.

6.2. Results on NSL-KDD-rand

6.2.1. Learning curves

Similar to the results presented in Section 6.1, Figure 6 presents the average
learning curves for each of the six AL methods and two constant reference lines.
In contrast to the results on the NSL-KDD dataset, the evaluation set E was

24

(a) L(0) = 125

Figure 6: Learning curves on NSL-KDD with random evaluation set for diﬀerent L(0).

(b) L(0) = 250

chosen anew for each simulation. More speciﬁcally, at the start of each repetition
the complete NSL-KDD-rand dataset was randomly partitioned in L(0), U(0)
and E. The blue dashed line (jas.ﬁn) is the average ﬁnal performance of the
simulation-speciﬁc GBMs on their corresponding evaluation sets. This metric
was F1 ≈ 0.994 for Figure 6a and F1 ≈ 0.995 for Figure 6b. This time, the
average ﬁnal performance of ALADIN represented by the purple dashed line
(ala.ﬁn) was no longer necessarily constant, but F1 ≈ 0.918 for initial set size
L(0) = 125 and F1 ≈ 0.917 for L(0) = 250. Lastly, the expected performance
of the best dummy classiﬁer is not visible in the ﬁgures, since it was F1 ≈ 0.650
for L(0) = 125 and F1 ≈ 0.651 for L(0) = 250.

6.2.2. Statistical tests

Table 7 and 8 show the p-values of the Wilcoxon signed-rank test with null

hypothesis as given in (10) for diﬀerent values of tref.

6.2.3. α-dynamic updating

The dynamics of the α-updating procedure of Jasmine are shown in Figure 7
for L(0) = 125 and L(0) = 250. As described before, the curves represent

25

Table 7: p-values Wilcoxon test jas.main vs. . . . with L(0) = 125

tref L(tref)
9
16
22
34
47
122
247
372

485
765
1005
1485
2005
5005
10005
15005

jas.basic
0.798
0.886
0.904
0.894
0.831
0.492
0.428
0.365

jas.rand
0.000365
5.96 · 10−7
1.30 · 10−8
9.31 · 10−10
9.31 · 10−10
9.31 · 10−10
9.31 · 10−10
9.31 · 10−10

jas.anom
0.0192
0.000333
1.52 · 10−5
8.20 · 10−8
9.31 · 10−10
9.31 · 10−10
9.31 · 10−10
9.31 · 10−10

jas.uncert
0.657
0.657
0.642
0.672
0.708
0.836
0.846
0.841

ala.main
5.96 · 10−7
1.86 · 10−9
1.86 · 10−9
9.31 · 10−10
9.31 · 10−10
9.31 · 10−10
9.31 · 10−10
9.31 · 10−10

Table 8: p-values Wilcoxon test jas.main vs. . . . with L(0) = 250

tref L(tref)
9
16
22
34
47
122
247
372

610
890
1130
1610
2130
5130
10130
15130

jas.basic
0.970
0.985
0.975
0.963
0.945
0.635
0.444
0.444

jas.rand
4.16 · 10−7
1.28 · 10−7
1.77 · 10−8
9.31 · 10−10
9.31 · 10−10
9.31 · 10−10
9.31 · 10−10
9.31 · 10−10

jas.anom
0.313
0.0261
8.59 · 10−4
5.96 · 10−7
9.31 · 10−10
9.31 · 10−10
9.31 · 10−10
9.31 · 10−10

jas.uncert
0.930
0.701
0.548
0.516
0.564
0.650
0.687
0.650

ala.main
2.79 · 10−9
1.86 · 10−9
9.31 · 10−10
9.31 · 10−10
9.31 · 10−10
9.31 · 10−10
9.31 · 10−10
9.31 · 10−10

(a) L(0) = 125

(b) L(0) = 250

Figure 7: Progress of query fractions for diﬀerent initial sizes.

the average query fractions αa(·) (a.anom), αz(·) (a.uncert) and αr(·) (a.rand)
throughout the iteration process.

6.2.4. Implication of Results on NSL-KDD-rand

At ﬁrst glance, the results on the randomly selected evaluation sets of NSL-
KDD-rand are much better for every considered AL method. This seems rea-
sonable, because the ﬁxed evaluation set for the NSL-KDD data contains unseen
cyberattacks on which the classiﬁer could not train. In the case of NSL-KDD-

26

rand, the evaluation set was randomly chosen from the complete dataset, so we
expected it to have the same structure as the train set, making it easier for the
classiﬁer to learn. This was speciﬁcally the case for the GBM, because it rapidly
obtained an almost perfect F1 score on the evaluation set.

The ﬁgures also show that the three learning curves for Jasmine, jas.basic
and jas.uncert increased in a similar fashion at the start of the procedure. This
was not the case for jas.anom, indicating that it was mostly important to query
uncertain observations. This was also reﬂected in the p-values, as shown by
Table 7 and 8. Jasmine quickly performed signiﬁcantly better than jas.anom,
but it had more diﬃculty in obtaining signiﬁcantly better results than jas.basic
and jas.uncert. The latter was even signiﬁcantly better than Jasmine. However,
it should be noted that the F1 scores were already near perfect for these three
query approaches. Moreover, the dynamics of the query fractions in Figure 7
show that there was a clear preference for querying more uncertainties than
anomalous observations.

Furthermore, the learning curves show that Jasmine obtained better results
than jas.rand and ALADIN. Both Table 7 and 8 indicate that Jasmine was sig-
niﬁcantly better for all considered reference values.

6.3. Results on UNSW-NB15

6.3.1. Learning curves

Figure 8 shows the average learning curves for every one of the six AL
methods and two constant reference lines. The evaluation set E was chosen anew
for each simulation, equivalent to what we discussed in Section 6.2. The blue
dashed line (jas.ﬁn) is the average ﬁnal performance of the simulation-speciﬁc
GBMs on their corresponding evaluation sets. For Figure 8a, this metric was
F1 ≈ 0.974, while it was F1 ≈ 0.973 for Figure 8b. The average ﬁnal performance
of ALADIN indicated by the purple dashed line (ala.ﬁn) was F1 ≈ 0.939 for both
initial set sizes. Lastly, the ﬁgures do no show the expected performance of the
best dummy classiﬁer, since it was F1 ≈ 0.225 for L(0) = 125 and F1 ≈ 0.222 for
L(0) = 250. These remarkably lower baseline values are because relatively far
fewer positive observations are present in UNSW-NB15 compared to NSL-KDD.

6.3.2. Statistical tests

Table 9 and 10 present the p-values of the Wilcoxon signed-rank test with

null hypothesis as given in (10) for diﬀerent values of tref.

6.3.3. α-dynamic updating

Figure 9 shows the α-dynamic updating procedure of Jasmine for L(0) = 125
and L(0) = 250. Equivalent to the results in Section 6.1 and 6.2, the curves
indicate the average query fractions αa(·) (a.anom), αz(·) (a.uncert) and αr(·)
(a.rand) throughout the iteration process.

27

(a) L(0) = 125

Figure 8: Learning curves on UNSW-NB15 with random evaluation set for diﬀerent L(0).

(b) L(0) = 250

Table 9: p-values Wilcoxon test jas.main vs. . . . with L(0) = 125

tref L(tref)
9
16
22
34
47
122
247
372

485
765
1005
1485
2005
5005
10005
15005

jas.basic
0.994
0.990
0.985
0.965
0.918
0.815
0.271
0.122

jas.rand
4.95 · 10−5
1.90 · 10−6
9.96 · 10−7
1.93 · 10−7
4.00 · 10−8
9.31 · 10−9
5.12 · 10−8
1.28 · 10−7

jas.anom
0.0213
3.96 · 10−5
4.00 · 10−6
1.28 · 10−7
6.52 · 10−9
1.86 · 10−9
1.86 · 10−9
1.86 · 10−9

jas.uncert
0.994
0.997
0.992
0.971
0.897
0.612
0.191
0.131

ala.main
0.0701
6.87 · 10−5
3.46 · 10−6
1.30 · 10−8
9.31 · 10−9
2.79 · 10−9
1.86 · 10−9
1.86 · 10−9

6.3.4. Implication of Results on UNSW-NB15

There are no striking diﬀerences between the two plots in Figure 8. However,
it seems that the average learning curves for initial set size L(0) = 125 are a bit
more shaky. Since L(0) is the only diﬀerent global parameter between the two
plots, the change in behavior is presumably due to how the GBM parameters
and Jasmine-speciﬁc parameters were tuned. It probably also had to do with

28

Table 10: p-values Wilcoxon test jas.main vs. . . . with L(0) = 250

tref L(tref)
9
16
22
34
47
122
247
372

610
890
1130
1610
2130
5130
10130
15130

jas.basic
0.715
0.735
0.761
0.650
0.350
0.185
0.0481
0.0275

jas.rand
3.46 · 10−7
5.96 · 10−7
4.16 · 10−7
9.31 · 10−9
2.79 · 10−9
9.31 · 10−10
9.31 · 10−10
9.31 · 10−10

jas.anom
7.99 · 10−6
1.90 · 10−6
2.36 · 10−7
1.77 · 10−8
9.31 · 10−10
9.31 · 10−10
9.31 · 10−10
9.31 · 10−10

jas.uncert
0.989
0.998
0.997
0.998
0.990
0.786
0.306
0.180

ala.main
0.149
0.00128
0.000230
1.52 · 10−5
2.57 · 10−6
9.31 · 10−10
9.31 · 10−10
9.31 · 10−10

(a) L(0) = 125

(b) L(0) = 250

Figure 9: Progress of query fractions for diﬀerent initial size L(0).

the imbalance of this dataset. Approximately 12.6% of the data is related to
cyberattacks, so on average about 16 observations were malicious in L(0). For
tuning purposes, this initial set was split in training, validation and test sets,
making it possible that only one malicious observation ended up in any of those
sets. Consequently, the tuned parameters possibly led to less stable behavior of
the GBM and the α-dynamic update procedure. Figure 9 supports the latter,
since more spikes are apparent in the conﬁdence regions than in the update
curves for the other two datasets. However, this is the case for both initial set
sizes, making it more likely that it is related to the tuning of the GBM. Hence,
balancing techniques of the training data such as under- or oversampling could
be considered to improve stability.

Furthermore, the results for the learning curves in Figure 8 are similar to
those obtained for NSL-KDD-rand. This is also true for the p-values presented
in Table 9 and 10 and the dynamics of the average α-update curves shown in
Figure 9.

7. Discussion

In this ﬁnal section of the paper, we ﬁrstly draw conclusions based on the
implications of the results discussed in Section 6. Secondly, we consider further
directions for AL in the ﬁeld of network intrusion detection.

29

7.1. Conclusion

The goal of this research was to propose our hybrid Active Learning method
Jasmine for network intrusion detection.
It consists of α-dynamic querying,
which means Jasmine is able to dynamically adjust the balance between query-
ing anomalous, uncertain and random observations. Consequently, only the
potentially most interesting observations are presented to the human expert.
This sets our method apart from other AL approaches that have a static query
function. In this paper, we ﬁrstly formulated the mathematical foundation of
Jasmine. Then, we described how the experiments were set up to determine
whether our method achieved good results. The ﬁrst dataset we chose for this
analysis was the commonly used NSL-KDD data. Also, we restructured this
data to obtain the second dataset NSL-KDD-rand with other properties. Addi-
tionally, we also chose the more recent and realistic UNSW-NB15 data.

On all three datasets, Jasmine performed signiﬁcantly better than ALADIN,
the benchmark AL method used in this research. This means for practitioners
that it is beneﬁcial to choose Jasmine over ALADIN for their AL problems.
However, we should note that Jasmine needs preprocessing time, which ALADIN
and other static AL methods do not need. This is because of GBM tuning and
Jasmine tuning.

Furthermore, we observed that Jasmine performed more robustly with re-
spect to the datasets. We compared the characteristic α-dynamic query func-
tion of Jasmine with other query functions: querying only anomalies, only un-
certainties, only random observations and querying anomalous and uncertain
observations in a ﬁxed 50/50 fashion. We noticed that Jasmine did not always
outperform the other approaches, but its performance was less inﬂuenced by
the considered data, and hence, more robust. On the NSL-KDD dataset, only
querying anomalies performed better when the labeling process had just started,
but Jasmine took over in the long run. On the NSL-KDD-rand and UNSW-
NB15 data, only querying uncertainties or querying in a 50/50 fashion reigned
supreme, but Jasmine followed closely. Only querying anomalies was clearly
a bad strategy for these two datasets. These ﬁndings suggest that Jasmine is
better able to adapt to the provided labeled dataset L(·). This is particularly
interesting in the face of concept drift: NIDSs operate in high non-stationary
contexts, which makes it wise to consider an AL method that is able to adjust
its query approach dynamically.

However, there is room for improvement in the way α-dynamic querying
is performed here. The results on NSL-KDD show that at ﬁrst querying more
anomalous than uncertain observations was beneﬁcial, but this was not reﬂected
in the way that the query fractions were updated. The updating procedure seems
to have a bias towards querying uncertainties.

7.2. Future Work

Our ﬁrst suggestion for further research is to reconsider the α-dynamic query
process such that the bias towards selecting uncertain observations is eliminated.
Another suggestion is to add unlabeled observations about which the classi-
ﬁer has a high prediction certainty to the labeled set without asking the oracle

30

for its label. Consequently, the labeled set increases much more during an iter-
ation, while the human expert does not have to label more observations. This
reduces labeling time drastically and possibly leads to better predictions in an
earlier stage of the AL process. Moreover, when more labels become available,
the preprocessing steps can be repeated (in a less extensive version) to allow
for the GBM to better adjust to the changing train set by retuning its hyperpa-
rameters. Also, some Jasmine-speciﬁc parameters could be retuned during the
process.

Our last suggestion is to consider human uncertainty in the AL method,
since it is not always clear whether a connection is benign or malicious. This
can be done by asking the oracle for their conﬁdence in each label that they
provide or by incorporating a general probability.

These suggestions would increase the deployment eﬃciency of Jasmine even
more. Therefore, we would like to apply our method in a practical setting to
see how it performs.

Appendix A.

In this section, we provide the mathematical speciﬁcations about α-dynamic
querying. Before we can give the explicit deﬁnitions of the query fractions for
the next iteration, we have to derive some general restrictions on the values
of the fractions αr(t), αa(t) and αz(t) for all t ∈ {0, . . . , T }, where T denotes
the maximum number of iterations. First, a fundamental requirement of the
fractions is that

αr(t) + αa(t) + αz(t) = 1,

(A.1)

and αr(t), αa(t), αz(t) ∈ [0, 1]. Furthermore, each iteration, we want to query
at least one anomaly and one uncertainty, otherwise (4) or (5) is undeﬁned,
and consequently, ∆γ(t) is undeﬁned. Thus, we need αa(t) and αz(t) to be at
least αmin
a,z := 1/Q. Then, the number of anomalies and uncertainties in Q(t)
is at least Q · αmin
a,z = 1. This means the upper bounds for αa(t) and αz(t)
are restricted to be at most 1 − αmin
a,z . The upper bound for αr(t) is at most
αmax
a,z , since we do allow to query no random observations, and
r
hence, allow αr(t) to go to 0. The deﬁnition of αr(t) is given in (9). Note that
αr(t) ∈ [αmin
:= αr(T ). Now, we can deﬁne the upper
bound for αa(t) and αz(t) as

) ⊂ [0, 1] with αmin

:= 1 − 2αmin

, αmax
r

r

r

a,z (t) := 1 − αr(t) − αmin
αmax
a,z .

Note that this upper bound depends on the iteration number t.

By using (i) αr(t), αa(t), αz(t) ∈ [0, 1], (ii) (A.1), and (iii) the deﬁnitions
a,z , αmin
, we characterize the w variables introduced in

a,z (t) and αmax

, αmax

r

r

of αmin

31

update rules (7) and (8) as follows:

a,z (t) − αa(t)

w(1)
w(2)
w(1)
w(2)

a (t) = αmax
a (t) = αa(t) − αmin
a,z
z (t) = αmax
z (t) = αz(t) − αmin
a,z .

a,z (t) − αz(t)

Let us explain the speciﬁcs of the update of the anomaly fraction αa(·). We
take the old value of αa(t) as a starting point for αa(t + 1). This fraction can
be increased by at most w(1)
a (t) = αmax
a,z (t) − αa(t) to obtain αmax
a,z (t) as the
new value. This increase w(1)
a (t) is scaled down by max{0, ∆γ(t)} such that
the increment is proportional to the value of ∆γ(t). Similarly, αa(t) can be
decreased by at most w(2)
a,z . The decrease
w(2)
a (t) is then scaled down by min{0, ∆γ(t)}. Hence, the constants ensure that
αa(t + 1) lies in the interval Ia,z(t) := [αmin
a,z (t)]. However, it should lie in
a,z , αmax
the interval Ia,z(t + 1) := [αmin
a,z (t + 1)]. This is why we apply the linear
transformation λt+1 : Ia,z(t) → Ia,z(t + 1). This function is given by

a (t) = αa(t) − αmin
a,z

to obtain αmin

a,z , αmax

λt+1(α) =

a,z (t + 1) − αmin
αmax
a,z
a,z (t) − αmin
αmax
a,z

(α − αmin

a,z ) + αmin
a,z .

(A.2)

Note that this function is not well-deﬁned whenever αmax
happens when αr(t) = 1 − αmin
Equation (9) shows that αr(t) is strictly less than αmax
inator in Equation (A.2) cannot be zero and λt+1 is well-deﬁned.

a,z (t) − αmin
a,z = 0. This
. However, the deﬁnition of αr(t) in
, and hence the denom-

a,z = αmax

r

r

Finally, for t ∈ {0, . . . , T − 1}, the systems of equations for the three query

fractions are given by
(cid:40)

αr(0) = αmax
αr(t + 1) = αmax

r

r

· 2−τ ·L(0)

· 2−τ ·(L(0)+Q·(t+1)),

αa(0) = α(0)
a
αa(t + 1) = λt+1

(cid:16)






αa(t) +(αmax

a,z (t) − αa(t)) max{0, ∆γ(t)}
,

a,z ) min{0, ∆γ(t)}

+(αa(t) − αmin

(cid:17)

and

αz(0) = α(0)
z
αz(t + 1) = λt+1

(cid:16)






References

αz(t) +(αmax

a,z (t) − αz(t)) max{0, −∆γ(t)}
(cid:17)
.

a,z ) min{0, −∆γ(t)}

+(αz(t) − αmin

[1] Consultancy.eu, Cost of cybercrime per incident jumps six-fold to e50,000

(2020).

32

URL
cost-of-cybercrime-per-incident-jumps-six-fold-to-50000

https://www.consultancy.eu/news/4409/

[2] S. A. Mouloua, J. Ferraro, M. Mouloua, G. Matthews, R. R. Copeland,
Trend analysis of cyber security research published in hfes proceedings
from 1980 to 2018, in: Proceedings of the Human Factors and Ergonomics
Society Annual Meeting, Vol. 63, SAGE Publications Sage CA: Los Angeles,
CA, 2019, pp. 1600–1604.

[3] R. Sommer, V. Paxson, Outside the closed world: On using machine learn-
ing for network intrusion detection, in: 2010 IEEE symposium on security
and privacy, IEEE, 2010, pp. 305–316.

[4] M. Zamani, M. Movahedi, Machine learning techniques for intrusion detec-

tion, arXiv preprint arXiv:1312.2177 (2013).

[5] N. Sultana, N. Chilamkurti, W. Peng, R. Alhadad, Survey on sdn based net-
work intrusion detection system using machine learning approaches, Peer-
to-Peer Networking and Applications 12 (2) (2019) 493–501.

[6] Y. Xin, L. Kong, Z. Liu, Y. Chen, Y. Li, H. Zhu, M. Gao, H. Hou, C. Wang,
Machine learning and deep learning methods for cybersecurity, IEEE Ac-
cess 6 (2018) 35365–35381.

[7] K. Yang, J. Ren, Y. Zhu, W. Zhang, Active learning for wireless iot intru-

sion detection, IEEE Wireless Communications 25 (6) (2018) 19–25.

[8] B. Settles, Active learning literature survey, Tech. rep., University of

Wisconsin-Madison Department of Computer Sciences (2009).

[9] P. Kumar, A. Gupta, Active learning query strategies for classiﬁcation, re-
gression, and clustering: a survey, Journal of Computer Science and Tech-
nology 35 (4) (2020) 913–945.

[10] Y. Li, L. Guo, An active learning based tcm-knn algorithm for supervised
network intrusion detection, Computers & security 26 (7-8) (2007) 459–467.

[11] J. L. Guerra Torres, C. A. Catania, E. Veas, Active learning approach to
label network traﬃc datasets, Journal of information security and applica-
tions 49 (2019) 102388.

[12] N. G¨ornitz, M. Kloft, K. Rieck, U. Brefeld, Active learning for network
intrusion detection, in: Proceedings of the 2nd ACM workshop on Security
and artiﬁcial intelligence, 2009, pp. 47–54.

[13] L. Yin, H. Wang, W. Fan, Active learning based support vector data de-
scription method for robust novelty detection, Knowledge-Based Systems
153 (2018) 40–52. doi:https://doi.org/10.1016/j.knosys.2018.04.
020.

33

[14] J. W. Stokes, J. Platt, J. Kravis, M. Shilman, Aladin: Active learning of

anomalies to detect intrusions (2008).

[15] D. D. Lewis, W. A. Gale, A sequential algorithm for training text classiﬁers,

in: SIGIR’94, Springer, 1994, pp. 3–12.

[16] D. Pelleg, A. Moore, Active learning for anomaly and rare-category detec-
tion, Advances in neural information processing systems 17 (2004) 1073–
1080.

[17] M. Almgren, E. Jonsson, Using active learning in intrusion detection, in:
Proceedings. 17th IEEE Computer Security Foundations Workshop, 2004.,
IEEE, 2004, pp. 88–98.

[18] S. Stolfo, et al., Kdd cup 1999 dataset, UCI KDD repository. http://kdd.

ics. uci. edu (1999).

[19] J. H. Friedman, Greedy function approximation: a gradient boosting ma-

chine, Annals of statistics (2001) 1189–1232.

[20] A. Natekin, A. Knoll, Gradient boosting machines, a tutorial, Frontiers in

neurorobotics 7 (2013) 21.

[21] J. O. Ogutu, H.-P. Piepho, T. Schulz-Streeck, A comparison of random
forests, boosting and support vector machines for genomic selection, in:
BMC proceedings, Vol. 5, Springer, 2011, p. S11.

[22] R. Caruana, N. Karampatziakis, A. Yessenalina, An empirical evaluation
of supervised learning in high dimensions, in: Proceedings of the 25th
international conference on Machine learning, 2008, pp. 96–103.

[23] F. T. Liu, K. M. Ting, Z.-H. Zhou, Isolation forest, in: 2008 Eighth IEEE
International Conference on Data Mining, IEEE, 2008, pp. 413–422.

[24] F. T. Liu, K. M. Ting, Z.-H. Zhou, Isolation-based anomaly detection, ACM
Transactions on Knowledge Discovery from Data (TKDD) 6 (1) (2012) 1–
39.

[25] M. Claesen, B. De Moor, Hyperparameter search in machine learning, arXiv

preprint arXiv:1502.02127 (2015).

[26] O. Yavanoglu, M. Aydos, A review on cyber security datasets for machine
learning algorithms, in: 2017 IEEE International Conference on Big Data
(Big Data), IEEE, 2017, pp. 2186–2193.

[27] M. A. Ferrag, L. Maglaras, S. Moschoyiannis, H. Janicke, Deep learning for
cyber security intrusion detection: Approaches, datasets, and comparative
study, Journal of Information Security and Applications 50 (2020) 102419.

34

[28] M. Tavallaee, E. Bagheri, W. Lu, A. A. Ghorbani, A detailed analysis
of the kdd cup 99 data set, in: 2009 IEEE symposium on computational
intelligence for security and defense applications, IEEE, 2009, pp. 1–6.

[29] S. J. Stolfo, W. Fan, W. Lee, A. Prodromidis, P. K. Chan, Cost-based mod-
eling for fraud and intrusion detection: Results from the jam project, in:
Proceedings DARPA Information Survivability Conference and Exposition.
DISCEX’00, Vol. 2, IEEE, 2000, pp. 130–144.

[30] N. Moustafa, J. Slay, Unsw-nb15: a comprehensive data set for network
intrusion detection systems (unsw-nb15 network data set), in: 2015 military
communications and information systems conference (MilCIS), IEEE, 2015,
pp. 1–6.

[31] B. A. Tama, K.-H. Rhee, An in-depth experimental study of anomaly detec-
tion using gradient boosted machine, Neural Computing and Applications
31 (4) (2019) 955–965.

35

