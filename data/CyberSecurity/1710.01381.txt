Generalized Colonel Blotto Game
Aidin Ferdowsi1,∗, Anibal Sanjab1,∗, Walid Saad1, and Tamer Bas¸ar2

8
1
0
2

r
a

M
2

]
T
G
.
s
c
[

2
v
1
8
3
1
0
.
0
1
7
1
:
v
i
X
r
a

Abstract— Competitive resource allocation between adver-
sarial decision makers arises in a wide spectrum of real-
world applications such as in communication systems, cyber-
physical systems security, as well as ﬁnancial and political
competition. Hence, developing analytical tools to model and
analyze competitive resource allocation is crucial for devising
optimal allocation strategies and anticipating the potential
outcomes of the competition. To this end, the Colonel Blotto
game is one of the most popular game-theoretic frameworks for
modeling and analyzing such competitive resource allocation
problems. However, in many practical competitive situations,
the Colonel Blotto game does not admit solutions in determin-
istic strategies and, hence, one must rely on analytically complex
mixed-strategies with their associated tractability, applicability,
and practicality challenges. In this regard,
in this paper,
a generalization of the Colonel Blotto game which enables
the derivation of deterministic, practical, and implementable
equilibrium strategies is proposed while accounting for scenar-
ios with heterogeneous battleﬁelds. In addition, the proposed
generalized game factors in the consumed/destroyed resources
in each battleﬁeld, a feature that is not considered in the
classical Blotto game. For this generalized game, the existence of
a Nash equilibrium in pure strategies is shown. Then, closed-
form analytical expressions of the equilibrium strategies are
derived and the outcome of the game is characterized, based
on the number of each player’s resources and each battleﬁeld’s
valuation. The generated results provide invaluable insights on
the outcome of the competition. For example, the results show
that, when both players are fully rational, the more resourceful
player can achieve a better total payoff at the Nash equilibrium,
a result that is not mimicked in the classical Blotto game.

I. INTRODUCTION

Game-theoretic resource allocation models have become
prevalent across a variety of domains such as wireless com-
munications [1] and [2], cyber-physical security [3]–[5], ﬁ-
nancial markets, and political/electoral competitions [6]–[8].
One of the mostly adopted game-theoretic frameworks for
modeling and analyzing such competitive resource allocation
problems is the so-called Colonel Blotto game (CBG) [9].
The CBG captures the competitive interactions between two
players that seek to allocate resources across a set of battle-
ﬁelds. The player who allocates more resources to a certain
battleﬁeld wins it and receives a corresponding valuation.
The fundamental question that each player seeks to answer
in a CBG is how to allocate its resources to maximize the
valuations acquired from the won battleﬁelds. In recent years,

This research was supported by the U.S. National Science Foundation
under Grants OAC-1541105 and CNS-1446621, and by the Army Research
Laboratory under IoBT Cooperative Agreement Number W911NF-17-2-
0196.

1Aidin

Ferdowsi∗, Anibal
Bradley

with Wireless@VT,
Computer
Engineering, Virginia
{aidin,anibals,walids}@vt.edu

Sanjab∗
Department

are
and
Tech, Blacksburg, VA, USA,

and Walid
of

Saad
Electrical

2Tamer Bas¸ar is with the Coordinated Science Laboratory, University of

Illinois at Urbana-Champaign, IL, USA, basar1@illinois.edu

∗The ﬁrst two authors have equally contributed to this paper.

many variants of the CBG have been studied including those
with homogeneous valuations [8], [10], symmetric resources,
multiple players [4], and heterogeneous resources [11]–[13].
This existing body of literature has primarily focused
on analyzing the existence of the equilibrium in a CBG.
For instance, the seminal work in [9] has proven that an
equilibrium in deterministic strategies (i.e. pure-strategies)
of the Blotto game does not exist when the number of
considered battleﬁelds is greater than two. As a result, most
of the literature has henceforth focused on analyzing the
mixed-strategy equilibrium of the CBG, which essentially
corresponds to a multi-variate probability distribution over
the resources to be allocated over each of the battleﬁelds. In
this regard, the works in [9], [12], [13] have studied uniform
marginal distributions of resources on each battleﬁeld.

However, relying on mixed strategies, as has been the case
in all of the CBG literature [8]–[13], presents serious chal-
lenges to the tractability, applicability, and implementability
of the derived solutions in real-world environments. In fact,
deriving such mixed strategies is often overly complex re-
quiring various mathematical simpliﬁcations along the way
for tractability [1]–[4], [14], [15]. Moreover, in terms of
applicability, the optimality of such mixed strategies assumes
that the game is actually played for an inﬁnitely large number
of times [16]. In addition, previous CBG models assume
win-or-lose settings over each battleﬁeld. In other words,
the player that allocates more resources over a battleﬁeld
wins all of its valuation and the other player receives
nothing. However, given that resources are consumed over
a certain battleﬁeld, even when this battleﬁeld is won or
lost, these consumed resources must be accounted for in the
game model. For instance, even when losing a battleﬁeld,
destroying a portion of the resources of the opponent can be
considered a gain for the non-winner.

The main contribution of this paper is therefore to develop
a fundamentally novel generalization of the CBG dubbed
as the Generalized Colonel Blotto Game (GCBG) which
captures the rich and broad settings of the classical CBG,
and, yet enables the derivation of tractable, deterministic,
and practical solutions to the two-player competitive resource
allocation problem while not being limited to studying win-
or-lose settings over each battleﬁeld. To this end, we ﬁrst
introduce the basics of the proposed GCBG and, then, we
compare its features to the classical CBG. Subsequently, we
prove the existence of an equilibrium to the GCBG – a pure-
strategy Nash equilibrium (NE) – and provide a detailed
derivation as well as closed-form analytical expressions of
the pure NE strategies of the GCBG. In addition, using the
derived NE strategies, we prove that when both players are
fully rational, the more resourceful player is able to achieve
an overall payoff that is greater than that of its opponent, and

 
 
 
 
 
 
hence, win the game. In contrast with the classical CBG, in
our proposed GCBG:

• We derive deterministic equilibrium strategies which
are practical, in the sense that the players can derive
exact optimal strategies and do not need to randomize
between possible strategies,

• We characterize low complexity solutions even for a
large number of battleﬁelds with heterogeneous valua-
tions,

• We model realistic applications of competitive resource
allocation problems by taking into consideration partial
winning and losing over a battleﬁeld.

Finally, we provide a numerical example which showcases
the effect of the number of resources of each player on the
NE strategies and outcomes of the GCBG.

II. PROPOSED GENERALIZED COLONEL BLOTTO GAME
A. Classical Colonel Blotto Game

j

,

,

{

{

n

P

N

Rj

{Q

vi}

A standard CBG [9]

n
i=1,
}j∈P ,
is deﬁned by six components: a) the players in the

}j∈P ,

U j
{
set
}
available resource Rj for j

}j∈P
,
a, b
o
{
P

, b) the strategy spaces

, e) the normalized value of each battleﬁeld, vi for i

, c) the
, d) a set of n battleﬁelds,
∈ P
,
N
∈ N
and f) the utility function, U j, for each player. The set of
j, corresponds to the
possible strategies for each player,
different possible distributions of its Rj resources across the
j is deﬁned as
battleﬁelds. Hence,

j for j

∈ P

Q

Q

n

Q
rj

j =

Q

rj
i ≤

Rj, rj

i ≥

0

,

(1)

(

i=1
X

(cid:12)
(cid:12)
(cid:12)
where rj
i is the number of allocated resource units by player
(cid:12)
(cid:12)
j to battleﬁeld i, and rj
j is the vector of these allocated
resources (an allocation strategy of player j) . To this end,
the payoff of player j, for a battleﬁeld i, is deﬁned as:

∈ Q

)

i (rj
uj

i , r−j

i

vi,
vi
2 ,
0,

) = 


i

if rj
if rj
if rj

i > r−j
i = r−j
i < r−j

i

i

,
,
,

(2)

i



where r−j
corresponds to the resources allocated by the
opponent of j to battleﬁeld i. Such resource allocation
strategies are known as pure deterministic strategies since
the allocation is not randomized over the battleﬁelds. The
utility function of each player, U j, over all battleﬁelds in
is deﬁned as:

N

U j(rj, r−j)=

i (rj
uj

i , r−j

i

).

(3)

P

Each player in

aims to choose a resource allocation
strategy that maximizes its payoff over the n battleﬁelds
given the potential resource allocation strategy of its op-
ponent. As such, the pure-strategy NE of the CBG can be
formally deﬁned as follows:
Deﬁnition 1. A strategy proﬁle (rj ∗

, r−j ∗
∈
−j, is a pure-strategy Nash equilibrium of

), such that rj ∗

j and r−j ∗

Q
the CBG if

∈ Q

n

i=1
X

Q

∈ P

For the CBG, it has been proven [9] that for Rb > Ra and
nRa > Rb, there exists no pure-strategy NE. As a result,
for solving the CBG, a common methodology is to explore
mixed strategies based on which each player j
chooses a
probability distribution (or a multi-variate probability density
j to maximize its potential expected payoff.
function) over
However, the reliance on such mixed strategies introduces
high analytical complexity and presents challenges in terms
of the tractability of the derivation of the solutions as well
as to the practicality and applicability of these solutions.
Hence, to enable the derivation of tractable, deterministic,
and practical solutions to the competitive resource allocation
problem, we next propose a generalization of the CBG
dubbed generalized Colonel Blotto game.

j

,

,

{

{

{

{

n

o

P

N

Rj

{Q

˜U j

n
i=1,

A GCBG

}j∈P ,

B. Proposed Generalized Colonel Blotto Game
vi}
}j∈P ,

}j∈P ,
is deﬁned by seven components that include the players,
k
strategy spaces, available resources, battleﬁelds, and valua-
tion of battleﬁelds as is the case in the CBG. However, we
˜U j
deﬁne a new utility function
}j∈P as an approximation to
the utility function of the CBG. This approximation is based
on a continuous differentiable function and an approximation
parameter, k. When k increases, the GCBG will very closely
resemble the CBG. At the limit, when k goes to inﬁnity, the
GCBG converges to the CBG. However, in contrast with the
CBG, the differentiability of the approximate utility function
enables the derivation of deterministic equilibrium strategies.
In this respect, as deﬁned in (2), the payoff from each
battleﬁeld resembles a step function. Hence, we propose an
approximation of this function, ˜uj
, k), referred to
approximation, deﬁned as follows:
hereinafter as k
−
vi
, k) , vi
i , r−j
2
π

i , r−j

˜uj
i (rj

arctan

i (rj

r−j
i

k(rj

i −

(5)

+

)

,

i

i

(cid:16)

(cid:17)

and the utility function of each player ˜U j is the summation
of the k
approximation payoffs from each battleﬁeld. Next,
in Lemma 1, we will show that (5) precisely approximates
uj
i (rj
) as the approximation factor k tends to inﬁnity.
approximation
Fig. 1 provides a number of plots of k
functions for different values of k.

−
i , r−j

−

i

Lemma 1. The payoff from each battleﬁeld i
expressed as follows:
i , r−j

i , r−j

uj
i (rj

˜uj
i (rj

, k).

i

i

) = lim
k→∞

can be

∈ N

(6)

Proof. The limit of the k-approximate payoff when k
can be written as:

→ ∞

lim
k→∞

˜uj
i (rj

i , r−j

i

, k)=


vi
π arctan (+
2 = vi
0 + vi
2 ,
vi
π arctan (

) + vi

∞

) + vi

−∞

i

2 = vj

i > r−j
i , rj
i = r−j
rj
i < r−j
2 = 0, rj

i

i

,
,
.

Therefore, as compared to (2),


i , r−j
i (rj
˜uj

i

lim
k→∞

, k) = uj

i (rj

i , r−j

i

),

(7)

(cid:4)

U j(rj ∗

, r−j ∗

)

U j(rj, r−j ∗

),

≥

rj
∀

j.

∈ Q

(4)

which proves the lemma.

0.5

0.4

0.3

0.2

0.1

0

-10

-8

-6

-4

-2

0

2

4

6

8

10

Fig. 1: k-approximate of the payoff from battleﬁeld 1 for
player a when va

1 = 0.5.

i

i

i

i

i (rj

i (rj

i , r−j

i , r−j

i , r−j
i , r−j

Hence, Lemma 1 provides an approximation for the
payoff from each battleﬁeld. Using ˜uj
, k) instead
of uj
) provides two additional beneﬁts as com-
pared to the CBG: a) the continuity and differentiability of
˜uj
i (rj
, k) helps in deriving pure-strategy NEs, and b)
˜uj
i (rj
, k) captures the notion of partial-win-or-lose by
accounting for resource consumption and losses which is a
practical feature in a GCBG that has not been considered in
the CBG. In fact, in practice, the payoff from each battleﬁeld
must consider the portion of resources destroyed/consumed
following the “battle” between the two players. This means
that the payoff from each battleﬁeld has to capture the loss
due to the resources destroyed in this battleﬁeld, which also
corresponds to a gain for the opponent. The k
approximate
utility function in (5) inherently captures this aspect. Fig.
1 shows the continuous transition from losing to winning
a certain battleﬁeld when using k-approximate payoff func-
tions. Here, we note that the larger k is, the closer the k-
approximation approximates the classical CBG.

−

Now, we deﬁne the k-approximate utility function per
n

player:

˜U j(rj, r−j, k) ,

i (rj
˜uj

i , r−j

i

, k).

(8)

i=1
X
From (5) and (8), and given that arctan is an odd function,
the players’ payoffs from each battleﬁeld can be related
following ˜uj
i , k) = vi, which
results in the following relation between the players’ utility
functions:

, k) + ˜u−j

i (r−j

i , r−j

i (rj

, rj

i

i

˜U j(rj, r−j, k) + ˜U −j(r−j, rj, k) = 1.

(9)

The relation in (9) shows that the GCBG is a constant-
sum game in which the pure-strategy NE is the solution of
the following minimax problem [16]:
V j(k) , 1

˜U j(rj, r−j, k), (10)

V −j(k) , min

r−j ∈Q−j

max
rj ∈Qj

−

where V j(k) is the value of
the GCBG with the k-
approximate utility function for player j. Next, we solve the
minimax problem in (10) and derive the pure-strategy NE of
the GCBG.

III. SOLUTION OF THE GCBG

To solve the minimax problem in (10), we must derive
a which maximizes ˜U a(ra, rb, k) for all possible
ra∗
b. Then, we choose rb∗
rb
b which minimizes
˜U a(ra∗, rb, k) considering the response, ra∗, to any chosen

∈ Q
∈ Q

∈ Q

∈ Q

rb
b. Given the resource limitation of each player, a
limit exists on the chosen allocations as expressed in (1).
First, we prove that this limit is binding, i.e. each player is
always better off spending all their available resources.
i=1 rj
i < Rj
Proposition 1. All the strategies of the form
i = Rj i.e, player j
are dominated by the strategies
P
is better off using all of its available resource.

i=1 rj

n

n

P

1, . . . , ¯rj
n

is by contradiction. Suppose ¯rj =
Proof. The proof
[¯rj
n] is the vector that maximizes ˜U j(rj, r−j, k) such
i=1 ¯rj
i = ¯Rj < Rj. Then, the payoff for player j
that:
choosing strategy ¯rj is:
n

P

˜U j(¯rj, ¯r−j, k) =

vi
π

arctan

k(¯rj

i −

¯r−j
i

)

+

1
2

.

(cid:16)

(cid:17)

i=1
X

Now, considering arbitrarily player a, we deﬁne a new

allocation vector
¯Ra, ¯ra
2 , . . . , ¯ra

˜U a(ρa, ¯rb, k) =

for player a as ρa = [¯ra
n]. Then, the payoff for player a will be:
1 + Ra

arctan

k(¯ra

¯rb
i )

¯Ra

1 + Ra

−

−

−

v1
π

n

i=2
X
v1
π

+

>

vi
π

arctan

(cid:0)
¯rb
i )

k(¯ra

i −

arctan

(cid:0)
k(¯ra

1 −

(cid:1)
+

¯rb
1)

+

n

= ˜U a(¯ra, ¯rb, k),

(cid:0)

i=2
X

(cid:1)

1
2

vi
π

(cid:1)

arctan

k(¯ra

i −

¯rb
i )

+

1
2

(cid:0)

(cid:1)

which contradicts with the assumption ¯rj = [¯rj
maximizes ˜U j(rj, r−j, k).

1, . . . , ¯rj
n]
(cid:4)

i −

∈ N

From Proposition 1, we know that the limit on the total
number of allocated resources is binding. Before character-
izing the solution of the game, we ﬁrst deﬁne the difference
between the allocated resources by each player on each
battleﬁeld i
, zi, and the difference between the total
available resources, D, as follows:
zi = ra

i , D = Ra
rb
In addition, we consider, without loss of generality, that
Rb < Ra, which implies that the available resources of an
arbitrary player b are less than those of its opponent, player
a. We also consider the case in which Ra/n < Rb, which
eliminates the trivial case studied in the CBG, in which, if
Ra > nRb, player a can trivially win the game. Using these
two inequality assumptions on Ra and Rb, the constraint on
D can be expressed as follows:
0 < D < (n

1)Rb.

Rb.

(12)

(11)

−

−

From Proposition 1 and (11), we can write:

n

zi = D.

(13)

i=1
X

Since the utility functions for both players are dependent
on the difference of allocated resources on each battleﬁeld,
zi, hereinafter, we use ˜U a(z, k) and ˜U a(ra, rb, k) inter-
changeably, where z = [z1, . . . , zn]. In what follows, we
fully characterize the pure-strategy NE for the GCB game.
First, we focus on solving the maximization component
of the minimax problem in (10). In this regard, Theorem 1

characterizes the local maxima of ˜U a(ra, rb, k). Here, with-
out loss of generality, we assume that the battleﬁelds are
indexed based on an increasing order of their value, i.e.
vn with one of these inequalities being
v1 ≥
strict to avoid solving a trivial case in which all battleﬁelds
are identical.
Theorem 1. A local maximum z∗ = [z∗
with respect to z, is a solution to the following equation:

v2 ≥ · · · ≥

n] of ˜U a(z, k)

1 , . . . , z∗

z∗
i + zn = D,

(14)

n−1

i=1
X

where
z∗
i =

1
k2vn

(k2z2

nvi + vi −

vn), for i

,

(15)

∈ M

r
and zn > 0.
Proof. Based on Proposition 1, zn can be expressed as zn =
n−1
i=1 zi, and player a’s utility function will be:
D

−

P

˜U a(z, k) =

n−1

vi
π

arctan(kzi)

n−1

i=1
X
vn
π

+

arctan

k(D

−

n

+

vi
2

zi)

!

.

(16)

i=1
X

Hence,

i=1
X
to ﬁnd the local maxima of player a’s utility
function, from the ﬁrst order necessary condition of op-
if z∗ is a local maximizer and
timality, we know that,
˜U a(z∗, k) = 0.
˜U a is continuously differentiable, then
Therefore, for i
=
0, and, hence:

, we must have ∂ ˜U a(z,k)

N \ {

∈ M

∇

∂zi

,

n

}

1
π

kvi
k2z2
i + 1 −

1
π

k2(D

kvn
n−1
l=1 zl)2 + 1
kvn
n + 1

k2z2

−
kvi
P
k2z2
i + 1 −

= 0,

= 0.

(17)

where

Thus, z∗

i must be one of two solutions:

z∗
i =

±

1
k2vn

(k2z2

r
which, from (13), must meet

nvi + vi −
n−1
i=1 z∗

vn), i

,

∈ M

(18)

i + zn = D.

Next, from the second order necessary conditions of
P
optimality, we know that, if z∗ is a local maximizer of
2 ˜U a(z∗, k), must be
˜U a(z, k), then the Hessian matrix,
negative deﬁnite. The second order derivatives, and elements
of the Hessian matrix, are calculated as follows:

∇

2k3vn(D

n−1
l=1 zl)
−
n−1
l=1 zl)2+1)2
P
−
2k3vnzn
P
n + 1)2 ,

(k2(D
1
π

(19)

∂2 ˜U a(z, k)
∂z2
i

1
π

=

−

2k3vizi

(k2z2

i +1)2 −

1
π

2k3vizi

1
π

=

−

i + 1)2 −
2k3vn(D

(k2z2
1
π

(k2(D

(k2z2
n−1
l=1 zl)
−
n−1
l=1 zl)2 + 1)2

P

−

1
π

−

−
2k3vnzn
P
n + 1)2 .

(k2z2

∂2 ˜U a(z, k)
∂zi∂zm

=

=

From (17), we have:

k2z2
k2z∗2

n + 1
i + 1

=

vn
vi

.

(21)

Plugging (21) in the expressions of the elements of the

Hessian matrix yields:

∂2 ˜U a(z, k)
∂z2
i
∂2 ˜U a(z, k)
∂zi∂zm

z=z∗ =

−

z=z∗ =

−

2k3vn

π(k2z2

n + 1)2 (

vn
vi

z∗
i + zn),

(22)

2k3vn

π(k2z2

n + 1)2 zn.

(23)

Then, the Hessian matrix at z∗ is expressed as:

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

H =

2 ˜U a(z∗, k) =

∇

2k3vn

−

π(k2z2

n + 1)2

H 1,

(24)

where

H 1= 






1+zn

vn

v1 z∗
zn
...
zn

vn

zn
v2 z∗
2 +zn
...
zn

· · ·

· · ·
. . .

zn
...
...
vn−1 z∗
n−1+zn



.






(25)
For z∗ to be a local maximum, H must be negative
deﬁnite and, hence, H 1 must be positive deﬁnite. Performing
row operations on H 1, we obtain an upper-triangular matrix:

· · ·

vn

H 2 =

z∗
1

0
...
...
0












0

z∗
2
. . .

· · ·
. . .
. . .
. . .

· · ·

· · ·

−

0
...
0

z∗
n−2 −
0

z∗
n−1
...
...
z∗
n−1
ξ












,

(26)

ξ =

vn
vn−1

z∗
n−1

1 +

vizn
vnz∗

i !

.

(27)

n−1

i=1
X

H 1 is positive deﬁnite if and only if its pivots (i.e. its
diagonal elements) are all positive since the number of
positive pivots of H 2 is equal to the number of positive
eigenvalues of H 1 [17]. Hence, by inspecting the diagonal
elements of H 2 in (26), for H 1 to be positive deﬁnite,
z∗
. Combining
i must be positive for i
this result with (18), we obtain the expressions in (15) for
i

∈ M \ {
Next, we investigate the sign of ξ in (27) which must
also be positive for H 1 to be positive deﬁnite. Knowing that
, we investigate four different
zi > 0 for i
}
cases regarding the signs of z∗
n−1 and zn and their effect on
the sign of ξ. We prove that zn > 0 and z∗
n−1 > 0 as deﬁned
in (15) is the only case that leads to a positive deﬁnite H 1
and, as a result, a negative deﬁnite H.

∈ M \ {

∈ M \ {

−

−

−

n

n

n

1

1

}

}

1

.

Case 1. z∗

n−1 < 0, and zn < 0: If zn−1 < 0 and zn < 0,
1) element of H 1 in (25) is negative.
then the (n
In addition, for a matrix to be positive deﬁnite, none of its
diagonal elements can be negative [17]. As such, if zn−1 < 0,

1, n

−

−

(20)

 
 
and zn < 0, then H 1 is not positive deﬁnite and hence H
is not negative deﬁnite.

Case 2. z∗
vn−1 z∗

ξ = vn

n−1 < 0, and zn > 0: We rewrite ξ in (27) as

n−1φ, where for z∗

n−1 < 0 and zn > 0,

vizn
vi
z2
n
vn
vn−1zn
q
vn−1
vn

+ vi−vn
k2vn

+ vn−1−vn
k2vn

vizn

φ = 1 +

n−2

vn

i=1
X

−

= 1 +

z2
n

vn
n−2

q

vnzn

i=1
X

−

vnzn

1 + vi−vn
k2viz2
n

vi
vn
vn−1zn
q
q
1 + vn−1−vn
vn−1
k2vn−1z2
vn
n

(28)

·

|

|

αǫ

< 1 and

q
<< 1, let ǫi = (vi −

q
Based on the binomial approximation, (1 + ǫ)α
ǫ

1 + αǫ
if
n).
|
i.e., when k is a large
For practical k-approximations,
number (k >> 0), ǫi meets the conditions of the binomial
. As
approximation and is such that ǫi ≈
such, let ǫi = ǫ for all i

ǫj for all i, j
, φ can be approximated as:

≈
vn)/(k2viz2

∈ M

|

∈ M

1 +

φ

≈

√vi

√vn(1 + ǫ/2) −

√vn−1
√vn(1 + ǫ/2)

.

(29)

n−2

i=1
X

Hence, since vi > vn−1 for i < n

1 we obtain φ > 0

−
H1 is not positive deﬁnite

ξ < 0
deﬁnite; for any practically large approximation index k.

⇒
H is not negative

⇔

n−1 > 0, and zn < 0: We express ξ as ξ =

⇒
Case 3. z∗
vn

vn−1 z∗

n−1Ξ, where

n−1

Ξ = 1 +

i=1
X

vi
vn

zn

z2
nvi/vn + (vi −

vn)/(k2vn)

.

(30)

Since z∗

p

n−1 > 0, the sign of ξ is the same as the sign of
Ξ. By taking the ﬁrst derivative of Ξ with respect to k, we
∂k < 0, since zn < 0 and z∗
can see that ∂Ξ
and vi > vn for all i
∈ M
Knowing that k > 0, the upper bound of Ξ, ¯Ξ, is then

∈ M
. Hence Ξ is decreasing in k.

i > 0 for all i

¯Ξ = lim
k→0

Ξ = 1 + k

Hence, ξ is negative when

n−1

i=1
X

vizn
vn(vi −

vn) ·

p

K >

1
−
vizn
√vn(vi−vn)

·

n−1
i=1

(31)

(32)

P

Here, we note that vn has the same order of magnitude as
vn). Hence, for a practical approximation index,
vn(vi −
k >> 0, the condition in (32) always holds true. Thus, this
p
implies that H1 is not positive deﬁnite and, hence, H is not
negative deﬁnite for any practically large k.

Case 4. z∗

n−1 > 0, and zn > 0: For this case, ξ > 0,
hence, H 1 is positive deﬁnite and as a result H is negative
deﬁnite. Hence, only for z∗
n−1 > 0, and zn > 0, H is
positive deﬁnite.

Therefore, the solutions z∗ proposed in (15) and meet-
ing (14) such that zn > 0, are the only possible local maxima
of ˜U a(z, k).
(cid:4)

In Theorem 1, we identiﬁed the local maxima of ˜U a(z, k)
as given in (15) and meeting zn > 0. We also proved that
these solutions must satisfy (14). Next, we study the equality
constraint in (14) which must be met. To this end, we let

n−1

fk(zn) , zn +

i=1 r
X

1
k2vn

(k2z2

nvi + vi −

vn) = D. (33)

fk(zn) is a strictly convex function with a negative mini-

mizing zn as stated in Proposition 2.
Proposition 2. fk(zn) is a strictly convex function whose
minimum occurs at a negative zn.

i=1
X

Proof. To prove the convexity of fk(zn), we compute its
second derivative with respect to zn.
nvi + vi −
(k2z2

k2z2

(34)

z2
n

n−1

d2f
dz2
n

vi
vn
−
vn)]3/2
(cid:1)

1
k2vn
[ 1
(cid:0)
k2vn

vn
nvi + vi −

=

.

2
f
dz2
n

By inspecting the numerator of each term in d

2
f
, every
dz2
n
vn)(k2vn) which is
numerator can be reduced to (vi −
positive. Hence, d
is a summation of positive terms (at
least one of which is strictly positive since at least one
> 0 and fk(zn) is
vi > vn for some i
strictly convex. To obtain the sign of zmin
n which minimizes
fk(zn), we inspect the ﬁrst derivative of fk(zn). Since zmin
is a minimum of fk(zn), we must have:

). Hence, d

2
f
dz2
n

∈ M

n

= 1 +

zn=zmin
n

n−1

i=1
X

df
dzn

(cid:12)
(cid:12)
(cid:12)

vi
zmin
n
vn
k2zmin2
n

vi + vi −

1
k2vn

q

(cid:0)

= 0.

vn

(35)

(cid:1)

Since the denominator of the summation term in (35) is
is always
(cid:4)

always positive, and since vi/vn for all i
positive, zmin

n must be negative to solve (35).

∈ M

Proposition 2 is valuable for characterizing the possible
solutions in zn to fk(zn) = D, and equivalently to (14), as
stated in Corollary 1. To this end, let D , fk(zmin
n ) be the
minimum value of fk(zn) which is unique given that fk(zn)
was proven to be strictly convex.
Corollary 1. fk(zn) = D has: a) two solutions if D > D,
b) one solution if D = D, or c) no solution if D < D.

Proof. From Proposition 2, we know that fk(zn) is a strictly
convex function. Therefore any line D parallel to the zn axis
will intersect fk(zn) in two points if D > D, one point if
(cid:4)
D = D, and will not intersect fk(zn) if D < D.

≥

Based on Corollary 1 and Theorem 1, we can conclude that
for D
D, we have one or two possible local maxima for
˜U a(z, k). However, we must check whether these maxima
are feasible as they should correspond to z∗
n > 0, which is a
necessary condition as proven in Theorem 1. These maxima
also must satisfy the following feasibility conditions on zi
for i

:

∈ M

6

5

4

3

2

1

0

-2

-1.5

-1

-0.5

0

0.5

1

1.5

2

Fig. 2: Comparison of solutions of equations fk(zn) =
D, L+(zn) = D, and L−(zn) = D.

ra
i ≤

Ra, rb

Rb,

≤
Therefore, for any solution z∗

⇒ −

i ≤

Rb

zi = ra

rb
i ≤
n > 0 of f (zn) = D, we

i −

Ra.

(36)

must check that z∗

i , for i

∈ N
0 < z∗

, satisfy
Ra.

i ≤
Next, we show that only one solution of fk(zn) = D
satisﬁes (37).

Theorem 2. For Dk
˜U a(z, k) has a unique maximum.

max

≥

(cid:26)

n−1
√vn(2n−1)

,

n−1
i=1

vi−vn
vn

P

q

,
(cid:27)

(37)

Proof. From Corollary 1, we know that, for D > D,
fk(zn) = D has two solutions which we denote as z∗
n < ¯z∗
n.
We need to prove that only one of these solutions satisﬁes
(37). First, we prove that fk(zn) has two slant asymptotes
L1(zn) and L2(zn), where fk(zn) > L+(zn), L−(zn). To
prove this statement, we ﬁnd the linear approximations of
and
fk(zn) as zn goes to +

∞

−∞

L+(zn) = lim
zn→∞

fk(zn) = zn +

= zn

1 +

n−1

i=1 r
X

vi
vn !

,

L−(zn) = lim

zn→−∞

fk(zn) = zn +

= zn

1

−

n−1

i=1 r
X

vi
vn !

.

n−1

, as follows:
vi
vn

zn

r

i=1
X

n−1
(
−

i=1
X

vi
vn

zn)

r

(38)

(39)

vi
vn !

n−1

i=1 r
X
vi
vn

,

n−1

zn +

i=1 r
X

1
k2vn
n−1

(k2z2

nvi + vi −

vn) > zn

1 +

⇔

zn

i=1
X

r

vi
vn

+

vi −
k2z2

vn
nvn

n−1

> zn

i=1 r
X
vn)/(k2z2

0 for
which always holds true since (vi −
nvn)
.
; with at least one strict inequality for an i
i
∈ M
∈ M
Hence, fk(zn) > L+(zn). Using a similar approach, we
can also prove that fk(zn) > L−(zn). From fk(zn) >
L+(zn), L−(zn), we can state that fk(zn) always lies in the
upper subspace of the intersection of its asymptotes as shown
in Fig. 2.

≥

Let us deﬁne the solutions of L+(zn) = D and L−(zn) =

D as ¯zn and zn, respectively; then we have:

¯zn > ¯z∗

n ≥

zmin
n ≥

z∗
n > zn.

(40)

These inequalities are illustrated in Fig. 2.

n < 0, and, thus, z∗

From Proposition 2, we have zmin

n < 0.
Hence, z∗
n < 0 cannot be an acceptable solution for f (zn) =
D since it violates the condition in (37). We next investigate
¯z∗
n. For it to be a valid solution, we must have 0 < ¯z∗
n < Ra
and the resulting z∗
i , which can be computed from (15), must
satisfy the constraints in (37). Since ¯zn is an upper bound of
¯z∗
n, we start by studying ¯zn. In this respect, next, we prove
that ¯zn < Ra:

n−1

L+(zn) = D,

zn

1 +

⇒

¯zn =

1 +

D
n−1
i=1

i=1 r
X

.

vi
vn

vi
vn !

= D,

(41)

From (41), we can see that ¯zn < Ra always holds true
> 1 and 0 < D < Ra. Hence, since

P

(cid:16)

q

(cid:17)

n−1
since 1 +
i=1
n < ¯zn and ¯zn < Ra, then ¯z∗
¯z∗
To satisfy ¯z∗

vi
vn

P

q

n > 0, we must have fk(0)

n < Ra.

D, which yields:

≤

n−1

i=1 r
X

vi −

vn
vn ≤

Dk.

(42)

i , for all i

Under the condition on D in (42), we obtain 0 <
¯z∗
n = ¯z∗
n < Ra. However, for z∗
n to be a valid solution,
the resulting z∗
which can be computed
∈ M
from (15), must satisfy 0 < z∗
Ra. From Theorem 1,
i > 0. To prove that z∗
we know that z∗
Ra for all
must be less
i
that Ra. Consider an index i that corresponds to such
maximum z∗
vn) >

, the maximum z∗
i

for all i

(k2 ¯z∗2

∈ M

∈ M

i ≤

i ≤

i . Since z∗
nvi + vi −
nvi + vi −

(k2 ¯z2

(k2 ¯z2

1
k2vn

i =
q
vn) (due to ¯z∗

n vi + vi −
n < ¯zn), we show that
Ra. Therefore, we must have:

vn)

1
k2vn
1
k2vn

q

q

≤

¯z2
n

vi
vn
vi
vn

+

vn
vi −
vnk2 ≤
vn
vi −
vnk2 ≤

+

Ra,

Ra2,

r

2

D2
n−1
i=1

(cid:16)

1 +

2 +

P
⇔

vn
vi −
vnk2 ≤

vi
vn
(cid:17)
q
D2vi
n
i=1 √vi
1)Rb = n−1
n Ra
1),
(cid:1)
(cid:0)P
−
and the maximum value for vi is 1, then, by comparing the
maximum value of the left-hand side of the inequality in (43)
with the minimum value of the right-hand side, we can ﬁnd
a minimum value for k as follows:

Ra > (nD)/(n

Since D < (n

Ra2.

(43)

⇒

−

D2 +

1

vnk2 ≤

Dk

≥

n

D2(

n

−
n
1
−
vn(2n

)2,

1

−

.

1)

(44)

p

Moreover, to prove that fk(zn) > L+(zn) we must have:

⇔

 
 
 
 
From (42) and (44), we can conclude the proof by

max

stating that the unique maximum of ˜U a(z, k), for Dk
n−1
n−1
, is z∗ such that z∗
i=1
√vn(2n−1)
(cid:27)
n = ¯z∗
is as deﬁned in (15), and z∗
n.

(cid:26)
∈ M
In Theorem 2, we derived a unique local maximum of

≥
i for
(cid:4)

vi−vn
vn

P

q

i

,

˜U a(z, k) for Dk
Theorem 3, we prove that this local maximum is actually a
global maximum of ˜U a(z, k).

n−1
√vn(2n−1)

vi−vn
vn

max

. In

P

q

≥

(cid:26)

(cid:27)

n−1
i=1

,

=
=
a

≥

unique

Theorem 3. The
[z∗

n−1, z∗

1, . . . , z∗
1
k2vn
unique
q

(k2z2

n], where
vn)

nvi + vi −

global maximum of

local maximum z∗
z∗
¯z∗
n
i
is

z∗
n =
for
i

and

,

∈ M

˜U a(z, k)

for Dk

max

n−1
√vn(2n−1)

,

(cid:26)

n−1
i=1

vi−vn
vn

.

(cid:27)

P

q

Proof. Theorem 2 showed that the derived local maximum
of ˜U a(z, k) for a given limit on Dk is unique. Next, we
prove that ˜U a(z, k) has no local minimum.

1

n

−

⇔

⇔

∈ M \ {

H1 is negative deﬁnite

The proof follows the same logic as that of Theorem 1 by
attempting to ﬁnd solutions in (18) which lead to a positive
deﬁnite Hessian matrix H. In this regard, H is positive
all pivots of H 2 are
deﬁnite
negative. As such, a local minimum must have all z∗
i < 0
for i
obtained from (18) and must have ξ < 0
which is deﬁned in (27). To this end, similarly to the four-
step case analysis derived in Theorem 1 over the signs of zn
and z∗
1
}
no feasible zn and z∗
n−1 lead to ξ < 0. In fact, it can be
derived that (z∗
n−1 < 0, zn < 0) and (z∗
n−1 > 0, zn > 0)
lead to non-feasible solutions that violate (14) while (z∗
n−1 >
0, zn < 0) and (z∗
n−1 < 0, zn > 0) lead to ξ > 0, and hence,
a non-positive deﬁnite H.

n−1, we can prove that for z∗

i < 0 for i

∈ M \ {

−

n

}

n and z∗

Therefore, z∗

n = ¯z∗
1
vn)
k2vn
is a unique local maximum of ˜U a(z, k) and
for i
˜U a(z, k) admits no local minima. Hence, this unique local
(cid:4)
maximum is a global maximum.

nvi + vi −

(k2z2

∈ M

i =

q

Based on the derived maximum of ˜U a(z, k) with respect
to z, we next characterize the pure-strategy NE for the
GCBG.

Theorem 4. For k

,
(cid:26)
(cid:27)
the pure-strategy NE for the GCB game is the allocation
vectors deﬁned as follows:

n−1
√vn(2n−1)

vi−vn
vn

max

, 1
D

P

q

1
D

≥

n−1
i=1

∗

∗

rb∗
= [rb
1
ra∗ = rb∗

, . . . , rb
n
+ [z∗

],
1, . . . , ¯z∗
n],
n (the positive solution of fk(zn) = D), and

(45)

(46)

where z∗

n = ¯z∗

z∗
i =

z∗2
n

r

vi
vn

+

vi −
vn
vnk2 ,

for i

∈ M

and

∗

rb
1

+

· · ·

∗

+ rb
n

= Rb.

(47)

(48)

Proof. As stated in (10), the pure-strategy NE of the GCBG
is the set of two vectors ra∗ and rb∗, which solve:

min
rb∈Qb

max
ra∈Qa

˜U a(ra, rb, k).

(49)

Maximizing ˜U a(ra, rb, k), with respect to ra is similar
to z, where z =

to maximizing ˜U a(z, k) with respect
ra

rb. In Theorem 3, we have shown that, if Dk
−
vi−vn
n−1
max
vn
√vn(2n−1)
(cid:27)
n−1, ¯z∗
1, . . . , z∗
one maximim at z∗ = [z∗
q
P
positive solution of fk(zn) = D, and z∗
i
(15). Therefore, ra∗ can be written as follows:

≥
, then ˜U a(z, k) has only
n], where ¯z∗

n is the
is as deﬁned in

n−1
i=1

(cid:26)

,

ra∗ = rb + z∗.

(50)

By substituting ra∗ in ˜U a(ra, rb, k), we will have:

˜U a(ra∗, rb, k) =

n

vi
π

arctan

k(ra∗

i −

rb
i )

+

vi
2

(cid:0)

arctan (k(z∗

i )) +

(cid:1)

1
2

,

(cid:17)

(51)

=

i=1 (cid:16)
X
n
vi
π

i=1
X

which has a constant value. Therefore, the minimizing vector
rb∗ consists of all the strategies in player b’s strategy set,
b.
Therefore, the pure strategy NE of the GCB is as deﬁned in
(45)-(48). Moreover, the value of the game for each player
can be expressed as follows:

Q

V a(k) , 1

V b(k) =

−

1
2

+

vi
π

arctan (kz∗

i ) .

(52)

n

i=1
X

(cid:4)
From Theorem 4, we can see that the GCB admits an
inﬁnite number of pure-strategy NEs. However, we have
characterized all of them and we have also shown that, by
deviating from one NE to the other, the payoff of each player
does not change.

∈ N

Moreover, Theorem 4 shows that the player with the higher
available resources can always achieve a higher payoff by
playing the derived pure-strategy NE, since z∗
i > 0 for
which yields V a(k) > V b(k). This implies that, if
i
both players are fully rational, the more resourceful player
wins the game in aggregate, which captures a missing feature
in the CBG. Indeed, in the CBG, even when a player is
more resourceful, it cannot ﬁnd a winning pure strategy. In
this respect, based on the k
approximation in the proposed
GCBG, we can signiﬁcantly increase the approximation
index k so that the GCBG very closely approximates the
CBG and still be able to derive a solution to the game in
pure strategies. Here, we note that, when k goes to inﬁnity,
our derived solution will no longer hold since the ﬁrst order
conditions in (17) will be met for any zi (i
). This is
aligned with the CBG which does not admit an NE in pure
strategies, and indeed, conﬁrms that when k goes to inﬁnity
our proposed GCBG converges to the classical CBG. Next,
we illustrate the GCBG and derived pure-strategy NE using
an example.

∈ M

−

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

1

2

3

4

5

6

7

8

9

10

Fig. 3: Difference between the allocation of resources at NE

1

0.8

0.6

0.4

0.2

0
-10

-8

-6

-4

-2

0

2

4

6

8

10

Fig. 4: Payoffs of the players at NE.

IV. AN ILLUSTRATIVE EXAMPLE
In this numerical example, we consider a GCBG with 10
battleﬁelds and a random valuation for the battleﬁelds (with
a randomly chosen vn = 0.0215). We ﬁrst compute the NE
of the game for different values of D. The results are shown
in Fig. 3. To satisfy the condition in Theorem 4 on k and D,
we choose k = 50. As can be seen in Fig. 3, the difference
between the allocated resources over each battleﬁeld at the
NE increases as D increases.

−

In Fig. 4, we derive the players’ payoffs for different D =
Ra
Rb. As expected, Fig. 4 shows that as the difference
between the available resources increases, the payoff for the
most resourceful player increases. Moreover, in Fig. 5 we de-
rived the NE for different values of the approximation index,
k, of the GCBG with D = 5. Fig. 5 shows that as k increases,
the most resourceful player achieves a higher total payoff.
This result illustrates the effect of the k
approximation in
the GCBG. In fact, as can be seen in (5) and Fig. 1, for
lower values of k, the effect of the consumed resources is
more accounted for in the expression of the utility function
which results in a lower total payoff for the winning player.

−

V. CONCLUSION

In this paper, we have proposed a novel generalized
Colonel Blotto game framework to analyze competitive re-
source allocation problems. When the approximation index
tends to inﬁnity, we have proven that the proposed game
converges to the classical Blotto game. However, in contrast
with the Blotto game, our proposed game admits an NE in
pure strategies, which renders the derived solutions amenable

1

0.8

0.6

0.4

0.2

0

1

2

3

4

5

6

7

8

9

10

Fig. 5: Payoffs of the players at NE with D = 5.

to practical applications. For this new class of CBG, we have
proven the existence of a pure-strategy NE and provided
a detailed derivation of closed-form analytical expressions
of the NE. Finally, we have presented a numerical example
which illustrates the effects of the increase in the number
of resources of each player on the game’s outcome and
NE strategies. Our results also showcased the effect of the
approximation index on the solution of the game.

REFERENCES
[1] Y. Wu, B. Wang, K. J. R. Liu, and T. C. Clancy, “Anti-jamming games
in multi-channel cognitive radio networks,” IEEE Journal on Selected
Areas in Communications, vol. 30, no. 1, pp. 4–15, January 2012.
[2] W. Saad, Z. Han, M. Debbah, and A. Hjorungnes, “A distributed
coalition formation framework for fair user cooperation in wireless
networks,” IEEE Transactions on Wireless Communications, vol. 8,
no. 9, pp. 4580–4593, September 2009.

[3] A. Ferdowsi, A. Sanjab, W. Saad, and N. B. Mandayam, “Game theory
for secure critical interdependent gas-power-water infrastructure,” in
Proc. of 10th Resilience Week, Wilmington, DE, USA, Sept 2017.
[4] A. Gupta, T. Bas¸ar, and G. A. Schwartz, A Three-Stage Colonel Blotto
Game: When to Provide More Information to an Adversary. Cham:
Springer International Publishing, 2014, pp. 216–233.

[5] A. Ferdowsi, W. Saad, and N. B. Mandayam, “Colonel Blotto Game
for secure state estimation in interdependent critical infrastructure,”
arXiv preprint arXiv:1709.09768, 2017.

[6] C. Thomas,

“N-dimensional blotto game with heterogeneous
battleﬁeld values,” Economic Theory, Jan 2017. [Online]. Available:
https://doi.org/10.1007/s00199-016-1030-z

[7] S. Behnezhad, A. Blum, M. Derakhshan, M. HajiAghayi, M. Mahdian,
C. H. Papadimitriou, R. L. Rivest, S. Seddighin, and P. B. Stark, “From
battleﬁelds to elections: Winning strategies of blotto and auditing
games,” in Proc. 29th ACM-SIAM Symposium on Discrete Algorithms,
January 2018, pp. 2291–2310.

[8] R. B. Myerson, “Incentives to cultivate favored minorities under
alternative electoral systems,” The American Political Science Review,
vol. 87, no. 4, pp. 856–869, 1993.

[9] B. Roberson, “The Colonel Blotto game,” Economic Theory, vol. 29,

no. 1, pp. 1–24, Sep 2006.

[10] N. Sahuguet and N. Persico, “Campaign spending regulation in a
model of redistributive politics,” Economic Theory, vol. 28, no. 1,
pp. 95–124, May 2006.

[11] G. Schwartz, P. Loiseau, and S. S. Sastry, “The heterogeneous Colonel
Blotto game,” in Proc. 7th International Conference on NETwork
Games, COntrol and OPtimization (NetGCoop), Trento, Italy, 2014,
pp. 232–238.

[12] M. Dziubi´nski, “Non-symmetric discrete General Lotto games,” Inter-
national Journal of Game Theory, vol. 42, no. 4, pp. 801–833, Nov
2013.

[13] J. Weinstein, “Two notes on the Blotto game,” The B.E. Journal of

Theoretical Economics, vol. 12, no. 1, 2012.

[14] C. K. Tan, T. C. Chuah, and S. W. Tan, “Fair subcarrier and
power allocation for multiuser orthogonal frequency-division multiple
access cognitive radio networks using a Colonel Blotto game,” IET
Communications, vol. 5, no. 11, pp. 1607–1618, July 2011.

[15] Y. Wu, B. Wang, and K. J. R. Liu, “Optimal power allocation strategy
against jamming attacks using the Colonel Blotto game,” in Proc. IEEE
Global Telecommunications Conference, Nov 2009, pp. 1–5.

[16] T. Bas¸ar and G. J. Olsder, Dynamic Noncooperative Game Theory.
Philadelphia, PA, USA: SIAM Series in Classics in Applied Mathe-
matics, Jan. 1999.

[17] M. S. Bazaraa, H. D. Sherali, and C. M. Shetty, Nonlinear program-

ming: theory and algorithms.

John Wiley & Sons, 2013.

