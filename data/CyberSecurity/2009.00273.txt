Graph-based Model of Smart Grid Architectures

Benedikt Klaer∗, ¨Omer Sen∗, Dennis van der Velde∗, Immanuel Hacker∗, Michael Andres∗, Martin Henze‡
∗Digital Energy, Fraunhofer FIT, Aachen, Germany
Email: {benedikt.klaer, oemer.sen, dennis.van.der.velde, immanuel.hacker, michael.andres}@ﬁt.fraunhofer.de
‡Cyber Analysis & Defense, Fraunhofer FKIE, Wachtberg, Germany
Email: martin.henze@fkie.fraunhofer.de

0
2
0
2

p
e
S
1

]
E
S
.
s
c
[

1
v
3
7
2
0
0
.
9
0
0
2
:
v
i
X
r
a

Abstract—The rising use of information and communication
technology in smart grids likewise increases the risk of failures
that endanger the security of power supply, e.g., due to errors
in the communication conﬁguration, faulty control algorithms,
or cyber-attacks. Co-simulations can be used to investigate such
effects, but require precise modeling of the energy, commu-
nication, and information domain within an integrated smart
grid infrastructure model. Given the complexity and lack of
detailed publicly available communication network models for
smart grid scenarios, there is a need for an automated and
systematic approach to creating such coupled models. In this
paper, we present an approach to automatically generate smart
grid infrastructure models based on an arbitrary electrical
distribution grid model using a generic architectural template.
We demonstrate the applicability and unique features of our
approach alongside examples concerning network planning, co-
simulation setup, and speciﬁcation of domain-speciﬁc intrusion
detection systems.

Index Terms—Smart Grid Model, Graph Model, SGAM, Co-

Simulation, Cyber-Physical System

I. INTRODUCTION

The increased penetration of electrical power grids with
volatile renewable energies, as well as new load situations,
e.g., through electro-mobility, confront grid operators with
new challenges: Bottlenecks due to increased power ﬂow or
voltage limits must be identiﬁed and remedied by timely active
grid operation, leading to increased use of information and
communication technology (ICT) [1]–[3]. Failures of this ICT
infrastructure seriously endanger the security of power supply,
e.g., through the incorrect conﬁguration of communication
links, defective algorithms for grid automation, or cyber-
attacks [2], [4]. Consequently, there is a need to (i) design
and conﬁgure ICT infrastructure in power grids to realize
topologies that are ﬂexible and resilient to failures, (ii) study
the impact of ICT failures and misconﬁguration as well as
defective algorithms, and (iii) develop resilience and cyber-
security approaches that consider both, the energy and ICT
domain.
Motivation and Background. Co-simulations of combined
energy and ICT domain are an indispensable tool to analyze
these risks and countermeasures at an early stage and enable
planning of more resilient power grids [5]. To enable such co-
simulation of large-scale smart grid scenarios, the consistent
and integrated modeling of data points, parameters, interfaces,
communication links, as well as ICT and Operational Technol-
ogy (OT) devices is of utmost importance [2], [5]. Focusing
on the electrical side of power grids, power grid models are an

indispensable tool for grid operators and researchers to plan
grid expansion and connection, as well as to solve operational
problems [6]. Popular power system simulators and analysis
tools such as MATPOWER or pandapower are shipped with
different public power grid models [6]. Despite the popularity
of modeling approaches for the electrical side of power grids,
corresponding models for the ICT side are missing, mainly
due to security concerns of grid operators [2]. Thus, synthetic
and ﬂexibly constructed ICT infrastructure models based on
power grid models provide a valuable alternative.
Relevant Literature. A fundamental foundation for the mod-
eling of smart grids is the Smart Grid Architecture Model
(SGAM) [7]. SGAM allows to describe smart grid system
architectures and use cases, with the aim to reveal gaps in
smart grid standardization [8]. In its core, SGAM provides an
approach to deconstruct the smart grid system landscape into
the three dimensions (i) domains (energy conversion chain),
(ii) zones, and (iii) the interoperability layer [9], [10].

The wide applicability of SGAM, enabling distributed simu-
lations and model-driven approaches [7], is utilized in previous
works demonstrating model-based rapid prototyping of smart
grids [11]. Further works are presenting approaches to reduce
complexity and improve traceability in the model-driven smart
grid application development [12], introducing SGAM-based
modeling language for also integrating security by design
concept [13]. Furthermore, substation design can be speciﬁed
by utilizing the common information model together with the
IEC 61850 standard through ontology matching [14] within
the Query/View/Transformation standard [15].

However, these studies lack a holistic approach to model
smart grid infrastructures, incorporating the technical interop-
erability speciﬁcation and conﬁguration of the various compo-
nents. W.r.t. the practical applicability, a detailed speciﬁcation
of data points, logical component behavior, and ICT network
and power grid conﬁguration intertwined in a common model
structure is needed.
Contributions and Organization. In this paper, we bridge the
gap between existing power grid models and the need to also
provide models for the corresponding ICT infrastructure and
its network conﬁguration. To this end, we present an approach
to model a graph-based energy information network based on
power grid models and smart grid use cases, drawing from
the concept of model-driven software engineering [11], [12],
[16]. The underlying graph structure of our approach enables
an automated construction of a smart grid infrastructure model

Author’s version of a paper accepted for publication in Proceedings of the 3rd International Conference on Smart Energy Systems and Technologies (SEST).
c(cid:13) 2020 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including
reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or
reuse of any copyrighted component of this work in other works.

 
 
 
 
 
 
with interoperable network conﬁguration. Furthermore,
the
automated creation of data points in OT devices allows for an
interoperable conﬁguration, e.g., in co-simulation trials, and
serves as a basis for actual deployment. Our contributions are:
1) We provide an analysis of current research challenges
regarding missing smart grid ICT models (Section II).
2) We propose and discuss a structured approach for cre-
ating a graph-based infrastructure model consisting of
blueprint, modeling, and conﬁguration (Section III).
3) We show the applicability and beneﬁts of our modeling
approach for network planning, co-simulation environ-
ments, and ICT security mechanisms (Section IV).

II. PROBLEM ANALYSIS

With the increasing deployment of IT and OT infrastructure,
grid operators, and researchers are facing new challenges w.r.t.
planning, operation, and security. In the following, we high-
light these challenges using concrete examples and identify
requirements to remedy this situation, especially considering
integrated modeling of power and ICT infrastructure.

A. Planning of ICT Infrastructures

The transformation of conventionally operated distribution
grids to smart grids requires a large-scale expansion of the
infrastructure with additional sensor and actuator technology.
The connection and interconnection of new locations to the
central SCADA system require forward-looking economic and
functional planning of the underlying communication network.
Requirements for communication links result from the vari-
ous smart grid applications and can be quantiﬁed in quality
parameters such as bandwidth, latency, jitter, or packet loss
rate [1]. To enable the most economical planning in relation
to the usage scenario, mathematical optimization methods can
be applied to digital infrastructure models [17].

Thus, planning ICT infrastructures requires knowledge of
(i) communication topologies and architectures, (ii) commu-
nication link parameter (e.g., bandwidth of single links), as
well as (iii) predicted data volume and quality requirements.

B. Optimization of Operation by Large-scale Co-Simulation

Simulations are valuable for the development of new meth-
ods to optimize the operation of complex energy systems.
Furthermore, negative impacts on a reliable power grid op-
eration due to ICT failures and misconﬁguration, as well
as cyber-attacks can be safely analyzed through simulations.
Co-simulation enables the execution of multiple simulation
models, e.g., a communication network simulator and a power
ﬂow solver, in one runtime environment. Usually, smart grid
co-simulation are deﬁned within use cases [18].

However, current co-simulation approaches are limited by
a gap between theoretical use case deﬁnition and practical
deployment of the simulation environment [11]. Most impor-
tantly, coupling different simulation environments in large-
scale scenarios typically requires a prohibitive manual effort.
Furthermore, often, only insufﬁcient data is available either on

the energy side or on the communication side to be able to
create an environment that sufﬁciently corresponds to reality.
Thus, to enable the largely automated examination of differ-
ent methods within co-simulation environments, the following
information is required: (i) unambiguous deﬁnition of the data
models required for the individual energy and ICT simulator,
(ii) deﬁnition of the links between the simulation models, and
(iii) automatic generation of distributed device conﬁgurations.

C. Domain-speciﬁc Security of Smart Grids

The increased complexity of smart grid ICT networks leads
to a multitude of new attack vectors (e.g due to more ICT,
new intrusion points, sensitive data exchange, cascade effects)
[19] Past attacks on cyber-physical systems [2], [4], [20] show
that semantically correct control and measurement data can
still cause critical process states. Such deceptive manipulation
is difﬁcult to detect with conventional security technologies
[21], thus it is not sufﬁcient to develop countermeasures for
energy and ICT separately.

To remedy this situation, ﬁrewalls with deep packet in-
spection could extend security policies on a semantic level
and include characteristics of the application layer in case of
available consistent information. Likewise, the availability of
speciﬁcations of network trafﬁc and information on process
data would allow us to create process-aware intrusion detection
systems. Finally, for reactive measures, the decision to isolate
certain areas or systems requires a risk assessment, which e.g.,
demands knowledge about operating parameters.

Consequently, to realize security approaches incorporating
both, energy and ICT, the following information is needed:
(i) communication relations, (ii) protocol
information, and
(iii) valid data points and instruction types for each device.

III. GRAPH-BASED MODELING APPROACH

As illustrated by our problem analysis, a wide range of use
cases demand integrated infrastructure models of smart grid ar-
chitectures, also containing information about communication
structures, systems, and applications. We present a structured
approach to creating such integrated infrastructure models for
smart grids.

To this end, our integrated SGAM-based infrastructure
model realizes a contextualized combination of a power grid
model with an ICT infrastructure model within a connected
graph based on three steps: (i) blueprint, (ii) modeling, and
(iii) conﬁguration. The resulting graph-based model can be
used to realize various functionality, e.g., to bootstrap co-
simulation environments (cf. Section IV).

A. Blueprint Phase

The ﬁrst step in creating the infrastructure model is the
architectural smart grid design, encompassing the deﬁnition
of the scenario framework and the considered use cases.
We call this the blueprint phase, as it does not refer to a
concrete model, but constitutes a general design decision. The
SGAM framework [10] offers an established standard for the

structured description of the scenario framework, providing a
wide range of use case deﬁnitions [8].

The interdisciplinary relationships of the model speciﬁca-
tion are reﬂected in the SGAM interoperability layers. To
illustrate this method, we provide a generic example of the
SGAM in Figure 1 which breaks down all available informa-
tion within component, communication, and information layer
at the distribution grid level.

1) Component Layer: The component

layer deﬁnes as-
signments between primary technology components in the
process zone and ICT components. Besides metadata for
devices, physical connections, and interfaces at the component
level are provided. Connections between the components are
represented with a one-to-one cardinality between interfaces.
As the SGAM design is independent of a speciﬁc power grid
model, the communication network can also only be described
conceptually based on SGAM. In the standard [10], the various
forms of communication networks are described and assigned
to speciﬁc technologies depending on where they are used.

The components illustrated in Figure 1 are generic and
therefore independent of a speciﬁc application. E.g., compo-
nents at the ﬁeld-level are subdivided into generic classes
of IEDs for control, measurement, and protection. Speciﬁc
in the
instantiations of these devices can be found, e.g.,
smart grid standards map [22]. The example shows a generic
setup for local area network (LAN) design on substation level
with ﬁeld-based communication links connected by station
switches. Between the station and operation layer, a wide area
network (WAN) connects multiple substations with the central
SCADA system. A private ﬁber-optic or powerline network of
the grid operator connects several secondary substations in a
metropolitan area network (MAN). The uplink to the central
SCADA system is achieved by a connection to the WAN via
the primary substation. Additionally, connections of secondary
substations through mobile communication can be speciﬁed.
In summary, the outputs of the component layer are: (i) ICT
components and interfaces, (ii) network architecture principle,
and (iii) network interconnection points.

2) Communication Layer: The communication layer de-
scribes the logical connections between smart grid compo-
nents. The layer gives information about used protocols and
the endpoints for each logical connection. The example in
Figure 1 shows communication links between IEDs, RTUs,
and SCADA via the IEC 60870 protocol. Based on the position
of a component in the automation hierarchy, we implicitly
derive their role as client/master or server/slave concerning
other components. Devices in a higher automation level rep-
resent the client/master of a logical connection. In the context
of modeling communication network settings, connections
within the communication layer also deﬁne required routes
and reachability between components.

Hence, the outputs of this layer of the model generation are:
(i) communication protocols, (ii) master/slave relationships,
(iii) network routes, and (iv) communication whitelist.

3) Information Layer: Within the information layer the
data models are speciﬁed. Based on appropriate standards,

Fig. 1. Generic SGAM example for the blueprint phase, i.e., transformer
voltage control use case (communication layer: green, information layer: blue)

canonical data models can be deﬁned (e.g., IEC 61968, IEC
61970, IEC 61850). For data point-oriented protocols (e.g.,
IEC 60870, Modbus), which are not object-oriented modeled,
data points have to be explicitly assigned to typed variables. In
the case of the IEC 60870 protocol, this means an assignment
of information object addresses (IOA), cause of transactions
(COT), and type identiﬁers (TypeID) to variables. Contrary,
object-oriented protocols (e.g., IEC 61850) assignments exist
implicitly. In a co-simulation, e.g., the source of the process
data is the result of each power ﬂow simulation step.

The exemplary information layer in Figure 1 shows a sim-
pliﬁed information ﬂow of a transformer voltage control use
case. Within this layer, we deﬁne that a primary substation has
a transformer tap position as a process data point. Components
on the ﬁeld-level connected to the transformer of the substation
can access its tap position variable. For voltage control, the
SCADA needs to adapt the voltage setpoint on the process
level. This requires an information ﬂow between the SCADA
and IED components, which is routed through the substation’s
RTU. Therefore, the conﬁguration of these process data points
and the assignment to the typed variables are required for all
components involved. Only this way we can determine within
the infrastructure model which data points the OT component
requires for the use case and whether a valid connection to
the primary component (e.g., transformer) exists.

Summarizing,

the outputs of the information layer are:
(i) data points, (ii) data ﬂow, and (iii) source of information.
4) Function and Business Layer: The function layer and the
business layer of the SGAM model do not provide information
to the modeling method and thus do not have to be considered.

B. Modeling Phase

The modeling phase aims to apply the blueprint

to a
concrete power grid model to derive a graph representation
of an integrated infrastructure model. A power grid model
contains topological information as well as electrical system

OperationStationFieldProcessDistribution DomainDERCustomerDistributionGenerationTransmissionProcessOperationEnterpriseMarketStationFieldHV/MVMV/LVProtection IEDControl IEDRTU / HMIRouter / ModemCommunication FrontendHVMVHVMVMVPrimary SubstationSecondary SubstationMeasurement IEDField SwitchStation SwitchMANMobilWANLVtapU_setSCADAFig. 2. Flowchart of the bottom-up modeling process for the creation of
primary technology and ICT objects as the basis of the digital data model

data and is a graph that represents the lines and systems as
edges and nodes. The application of our blueprint follows a
bottom-up approach as illustrated in Figure 2.

1) Object oriented Modeling: In Step 1, we perform object-
oriented modeling of the primary technology and instantiate
elementary primary objects (e.g., busbars, transformers, loads,
and generators) according to the power grid ﬁle provided
in Step 0. Subsequently, in Step 2, we perform based on
the station speciﬁcation (component layer of the blueprint)
a contextual aggregation of single objects of the primary
technology to station objects (e.g., primary/secondary sub-
station, DER, or prosumer). Afterwards, for each station, a
component-speciﬁc placement and connection of secondary
and protection technology to the primary technology according
to the blueprint is performed. In Step 4, we realize station-wide
subnets by placing and connecting local network components
to ﬁeld-level devices. At the station level, RTU units are placed
in Step 5. The connection of the station level to the WAN
(Step 6) follows the speciﬁed communication technology (e.g.,
cellular network, powerline, or ﬁber).

2) WAN Graph Modeling: In Step 7, the WAN is set up as
a connecting communication network. The topology of the
communication network can be without explicitly speciﬁed
deduced from the used communication technologies and the
power grid model. To this end, we identify,
independent
of concrete technological realization,
three communication
paradigms: (i) unbound to electrical topology (e.g., mobile),
(ii) linked to electrical topology (e.g., PLC), or (iii) parallel
to electrical topology (e.g., ﬁber or wire).

If the WAN infrastructure is unbound to electrical topology,
e.g., in the case of mobile communication, we ﬁrst assign mo-
bile radio modems located at the stations to local base stations
(Node-B) in cell structures. The network trafﬁc is then routed
via base station controllers within the hierarchical internal net-
work of the communication provider. Consequently, the grid
operator can access the RTUs from a central location, resulting
in a star-shaped hierarchical communication infrastructure.

WAN infrastructure linked to electrical topology, e.g., pow-
erline communication, uses the existing cable and overhead
line network. Thus, the resulting topology of the communica-
tion network is strictly bound to the electrical topology and
thus impacted by switching measures of the grid operator.

Fig. 3. Process scheme for the consecutive derivation of parameters for the
conﬁguration of the communication network

is laid parallel

Finally, WAN infrastructure running parallel to electrical
topology, e.g., optical ﬁber cables,
to the
electrical topology. The resulting topology is line-oriented,
independent of the switching state or electrical inﬂuences, and
can be further optimized regarding deployment costs through
the usage of minimum spanning tree algorithms (cf. Section 2
in [23]). After the set-up of the WAN in Step 8, the individual
actors are connected to their respective networks.

C. Conﬁguration Phase

1) Conﬁguration

of Communication Network:

The goal of the conﬁguration phase is to derive the nec-
essary parametrization of the integrated infrastructure model
created during the modeling phase (cf. Section III-B), i.e.,
parametrization of the communication network (IP addresses,
networking routes) and conﬁguration of process data points.
The
parametrization of the communication network also follows a
bottom-up approach as shown in Figure 3. We can directly
derive all physical communication links from the graph
of the integrated infrastructure model (cf. Section III-B).
Initially in Step 1, we parameterize the communication links
based in the provided speciﬁcation regarding quality metrics
(e.g., maximum bandwidth, delay, or jitter). In Step 2, we
initialize the communication interfaces on OSI Layer 1 for all
components, where the number of interfaces follows the node
degree in the graph of the infrastructure model. During Step
3, we split the graph into OSI Layer 2 subnets at all routing
or gateway components and connect the station zone with the
operation zone. Based on these subnets, IP addresses on OSI
Layer 3 are allocated to devices in Step 4. Necessary routes
and communication reachabilities are derived from client and
server roles deﬁned at the protocol level (cf. Section III-A).
Static routes between components are computed through
graph-based shortest path algorithms considering quality
metrics (cf. Section 3 in [23]). In Step 5, static routing entries
are registered for components with routing functionality on
the resulting paths, ensuring connectivity between the subnets.
An additional feature of the infrastructure model is the
automated generation of security policies, e.g., in ﬁrewalls
or intrusion detection systems. We derive security policies
from communication relationships, address assignments, and

EnergyGridPrimary technologyobjectsPrimary TechnologyTransformer, Breaker, Gen, LoadSubstations, DER, ConsumerAggregate tostationobjectsIED: protection, measurement, controlNetwork switchRTU, localSCADASwitch, Gateway, Router, ModemConnect energyactorstoWAN networksPlace IEDs on technologyobjectsField ZoneConnect all IEDs tostationswitchLAN ZoneConnect RTU tostationswitchStation ZoneConnect stationRTU toWAN deviceWAN ZoneWAN ZoneFiber, PLC, MobilInterconnect WAN devicesOperation ZoneDSO, Flexibilityoperator, DER operatorObjects:Building Process:Zone:Primary Technology023456718SCADA <-> RTU <-> IEDL3 AdressesCommunication GraphCreate Layer 2 SubnetCreate Layer 3 SubnetCreate Layer4 StaticRoutingSecurity PoliciesFirewall, IDSL2SubnetsNetwork InterfacesCreate Layer 1 InterfacesProcess:Objects:1345602ParameterizationJitter, BandwidthFig. 4. Process schematic for automatic parametrization of the process data
points through hierarchical inheritance between SGAM zone layers

protocol properties (e.g., used ports), speciﬁed by the protocol
level in the blueprint phase. Application layer security can be
conﬁgured by also providing information about the exchanged
process data, collected during data point conﬁguration.

2) Data Point Conﬁguration: The results of the blueprint
and modeling phase are used for the automated conﬁguration
of the process data points, exemplary shown in Figure 4.

As described in Section III-A3, the information layer deﬁnes
data of primary technology (e.g., tap position of transformers)
and process data points in components (e.g., voltage setpoints).
The availability of process data to ﬁeld devices (e.g., IED) is
deﬁned in Step 1 by the connected physical interface of a pri-
mary technology object. In Step 2, process data points of ﬁeld
devices (e.g., for IEC 60870: IOA, type identiﬁer, COA) are
parameterized according to the data model of the information
layer. Using the graph underlying our infrastructure model, we
can inherit (Step 3) and aggregate (Step 4) process data points
of underlying trees from client applications.

Inheritance continues at the station level and deﬁnes the
available aggregated process data points for the SCADA
system in Step 5. In Step 6, the inheritance of data points
between two SCADA systems is shown and provides utility
for ﬂexibility proposals for distribution grid operators. Fur-
ther advantages of this structured data point inheritance are:
(i) IEDs receive a correct reference to permitted accesses
within the co-simulation, (ii) process data points are aligned
with energy objects in the grid model (e.g., switches, trans-
formers), (iii) data aggregating devices (RTU, SCADA) are
automatically conﬁgured correctly.

D. Computational Performance

As a foundation for a co-simulation case study, we assess
the computational performance of our graph-based modeling
approach by measuring the time required to automatically
create integrated infrastructure models. We report on the mean
processing time and its standard deviation (STD) for the
automated build-up process of the infrastructure model over
10 repetitions for 3 medium-voltage grid models. The ﬁrst
grid model is composed of 4 buses and the corresponding
generated infrastructure model consists of 48 nodes, which was
computed within 2s (STD 0.4s). For the second grid model
with 12 buses, generating an infrastructure model with 143

Fig. 5. Visualization of the graph-based data model of the CIGRE MV
reference grid based on the template of Figure 1

nodes takes 8.5s (STD 0.37s), while producing a 318 node
large infrastructure model from the CIGRE MV reference grid
model [3] requires 14.8s (STD 0.8s). These numbers indicate
that our approach to create a contextualized combination of a
power grid model with an ICT infrastructure model provides
sufﬁcient performance for typical application scenarios.

IV. APPLICABILITY

Our methodology presented in Section III already shows
advantages to the automatable and interoperable construction
of a graph-based infrastructure data model. The applicability
of this data model to the results of the problem analysis is
explained in the following.

A. Advantages to Network Planning

Using the method presented in Section III, communication
networks can be constructed based on the power grid model.
Through the explicit data point conﬁguration of each device
(cf. Section III-C2), as well as the respective communication
relationships, the net data volume can be estimated protocol-
unspeciﬁc for monitoring and control applications depending
on the cycle duration, and in the burst case. Since static routes
are part of the speciﬁcations, the packet ﬂow is deterministic
links as well as the
and the bandwidth of the individual
time response between hosts can be estimated conservatively
over the entire communication graph. For a more detailed
evaluation of the protocol overhead, time behavior, or inﬂuence
of simultaneities on message queuing, the execution of the
scenario in a co-simulation (cf. Section IV-B) is necessary.
Economic feasibility studies for the placement of additional
communication lines in case of limit violations can be carried
out automatically with the help of graph-based optimization
methods (e.g., Steiner tree problem).

B. Deployment of Co-Simulation Environments

One of the major challenges in realizing co-simulation for
operational analysis is the manual effort required to couple
different simulation environments, e.g., power ﬂow simula-
tion and communication network simulation, in large-scale

IEDphyserverEnergyObjectphyIEDphyserverEnergyObjectphyIEDphyserverEnergyObjectphyRTUclientserverRTUclientserverSCADAclientSCADAclientserverIEDphyserverEnergyObjectphyRTUclientserverMonitoring values,Measurement values, setpoints, switchingandtapcommands+ protectionparameter, controlingsetpoints, limits+ aggregationofdata234156Primary SubstationRouterMobile + InternetModemSecondarySubstationSCADARTUModemSwitchIEDMV BusLV LoadRTUWANOperationStationFieldProcessLayer:WANWANStationscenarios for deployment (cf. Section II-B). To showcase the
applicability and beneﬁts of our graph-based model, we use it
to create a co-simulation of the grid and communication infras-
tructure of a distribution system operator using pandapower [6]
as power ﬂow solver, ns-3 [24] as communication network
simulator, and mosaik [5] as co-simulation frameworks. Start-
ing from a concrete power grid model, we use our approach
to derive a graph representation of an integrated infrastructure
model. An exemplary result of our modeling approach based
on the publicly available CIGRE MV reference grid model [3]
is shown in Figure 5. Thus, the resulting graph-based model,
presented in Figure 5, contains all information necessary to
setup the corresponding communication network in ns-3 via a
YAML network conﬁguration ﬁle and couple power ﬂow and
communication network simulation using mosaik.

To this end, all ICT and OT assets (e.g., RTUs or switches)
as well as their interconnection can be laid out
in ns-3
with the information provided by our model. The network
parametrization in ns-3 (e.g., IP addresses or static routes)
then follows from the results of the conﬁguration phase (cf.
Section III-C). All information required by mosaik to couple
both pandapower and ns-3 is automatically available through
the graph-based relationships. For example, this allows an
RTU simulated in ns-3 to read the corresponding measurement
values from the electrical grid provided by the pandapower
simulator. Consequently, our graph-based integrated infrastruc-
ture modeling allows us to fully automate the creation and
deployment of co-simulation environments.

C. Whitelist Conﬁguration for Advanced Security

Speciﬁcations for domain-speciﬁc ﬁrewalls and intrusion
detection can be collected directly through the explicit data
model. Thus, whitelists can be created from the data model
and the detection of anomalies and even unknown threads
becomes possible. Possible whitelist conﬁgurations through
our data model include communication (e.g., link quality, rout-
ing, packet ﬂows), authentication (e.g., MAC/IP addresses),
and process data (e.g., control, measurement, plausibility).
Different whitelist strategies can be examined automatically
and comprehensively against different attacks using a co-
simulation environment.

V. CONCLUSION

A reliable operation of smart grids requires accompanying
scientiﬁc studies. To this end, we ﬁrst identiﬁed challenges
in the network planning, co-simulation, and development of
further IT security tools for smart grids (Section II). Intending
to address these challenges, our integrated infrastructure mod-
eling method allows the construction of complex infrastructure
models based on the underlying power grid using a graph-
based approach (Section III). We showcase the applicability
and advantages of our approach using concrete references to
the identiﬁed challenges (Section IV). In contrast to existing
modeling techniques, we provide a way to consistently and
automatically create conﬁgurations and parametrization for co-
simulations and hardware-in-the-loop testbeds. Furthermore,

dependencies and security concepts between the cyber and
energy domain can be directly included in the optimization
of smart grid topologies and conﬁguration. Future work will
deal with the automated creation of more secure network
structures (e.g., VPN, MPLS) in this framework. To conclude,
our work bridges the gap between existing power grid models
and the need to also provide models for the corresponding
ICT infrastructure by automatically deriving ICT infrastructure
models from given power grid models.
ACKNOWLEDGMENTS
This work has partly been funded
by the German Federal Ministry for Economic Affairs and
Energy (BMWi) under project funding reference 0350028.

REFERENCES

[1] D. Bian et al., “Performance evaluation of communication technologies
and network structure for smart grid applications,” IET Communications,
vol. 13, no. 8, 2019.

[2] D. van der Velde et al., “Methods for Actors in the Electric Power
System to Prevent, Detect and React to ICT Attacks and Failures,” in
IEEE ENERGYCon, 2020.

[3] K. Strunz et al., Benchmark Systems for Network Integration of Renew-
able and Distributed Energy Resources. TF C6.04.02: TB 575, 2014.
[4] R. M. Lee et al., “Analysis of the Cyber Attack on the Ukrainian Power

Grid,” E-ISAC, 2016.

[5] C. Steinbrink et al., “CPES Testing with mosaik: Co-Simulation Plan-

ning, Execution and Analysis,” Applied Sciences, vol. 9, no. 5, 2019.

[6] L. Thurner et al., “Pandapower—An Open-Source Python Tool for
Convenient Modeling, Analysis, and Optimization of Electric Power
Systems,” in IEEE Trans. Power Syst., vol. 33, no. 6, 2018.

[7] M. Uslar et al., “Applying the Smart Grid Architecture Model for
Designing and Validating System-of-Systems in the Power and Energy
Domain: A European Perspective,” Energies, vol. 12, no. 2, 2019.
[8] M. Gottschalk et al., The Use Case and Smart Grid Architecture Model

Approach. Springer, 2017.

[9] M. Castro et al., “Modelling the transition to distribution system operator

using the smart grid architecture model,” 2019.

[10] CEN-CENELEC-ETSI Smart Grid Coordination Group, “Smart Grid

Reference Architecture,” 2012.

[11] F. P. Andr´en et al., “Engineering Smart Grids: Applying Model-Driven
Development from Use Case Design to Deployment,” Energies, vol. 10,
no. 3, 2017.

[12] M. Fischinger et al., “Towards a model-centric approach for developing

dependable smart grid applications,” in ICSRS, 2019.

[13] C. Neureiter et al., “Domain speciﬁc and model based systems engineer-
ing in the smart grid as prerequesite for security by design,” Electronics,
vol. 5, no. 2, 2016.

[14] A. Schumilin et al., “A Consistent View of the Smart Grid: Bridging

the Gap between IEC CIM and IEC 61850,” in SEAA, 2018.

[15] B. Lee and D.-K. Kim, “Harmonizing iec 61850 and cim for connectivity

of substation automation,” Comput. Stand. Interfaces, vol. 50, 2017.

[16] F. Andr´en et al., “Towards a Semantic Driven Framework for Smart
Grid Applications: Model-Driven Development using CIM, IEC 61850
and IEC 61499,” Informatik Spektrum, vol. 36, 2013.

[17] A. Koster and X. Muoz, Graphs and Algorithms in Communication

Networks. Springer, 2010.

[18] A. Estebsari et al., “A SGAM-Based Test Platform to Develop a Scheme
for Wide Area Measurement-Free Monitoring of Smart Grids under High
PV Penetration,” Energies, vol. 12, no. 8, 2019.

[19] P. Ponmurugan et al., “Intrusion Detection Strategies in Smart Grid,” in

Design and Analysis of Security Protocol for Communication, 2020.

[20] R. Langner, “Stuxnet: Dissecting a Cyberwarfare Weapon,” IEEE Secu-

rity & Privacy, vol. 9, no. 3, 2011.

[21] J. Kim and L. Tong, “On Topology Attack of a Smart Grid: Undetectable
Attacks and Countermeasures,” IEEE J. Sel. Areas Commun., vol. 31,
no. 7, 2013.

[22] IEC, “Smart Grid Standards Map,” http://smartgridstandardsmap.com/.
[23] K. A. Tin, “Applications of the shortest spanning tree and path on graph

theory,” Algorithms, vol. 1, no. 2, pp. 3–6, 2019.

[24] T. R. Henderson et al., “Network Simulations with the ns-3 Simulator,”

ACM SIGCOMM Demonstration, 2008.

