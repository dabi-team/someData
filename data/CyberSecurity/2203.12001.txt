Mitigating Moral Hazard in Cyber Insurance Using Risk Preference Design

Shutian Liu and Quanyan Zhu

2
2
0
2

r
a

M
2
2

]
T
G
.
s
c
[

1
v
1
0
0
2
1
.
3
0
2
2
:
v
i
X
r
a

Abstract— Cyber insurance is a risk-sharing mechanism
that can improve cyber-physical systems (CPS) security and
resilience. The risk preference of the insured plays an impor-
tant role in cyber insurance markets. With the advances in
information technologies, it can be reshaped through nudging,
marketing, or other types of information campaigns. In this
paper, we propose a framework of risk preference design
for a class of principal-agent cyber insurance problems. It
creates an additional dimension of freedom for the insurer for
designing incentive-compatible and welfare-maximizing cyber
insurance contracts. Furthermore, this approach enables a
quantitative approach to reduce the moral hazard that arises
from information asymmetry between the insured and the
insurer. We characterize the conditions under which the optimal
contract is monotone in the outcome. This justiﬁes the feasibility
of linear contracts in practice. This work establishes a metric
to quantify the intensity of moral hazard and create a theo-
retic underpinning for controlling moral hazard through risk
preference design. We use a linear contract case study to show
numerical results and demonstrate its role in strengthening CPS
security.

I. INTRODUCTION

Recent years have witnessed signiﬁcant advances in the
development and social impacts of Cyber-Physical System
(CPS) technologies, including smart grids, autonomous ve-
hicle systems, and implantable medical devices [1]. CPS
are complex systems integrating various components and
technologies (e.g., Information Technologies and Operational
Technologies) to enable mission-critical functions. As a
result, CPS inherits vulnerabilities from many sources. These
vulnerabilities can be exploited by attackers and inﬂict CPS
users signiﬁcant losses, and they are hard to eliminate. There
is a crucial need to reduce the risk of CPS users and increase
the resiliency in face of attacks.

Cyber insurance is a ﬁnancial product that transfers cyber
risks between the insurer and the insured. Complementary to
cyber protection/defense mechanisms, it aims to improve the
cyber resiliency of a system by mitigating the ﬁnancial losses
as a result of successful attacks. Cyber insurance involves a
contractual agreement that determines the premium and the
coverage of the insurance contract. The premium is an amount
of fee paid by the insured to the insurer to participate in the
insurance program. The coverage speciﬁes the amount of loss
the insurer will cover. With a properly designed contract, the
security of CPS users can beneﬁt from cyber insurance.

One design framework for cyber insurance relies on
a class of principal-agent models [2], which capture the
information asymmetry between the insurer and the insured.
The asymmetry leads to the moral hazard phenomenon [3] in
which the insured users tend to behave more recklessly when
interacting with the system and result in severe consequences.

Risk aversion plays an important role in moral hazard. It is
known that risk-averse behaviors of the user can increase
the gap between the principal’s proﬁts obtained from the
contract with the full observability of the user’s action and the
contract when the user’s action is hidden. This phenomenon
is absent when the insurer meets a risk-neutral user [4].
Hence, measuring the level of risk aversion is essential in
investigating the effect of moral hazard on cyber insurance.
Risk measure [5] provides a convenient way to quantify
the risks and model agents’ risk perception or preferences.
Different from the risk described under the expected utility
theory, risk measure is richer in capturing individual percep-
tions of risks induced by the probabilistic nature of random
outcomes. The design of risk measure is a way to control
the risk preferences of the agents using exogenous inﬂuences
such as nudging, marketing, and propaganda [6], [7].

Fig. 1: Risk Preference Design Framework for Cyber In-
surance: An insurer aims to reshape the risk perception of
the users and design incentive-compatible cyber insurance
contracts. The loss from the cyber risks is covered by the
insurer after an active defense from the insured user.

This work aims to propose, as shown in Fig. 1, a risk
preference design framework to shape the users’ risk pref-
erences for high-performance cyber insurance. We consider
a class of principle-agent problems in which one principal
meets an idiosyncratic individual from a population of agents.
Each agent has a risk preference type associated with an
idiosyncratic risk measure. The goal of the design aims to
optimize the proﬁt of the insurer. We formulate the problem
as a bilevel optimization problem. In the upper-level insurer’s
problem, the insurer optimizes her proﬁt by offering a contract
and performing risk preference design subject to participation
constraints. In the lower-level user’s problem, the user follows
the claimed contract under the chosen risk preference.

Using the risk preference design framework, we charac-
terize the solution to the insurer’s problem by imposing
the conditions under which the optimal contract exhibits
monotonicity. This paves the way for considering linear

 
 
 
 
 
 
contracts in practice. We quantify the Intensity of Moral
Hazard (IMH) by benchmarking the action of the user
from solving his problem with the action obtained from
the full-information counterpart of the insurer’s problem.
Leveraging the optimality conditions of the contract problems,
we quantify how IMH varies according to the change in the
risk preference type distributions. This analysis enables the
risk preference design for mitigating moral hazard and creates
a revenue-compatible design for the principal. In the case
study, we use linear contracts as an example to show that
risk preference design reduces moral hazard and improves
security.

Section II provides a brief literature review. Section III
introduces risk preference types and formulates the design
problem. Section IV analyzes the optimal contract and the
proposed approach to quantify moral hazard. Section V
contains a case study. Section VI concludes the paper.

II. RELATED WORKS

One of the classic approaches to model risk perception
relies on the expected utility theory of [8], where decisions of
the players or the agents are assumed to maximize their utility.
The concept is extended in [9] and [10] to the well-known
Arrow-Pratt measure of absolute risk aversion. Another related
approach is the cumulative prospect theory of [11], where the
probability of the random outcomes is weighted. Motivated
by the cumulative prospect theory, we use risk measures
to capture individual risk preferences. The seminal work
[5] has proposed to adopt coherent risk measures (CRMs)
for risk quantiﬁcation. The axioms that a CRM satisﬁes
not only make it meaningful in practice but also enables
the dual representation [5], [12]. This representation shows
the robustness of a CRM and connects it with the popular
distributionally robust optimization [13].

Risk design is closely related to system robustness [14].
Risk design in cyber insurance elicits human behaviors
that have an impact on cyber security and resilience. In
[15], the authors have proposed a pre-screening method to
increase network security by designing incentive contract
which increases users’ effort levels. In [16], the authors
have have shown that an increased level of risk aversion
increases the social welfare gain from using cyber insurance
for protection. This work aims to consolidate the design
of risk preferences of users into cyber insurance to further
mitigate cyber risks.

III. PROBLEM FORMULATION

In this section, we introduce the framework of cyber
insurance with risk preference design. We present the concept
of risk preference types to model different perceptions of
risks in connection with a class of principal-agent problems.

A. Risk preference types

Consider a mass 1 population of users of networked
systems. This population faces uncertainties that arise from
cyber risks captured by the probability space (Ξ, F ) with
the reference probability measure P. We use ξ ∈ Ξ ⊂ R to

denote a sampled outcome. We denote by Z : Ξ → R a random
loss, where Z is a measurable function with ﬁnite p-th order
moment from the space Z := Lp(Ξ, F , P). The parameter
p lives in [1, +∞). Individuals in this population possess
different risk preferences toward uncertainty. In particular,
each individual is identiﬁed with a risk preference type
θ ∈ Θ ⊂ R. A risk preference of type θ determines the way
user’s perception of risks, and it is captured by a risk measure
ρθ : Z → R.

Let (Θ, G ) denote the underlying probability space of risk
preference types. The risk preference types in the population
are distributed according to a probability measure µ 0 from the
set of probability measures Q deﬁned on (Θ, G ). Note that, in
practice, µ 0 can be known by collecting information through
questionnaires or analyzing historical customer behaviors.

The goal of risk preference design is to ﬁnd a distribution
µ ∈ Q so that incentive contracts can be created between
the users and the insurer to cover potential losses due to
users’ cyber risks. We consider designing the distribution of
risk preferences owing to the following three reasons. First,
the utility of the insurer is measured by the outcome of
a population of users participating in the contract. Hence
the expected utility captures the incentives of the insurer.
Second, it is difﬁcult to design customized contracts as
precise individual user’s risk perception is hard to measure.
The collective pattern of the users of the same type can be
statistically measured. Third, this distributional perspective
can be endowed with an interpretation that the insurer and the
same user interact repeatedly for a sufﬁciently long period
of time. We will elaborate this point further in Section III-B.
We assume that the risk measures ρθ for all θ ∈ Θ are
CRMs [5]. Below is the deﬁnition of coherent risk measures.
Deﬁnition 1 (Coherent Risk Measures [5]): A function
ρ : Z → R is called a Coherent Risk Measure if it satisﬁes
(A1) Monotonicity: ρ(Z) ≥ ρ(Z(cid:48)) if Z, Z(cid:48) ∈ Z and Z (cid:23) Z(cid:48).
(A2) Convexity: ρ(tZ + (1 − t)Z(cid:48)) ≤ tρ(Z) + (1 − t)ρ(Z(cid:48)) for
all Z, Z(cid:48) ∈ Z and t ∈ [0, 1].
(A3) Translation equivariance: If Z ∈ Z and a ∈ R, then
ρ(Z + a) = ρ(Z) + a.
(A4) Positive homogeneity: ρ(tZ) = tρ(Z) if Z ∈ Z and
t ∈ R+.

One of the most signiﬁcant consequences of CRMs is
their dual representation [5], [12]. Let Z ∗ := Lq(Ξ, F , P)
for q ∈ (1, ∞] denote the dual space of Z , i.e., 1
q = 1.
Following [5], [12], the dual representation of ρθ is

p + 1

(cid:90)

ρθ [Z(ξ )] = sup
ζ ∈Aθ

Z(ξ )ζ (ξ )dP(ξ , x),

(1)

Ξ
where Aθ ⊂ Z ∗ denotes the dual set associated with the
risk measure ρθ . The set Aθ is convex and compact when
p ∈ [1, +∞) [17]. Hence, the maximum of (1) is attained.

B. Cyber Insurance with Risk Preference Design

We incorporate the risk preference types discussed in
Section III-A into a principal-agent problem by specifying the
following action-outcome relation. Consider a principal-agent
problem with one principal and one agent. Let x ∈ X denote
the agent’s action, which represents the amount of security

investment that he spends on his device. We set Ξ := [ξ , ¯ξ ]
and identify it as the set of random cyber risks which affect the
costs of both the principal and the agent. The parameterized
probability measure P(ξ , x) describes the stochastic relation
between the cyber risk and the security investment. We assume
that for all x ∈ X, P(ξ , x) is absolutely continuous with the
reference probability measure P(ξ ), i.e., there is a density
function p(ξ , x) such that dP(ξ , x) = p(ξ , x)dP(ξ ). And we
assume that p(·, x) is differentiable for all x ∈ X and p(ξ , ·)
is continuously differentiable for all ξ ∈ Ξ.

The insurer acts as the principal in the problem. She
has the power of claiming a coverage plan of the cyber
losses described by the function w(·) : Ξ → Ξ and choosing
a distribution of risk preference types µ ∈ Q for the users.
For a given cyber risk ξ , she observes cost (or negative
proﬁt) w(ξ ) + ξ . We assume that the insurer is risk-neutral.
Hence, her expected cost from claiming a plan w(·) is
(cid:82)
Ξ w(ξ ) + ξ dP(ξ , x). The manipulation of risk preferences
can come with a cost. We introduce the order-1 Wasserstein
distance [18] W1(µ, µ 0) to represent the cost associated with
the effort to change the risk preference distribution from µ 0
to µ. The cost of the insurer in designing w(·) and µ is

(cid:90)

Ξ

w(ξ ) + ξ dP(ξ , x) + γW1(µ, µ 0),

(2)

where γ > 0 represents the monetary cost of risk manipulation.
Consider a user with type θi. If he takes action xi under
plan w(·), the cyber risk that he perceives is ρθi[U(w(ξ ), xi)]
with the random cost U ∈ Z . We assume that U is increasing
and convex in w, which indicates that the users exhibit
loss aversion. Note that since U can be understood as a
disutility function, our assumptions on U are consistent with
the assumptions that a utility function is non-decreasing and
concave. In the literature, these assumptions are often referred
to as ’risk aversion’ [2]. We use the term loss aversion to
distinguish it from risk preferences represented by the risk
measures ρθ . Our treatment of risk is motivated by [11], where
the authors combine the loss aversion and the probability
weighting to characterize decisions under risk.

The agent is assume to be an idiosyncratic individual from
the population of users who bears the averaged action x.
When the type distribution is µ, the cost of the agent is

(cid:90)

Θ

ρθ [U(w(ξ ), x)]dµ(θ ).

(3)

Note that in (3), the randomness is addressed by the risk
measures ρθ ; the integral over Θ represents an averaging over
all the risk preference which generates the averaged action x.
¯U > 0 denote the deterministic cyber risk threshold
that the agent can bear. The hidden action cyber insurance
problem with risk-preference design is formulated as follows:

Let

min
w(·),µ(·),x

s.t.

(cid:90)

Ξ

(cid:90)

Θ

w(ξ ) + ξ dP(ξ , x) + γW1(µ, µ 0)

ρθ [U(w(ξ ), x)]dµ(θ ) ≤ ¯U, (IR),

x ∈ arg min

x(cid:48)∈X

(cid:90)

Θ

ρθ [U(w(ξ ), x(cid:48))]dµ(θ ), (IC).

compatibility constraint stating that the agent should minimize
his own cost when his action is hidden.

The main difference between (4) and the classical principal-
agent problems is that
the distribution µ characterizing
the distribution of risk preferences of the users becomes
part of the design, offering a new degree of freedom to
model the informational inﬂuences on the users and create
additional control to elicit proper cyber hygiene of the users
and, at the meantime, improve the social welfare and the
proﬁt. Furthermore, as we will show in Section IV, the risk
preference design mitigates the moral hazard issue.

IV. ANALYSIS OF THE DESIGN FRAMEWORK

A. Characterization of Optimal Contracts

In this section, we use the ﬁrst-order approach to charac-
terize several properties of the optimal coverage plan for the
contract problems deﬁned in Section III. We obtain conditions
for the monotonicity of w(·).

Consider the ﬁrst-order optimality condition of (IC):

∂
∂ x

(cid:90)

Θ

ρθ [U(w(ξ ), x)]dµ(θ ) = 0.

(5)

We assume that the set of density functions which attains
i.e.,
the maximum of (1) is a singleton for all θ ∈ Θ,
∂ ρθ [U(w(ξ ), x)] = { ¯ζθ (ξ , x)}. Then, (5) leads to

0 =

=

∂
∂ x
∂
∂ x

(cid:90)

(cid:90)

Θ

(cid:90)

Ξ
(cid:18)(cid:90)

Ξ

Θ

U(w(ξ ), x) ¯ζθ (ξ , x)p(ξ , x)dP(ξ )dµ(θ )

(cid:19)
¯ζθ (ξ , x)dµ(θ )

U(w(ξ ), x)p(ξ , x)dP(ξ ).

(6)

Ignoring the second-order optimality condition of (IC), we
ﬁnd (6) as an alternative for the (IC) in (4).

The Lagrangian of problem (4) when (IC) is substituted by
the ﬁrst-order condition (6) can be expressed as the following:

w(ξ ) + ξ dP(ξ , x) + γW1(µ, µ 0)
Ξ
(cid:90)

ρθ [U(w(ξ ), x)]dµ(θ ) − ¯U
(cid:90)

(cid:90)

L =

+ α

+ β

Θ
∂
∂ x

Θ

Eµ [ ¯ζθ (ξ , x)]U(w(ξ ), x)p(ξ , x)dP(ξ )dµ(θ ).

(7)

Deﬁne π(ξ , θ , x) = ¯ζθ (ξ , x)p(ξ , x). Minimizing w(ξ ) point-
wise in ξ , we obtain the ﬁrst-order condition of (7) for ξ ∈ Ξ:

− p(ξ , x) = Eµ

(cid:26)

απ(ξ , θ , x)

∂
∂ w

U(w(ξ ), x)

+ β

∂
∂ w

(cid:18)

π(ξ , θ , x)

∂
∂ x

U(w(ξ ), x) +U(w(ξ ), x)

π(ξ , θ , x)

(cid:19) (cid:27)
.

∂
∂ x

(8)
Before we proceed, we make the assumption that
∂ 2
∂ x∂ wU(w(ξ ), x) = 0. Note that this assumption is weaker
than the one that the agent’s cost is separable in the security
investment and the gain from the coverage plan in the
cyber insurance contract. After several steps of algebraic
manipulations, (8) leads to

In (4), (IR) is the individual rationality constraint guaranteeing
that participation beneﬁts the agent; (IC) is the incentive

=

∂
∂ w

U(w(ξ ), x) · Eµ

(4)

− p(ξ , x)
(cid:26)

= Eµ

απ(ξ , θ , x)

U(w(ξ ), x) + β

U(w(ξ ), x)

∂
∂ w

(cid:26)

∂
∂ w
∂
∂ x

∂
∂ x
(cid:27)

(cid:27)

π(ξ , θ , x)

(9)

απ(ξ , θ , x) + β

π(ξ , θ , x)

.

Dividing both sides of (9) by p(ξ , x) ∂

∂ wU(w(ξ ), x), we obtain

−1
∂
∂ wU(w(ξ ), x)
(cid:40)

= Eµ

α ¯ζθ (ξ , x) + β

(cid:32)

∂
∂ x

¯ζθ (ξ , x) + ¯ζθ (ξ , x)

(cid:33)(cid:41)

∂
∂ x p(ξ , x)
p(ξ , x)

= Eµ

(cid:8) ¯ζθ (ξ , x)(cid:9) ·

(cid:32)

α + β

(cid:33)

∂
∂ x p(ξ , x)
p(ξ , x)

+ β Eµ

(cid:26) ∂
∂ x

(cid:27)

¯ζθ (ξ , x)

.

(10)
Differentiating with respect to ξ over ¯Ξ on both sides of (10),
we obtain

w(cid:48)(ξ ) · ∂ 2
(cid:16) ∂

∂ w2 U(w(ξ ), x)

(cid:17)2 = β

∂
∂ ξ

Eµ

(cid:26) ∂
∂ x

(cid:27)

¯ζθ (ξ , x)

∂ wU(w(ξ ), x)
(cid:40)

+

∂
∂ ξ

(cid:32)

Eµ [ ¯ζθ (ξ , x)] ·

α + β

(11)

∂
∂ x p(ξ , x)
p(ξ , x)

(cid:33)(cid:41)

.

The above discussions lead to the following result, which
characterizes the monotonicity of the optimal coverage plan.
Proposition 1: Suppose that the density function ¯ζθ (·, x) is
differentiable on a subset ¯Ξ ⊂ Ξ. Then, the optimal coverage
plan w of (4) is increasing in the cyber risk on ¯Ξ, i.e.,
w(cid:48)(ξ ) ≥ 0, if the following conditions hold:
(C1) The functions p(ξ , x) and
(cid:82)
Ξ p(ξ , x)dξ > 0 and ∂
∂ x
(C2) Severe loss avoidance:

satisfy
¯ζθ (ξ , x)dξ > 0, respectively;

¯ζθ (ξ , x)

(cid:82)
Ξ

∂
∂ x

∂
∂ ξ

Eµ

(cid:26) ∂
∂ x

(cid:27)

¯ζθ (ξ , x)

≥ 0;

(C3) Risk-sensitive monotone likelihood ratio property:

(cid:40)

(cid:32)

Eµ [ ¯ζθ (ξ , x)] ·

α + β

(cid:33)(cid:41)

∂
∂ x p(ξ , x)
p(ξ , x)

≥ 0.

∂
∂ ξ

Proof: By combining (C1) with the convexity of U with
respect to w, we can show β > 0 using the similar arguments
as in [3]. When (C2) and (C3) hold, the optimality condition
(11) leads to the monotonicity of w.

The conditions in Proposition 1 have the following interpre-
tations. Condition (C1) implies two facts. First, without taking
the user’s risk preference into account, the true likelihood
for higher cyber risks to occur decreases when the security
investment increases. Second, the perceived likelihood for
higher cyber risks to occur of a user with risk preference type
θ is decreased when the security investment increases. These
two facts are consistent within the cyber insurance context.
Before we elaborate on condition (C2), we ﬁrst observe the
following fact. Since the coverage plan w is increasing in the
cyber risk ξ and the cost U is increasing in w, we conclude
that U is also increasing in ξ . In addition, from (1), we
know that for all θ the optimal density function ¯ζθ (ξ , x) is
¯ζθ (ξ , x) > 0. Then, condition (C2)
increasing in ξ , i.e.,
means that an increase in the user’s security investment
shows his panic towards the potential occurrences of severer
cyber risks. In other words, the user tries to avoid severe
losses. Condition (C3) is the risk-sensitive counterpart of the
monotone likelihood ratio property:
(cid:33)

∂
∂ ξ

(cid:32) ∂

∂
∂ ξ

∂ x p(ξ , x)
p(ξ , x)

≥ 0.

(12)

ratio property for some commonly used CRMs, such as the
mean semideviation measure and the average value-at-risk
measure [12]. The reason lies in that the density function
¯ζθ (ξ , x) of these two measures is piecewise constant. It means
that the right-hand side of (11) becomes

Eµ [ ¯ζθ (ξ , x)] ·

(cid:32)

α + β

∂
∂ x p(ξ , x)
p(ξ , x)

(cid:33)

.

∂
∂ ξ

Then, we can recover (12).

B. Mitigation of moral hazard

It is well-known from the literature that one of the causes
of moral hazard is the issue of hidden action; i.e., the insurer
cannot observe the action taken by the insured. In this section,
we propose to measure the IMH and provide a method to
mitigate moral hazard. For notational simplicity, we consider
an n-dimensional ﬁnite risk preference type space Θ =
{θ1, θ2, ..., θn} with probability measure µ = (µ1, µ2, ..., µn)T .
a) Measuring the IMH: We ﬁrst consider the following
full-information benchmark associated with (4) assuming that
the risk preference distribution µ is given:

min
w(·),x

s.t.

(cid:90)

Ξ
n
∑
i=1

w(ξ ) + ξ dP(ξ , x) + γW1(µ, µ 0)

ρθi [U(w(ξ ), x)] · µi ≤ ¯U, (IR).

(13)

Let w∗ and x∗ denote the optimal solution of (13) given µ.
The Lagrangian of (13) is

Lb =

(cid:90)

Ξ

(w(ξ ) + ξ )p(ξ , x)dP(ξ ) + γW1(µ, µ 0)
(cid:32) n
∑
i=1

ρθi [U(w(ξ ), x)] · µi − ¯U

(cid:33)

.

+ α

Then, the action x∗ solves

0 =

∂
∂ x

Lb =

∂
∂ x

+ α

(cid:90)

Ξ
∂
∂ x

(w∗(ξ ) + ξ )p(ξ , x)dP(ξ )

n
∑
i=1

ρθi [U(w∗(ξ ), x)] · µi.

(14)

(15)

Hidden actions refer to the fact that x∗ will not be the real
action taken by the agent after receiving w∗ announced by
the principal. From the agent’s perspective, an action xa
optimizing his own objective is superior, i.e., xa such that

xa ∈ arg min

x∈X

n
∑
i=1

ρθi [U(w∗(ξ ), x)] · µi.

(16)

Therefore, the deviation from x∗ to xa is the result of the
moral hazard issue and x∗ − xa is a meaningful metric for
measuring the IMH. The value of x∗ − xa is nonnegative
because of the assumptions made in Section III.

Deﬁnition 2: We refer to the quantity x∗ − xa as the IMH.

A high value of x∗ − xa indicates an intense moral hazard.

Note that the conditions for proving monotonicity on ¯Ξ can
reduce to simply (C1) and the standard monotone likelihood

Note that (16) is part of the IC constraint in (4). However,

the actions solving (4) and 16 are different in general.

b) Mitigation of moral hazard through risk preference
design: We study how IMH varies according to the changes in
µ. From (16), xa satisﬁes the following ﬁrst-order condition:

∂
∂ x

n
∑
i=1

ρθi [U(w∗(ξ ), x)] · µi = 0.

(17)

Deﬁne H1 : X × Q → R and H2 : X × Q → R according to

H1(x, µ) =

∂
∂ x

Lb,

(18)

as in (15), and

H2(x, µ) =

∂
∂ x

n
∑
i=1

ρθi [U(w(ξ ), x)] · µi.

(19)

as in (17), respectively. Then, we obtain from (15) and (17)
that, for a given µ, H1(x∗, µ) = 0 and H2(xa, µ) = 0.

The next result states how to reduce IMH by designing

the distribution of risk preference types.

Proposition 2: Let x∗ and xa denote the isolated local
minima of (13) and (16) given µ, respectively. Let JH1,x denote
the Jacobian matrix of H1 with respect to the ﬁrst argument;
let JH2,x denote the Jacobian matrix of H2 with respect to the
ﬁrst argument. Then, in a neighborhood Nµ ⊂ Q of µ, the
IMH can be reduced by changing µ to µ (cid:48) = µ + c∆µ with
c > 0 sufﬁciently small, if ∆µ satisﬁes

(∆µ)T · ∇T (µ) ≤ 0,

where ∇T (µ) = ( ∂ T
∂ µ1

(µ), ∂ T
∂ µ2

(µ), ..., ∂ T
∂ µn

(µ))T with

∂ T
∂ µi

(µ) = (cid:0)JH2,x(xa, µ)(cid:1)−1 ∂ H2
∂ µi
− (cid:0)JH1,x(x∗, µ)(cid:1)−1 ∂ H1
∂ µi

(xa, µ)

(x∗, µ),

(20)

(21)

for all i = 1, 2, ..., n.

Lb (cid:31) 0 and ∂ 2

Proof: Consider the optimization problems (13) and (16).
Since x∗ and xa are local minima, the ﬁrst-order conditions
hold, i.e., H1(x∗, µ) = 0 and H2(xa, µ) = 0. Since the local
minima x∗ and xa are isolated, the second-order conditions
require that ∂ 2
∂ x2 ∑n
i=1 ρθi[U(w(ξ ), x)] · µi (cid:31) 0.
∂ x2
Equivalently, we obtain JH1,x(x∗, µ) (cid:31) 0 and JH2,x(xa, µ) (cid:31) 0.
Invoking the implicit function theorem, we know that there
exists differentiable functions h1(·) and h2(·) deﬁned on
neighborhoods Vx∗ × V 1
µ of (xa, µ),
such that h1(µ) = x∗ and h2(µ) = xa. Furthermore,
the
derivatives of the functions h1(·) and h2(·) with respect to
µi for all i = 1, 2, ..., n are

µ of (x∗, µ) and Vxa × V 2

∂ h1
∂ µi

(µ) = − (cid:0)JH1,x(h1(µ), µ)(cid:1)−1 ∂ H1
∂ µi

(h1(µ), µ),

(22)

and

∂ h2
∂ µi

(µ) = − (cid:0)JH2,x(h2(µ), µ)(cid:1)−1 ∂ H2
∂ µi

(h2(µ), µ),

(23)

respectively. Let Nµ = V 1
µ ∩ V 2
µ . Deﬁne T (µ) = h1(µ) −
h2(µ) with support Nµ . Then, the quantity x∗ − xa can be
represented using T (µ) for µ ∈ Nµ . The gradient ∇T (µ) =
( ∂ T
(µ))T follows from (22) and (23) for
∂ µi
µ ∈ Nµ . Next, consider T (µ (cid:48)), which represents the IMH
when the distribution of risk preference is µ (cid:48) = µ + c∆µ.
Taylor’s theorem indicates that:

(µ), ..., ∂ T
∂ µn

(µ), ∂ T
∂ µ2

T (µ (cid:48)) = T (µ) + c(∆µ)T · ∇T (µ) + o(c).

For sufﬁciently small c > 0, condition (20) leads to T (µ (cid:48)) ≤
T (µ). This completes the proof.

Obtaining the value of IMH relies on solving problems
(16) and (13). However, Proposition 2 offers a method to
check whether a target distribution of risk preference types
mitigates the effect of the moral hazard.

c) Design methods: We have shown that the IMH can
be mitigated by risk preference design. Next, we show that
the direction ∆µ in 20 can decrease the objective value of
(13), making µ (cid:48) = µ + c∆µ a favorable design.

Before stating the results, we ﬁrst present an equivalent rep-
resentation of W1(µ, µ 0). Since we consider ﬁnite probability
measures, strong duality holds in the Kantorovich-Rubinstein
dual problem [18] of W1(µ, µ 0), i.e.,

W1(µ, µ 0) = max
b∈B

n
∑
i=1

biµi −

n
∑
i=1

biµ 0
i ,

(24)

where B = {b ∈ Rn : |bi − b j| ≤ |i − j|, ∀i, j = 1, 2, ..., n}.

Proposition 3: For a given µ, let ∇T (µ) be deﬁned as in
Proposition 2. Let b∗ ∈ Rn denote the solution to (24). Then,
there exists ∆µ, such that by changing µ to µ (cid:48) = µ + c∆µ,
the IMH and the objective cost of (13) decrease, if there does
not exist a > 0, such that

− ab∗ = ∇T (µ).

(25)
Proof: Since in the objective function of (13), the only
term depending on µ is W1(µ, µ 0), we only need to show that
W1(µ (cid:48), µ 0) ≤ W1(µ, µ 0) for µ (cid:48) = µ + c∆µ. Equivalently, we
show that ∆µ is a descent direction of W1(µ, µ 0). To obtain
the descent direction, we compute the gradient of W1(µ, µ 0)
using the representation (24). Since (24) is an optimization
problem, the envelope theorem indicates that

∇µW1(µ, µ 0) = ∇µ

(cid:32) n
∑
i=1

b∗
i µi −

n
∑
i=1

(cid:33)

b∗
i µ 0
i

= b∗,

(26)

where b∗ solves (24). Then, ∆µ descends W1(µ, µ 0) if

(∆µ)T · b∗ ≤ 0.

(27)

From Proposition 2, we know that changing µ to µ (cid:48) mitigates
the IMH if ∆µ satisﬁes condition (20). Hence (20) and (27)
lead to the condition (25). This completes the proof.

The results in Proposition 2 and Proposition 3 lead to
strengthened security for the following reasons. A lower
value of the IMH indicates a smaller difference in the action
ideal for the insurer and the action the user chooses in reality.
It means that there is an increased likelihood to sign a contract
where the agreed action generates a reasonable amount of
cyber risk that the insurer can bear, and it is not overly
challenging for the user to execute. Furthermore, to come
up with such a contract, the insurer needs to prepare for the
consumption required for shaping the users’ perceptions. Once
the cost of risk design and the cost of coverage do not exceed
the payment from the user, a contractual agreement which
improves cyber security can be reached. We will elaborate
on this point in Section V.

V. CASE STUDY: LINEAR CONTRACTS

In this section, we use a special case study of linear
contracts to show that risk preference design strengthens
cyber security. We consider a scenario where an attacker

arming the insurer with an additional dimension of freedom
to provide incentive-compatible contracts. Using the proposed
measure for moral hazard, we have shown analytically that
risk preference design can not only mitigate the moral hazard
issue but also enhance the overall security of the system.

The structure of our framework is essentially a bilevel
programming problem. These problems are hard to solve due
to their structural complexity. For future work, we would
investigate representations of risk measures to simplify the
risk preference design problem. This effort could lead to
the equivalents of the agent’s problem, enabling single-level
reformulations of the bilevel programming problem.

REFERENCES

[1] A. Humayed, J. Lin, F. Li, and B. Luo, “Cyber-physical systems
security—a survey,” IEEE Internet of Things Journal, vol. 4, no. 6, pp.
1802–1831, 2017.

[2] S. J. Grossman and O. D. Hart, “An analysis of the principal-agent
problem,” in Foundations of insurance economics. Springer, 1992,
pp. 302–340.

[3] B. Holmstr¨om, “Moral hazard and observability,” The Bell journal of

economics, pp. 74–91, 1979.

[4] H. Chade and V. N. V. De Serio, “Risk aversion, moral hazard, and
the principal’s loss,” Economic Theory, vol. 20, no. 3, pp. 637–644,
2002.

[5] P. Artzner, F. Delbaen, J.-M. Eber, and D. Heath, “Coherent measures
of risk,” Mathematical ﬁnance, vol. 9, no. 3, pp. 203–228, 1999.
[6] P. Slovic and E. Peters, “Risk perception and affect,” Current directions

in psychological science, vol. 15, no. 6, pp. 322–325, 2006.

[7] P. Slovic, “The construction of preference.” American psychologist,

vol. 50, no. 5, p. 364, 1995.

[8] O. Morgenstern and J. Von Neumann, Theory of games and economic

behavior. Princeton university press, 1953.

[9] K. J. Arrow, “The theory of risk aversion,” Essays in the theory of

risk-bearing, pp. 90–120, 1971.

[10] J. W. Pratt, “Risk aversion in the small and in the large,” in Uncertainty

in economics. Elsevier, 1978, pp. 59–79.

[11] A. Tversky and D. Kahneman, “Advances in prospect theory: Cumu-
lative representation of uncertainty,” Journal of Risk and uncertainty,
vol. 5, no. 4, pp. 297–323, 1992.

[12] A. Ruszczy´nski and A. Shapiro, “Optimization of convex risk functions,”
Mathematics of operations research, vol. 31, no. 3, pp. 433–452, 2006.
[13] A. Shapiro, “Distributionally robust stochastic programming,” SIAM
Journal on Optimization, vol. 27, no. 4, pp. 2258–2275, 2017.
[14] S. Liu and Q. Zhu, “Robust and stochastic optimization with a hybrid
coherent risk measure with an application to supervised learning,” IEEE
Control Systems Letters, vol. 5, no. 3, pp. 965–970, 2020.

[15] M. M. Khalili, P. Naghizadeh, and M. Liu, “Designing cyber insurance
policies: The role of pre-screening and security interdependence,” IEEE
Transactions on Information Forensics and Security, vol. 13, no. 9, pp.
2226–2239, 2018.

[16] D. Kuru and S. Bayraktar, “The effect of cyber-risk insurance to social

welfare,” Journal of Financial Crime, 2017.

[17] A. Shapiro, D. Dentcheva, and A. Ruszczynski, Lectures on stochastic

programming: modeling and theory. SIAM, 2021.

[18] C. Villani, Optimal transport: old and new. Springer, 2009, vol. 338.
[19] Y. Ge and Q. Zhu, “Accountability and insurance in iot supply chain,”

arXiv preprint arXiv:2201.11855, 2022.

[20] Q. Zhu, “Cyber insurance,” arXiv preprint arXiv:1810.00290, 2018.

infects a network with ransomware [19]. The network users
can defend against the attacker by upgrading their ﬁrewalls to
decrease the number of ﬁles locked by the ransomware. This
reduces the amount of ransom to pay at a cost of a system
upgrade. The users can also buy cyber insurance to cover a
portion of their loss by prepaying a premium.

Consider two risk preference types where θ1 represents the
expectation measure, i.e., ρθ1[Z] = E[Z], and θ2 represents the
absolute semideviation measure [17] with parameter κ > 0,
i.e., ρθ2[Z] = E[Z] + κE{[Z − E[Z]]+}. The original distribu-
tion of types is µ 0 = (µ 0
2 ). We consider two available
system upgrade investments X = {xL, xH } with xL < xH and
three possible losses due to the ransomware (ξ1, ξ2, ξ3) =
(1, 2, 3). The probability of (ξ1, ξ2, ξ3) is (0.3, 0.4, 0.3) under
xL and (0.5, 0.3, 0.2) under xH . Note that this indicates that
when the security investment increases, there is a lower
likelihood for more severe losses to occur.

1 , µ 0

The insurer offers a linear contract containing a coverage
c ∈ (0, 1) with a premium p > 0. Her expected cost from this
contract is E[cξ − p]. Since c ∈ (0, 1), she prefers the high
investment xH to the low investment xL from the user. We
set the user’s loss aversion to be quadratic; i.e., he perceives
ξ 2 when the cyber loss is ξ . The relative cost of investment
is m > 0. If the user does not buy insurance, he receives
the full cyber loss ξ without any coverage from the insurer.
The cost for the user is ¯U(x) = ∑i=1,2 µ 0
i · ρθi[ξ 2 + mx]. If he
purchases the insurance, the cost becomes ˜U(x) = ∑i=1,2 µ 0
i ·
ρθi[((1 − c)ξ )2 + mx + p].

Suppose m(xH − xL) > 1.1c2 + 0.6κc2µ 0

2 . Then, ˜U(xH ) >
˜U(xL). From (IC) of (4), we know that the user will only agree
on xL in a contract. The moral hazard issue occurs because
of the distinction between the insurer’s and user’s preferences
over the security investments. Note that participating in the
contract is proﬁtable if p ≤ (2c − c2) · (3.5 + 1.25κ µ 0

2 ).

With risk preference design, it is straightforward to observe
that as long as we increase the portion of type θ2 to µ2 such
that m(xH − xL) < 1.1c2 + 0.6κc2µ2, the user prefers xH to xL.
It means that by designing the distribution of risk preference
types so that more individuals evaluate risk according to the
absolute semideviation measure, the moral hazard issue can be
mitigated. One of the features of the absolute semideviation
measure is that it emphasizes the high impact outcomes
in spite of their low possibilities. Hence, a user adopting
this perception of risk shows aversion toward severe system
losses caused by ransomware. The consequence of this risk
preference design is that a reached contract elicits a high-level
security effort from the user to protect the system. It not only
enables risk sharing between the user and the insurer but also
enhances the overall defense against ransomware.

VI. CONCLUSION

In this paper, we have proposed cyber insurance with
a risk preference design framework to provide risk-sharing
contracts for cyber-physical systems security. We have deﬁned
risk preference types for users and adopted risk measures to
capture their perceptions of cyber losses. We have made the
distribution of the types a design parameter in the framework,

