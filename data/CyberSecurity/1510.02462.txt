Secure State Estimation against Sensor Attacks in
the Presence of Noise

Shaunak Mishra, Yasser Shoukry, Nikhil Karamchandani, Suhas Diggavi and Paulo Tabuada

1

5
1
0
2

t
c
O
2
1

]

C
O
.
h
t
a
m

[

2
v
2
6
4
2
0
.
0
1
5
1
:
v
i
X
r
a

Abstract—We consider the problem of estimating the state of
a noisy linear dynamical system when an unknown subset of
sensors is arbitrarily corrupted by an adversary. We propose a
secure state estimation algorithm, and derive (optimal) bounds
on the achievable state estimation error given an upper bound
on the number of attacked sensors. The proposed state estimator
involves Kalman ﬁlters operating over subsets of sensors to search
for a sensor subset which is reliable for state estimation. To
further improve the subset search time, we propose Satisﬁability
Modulo Theory based techniques to exploit the combinatorial
nature of searching over sensor subsets. Finally, as a result of
independent interest, we give a coding theoretic view of attack
detection and state estimation against sensor attacks in a noiseless
dynamical system.

I. INTRODUCTION

Securing cyber-physical systems (CPS) is a problem of
growing importance as the vast majority of today’s critical
infrastructure is managed by such systems. In this context,
it is crucial to understand the fundamental limits for state
estimation, an integral aspect of CPS,
in the presence of
malicious attacks. With this motivation, we focus on securely
estimating the state of a linear dynamical system from a
set of noisy and maliciously corrupted sensor measurements.
We restrict the sensor attacks to be sparse in nature, i.e., an
adversary can arbitrarily corrupt an unknown subset of sensors
in the system but is restricted by an upper bound on the number
of attacked sensors.

Several recent works have studied the problem of secure
state estimation against sensor attacks in linear dynamical
systems. For setups with no noise in sensor measurements,
the results reported in [2], [3], [4] show that, given a strong
notion of observability, (sparse) sensor attacks can always be
detected and isolated, and we can exactly estimate the state
of the system. However, with noisy sensors, it is not trivial to
distinguish between the noise and the attacks injected by an
adversary. Prior work on state estimation with sensor attacks
in the presence of noise can be broadly divided into two
categories depending on the noise model: 1) bounded non-
stochastic noise, and 2) Gaussian noise. Results reported in
[5], [6], [7] deal with bounded non-stochastic noise. Though
they provide sufﬁcient conditions for distinguishing the sparse

S. Mishra, Y. Shoukry, S. Diggavi and P. Tabuada are with the Elec-
trical Engineering Department, University of California, Los Angeles,
CA 90095-1594, USA (e-mail: {shaunakmishra, yshoukry, suhasdiggavi,
tabuada}@ucla.edu). N. Karamchandani is with the Electrical Engineering
Department, Indian Institute of Technology Bombay, Mumbai-400076, India
(email: nikhilk@ee.iitb.ac.in). The work was supported by NSF grant 1136174
and DARPA under agreement number FA8750-12-2-0247. A preliminary
version of this work appeared in the proceedings of ISIT 2015 [1].

attack vector from bounded noise, they do not guarantee the
optimality of their estimation algorithm. The problem we focus
i.e., sensor
on in this paper falls in the second category,
attacks in the presence of Gaussian noise. Prior work in this
category includes [8], [9], [10], [11]. In [8], the focus is
on detecting a class of sensor attacks called replay attacks
where the attacker replaces legitimate sensor outputs with
outputs from previous time instants. In [9], the performance
degradation of a scalar Kalman ﬁlter (i.e., scalar state and a
single sensor) is studied when the (single) sensor is under
attack. They do not study attack sparsity across multiple
sensors, and in addition, they focus on an adversary whose
objective is to degrade the estimation performance without
being detected (leading to a restricted class of sensor attacks).
In [10] and [11], robustiﬁcation approaches for state estimation
against sparse sensor attacks are studied. However, they lack
optimality guarantees against arbitrary sensor attacks.

In this paper, we study a general linear dynamical system
with process and sensor noises having a Gaussian distribution,
and give (optimal) guarantees on the achievable state estima-
tion error against arbitrary sensor attacks. The following toy
example is illustrative of the nature of the problem addressed
in this paper and some of the ideas behind our solution.

∈ {

1, 2, 3
}

Example 1. Consider a linear dynamical system with a scalar
state x(t) such that x(t + 1) = x(t) + w(t), and three sensors
(indexed by d
) with outputs yd(t) = x(t) + vd(t);
where w(t) and vd(t) are the process noise and sensor noise at
sensor d respectively. The process and sensor noises follow a
zero mean Gaussian distribution with i.i.d. instantiations over
time. The sensor noise is also independent across sensors.
Now, consider an adversary which can attack any one of the
sensors in the system and arbitrarily change its output. In the
absence of sensor noise, it is trivial to detect such an attack
since the two good sensors (not attacked by the adversary)
will have the same output. Hence, a majority based rule on
the outputs leads to the exact state. However, in the presence
of sensor noise, a difference in outputs across sensors can also
be attributed to the noise, and thus cannot be considered an
attack indicator. As a consequence of results in this paper, in
this example we can identify a subset of two sensors which can
be reliably used for state estimation despite an adversary who
can attack any one of the three noisy sensors. In particular,
our approach for this example would be to search for a subset
of two sensors which satisfy the following check: over a large
enough time window, the outputs from the two sensors are
consistent with the Kalman state estimate based on outputs
from the same subset of sensors. Furthermore, we can show

 
 
 
 
 
 
2

that such an approach leads to the optimal state estimation
error for the given adversarial setup.

In this paper, we generalize the Kalman ﬁlter based ap-
proach in the above example to a general linear dynamical
system with sensor and process noise. The Kalman estimate
based check mentioned in the above example forms the basis
of a detector for an effective attack; a notion that we introduce
in this paper. For state estimation, we search for a sensor
subset which passes such an effective attack detector, and then
use outputs from such a sensor subset for state estimation.
We also derive impossibility results (lower bounds) on the
state estimation error in our adversarial setup, and show that
our proposed state estimation algorithm is optimal
in the
sense that it achieves these lower bounds. To further reduce
the sensor subset search time for the state estimator, we
propose Satisﬁability Modulo Theory (SMT) based techniques
to harness the combinatorial nature of the search problem,
and demonstrate the improvements in search time through
numerical experiments.

As a result of independent

interest, we give a coding
theoretic interpretation (alternate proof) for the necessary and
sufﬁcient conditions for secure state estimation in the absence
of noise [3], [4], [6] (known as the sparse observability condi-
tion). In particular, we relate the sparse observability condition
required for attack detection and secure state estimation in
dynamical systems to the Hamming distance requirements for
error detection and correction [12] in classical coding theory.
The remainder of this paper1 is organized as follows.
Section II deals with the setup and problem formulation. In
Section III, we describe our effective attack detector followed
by Section IV on our main results for effective attack detection
and secure state estimation. Section V deals with SMT based
techniques and Section VI with the experimental results.
Finally, Section VII describes the coding theoretic view for
attack detection and secure state estimation.

II. SETUP

In this section, we discuss the adversarial setup along with
assumptions on the underlying dynamical system, and provide
a mathematical formulation of the state estimation problem
considered in this paper.

A. Notation

The symbols N, R and B denote the sets of natural, real,
denotes
and Boolean numbers respectively. The symbol
Rn,
the logical AND operator. The support of a vector x
denoted by supp(x), is the set of indices of the non-zero
elements of x. If s is a set,
is the cardinality of s.
Rm×n, unless stated otherwise, we
For the matrix M
R1×n the ith row of the matrix. For the
denote by Mi
R|s|×n the matrix
, we denote by Ms
set s
}
obtained from M by removing all
those

the rows except

∈
1, . . . , m

⊆ {

s
|

∧

∈

∈

∈

|

indexed by s. We use tr (M) to denote the trace of the matrix
M. If the matrix M is symmetric, we use λmin (M) and
λmax (M) to denote the minimum and maximum eigenvalue
of M respectively. We denote by Sn
n
×
Rn,
positive semi-deﬁnite matrices. For a random variable x
we denote its mean by E (x)
R and its covariance by
V ar(x)
t∈N,
+. For a discrete time random process
the sample average of x using N samples starting at time t1
is deﬁned as follows:

+ the set of all n

x(t)
}
{

Sn

∈

∈

∈

EN,t1 (x) =

1
N

t1+N −1
(cid:88)

t=t1

x(t).

(1)

∈

∈

Rm×1 the identity
Rm×m and 1m
We denote by Im
matrix of dimension m and the vector of all ones respectively.
N (µ, Ω) is used to denote an i.i.d.
The notation x(t)
Gaussian random process with mean µ and covariance matrix
Ω. Finally, we use the symbol (cid:52) for element-wise comparison
between matrices. That is, for two matrices A and B of the
same size, A (cid:52) B is true if and only if each element ai,j is
smaller than or equal to bi,j.

∼

B. System model

We consider a linear dynamical system ΣΣΣa with sensor

attacks as shown below:
(cid:40)

ΣΣΣa

x (t + 1) = Ax(t) + Bu(t) + w(t),
y(t)

= Cx(t) + v(t) + a(t),

(2)

∈

∈

∼

vIp

Rm denotes the input at time t, w(t)

N,
Rn denotes the state of the plant at time t
where x(t)
∈
(cid:1)
N (cid:0)0, σ2
wIn
u(t)
∼
Rp denotes the
denotes the process noise at time t, y(t)
∈
(cid:1) denotes
N (cid:0)0, σ2
output of the plant at time t and v(t)
the sensor noise at time t. Both v(t) and w(t) have i.i.d.
instantiations over time, and v(t) is independent of w(t). In
addition, we denote the output and (sensor) noise at sensor i
∈
R respectively.
1, 2, . . . , p
{
∈
We assume that the input u(t) is known at all time. Hence, its
contribution to the output y(t) is also known, and therefore,
u(t) can be ignored. That is, for the rest of the paper, and
without loss of generality, we consider the case of u(t) = 0
for all time t

at time t as yi(t)

R and vi(t)

∈

}

N.
The sensor attack vector a(t)
∈
a k-adversary deﬁned as follows.

∈

Rp in (2) is introduced by

Assumption 1. A k-adversary can corrupt any k out of the p
sensors in the system.

⊆ {

1, 2, . . . , p

Speciﬁcally, let κκκ

denote the set of attacked
= k). The k-adversary can observe the actual
sensors (with
outputs in the k attacked sensors and change them arbitrarily.
N.
For an attack free sensor j /
∈

κκκ, aj(t) = 0 for all time t

κκκ
|
|

∈

}

Assumption 2. The adversary’s choice of κκκ is unknown but
is assumed to be constant over time (static adversary).

1Compared to the preliminary version [1], this paper differs in the presen-
tation of results through effective attack detection. In addition, we reduce the
complexity of the state estimation algorithm in [1] and also describe SMT
based techniques for reducing the subset search time.

Assumption 3. The adversary is assumed to have unbounded
computational power, and knows the system parameters (e.g.,
A and C) and noise statistics (e.g., σ2

w and σ2
v).

However,

the adversary is limited to have only causal
knowledge of the process and sensor noise as stated by the
following two assumptions.

Assumption 4. The adversary’s knowledge at time t is statis-
tically independent of w(t(cid:48)) for t(cid:48) > t, i.e., a(t) is statistically
independent of

w(t(cid:48))

{

t(cid:48)>t.
}

Assumption 5. For an attack-free sensor i
the adversary’s knowledge at
statistically independent of

t(cid:48)>t.

κκκ,
time t (and hence a(t)) is

1, 2, . . . , p

∈ {

} \

vi(t(cid:48))
}
{

Intuitively, Assumptions 4 and 5 limit the adversary to have
only causal knowledge of the process noise and the sensor
noise in good sensors (not attacked by the adversary). Note
that, apart from Assumptions 4 and 5, we do not impose
any restrictions on the statistical properties, boundedness and
the time evolution of the corruptions introduced by the k-
adversary.

In the following subsections, we ﬁrst introduce the (ef-
fective) attack detection problem, followed by the (optimal)
secure state estimation problem. As we show later in the paper
(in Section IV), our solution for the effective attack detection
problem is used as a crucial component for solving the secure
state estimation problem.

C. Effective Attack Detection Problem

In this section, we introduce our notion of effective (sensor)
attacks and formulate the problem of detecting them. Recall
that in the absence of sensor attacks, using a Kalman ﬁlter
for estimating the state in (2) leads to the (optimal) minimum
mean square error (MMSE) covariance asymptotically [13].
In this context, our notion of effective attacks is based on
the following intuition: if we naively use a Kalman ﬁlter for
state estimation in the presence of an adversary, an attack
is effective when it causes a higher empirical error variance
compared to the attack-free case. Before we formally state our
deﬁnition of effective attacks, we ﬁrst setup some notation for
Kalman ﬁlters as described below.

}

−

⊆ {

time t

1, 2, . . . , p

−
. Since we use outputs till

We denote by ˆxs(t) the state estimate of a Kalman ﬁlter at
time t using outputs till time t
1 from the sensor subset
s
1,
we essentially use the prediction version of a Kalman ﬁlter
as opposed to ﬁltering where outputs till time t are used
to compute ˆxs(t). In this paper, we state our results using
the extension
the prediction version of the Kalman ﬁlter;
for the ﬁltering version is straightforward (for details about
the ﬁltering version of our results, see Appendix C). In
addition to ˆxs(t), we denote by ˆx(cid:63)
s (t) the Kalman ﬁlter state
estimate at time t using sensor subset s when all the sensors
in s are attack-free. We eliminate the subscript s from the
previous notation whenever the Kalman ﬁlter uses all sensor
measurements, i.e., when s =
1, . . . , p
. In this paper, for the
{
sake of simplicity, we assume that all the Kalman ﬁlters we
consider (in our proposed algorithms and their analysis) are in
steady state [13] when they use uncorrupted sensor outputs.
Hence, in the absence of attacks, the error covariance matrix
P(cid:63)(t)

S+

}

∈

n deﬁned as:
(cid:16)
P(cid:63)(t) = P(cid:63) = E

(x(t)

−

ˆx(cid:63)(t)) (x(t)

−

ˆx(cid:63)(t))T (cid:17)

,

3

does not depend on time. In a similar spirit, we deﬁne the error
covariance matrix P(cid:63)
n corresponding to sensor subset
1, 2, . . . , p
s
as:
s = E(x(t)

s (t))(x(t)

s (t))T .
ˆx(cid:63)

s ∈

⊆ {

P(cid:63)

ˆx(cid:63)

S+

}

−

−

Note that the error covariance matrix depends on the set of
sensors involved in estimating the state. Also, the steady state
error has zero mean, i.e., E (x(t)
s (t)) = 0. Using the
above notation, we deﬁne an ((cid:15), s)-effective attack as follows.

ˆx(cid:63)

−

Deﬁnition 1 (((cid:15), s)-Effective Attack). Consider the linear
dynamical system under attack ΣaΣaΣa as deﬁned in (2), and a
k-adversary satisfying Assumptions 1-5. For the set of sensors
N, an attack signal is
s, an (cid:15) > 0, and a large enough N
called ((cid:15), s)-effective at time t1 if the following bound holds:

∈

tr (cid:0)EN,t1

s

(cid:0)eseT
(cid:1)(cid:1) > tr(P(cid:63)
ˆxs(t), and EN,t1 (
) denotes the sample
·

s ) + (cid:15),

where es(t) = x(t)
average as deﬁned (1).

−

In other words, an attack is called ((cid:15), s)-effective if it can
lead to a higher estimation error compared to the optimal
estimation error in the absence of sensor attacks, using the
same set of sensors s. An attack is called ((cid:15), s)-ineffective
(cid:1)
(cid:0)eseT
if it is not ((cid:15), s)-effective. Essentially, we use EN,t1
as a proxy for the state estimation error covariance matrix
in the presence of attacks; a sample average is used instead
of an expectation because the resultant error in the presence
of attacks may not be ergodic. Also, since ˆxs(t) is computed
using all measurements from time 0 till time t
1, Deﬁnition 1
implicitly takes into consideration the effect of attack signal
a(t) for the time window starting from 0 till time t + N
1.
Using the above notion of an ((cid:15), s)-effective attack, we

−

−

s

deﬁne the (cid:15)-effective attack detection problem as follows.

Problem 1. [(cid:15)-Effective Attack Detection Problem] Consider
the linear dynamical system under attack ΣaΣaΣa as deﬁned in (2),
and a k-adversary satisfying Assumptions 1-5. Let sall be the
set of all sensors, i.e., sall =
. Given an (cid:15) > 0,
construct an attack indicator ˆdattack

1, . . . , p
{

such that:

}
0, 1
}

∈ {

ˆdattack(t1) =

(cid:40)

1
0

if the attack is ((cid:15), sall)-effective at time t1
otherwise.

D. Optimal Secure State Estimation Problem

We now focus on the problem of estimating the state from
the adversarially corrupted sensors. We start by showing a
negative result stating that a certain estimation error bound
may be impossible to achieve in the presence of a k-adversary.
To do so, we deﬁne the sensor set that contains p
k sensors
and corresponds to the worst case Kalman estimate as:

−

sworst,p−k = arg max

s⊆{1,2,...,p},
|s|=p−k

tr(P(cid:63)

s ).

(3)

The impossibility result can now be stated as follows.

Theorem 1 (Impossibility). Consider the linear dynamical
system under attack ΣaΣaΣa as deﬁned in (2), and an oracle

4

MMSE estimator that has knowledge of κκκ, i.e., the set of
sensors attacked by a k-adversary. Then, there exists a choice
of sensors κκκ and an attack sequence a(t) such that the trace of
the error covariance of the oracle estimator is bounded from
below as follows:

(cid:18)

tr

E (cid:0)e(t)eT (t)(cid:1)

(cid:19)

(cid:18)

tr

≥

P(cid:63)

sworst,p−k

(cid:19)

,

(4)

where e(t) above is the oracle estimator’s error.

−

vj(t),

Cjx(t)

Proof. Consider the attack scenario where the outputs from
all attacked sensors are equal to zero, i.e., the corruption
κκκ. Hence, the information
aj(t) =
j
∀
collected from the attacked sensors cannot enhance the esti-
mation performance. Accordingly, the estimation performance
from the remaining sensors is the best one can expect to
achieve. Hence, the result follows by picking κκκ such that
κκκ =

sworst,p−k.

−

∈

1, . . . , p
{

} \

In the context of Theorem 1, we deﬁne a state estimate to be
optimal if it is guaranteed to achieve the lower bound shown
in (4). This can be formalized as follows.

Problem 2. [Optimal Secure State Estimation Problem]
Consider the linear dynamical system under attack ΣaΣaΣa as
deﬁned in (2), and a k-adversary satisfying Assumptions 1-5.
For a time window G =
, construct
t1, t1 + 1, . . . , t1 + N
1
{
}
t∈G such that:
the state estimates
ˆx(t)
}
{
(cid:0)eeT (cid:1)
EN,t1

P(cid:63)

tr

tr

−

(cid:18)

(cid:19)

(cid:19)

(cid:18)

,

sworst,p−k

≤

where e(t) = x(t)

−

ˆx(t) is the state estimation error.

Similarly to Deﬁnition 1, we use the sample average
(cid:0)eeT (cid:1) in Problem 2 (and not expectation) since the
EN,t1
resultant error in the presence of attacks may not be ergodic.

III. SPARSE OBSERVABILITY AND ((cid:15), s)-EFFECTIVE
ATTACK DETECTION
In this section, we ﬁrst describe the notion of k-sparse
observability [4]. This notion plays an important role in deter-
mining when Problems 1 and 2 are solvable. After describing
sparse observability, we describe an algorithm for ((cid:15), s)-
effective attack detection which leverages sparse observability
for its performance guarantees.

|

−

= p

⊆ {

1, . . . , p

k, the pair (A, Cs) is observable.

A. k-Sparse Observability
Deﬁnition 2. (k-Sparse Observable System) The linear dy-
namical system under attack ΣaΣaΣa as deﬁned in (2), is said to
with
be k-sparse observable if for every set s
s
|
In other words, a system is k-sparse observable if it remains
observable after eliminating any choice of k sensors. In the
absence of sensor and process noise, the conditions under
which exact (i.e., zero error) state estimation can be done
despite sensor attacks have been studied in [3], [4], [6] where
is shown that 2k-sparse observability is necessary and
it
sufﬁcient for exact state estimation against a k-adversary. In
Section VII, we provide a coding theoretic interpretation for

}

this condition in the context of attack detection and secure
state estimation in any noiseless dynamical system.

B. ((cid:15), s)-Effective Attack Detector

In this section, we describe an algorithm based on the sparse
observability condition for detecting an ((cid:15), s)-effective attack.
We ﬁrst introduce some additional notation, followed by the
description of the algorithm and its performance guarantee.
1) Additional notation: Let the sensors be indexed by i
1, 2, . . . , p
{

∈
. We deﬁne the following observability matrices:

}

Oi =










CT
i
CT
i A
...
i Aµi−1

CT

, O =






,






(5)










O1
O2
...
Op

where Oi is the observability matrix for sensor i (with observ-
ability index µi as shown in (5)) and O is the observability
matrix for the entire system (i.e., p sensors) formed by stacking
the observability matrices for the sensors. Similarly, for any
sensor subset s
, we denote the observability
}
matrix for s by Os (formed by stacking the observability
matrices of sensors in s). Without loss of generality, we will
consider the observability index µi = n for each sensor. For
any sensor subset s with
> k, we deﬁne λmin,s\k as
follows:

1, 2, . . . , p

s
|
|

⊆ {

λmin,s\k =

(cid:0)O T
s1

Os1

(cid:1) ,

λmin

min
s1⊂s, |s1|=|s|−k
(cid:1) denotes the minimum eigenvalue of

(6)

where λmin
O T
s1

(cid:0)O T
s1

Os1

Os1 . We deﬁne matrices Ji, J and M as shown below:










0
CT
i
CT
i A
...

Ji =

CT
wJJT + σ2

i Aµi−2 CT
vInp.

M = σ2

0
0
CT
i
...
i Aµi−3










. . .
0
. . .
0
. . .
0
...
. . .
. . . CT
i

, J =








J1
J2
...
Jp








,

(7)

s, and Ms = σ2

In a similar spirit, Js is deﬁned for a sensor subset s by
stacking Ji for i
vIn|s|. We use the
following notation for sensor outputs and noises corresponding
to a time window of size µi = n (observability index):


wJsJT

s +σ2

∈







yi(t) =

¯y(t) =

yi(t)
yi(t + 1)
...
yi(t + µi
y1(t)
y2(t)
...
yp(t)






−















, vi(t) =






1)






vi(t)
vi(t + 1)
...
vi(t + µi


−

,






1)

, ¯v(t) =

, ¯w(t) =















v1(t)
v2(t)
...
vp(t)

w(t)
w(t + 1)
...
w(t + n






−








,

1)
(8)

where yi(t) and vi(t) denote the output and sensor noise at
sensor i at time t respectively.

Algorithm 1 ATTACK-DETECT(s, t1)

1: Run a Kalman ﬁlter that uses all measurements from
1 and compute the

sensors indexed by s until time t1
estimate ˆxs(t1)
2: Recursively repeat

Rn.

∈

the previous step N

−

Rn,

t
∀

∈

1 times to
t1, t1 +

−
G =

{

calculate all estimates ˆxs(t)
1, . . . , t1 + N

1

∈

.
}

3: For time t

−
G, calculate the block residue:

∈
rs(t) = ¯ys(t)

Os ˆxs(t)

−

G.

t
∀

∈

4: if block residue test deﬁned below holds,

O T

s + Ms

(cid:1) (cid:52) η 1n|s|1T

n|s|,

(cid:15) ,

then

s

(cid:1)

−

EN,t1

(cid:0)rsrT

(cid:0)OsP(cid:63)
s
(cid:16) λmin,s\k
(cid:17)
3n(|s|−k)
≤
assert ˆdattack,s(t1) := 0

where 0 < η

5:
6: else
7:
8: end if
9: return ( ˆdattack,s(t1),

assert ˆdattack,s(t1) := 1

ˆxs(t)
{

t∈G)
}

−

1
}

2) Attack Detection Algorithm: We consider the attack
t1, t1 +1, . . . , t1 +
detection problem for a time window G =
{
N
, and assume without loss of generality that the window
size N is divisible by n. For a sensor subset s with
> k, we
start by computing the state estimate ˆxs(t1) obtained through
a Kalman ﬁlter that uses measurements collected from time
0 up to time t1
1 from all sensors indexed by the subset
s. Using this estimate, we can calculate the block residue
rs(t1) which is the discrepancy between the estimated output
ˆys(t1) = Os ˆxs(t1) and the actual output ys(t1), i.e.,
Os ˆxs(t1).

ˆys(t1) = ys(t1)

rs(t1) = ys(t1)

s
|

(9)

−

|

−

−

By repeating the previous procedure N
1 times, we can
−
rs(t)
t∈G. The next step is
obtain the sequence of residues
}
to calculate the sample average of rs(t)rT
s (t), and compare
the sample average with the expected value of rs(t)rT
s (t) in
the case when sensor subset s is attack-free. This can be done
using the following (block) residue test:

{

for some η > 0. Simply put, the residue test just checks
whether the sample average of rs(t)rT
s (t) over the time win-
dow G is close to its attack-free expected value OsP(cid:63)
s +Ms
s
(details in Section III-C). It is crucial to recall that the attack-
free estimation error covariance matrix P(cid:63)
s used in (10) can be
computed ofﬂine [13] without the need for any data collected
from attack-free sensors. If the element-wise comparison in
the residue test (10) is valid, we set the attack detection ﬂag
ˆdattack,s(t1) to zero indicating that no attack was detected in
sensor subset s. This procedure is summarized in Algorithm 1.

O T

C. Performance Guarantees

In this subsection, we describe our ﬁrst main result which

is concerned with the correctness of Algorithm 1.

5

−

5 and a sensor subset s

Lemma 1. Let the linear dynamical system as deﬁned in (2)
be 2k-sparse observable. Consider a k-adversary satisfying
with
Assumptions 1
k. For any (cid:15) > 0 and δ > 0, there exists a large
p
s
|
| ≥
enough time window length N such that when Algorithm 1
terminates with ˆdattack,s(t1) = 0, the following probability
bound holds:
(cid:16)

1, 2, . . . , p

⊆ {

−

(cid:17)

}

P

tr (cid:0)Et1,N

(cid:0)eseT

s

(cid:1)

(cid:1)

P(cid:63)
s

−

(cid:15)

≤

1

≥

−

δ,

(11)

ˆxs(t). In other words, for large enough
P(cid:63)
(cid:15) holds with high
s
the attack is an ((cid:15), s)-

≤

(cid:1)

s

−

where es(t) = x(t)
N , the bound tr (cid:0)Et1,N
(cid:0)eseT
probability2 (w.h.p.). Moreover,
effective attack, the following also holds:
(cid:17)
(cid:16) ˆdattack,s(t1) = dattack,s(t1)

−
if

P

(cid:1)

δ,

1

−

≥

(12)

is

where ˆdattack,s(t1)
the output of Algorithm 1 while
dattack,s(t1) is the output of an oracle detector that knows the
exact set of attacked sensors. Hence, Algorithm 1 can detect
any ((cid:15), s)-effective attack w.h.p. for large enough N .

Proof of Lemma 1. We focus only on showing that (11) holds
whenever Algorithm 1 terminates with ˆdattack,s(t1) = 0; the
rest of the lemma follows easily from Deﬁnition 1. Since we
assume that the set s has cardinality
k, we can
conclude that there exists a subset sg
s with cardinality
2k sensors such that all its sensors are attack-
sg
|
free (subscript g in sg stands for good sensors in s). Hence,
by decomposing the set s into an attack-free set sg and a
potentially attacked set s
sg, we can conclude that, after a
permutation similarity transformation for (10), the following
holds for the attack-free subset sg:

s
| ≥
⊂

| ≥

−

−

p

p

\

|

EN,t1

(cid:16)

rsg rT
sg

(cid:17)

Therefore,

Osg P(cid:63)
s

O T

sg −

−

Msg

(cid:52) η 1n(|s|−k)1T

n(|s|−k).

(cid:16)

tr

EN,t1

(cid:16)

rsg rT
sg

(cid:17)

Osg P(cid:63)
s

−

(cid:17)

Msg

O T

sg −
n(

≤

s
| −
|

k)η = (cid:15)1.

(13)

Similarly, after a suitable permutation Π, we can decompose
the block residue rs(t) deﬁned in equation (9) as follows:

(cid:21)

Osg ˆxs(t)
Os\sg ˆxs(t)

=

(cid:20) ysg (t)
ys\sg (t)

(cid:20) rsg (t)
(cid:21)
rs\sg (t)
(cid:20)Osg x(t) + Jsg ¯w(t) + ¯vsg (t)
ys\sg (t)

−
−

−
(cid:20) Osg es(t) + zsg (t)
ys\sg (t)

Os\sg ˆxs(t)

−
Os\sg ˆxs(t)
(cid:21)

=

=

−

Osg ˆxs(t)

(cid:21)

,

(14)

where zsg (t) = Jsg ¯w(t) + ¯vsg (t). Using (14), we can rewrite
tr

(cid:17)(cid:17)

(cid:16)

(cid:16)

as:

EN,t1
(cid:16)

EN,t1

tr

= tr

rsg rT
sg
(cid:16)

(cid:17)(cid:17)

rsg rT
sg
(cid:16)
EN,t1

Osg

(cid:0)eseT

s

(cid:1) O T
sg

(cid:17)

+ tr

(cid:16)

EN,t1

(cid:16)

zsg zT
sg

(cid:17)(cid:17)

2 By stating that the bound holds with high probability for large enough N ,
we mean that for any δ > 0 and (cid:15) > 0, ∃Nδ,(cid:15) ∈ N such that for N > Nδ,(cid:15),
(cid:16)
tr (cid:0)Et1,N
P

(cid:1) − P(cid:63)
s

(cid:0)eseT
s

≥ 1 − δ.

(cid:1) ≤ (cid:15)

(cid:17)

EN,t1

(cid:0)rsrT

s

(cid:1)

−

(cid:0)OsP(cid:63)

s

O T

s + Ms

(cid:1) (cid:52) η 1n|s|1T

n|s|,

(10)

Π (rs(t)) =

6

+ 2EN,t1

(cid:16)

eT
s

O T
sg

zsg

(cid:17)

.

By combining (13) and (15):
(cid:1) O T

(cid:16)

Osg

EN,t1

tr

(cid:17)

O T
sg

(cid:16)

zsg zT
sg

(cid:17)(cid:17)

+ (cid:15)1

s

(cid:0)eseT
tr (cid:0)Msg
2EN,t1

(cid:1)

Osg P(cid:63)
s
(cid:16)

EN,t1
(cid:17)

O T
sg

zsg

sg −
tr

−
(cid:16)
eT
s

≤

−

(cid:16)

2EN,t1

eT
s

O T
sg

zsg

(cid:17)

(a)

≤
(b)

≤

2(cid:15)1

−

3(cid:15)1,

(15)

Algorithm 2 EXHAUSTIVE SEARCH

1: Enumerate all sets s

S =
2: Exhaustively search for s∗
and use ˆxs∗ (t) for t

s
|
{

s

∈
⊂ {

S such that:
,
1, 2, . . . , p

s
|
|

= p

k

.

}

−

}

S for which dattack,s∗ (t1) = 0

∈

G as the state estimate.

∈

observable system in order to repeat the steps in the proof
for Lemma 1; this requirement is guaranteed by the k-sparse
observability condition. On a related note, in Section VII,
we give a coding theoretic interpretation for the k-sparse
observability requirement for attack detection.

(16)

(17)

(cid:17)

(cid:16)

where (a) follows w.h.p. due to the law of large num-
bers (LLN) for large enough N (details in Appendix A1),
and (b) follows w.h.p. by showing that
the cross term
2EN,t1
has zero mean and vanishingly small vari-
ance for large enough N . The cross term analysis is described
in detail in Appendix A2. Now recall that for any two matrices,
A and B of appropriate dimensions, tr (AB) = tr (BA).
Using this fact along with (17), the following holds:

eT O T
sg

zsg

(cid:16)

tr

EN,t1

(cid:0)eseT

s −

P(cid:63)
s

(cid:1) O T
sg

Osg

(cid:17)

3(cid:15)1,

≤

(18)

and hence, we get the following bound which completes the
proof:

tr (cid:0)EN,t1

(cid:0)eseT

s

(cid:1)

P(cid:63)
s

(cid:1) (c)
≤

−

3(cid:15)1
(cid:16)
O T
sg

(cid:17)

Osg

(d)

3(cid:15)1

≤

λmin,s\k ≤

(cid:15)

λmin

(19)

where (c) follows from Lemma 3 in Appendix B and (d)
follows from the deﬁnition of λmin,s\k. Note that, it follows
2k and 2k-sparse observability, that both
from
−
λmin
and λmin,s\k are bounded away from zero.

p
sg
(cid:16)
(cid:17)
| ≥
|
Osg
O T
sg

IV. EFFECTIVE ATTACK DETECTION AND SECURE STATE
ESTIMATION

Based on the performance guarantees for the ATTACK-
DETECT algorithm described in Section III, in this section
we describe our main results for Problems 1 and 2.

A. Attack detection

We start by showing a solution to Problem 1 ((cid:15)-effective

attack detection), which follows directly from Lemma 1.

Theorem 2. Let the linear dynamical system deﬁned in (2)
be k-sparse observable system. Consider a k-adversary sat-
isfying Assumptions 1-5, and the detector ˆdattack(t1) =
ATTACK-DETECT(sall, t1) where the set sall =
.
}
Then, for large enough time window length N , w.h.p. ˆdattack(t1)
is equal to the attack indicator which solves Problem 1.

1, . . . , p
{

Proof. The proof is similar to the proof of Lemma 1. In the
proof of Lemma 1, we basically required the set of good
sensors sg to form an observable system. Similarly, while
checking for effective attacks on a sensor set of size p, we
k) to form an
require the set of good sensors (of size

p

≥

−

B. Secure State Estimation

(cid:1) sensor subsets of size p

Algorithm 2 describes our proposed solution for Problem 2
(secure state estimation). As described in Algorithm 2, we
exhaustively enumerate (cid:0) p
k,
and then apply ATTACK-DETECT on each sensor subset until
we ﬁnd one subset s∗ for which ATTACK-DETECT returns
ˆdattack,s∗ (t1) = 0 indicating that the subset is ((cid:15)-effective)
attack-free. The following theorem states the performance
guarantees associated with Algorithm 2.

p−k

−

Theorem 3. Let the linear dynamical system deﬁned in (2)
be 2k-sparse observable system. Consider a k-adversary sat-
isfying Assumptions 1-5. Consider the state estimate ˆxs∗ (t)
computed by Algorithm 2. Then, for any (cid:15) > 0 and δ > 0,
there exists a large enough N such that:
(cid:0)es∗ eT

tr (cid:0)EN,t1

+ (cid:15)

P(cid:63)

(cid:1)(cid:1)

tr

δ,

P

(cid:17)

(cid:17)

(cid:16)

(cid:16)

1

sworst,p−k

s∗

≤

≥

−

(20)

estimation
In other
bound

the

where es∗ (t) = x(t)
error using
words,

ˆxs∗ (t) as

lim sup
N→∞

1
N

t∈G

w.h.p.
(cid:88)

Algorithm 2
(cid:16)

eT
s∗ (t)es∗ (t)

tr

P(cid:63)

achieves
(cid:17)

sworst,p−k

.

≤

ˆxs∗ (t)
state

the
is
estimate.

−
the

Proof. The result follows from Lemma 1 which ensures
the ((cid:15), s)-effective attack prop-
that,
the
erty,
in the worst case,
bound (11). This in turn implies that,

in the absence of
the calculated state estimate still guarantees

(cid:88)

1
N

t∈G

eT
s∗ (t)es∗ (t) = tr

lim sup
N→∞
However, since the k-adversary may not always attack
the worst case set of sensors sworst,p−k, we can replace
leading to
the equality sign above with an inequality,

is achievable.

sworst,p−k

P(cid:63)

(cid:16)

(cid:17)

lim sup
N→∞

1
N

(cid:88)

t∈G

eT
s∗ (t)es∗ (t)

tr

≤

(cid:16)

P(cid:63)

sworst,p−k

(cid:17)

.

V. REDUCING SEARCH TIME USING SATISFIABILITY
MODULO THEORY SOLVING
Algorithm 2 exhaustively explores all combinations of p
k
sensors until a set s∗ satisfying dattack,s∗ (t1) = 0 is found. In
this section, we explore the idea of using sophisticated search
techniques in order to harness the underlying combinatorial
aspect of the secure state estimation problem. In particular,
we extend previous work by the authors and co-workers on
using Satisﬁability Modulo Theory (SMT)-like solvers [5],

−

b1

b1

b2

b2

b2

b2

b3

b3

b3

b3

b3

b3

b3

b3

7

{

0, 0, 1
}

1, 1, 0
0, 1, 0
}
}
{
three Boolean indica-
(a) A tree showing all
tor variables b1, b2, b3 when a conﬂicting certiﬁcate of
the form
φcert := b1 + b2 + b3 ≥ 1 is generated. The missing combination {0, 0, 0}
is the only one that is eliminated as a result of this certiﬁcate.

{
the combinations of

1, 1, 1
}
{

1, 0, 1
}

1, 0, 0
}

0, 1, 1
{

{

}

{

{

0, 0, 1
}

0, 1, 1
}
(b) A tree showing all the combinations of three Boolean indicator variables
b1, b2, b3 when a conﬂicting certiﬁcate of the form φcert := b3 ≥ 1 is gener-
ated. The missing four combinations {0, 0, 0}, {0, 1, 0}, {1, 0, 0}, {1, 1, 0}
are eliminated as a result of this certiﬁcate.

1, 0, 1
}

1, 1, 1
}

{

{

{

Fig. 1. Pictorial example illustrating the effect of generating smaller conﬂicting certiﬁcates.

developed for the noiseless case, in order to improve the search
time while preserving optimality of the solution.

−

The driving concept behind SMT solvers can be summarized
as follows. First, the search space of all sensor subsets with
cardinality p
k, is encoded using Boolean variables (the num-
ber of Boolean variables increases linearly with the number
of sensors), and a Boolean search engine (e.g., SAT solver) is
used in order to traverse the search space. Whenever the SAT
solver suggests one possible solution in the search space, a
higher level solver (typically referred to as the Theory-solver)
is used to check the correctness of that particular solution.
Finally, in order to prevent the SAT solver from enumerating
all possible solutions in the search space, the Theory-solver
generates counter examples (certiﬁcates), explaining why a
particular solution is not valid. Each certiﬁcate is used by
the SAT solver in order to prune the search space and
hence enhance the performance of the overall algorithm. This
methodology of “counter-example guided search” effectively
breaks the secure state estimation problem into two simpler
tasks over the Boolean and Reals domain. Further details about
this technique are described below.

A. Overall Architecture

∈

We start by introducing a Boolean indicator variable b =
Bp where the assignment bi = 1 hypothesizes
(b1, . . . , bp)
that the ith sensor is under attack while the assignment bi = 0
the ith sensor is attack-free. Using this
hypothesizes that
indicator variable, b, we start by asking the (pseudo-)Boolean
SAT solver to assign values to b in order to satisfy the
following formula:

φ(0) ::=

p
(cid:88)

bi

≤

k,

(21)

In the next step,

this hypothesized assignment

i=1
which ensures that at most k sensors are going to be hypothe-
sized as being under attack (the addition in (21) is over Reals).
is then
checked by the theory solver. This
is done by run-
ning the ATTACK-DETECT algorithm (Algorithm 1) using
only the set of hypothesized attack-free sensors s(b) =
supp(b). If the ATTACK-DETECT algorithm re-
1, . . . , p
{
turns ˆdattack,s(b) = 0 then our solver approves this hypothesis
and the algorithm terminates. Otherwise, an UNSAT certiﬁcate
(also known as a counter-example) is generated explaining
why this assignment of b is not valid (i.e., a conﬂict). A

} −

trivial UNSAT certiﬁcate that can always be generated takes
the following form (in iteration j):
(cid:88)

(22)

φcert(j) ::=

bi

1,

≥

i∈s(b)

which ensures that the current assignment of the variable b
is excluded. Once this UNSAT certiﬁcate is generated, the
(pseudo-)Boolean SAT solver is then invoked again in the next
iteration with the following constraints:

φ(j + 1) ::= φ(j)

φcert(j),

∧

until one assignment of the variable b passes the attack
detection test. This procedure is summarized in Algorithm 3.

B. Conﬂicting Certiﬁcates

The generated UNSAT certiﬁcates heavily affect the overall
execution time. Smaller UNSAT certiﬁcates prune the search
space faster. For simplicity, consider the example shown in
Figure 1 where the vector b has only three elements. On one
hand, an UNSAT certiﬁcate that has the form φcert = b1 +b2 +
b3
1 leads to pruning only one sample in the search space.
On the other hand, a smaller UNSAT certiﬁcate that has the
form φcert = b1
1 eliminates four samples in the search
space which is indeed a higher reduction, and hence leads to
better execution time.

≥

≥

To generate a compact (i.e., smaller) Boolean constraint that
explains a conﬂict, we aim to ﬁnd a small set of sensors that
cannot all be attack-free. To do so, we start by removing
one sensor from the set s(b) and run the ATTACK-DETECT
algorithm on the reduced set s(cid:48)(b) to obtain ˆdattack,s(cid:48)(b). If
ˆdattack,s(cid:48)(b) still equals one (which indicates that set s(cid:48)(b) still
contains a conﬂicting set of sensors), we generate the more
compact certiﬁcate:

φcert(j) ::=

(cid:88)

i∈s(cid:48)(b)

bi

1.

≥

(23)

We continue removing sensors one by one until we cannot ﬁnd
any more conﬂicting sensor sets. Indeed, the order in which
the sensors are removed is going to affect the overall execution
time. In Algorithm 4 we implement a heuristic (for choosing
this order) which is inspired by the strategy we adopted in the
noiseless case [5].

Note that the reduced sets s(cid:48)(b) are used only to generate
to show that

the UNSAT certiﬁcates. Hence,

is direct

it

8

Algorithm 3 SMT-BASED SEARCH

Algorithm 4 GENERATE-CERTIFICATE(s,

ˆxs∗ (t)
}

{

t∈G;

15:

t∈G) := ATTACK-DETECT(s(cid:48), t1);

1: status := UNSAT;
2: φB := (cid:80)
k;
3: while status == UNSAT do
4:

i∈{1,...,p} bi

≤

b := SAT-SOLVE(φB);
s(b) :=
1, 2, . . . , p
{
} −
( ˆdattack,s(b),
ˆxs(b)(t)
t∈G)
{
}
:= ATTACK-DETECT(s(b), t1);
if ˆdattack,s(b) == 1 then

supp(b);

5:

6:

7:
8:

φcert
:= GENERATE-CERTIFICATE(s(b),
φB := φB

φcert;

∧

ˆxs(b)(t)
{

t∈G);
}

end if

9:
10:
11: end while
12: s∗ = s(b);
13: return

Algorithm 3 still preserves the optimality of the state estimate
as stated by the following result.

Theorem 4. Let the linear dynamical system deﬁned in (2)
be 2k-sparse observable system. Consider a k-adversary sat-
isfying Assumptions 1-5. Consider the state estimate ˆxs∗ (t)
computed by Algorithm 3. Then, for any (cid:15) > 0 and δ > 0,
there exists a large enough N such that:

(cid:16)

P

tr (cid:0)EN,t1

(cid:0)es∗ eT

s∗

(cid:1)(cid:1)

(cid:16)

tr

P(cid:63)

sworst,p−k

(cid:17)

(cid:17)

+ (cid:15)

≤

1

−

≥

δ.

(24)

Note that although, for the sake of brevity, we did not
analyze analytically the worst case execution time (in terms
on number of iterations) of Algorithm 3, we show numerical
results in Section VI that support the claim that the proposed
SMT-like solver works much better in practice compared to
the exhaustive search procedure (Algorithm 2).

VI. NUMERICAL EXPERIMENTS

In this section, we report numerical results for Algorithms 2

and 3 as described by the experiments below.

A. Experiment 1: Residue test performance in Algorithm 2

In this experiment, we numerically check the performance
of the residue test involved in Algorithm 2 while checking
for effective attacks across sensor subsets. We generate a
stable system randomly with n = 20 (state dimension) and
p = 5 sensors. We select k = 2 sensors at random, and
apply a random attack signal to the two sensors. We apply
Algorithm 2 by running all the (cid:0)5
(cid:1) = 10 Kalman ﬁlters
(one for each distinct sensor subset of size 3) and do the
residue test corresponding to each sensor subset. Figure 2
shows the maximum entry in the residue test matrix Rs =
(cid:1) for the 10 different Kalman
EN,t1
ﬁlters. It is apparent from Figure 2 that only one Kalman ﬁlter
produces a state estimate that passes the residue test deﬁned in
Algorithm 1. This indeed corresponds to the set of attack-free
sensors in the experiment.

(cid:0)OsP(cid:63)

s + Ms

(cid:0)rsrT

O T

−

(cid:1)

3

s

s

ˆxs(t)
{

t∈G)
}

t1, . . . , t1 + N
{
O T
Mi
i −

−

(cid:1)

1
ηn(cid:12)
−
(cid:12);

}

2k + 1 smallest residues

2k + 1]) ;

s(cid:48) = s

{

(cid:1),

(cid:0)O T
i

(cid:12)
−
(cid:12)tr (cid:0)EN,t1

s
∈
G =
∈
OiP(cid:63)
s
−
Oi

1: Compute the residues for i
Oi ˆxs(t),
t
2: ri(t) := yi(t)
∀
(cid:1)
(cid:0)rirT
3: µi(t1) :=
i
4: Normalize the residues
5: µi(t1) := µi(t1)/λmax
µi(t1)
6: µ(t1) :=
i∈s ;
}
7: Sort the residues in ascending order
8:
9: Choose sensor indices of p
µ min r := Index (µ sorted[1 : p
10:
11: Search linearly for the UNSAT certiﬁcate
12: status = UNSAT; counter = 1; φconf-cert = 1;
13: while status == UNSAT do
14:

µ sorted(t1) := sortAscendingly(µ(t1));

−

−

s(cid:48) := s(cid:48)
µ min r[counter];
\
( ˆdattack,s(cid:48),
ˆxs(cid:48)(t)
}
{
if ˆdattack,s(cid:48) == 1 then

φconf-cert := φconf-cert ∧
counter := counter + 1;

(cid:80)

i∈s(cid:48) bi

1;

≥

else

16:
17:
18:
19:
20:
21:
22: end while
23: return φconf-cert

end if

status := SAT;

(cid:0)rsrT
s

(cid:1) − (cid:0)OsP(cid:63)
s

Fig. 2. Figure showing the maximum entry in the residue test matrix Rs =
(cid:1) for the 10 Kalman ﬁlters in Experiment
EN,t1
1 versus the threshold η = 0.7 (indicated by the dashed red line). As shown
in the ﬁgure, there is only one subset of sensors which satisﬁes the threshold
η, and this corresponds to the attack-free set of sensors.

s + Ms

O T

B. Experiment 2: Performance of SMT-based Search

In this experiment, we compare the sensor subset search
time for the SMT-based approach (Algorithm 3) with that
for the exhaustive search approach (Algorithm 2). For this
experiment, we ﬁx n = 50 (state dimension) and vary the
number of sensors from p = 3 to p = 15. For each system,
we pick one third of the sensors to be under attack, i.e.,
p/3
k =
. The attack signal is chosen as a linear function
(cid:99)
(cid:98)
of the measurement noise. For each system, we run the
(cid:1) Kalman ﬁlters to generate the state estimates
bank of (cid:0) p
corresponding to all sensor subsets of size p
k. We then use
both exhaustive search as well as the SMT-based search to ﬁnd
the sensor subset that satisﬁes the residue test in Algorithm 1.
Figure 3 shows the average time needed to perform the search

p−k

−

012345678901020Time(s)MaximumentryinRsWith SMT
Without SMT

60

40

20

)
s
(

e
m

i
t

h
c
r
a
e
S

0

3

4

5

6

8

9
7
Number of outputs p

10 11 12 13 14 15

Fig. 3. Comparison of sensor subset search times for exhaustive search and
SMT based search.

across 50 runs of the same experiment. Figure 3 suggests
that the SMT-based search has an exponential improvement
over exhaustive search as the number of sensors increases. In
particular, for p = 15, the SMT-based search out-performs
exhaustive search by an order of magnitude.

VII. SPARSE OBSERVABILITY: CODING THEORETIC VIEW

In this section, we revisit the sparse observability condition
against a k-adversary and give a coding theoretic interpretation
for the same. We demonstrate how techniques developed for
error correction in classical coding theory [12] can be used
for understanding the resilience of dynamical systems against
malicious attacks3. We ﬁrst describe our coding theoretic
interpretation for sensor attacks in a linear system, and then
discuss how it can be generalized for non-linear systems.

∈

−

−

Consider the linear dynamical system in (2) without the
process and sensor noise (i.e., x (t + 1) = Ax(t), y(t) =
Rn and
Cx(t) + a(t)). If the system’s initial state is x(0)
the system is θ-sparse observable, then clearly in the absence
θ
of sensor attacks, by observing the outputs from any p
sensors for n time instants (t = 0, 1, . . . , n
1) we can
exactly recover x(0) and hence, exactly estimate the state of
the plant. A coding theoretic view of this can be given as
follows. Consider the outputs from sensor d
1, 2, . . . , p
}
Rn. Thus, in the
for n time instants as a symbol
(cid:3), due to
2 . . .
(symbol) observation vector
p
Y
θ-sparse observability, any p
θ symbols are sufﬁcient (in the
−
absence of attacks) to recover the initial state x(0). Now, let
us consider the case of a k-adversary which can arbitrarily
corrupt any k sensors. In the coding theoretic view,
this
corresponds to arbitrarily corrupting any k (out of p) symbols
in the observation vector. Intuitively, based on the relationship
between error correcting codes and the Hamming distance
between codewords in classical coding theory [12], one can
expect the recovery of the initial state despite such corruptions
to depend on the (symbol) Hamming distance between the
observation vectors corresponding to two distinct initial states
= x(2)(0)). In this
(say x(1)(0) and x(2)(0) with x(1)(0)

Y
= (cid:2)

∈ {

Y

Y

Y

∈

d

1

9

context, the following lemma relates θ-sparse observability to
the minimum Hamming distance between observation vectors
in the absence of attacks.

Lemma 2. For a θ-sparse observable system, the minimum
(symbol) Hamming distance between observation vectors cor-
responding to distinct initial states is θ + 1.

Y

Y

Y

−

−
−

(1) and

(1) and

1 symbols in

Proof. Consider a system with p sensors, and observation
(2) corresponding to distinct initial states
vectors
x(1)(0) and x(2)(0). Due to θ-sparse observability, at most
(2) can be identical; if any
θ
p
Y
θ of the symbols are identical, this would imply x(1)(0) =
p
x(2)(0). Hence, the (symbol) Hamming distance between the
(2) (corresponding to x(1)(0)
observation vectors
Y
and x(2)(0)) is at least p
1) = θ + 1 symbols.
(p
Also, there exists a pair of initial states (cid:0)x(1)(0), x(2)(0)(cid:1),
(2)
such that the corresponding observation vectors
Y
1 symbols4 and differ in the
are identical in exactly p
−
rest θ + 1 symbols. Hence, the minimum (symbol) Hamming
distance between the observation vectors is θ + 1.

(1) and

(1) and

−

−

−

−

Y

Y

θ

θ

sensor corruptions,

θ sensor corruptions.

For a θ-sparse observable system, since the minimum Ham-
ming distance between the observation vectors corresponding
to distinct initial states is θ + 1, we can:
(1) correct up to k < θ+1
2
(2) detect up to k
≤
θ (sparse observ-
Note that (1) above is equivalent to 2k
ability condition for secure state estimation [4]). It should be
noted that a k-adversary can attack any set of k (out of p)
sensors, and the condition k < θ+1
is both necessary and
2
sufﬁcient for exact state estimation despite such attacks. When
θ+1
k
2 , it is straightforward to show a scenario where the
observation vector (after attacks) can be explained by multiple
initial states, and hence exact state estimation is not possible.
The following example illustrates such an attack scenario.

≥

≤

Y

(1) and

(1) and

Example 2. Consider a θ-sparse observable system with θ =
3, number of sensors p = 5, and a k-adversary with k = 2.
Clearly, the condition k < θ+1
is not satisﬁed in this example.
2
Let x(1)(0) and x(2)(0) be distinct initial states, such that
(2) have
the corresponding observation vectors
Y
(minimum) Hamming distance θ + 1 = 4 symbols. Figure 4
(2), and for the sake
depicts the observation vectors
Y
of this example, we assume that the observation vectors have
(1)
1) and differ in
the same ﬁrst symbol (i.e.,
1 =
the rest 4 symbols (hence, a Hamming distance of 4). Now, as
shown in Figure 4, suppose the observation vector after attacks
(2)
. Clearly, there are two
was
4 Y
possible explanations for this (attacked) observation vector:
(a) the initial state was x(1)(0) and sensors 4 and 5 were
attacked, or (b) the initial state was x(2)(0) and sensors 2 and
3 were attacked. Since there are two possibilities, we cannot
estimate the initial state exactly given the attacked observation

(1)
2 Y

(1)
3 Y

(2)
1 =

(2)
5

=

Y

Y

Y

Y

Y

Y

Y

(cid:104)

(cid:105)

1

3With a similar motivation, in [14] the authors use coding techniques to
enable secure state estimation in the presence of a corrupt observer with
unattacked sensor outputs.

4If there is no such pair of initial states, the initial state can be recovered
by observing any p − θ − 1 sensors. By deﬁnition, in a θ-sparse observable
system, θ is the largest positive integer, such that the initial state can be
recovered by observing any p − θ sensors.

(cid:54)
10

[15] S.-D. Wang, T.-S. Kuo, and C.-F. Hsu, “Trace bounds on the solution of
the algebraic matrix Riccati and Lyapunov equation,” IEEE Transactions
on Automatic Control, vol. 31, no. 7, pp. 654–656, Jul 1986.

A. Proof details for Theorem 2

APPENDIX

initial states x(1)(0) and x(2)(0),

Fig. 4.
tinct
vectors are
(cid:104)
(1)
2

Example with θ = 3, p = 5 and k = 2. For dis-
the corresponding observation
=
, there are two possibilities for the initial state:
Y
(a) x(1)(0) with attacks on sensors 4 and 5, or (b) x(2)(0) with attacks on
sensors 2 and 3.

(2). Given (attacked) observation vector
(2)
5

(1) and
Y
(2)
(1)
4
3
Y

Y
Y

Y

Y

Y

(cid:105)

1

vector. This example can be easily generalized to show the
necessity of the condition k < θ+1
2 .

For (noiseless) non-linear systems, by analogously deﬁning
θ-sparse observability, the same coding theoretic interpretation
holds. This leads to the necessary and sufﬁcient conditions for
attack detection and secure state estimation in any noiseless
dynamical system with sensor attacks.

REFERENCES

[1] S. Mishra, Y. Shoukry, N. Karamchandani, S. Diggavi, and P. Tabuada,
“Secure state estimation: optimal guarantees against sensor attacks in
the presence of noise,” in IEEE International Symposium on Information
Theory (ISIT), June 2015.

[2] F. Pasqualetti, F. Dorﬂer, and F. Bullo, “Control-theoretic methods for
cyberphysical security: Geometric principles for optimal cross-layer
resilient control systems,” Control Systems, IEEE, vol. 35, no. 1, pp.
110–127, Feb 2015.

[3] H. Fawzi, P. Tabuada, and S. Diggavi, “Secure estimation and control for
cyber-physical systems under adversarial attacks,” IEEE Transactions on
Automatic Control, vol. 59, no. 6, pp. 1454–1467, June 2014.

[4] Y. Shoukry and P. Tabuada, “Event-triggered state observers for sparse
sensor noise/attacks,” arXiv pre-print, Sep. 2013. [Online]. Available:
http://arxiv.org/abs/1309.3511

[5] Y. Shoukry, P. Nuzzo, A. Puggelli, A. L. Sangiovanni-Vincentelli, S. A.
Seshia, and P. Tabuada, “Secure state estimation for cyber physical
systems under sensor attacks: a satisﬁability modulo theory approach,”
arXiv pre-print, Dec. 2014.

[6] M. S. Chong, M. Wakaiki, and J. P. Hespanha, “Observability of linear
systems under adversarial attacks,” in American Control Conference
(ACC), 2015.

[7] M. Pajic, J. Weimer, N. Bezzo, P. Tabuada, O. Sokolsky, I. Lee,
and G. Pappas, “Robustness of attack-resilient state estimators,” in
ACM/IEEE International Conference on Cyber-Physical Systems (IC-
CPS), 2014.

[8] Y. Mo and B. Sinopoli, “Secure control against replay attacks,” in
Allerton Conference on Communication, Control, and Computing, 2009.
[9] C.-Z. Bai and V. Gupta, “On kalman ﬁltering in the presence of a
compromised sensor: fundamental performance bounds,” in American
Control Conference (ACC), 2014.

[10] J. Mattingley and S. Boyd, “Real-time convex optimization in signal
processing,” IEEE Signal Processing Magazine, vol. 27, no. 3, pp. 50–
61, May 2010.

[11] S. Farahmand, G. B. Giannakis, and D. Angelosante, “Doubly robust
smoothing of dynamical processes via outlier sparsity constraints,” IEEE
Trans. on Signal Processing, vol. 59, no. 10, pp. 4529–4543, Oct. 2011.
Cambridge

[12] R. Blahut, Algebraic Codes for Data Transmission.

University Press, 2003.

[13] T. Kailath, A. Sayed, and B. Hassibi, Linear Estimation. Prentice Hall,

2000.

1) Proof of (16) using LLN:
tr (cid:0)Msg

EN,t1

tr

(cid:16)

(cid:16)

(cid:1)

zsg zT
sg

(cid:17)(cid:17)

−
tr (cid:0)Msg

=

1
n

n−1
(cid:88)

l=0

(cid:1)

−

1
N

(cid:88)

t∈G

(cid:16)
zsg (t)zT

sg (t)

(cid:17)

tr

(cid:32)

tr (cid:0)Msg

1
n

(cid:1)

1
NB

−

(cid:88)

t∈Gl

(cid:16)

zsg (t)zT

(cid:17)
sg (t)

tr

(cid:33)

tr (cid:0)Msg

(cid:1)

1
NB

−

(cid:88)

t∈Gl

(cid:16)

zsg (t)zT

(cid:17)
sg (t)

tr

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

n−1
(cid:88)

(a)
=

l=0
n−1
(cid:88)

≤

(b)

≤

l=0

(cid:15)1,

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
n

((t

t
{

t1) mod n) = l

where (a) follows from partitioning time window G (of size
N ) into n groups G0, G1, . . . Gn−1 (each of size NB) such
that Gl =
, and (b) follows w.h.p.
(cid:17)
}
from LLN (for different time indices in Gl, tr
sg (t)
corresponds to i.i.d. realizations of the same random variable).
2) Cross term analysis and proof of (17): The cross term
can be written down as a sum of n terms

zsg (t)zT

−

(cid:16)

(cid:17)

(cid:16)

|

2EN,t1
Osg es
as shown below:

zT
sg

(cid:16)

2EN,t1

zT
sg

Osg es

(cid:17) (a)
=

2
n

=

2
n

(cid:33)

sg (t)Osg es(t)
zT

1
NB

(cid:88)

t∈Gl

(25)

(cid:32)

n−1
(cid:88)

l=0
n−1
(cid:88)

l=0

ζl,

where (a) follows from partitioning time window G (of size
N ) into n groups G0, G1, . . . Gn−1 (each of size NB) such
that Gl =
. Now, we will show that
}
each ζl has zero mean and vanishingly small variance for large
enough N . The mean analysis can be done as shown below:

t1) mod n) = l

t
{

((t

−

|

E (ζl) = E

(cid:32)

1
NB

(cid:88)

(cid:33)

sg (t)Osg es(t)
zT

(a)
=

1
NB

t∈Gl
(cid:16)

E

(cid:88)

t∈Gl

(cid:17)

zT
sg (t)

E (cid:0)Osg es(t)(cid:1) = 0,

(26)

where (a) follows from the independence of es(t) from zT
sg (t)
(due to assumptions 4 and 5). This implies that the cross term
2EN,t1
has zero mean. As a consequence of (26)
and (16),

Osg es

zT
sg

(cid:16)

(cid:17)

2(cid:15)1

(cid:16)

(cid:16)

E

≥
= E

EN,t1

EN,t1
(cid:16)

(cid:16)

(cid:16)

tr

tr

(cid:16)

Osg
(cid:16)(cid:0)eseT
(cid:17)

λmin

O T
sg

Osg

s −
E (cid:0)EN,t1

(cid:0)eseT

P(cid:63)
s
(cid:1) O T
sg

(cid:1) O T
sg
Osg

s −
P(cid:63)
s

(cid:17)(cid:17)(cid:17)

(cid:17)(cid:17)(cid:17)

(cid:0)tr (cid:0)eseT

s −

(cid:1)(cid:1)(cid:1) ,

P(cid:63)
s

(27)

[14] S. Mishra, N. Karamchandani, P. Tabuada, and S. Diggavi, “Secure state
estimation and control using multiple (insecure) observers,” in IEEE
Conference on Decision and Control (CDC), 2014.

(a)

≥

Y1Y(1)2Y(1)3Y(1)4Y(1)5Y1Y(2)2Y(2)3Y(2)4Y(2)5Y(1)Y(2)Y1Y(1)2Y(1)3Y(2)4Y(2)5Yx(1)(0)x(2)(0)where (a) follows from Lemma 3 (discussed in Appendix B).
Using (27),

E (cid:0)EN,t1

(cid:0)tr (cid:0)eseT

s

(cid:1)(cid:1)(cid:1)

2(cid:15)1
(cid:16)
O T
sg

Osg

≤

λmin

(cid:17) + tr (P(cid:63)

s ) .

(28)

We will use the intermediate result (28) in the variance analysis
of ζl =
zsg (t)

sg (t)Osg es(t) =
zT

s (t)O T
eT
sg

(cid:88)

(cid:88)

(cid:15)2,

1
NB

t∈Gl

1
NB

described below.

t∈Gl

For any (cid:15)2 > 0, there exists a large enough NB such that:
(cid:33)

(cid:32)

s (t)O T
eT
sg

zsg (t)

V ar

1
NB

(cid:88)

t∈Gl



(cid:32)

= E



1
NB

(cid:88)

t∈Gl

s (t)O T
eT
sg

zsg (t)

(cid:32)

(cid:32)

E

−

1
NB

(cid:88)

t∈Gl

s (t)O T
eT
sg

zsg (t)

(cid:33)2


(cid:33)(cid:33)2

1
NB

(cid:88)

t∈Gl

s (t)O T
eT
sg

(cid:33)2


zsg (t)



(cid:32)



(a)
= E

(cid:32)

= E

1
N 2
B


(b)
= E

(cid:32)

1
N 2
B

+

2
N 2
B
(cid:32)

(c)
= E

1
N 2
B

= E

(cid:32)

1
N 2
B

(cid:32)

(d)
= E

(cid:32)

= E

1
N 2
B

(e)
=

1
N 2
B

(f )

≤

1
N 2
B

s (t)O T
eT
sg

zsg (t)eT

s (t)O T
sg

zsg (t)

(cid:33)

(cid:88)

t∈Gl

+ E



2
N 2
B

(cid:88)

t,t(cid:48)∈Gl, t<t(cid:48)

s (t)O T
eT
sg

zsg (t)eT

s (t(cid:48))O T
sg

zsg (t(cid:48))





s (t)O T
eT
sg

zsg (t)eT

s (t)O T
sg

zsg (t)

(cid:33)

(cid:88)

t∈Gl
(cid:88)

(cid:88)

t∈Gl

(cid:88)

t∈Gl

t,t(cid:48)∈Gl, t<t(cid:48)

(cid:16)

E

s (t)O T
eT
sg

zsg (t)eT

s (t(cid:48))O T
sg

(cid:17)

E (cid:0)zsg (t(cid:48))(cid:1)

(cid:33)

s (t)O T
eT
sg

zsg (t)eT

s (t)O T
sg

zsg (t)

s (t)O T
eT
sg

zsg (t)

(cid:16)

O T
sg

zsg (t)

(cid:17)T

(cid:33)

es(t)

1
N 2
B

(cid:88)

tr

t∈Gl

t∈Gl
(cid:16)

tr

(cid:88)

(cid:18)

s (t)O T
eT
sg

zsg (t)

(cid:16)

O T
sg

(cid:17)T

zsg (t)

es(t)

(cid:19)(cid:33)

(cid:18)

(cid:88)

tr

O T
sg

zsg (t)

(cid:16)

O T
sg

(cid:17)T

zsg (t)

(cid:19)(cid:33)

es(t)eT

s (t)

(cid:16)

E

O T
sg

zsg (t)zT

sg (t)Osg

(cid:17)

E (cid:0)es(t)eT

s (t)(cid:1)(cid:17)

t∈Gl

(cid:88)

(cid:16)

λmax

O T
sg

Msg

Osg

(cid:17)

tr (cid:0)E (cid:0)es(t)eT

s (t)(cid:1)(cid:1)

λmax

Msg

t∈Gl
(cid:16)
O T
sg
NB

(cid:16)

λmax

Msg

O T
sg
NB

=

=

(cid:17)

Osg

(cid:17)

Osg

(cid:32)

(cid:32)

E

E

1
NB

(cid:88)

t∈Gl

1
NB

(cid:88)

t∈Gl

(cid:33)

tr (cid:0)es(t)eT

s (t)(cid:1)

(cid:33)

eT
s (t)es(t)

11

(cid:88)

(cid:33)

es

T (t)es(t)

t∈Gl
(cid:80)
t∈G eT

s (t)es(t)(cid:1)

(cid:16)

(cid:16)

nλmax

nλmax

(cid:17)

Osg

(cid:32)

E

Msg

O T
sg
NB

1
N

O T
sg

Msg

Osg

(cid:17)

E (cid:0) 1
N

NB

=

≤
(g)

(29)

≤
where (a) follows from (26), (b) follows from the in-
dependence of zsg (t(cid:48)) from eT
for
t(cid:48) > t, (c) follows from E (cid:0)zsg (t(cid:48))(cid:1) = 0, (d) follows
from eT
zsg (t) being a scalar, (e) follows from the
independence of zsg (t) from es(t), (f) follows from Lemma 3
(discussed in Appendix B) with,

s (t(cid:48))O T
sg

s (t)O T
sg

s (t)O T
sg

zsg (t)eT

(cid:18)

(cid:18)

E

λmax

O T
zsg (t)
sg
(cid:16)

(cid:16)

O T
sg

zsg (t)
(cid:17)

= λmax

O T
sg

Msg

Osg

.

(cid:17)T (cid:19)(cid:19)

(30)

→ ∞
ance of the cross term 2EN,t1

Finally, (g) follows from (28) for large enough NB. This com-
pletes the variance analysis of ζl, and clearly ζl has vanishingly
small variance as NB
. As a consequence, the vari-
(cid:16)
2
n
vanishingly small for NB
(follows from the Cauchy-
(cid:17)
Schwarz inequality). Since the cross term 2EN,t1
Osg es
has zero mean and vanishingly small variance, by the Cheby-
Osg es
(cid:15)1 holds w.h.p., and
shev inequality,
this completes the proof of (17).

(cid:12)
(cid:12)2EN,t1
(cid:12)

(cid:17)(cid:12)
(cid:12)
(cid:12) ≤

ζl is also

Osg es

→ ∞

n−1
(cid:88)

zT
sg

zT
sg

zT
sg

l=0

=

(cid:16)

(cid:16)

(cid:17)

B. Bounds on the trace of product of symmetric matrices

A useful lemma from [15] can be described as follows.
Lemma 3. If A and B are two symmetric matrices in Rn×n,
and B is positive semi-deﬁnite:

λmin (A) tr (B)

tr (AB)

≤

≤

λmax (A) tr (B) .

(31)

C. Results for the ﬁltering version of the Kalman ﬁlter

As stated in Section II, we use the prediction version of
the Kalman ﬁlter for deriving our main results in this paper.
Proving similar results for the ﬁltering version can be done
using the same techniques used for the prediction version. In
the remainder of this Section, we will ﬁrst describe the ﬁltering
setup with some additional notation, and then describe our
effective attack detector for the ﬁltering setup.

1) Filtering setup and additional notation: The state esti-
mate update rule for the ﬁltering version of the Kalman ﬁlter
(in steady state) is as shown below [13]:

ˆx(t) = ˆx(P )(t) + L

ˆx(P )(t + 1) = Aˆx(t),

(cid:16)

y(t)

−

Cˆx(P )(t)

(cid:17)

,

(32)

(33)

where L is the steady state Kalman ﬁlter gain, and ˆx(t) is
the (ﬁltered) state estimate at time t (which also depends
on the output at time t). We denote by Ls the steady state
Kalman ﬁlter gain when only outputs from sensor subset s

⊆

12

}

are used, and use F(cid:63)

1, 2, . . . , p
s for the corresponding ﬁlter-
{
ing error covariance matrix. In addition, we use the following
notation for the senor noise in subset s =
at
time t:

i1, i2, . . . , i|s|}

{

˜vs(t) =















vi1(t)
vi2(t)
...
vi|s|(t)

,

(34)

(35)

and deﬁne ∆s as shown below:
∆s = E (cid:0)zs(t)˜vT

s (t)LT
s

O T
s

(cid:1) ,

where zs(t) = Js ¯w(t) + ¯vs(t) (as deﬁned for the prediction
setup in Section III). Note that ∆s can be easily expressed
v, LT
(after evaluating the expectation in (35)) in terms of σ2
s ,
and O T
s ; we deﬁne ∆s just for conveniently describing our
detector and proving its performance guarantees. In the predic-
tion setup, we limited the the adversary through Assumptions
1-5; however, in the ﬁltering setup, to show similar results, we
require stronger versions of Assumptions 4 and 5 as described
below:

Assumption 6. The adversary’s knowledge at time t is statis-
tically independent of w(t(cid:48)) for t(cid:48)
t, i.e., a(t) is statistically
independent of

≥

w(t(cid:48))
t(cid:48)≥t.
}
{

Assumption 7. For an attack-free sensor i
the adversary’s knowledge at
statistically independent of

κκκ,
time t (and hence a(t)) is

1, 2, . . . , p

∈ {

} \

vi(t(cid:48))
t(cid:48)≥t.
}

{

Using these assumptions, we deﬁne the effective attack

detection problem for the ﬁltering setup as follows.

Deﬁnition 3 (((cid:15), s)-Effective Attack (ﬁltering)). Consider the
linear dynamical system under attack ΣaΣaΣa as deﬁned in (2), and
a k-adversary satisfying Assumptions 1-3 and Assumptions 6-
7. For the set of sensors s, an (cid:15) > 0, and a large enough
N, an attack signal is called ((cid:15), s)-effective at time t1 if
N
the following bound holds:

∈

tr (cid:0)EN,t1

(cid:0)eseT

s

(cid:1)(cid:1) > tr(F(cid:63)

s ) + (cid:15),

where es(t) = x(t)
estimate).

−

ˆxs(t) (with ˆxs(t) being the ﬁltered state

Note that, compared to Deﬁnition 1 for the prediction setup,
we have just replaced P(cid:63)
s by F(cid:63)
s as shown above. In the
following subsections, we describe the effective attack detector
for the ﬁltering setup and prove its performance guarantees.
2) (cid:15)-effective attack detector for ﬁltering setup: The ef-
fective attack detector for the ﬁltering setup is described in
Algorithm 5. Compared to Algorithm 1 for the prediction
setup, Algorithm 5 mainly differs in the residue test; F(cid:63)
s is
used in place of P(cid:63)
s account
s , and the extra terms
for the dependence of the estimation error at time t on the
sensor noise at time t (details in the following subsection
the expected value
on performance guarantees). Note that
of rs(t)rT
s (t) in the absence of attacks is exactly equal to
OsF(cid:63)
s ; as in the prediction version,
s
the residue test basically checks if the sample average of
rs(t)rT
s (t) in the presence of attacks is close to its expected
value in the absence of attacks.

s + Ms

∆T

∆T

O T

∆s

∆s

−

−

−

−

Algorithm 5 FILTERING ATTACK-DETECT(s, t1)

1: Run a Kalman ﬁlter that uses all measurements from
time t1 and compute the

sensors indexed by s until
estimate ˆxs(t1)
2: Recursively repeat

Rn.

∈

calculate all estimates ˆxs(t)
1, . . . , t1 + N

.

∈

1
}

3: For time t

−
G, calculate the block residue:

the previous step N

Rn,

t
∀

∈

−
G =

1 times to
t1, t1 +
{

∈
rs(t) = ¯ys(t)

Os ˆxs(t)

−

G.

t
∀

∈

4: if block residue test deﬁned below holds,

EN,t1

(cid:0)rsrT

s

(cid:1)

(cid:0)OsF(cid:63)

s

−

O T

s + Ms

(cid:1)

∆T
∆s
s
−
(cid:52) η 1n|s|1T
n|s|,

−

(36)

(cid:17)

(cid:15) ,

then

where 0 < η

(cid:16) λmin,s\k
3n(|s|−k)
≤
assert ˆdattack,s(t1) := 0

5:
6: else
7:
8: end if
9: return ( ˆdattack,s(t1),

assert ˆdattack,s(t1) := 1

ˆxs(t)
}

{

t∈G)

3) Performance guarantees for Algorithm 5: The following
lemma states the performance guarantees for Algorithm 5 in
the context of detecting (cid:15)-effective attacks in the ﬁltering setup.

3 and Assumptions 6

Lemma 4. Let the linear dynamical system as deﬁned in (2)
be 2k-sparse observable. Consider a k-adversary satisfying
Assumptions 1
7, and a sensor subset
k. For any (cid:15) > 0 and δ >
p
s
0, there exists a large enough time window length N such
that when Algorithm 5 terminates with ˆdattack,s(t1) = 0, the
following probability bound holds:

−
1, 2, . . . , p
}

s
| ≥
|

with

⊆ {

−

−

(cid:16)

P

tr (cid:0)Et1,N

(cid:0)eseT

s

(cid:1)

(cid:1)

F(cid:63)
s

−

≤

(cid:17)

(cid:15)

δ,

1

−

≥

(37)

where es(t) = x(t)
error.

−

ˆxs(t) is the (ﬁltering) state estimation

Proof. The proof is similar to that for the prediction version
(Lemma 1). The main difference lies in the cross term analysis;
it is more involved than in the prediction version due to the
dependence of estimation error at time t on the sensor noise
at time t. We describe the proof details below.
Since we assume that the set s has cardinality

k, we
p
s with cardinality
can conclude that there exists a subset sg
2k sensors such that all its sensors are attack-
sg
|
free (subscript g in sg stands for good sensors in s). Hence,
by decomposing the set s into an attack-free set sg and a
potentially attacked set s
sg, we can conclude that, after a
permutation similarity transformation for (36), the following
holds for the attack-free subset sg:

s
| ≥

| ≥

⊂

−

−

p

\

|

EN,t1

(cid:16)
rsg rT
sg

(cid:17)

Osg F(cid:63)
s

O T

sg −

−

Msg + ∆sg + ∆T
sg

(cid:52) η 1n(|s|−k)1T

n(|s|−k),
(38)

where ∆sg = E

(cid:16)

zsg (t)˜vT

s (t)LT
s

O T
sg

(cid:17)

. Therefore,

(cid:16)

tr

EN,t1

(cid:16)

rsg rT
sg

(cid:17)

Osg F(cid:63)
s

−

O T

sg −
n(
|

≤

Msg + ∆sg + ∆T
sg
k)η = (cid:15)1.
s
| −

(cid:17)

(39)

As
(cid:16)
tr

in
EN,t1

(cid:16)

the
rsg rT
sg

prediction
(cid:17)(cid:17)
as:

version, we

can

rewrite

13

(cid:33)

sg (t)Osg es(t)
zT

terms as shown below:

(cid:16)

2EN,t1

zT
sg

Osg es

(cid:17) (a)
=

2
n

=

2
n

1
NB

(cid:88)

t∈Gl

(cid:32)

n−1
(cid:88)

l=0
n−1
(cid:88)

l=0

ζl,

(cid:16)
EN,t1

tr

(cid:16)

= tr

(cid:17)(cid:17)

rsg rT
sg
(cid:16)
Osg
EN,t1
(cid:16)

+ 2EN,t1

eT
s

O T
sg

zsg

(cid:0)eseT
s
(cid:17)

(cid:17)

(cid:1) O T
sg

+ tr

(cid:16)

EN,t1

(cid:16)
zsg zT
sg

(cid:17)(cid:17)

.

(40)

By combining (39) and (40):

(cid:16)

Osg

tr

EN,t1

(cid:1) O T

s

(cid:0)eseT
tr (cid:0)Msg
2EN,t1

(cid:1)

Osg F(cid:63)
s
(cid:16)

EN,t1
(cid:17)

O T
sg

zsg

sg −
tr

−
(cid:16)
eT
s

≤

−

2EN,t1

(cid:16)

eT
s

O T
sg

(a)

≤
(b)

≤

2(cid:15)1

−

3(cid:15)1,

(cid:17)

O T
sg

(cid:16)

(cid:17)(cid:17)

zsg zT
sg
2tr (cid:0)∆sg
(cid:17)

−

zsg

+ (cid:15)1

(cid:1)

2tr (cid:0)∆sg

−

(cid:16)

where (a) follows w.h.p. due to the law of large num-
bers (LLN) for large enough N (as shown in Appendix
A1), and (b) follows w.h.p. by showing that the cross term
(cid:1) and van-
2EN,t1
has mean equal to
ishingly small variance for large enough N . The cross term
analysis is described in detail in Appendix D. Using (42), the
following holds:

2tr (cid:0)∆sg

eT O T
sg

zsg

−

(cid:17)

(cid:16)

tr

EN,t1

(cid:0)eseT

s −

F(cid:63)
s

(cid:1) O T
sg

Osg

(cid:17)

3(cid:15)1,

≤

(43)

and hence, we get the following bound which completes the
proof:

tr (cid:0)EN,t1

(cid:0)eseT

s

(cid:1)

F(cid:63)
s

(cid:1) (c)
≤

−

3(cid:15)1
(cid:16)
O T
sg

(cid:17)

Osg

(d)

3(cid:15)1

≤

λmin,s\k ≤

(cid:15)

λmin

(44)

where (c) follows from Lemma 3 in Appendix B and (d)
follows from the deﬁnition of λmin,s\k. Note that, it follows
2k and 2k-sparse observability, that both
from
−
and λmin,s\k are bounded away from zero.
λmin

p
sg
(cid:17)
(cid:16)
| ≥
|
Osg
O T
sg

Using Lemma 4, deriving results for secure state estimation
in the ﬁltering setup is straightforward, and we skip the details
for brevity.

D. Cross term analysis for ﬁltering and proof of (42)

As
2EN,t1

in
(cid:16)
zT
sg

the
Osg es

(cid:17)

term
prediction
can be written down as a sum of n

setup,

cross

the

((t

t
{

where (a) follows from partitioning time window G (of size
N ) into n groups G0, G1, . . . Gn−1 (each of size NB) such
that Gl =
. Now, we will show that
}
|
tr (cid:0)∆sg
(cid:1) and vanishingly small
each ζl has mean equal to
variance for large enough N . The mean analysis can be done
as shown below:
(cid:32)

t1) mod n) = l

(cid:33)

−

−

E (ζl) = E

1
NB

sg (t)Osg es(t)
zT

(a)
= E

(cid:32)

1
NB

sg (t)Osg (˜es(t)
zT

Ls ˜vs(t))

−

(cid:33)

(cid:1) (41)

(42)

(cid:32)

= E

E

−

1
NB
(cid:32)

(cid:33)

(cid:88)

t∈Gl

sg (t)Osg ˜es(t)
zT

(cid:88)

sg (t)Osg Ls ˜vs(t)
zT

(cid:33)

(cid:88)

t∈Gl

(cid:88)

t∈Gl

1
NB

(cid:88)

t∈Gl
(cid:16)

E

(b)
=

1
NB

t∈Gl
(cid:32)

1
NB

E

−

(cid:32)

(cid:32)

(cid:32)

(cid:32)

(cid:32)

1
NB

1
NB

1
NB

1
NB

1
NB

=

E

−

=

E

−

=

E

−

=

E

−

=

E

−

zT
sg (t)

(cid:17)

E (cid:0)Osg ˜es(t)(cid:1)

(cid:88)

t∈Gl

(cid:88)

t∈Gl

(cid:88)

t∈Gl

(cid:88)

t∈Gl

(cid:88)

t∈Gl

(cid:88)

(cid:33)

sg (t)Osg Ls ˜vs(t)
zT

(cid:33)

sg (t)Osg Ls ˜vs(t)
zT

(cid:16)

(cid:17)
sg (t)Osg Ls ˜vs(t)
zT

tr

(cid:33)

(cid:16)(cid:0)Osg Ls ˜vs(t)(cid:1)T

tr

(cid:17)

zsg (t)

(cid:33)

(cid:16)

tr

(cid:16)

tr

s (t)LT
˜vT
s

O T
sg

(cid:33)

(cid:17)

zsg (t)

zsg (t)˜vT

s (t)LT
s

O T
sg

(cid:33)

(cid:17)

t∈Gl
(cid:16)

tr

(cid:16)

E

zsg (t)˜vT

s (t)LT
s

O T
sg

(cid:17)(cid:17)

=

=

=

(cid:88)

1
NB

−

t∈Gl
(cid:88)

1
NB
tr (cid:0)∆sg

t∈Gl
(cid:1) ,

−

−

tr (cid:0)∆sg

(cid:1)

(45)

where (a) follows from expressing es(t) as ˜es(t)
Ls ˜vs(t)
(i.e., separating out the sensor noise at time t component
in es(t)), and (b) follows from the independence of ˜es(t)
from zT
sg (t) (follows from assumptions 6 and 7). This implies
that the cross term 2EN,t1
has mean equal to

Osg es

−

(cid:17)

(cid:16)

zT
sg

14

−

2tr (cid:0)∆sg

2(cid:15)1

E

≥
= E

(a)

≥

(cid:1). Also, using (45) and (41),
(cid:16)

(cid:16)

(cid:16)

tr

(cid:16)

tr

(cid:16)

EN,t1

EN,t1
(cid:16)

λmin

O T
sg

Osg

(cid:0)eseT

Osg
(cid:16)(cid:0)eseT
(cid:17)

s −
E (cid:0)EN,t1

F(cid:63)
s
(cid:1) O T
sg

(cid:1) O T
sg
Osg

s −
F(cid:63)
s

(cid:17)(cid:17)(cid:17)

(cid:17)(cid:17)(cid:17)

(cid:0)tr (cid:0)eseT

s −

(cid:1)(cid:1)(cid:1) ,

F(cid:63)
s

(46)

where (a) follows from Lemma 3 (discussed in Appendix B).
Using (46),
E (cid:0)EN,t1

(cid:0)tr (cid:0)eseT

(cid:17) + tr (F(cid:63)

(47)

s ) .

(cid:1)(cid:1)(cid:1)

s

2(cid:15)1
(cid:16)
O T
sg

Osg

≤

λmin

We will use the above intermediate result in the variance
analysis done below.

The variance analysis for ζl can be done as shown below:
(cid:33)2



sg (t)Osg es(t)
zT

(cid:88)



(cid:32)

E

1
NB


(cid:32)

t∈Gl

= E



(cid:32)

= E

1
NB

(cid:88)

t∈Gl

s (t)O T
eT
sg

zsg (t)

(cid:33)2


s (t)O T
eT
sg

(cid:17)2(cid:33)

zsg (t)

(cid:88)

(cid:16)

t∈Gl

+ E



2
N 2
B

(cid:88)

t,t(cid:48)∈Gl,t<t(cid:48)

s (t)O T
eT
sg

zsg (t)eT

s (t(cid:48))O T
sg

zsg (t(cid:48))



(cid:32)

= E

s (t)O T
eT
sg

(cid:17)2(cid:33)

zsg (t)

(cid:88)

(cid:16)

t∈Gl

s (t)O T
eT
sg

zsg (t)˜eT

s (t(cid:48))O T
sg

zsg (t(cid:48))



1
N 2
B


1
N 2
B


+ E



2
N 2
B





E

2
N 2
B

−

(cid:88)

t,t(cid:48)∈Gl,t<t(cid:48)

(cid:88)

t,t(cid:48)∈Gl,t<t(cid:48)

E

×

(cid:16)

˜vT
s (t(cid:48))LT
s
(cid:17)2(cid:33)

(cid:88)

(cid:16)

s (t)O T
eT
sg

zsg (t)

(cid:17) (cid:17)

O T
sg

zsg (t(cid:48))

t∈Gl
(cid:88)

(cid:0)tr (cid:0)∆sg

(cid:1)(cid:1)2

t,t(cid:48)∈Gl,t<t(cid:48)

(cid:16)

s (t)O T
eT
sg

(cid:17)2(cid:33)

zsg (t)

1)

−

(cid:0)tr (cid:0)∆sg

(cid:1)(cid:1)2

,

(48)

(b)
= E

(cid:32)

1
N 2
B

2
N 2
B
(cid:32)

+

= E

+

(cid:88)

t∈Gl

1
N 2
B
NB (NB
N 2
B

(a)
s (t)O T
sg
from E
(cid:17)

where
from eT
follows
(cid:16)
s (t)O T
eT
sg

follows
from independence
s (t(cid:48))O T
zsg (t)˜eT
for
sg
(cid:16)
(cid:17)
O T
s (t(cid:48))LT
˜vT
zsg (t(cid:48))
sg
s
(cid:1). Now, we
tr (cid:0)∆sg
on
analyzing the ﬁrst term in (48) as shown below. For any
(cid:15)2 > 0, there exists a large enough NB such that:

zsg (t(cid:48))
of
t < t(cid:48), and (b)
= tr (cid:0)∆sg
and

zsg (t)

focus

−

=

E

(cid:1)

(cid:32)

E

1
N 2
B
(cid:32)

s (t)O T
eT
sg

zsg (t)

(cid:17)2(cid:33)

(cid:88)

(cid:16)

t∈Gl





= E

= E

= E

= E



1
N 2
B

(cid:32)

(cid:32)

1
N 2
B

1
N 2
B

(cid:32)

1
N 2
B
(cid:32)

(cid:17)2(cid:33)

(cid:88)

(cid:16)

t∈Gl

(cid:88)

t∈Gl

(˜es(t)

−

Ls ˜vs(t))T O T
sg

zsg (t)

(cid:16)(cid:0)˜eT

s (t)

−

s (t)LT
˜vT
s

(cid:1) O T
sg

zsg (t)

(cid:17)2(cid:33)

(cid:88)

(cid:16)

t∈Gl

(cid:88)

(cid:16)

t∈Gl

s (t)O T
˜eT
sg

s (t)O T
˜eT
sg

zsg (t)

s (t)LT
˜vT
s

−
(cid:17)2(cid:33)

zsg (t)

(cid:17)2(cid:33)

zsg (t)

O T
sg

E

−

+ E

2
N 2
B

(cid:88)

t∈Gl

(cid:32)

1
N 2
B

(cid:88)

(cid:16)

t∈Gl

s (t)O T
˜eT
sg

zsg (t)˜vT

s (t)LT
s

O T
sg

zsg (t)

s (t)LT
˜vT
s

O T
sg

(cid:17)2(cid:33)

zsg (t)

(cid:33)

(cid:33)

s (t)O T
˜eT
sg

zsg (t)˜vT

s (t)LT
s

O T
sg

zsg (t)

s (t)O T
eT
sg

zsg (t)˜vT

s (t(cid:48))LT
s

O T
sg

zsg (t(cid:48))



(cid:88)

(cid:16)

t∈Gl
(cid:88)

s (t)O T
eT
sg

zsg (t)

(cid:17)2(cid:33)

E

(cid:16)

s (t)O T
eT
sg

zsg (t)˜eT

s (t(cid:48))O T
sg

(cid:17)

E (cid:0)zsg (t(cid:48))(cid:1)

t,t(cid:48)∈Gl,t<t(cid:48)

2
N 2
B

(cid:88)

t,t(cid:48)∈Gl,t<t(cid:48)

s (t)O T
eT
sg

zsg (t)˜vT

s (t(cid:48))LT
s

O T
sg

zsg (t(cid:48))



= E



s (t)O T
eT
sg

(cid:17)2(cid:33)

zsg (t)

+ 0

(cid:88)

(cid:16)

t∈Gl

(a)
= E

(cid:32)

1
N 2
B

2
N 2
B


E



+

−

(cid:32)

= E

1
N 2
B


E



−

2
N 2
B

(cid:88)

t,t(cid:48)∈Gl,t<t(cid:48)

s (t)O T
eT
sg

zsg (t)˜vT

s (t(cid:48))LT
s

O T
sg

zsg (t(cid:48))



= E

= E

(cid:32)

1
N 2
B

2
N 2
B

−

(cid:88)

(cid:16)

s (t)O T
eT
sg

(cid:17)2(cid:33)

zsg (t)

t∈Gl
(cid:88)

(cid:16)

(cid:16)

E

s (t)O T
eT
sg

(cid:17)

zsg (t)

t,t(cid:48)∈Gl,t<t(cid:48)

−

+



(cid:88)

(cid:16)

t∈Gl

s (t)O T
˜eT
sg

(cid:17)2(cid:33)

zsg (t)

(cid:32)

1
N 2
B
(cid:32)

E

1
NB
(cid:32)

1
N 2
B
(cid:18)

(cid:80)

(cid:88)

t∈Gl

2
N 2
B
(cid:18)(cid:16)

E

s (t)LT
˜vT
s

O T
sg

(cid:88)

(cid:16)

t∈Gl

s (t)O T
˜eT
sg

E(˜eT
s (t))
NB

t∈Gl

(cid:19)

(cid:16)

E

O T
sg

−

+

2

E

1
NB

NB

(cid:18)(cid:16)

s (t)LT
˜vT
s

O T
sg

zsg (t)

(cid:17)2(cid:19)

zsg (t)

(cid:17)2(cid:33)

zsg (t)

s (t)LT
s

(cid:17)

O T
sg

zsg (t)

zsg (t)˜vT
(cid:17)2(cid:19)

s (t)O T
˜eT
sg

zsg (t)˜eT

s (t)O T
sg

zsg (t)

(cid:33)

(b)

≤

(cid:15)2,

15

(49)

(cid:17)

zsg (t)

O T
sg

where (a) follows from Lemma 3 (discussed in Appendix B),
and (b) follows for large enough NB from the boundedness
of E (cid:0)EN,t1

(cid:1)(cid:1)(cid:1) as shown in (47).
Using (49) and (48), for any (cid:15)3 > 0, there exists a large

(cid:0)tr (cid:0)eseT

s

enough NB such that:
V ar(ζl) = E(ζ 2
l )

(E(ζl))2

−
(cid:15)3 + (cid:0)tr (cid:0)∆sg

(a)

≤

(cid:1)(cid:1)2

−

(cid:0)tr (cid:0)∆sg

(cid:1)(cid:1)2

= (cid:15)3,

(50)

where (a) follows from (49) and (48). This completes the
variance analysis of ζl, and clearly ζl has vanishingly small
variance as NB
. As a consequence, the variance of the

cross term 2EN,t1

→ ∞
(cid:16)
zT
sg

Osg es

(cid:17)

=

2
n

n−1
(cid:88)

l=0

ζl is also vanishingly

(cid:88)

(cid:16)

tr

s (t)O T
˜eT
sg

zsg (t)zT

(cid:17)
sg (t)Osg ˜es(t)

(cid:33)

small for NB
inequality). This completes the proof of (42).

→ ∞

(follows from the Cauchy-Schwarz

= E

−

+

= E

−

+

= E

−

+

= E

2

1
NB
(cid:32)

1
N 2
B
(cid:18)

(cid:80)

2

1
NB
(cid:32)

1
N 2
B
(cid:18)

(cid:80)

=

=

2

−

+

1
NB
1
N 2
B
(cid:18)

2

−

+

1
NB
1
N 2
B
(cid:18)

−

+

2

1
NB

(cid:32)

1
N 2
B
(cid:18)

(cid:80)

(cid:88)

t∈Gl

NB

(cid:18)(cid:16)

E

2

1
NB
(cid:32)

E(˜eT
s (t))
NB

t∈Gl

(cid:19)

(cid:16)

E

O T
sg

s (t)LT
˜vT
s

O T
sg

zsg (t)

s (t)LT
s

zsg (t)˜vT
(cid:17)2(cid:19)

s (t)O T
˜eT
sg

zsg (t)zT

sg (t)Osg ˜es(t)

(cid:33)

(cid:88)

t∈Gl

1
N 2
B
(cid:18)

(cid:80)

E(˜eT
s (t))
NB

t∈Gl

(cid:19)

(cid:16)

E

O T
sg

NB

(cid:18)(cid:16)

E

s (t)LT
˜vT
s

O T
sg

zsg (t)

zsg (t)˜vT
(cid:17)2(cid:19)

s (t)LT
s

(cid:17)

zsg (t)

O T
sg

t∈Gl

E(˜eT
s (t))
NB

t∈Gl

(cid:19)

(cid:16)

E

O T
sg

NB

(cid:18)(cid:16)

E

˜vT
s (t)LT
s

O T
sg

zsg (t)

s (t)LT
s

(cid:17)

zsg (t)

O T
sg

zsg (t)˜vT
(cid:17)2(cid:19)

˜es(t)˜eT

s (t)O T
sg

zsg (t)zT

sg (t)Osg

(cid:33)

(cid:17)

(cid:88)

(cid:16)

tr

t∈Gl

s (t)LT
s

(cid:17)

zsg (t)

O T
sg

zsg (t)˜vT
(cid:17)2(cid:19)

(cid:88)

tr

E (cid:0)˜es(t)˜eT

s (t)(cid:1) E

(cid:16)

O T
sg

zsg (t)zT

sg (t)Osg

(cid:17)(cid:17)

(cid:19)

(cid:16)

E

O T
sg

O T
sg

zsg (t)

E(˜eT
s (t))
NB

t∈Gl

NB

(cid:18)(cid:16)

E

s (t)LT
˜vT
s
(cid:16)

t∈Gl

(cid:80)

t∈Gl

(cid:19)

E(˜eT
s (t))
NB

NB

(cid:18)(cid:16)

E

s (t)LT
˜vT
s
(cid:16)

tr

E (cid:0)˜es(t)˜eT

O T
sg

zsg (t)
s (t)(cid:1) (cid:16)

(cid:88)

t∈Gl

(cid:80)

(cid:19)

E(˜eT
s (t))
NB

t∈Gl

(cid:16)

E

O T
sg

s (t)LT
s

(cid:17)

zsg (t)

O T
sg

zsg (t)˜vT
(cid:17)2(cid:19)

(cid:17)(cid:17)

Msg

Osg

O T
sg

(cid:16)

E

O T
sg

s (t)LT
s

(cid:17)

zsg (t)

O T
sg

zsg (t)˜vT
(cid:17)2(cid:19)

NB

(cid:18)(cid:16)

E

s (t)LT
˜vT
s

O T
sg

zsg (t)

(a)

λmax

≤

(cid:17)

Osg

(cid:16)

Msg

O T
sg
N 2
B

(cid:80)

t∈Gl

E(˜eT
s (t))
NB

(cid:19)

(cid:18)

2

NB

(cid:18)(cid:16)

−

+

E

1
NB

s (t)LT
˜vT
s

O T
sg

zsg (t)

tr (cid:0)E (cid:0)˜es(t)˜eT

s (t)(cid:1)(cid:1)

(cid:88)

t∈Gl

(cid:16)

E

O T
sg

s (t)LT
s

(cid:17)

zsg (t)

O T
sg

zsg (t)˜vT
(cid:17)2(cid:19)

