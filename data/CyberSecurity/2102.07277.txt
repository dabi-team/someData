Anomaly Detection for Scenario-based Insider Activities using CGAN Augmented
Data

R G Gayathri, Atul Sajjanhar, Yong Xiang and Xingjun Ma
School of Information Technology
Deakin University
Geelong, VIC 3217, Australia
{gradhabaigopina, atul.sajjanhar, yong.xiang, daniel.ma}@deakin.edu.au

1
2
0
2

l
u
J

8

]

R
C
.
s
c
[

2
v
7
7
2
7
0
.
2
0
1
2
:
v
i
X
r
a

Abstract—Insider threats are the cyber attacks from the
trusted entities within an organization. An insider attack is
hard to detect as it may not leave a footprint and potentially
cause huge damage to organizations. Anomaly detection is
the most common approach for insider threat detection. Lack
of real-world data and the skewed class distribution in the
datasets makes insider threat analysis an understudied research
area. In this paper, we propose a Conditional Generative
Adversarial Network (CGAN) to enrich under-represented
minority class samples to provide meaningful and diverse data
for anomaly detection from the original malicious scenarios.
Comprehensive experiments performed on benchmark dataset
demonstrates the effectiveness of using CGAN augmented data,
and the capability of multi-class anomaly detection for insider
activity analysis. Moreover, the method is compared with other
existing methods against different parameters and performance
metrics.

Keywords-insider threat; anomaly detection; adversarial
training; generative adversarial network; data augmentation

I. INTRODUCTION

Organizations are always at high risk from various kinds
of cyber attacks. The attacks originated within the organi-
zation, referred to as insider attacks, where attackers are in
close association with the workplace directly or indirectly
and physically or logically are of serious concern. Recently,
the reports indicate a drastic rise in the frequency of insider
attacks which force the experts to study it more seriously.
A study sponsored by ObserveIT and IBM, conducted by
Ponemon Institute reveals a 47% increase in the insider
incidents in last two years; 3200 in 2018 to 4700 in 2020
[1].

Insider threat does not happen in a single day. It needs a
lot of time and effort to perform an attack. Various attacking
strategies are identiﬁed from the past experiences and attack
patterns are listed as scenarios [2]. Detailed study of insider
threats reveals that each malicious activity results out of
more than one fraudulent action on the trusted resources
accessed by the attacker. Earlier research initiatives mapped
the malicious insider activities to several scenarios namely
Data Exﬁltration (Scenario 1), IT Sabotage (Scenario 2), and
Intellectual Property Theft (Scenario 3) and so on.

Though the severity of its impact and the rising numbers
and frequency are well-known, the unavailability of real-
world data due to privacy reasons and the skewed data dis-
tributions marked the insider threat analysis an understudied
cyber attack. The insider threat analysis is a typical case of
anomaly detection usecase where the anomalous actions are
the rarest. Anomaly detection is highly signiﬁcant in all real-
world applications [3]; especially cybersecurity. In general,
insider threat analysis is performed as an anomaly detection
task, usually as a binary or one-class classiﬁcation learning
problem.

Supervised learning models built with insufﬁcient data
from participating classes tend to overﬁt thereby learning
only the predominant classes resulting in degraded training
efﬁcacy. These models fail to generalize on test data. Though
many solutions exist to handle overﬁtting, trying to collect
more data is the promising method. Meaningful and reliable
data samples representing every single class in the data
deﬁnitely contribute well to the improved anomaly detection
methods.

To the best of our knowledge, this is the ﬁrst attempt
using a generative model to enrich the minority data sam-
ples of various insider activities and perform multi-class
classiﬁcation based anomaly detection. The main aim is
to generate data for various underrepresented malicious
scenarios that result in a suspicious action. We propose
a conditional generative adversarial network (CGAN) to
reduce the negative impacts of skewed class distributions
in insider threat dataset by boosting the available data and
perform anomaly detection. We use t-distributed Stochastic
Neighbor Embedding (t-SNE), a manifold-learning based
visualization method to perform the qualitative analysis of
the CGAN generated data.

We present a systematic evaluation report that gives the
detailed analysis on how the proposed approach improved
the performance in terms of popular measures. Compre-
hensive experiments are performed based on a benchmark
dataset under various settings to demonstrate the effective-
ness of synthetic data generation for insider detection in
comparison with the existing works.

The rest of this paper is organized as follows. Section

 
 
 
 
 
 
II summarizes the existing insider threat approaches using
machine learning (ML) and deep learning (DL) methods and
synthetic data generation using CGAN. Section III presents
technical overview of the proposed approach. Section IV
briefs about the data description being used for validation
and the algorithms used followed by evaluation on the
performance of our method in terms of various metrics.
Section V concludes the paper and identiﬁes potential future
research directions.

II. RELATED WORK

Insider threat analysis has been studied for many years.
But the research community could not contribute a lot in
this attack. The limited availability of real-world data has
hindered the exhaustive exploration of effective solutions.
Nowadays, it attracts wider attention due to the increase
in frequency of attacks and the advent of promising data
analysis techniques.

An employee behaving normally is very common; but
an insider activity is hard to identify and might go undis-
covered. In this situation, the presence of non-malicious
activities are signiﬁcant majority compared to the malicious
ones which are very scarce. This kind of highly imbalanced
data are unusable as training data for ML/DL models. The
signiﬁcance of class imbalance has not been dealt with
clearly and adequately in the literature so far, speciﬁcally
on AI-based solutions for insider threat analysis.

The recent surveys [4] reveal that very few publications
on insider threat with deep learning have applied methods
to balance the disproportionate class samples. In the paper
[5], oversampling is used to balance the class imbalance
followed by an ensemble of one-class classiﬁers. The authors
proposed an Local Outlier Factor (LOF) based oversampling
of false-positive instances that are to generate synthetic data
points.

Some other recent works include random oversampling of
the training set with various sampling ratios [6] following
a binary classiﬁcation for each scenario, generating manu-
ally augmented data using an existing dataset to create an
augmented dataset [7], spread sub-sampling method [8] and
SMOTE based data adjustment [9].

Recently, data augmentation using vanillaGAN has been
performed on insider threat analysis [10]. The authors used a
GAN with fully connected layers to generate the data. Tree-
based classiﬁer models are used to test the performance of
the data adjusted samples; these models are also prone to
overﬁtting which can result in very high performance scores.
The performance seems to be exemplary when compared
to all existing models, but the approach makes a lot of
assumptions. VanillaGAN convergence and mode collapse,
the two tricky aspects of GAN are not dealt with in detail.
The qualitative and quantitative evaluation for synthetic data
is very vague from the experiments. Moreover, robustness of
the data created using generative models is debatable.

The use of adversarial training approaches and synthetic
data generation in other application areas like medical
imaging and the extensive usage of GANs in cybersecurity
problems like intrusion detection motivated us to investigate
the potential of GANs for insider threat detection. We
discuss the proposed method in detail
in the following
sections.

III. PROPOSED METHOD

We follow a multi-stage workﬂow to perform the insider
threat analysis. The overall process is split into three sequen-
tial stages: (i) Behaviour Extraction (ii) Conditional GAN-
based Data Generation (iii) Anomaly detection. First step
performs the pre-processing and feature space generation.
Second step performs the data augmentation. Finally, the
anomaly detection is carried out. Each step is explained in
detail in the coming sections.

Let the original dataset be IOriginal extracted after the
feature engineering stage. IOriginal is split into two subsets:
train IT rain and test IT est. The generative model is used to
generate synthetic training data ISynthetic. The training split
from the original dataset, IT rain and the synthetic training
dataset, ISynthetic are combined to form the augmented
training set IAugment which is used for anomaly detection.
Fig. 1 provides a detailed outline of the proposed workﬂow.

Figure 1. Overview of GAN based Insider Threat Analysis

A. Behaviour Extraction

This section deals with the feature space generation for
the insider threat analysis. Context based behavior proﬁling
is used to generate the feature set IOriginal for the anomaly
detection. We used the features from the paper [6]. However,
each user is identiﬁed as an insider based on the entire
activity log instead of those related to the particular scenario.
This leads to a context-based user proﬁling where all the
features contribute to the user behavior. The distinct feature
sets identiﬁed for three scenarios are merged together to
form a single feature set to represent context-based features.
This makes the feature space easy to scale in cases of new
scenario identiﬁcation.

The various user activities used to represent user behav-
ior are derived from a set of log ﬁles. The user activity
logs obtained from the logon-logoff details of the users,
ﬁle access history, external device usage patterns, email
communications and the web browsing history ﬁles are pre-
processed as per the explanation provided in [6]. The feature
engineering detailed in this section is not restricted to any
particular dataset; but can be used for any data with minimal
adaptation depending on the availability of the log ﬁles. The
summary of feature space generation is depicted in Fig. 2.

Figure 2. Context Based Daily Feature Set

The difference between the feature set generation of the
proposed approach and the one used in the work [6] is in
the two features H2 and H3; those depicting web browsing
history. H1, a frequency-based feature, is computed as the
number of times a user visits the website wikileaks.org. The
previous work followed a TF-IDF based feature extraction
creating a corpus with the data available within the log ﬁles
provided as part of the dataset. But this method seems to
be unsuitable as the corpus generation is done using the
keywords provided by the data itself; the corpus not being
exhaustive.

We propose a Jaccard similarity index based score to
compute H2 and H3. Jaccard similarity coefﬁcient gives
a score between 0 and 1 where 0 indicates no similarity
and 1 indicates a similarity. This can be interpreted as
the correlation between related keywords. Jaccard Similarity
based methods are used in information retrieval systems and
text processing.

In the proposed method, we build two corpora D1 and D2.
D1 consists of terms related to job opportunities; keyword
list from Scenario 1. D2 contains terms, such as keylogger,
password, crack etc; keyword list from Scenario 2 and
Scenario 3. Jaccard Similarity Coefﬁcient is computed for
each set of keywords from the individual user actions to get
the features H2 and H3. Let us consider two sets of keywords
X and Y where X is the keyword list for the daily activity
and Y is the keyword list in the corpus. The computation of
H1 and H2 features are as follows:

H2 = J(keywords, D1)

H3 = J(keywords, D2)
|X ∩ Y |
|X ∪ Y |

J(X, Y ) =

(1)

The pre-processed dataset IOriginal consists of various
insider activities; hence classes are labeled on the individual
scenarios. The feature set comprehensively describe the daily
resource usage pattern of each user which results in an
extremely imbalanced class distribution. Many works have
been done on balancing the data using re-sampling methods,
cost-sensitive approaches, etc. In this work, our main aim
is to use a generative model to balance the data distribution
and build a supervised learning model for anomaly detection.
Next section explains how generative adversarial networks
are utilized to reduce the skewed class distribution.

B. Conditional GAN-based Data Augmentation

One of the main limitations that restricts the insider threat
analysis is the lack of real-world datasets. Generative Adver-
sarial Networks (GAN) [11], a variant of neural networks,
triggered a trusted way to generate synthetic data with the
same properties as of a given data distribution. GANs are
widely used in image processing to create visually similar
images as that of the real images such that an adversary ﬁnds
it difﬁcult to distinguish them. Though GANs are popular
for data formats like text and images, their adoption in
tabular data with numerical data types are not that common
at present. Our feature set comprises of numeric attributes;
therefore we design a new CGAN network which is less
complex and suitable for the tabular 2D data.

We propose a conditional-GAN (CGAN) which is condi-
tioned by the minority malicious class labels. The two-folded
beneﬁt of using the CGAN generated data are : (i) It helps to
reduce the impact of class imbalance (ii) The CGAN helps in
increasing the diversity of training set by including data from
all classes. Conditional GAN generates data conditioned on
class labels via label embeddings in both discriminator and
generator. The conditional GAN worked well in all settings
and proved to be acceptable for insider threat analysis. In the
network, the discriminator (D) tries to distinguish whether
the data is from the real distribution, while the generator (G)
generates synthetic data and tries to fool the discriminator.
We use a fully connected neural network in the generator and
discriminator. The CGAN network architecture is as shown
in Table. I.

The design is made out of a simple conﬁguration for
generating usable synthetic numerical data for insider threat.
The generator and discriminator are fully connected layers
with {32, 64 and 128} and {256, 128 and 32} neurons
respectively. Latent dimension input to the generator is same
as the number of features. The discriminator is regularized
using a drop out of 0.2 in the penultimate layer. Adam

Table I
PROPOSED CGAN NETWORK ARCHITECTURE

Operations
Generator
Dense
Dense
Dense
Discriminator
Dense
Dense
Dense
Dense
CGAN Parameters
Optimizer
Epochs
Batch Size
Conditioned
Latent Dimension

Units

Non Linearity

Dropout

32
64
128

256
128
32
1

LeakyReLU
LeakyReLU
Linear

LeakyReLU
LeakyReLU
LeakyReLU
Sigmoid

0.2

Adam (lr=0.0002, beta 1=0.5)
300
64
On Minority Classes
20

optimizer, Leaky ReLU and dropout regularization are used
as they are the standard followed in similar problems.
Binary cross-entropy is used as the adversarial loss function
as it suits well for a model performance with an output
probability between 0 and 1. The training involved 300
epochs. Training more than the given epochs did not provide
any improvement in the generator performance.

There is an extremely low sample count for certain
classes. These classes are left unpicked during random
selection of original samples in the training phase. Therefore,
in the network design, the random real samples are chosen
such that all the classes are given equal importance in the
CGAN training. This ensures that no class is left behind in
any of the iterations such that discriminator gets all classes in
each step. Any number of samples from any minority class
can be generated by providing the type of class required
as input. The new samples are merged into the original
training distribution. As shown in Fig 1, the synthetic dataset
ISynthetic is combined with IT rain, the training dataset from
IOriginal. We provide test results and comparisons in the
coming sections to support the proposed data augmentation
step for insider threat datasets.

C. Anomaly Detection - Multi Class Classiﬁcation

Anomaly detection using ML/DL algorithms are popularly
accepted approach for insider threat detection. Existing
approaches had tended to focus on supervised learning using
two classes : Malicious and Non-malicious. One of the
major reasons for the binary classiﬁcation based analysis
is the lack of insider threat datasets and the diversity of
the malicious activities. Tree-based models are known to
perform well on small data whereas deep learning models
need signiﬁcant number of samples in its training dataset to
learn the representations to build a robust classiﬁer. Though
there are algorithms like XGBoost which perform well on
the imbalanced data, the need for other complex learning
models like artiﬁcial neural networks prevail. We chose a

mix of ensemble algorithms and artiﬁcial neural networks
which are gaining popularity recently.

Binary classiﬁcation is a special case of multi-class
classiﬁcation where each malicious class is modeled as a
separate classiﬁcation problem. In other words, it follows
a multiple binary classiﬁcation approach or One-vs-Rest
strategy. In this method, one builds independent classiﬁers
for each class. None of the existing methods tried to merge
the results to a multi-class set up. On the other hand,
a multinomial classiﬁer learns directly from the available
classes. This means that the parameters are estimated in a
class interdependent manner thereby building models that
are robust against outliers.

Unlike existing methods, the proposed method considers
the pre-deﬁned scenario based malicious activities and try to
give a deeper insight into the employee activities. Anomaly
detection considers the different scenarios under malicious
class and normal activities as non-malicious instances and
perform the multi-class classiﬁcation. The classiﬁer tries
to discriminate the anomalous activities from rest of the
samples. In the paper [12], multi-class classiﬁcation and
its importance for learning from imbalanced data are dealt
with in detail. The work suggests the effectiveness of neural
networks and ensemble based methods for imbalanced data
handling.

The algorithms chosen for supervised learning include
XGBoost, Random Forest
(RF), Multilayer Perceptron
(MLP) and 1-Dimensional Convolutional Neural Network
(1DCNN). XGBoost, a tree-based ensemble algorithm,
proved to be very efﬁcient for all kinds of data. Hence,
many existing works on insider threat analysis use XGBoost
for modeling [13]. Random Forest, yet another tree-based
ensemble algorithm, is also a popular one for imbalanced
data. We chose MLP and 1DCNN as the neural network
algorithms for our experiment. MLP, a popular neural net-
work, is suitable for numerical data and known for better
generalization. 1DCNN, a CNN model that operates over 1D
sequences, popular for time-series data is gaining acceptance
in other domains like intrusion detection [14].

IV. EXPERIMENTS

In this section, we evaluate the performance of the pro-
posed method. We provide the dataset description followed
by the models being used for training and performance
evaluation. We have implemented the method using Python
programming language, Tensorﬂow and Keras.

A. Dataset Description

Real-world data scarcity caused a major hindrance to
the experimentation. Usual practice is to use either data
collected from real user data, or use synthetically generated
data. Malicious insiders are predominantly employees in
an organization with access rights. Data collection involves
tracking and monitoring of the user actions and
direct

behaviors of the employees. This creates privacy and con-
ﬁdentiality concerns in an organization. Therefore, in cases
like this researchers are forced to progress with synthetic
data.

We used the CMU CERT dataset [15], the widely accepted
synthetic data for insider threat detection. There are various
versions of CERT datasets available. CERT v4.2 is com-
monly used as it has the maximum cases of insiders grouped
into three scenarios. The data spans over 500 days with 1000
users and 70 insiders. Table II represents the summary of
activity logs used for pre-processing.

Table II
SUMMARY OF THE HETEROGENEOUS LOG FILES

Data
Logon.csv
Email.csv
Http.csv
Device.csv
File.csv
Pre-processed Data Summary
Non-malicious events
Malicious events
No. of features
Total instances
Malicious
Non-Malicious

No.of Instances
854859
2629979
1048575
405380
445581

7154815
7323
20
330452
966
329487

Synthetic data comprises of various log ﬁles as depicted in
Fig 2. Pre-processed data consists of 330452 non-malicious
instances and 966 malicious instances. The pre-processed
data are labeled into four classes namely non-malicious,
the data distribution
is obvious that
S1, S2 and S3. It
is extremely skewed, where malicious insider related data
counts to only 1.278%. Scenario 3 (IT sabotage related
malicious actions) has the least amount of users and data
instances. Maximum number of instances are for Scenario
2 followed by Scenario 1.

Figure 3. Kernel density estimation of original and synthetic data

from the original dataset. PCA differs from t-SNE where
the later one preserves the local neighbors of the data points.
t-SNE can be considered as a manifold learning where the
geometric data properties are used. t-SNE helps to increase
the interpretability of data in the lower dimensions. Fig. 4
shows the PCA and t-SNE visualization of the data on 2D.
PCA shows the dimension reduced data. Since it is a 2D
visualization, the separate clusters are not visible; hence the
overlap. In the t-SNE based visualization, the three clusters
are the minority insider activity samples generated using the
CGAN model. The larger spread of the data show that there
is no evident mode-collapse.

Figure 4. PCA and t-SNE based visualization

B. Authenticity of Synthetic Data

C. Performance Metrics

Metrics for measuring the similarity of synthetic data
against original data distribution for numerical data types
are not well established. In case of images, there are metrics
like Inception Score to compare the synthetic and real
images. Due to the unavailability of any proven metric to
compare the numerical data similarity between the original
and synthetic data distribution, we use visual approach based
on kernel density estimates (KDE), the Principal Component
Analysis (PCA) and t-distributed Stochastic Neighbor Em-
bedding (t-SNE) on the original and synthetic data.

We used a kernel density estimation, a non-parametric
method, on the original and synthetic data to show the data
distribution similarity. Due to space constraint, we depict
two features using the visualization. Fig. 3 depicts the kernel
density estimation plot on two features L1 and L5.

PCA is a technique that converts n-dimensions of data
into k-dimensions while maintaining as much information

The classiﬁcation models are validated against common
performance metrics for imbalanced data like precision (P),
recall (R) and f-score(F). It
is highly recommended to
have high precision and recall. Sometimes these measures
alone do not reﬂect the true performance of various models.
Usually, the majority class is considered as the negative
class. It is because of the assumption that interesting samples
are rare and hence, considered as positive.

Though the existing works achieved a high precision
and recall, no work has performed a detailed analysis of
learning reports. In addition to analyzing the results based
on precision and recall, we validated the results against the
number of false-positives and false-negatives. Considering
the prime importance of the confusion matrix, also referred
to as an error matrix, we have included two more metrics,
namely, Cohen’s Kappa (Kappa) and Mathews Correlation
Coefﬁcient (MCC) [16] for the experimental evaluation.

Cohen’s Kappa or Kappa score measures the degree of
agreement between the true values and the predicted values.
Cohen’s kappa is always less than or equal to 1. Values of 0
or less, indicate that the classiﬁer is useless. A value between
0.81–1 is interpreted as almost perfect agreement; the score
reaches its maximum for balanced data.

Precision, recall and F-score are asymmetric; when the
classes are interchanged,
their values change. Precision
and recall consider the positive class to be the class of
interest. True-Positive (TP), False-positive (FP), and False-
Negative (FN) from the confusion matrix are used for their
computation. True-Negative (TN) — is not used in these
metrics. Changes in TN never reﬂect the precision and recall.
Hence, we consider MCC, a symmetric metric which gives
value between -1 and +1 inclusive. MCC considers all four
values in the confusion matrix; no class is more important
so that switching the negative and positive classes will give
same value. A value close to 1 means that both classes are
predicted well.

D. Results and Discussion

In this section, we explain the performance of multi-
class anomaly detection approach using tree-based and
ANN algorithms on insider detection. Comprehensive set
of experiments were conducted on original data as well as
applying various data augmentation methods as follows : (i)
on original skewed data with no data augmentation (ii) on
Random Over Sampled (ROS) training data (iii) on SMOTE
oversampled training data and (iv) GAN generated synthetic
data in the training set. Table III gives the performance of
anomaly detection using multi-class classiﬁcation.

Table III
PERFORMANCE ANALYSIS OF MULTI-CLASS CLASSIFICATION

Training Models
Real + RF
ROS + RF
SMOTE + RF
CGAN + RF
Real + XGBoost
ROS + XGBoost
SMOTE + XGBoost
CGAN + XGBoost
Real + MLP
ROS + MLP
SMOTE + MLP
CGAN + MLP
Real + 1DCNN
ROS + 1DCNN
SMOTE + 1DCNN
CGAN + 1DCNN

P
0.482
0.438
0.596
0.751
0.749
0.368
0.396
0.782
0.275
0.406
0.452
0.833
0.267
0.536
0.527
0.799

R
0.645
0.658
0.735
0.748
0.655
0.866
0.771
0.761
0.788
0.790
0.774
0.767
0.932
0.793
0.778
0.767

F
0.482
0.479
0.648
0.739
0.697
0.419
0.431
0.759
0.283
0.457
0.492
0.733
0.263
0.531
0.524
0.763

Kappa MCC
0.512
0.465
0.431
0.347
0.746
0.740
0.920
0.920
0.884
0.877
0.290
0.156
0.250
0.120
0.886
0.891
0.168
0.055
0.296
0.162
0.289
0.156
0.805
0.857
0.136
0.036
0.371
0.245
0.360
0.233
0.831
0.821

ML/DL methods were used for building anomaly detec-
tion models on all the above mentioned data settings. We use
text highlighted in bold to depict the interesting results in the
tables with experimental results. The tables use the abbrevi-
ations Precision (P), Recall (R), F-score (F), Cohen’s Kappa

(Kappa) and Mathews Correlation Coefﬁcient (MCC).

The results from RF algorithm is disappointing in the
multi-class classiﬁcation on the original data; but it gave
noticable increase in performance on using more meaningful
data for training. Compared to ROS and SMOTE, CGAN
shows remarkable improvement in all performance metrics.
In case of RF, there are chances of overﬁtting with ROS
and SMOTE data augmentation. In order to reduce the
effect of overﬁtting, we used the gradient boosting ensemble
(XGBoost). The ROS and SMOTE oversampling do not
show any improvement in XGBoost whereas the real data
and the CGAN boosted training data resulted in a better
model creation. With CGAN, XGBoost shows reasonable
rise in the precision and f-score metrics.

The deep learning algorithms need more data to learn
from the deep representative features. Hence, MLP and
1DCNN show remarkable improvement in the metrics. We
also used the Cohen’s Kappa measure and MCC to validate
the performance. The CGAN enriched dataset yielded the
strong performance in terms of Kappa score. MCC, a
correlation value shows a signiﬁcant improvement for the
CGAN enriched multi-class classiﬁcation experiments. The
performance of GAN augmented data for the anomaly detec-
tion is evident from the striking improvement in the metrics
as shown in Table III. The results offer compelling evidence
for supporting the efﬁciency of our proposed method.

E. Comparison with Existing Methods

In this section, we discuss experimental results of binary
classiﬁcation on the proposed method using same features.
We conducted scenario-based binary classiﬁcation and the
results are illustrated in Tables IV, V and VI using the
feature space generation in Section III-A.

The same CGAN architecture is used to generate samples
for each class. For instance, to perform the binary classiﬁca-
tion for Scenario 1 vs non-malicious samples, we generated
data for scenario S1 using the CGAN model and considered
all other samples as non-malicious class.

We present

the binary classiﬁcation on three sets of
training data : (i) original data (ii) SMOTE oversampled
data and (iii) original data boosted with CGAN generated
synthetic data. In case of Scenario 1, the original data has 85
instances which is signiﬁcantly low in number for complex
models to learn the patterns from a high volume of negative
samples. The results show that XGBoost could perform
moderately for the original data. But the precision is low
with a higher number of false-positives. Though the SMOTE
oversampling did not make any improvement, the synthetic
data from GAN merged with original training data gives a
remarkable decrease in the number of false-positives for all
models which is evident in all metrics. Table IV gives the
analysis of the insider activities using the proposed method
with scenario 1 and all other cases being non-malicious.

Table IV
PERFORMANCE ANALYSIS OF SCENARIO 1 BINARY CLASSIFICATION

Table VI
PERFORMANCE ANALYSIS FOR SCENARIO 3 BINARY CLASSIFICATION

Training Models
Real + RF
SMOTE + RF
CGAN + RF
Real + XGBoost
SMOTE + XGBoost
CGAN + XGBoost
Real + MLP
SMOTE + MLP
CGAN + MLP
Real + 1DCNN
SMOTE + 1DCNN
CGAN + 1DCNN

Scenario 1

P
0.517
0.721
0.875
0.614
0.503
0.999
0.502
0.506
0.917
0.509
0.505
0.968

R
0.909
0.941
0.942
0.941
0.924
0.942
0.943
0.959
0.941
0.964
0.931
0.941

F
0.531
0.794
0.905
0.681
0.497
0.968
0.490
0.506
0.928
0.514
0.505
0.954

Kappa MCC
0.165
0.063
0.624
0.588
0.813
0.810
0.448
0.361
0.075
0.013
0.939
0.937
0.062
0.008
0.101
0.021
0.857
0.857
0.128
0.034
0.095
0.020
0.909
0.909

Training Models
Real + RF
SMOTE + RF
GAN + RF
Real + XGBoost
SMOTE + XGBoost
GAN + XGBoost
Real + MLP
SMOTE + MLP
GAN + MLP
Real + 1DCNN
SMOTE + 1DCNN
GAN + 1DCNN

Scenario 3

P
0.749
0.536
0.833
0.611
0.503
0.999
0.500
0.687
0.749
0.500
0.625
0.749

R
0.625
0.625
0.749
0.749
0.995
0.767
0.984
0.874
0.749
0.945
0.749
0.875

F
0.667
0.555
0.786
0.654
0.503
0.833
0.495
0.745
0.749
0.472
0.667
0.799

Kappa MCC
0.333
0.333
0.077
0.011
0.577
0.571
0.333
0.308
0.133
0.111
0.707
0.667
0.042
0.004
0.530
0.499
0.452
0.399
0.022
0.001
0.353
0.333
0.707
0.667

Scenario 2 with 865 original samples performed well on
RF and XGBoost whereas it fails for neural network models.
Irrespective of the imbalance issue and the augmentation
methods, RF and XGBoost give satisfactory results. As our
focus is on deep learning models, training the model using
CGAN merged training data shows a dramatic progress in
the metrics. False-positives reduced considerably for MLP
and 1DCNN where MLP performs almost similar to RF and
XGBoost. The results for scenario 2 experiments are shown
in Table V.

Table V
PERFORMANCE ANALYSIS FOR SCENARIO 2 BINARY CLASSIFICATION

Training Models
Real + RF
SMOTE + RF
CGAN + RF
Real + XGBoost
SMOTE + XGBoost
CGAN + XGBoost
Real + MLP
SMOTE + MLP
CGAN + MLP
Real + 1DCNN
SMOTE + 1DCNN
CGAN + 1DCNN

Scenario 2

P
0.955
0.869
0.958
0.999
0.723
0.999
0.578
0.868
0.962
0.689
0.883
0.882

R
0.918
0.918
0.947
0.951
0.995
0.870
0.990
0.994
0.988
0.994
0.996
0.988

F
0.936
0.785
0.952
0.974
0.806
0.925
0.632
0.922
0.974
0.773
0.933
0.928

Kappa MCC
0.873
0.872
0.786
0.784
0.906
0.905
0.949
0.947
0.664
0.614
0.859
0.849
0.393
0.269
0.852
0.843
0.949
0.949
0.613
0.548
0.873
0.865
0.863
0.856

Extreme imbalance is present in Scenario 3 data with
only 20 malicious instances in the dataset. RF and XGBoost
give a promising result for such a skewed data. 1DCNN
increased its efﬁcacy on boosting the training dataset using
CGAN with notable enhancement in precision, F-score and
substantial increase in Kappa score and MCC. Table VI
provides the performance analysis for scenario 3.

The experiments show that the CGAN based training for
multi-class classiﬁcation works as expected for anomaly
detection of insider activities. There are a few key ﬁndings
from these results. The method cannot be tested and proved
to be 100% precise just because of one set of features or
one set of data. Since the principal interest of the research

was on CGAN based data augmentation for diverse and
increased data samples, we chose the simplest feature set
for validation. This feature set cannot provide a complete
context of the behavior which needs to be enhanced. Area
Under the Curve (AUC) score found to be very high for
experiments and did not provide any useful analysis; hence
not considered in the evaluation. Improved and powerful
performance analysis strategies should be used to evaluate
and compare learning models.

The literature shows numerous solution approaches being
used in insider threat attack which makes the comparison
of methods challenging in terms of data, methods, and the
goals. We have tried to incorporate different contexts in
which the insider detection has been studied previously and
provided compatible comparisons. We selected some results
from previous works for a general comparison. The data
augmentation strategy used, dataset for evaluation and the
learning model are the criteria used for the selection of
methods summarized in Table VII.

Table VII
SUMMARY OF EXISTING METHODS

[6]

[7]

[8]

[9]

Method

Augmentation

Dataset

Random Over Sampling

CERT 4.2

Model
Deep Autoencoder
Random Forest

Create
Synthetic Data

Enron email

Isolation Forest

Spread Subsample

Dataset from a
market leader

Data Adjustment
with SMOTE

CERT 6.2

[10]

VanillaGAN

CERT 4.2

Proposed work

Conditional GAN

CERT 4.2

J48 Decision Tree
Naive Bayes
Random Forest
Support Vector Machines
Random Forest
Gradient Boosting
XGBoost
Decision Tree
XGBoost
Random Forest
XGBoost
Neural Network
1DCNN

No. of Classes

Binary

Binary

Binary

Binary

Binary

Multi-Class

The scenario-based classiﬁcation in the work [6] con-
sidered the problem as three different binary classiﬁcation
problems. ROS is used for data augmentation under various
sampling ratios. The method gave best results for Scenario
2 on RF whereas it could not perform satisfactorily on
Scenarios 1 and 2. But our experiments on scenario-based

binary classiﬁcation using CGAN data augmentation gives
better results for each scenario. An ensemble strategy com-
bined with data adjusted XGBoost model for insider threat
detection proposed in [9] gave promising results with an
average recall of 98.5% which is similar to our binary
classiﬁcation results.

Similarly,

in the paper [10], all scenarios resulted in
outstanding performance with almost 100% for all metrics
using GANs. Our experiments using CGAN and scenario-
based binary classiﬁcation gave slightly different results for
all scenarios. It can be attributed to many reasons like feature
space, GAN architecture and the training. In both the cases,
XGBoost performs well as it did in other existing works
without any data augmentation[13].

The method followed in [7] based on the email com-
munications create a new set of data, Enron+, followed by
anomaly detection using Isolation Forest algorithm. Spread
subsample, a method that selects the random samples to ﬁt
in the memory by balancing the skewed class distributions
is mentioned in the paper [8]. These two works are not
comparable in terms of metrics or methods, but provides
insight into the possible data re-sampling approaches. In
the next section, we summarize the work by discussing the
conclusion and scope for future enhancements.

V. CONCLUSION

With the aim to improve the detection of malicious insider
activities, and to curtail the negative effects of imbalanced
class distribution in data, this paper proposed a novel condi-
tional GAN data augmentation followed by anomaly detec-
tion for insider activity detection. The proposed method is an
end-to-end workﬂow starting with data pre-processing of the
heterogeneous user access log ﬁles, feature space creation
and feature set generation. The prime focus is on the design
of a CGAN for the malicious insider scenarios and the
synthetic data generation. Synthetic data quality is analysed
using visual methods like kernel density estimation, PCA
and t-SNE. CGAN-based data augmentation helps generate
more data from original data distribution. Anomaly detection
is performed using multi-class classiﬁcation with four class
labels. The performance of proposed approach is evaluated
on the benchmark CMU CERT dataset using ensemble and
deep learning models. In this work, effectiveness of data aug-
mentation is studied in the context of insider threat analysis.
Future work will investigate how GAN performs on different
insider threat datasets available and under various feature
spaces. Moreover, there are scopes for detailed analysis on
the GAN evaluation and performance.

REFERENCES

[1] Ponemon report 2020 cost of
Observeit.com,
28-Jan-2020.
https://www.observeit.com/2020costoﬁnsiderthreat.

Insider Threats: Global,
Available:

[Online].

[2] M. C. Theis, R. F. Trzeciak, D. L. Costa, A. P. Moore,
S. Miller, T. Cassidy, W. R. Claycomb, “Common Sense
Guide to Mitigating Insider Threats, Sixth Edition”, Software
Engineering Institute, CMU/SEI-2018-TR-010, 2019.

[3] V. Chandola, A. Banerjee, and V. Kumar, “Anomaly detection:
A survey,” ACM Comput. Surv., vol. 41, no. 3, pp. 1–58, 2009.

[4] I. Homoliak, F. Toffalini, J. Guarnizo, Y. Elovici, and M.
Ochoa, “Insight into insiders and IT: A survey of insider threat
taxonomies, analysis, modeling, and countermeasures”, ACM
Comput. Surv., vol. 52, no. 2, pp. 1–40, 2019.

[5] D. Haidar and M. M. Gaber, “Adaptive one-class ensemble-
based anomaly detection: An application to insider threats”,
in 2018 International Joint Conference on Neural Networks
(IJCNN), 2018.

[6] P. Chattopadhyay, L. Wang, and Y.-P. Tan, “Scenario-based
insider threat detection from cyber activities,” IEEE Trans.
Comput. Soc. Syst., vol. 5, no. 3, pp. 660–675, 2018.

[7] C. Soh, S. Yu, A. Narayanan, S. Duraisamy, and L. Chen,
“Employee proﬁling via aspect-based sentiment and network
for insider threats detection”, Expert Syst. Appl., vol. 135, pp.
351–361, 2019.

[8] N. M. Sheykhkanloo and A. Hall, “Insider threat detection
using supervised machine learning algorithms on an extremely
imbalanced dataset”, Int. J. Cyber Warf. Terror., vol. 10, no. 2,
pp. 1–26, 2020.

[9] S. Zou, H. Sun, G. Xu, and R. Quan, “Ensemble strategy
for insider threat detection from user activity logs”, Comput.
Mater. Contin., vol. 65, no. 2, pp. 1321–1334, 2020.

[10] F. Yuan, Y. Shang, Y. Liu, Y. Cao, and J. Tan, “Data
augmentation for insider threat detection with GAN”, in 2020
IEEE 32nd International Conference on Tools with Artiﬁcial
Intelligence (ICTAI), 2020.

[11] I. J. Goodfellow et al., “Generative adversarial nets”, Proceed-
ings of the 27th International Conference on Neural Informa-
tion Processing Systems, vol. 2, no. NIPS’14, pp. 2672–2680,
2014.

[12] H. He and E. A. Garcia, “Learning from imbalanced data”,
IEEE Trans. Knowl. Data Eng., vol. 21, no. 9, pp. 1263–1284,
2009.

[13] D. C. Le, N. Zincir-Heywood, and M. I. Heywood, “Ana-
lyzing data granularity levels for insider threat detection using
machine learning”, IEEE Trans. Netw. Serv. Manag., vol. 17,
no. 1, pp. 30–44, 2020.

[14] M. Azizjon, A. Jumabek, and W. Kim, “1D CNN based
network intrusion detection with normalization on imbalanced
data”, in 2020 International Conference on Artiﬁcial Intelli-
gence in Information and Communication (ICAIIC), 2020.

[15] C. M. U. CERT Team, “CMU CERT synthetic insider
threat data sets”, https://resources.sei.cmu.edu/library/asset-
view.cfm?assetid=508099.

[16] B. W. Matthews, “Comparison of the predicted and observed
secondary structure of T4 phage lysozyme”, Biochim. Biophys.
Acta, vol. 405, no. 2, pp. 442–451, 1975.

