Analysis of Stochastic Switched Systems with Application to
Networked Control Under Jamming Attacks

Ahmet Cetinkaya, Hideaki Ishii, and Tomohisa Hayakawa

1

8
1
0
2

r
p
A
0
2

]

Y
S
.
s
c
[

4
v
7
4
6
7
0
.
4
0
7
1
:
v
i
X
r
a

Abstract—We investigate the stability problem for discrete-
time stochastic switched linear systems under the speciﬁc sce-
narios where information about the switching patterns and the
probability of switches are not available. Our analysis focuses
on the average number of times each mode becomes active in
the long run and, in particular, utilizes their lower- and upper-
bounds. This setup is motivated by cyber security issues for
networked control systems in the presence of packet losses due
to malicious jamming attacks where the attacker’s strategy is
not known a priori. We derive a sufﬁcient condition for almost
sure asymptotic stability of the switched systems which can
be examined by solving a linear programming problem. Our
approach exploits the dynamics of an equivalent system that
describes the evolution of the switched system’s state at every
few steps; the stability analysis may become less conservative by
increasing the step size. The computational efﬁciency is further
enhanced by exploiting the structure in the stability analysis
problem, and we introduce an alternative linear programming
problem that has fewer variables. We demonstrate the efﬁcacy
of our results by analyzing networked control problems where
communication channels face random packet losses as well as
jamming attacks.

Index Terms—Stochastic switched systems, stability analy-
sis, linear programming, networked control systems, jamming,
packet losses.

I. INTRODUCTION

In the recent studies of hybrid systems, switched systems
represent an important and fundamental class due to their
simple structures. Switched systems are composed of a number
of subsystems that possess different continuous dynamics and
a discrete-valued switching mode signal which determines
the active subsystem. Complicated behaviors in the state
evolutions can be demonstrated, depending on the nature of
the switching as well as the dynamics of the subsystems. For
this reason, analyses of switched systems concerning their
stability and performance have posed various challenges and
led researchers to interesting results [1], [2].

Recently, the importance of this class of hybrid systems
is rising from the application side. In particular, in large-
scale networked control systems, switchings in the system
dynamics frequently take place whenever the status in the
communication networks changes. In such systems, network
channels connect the plant having many sensors and actuators
with remote controllers. Thus, transmission times and patterns

A. Cetinkaya and H.

Science, Tokyo Insitute of Technology, Yokohama, 226-8502,
ahmet@sc.dis.titech.ac.jp,ishii@c.titech.ac.jp

Ishii are with the Department of Computer
Japan.

T. Hayakawa

is with the Department of Systems

Engineering, Tokyo Institute of Technology, Tokyo 152-8552,
hayakawa@mei.titech.ac.jp

and Control
Japan.

This work was supported in part by the JST CREST Grant No. JP-
MJCR15K3 and by JSPS under Grant-in-Aid for Scientiﬁc Research Grant
No. 15H04020.

of control-related signals affect the dynamics of the plant
as well as the overall closed-loop system. Furthermore, the
communication is often unreliable in that the transmitted data
may become lost, not reaching the destination depending on
the condition of the channels. Since such channel behaviors
are commonly modeled in a probabilistic manner, the study
of networked control systems often call for the framework of
stochastic switched systems.

Stability of switched systems has been studied for different
types of mode signals. The case of (deterministic) arbitrary
switching has been explored in a number of works including
[3], [4], establishing conditions under which a switched system
remains stable for all possible mode switching scenarios. The
switching frequency in the mode signal can be restricted
by utilizing dwell-time and average dwell-time notions. The
works [5], [6] dealt with systems composed of only stable
subsystems while [7], [8] made extensions to systems also
consisting of unstable subsystems. In addition, [9] investigated
the problem of designing state-dependent switching rules to
guarantee stability.

For stochastic mode signals, stability issues of switched
systems have attracted considerable attention as well (see
[10], [11] and the references therein). In most cases, stability
results for such systems rely on statistical information on the
mode signal such as the probability of mode switches and
the stationary distributions associated with the modes. An
important class there is that of Markov jump systems, for
which the mode signal is dominated by underlying Markov
chains [12]–[16]. Moreover, some works characterized both
stochastic and deterministic effects in the switching of the
mode signal, referred to as “dual switching” [17], [18].

In this paper, we investigate a stability problem for discrete-
time stochastic switched linear systems with a special empha-
sis on the case where information about the mode switching
probabilities or the stationary distributions are not available for
analysis. Our interest stems from the current research activities
on cyber security of networked control systems [19]–[21].
Today, more control systems are connected to the Internet and
wireless networks for their remote operation and monitoring.
Such communication settings signiﬁcantly increase the risk to
be targeted by malicious cyber attackers. Clearly, the system
dynamics can change, for example, if attackers interfere with
the communication of the control related signals. Under such
conditions, the networked system may be represented as a
stochastic switched system, but the a priori knowledge on the
switching, whether it is deterministic or probabilistic, would be
extremely limited. In the networked control literature, recent
works dealt with denial-of-service (DoS) and jamming attacks
[22]–[24] or packet drops by compromised routers [25], [26].
Our problem formulation is based on the approach in our

 
 
 
 
 
 
recent work [21]; see also [27]–[30] for more related results.
There, we focused on the stochastic stability of a networked
control system under malicious jamming attacks, where the
jamming causes losses of data during packet transmissions due
to strong interferences. The normal operation and the dynamics
under jamming attacks are represented with two different
modes. The transmission failure instants and the probability of
transmission failures are inﬂuenced by the attacker’s actions
and hence not available for analysis. In [21], we introduced a
novel stochastic model regarding the timings of jamming using
only the asymptotic tail probabilities of average transmission
failures. Roughly speaking, it corresponds to the bound on the
average ratio of time that the communication is blocked due
to jamming. A key property of the model lies in its generality,
being capable to describe both malicious and nonmalicious
data losses. Speciﬁcally, it can represent discrete-time versions
of the jamming and denial-of-service attack models in [19],
[20] as well as random packet loss models based on Bernoulli
and Markov processes [31]–[34].

In this paper, as a generalization of this class of systems
in networked control under jamming attacks, we consider
stochastic switched systems having arbitrary number of modes.
The limited knowledge on the model signal is represented by
the lower- and upper-bounds on the percentage of the time
each mode is active in the long run. We pay special attention to
improving the conservatism and computational efﬁciency for
the stability analysis. It is established that linear programming
can be used for identifying the worst mode switching scenario
in terms of stability, and we assess the stability of the system
under that scenario. This stability assessment approach is
different from the matrix inequality-type stability conditions
obtained with the Lyapunov-based stability analysis in [21].
Certain aspects are generalized in the linear programming-
based conditions and for this reason less conservative analysis
is possible. In this paper, we will discuss these points in detail
and also illustrate by numerical examples. Moreover, the pro-
posed approach differs from those in [35]–[38], where linear
programming is used for constructing Lyapunov functions.

∈

In the course of our analysis, we ﬁrst construct a new
system that describes the evolution of the switched system’s
N steps. For a given switched system
state at every h
with M modes, this new “lifted” version of the system is
composed of M h modes, each of which is identiﬁed by a
sequence of h numbers indicating a progression of modes
in the original system. The advantage of the approach is
that
the conservatism in the analysis may be reduced by
increasing the size of h. This is possible because, with large h,
stability/instability properties of more switching patterns are
taken into account. Furthermore, to reduce the computational
complexity, we exploit the problem structure and develop
an alternative linear programming problem. This problem
shares the same optimal objective function value with the
original problem, but involves fewer variables, which are in
fact polynomial with respect to the problem size.

The idea of studying a new system that describes the state’s
evolution at every few steps has previously been employed
in [39]–[42]. The works [39] and [40] explore Markov jump
systems, but assume the full knowledge of the Markov chain.

2

On the other hand, in [41] and [42], stability problems under
constrained switching rules are addressed, where all possible
switching patterns are identiﬁed through graphs that indicate
the constraints in the switching. In our problem setting,
information about the possible switching patterns is not avail-
able, and moreover, we consider scenarios where switching is
allowed between all pairs of modes. For this particular setting,
the stability results in [41], [42] require all subsystems to
be stable. Therefore, they are not applicable for our problem
since we allow both stable and unstable subsystem dynamics.
In addition to the analysis of switched systems, an approach
similar to the investigation of the dynamics over multiple time
steps has also been used for establishing the convergence of
risk-sensitive and risk sensitive like ﬁlters in [43], [44].

We show in the paper that our results are applicable
to a wide class of mode signals. In particular, it includes
those that are the outputs of hidden Markov chains whose
actual state space and transition probabilities are unknown.
In networked control problems under random and malicious
packet transmission failures such signals may arise in periodic
attacks discussed in [19] as well as random packet losses
on channels described with Markov models studied in [45],
[46]. We apply our stability results in two networked control
problems, where the plant and the remotely located controller
exchange information packets over one or more channels
subject to packet losses due to random communication errors
or malicious jamming attacks.

The rest of the paper is organized as follows. In Section II,
we explain the switched system dynamics and obtain sufﬁcient
stability conditions by utilizing bounds on the average number
of times each mode is active in the long run. In Section III,
we present our approach for checking stability conditions by
means of solving linear programming problems. Moreover,
in Section IV, we discuss the application of our results in
the problem of networked control under jamming attacks.
in
We present numerical examples in Section V. Finally,
Section VI, we conclude the paper.

We note that part of the results in Sections II and III
appeared in our preliminary report [47] for the special case
of two modes in the context of a networked control problem.
Here, we provide complete proofs and more detailed discus-
sions for the general modes case.

We use a fairly standard notation in the paper. Speciﬁ-
cally, N and N0 respectively denote positive and nonnega-
tive integers. A ﬁnite-length sequence of ordered elements
q1, q2, . . . , qh is represented by q = (q1, q2, . . . , qh). We use
to denote the largest integer that is smaller than or equal
] denotes the probability
, P). Furthermore, we utilize
F
,
∈ F
E, and 1[E](ω) = 0 for ω /
E.
∈

⌊·⌋
to its real argument. The notation P[
on a probability space (Ω,
1[E] : Ω
→ {
that is, 1[E](ω) = 1 for ω

for the indicator of the event E

0, 1

∈

}

·

II. STOCHASTIC SWITCHED SYSTEM STABILITY
ANALYSIS

In this section we ﬁrst describe the dynamics of a stochastic
switched system. We then discuss the stability problem and
provide sufﬁcient almost sure asymptotic stability conditions.

A. Switched System Dynamics

Consider the discrete-time switched linear system with M

N modes described by

∈

x(t + 1) = Ar(t)x(t),

∈
t∈N0

N0,

(1)

∈

x(0) = x0, r(0) = r0, t
Rn denotes the state vector,
is the mode signal, and As

∈
Rn×n,
, represent the system matrices for each mode.
}
1, . . . , M
{

to denote the set of modes.

{
∈

r(t)

t∈N0 is assumed to be a

}
r(t)

where x(t)
1, . . . , M

{
s
∈ {
We use

}}
1, . . . , M
,

M

The mode signal

stochastic process that satisﬁes the following assumption.

{

∈ M}

Assumption 2.1: There exist scalars ρs, ρs ∈

such that

[0, 1], s

,

∈ M

lim inf
k→∞

lim sup
k→∞

1
k

1
k

k−1

t=0
X
k−1

t=0
X

1[r(t) = s]

1[r(t) = s]

ρs,

≥

ρs,

≤

(2)

(3)

almost surely.

In Assumption 2.1,

the scalars ρs
and ρs respectively
represent lower- and upper-bounds on the long-run average
number of times mode s is active. If no information is available
and ρs can
on the long-run average for mode s, the scalars ρs
be selected as ρs = 0 and ρs = 1, since (2) and (3) are trivially
satisﬁed with those values for all s

.

Our main motivation for considering Assumption 2.1 is
to analyze switched systems for which precise information
about the mode switching rules is not available for analysis.
, can
In Section II-B, we show that the scalars ρs
be used for analysis, even if we do not know how the mode
may switch at each time t.

, ρs, s

∈ M

∈ M

{

r(t)

r(t)

∈ M}

∈ M}

. On the other hand,

Assumption 2.1 allows the mode signal

t∈N0 to
be generated in many different ways either randomly according
to a probability distribution or in a deterministic fashion. For
t∈N0 may be a stationary and ergodic
instance,
{
[0, 1]M . In
stochastic process with stationary distribution π
∈
that case ρs
ρs,
and ρs would be scalars that satisfy ρs ≤
t∈N0 may also rep-
r(t)
s
{
∈ M
resent a deterministically generated switching sequence. For
N
example, a particular mode switching pattern of length T
can be repeated to create a periodic switching sequence. In that
and ρs would correspond to lower- and upper-bounds
case, ρs
on the ratio of the number of times mode s is active in the T -
t∈N0 is
length switching pattern. In the case where
k−1
,
deterministic, the limits limk→∞
t=0
∈ M
when they exist, correspond to the “discrete event rate” utilized
by [48], [49] for deterministic systems.

{
∈ M}
1[r(t) = q], q

∈ M}

r(t)

P

πs

≤

∈

1
k

Remark 2.1: In the literature of stochastic switched systems
the mode signal is typically characterized as a Markov chain
t∈N0 is not necessarily a
[13]. In this paper,
Markov chain. In fact in certain cases, we may have

∈ M}

r(t)

{

P[r(t + 1) = q

|

r(0), r(1), . . . , r(t)]

= P[r(t + 1) = q

r(t)],

|

which indicates that r(
) fails to satisfy the Markov property
·
) may also depend on other processes.
[50]. Furthermore, r(
·
Our main motivation for considering this general setup for

3

{

r(t)

∈ M}

t∈N0 comes from the networked
the mode signal
control problem under jamming attacks. As we illustrate in
Section IV, a networked control system under jamming attacks
can be represented by the switched system (1). The mode
signal of such a switched system is not necessarily a Markov
process, since the attacker can inﬂuence the mode signal
in various ways. Consequently, the analysis of the switched
system (1) requires methods that are different from those
utilized in switched systems with Markov modes [13].

In our stability analysis in the following section, we utilize
and ρs satisfying (2) and (3) instead of transition
the scalars ρs
probabilities or switching patterns. In Section IV, we model
networked control systems as switched systems, where the
mode signals represent the state of certain communication
and ρs are characterized
channels that face jamming. There, ρs
based on the information about the average number of times
transmissions fail due to attacks in the long run.

B. Stability Analysis

In this section, we explore the stability of the switched
system (1), where the mode signal satisﬁes Assumption 2.1.
We use the stochastic stability notion of almost sure asymptotic
stability in our analysis.

Deﬁnition 2.2: The zero solution x(t)

0 of the stochastic
system (1) is almost surely stable if for each ǫ > 0 and ¯p > 0,
there exists δ = δ(ǫ, ¯p) > 0 such that if

≡
x0k2 < δ, then

P[ sup

t∈N0 k

x(t)

k
k2 > ǫ] < ¯p,

(4)

k · k2 denotes the Euclidean norm. Moreover, the zero
0 is asymptotically stable almost surely if it

where
solution x(t)
is almost surely stable and

≡

P[ lim

t→∞ k

x(t)

k2 = 0] = 1.

(5)

Stability of discrete-time switched systems has been investi-
gated in many studies under different assumptions on the mode
signal. For instance, in several works (see [2] and the refer-
ences therein) researchers explore stability of systems with
a form similar to (1) under arbitrary switching. A necessary
condition is stability of each mode (i.e., A1, A2, . . . , AM need
to be Schur matrices). In our problem setting we allow some
of the modes to be unstable, and hence this approach is not
applicable.

On the other hand, researchers also studied stability of
systems similar to (1) for the case where r(
) is a Markov
·
process (see, e.g., [12], [13], [39]). The stability analysis in
those studies relies on transition probabilities and stationary
distributions associated with the Markov process that charac-
terize the switching sequence. Note again that in our case, r(
)
·
need not be a Markov process. Furthermore, to account for the
uncertainty in generation of the mode signal, we assume that
statistical information concerning transition probabilities and
stationary distributions is not available. Hence, the stability
results reported in the above-mentioned literature are not
applicable to the present problem.

In our stability analysis of the switched system, we follow
the approach in [39], [41] and investigate the evolution of the

6
N steps. First, let
system’s state at every h
set of sequences of length h with entries in

∈

M

, that is,

M

h denote the

Proof: We ﬁrst show (11). By (9),

h ,

{

M

(q1, q2, . . . , qh) : qj

, j

∈ M

∈ {

1, . . . , h

.

}}

Xq∈Mh

4

(12)

cs(q)
h

lim
k→∞

1
k

k−1

1[¯r(i) = q]

k−1

i=0
X

cs(q)1[¯r(i) = q]

= lim
k→∞

= lim
k→∞

1
kh

1
kh

Here, we have

i=0
X
kh−1

Xq∈Mh
1[r(i) = s].

i=0
X

¯kh−1

1[r(i) = s] : ¯k

k

≥

o

i=0
X
1
¯k

n

¯k−1

i=0
X

1[r(i) = s] : ¯k

≥

k

,

k

o

N,

∈

(13)

1[r(i) = s]

sup
¯k≥k

≤

1
¯k

¯k−1

i=0
X

1[r(i) = s],

N.

k

∈

(14)

1
¯kh

n

⊆

and hence

1
¯kh

sup
¯k≥k

¯kh−1

i=0
X

Therefore,

lim sup
k→∞

1
kh

kh−1

i=0
X

1[r(i) = s]

lim sup
k→∞

≤

1
k

k−1

i=0
X

1[r(i) = s].

(15)

N,

(9)

∈

As a result, (11) follows from (3), (12), and (15).

The inequality (10) can be shown using a similar approach.

Next, we employ Lemma 2.3 to establish sufﬁcient condi-
tions for almost sure asymptotic stability. To this end, ﬁrst, for
denote the induced matrix
a given matrix N
norm deﬁned by

Rn×n, let

N

∈

k

k

N

k

k

, sup

x∈Rn\{0}

N x
k
x
k

k
k

,

(16)

k

k·k

N1N2k ≤ k

Rn×n (see Section 5.6 in [51]).

on the right-hand side denotes a vector norm on Rn.
where
In the proof of the next result, we use the submultiplicativity
property of induced matrix norms, i.e.,
N2k
for N1, N2 ∈
Theorem 2.4: Consider the switched system (1). Sup-
t∈N0 sat-
pose that the mode signal
r(t)
∈ {
, and
isﬁes Assumption 2.1 with ρs, ρs ∈
h for
1
limk→∞
k
a given h
and
a scalar ε

1, . . . , M
[0, 1], s
k−1
1[¯r(i) = q] exists for each q
i=0
N. If there exist an induced matrix norm
∈
P
(0, 1) such that the inequality
∈

}}
∈ M
∈ M
k · k

N1kk

{

(10)

(11)

holds with

γqρq < 0,

Xq∈Mh

γq ,

Γq

ln
k
ln ε,

,

k

(

= 0,
Γq
Γq = 0,

q

∈ M

h,

(17)

(18)

With this deﬁnition, qi (ith entry of a sequence q) represents
a mode in the set of modes
i∈N0
be a sequence-valued process deﬁned by

. Now, let

∈ M

¯r(i)

M

{

}

h

¯r(i) , (r(ih), r(ih + 1), . . . , r((i + 1)h

1)), i

−

∈

N0. (6)

It then follows that the state evaluated at every h steps is
described by

x((i + 1)h) = Γ¯r(i)x(ih),

N0,

i

∈

where

Γq , Aqh Aqh−1 · · ·

Aq1 ,

q

h.

∈ M

(7)

(8)

The dynamical system (7) is a “lifted” switched system with
M h number of modes. Each mode of this system is identiﬁed
by a sequence of h numbers from
representing the modes
of the original switched system (1).
0, . . . , h

M

h

Now, let cs :
h
j=1

M
1[qj = s], q

→ {

h, s

∈ M

be deﬁned by cs(q) ,
}
. With this deﬁnition, the
∈ M
h is

number of entries with value s in the sequence q
P
represented with cs(q). Note that cs satisﬁes

∈ M

k−1

kh−1

cs(q)1[¯r(i) = q] =

1[r(i) = s], k

i=0
X

Xq∈Mh

i=0
X

which establishes a key relation between the mode signal r(
·
and the sequence-valued process ¯r(
·

In Lemma 2.3 below, we use (9) to obtain a relation between
ρs, ρs in Assumption 2.1 and the long-run average numbers of
h. The long run average
the occurrences of all sequences in
for a sequence q

h is given by

M

).

)

∈ M

lim
k→∞

1
k

k−1

i=0
X

1[¯r(i) = q],

whenever this limit exists,
converges almost surely to a random variable as k

that

is, 1
k

k−1
i=0

Lemma 2.3: Suppose
{
sumption 2.1 with ρs, ρs
k−1
limk→∞
i=0
we have

1
k

r(t)

P

∈
1[¯r(i) = q] exists for each q

P
∈ M}

t∈N0
[0, 1], s

1[¯r(i) = q]

.
→ ∞
satisﬁes As-
.
If
h, then

∈ M
∈ M

cs(q)
h

lim
k→∞

Xq∈Mh

cs(q)
h

lim
k→∞

Xq∈Mh
, almost surely.

for s

∈ M

1
k

1
k

k−1

i=0
X
k−1

i=0
X

1[¯r(i) = q]

ρs,

≥

1[¯r(i) = q]

ρs,

≤

6
for all ρq

[0, 1], q

∈

∈ M

h, that satisfy

ρq = 1,

Xq∈Mh
cs(q)
h

ρs ≤

Xq∈Mh

ρq

≤

ρs,

s

,

∈ M

(19)

(20)

then the zero solution x(t)
is asymptotically stable almost surely.

≡

0 of the dynamical system (1)

Proof: First, it follows from (7) that

x((k + 1)h)
k

k

=

k

Γ¯r(k)x(kh)

k ≤ k

Γ¯r(k)kk

x(kh)
k

,

and hence by the submultiplicativity property of the induced
matrix norm

, we have

k · k

N0,

,

k

∈

x(kh)

k ≤
k−1
i=0 k

k
where η(k) ,
k−1
i=0 γ¯r(i), k

x0k
η(k)
k
. Now we deﬁne µ(k) ,
Γ¯r(i)k
N0, where γq, q
h, are given by (18).
Q
It follows from (18) together with the deﬁnitions of η(k)
P
N0. Furthermore, since
and µ(k) that η(k)
γ¯r(i) =

q∈Mh γq1[¯r(i) = q], we have

eµ(k), k

∈ M

(21)

≤

∈

∈

k−1
P

µ(k) =

γq1[¯r(i) = q] =

γq

1[¯r(i) = q],

k−1

i=0
Xq∈Mh
X
N, and as a result,

for k

∈

Xq∈Mh

i=0
X

lim
k→∞

1
k

µ(k) =

γq lim
k→∞

1
k

Xq∈Mh

almost surely. Here, note that limk→∞
[0, 1]. Furthermore,

i=0
X
1
k

k−1

1[¯r(i) = q],

(22)

k−1

1[¯r(i) = q]

1
k

i=0
X
k−1

lim
k→∞

Xq∈Mh

= lim
k→∞

1
k

1[¯r(i) = q] = lim
k→∞

i=0
X

Xq∈Mh

1
k

k−1

i=0
X

1 = 1.

(23)

h, and

∈ M
h, s.t. (19), (20)

.

o

Let ρ∗
q

, limk→∞

1
k

k−1
i=0

1[¯r(i) = q], q

ϑ , max

n Xq∈Mh

P
γqρq : ρq

[0, 1], q

∈

∈ M

Furthermore, let E, F

⊂ F

be the events deﬁned by

E ,

ω

{

∈

Ω :

ρ∗
q = 1,

Xq∈Mh

ρs ≤

cs(q)
h

ρ∗
q ≤

ρs, s

.

∈ M}

F ,

ω

{

∈

γqρ∗

q ≤

.

ϑ
}

Xq∈Mh
Ω :

Xq∈Mh

We ﬁrst show that P[E] = 1. Observe that (23) implies (19)
with ρq replaced by ρ∗
q. Moreover, Lemma 2.3 implies that
(20) with ρq replaced by ρ∗
q holds almost surely. Hence, we
F , we also have P[F ] = 1.
have P[E] = 1. Now, since E

⊆

5

Furthermore, (17) implies that ϑ < 0. As a result, by noting
that P[F ] = 1, we obtain
ϑ < 0, almost
surely. We use this fact together with (22) to obtain

q∈Mh γqρ∗

q ≤

P

lim
k→∞

1
k

µ(k) =

γqρ∗

q ≤

ϑ < 0,

(24)

Xq∈Mh

almost surely. Here, (24) implies limk→∞ µ(k) =
,
−∞
eµ(k), we
almost surely. As a result, by noting that η(k)
obtain P[limk→∞ η(k) = 0] = 1. Thus, for any ǫ > 0,
limj→∞ P[supk≥j η(k) > ǫ] = 0 (see Proposition 5.6 of [52]).
Therefore, for any ǫ > 0 and ¯p > 0, there exists a positive
integer N (ǫ, ¯p) such that

≤

P[sup
k≥j

η(k) > ǫ] < ¯p,

j

N (ǫ, ¯p).

≥

(25)

In what follows, we show almost sure stability of the

switched system by using (21) and (25). First, we deﬁne

φ , max

1, max

s∈M k

{

As

k}

(26)

k ,
T

and
deﬁnitions, we obtain

{

kh, . . . , (k + 1)h

, k

1

}

−

∈

N0. Using these

x(t + 1)
k

k

=

≤

Ar(t)x(t)
k
x(t)
φ
k
k
x(t)

,

k ≤ k
t
∈ T

Ar(t)kk
k.

x(t)
k

(27)

It then follows from (27) that
Since
T
φh−1
≤
Consequently,

k ≤
k has h time instants and φ
φh
φh and hence

x(t)

k ≤

k

k

φt−kh

k

, t

x(kh)
∈ T
k
1, we have φt−kh
for all t

k.

≤
k.

≥
x(kh)
k
k

∈ T

η(k)

x(kh)

kk

−1

x0k

max
t∈Tk k

x(t)
k

≥

φ−h

x0k

k

−1, k

∈

N0.

≥ k

Then it follows from (25) that for all ǫ > 0 and ¯p > 0,

> ǫφh

x(t)
k

max
t∈Tk k

x(t)
k

]

x0k

k
φ−h

P[sup
max
t∈Tk k
k≥j
= P[sup
k≥j
P[sup
k≥j

≤

−1 > ǫ]

k

x0k
j

≥

η(k) > ǫ] < ¯p,

N (ǫ, ¯p).

Now let δ1 , φ−h. Notice that if
and therefore, for all j

x0k ≤

k

N (ǫ, ¯p), we have

δ1, then φh

x0k ≤

k

1,

≥
x(t)
k

max
t∈Tk k

max
t∈Tk k
P[sup
k≥j

P[sup
k≥j

≤

> ǫ]

> ǫφh

x(t)
k

] < ¯p.

x0k

k

(29)

Furthermore, observe that for all k
we have
result of (28),

x0k ≤

x(kh)

k ≤

φk

k

k

∈ {
φN (ǫ, ¯p)−1

0, 1, . . . , N (ǫ, ¯p)
x0k

,
}
. Hence, as a

−

1

k

max
t∈Tk k

x(t)

k ≤

φh

k

x(kh)

k ≤

for all k
ǫφ1−h−N (ǫ, ¯p). Now,

∈ {

0, 1, . . . , N (ǫ, ¯p)
x0k ≤

if

k

φh+N (ǫ, ¯p)−1

,

k

(30)

x0k
. Let δ2(ǫ, ¯p) ,
then by (30),

1
−
}
δ2(ǫ, ¯p),

k−1
i=0

1[¯r(i) = q]

∈

max
t∈Tk k

x(t)

k ≤

φh

x(kh)
k

,

k

N0.

k

∈

(28)

P

Now by (21) and (28),

maxt∈Tk k
x0k ≤
k

x(t)

k ≤

δ2(ǫ, ¯p), then
P[

ǫ, k

0, 1, . . . , N (ǫ, ¯p)

. Thus, if

1

}

−

∈ {

max
k∈{0,1,...,N (ǫ, ¯p)}

max
t∈Tk k

x(t)
k

> ǫ] = 0.

(31)

Due to (29) and (31), for all ǫ > 0, ¯p > 0, we have

> ǫ]

x(t)
k
> ǫ

}

P[ sup

t∈N0 k
= P[

x(t)
k

> ǫ] = P[ sup
k∈N0

max
t∈Tk k

max
t∈Tk k
x(t)
k

x(t)
k
]

> ǫ

}

{

∪ {

max
k∈{0,...,N (ǫ, ¯p)−1}
max
t∈Tk k

sup
k≥N (ǫ, ¯p)
max
k∈{0,...,N (ǫ, ¯p)−1}
max
t∈Tk k

sup
k≥N (ǫ, ¯p)

max
t∈Tk k
x(t)
k

P[

≤

+ P[

> ǫ]

x(t)
k
> ǫ] < ¯p,

(32)

whenever

< min(δ1, δ2(ǫ, ¯p)).

x0k

k

By Corollary 5.4.5 of [51], there exist c1, c2 > 0 such that
c2k

x
k2 ≤
By (32) and (33), we obtain that for all ǫ > 0, ¯p > 0,

c1k

k ≤ k

Rn.

x
k

(33)

∈

x

x

,

P[ sup

P[ sup

>

≤

x(t)

t∈N0 k

x(t)
k

t∈N0 k
x0k

k2 > ǫ]
< min(δ1, δ2( ǫ
x0k ≤
c2
, we have that for all ǫ > 0, ¯p > 0, the inequality
, ¯p)),

k
x0k2 < δ(ǫ, ¯p) , c1 min(δ1, δ2( ǫ

, ¯p)). Now, since

(4) holds whenever
which implies almost sure stability.

whenever
kx0k2
c1

] < ¯p,

c2

k

k

ǫ
c2

the zero solution.

Next, we show (5) to establish almost sure asymptotic
stability of
In this regard, ﬁrst no-
tice that P[limk→∞ η(k) = 0] = 1. By using (21),
we obtain P[limk→∞ k
= 0] = 1, which implies
P[limt→∞ k
= 0] = 1. Now as a consequence of (33),
x(t)
k
we have (5). Hence the zero solution of the switched system
(1) is asymptotically stable almost surely.

x(kh)
k

k

k

∈

∈

Γq

∈ M

[0, 1], q

Theorem 2.4 provides an almost sure asymptotic stability
condition for the switched system (1). This result indicates
that the stability can be assessed by checking the inequality
h, such that (19), (20)
(17) for all scalars ρq
R represents the effect of mode
hold. In (17), the scalar γq
sequence q. Speciﬁcally, for mode sequences with
< 1,
we have γq < 0. A negative value for γq implies that the
norm of the system’s state gets smaller after h time steps, if
the mode within those h time steps follows the sequence q.
Note that for the case Γq = 0, ε
(0, 1) in (18) ensures
that γq is well deﬁned and negative. In practice, ε can be
selected as a very small positive number. On the other hand, for
mode sequences with
> 1, we have γq > 0. A positive
value for γq indicates that the mode sequence q may cause
the norm of the system’s state to increase. Hence, the term
1[¯r(i) =
q] would correspond to the average of the effects of all h-
P
h. However, this average cannot be
length sequences in
computed directly, since in this paper, we consider the case
1[¯r(i) = q] are
where the speciﬁc values of limk→∞
not available.

q∈Mh γqρq in (17) with ρq = limk→∞

k−1
i=0

k−1
i=0

M

P

Γq

∈

1
k

1
k

k

k

On the other hand, we show by using Lemma 2.3 that if the
long-run average activity of modes is known to be bounded

P

6

1
k

k−1
i=0

P

∈ M

P
q∈Mh γqρq in (17) for all ρq

1[¯r(i) = q]
as in (2) and (3), then ρq = limk→∞
would satisfy (19), (20). Hence, for stability analysis, one
can check the sign of
∈
h, that satisfy (19), (20). This is equivalent to
[0, 1], q
checking the stability for all possible mode sequence scenarios
that satisfy (2) and (3), since different values of the limits
h, represent
ρq = limk→∞
different scenarios. We will show in Section III that rather
than checking the condition in (17) for all possible scenarios,
we can utilize linear programming methods to identify the
worst scenario in terms of stability, and check the condition
only for that scenario.

1[¯r(i) = q], q

∈ M

k−1
i=0

P

1
k

1
k

P

r(t)

∈ M

Note that

1[¯r(i) = q] for all q

in Theorem 2.4 we require the existence of
k−1
h, even though
limk→∞
i=0
the particular values of these limits are not needed for stability
analysis. The following result identiﬁes a class of mode signals
t∈N0 for which these limits exist. Using this
{
result, we will show that our analysis technique is applicable
in a variety of scenarios.
Proposition 2.5: Let

g(t)
be a ﬁnite-state irreducible Markov chain. Assume

t∈N0 with g(0) = g0 ∈ S
∈

∈ S}

r(t)

∈ {

0, 1

}}

{

{

t∈N0 is given by

M}

r(t) , 


g(t)

∈ S1,

1,

...

N0,

t

∈

(34)

M,

g(t)

M ,

∈ S

∈ M

where
M
i=1S


M form a partition of the set
S2, . . . ,
S1,
S
and
i =
i
S
∪
S
1
the limits limk→∞
k

S
= j. Then for all h
h, exist.

1[¯l(i) = q], q

k−1
i=0

j =

∩ S

, i

∅

,

∈

i.e.,
N,

The proof of this result is composed of several key steps.
P
) is generated
The ﬁrst step is based on the observation that ¯r(
·
from sequences of values that the process r(
) takes between
·
every h time steps. By exploiting this observation, we con-
struct a new process ¯g(
) representing the sequences of values
·
) takes between every d steps, where d is a carefully
that g(
·
chosen period length that is an integer multiple of h. In the
second step, we establish the relation between the processes
) by using (34). Then, in the ﬁnal step, we show
) and ¯g(
¯r(
·
·
1[¯r(i) = q] can be obtained by utilizing
1
that limk→∞
k
invariant distributions of ¯g(
·

Proof: In the proof, we use the notion of period for
N of a state

Markov chains [53]. Speciﬁcally, the period τσ
σ

is deﬁned by

k−1
i=0

P

∈

).

∈ S
τσ , gcd
{

N : P[g(t) = σ

t

∈

g(0) = σ] > 0

, σ

}

,

∈ S

|

g(t)

where gcd(T ) denotes the greatest common denominator of
the elements of the set T . By this deﬁnition, the random
time intervals between revisits to state σ are guaranteed to be
t∈N0 is an irreducible
integer multiples of τσ. Since
{
ﬁnite-state Markov chain, it follows from Corollary 8.3.7 of
N to
[53] that the period is the same for all states. We use τ
denote this period, i.e., τ = τ1 = τ2 =
denotes the number of elements in the set

∈
= τ|S|, where
|S|
. Now let d , τ h.
Next, we deﬁne a sequence-valued process to characterize
) in every d steps. To this end, ﬁrst, for
,

the evolution of g(
·
σ,k ,
each σ
I

: P[g(kd) = s

g(0) = σ] > 0

· · ·
S

∈ S}

, let

∈ S

∈ S

}

{

s

|

6
∈ {

1, . . . ,

|S|
denotes
k
k=1I
the states that can be reached from the state σ in steps that
are integer multiples of d. In addition, for each σ

σ,k. The set

σ ,
I

, and

|S|}

⊂ S

, let

σ
I

∪

¯
σ ,
S

(¯s1, ¯s2, . . . , ¯sd) : ¯sj
{
P[g(1) = ¯s2, . . . , g(d

, j
∈ {
1) = ¯sd
|

∈ S
−

Now we deﬁne the sequence-valued process

{
¯g(i) , (g(id), g(id + 1), . . . , g((i + 1)d

¯g(i)
}
1)).

∈ S
σ,
1, . . . , d
, ¯s1 ∈ I
}
.
g(0) = ¯s1] > 0
}
i∈N0 by

−

(35)

N0.

Notice that ¯g(i)

¯
g0 , i
∈
S
¯
chain
g0 }
S
Speciﬁcally, we prove that for every ¯σ, ¯s
¯k

Our next goal is to show that the sequence-valued Markov
is an irreducible Markov chain.
¯
g0 , there exists
S

∈
N such that

¯g(i)

i∈N0

∈

∈

{

∈

P[¯g(i + ¯k) = ¯s

¯g(i) = ¯σ] > 0.

(36)

|
N0, that is, the ﬁrst
g0 , i
To this end, ﬁrst note that ¯g1(i)
∈
) takes are elements
elements of the sequence-values that ¯g(
·
g0 that for all
g0 . It follows from the deﬁnition of
of the set
I
I
g0 ,
σ, s

∈ I

∈ I

k

N : P[g(kd) = s

g(0) = σ] > 0

=

.

∅

} 6

{

∈
Now, deﬁne k :

|
N by

g0 × I
I
k(σ, s) , min
k
{

∈

g0 →
N : P[g(kd) = s

|
Moreover, note that for any given ¯σ, ¯s
pick a state c

g0 and let ¯k , k(c, ¯s1) + 1 so that
P[g(1) = c
By (37), we have P[g(k(c, ¯s1)d) = ¯s1|
consequently

g(0) = ¯σd] > 0.

∈ I

∈

|

g(0) = σ] > 0

.

(37)

}
¯
g0 , we can always
S

g(0) = c] > 0, and

P[¯g(i + ¯k) = ¯s
|

¯g(i) = ¯σ]

g((i + 1)d

= P[¯g(i + ¯k) = ¯s
−
|
= P[g((i + ¯k)d + 1) = ¯s2, . . . ,
1) = ¯sd

g((i + ¯k + 1)d
−
P[g((i + ¯k)d) = ¯s1|
·
P[g((i + ¯k)d + 1) = ¯s2, . . . ,
1) = ¯sd

≥

|

g((i + ¯k + 1)d
−
P[g((i + ¯k)d) = ¯s1|
P[g((i + 1)d) = c
|

·

·

|

g((i + ¯k)d) = ¯s1]

g((i + 1)d

1) = ¯σd]

−

g((i + ¯k)d) = ¯s1]

g((i + 1)d) = c]

g((i + 1)d

1) = ¯σd] > 0.

−

¯
Thus, the sequence-valued Markov chain
¯g(i)
g0 }
{
S
∈
irreducible. Now, deﬁne the function α : ¯
h
g0 × M
→
S

i∈N0 is
N0 by

α(¯s, q) ,

τ −1

j=0
X

1[¯sjh+1 ∈ S

q1 , . . . , ¯sjh+h

qh ],

∈ S

(38)

∈

∈ M

¯
g0 , q
S

h. Note that α(¯s, q)

N0 is the number
for ¯s
), when the
of times the sequence q appears in the process r(
·
process g(
) takes the values ¯s1, ¯s2, . . . , ¯sd. This number is
·
computed by dividing the d-length sequence ¯s into τ number
of h-length sequences and counting the number of h-length
sequences whose elements are from sets

∈

q2 , . . . ,

qh .

q1 ,

S

S

S

7

k−1

1[¯g(i) = ¯s]α(¯s, q).

(39)

By using (38), we get

τ k−1

1[¯r(i) = q] =

1
τ k

1
τ k

i=0
X

X¯s∈ ¯Sg0

i=0
X
¯
g0 , denote the invariant distribution
Let ¯πg0,¯s
S
¯
i∈N0. It then follows from ergodic
associated with
g0 }
S
theorem for ﬁnite-state Markov chains (see Theorem 1.10.2 of
[50]) that

[0, 1], ¯s
¯g(i)

∈
∈

∈

{

lim
k→∞

1
k

k−1

i=0
X

X¯s∈ ¯Sg0

1[¯g(i) = ¯s]α(¯s, q) =

¯πg0,¯sα(¯s, q).

X¯s∈ ¯Sg0

Hence, as a consequence of (39), limk→∞
q] exists and is given by

1
τ k

τ k−1
i=0

1[¯r(i) =

P

1
τ

X¯s∈ ¯Sg0

¯πg0,¯sα(¯s, q).

(40)

lim
k→∞

1
τ k

τ k−1

1[¯r(i) = q] =

i=0
X
Our ﬁnal goal is to show

k−1

lim
k→∞

1
k

1[¯r(i) = q] = lim
k→∞

1
τ k

τ k−1

1[¯r(i) = q].

i=0
X
To this end, ﬁrst let θ(k) ,

i=0
X
and observe that

1
k

k−1

i=0
X
1
k

+

⌊

k
τ ⌋
1
k

1[¯r(i) = q] =

1[¯r(i) = q],

k−1

Xi=τ θ(k)
0, 1

Since 1[¯r(i) = q]
q]
≤
limk→∞

∈ {
τ
k , and hence, 0

≤

τ
k = 0. As a result,
k−1

, we have 0
}
limk→∞

1
k

τ θ(k)−1

i=0
X

1[¯r(i) = q]

N0.

k

∈

(41)

≤

1
k
k−1
P
i=τ θ(k)

1[¯r(i) =

k−1
i=τ θ(k)
1[¯r(i) = q]

≤

P

1[¯r(i) = q] = 0.

(42)

τ θ(k)−1

1[¯r(i) = q]

lim
k→∞

1
k

i=0
X
1
k

τ θ(k)
τ θ(k)

= lim
k→∞

τ θ(k)−1

i=0
X

= lim
k→∞

τ θ(k)
k

lim
k→∞

1
τ θ(k)

1[¯r(i) = q]

τ θ(k)−1

i=0
X

1[¯r(i) = q].

(43)

Since limk→∞

τ θ(k)

k = 1, by (40) and (43),

lim
k→∞

It
then
limk→∞

1
k

1
k

τ θ(k)−1

i=0
X
follows
k−1
i=0

1[¯r(i) = q] =

1
τ

¯πg0,¯sα(¯s, q).

(44)

X¯s∈ ¯Sg0
(42),

from (41),

and

(44)

that

1[¯r(i) = q] exists and is given by

P
1
k

lim
k→∞

k−1

i=0
X

1[¯r(i) = q] =

1
τ

X¯s∈ ¯Sg0

¯πg0,¯sα(¯s, q).

1) = ¯σd]

lim
k→∞

Furthermore, we have

1
k

Xi=τ θ(k)

Transition diagram for Markov chain {g(t) ∈ S =
Figure 1.
{1, 2, 3, 4}}t∈N0 with initial condition g(0) = 1 and partitions S1 =
{1}, S2 = {2, 3, 4}, characterizing a 4-periodic mode sequence
1, 2, 2, 2, 1, 2, 2, 2, . . ..

{

}}

r(t)

∈ S}

1, . . . , M

S2, . . . ,

t∈N0 . The set

Remark 2.6: In Proposition 2.5, we provide a characteriza-
t∈N0 through

tion of the mode signal
∈ {
an irreducible Markov chain
g(t)
S
{
) is the union of disjoint sets
of the possible values of g(
·
M . By the deﬁnition in (34), the mode signal
S1,
takes the value s, when g(t)
s. Observe that this mode
signal follows the hidden Markov model [54], and even though
t∈N0 may fail
{
to be so as we will show in two examples shortly below. To
see this, we ﬁrst express the switched system (1) equivalently
by the alternative system

t∈N0 is a Markov chain,

∈ M}

∈ S}

∈ S

g(t)

r(t)

S

{

x(t + 1) = ¯Ag(t)x(t),

(45)

g(t)

∈ S}

∈ S
{

with ¯Aj , Ai, j
i. Here, (45) is a switched system where
t∈N0 is a Markov chain. This
the mode signal
switched system is also called a Markov jump system [13].
We would like to highlight that the stability results on Markov
jump systems are not applicable here. Different from the
ordinary Markov jump systems, neither transition probabilities
nor stationary distributions of the process g(
) are available for
·
analysis. In fact even the size of the set
may not be known.
In particular, when we consider the application to networked
control under jamming attacks (see Sections IV and V), the
t∈N0 may characterize a jamming attacker’s
process
strategy and its properties are not available for analysis.

∈ S}

g(t)

S

{

Furthermore, we remark that (34) is only one of the possible
characterizations of the mode signal for our analysis to be ap-
plicable. The mode signal may also be generated in other ways
following different random or deterministic characterizations.
Our stability analysis in Theorem 2.4 relies on the bounds on
the average number of times each mode is active in the long
run (see Assumption 2.1) instead of the properties of particular
mode signal characterizations.

The characterization through (34) is general enough to
model various types of mode signals. We present two examples
in this regard.

{

g(t)

∈ S}

Example 1: Periodic mode switchings can be described with
t∈N0.
an irreducible and periodic Markov chain
Consider for example a switched system with 2 modes. The
mode sequence is assumed to repeat itself in every 4 time
steps. Speciﬁcally, in every 4 time steps, mode 1 is active for
1 time step then mode 2 becomes active for the next 3 time
steps. This switching scenario can be characterized by setting
S1 ,
t∈N0 as a Markov
chain with transition probabilities shown on the edges of the
transition graph in Fig. 1. Here, g(
) repeatedly takes the values
·
1, 2, 3, 4, 1, 2, 3, 4, . . .. As a result, by the deﬁnition in (34),
) takes the values 1, 2, 2, 2, 1, 2, 2, 2, . . .
the mode signal r(
·
indicating the periodic change in the mode.

S2 ,

2, 3, 4

∈ S}

, and

g(t)

}

{

1

{

}

{

,

8

1

−

In this example,

the switched system can be used for
modeling a networked control system under periodic attacks.
In particular, the ﬁrst mode corresponds to a successful packet
exchange between the plant and the controller, and the second
mode represents the dynamics when there is a transmission
failure due to attacks. The characterization of the mode signal
through the setup in Fig. 1 represents an example of the
discrete-time version of the periodic attacks discussed in [19].
Here the attacker periodically repeats sleeping for 1 time step
and emitting a jamming signal to block network transmissions
is important to note that
for 3 consecutive time steps. It
when the networked control system is periodically attacked,
the speciﬁc failure sequence and the period itself are part of
attacker’s strategy and in general they are not available to the
system operator. We consider a networked control problem that
covers this case in Section IV. There, we show that to check
networked control system’s stability through Theorem 2.4,
only the knowledge of the upper-bound on the average attack
ratio is needed. For the periodic attack in Fig. 1, the upper-
bound on this ratio is given by ρ2, since the second mode
corresponds to the attacks. Notice that in this case we can
select ρ

ρ2, ρ1 = 1, and ρ

= 0.

= 1

2

{

{

}

=

g(t)

∈ S

S2 ,

S1 ,

S1 ∪ S2}

Example 2: The characterization in (34) can also be used to
describe random packet transmission failures. For example,
communication channels following the Markov model can
, and
be described simply by setting
1
}
t∈N0 as a Markov chain with certain
{
transition probabilities. In addition, the Gilbert-Elliott model
and other more advanced models based on Markov chains (see
[45], [46]) can also be described within the framework. For
instance, in Gilbert-Elliott model, the channel is in the state of
either “Good” or “Bad”. In Good channel state, packet losses
occur with a small probability e; moreover, in Bad channel
state, failure probability denoted by f may be large. Transi-
tions between Good and Bad states occur with probability p
from Good to Bad and q from Bad to Good. This scenario
S1 ,
, and
can be described by setting
,
}
t∈N0 as a Markov chain with transition
g(t)
{
diagram shown in Fig. 2. In this setting, g(t)
corre-
1, 3
}
∈ {
sponds to Good channel state and g(t)
corresponds
2, 4
∈ {
}
∈ S2 indicates a
to Bad. On the other hand, by (34), g(t)
packet exchange failure at time t, whereas g(t)
∈ S1 indicates
a successful packet exchange attempt. Using different settings
t∈N0, we can also model the
for
situation where the network faces both jamming attacks and
random packet transmission failures.

S2, and

S1 ∪ S2}

S2 ,

∈ S}

S1,

g(t)

∈ S

3, 4

1, 2

=

{

}

{

{

2

,

{

∈

∈ M}
k−1
1
i=0
k

Note that when

1[¯r(i) = q], q

r(t)
(34), the limits limk→∞
for all h
Theorem 2.4 can be conducted with any h
hand, for other characterizations of
r(t)
{
be the case that the limits exist for h
for h > ˆh, where ˆh
∈
applicable only for h

t∈N0 is characterized through
h, exist
N. Hence, in such cases, the stability analysis in
N. On the other
t∈N0, it may
but not
N. In those situations, Theorem 2.4 is

∈
∈ M}
1, 2, . . . , ˆh
}

1, 2, . . . , ˆh

∈ M

∈ {

P

.

∈ {

}

III. STABILITY ASSESSMENT VIA LINEAR PROGRAMMING
In this section, we investigate two closely-related linear
programming problems and present a method for checking

9

1−̺
̺−̺

ρs)

and similarly,

1 = lim inf
k→∞

1
k

M

k−1

M

1[r(t) = s]

t=0
X
1
k

lim sup
k→∞

s=1
X
k−1

1[r(t) = s]

≥

s=1
X
M
s=1 ρs

, ̺ ,

t=0
X

Now let ̺ ,
and consider ρq, q

P

h, given by
P

M

s=1 ρs and βs , (ρs −

M

≥

s=1
X

ρs.

∈ M
ρs + βs,
0,

ρq =

(

if cs(q) = h, s
otherwise.

,

∈ M

(47)

h,
To establish that the feasible region contains ρq, q
given by (47), we show that (19) and (20) hold. First, (19)
holds because

∈ M

Transition diagram for Markov chain {g(t) ∈ S =
Figure 2.
{1, 2, 3, 4}}t∈N0 with partitions S1 = {1, 2}, S2 = {3, 4}, characterizing
packet exchange failures on a Gilbert-Elliott channel.

the almost sure asymptotic stability condition given in Theo-
rem 2.4 through their optimal solutions.

A. Linear Programming Problem 1

M

ρq =

(ρs + βs) = ̺ +

Theorem 2.4 states that the switched system (1) is stable if
there exists an induced matrix norm
(0, 1)
h,
such that the inequality (17) holds for all ρq
that satisfy (19), (20). In what follows, we provide a linear
programming problem to check this condition for a given
induced matrix norm
Now deﬁne γq

h, as in (18) and consider the

and a scalar ε
[0, 1], q

∈
∈ M

and scalar ε

k · k
R, q

(0, 1).

k·k

∈

∈

linear programming problem

∈

∈ M

maximize
ρq∈[0,1], q∈Mh
subject to

q∈Mh γqρq
(19), (20).

P

(46)

∈ M

For the stability analysis, different values of ρq, q

h,
that satisfy (19), (20) represent possible mode activity sce-
the long run average conditions (2) and
narios such that
(3) hold. The linear programming problem (46) allows us to
q∈Mh γqρq. We can then
identify scenarios that maximize
check the stability condition (17) with the maximum value of
q∈Mh γqρq instead of checking it for all possible scenarios.
In the following lemma, we show that the linear program-
P
there always exist
ming problem (46) is feasible,
h, that satisfy (19), (20). Furthermore, we
ρq
show that the problem is bounded (i.e., the objective function

that is,

[0, 1], q

∈ M

P

∈

q∈Mh γqρq in (46) is bounded).
Lemma 3.1: The linear programming problem (46) is feasi-

P
ble and bounded.

Proof: First, we show that the feasible region of the
linear programming problem is not empty. To this end, ﬁrst
M
observe that
s=1 ρs. This is because
Assumption 2.1 implies

s=1 ρs ≤

≤

M

1

P

P

1 = lim sup

k→∞

1
k

k−1

M

1[r(t) = s]

M

≤

s=1
X

lim sup
k→∞

t=0
X
1
k

s=1
X
k−1

t=0
X

1[r(t) = s]

M

≤

s=1
X

ρs,

Xq∈Mh

s=1
X
1
(cid:18)

1
̺

= ̺

−
−
Now we show (20). Since ̺
ρs]. It then follows that

−

̺
̺

+

1
̺

(cid:19)
1

≤

≤

(ρs −

ρs)

M

1
̺

̺
̺

−
−
̺
̺

s=1
X
̺ = 1.

−
−
̺, we have βs

(48)

[0, ρs −

∈

cs(q)ρq = ρs + βs

[ρs, ρs],

∈

s

.

∈ M

(49)

Xq∈Mh

It now remains to show that the solutions to the linear pro-

P

∞

gramming problem are bounded. Note that since ρq

h, we have

M
(maxq∈Mh γq)M h <

q∈Mh γqρq

(maxq∈Mh γq)
, which completes the proof.

≤

1, q
≤
q∈Mh ρq

∈
≤

Lemma 3.1 implies that there exists an optimal solution to
the linear programming problem (46) (see Proposition 3.1 of
[55]). Even though there may be multiple optimal solutions,
we can always compute the optimal value of the objective
function using any one of those solutions. Let Jh denote
the optimal value of the objective function when h-length
sequences are considered, that is,

P

∈

∈ M

Jh , max

γqρq : ρq

[0, 1], q

h, s.t. (19), (20)

.

n Xq∈Mh

o
The stability of the switched system (1) can be assessed
by checking the sign of the optimal value Jh. Speciﬁcally,
0 of the switched system (1) is
the zero solution x(t)
asymptotically stable almost surely if

≡

Jh < 0.

(50)

∈

∈ M

This is because (50) implies that (17) in Theorem 2.4 holds
for all ρq

h, that satisfy (19), (20).

[0, 1], q

Remark 3.2: The optimal solution Jh for the linear pro-
gramming problem (46) may be positive when h is small, but
may become negative for sufﬁciently large h. The reason is
that with large h, stability/instability properties of more mode
activity patterns are taken into account. For instance, consider
a switched system with two modes. When h = 2, the effects
of the dynamics associated with packet failure sequences in

2 ,

M

(1, 1), (1, 2), (2, 1), (2, 2)
}

{

are represented by γq, q

∈

∈

∈ M

2. However, γq, q

2, cannot be used to distinguish the
M
difference between stabilizing (destabilizing) effects of longer
mode activity sequences (1, 2, 2, 1) and (2, 1, 1, 2), since both
of them are composed of the same smaller sequences (1, 2),
(2, 1). Thus to show stability, we may need to take into
account longer mode sequences and obtain Jh for larger values
N. Note that γq associated with a mode sequence
of h
q = (1, 2, 2, 1) may be negative, even though γ(1,2) and
γ(2,1) associated with the smaller sequences (1, 2), (2, 1) are
positive. This is similar to the observation that a switched
system with individually unstable modes may be stable if the
switching is constrained in a certain way (see Chapter 2 of
[5]). We note that our approach of choosing a larger h value
is related to the approach utilized in [39] for showing average
contractivity of Markov jump systems over h steps as well
as the approaches used in [40]–[42] for showing switched
system stability through the investigation of the evolution of
the mode signal over multiple time steps. In addition to these
works, a related approach was also used in [43], [44] to show
convergence of risk-sensitive and risk sensitive like ﬁlters by
means of establishing strict contractivity of Riccati recursions
over h steps.

∈ M

Even though there are efﬁcient algorithms for solving linear
programming problems, it is difﬁcult to solve (46) and obtain
N is large. This is because the number of
Jh when h
∈
h, of the problem (46) grows exponentially
variables ρq, q
h,
in h. Speciﬁcally, the number of elements of the set
and hence the number of variables of the linear programming
problem (46) is given by f (h, M ) , M h. In the following,
we show that an alternative linear programming problem with
fewer variables shares the same optimal objective function
value as that of (46). In particular, the number of variables
in this alternative problem grows only polynomially in h.

M

B. Linear Programming Problem 2

We observe in the linear programming problem (46) that
due to the particular structure of our problem setting, some
of the variables have the same coefﬁcients in the constraints.
In particular, if two (or more) mode sequences are reordered
versions of each other, then the variables associated with those
mode sequences have the same coefﬁcients in the constraints.
This allows us to obtain an alternative problem with fewer
variables.

1 ≤

ρ(1,1) + 0.5ρ(1,2) + 0.5ρ(2,1) + 0ρ(2,2) ≤

0ρ(1,1) + 0.5ρ(1,2) + 0.5ρ(2,1) + 1ρ(2,2) ≤

For an intuitive explanation of how this is possible, consider
the case with M = 2, h = 2. In this case, the constraints in
ρ1 and
(20) are ρ
ρ2, where the
ρ
2 ≤
variables ρ(1,2) and ρ(2,1) have the same coefﬁcients. If, for ex-
γ(1,2), then it means that we can maximize the
ample, γ(2,1) ≥
objective γ(1,1)ρ(1,1) + γ(1,2)ρ(1,2) + γ(2,1)ρ(2,1) + γ(2,2)ρ(2,2)
by setting ρ(1,2) to 0 and considering only ρ(1,1), ρ(2,1), ρ(2,2)
as variables of the optimization problem. This is because if
h, is an optimal solution of the problem,
ρq = ˜ρq, q
h, with ˆρ(1,1) = ˜ρ(1,1), ˆρ(1,2) = 0,
then ρq = ˆρq, q
ˆρ(2,1) = ˜ρ(1,2) + ˜ρ(2,1), and ˆρ(2,2) = ˜ρ(2,2) is also an optimal
h, satisfy the constraints
solution since ρq = ˆρq, q
γ(1,2) implies
and γ(2,1) ≥
q∈Mh γq ˆρq.

q∈Mh γq ˜ρq

∈ M

∈ M

∈ M

≤

P

P

10

∈ M

(Furthermore, if γ(2,1) is strictly larger than γ(1,2), then for all
h, the value of ρ(1,2) is necessarily
optimal solutions ρq, q
0.) As this discussion indicates, the variable ρ(1,2) can be
removed from the optimization problem for this example,
since the terms that involve ρ(1,2) are all 0. Similarly, if
then the variable ρ(2,1) can be removed.
γ(2,1) ≤
N and
Notice that similar techniques can be used for all M
N. Furthermore, more variable reductions are achieved
h
as M and h increase. In particular, we obtain the following
linear programming problem:

γ(1,2),

∈

∈

(z1, z2, . . . , zM ) : zs

0, 1, . . . , h

, s

∈
∈ {
, and consider the linear programming

}

{

h ,
Z
M
s=1zs = h

Let
,
M
problem
P
maximize
ρ′
z ∈[0,1], z∈Zh
subject to

}

where

zρ′
γ′
z

z∈Zh

ρ′
z = 1,
P
zs
h ρ′

z∈Zh

z∈Zh

ρs ≤
P

z ≤

(51)

(a)
, (b)

ρs, s

∈ M

P
, max
q∈Mh,z

γ′
z

γq,

z

h,

∈ Z

(52)

h : c1(q) = z1, c2(q) = z2, c3(q) =

h,z ,
with
z3 . . . , cM (q) = zM

M

{

q

∈ M
, z
}

h.

∈ Z

In what follows, we ﬁrst show that the objective functions
of the linear programming problems (46) and (51) have the
same optimal values. After that we discuss the advantage
of the linear programming problem (51) over the problem
(46). Speciﬁcally, we show that it is easier to solve the
linear programming problem (51) because it involves fewer
variables.

Lemma 3.3: The linear programming problem (51) is feasi-

ble and bounded.

Proof: The proof is similar to that of Lemma 3.1. First,
we show that the feasible region of the linear programming
problem (51) is not empty. To this end, consider ρ′
h,
given by

z, z

∈ Z

ρ′
z =

ρq,

(53)

Xq∈Mh,z

≥

[0, 1], z

z ∈
h, implies ρ′

with ρq given in (47). Notice that ρ′
h. This
∈ Z
0, and moreover,
is because ρq
0, q
z ≥
ρ′
q∈Mh ρq = 1 due to (48). To establish
z =
that the feasible region contains ρ′
h, given by (53), we
show that (51a) and (51b) hold. Now, (51a) holds, because it
follows from (48) that

q∈Mh,z ρq

∈ M

∈ Z

z, z

P

P

≤

ρ′
z =

ρq =

ρq = 1,

z∈Zh
X

z∈Zh Xq∈Mh,z
X
where we also used the fact that
z, ˆz

∈ Z
Next,

h, and
to

h,z =

M
h.
z∈ZhM
∪
M
show (51b), note
zs
h ρq =

q∈Mh

h,z

Xq∈Mh

h,ˆz =

∅

∩M

for z

= ˆz,

that
=
cs(q)
h ρq. Hence, (49) im-

z∈Zh

zs
h ρ′
z

P

q∈Mh,z

It now remains to show that the solutions to the linear

z∈Zh
plies (51b).
P
P
P
programming problem are bounded. Note that since ρ′
z ≤
zρ′
γ′
1, z
h,
z ≤
∈ Z
ρ′
(maxz∈Zh γ′
,
<
z)
z ≤
∞
which completes the proof.

that
(maxq∈Mh γq)

it follows from (52)

z∈Zh

z∈Zh
h+M−1
M−1
P
(cid:0)

(cid:1)

P

6
By Lemma 3.3, there exists an optimal solution to the linear
h denote the optimal value
N, that is,

programming problem (51). Let J ′
of the objective function for a given h

∈

J ′
h

, max

z∈Zh
n X

γ′
zρ′

z : ρ′

z, z

∈ Z

h, s.t. (51a), (51b)

.

o

Jh

Lemma 3.4: The objective functions of the linear program-
ming problems (46) and (51) have the same optimal values,
that is, Jh = J ′
h.

J ′
h and

Proof: We prove this result by showing Jh
J ′
h separately.

≤

≤

≥
J ′
h, we show that for all ρq
To establish Jh
h, such that (19), (20) hold, we have

[0, 1], q
∈
∈
J ′
h.
q∈Mh γqρq
M
h, such that (19),
Now, notice that for all ρq
∈
,
(20) hold, the constraints in (51a) and (51b) hold with ρ′
z
J ′
h.
h, such that (19), (20) hold, we have
P

q∈Mh,z ρq, z
Hence, for all ρq, q
P

h, and as a result,

[0, 1], q

P
∈ M

zρ′
γ′

z ≤

∈ Z

z∈Zh

∈ M

≤

γqρq =

Xq∈Mh

z∈Zh Xq∈Mh,z
X
γ′
z

=

γqρq

≤

ρq =

γ′
zρq

z∈Zh Xq∈Mh,z
X
zρ′
γ′
z ≤

J ′
h,

z∈Zh
X

Xq∈Mh,z

which implies Jh
To prove Jh

z∈Zh
X
J ′
h.
≤
J ′
h, we now show that there exists ρq
h, such that
z, z

∈
h and (19), (20)
h, denote an optimal solution to the

q∈Mh γqρq = J ′

≥
[0, 1], q
hold. Here, let ˆρ′
linear programming problem (51), that is,

∈ M

∈ Z

P

γ′
z ˆρ′

z = J ′
h.

i∈Zh
X
h, let q(z)
h,z

Now, for each z
ρq(z) = ˆρ′

∈ Z
z, ρq = 0, q

∈
q(z)
h, satisfy (19), (20); furthermore,

∈ M

\ {

}

argmaxq∈Mh,z γq and set
. It follows that ρq, q

∈

M

γqρq =

γ′
z ˆρ′

z = J ′
h.

z∈Zh
Xq∈Mh
X
This establishes that there exist ρq

h, such that
[0, 1], q
h and (19), (20) hold, which implies that

∈ M

∈

≥
A direct consequence of Lemma 3.4 is that if J ′

h < 0,
0 of the switched system (1) is

then the zero solution x(t)
asymptotically stable almost surely.

≡

So far we established that almost sure asymptotic stability
of the switched system (1) can be assessed by checking signs
of the optimal objective function values (Jh and J ′
h) of linear
programming problems (46) and (51). The switched system
(1) is stable if the value of Jh = J ′

h is negative.

We observe that solving the linear programming problem
(51) can be computationally more advantageous in comparison
to the problem (46). This is because (51) involves fewer
variables. Speciﬁcally, the number of elements of the set
h,
and hence the number of variables of the linear programming
problem (51), is f ′(h, M ) ,
(M−1)!h! . For h
and M larger than 1, the number of variables in the problem
(cid:0)
(51) is strictly smaller than that of the problem (46), that is,

= (h+M−1)!

h+M−1
M−1

Z

(cid:1)

f ′(h, M ) < f (h, M ),

h > 1, M > 1.

q∈Mh γqρq = J ′

Jh
P

J ′
h.

11

ln f (h, 3)
ln f ′(h, 3)

1

5

10

15

20

25

h

ln f (15, M )
ln f ′(15, M )

30

20

10

0

60

40

20

0

1

5

10

15

M
Figure 3. Comparison of ln f (h, M ) and ln f ′(h, M ) (Top: varying h, ﬁxed
M = 3; Bottom: ﬁxed h = 15, varying M ).

We note again that f grows exponentially in h. On the other
hand f ′, the number of variables in the problem (51), grows
only polynomially in h. Speciﬁcally, we have

f ′(αh, M )

αM−1f ′(h, M ), α, h, M

N.

≤
∈
As a result, when h is large, obtaining J ′
h is much faster than
obtaining Jh. We also remark that the number of variables
grows polynomially in the number of modes M as well. In
particular, we have

f ′(h, αM )

≤

αhf ′(h, M ), α, h, M

N.

∈

Fig. 3 shows graphs of ln f (h, M ) and ln f ′(h, M ) indicating
how the numbers of variables in problems (46) and (51) grow
with respect to h and M . The difference becomes larger as
M and h get larger. For instance, in the case where h = 15
and M = 3, there are f (15, 3) = 14,348,907 variables in
the problem (46), whereas (51) involves only f ′(15, 3) = 136
variables.

z, z

∈ Z

Notice that an optimal solution ˆρ′

∈ M
h, as ˆρq(z) = ˆρ′

h, to the problem (46) by selecting q(z)
h and then setting ˆρq, q
q(z)

h, to the linear
programming problem (51) can be used to obtain an optimal
solution ˆρq, q
argmaxq∈Mh,z γq for each z

∈
∈
h.
M
∈ M
As established in the second part of the proof of Lemma 3.4,
q∈Mh γq ˆρq = J ′
h, and hence provide an
ˆρq, q
optimal solution to the problem (46), since Jh = J ′
h. Clearly,
if for any z
h the set argmaxq∈Mh,z γq has more than
one element, then there are multiple optimal solutions to the
problem (46).

z, ˆρq = 0, q

h, satisfy

∈ M

∈ Z

∈ Z

∈ Z

\ {

, z

P

h,z

}

h!

It

is important to note that although solving the linear
programming problem (51) is easier due to fewer variables,
it requires precomputation of coefﬁcients γ′
z by (52). Notice
that, for each z, the complexity of computing γ′
z is linear in
h,z, which is given by
the number of variables of the set
z1!z2!···zM ! . It turns out that this computation can be carried
out for all coefﬁcients γ′
z at the same time using parallel
computing techniques. For instance, in the case of h = 15
h of f ′(15, 3) = 136 variables can
and M = 3, the set
be partitioned into 8 subsets with size 17. We can then
utilize a computer with 8 central processing units to carry

M

Z

out the computation for each of these subsets. Both linear
programming problems (46) and (51) require calculation of
h,
norms of matrix products in the computation of γq, q
given in (18). For large values of h, this is a computationally
intensive calculation, but it can also be conducted in parallel
for different q values.

∈ M

∈

∈

∈ M

∈ M

We also note that using different matrix norms in the
h, can be useful to check stability in
deﬁnition of γq, q
the case of limited computational resources. This is because
Jh and J ′
h may be positive for a particular matrix norm and
h, depend on
negative for another. Note also that γq, q
∈ M
h. If
the value of ε in (18) if Γq = 0 for some q
Γq = 0 for some q
Qh and the optimal solution value
Jh = J ′
h is positive for a particular value of ε, then we can
try solving the linear programming problems with a smaller
ε value. If the optimal solution value Jh = J ′
h is negative
for a value ε = ˆε, then the stabilization is guaranteed. In that
case, we do not need to consider smaller ε values, since for
(0, ˆε), the optimal solution value Jh = J ′
h is also
every ε
guaranteed to be negative. This is because the constraints in
the linear programming problems do not change with ε and
the coefﬁcients of the objective functions for the case with
ε

(0, ˆε) are smaller than the case with ε = ˆε.

0 if and only if there exist ρq

h, such that (19), (20), and

∈
We remark that for stability analysis, the sign of Jh and J ′
h
can also be assessed by solving linear feasibility problems
without computing the actual values of those scalars. In
particular, we have Jh
[0, 1],
∈
0 hold.
q
Similarly, we have J ′
[0, 1],
0 hold.
z
Note that solving these feasibility problems is not necessarily
faster in comparison to solving the associated linear program-
ming problems, since the numbers of variables in these two
feasibility problems are equal to those in the associated linear
programming problems.

≥
0 if and only if there exist ρ′
z ∈
P

h ≥
h, such that (51a), (51b), and

q∈Mh γqρq

∈ M

zρ′
γ′

z ≥

∈ Z

z∈Zh

P

≥

IV. APPLICATION TO NETWORKED CONTROL UNDER
JAMMING ATTACKS

In this section we consider two problem settings where we

model the networked control system as a switched system.

A. Control over Delay-Free Communication Links

First, we explore the networked control problem where
at each time instant, the plant and the controller attempt to
exchange state and control input packets over a communication
channel. In this problem setting, network transmissions do not
face delay, but packet exchange attempts between the plant and
the controller may be subject to packet losses due to malicious
jamming attacks or nonmalicious communication errors. In a
successful packet exchange attempt, the plant transmits the
state information to the controller; the controller uses the
received state information to compute the control input through
a linear control law and sends back the control input to the
plant. The transmitted control input is then applied at the plant
side. Packet exchange attempt failures happen when either the
measured state packets or the control input packets are lost.
In that case, the control input at the plant side is set to 0.

12

Figure 4. Packet exchange success mode (left) and failure mode (right) of
the networked control system.

Fig. 4 illustrates the operation of the networked control system
during a successful packet exchange attempt at time t1 and a
failed exchange attempt at time t2.

The dynamics of the linear plant is given by

˜x(t + 1) = A˜x(t) + Bu(t),

R˜n and u(t)
where ˜x(t)
control input, respectively; furthermore, A
are the state and input matrices, respectively.

∈

∈

∈

N0,

t

˜x(0) = ˜x0,
Rm denote the state and the
R˜n×˜n and B ˜n×m

(54)

∈

l(t)

We use the binary-valued process

t∈N0 to
describe success or failure states of packet exchange attempts.
Speciﬁcally,
the packet
the state l(t) = 0 indicates that
exchange attempt at time t is successful, whereas l(t) = 1
indicates failure. In this case, the control input u(t) applied at
the plant side is given by

∈ {

0, 1

}}

{

where K

∈

u(t) , (1
Rm×˜n denotes the feedback gain.

l(t)) K ˜x(t),

−

∈

t

N0,

(55)

In [21], we proposed a characterization for
0, 1

∈
t∈N0 that allows us to model the effects of random
{
packet losses and jamming attacks in a uniﬁed manner. This
characterization relies on the following assumption.

l(t)

}}

{

Assumption 4.1: There exists a scalar ρ

∞

k−1

P[

l(i) > ρk] <

k=1
X

i=0
X

[0, 1] such that

∈

.
∞

(56)

(cid:3)

∈

(cid:2) P

k−1
i=0 l(i)/k > ρ

Here, the inequality (56) can be considered as a condition
on the evolution of tail probability P
. The
scalar ρ
[0, 1] in (56) plays a key role in characterizing a
probabilistic bound on the average ratio of packet exchange
failures. Observe that the case where all packet transmission
attempts result in failure can be described by setting ρ = 1. It
is shown in [21] that ρ in (56) can be obtained to be strictly
smaller than 1 for certain random and malicious packet loss
models. These models include time-inhomogeneous Markov
chains for describing random packet losses, as well as a
discrete-time version of the malicious attack model in [20],
where the number of packet exchange attempts that face
attacks is upper bounded by a certain ratio of the total number
of packet exchange attempts.

We showed in [21] that the closed-loop networked control
system is stable, when ρ in (56) takes a sufﬁciently small
value. In what follows we provide an alternative stability
analysis method for the networked control system by utilizing
Theorem 2.4. This new method turns out to be less conser-
vative than the results in [21] in certain scenarios. To utilize
Theorem 2.4 we ﬁrst describe the closed-loop system as a
discrete-time switched system.

The networked control system (54), (55) is equivalently
described as a discrete-time switched system (1) with the state
x(t) = ˜x(t) and the mode signal given by r(t) = l(t)+1. Fur-
thermore, the subsystem matrices are given by A1 = A+BK,
A2 = A. Now, under Assumption 4.1, the inequalities (2) and
(3) in Assumption 2.1 hold with ρ
= 0,
= 1
1
and ρ2 = ρ. This is because (56) implies

ρ, ρ1 = 1, ρ
2

−

13

ρ,

(57)

Figure 5. Networked control over delay-free and 1-step-delayed channels.

lim sup
k→∞

1
k

k−1

l(t)

≤

t=0
X
k−1
ρ. Through
and hence lim supk→∞
t=0
this switched system characterization, stability of the net-
worked control system (54), (55) can be analyzed by using
Theorem 2.4. Moreover, the linear programming problems
developed in Section III can also be employed.

1[r(t) = 2]

P

≤

1
k

In [21] (see also [27]), an event-triggering controller is
used for stabilization, and the packet exchange attempt times
are decided by utilizing a set of triggering conditions. These
conditions can be adjusted to consider the problem setting
where the plant and the controller attempt packet exchanges
at each time instant. For this problem setting, Theorem 2.4 is
less conservative and can be considered as an enhancement of
the stability result presented in [21]. In fact, the stability result
in [21] is obtained by analyzing the evolution of a Lyapunov-
like function V (x) = xTP x at each time step. This analysis
idea can be recovered by our approach presented in this paper
through setting h = 1, and deﬁning the norm in (18) as the
P , √xTP x. In
matrix norm induced by the vector norm
x
k
k−1
1
particular, for the case where limk→∞
i=0 l(i) exists, for
k
all scenarios in which the stability condition in Theorem 3.5 in
[21] holds, the stability condition in Theorem 2.4 also holds.
Furthermore, as we illustrate in Section V, there are cases
where the condition in Theorem 3.5 in [21] does not hold but
the condition in Theorem 2.4 is satisﬁed.

The following result shows that when limk→∞

k−1
i=0 l(i)
exists, for all scenarios in which the stability condition in The-
orem 3.5 in [21] holds, the stability condition in Theorem 2.4
also holds.

Proposition 4.1: Assume limk→∞

k−1
i=0 l(i) exists. Sup-
pose the stability condition in Theorem 3.5 in [21] holds, that
P
Rn×n and scalars
is, there exist a positive-deﬁnite matrix P
β

) such that

(0, 1), ϕ

[1,

P

P

∈

1
k

1
k

k

∈

∈
βP

ϕP
(1

−

∞
(A + BK)T P (A + BK)
ATP A
−
≥
ρ) ln β + ρ ln ϕ < 0,

0,

−

0,

≥

(58)

(59)
(60)

hold. Then with h , 1 the stability condition in Theorem 2.4
k−1
h, exist;
also holds, i.e., limk→∞
i=0
∈ M
and a scalar ε
moreover, there is a matrix norm
(0, 1)
∈
P
h, that satisfy
such that (17) holds for all ρq
(19) and (20).

1[¯r(i) = q], q

k · k
[0, 1], q

∈ M

∈

1
k

(1), (2)
{
}
implies that limk→∞

Proof: First, note that when h = 1, we have
. As a result, existence of limk→∞

h =
M
k−1
1
i=0 l(i)
k
h, also exist.
Next, let the norm in (18) be the matrix norm induced
,

1[¯r(i) = q], q

by the vector norm

P , √xTP x,

k−1
i=0

∈ M

that

P

M

is,

1
k

P
x
k
k

k

k

kMxkP
kxkP

, M

supx∈Rn\{0}
equalities (58) and (59) imply
A2k
A
k
k ≤
by using (60) and ρ(2) ≤

=

∈

k

Rn×n. Under this norm, the in-
√β and
A + BK
=
k
√ϕ. Now let ε , √β. Since ε = √β < √ϕ,

k ≤

k

A1k
ρ2 = ρ, we get

γqρq = γ(1)ρ(1) + γ(2)ρ(2) = γ(1)(1

ρ(2)) + γ(2)ρ(2)

−

A + BK

, ε

+ ρ(2) ln max

, ε

A
k

}

{k

}

Xq∈Mh
= (1

(1

(1

≤

≤

−

−

−

ρ(2)) ln max
ρ(2)) ln

ρ) ln

{k

k
β + ρ(2) ln √ϕ
1
2

p
β + ρ ln √ϕ =

((1

ρ) ln β + ρ ln ϕ) < 0,

−

for all ρq
(20) hold, which completes the proof.

(1), (2)
}

∈ M

∈

{

h =

p
[0, 1], q

, such that (19) and

B. Control over Delay-Free and One-Step Delayed Commu-
nication Links

The switched system framework generalizes [21] to the
multiple mode case with M > 2. This aspect is now illustrated
through the networked control system depicted in Fig. 5,
where the control actions are transmitted to the plant over two
separate communication channels. We assume that one of these
channels faces no delay and the other one faces 1-step delay
in transmissions. Investigation of a networked control setup
involving multiple channels with different delays is useful for
analyzing systems that incorporate multiple actuators placed
at different locations. The nodes that relay the information
coming from the controller to certain actuators may induce
delays due to different security measures in transmission
powers, encryptions, and so on.
In our problem setting,

is as given in (54).
The controller receives the system state ˜x(t) at each time
inputs KN ˜x(t) and KD ˜x(t)
t, and computes two control
that are attempted to be transmitted on the delay-free and
1-step-delayed channels, respectively. We respectively use
t∈N0 to indicate
lD(t)
lN(t)
{
failures on the delay-free and the one-step-delayed channels.
If both channels fail (lN(t) = 1, lD(t) = 1), the control input
at the plant side is set to 0. Furthermore, the control data
1) received from the delayed channel is used only if
KD ˜x(t
the transmission on the delay-free channel fails (lN(t) = 1,
lD(t) = 0). Otherwise (when lN(t) = 0, lD(t) = 1 or
lN(t) = 0, lD(t) = 0), the control input at the plant side
is set to KN ˜x(t) received from the delay-free channel. Hence,
the control input applied at the plant is given by

t∈N0 and

the plant

∈ {

∈ {

0, 1

0, 1

}}

}}

−

{

u(t) = (1

−

lN(t))KN ˜x(t)+lN(t)(1

lD(t))KD ˜x(t

1), (61)

−

−

14

5

10

15

h

20

25

30 0

1

0.5

ρ

1. Assuming u(0) = 0, the closed-loop dynamics (54),

for t
(61) can be given by

≥

−

lN(t))BKN lN(t)(1
I˜n

−

lD(t))BKD
0

˜x(t + 1)
˜x(t)

,

t

N0.

∈

(cid:21)
(62)

0

′h
J

10

−

˜x(t + 2)
˜x(t + 1)

(cid:20)

(cid:21)

A + (1

=

(cid:20)

·

(cid:20)
By setting

(cid:21)

(cid:21)

x(t) ,

˜x(t + 1)
˜x(t)

(cid:20)

, r(t) ,

1,
2,
3,




lN(t) = 0,
lN(t) = 1, lD(t) = 0,
lN(t) = 1, lD(t) = 1,

(63)
N0, the closed-loop dynamics (62) forms a switched



for t
system (1) with 3 modes represented by

∈

A1 ,

A2 ,

(cid:20)

(cid:20)

A + BKN 0
0

I˜n
A BKD
I˜n

0

,

(cid:21)

, A3 ,

(cid:21)

A 0
0
I˜n

.

(cid:21)

(cid:20)

(64)

Concerning the communication channels in the networked

control system, we assume the following.

Assumption 4.2: There exist scalars σN, σD, ρN, ρD ∈

such that

[0, 1]

lim inf
k→∞

lim inf
k→∞

1
k

1
k

k−1

t=0
X
k−1

t=0
X

hold almost surely.

lN(t)

σN, lim sup
k→∞

≥

lD(t)

σD, lim sup
k→∞

≥

1
k

1
k

k−1

t=0
X
k−1

t=0
X

lN(t)

lD(t)

≤

≤

ρN,

(65)

ρD,

(66)

Note that this assumption provides lower- and upper-bounds
on the long-run average numbers of transmission failures on
the delay-free and 1-step-delayed channels.

In the following result, we show that under Assumption 4.2,
the mode signal of the switched system representing the
networked control system satisﬁes Assumption 2.1.

Proposition 4.2: Suppose (65) and (66) in Assumption 4.2

are satisﬁed. Then (2) and (3) in Assumption 2.1 hold with

ρ

ρ

ρ

1

2

3

= 1

−
= max

= max

ρN, ρ1 = 1
−
0, σN −
ρD}
0, σN + σD −

{

{

σN,
, ρ2 = min
{

ρN, 1

σD}
−
ρN, ρD}

{

1

, ρ3 = min

}

(67)

(68)

(69)

,

.

Proof: We use Lemma A.1 to show the result. To this

end, note that

lN(t),

1[r(t) = 1] = 1
1[r(t) = 2] = lN(t)(1
−
1[r(t) = 3] = lN(t)lD(t),

−

lD(t)),
t

∈

(70)

(71)
(72)

N0.

First, we show (2) and (3) hold for the case s = 1 with ρ
, ρ1
given in (67). By (65) and (66), the inequalities (74) and (75)
lN(t),
in Lemma A.1 hold with ξ1(
), ξ2(
−
·
·
σN, ς2 = 1,
ξ2(t) = 1, t
−

) given by ξ1(t) = 1
ρN, ̺1 = 1

N0, and ς1 = 1

−

∈

1

Figure 6. Optimal solution value J ′
with respect to h and ρ.

h of the linear programming problem (51)

1

̺2 = 1. By the lemma, we obtain (2) from (76) and (3) from
(77) with ρ

, ρ1 given in (67).

lD(t), t

Next, we show (2) and (3) hold for the case s = 2 with
, ρ2 given in (68). By (65) and (66), the inequalities (74)
ρ
2
) given by ξ1(t) = lN(t), ξ2(t) =
and (75) hold with ξ1(
·
N0, and ς1 = σN, ̺1 = ρN, ς2 = 1
ρD,
1
−
σD. By applying Lemma A.1, we obtain (2) from (76)
̺2 = 1
, ρ2 given in (68). The result for the
and (3) from (77) with ρ
other case (s = 3) is obtained similarly by using Lemma A.1
together with (72).

), ξ2(
·

−

−

∈

2

Proposition 4.2 shows that the networked control system
(54), (61) with communication channels satisfying Assump-
tion 4.2 can be represented by a switched system with a mode
signal that satisﬁes Assumption 2.1. As a result, Theorem 2.4
and the linear programming problems developed in Section III
can be used for the stability analysis.

V. NUMERICAL EXAMPLES

In this section, we illustrate the efﬁcacy of our results by
investigating stability properties of networked control systems
discussed in Sections IV-A and IV-B.

A) Example 1: Consider the system (54) with

A =

1
0.1
0.5 1.1

, B =

.

(73)

0.1
1.2

(cid:20)

(cid:21)

(cid:20)

−

(cid:21)
In [21], we explored stabilization of this system over a network
that faces random and malicious packet losses. There, we
proposed a linear state feedback controller with feedback
gain K =
. By utilizing Theorem
0.9411
3.5 of [21], we see that the closed-loop system is almost
surely asymptotically stable whenever the scalar ρ identiﬁed in
Assumption 4.1 is inside the range [0, 0.411]. In the following
we show that even for strictly larger values of ρ, the closed-
loop system remains almost surely asymptotically stable.

2.9012

−

−

(cid:3)

(cid:2)

For investigating stability of the closed-loop system (54),
(55), we ﬁrst characterize it as a switched system (1) with
two modes represented with A1 = A + BK and A2 = A.
Notice that for this switched system, Assumption 4.1 implies
ρ,
(57), and as a result, Assumption 2.1 holds with ρ
ρ1 = 1, ρ

= 0, and ρ2 = ρ.

= 1

−

1

We numerically solve the linear programming problems (46)
h for different values of ρ and

and (51) to obtain Jh and J ′

2

ρ = 0.7

ρ = 0.5

ρ = 0.3

5

′h
J

0

15

5

−

1

5

10

20

25

30

15
h

Figure 7. Optimal solution value J ′
with respect to h for ρ = 0.3, ρ = 0.5 and ρ = 0.7.

h of the linear programming problem (51)

Figure 9. Transition diagram for {g(t) ∈ S}t∈N0 representing an 8-periodic
jamming attack strategy against the networked control system depicted in
Fig 5. With initial condition g(0) = 1, the delay-free channel is periodically
attacked at times 8t+2, 8t+3, 8t+6, 8t+7, and moreover, the 1-step-delayed
channel is periodically attacked at times 8t + 1, 8t + 2, for t ∈ N0.

k · k1

k · k2

k · k∞

P

k · k

′h
J

2

1

0

1

5

10

15
h

20

25

30

Figure 8. Optimal solution value J ′
with respect to h for ﬁxed ρ = 0.6 and different norms used in (18).

h of the linear programming problem (51)

{

}

∈

≥

[0, 1], q

. For h

1, . . . , 11

h for h =

h. For ﬁnding the coefﬁcients γq and γ′
z of the objective
functions, we use (18) (with the matrix norm induced by the
Euclidean norm and ε = 10−24) and (52). We numerically
conﬁrm that Jh = J ′
12, we
utilize only the linear programming problem (51) and obtain
J ′
h, as solving the problem (46) takes excessively long times.
We see in Fig. 6 that for smaller values of ρ, J ′
h takes negative
values indicating almost sure asymptotic stability. In particular,
we see in Fig. 7 that when ρ = 0.5, we obtain J ′
22 < 0, which
22, that satisfy
implies that (17) holds for all ρq
∈ M
(19), (20). It follows from Theorem 2.4 that if Assumption 4.1
1[¯l(t) = q] exists
holds with ρ = 0.5, and limk→∞
22, then the zero solution of the closed-loop
for each q
P
system is almost surely asymptotically stable. We note again
that for ρ = 0.5, the stability conditions of Theorem 3.5 in
[21] do not hold. This indicates that the stability conditions
obtained in this paper are less conservative than those in [21].
Note that for a given ρ, obtaining a nonnegative value for
Jh = J ′
h does not necessarily imply that the system is unstable.
For the same ρ, the value of J ′
h may be positive for small h and
negative for sufﬁciently large h (see Remark 3.2). For instance,
in this example, J ′
10 takes a negative value for ρ = 0.3, but
not for ρ = 0.5 or ρ = 0.7 (Fig. 7). If one can only compute
J ′
h up to h = 10 due to limited computational power, then
stability for ρ = 0.5 cannot be concluded.

k−1
t=0

∈ M

1
k

∈ M

We also remark that using different matrix norms in the
h, given in (18) results in different
deﬁnition of γq, q
trajectories for J ′
h with matrix
norms
k · k∞ (induced respectively by the 1-
k · k1,
norm, the Euclidean norm, and the inﬁnity norm of vectors),
P induced by the vector norm
as well as the matrix norm
P , √xTP x. Here, we use the positive-deﬁnite matrix P

h. For illustration, we compute J ′
k · k2,

k · k

x
k

k

h obtained with the matrix norm

that we previously utilized in [21] for the Lyapunov-based
stability analysis of this system. Fig. 8 shows the optimal
solution value J ′
h of the linear programming problem (51)
for different values of h when ρ = 0.6. For this example, the
values of J ′
P is clearly
lower than others. We also observe that J ′
P
k·k
30, that
is negative. Thus, (17) holds for all ρq
∈ M
satisfy (19), (20). It then follows from Theorem 2.4 if Assump-
1[¯l(t) = q]
1
tion 4.1 holds with ρ = 0.6, and limk→∞
k
30, then the zero solution of the closed-
exists for each q
loop system is almost surely asymptotically stable. Hence,
for instance, the system is stable under all periodic attack
[0, 0.6], since Proposition 2.5 implies that
scenarios with ρ
∈
1
30, exist in the
the limits limk→∞
k
periodic case.

k · k
30 obtained with
[0, 1], q

1[¯l(t) = q], q

k−1
t=0

k−1
t=0

∈ M

∈ M

P

∈

2

= 1

k · k2 and the bounds ρ

In fact this stability region [0, 0.6] is quite tight, as there
exists a destabilizing attack strategy for ρ = 0.64. This attack
strategy is periodic with a period of 150 time steps. It was
∈ Z30, to the linear
identiﬁed through the solution ρz, z
programming problem (51) solved with h = 30 by using the
ρ, ρ1 = 1,
matrix norm
= 0, ρ2 = ρ, where ρ = 0.64. Under this attack strategy, the
ρ
mode signal of the associated switched system (1) repeats the
same pattern in every 150 time steps. This pattern is composed
30 appearing once and then
of a particular sequence ˜q
30 appearing 4 times. Note that under
another sequence ˆq
this attack strategy, Assumption 4.1 holds with ρ = 0.64,
and furthermore, the monodromy matrix associated with the
closed-loop periodic networked control system possesses an
eigenvalue that is outside the unit circle of the complex plane
indicating divergence of the state.

∈ M

∈ M

−

1

P

B) Example 2: In this example we demonstrate the results
for the networked control setup discussed in Section IV-B.
Speciﬁcally, we consider the plant with A and B given by (73)
in the previous subsection. The control packets are transmitted
to the plant over the delay-free and the 1-step-delayed channels
depicted in Fig. 5. The feedback gains associated with these
channels are given by KN =
and
2.9012
0.3 ]. We note that KN is the gain from the
KD = [
previous subsection, and KD ensures that A2 (of the equivalent
switched system formulation (1) with (64)) is a Schur matrix.
We consider the case where the channels are subject to

0.9411

0.04

−

−

−

−

(cid:2)

(cid:3)

coordinated periodic jamming attacks. In this case,

∈
t∈N0, the failure indicators
0, 1
{
of the delay-free and the one-step-delayed channels, can be

t∈N0 and

lD(t)

lN(t)

∈ {

0, 1

}}

}}

{

{

0
′2
J

4

2

0

2

−

0

16

ρD = 0.3

ρD = 0.2

ρD = 0.1

ρN = 0.6

ρN = 0.5

ρN = 0.4

3

2

1

0

′h
J

0.25

0.5
ρD

0.75

1

1

5

10
h

15

20

Figure 10. Optimal solution value J ′
20 of the linear programming problem
(51) with respect to ρD for the cases ρN = 0.4, ρN = 0.5, and ρN = 0.6.
(We set σD = σN = 0 for all cases.)

Figure 11. Optimal solution value J ′
h of the linear programming problem
(51) with respect to h for the cases ρD = 0.1, ρD = 0.2, and ρD = 0.3.
(We set σD = 0, σN = ρN = 1 for all cases.)

given by

lN(t) =

∈ SN,
1,
g(t)
0, otherwise,

(

lD(t) =

1,
0

(

∈ SD,
g(t)
otherwise,

{

S

g(t)

∈ S}

∈ S N =

∈ S}
S N and
{

S D are subsets of
g(t)

t∈N0 is a ﬁnite-state irreducible and periodic
where
Markov chain with transition probabilities either 0 or 1, and
. Fig. 9 shows the transi-
moreover,
t∈N0 with an 8-periodic pattern. At
tion diagram of
time t, the transmission on the delay-free channel is attacked
; moreover, the transmission on the
if g(t)
3, 4, 7, 8
, and
1-step-delayed channel is attacked if g(t)
∈ SD =
both channels are attacked when g(t) = 3. Note that for any
t∈N0,
attack strategy represented with an irreducible
g(t)
{
S1 ,
S \ SN,
the mode signal given by (63) satisﬁes (34) with
S2 ,
S \ SD), and
it
SN ∩ S D. Hence,
(
N, the limits
follows from Proposition 2.5 that for all h
1[¯r(i) = q], q
h, exist.
limk→∞

S3 ,

SN ∩
1
k

k−1
i=0

∈ S}

2, 3

∈

}

{

{

}

P

To investigate the stability of the networked control system,
we consider different scenarios where the long-run-average
transmission failures on both channels satisfy Assumption 4.2.
Then, Proposition 4.2 implies that the switched system repre-
sentation satisﬁes Assumption 2.1 with ρs, ρs, s
,
given by (67)–(69) as functions of σN, σD, ρN, ρD.

1, 2, 3

∈ {

}

∈ M

We ﬁrst consider the case where the information about the
average number of failures on delay-free and 1-step-delayed
channels is limited. In particular, we set the lower-bounds on
the long-run average number of failures on both channels to
0, that is, σN = σD = 0. Our goal is to identify upper-bounds
on the long-run average number of failures of the channels
(ρN and ρD) for which the closed-loop networked control
system is stable. To this end, we solve the linear programming
problem (51) for different values of ρN and ρD. For ﬁnding
the coefﬁcients γ′
h, of the objective
function, we use (18) (with the matrix norm induced by the
Euclidean norm and ε = 10−24).

z = maxq∈Mh,z γq, z

∈ Z

Fig. 10 shows how the optimal objective function J ′

20 of the
linear programming problem (51) changes with respect to ρD
for the values ρN = 0.4, ρN = 0.5, and ρN = 0.6. Observe that
when the long-run average number of failures on the delay-free
communication channel is sufﬁciently small, stability can be
achieved regardless of the amount of transmission failures on
the 1-step-delayed channel. This is seen in Fig. 10 for the case
ρN = 0.4. Speciﬁcally, we have J ′
20 < 0, which implies that

∈

∈ M

[0, 1], q

20, that satisfy (19), (20).
(17) holds for all ρq
Hence, the stability can be concluded by Theorem 2.4 for all
[0, 1]. On the other hand, when the delay-free channel
ρD ∈
faces more failures, the transmissions on the 1-step-delayed
channel become more important. In particular for ρN = 0.5
and ρN = 0.6, the value of J ′
20 is negative and the stability
can be concluded only for sufﬁciently small values of ρD.

Next, we consider the situation where the delay-free channel
is known to be completely blocked due to jamming attacks at
each time instant. To explore this case, we set σN = ρN = 1.
In this setup, all control packets are to be transmitted over the
1-step-delayed channel. We would like to ﬁnd out the long-
run average number of failures that can be tolerated on this
channel. For this purpose, we solve the linear programming
problem (51) to obtain J ′
h with respect to h for three different
cases: ρD = 0.1, ρD = 0.2, and ρD = 0.3. In all cases we
set σD = 0. Fig. 11 shows J ′
h for different values of ρD.
We observe that J ′
14 < 0 when ρD = 0.1, implying that (17)
14, that satisfy (19), (20).
holds for all ρq
∈ M
Hence, by Theorem 2.4 the zero solution of the closed-loop
system is almost surely asymptotically stable if the ratio of the
transmission failures on the 1-step-delayed channel is bounded
by 0.1 in the long-run. On the other hand, for ρD = 0.2 and
ρD = 0.3, we cannot guarantee stability, since we have J ′
h >
0, h

1, . . . , 20

[0, 1], q

∈

.

∈ {

}

C) Example 3: Consider the system (54), (55) with

A =

0
1
a1 a2 (cid:21)

(cid:20)

, B =

0
1

(cid:20)

(cid:21)

, K =

a1 −

−

a2

(cid:2)

,

(cid:3)

0, 1

l(t)

where a1 = 2, a2 = 1. Suppose that the failure indicator
t∈N0 satisﬁes Assumption 4.1, where ρ
process
denotes the probabilistic bound on the average ratio of failures.
This networked control system can be written as a switched
system (1) with

∈ {

}}

{

A1 = A + BK =

0 1
0 0

(cid:21)

(cid:20)

, A2 = A =

0
2

1
1

.

(cid:21)

(cid:20)

, 1, ρ

Following the formulation in Section IV-A, let ρ
−
, ρ. It follows from (57) that
ρ, ρ1
Assumption 2.1 is satisﬁed. Our goal is to check the stability
of this system by using Theorem 2.4. To this end we utilize

, 0, and ρ2

2

1

, 1

the linear programming problem (46). Notice that for this
example, with h = 2, we have

Γ(1,1) = A2

1 = 0

≥

≥

in (7). Hence, γ(1,1), in (18) depends on the particular value
selected for ε. With the matrix norm induced by the Euclidean
norm and ε = 10−24, we solve the linear programming
problem (46) and obtain J2 > 0 for every ρ
0.5. For
instance, we have J2 = 0.8047 for ρ = 0.5, J2 = 0.9328
for ρ = 0.6, and J2 = 1.0609 for ρ = 0.7. Notice that when
0.5, either one of the switching sequences 2, 1, 2, 1, . . .
ρ
or 1, 2, 1, 2, . . . are allowed. These sequences destabilize the
system. As a result J2 cannot be negative when ρ
0.5.
In particular, when ρ = 0.5, an optimal solution is given by
= (2, 1), which corresponds
ρ(2,1) = 1.0 and ρq = 0 for q
to the switching sequence 2, 1, 2, 1, . . .. Notice that when
ρ > 0.5, there are also other destabilizing sequences where
the unstable mode (with subsystem matrix A2) runs most of
the time.

≥

On the other hand, for ρ < 0.5, J2 can be obtained negative,
since in all optimal solutions, we have ρ(1,1) > 0. Notice
that the sequence (1, 1) indicates the pattern where the stable
mode (with subsystem matrix A1) is active at consecutive time
instants. For example, when ρ = 0.48, with ε = 10−16, we
obtain J2 =
0.7011, indicating stability. Notice that when
ρ = 0.49, with ε = 10−16, we obtain a positive J2 value,
but by picking a smaller ε = 10−24, we get J2 =
0.3166
indicating stability.

−

−

VI. CONCLUSION

∈

We explored almost sure asymptotic stability of a stochas-
tic switched linear system. Our proposed stability analysis
approach relies on studying the switched system’s state at
N steps. We obtained sufﬁcient stability conditions
every h
and showed that the stability can be checked by solving a
linear programming problem. The number of variables in this
problem grows polynomially in the number of subsystems,
but exponentially in h, which makes the computation difﬁcult
when h is large. To overcome this issue, we constructed an
alternative linear programming problem, where the number of
variables grows polynomially in both the number of subsys-
tems and h. Even though the calculation of the coefﬁcients in
the alternative problem takes additional time, the solution is
obtained faster compared to the original problem.

Our linear programming-based analysis approach allows us
to check stability without relying on statistical information on
the mode signal. In particular, the probability of mode switches
and the stationary distributions associated with the modes are
not needed for stability analysis. We applied our approach in
exploring networked control systems under malicious jamming
attacks. The technical challenge there is that the attackers’
speciﬁc strategies are not available for analysis. By using our
approach, we showed that stability can be guaranteed under all
possible attack strategies when the long-run average number
of network transmission failures satisﬁes certain conditions.
In practice, our approach can be used by system operators
to assess the safety of industrial processes. Speciﬁcally, our

17

stability results can be utilized in identifying the level of
jamming attacks that can be tolerated on the communication
channels used for the measurement and the control of a plant.
Investigations of the case with noisy dynamics and the
stabilization problem are part of our future extensions. In
the stabilization problem, the controller may not have access
to precise information of the active mode. In those cases,
the system modes are divided into several groups, and the
controller only knows which group contains the currently
active mode. This problem was considered for discrete- and
continuous-time Markov jump systems by [56], [57]. For this
problem setting, our approaches may be extended for the case
where the mode signal is not necessarily a Markov process.

REFERENCES

[1] D. Liberzon and A. S. Morse, “Basic problems in stability and design of
switched systems,” IEEE Control Syst., vol. 19, no. 5, pp. 59–70, 1999.
[2] H. Lin and P. J. Antsaklis, “Stability and stabilizability of switched
linear systems: A survey of recent results,” IEEE Trans. Autom. Control,
vol. 54, no. 2, pp. 308–322, 2009.

[3] D. Liberzon, J. P. Hespanha, and A. S. Morse, “Stability of switched
systems: A Lie-algebraic condition,” Syst. Control Lett., vol. 37, no. 3,
pp. 117–122, 1999.

[4] J. Daafouz, P. Riedinger, and C. Iung, “Stability analysis and control syn-
thesis for switched systems: A switched Lyapunov function approach,”
IEEE Trans. Autom. Control, vol. 47, no. 11, pp. 1883–1887, 2002.

[5] D. Liberzon, Switching in Systems and Control. Birkhauser, 2003.
[6] J. P. Hespanha and A. S. Morse, “Stability of switched systems with
average dwell-time,” in Proc. IEEE Conf. Dec. Contr., pp. 2655–2660,
1999.

[7] G. Zhai, H. Guisheng, B. Hu, K. Yasuda, and A. N. Michel, “Stability
analysis of switched systems with stable and unstable subsystems: An
average dwell time approach,” Int. J. Syst. Sci., vol. 32, no. 8, pp. 1055–
1061, 2001.

[8] H. Zhang, D. Xie, H. Zhang, and G. Wang, “Stability analysis for
discrete-time switched systems with unstable subsystems by a mode-
dependent average dwell time approach,” ISA Trans., vol. 53, no. 4,
pp. 1081–1086, 2014.

[9] H. Ishii, T. Basar, and R. Tempo, “Randomized algorithms for synthesis
of switching rules for multimodal systems,” IEEE Trans. Autom. Control,
vol. 50, no. 6, pp. 754–767, 2005.

[10] A. R. Teel, A. Subbaraman, and A. Sferlazza, “Stability analysis for
stochastic hybrid systems: A survey,” Automatica, vol. 50, no. 10,
pp. 2435–2456, 2014.

[11] P. Shi and F. Li, “A survey on Markovian jump systems: Modeling and

design,” Int. J. Control Autom. Syst., vol. 13, no. 1, pp. 1–16, 2015.

[12] Y. Fang, K. Loparo, and X. Feng, “Stability of discrete time jump linear
systems,” J. Math. Systems Estim. Control, vol. 5, no. 3, pp. 275–321,
1995.

[13] O. L. V. Costa, M. D. Fragoso, and R. P. Marques, Discrete-Time Markov

Jump Linear Systems. Springer, 2004.

[14] W. Zhou, Q. Zhu, P. Shi, H. Su, J. Fang, and L. Zhou, “Adaptive synchro-
nization for neutral-type neural networks with stochastic perturbation
and Markovian switching parameters,” IEEE Trans. Cybern., vol. 44,
no. 12, pp. 2848–2860, 2014.

[15] Q. Zhu, “Razumikhin-type theorem for stochastic functional differential
equations with Lévy noise and Markov switching,” Int. J. Control,
vol. 90, no. 8, pp. 1703–1712, 2017.

[16] B. Wang and Q. Zhu, “Stability analysis of Markov switched stochastic
differential equations with both stable and unstable subsystems,” Syst.
Control Lettr., vol. 105, pp. 55–61, 2017.

[17] P. Bolzern, P. Colaneri, and G. De Nicolao, “Markov jump linear systems
with switching transition rates: Mean square stability with dwell-time,”
Automatica, vol. 46, no. 6, pp. 1081–1088, 2010.

[18] P. Bolzern, P. Colaneri, and G. De Nicolao, “Design of stabilizing
strategies for discrete-time dual switching linear systems,” Automatica,
vol. 69, pp. 93–100, 2016.

[19] H. Shisheh Foroush and S. Martínez, “On single-input controllable linear
systems under periodic DoS jamming attacks,” in Proc. SIAM Conf.
Contr. Appl., 2013.

6
[20] C. De Persis and P. Tesi, “Input-to-state stabilizing control under denial-
of-service,” IEEE Trans. Autom. Control, vol. 60, no. 11, pp. 2930–2944,
2015.

[45] P. Sadeghi, R. A. Kennedy, P. B. Rapajic, and R. Shams, “Finite-state
Markov modeling of fading channels,” IEEE Signal Process. Mag.,
vol. 25, no. 5, pp. 57–80, 2008.

18

[21] A. Cetinkaya, H. Ishii, and T. Hayakawa, “Networked control under
losses,” IEEE Trans. Autom. Control,

random and malicious packet
vol. 62, no. 5, pp. 2434–2449, 2017.

[22] W. Xu, W. Trappe, Y. Zhang, and T. Wood, “The feasibility of launching
and detecting jamming attacks in wireless networks,” in Proc. 6th ACM
Int. Symp. Mobile Ad Hoc Network. Comput., pp. 46–57, 2005.
[23] S. Amin, A. A. Cárdenas, and S. S. Sastry, “Safe and secure networked
control systems under Denial-of-Service attacks,” in Proc. 12th HSCC,
pp. 31–45, 2009.

[24] K. Pelechrinis, M. Iliofotou, and S. V. Krishnamurty, “Denial of service
attacks in wireless networks: The case of jammers,” IEEE Commun.
Surveys Tuts., vol. 13, no. 2, pp. 245–257, 2011.

[25] A. T. Mizrak, S. Savage, and K. Marzullo, “Detecting malicious packet
losses,” IEEE Trans. Parallel Distrib. Syst., vol. 20, no. 2, pp. 191–206,
2009.

[26] T. Shu and M. Krunz, “Privacy-preserving and truthful detection of
packet dropping attacks in wireless ad hoc networks,” IEEE Trans.
Mobile Computing, vol. 14, no. 4, pp. 813–828, 2015.

[27] A. Cetinkaya, H. Ishii, and T. Hayakawa, “Event-triggered control over
unreliable networks subject to jamming attacks,” in Proc. IEEE Conf.
Dec. Contr., pp. 4818–4823, 2015.

[28] A. Cetinkaya, H. Ishii, and T. Hayakawa, “Event-triggered output
feedback control resilient against jamming attacks and random packet
losses,” in Proc. IFAC NecSys, pp. 270–275, 2015.

[29] A. Cetinkaya, H. Ishii, and T. Hayakawa, “Random and malicious
packet transmission failures on multi-hop channels in networked control
systems,” in Proc. IFAC NecSys, pp. 49–54, 2016.

[30] A. Cetinkaya, H. Ishii, and T. Hayakawa, “Wireless control under
jamming attacks with bounded average interference power,” in Proc.
IFAC World Cong., pp. 8735–8740, 2017. Also, to appear, SIAM J.
Control Optim., 2018.

[31] J. P. Hespanha, P. Naghshtabrizi, and Y. Xu, “A survey of recent results
in networked control systems,” Proc. IEEE, vol. 95, no. 1, pp. 138–172,
2007.

[32] H. Ishii, “Limitations in remote stabilization over unreliable channels
without acknowledgements,” Automatica, vol. 45, no. 10, pp. 2278–
2285, 2009.

[33] L. Xie and L. Xie, “Stability analysis of networked sampled-data linear
systems with Markovian packet losses,” IEEE Trans. Autom. Control,
vol. 54, no. 6, pp. 1375–1381, 2009.

[34] K. Okano and H. Ishii, “Stabilization of uncertain systems with ﬁnite
data rates and Markovian packet losses,” IEEE Trans. Control Netw.
Syst., vol. 1, no. 4, pp. 298–307, 2014.

{

[46] M. Ellis, D. P. Pezaros, T. Kypraios, and C. Perkins, “A two-level
Markov model for packet loss in UDP/IP-based real-time video ap-
plications targeting residential users,” Comput. Netw., vol. 70, no. 9,
pp. 384–399, 2014.

[47] A. Cetinkaya, H. Ishii, and T. Hayakawa, “Enhanced stability analysis
for networked control systems under random and malicious packet
losses,” in Proc. IEEE Conf. Dec. Contr., pp. 2721–2726, 2016.
[48] A. Hassibi, S. P. Boyd, and J. P. How, “Control of asynchronous
dynamical systems with rate constraints on events,” in Proc. IEEE Conf.
Dec. Contr., pp. 1345–1351, 1999.

[49] W. Zhang, M. S. Branicky, and S. M. Phillips, “Stability of networked
control systems,” IEEE Contr. Syst. Mag., vol. 21, no. 1, pp. 84–99,
2001.

[50] J. Norris, Markov Chains. Cambridge University Press, 2009.
[51] R. A. Horn and C. R. Johnson, Matrix Analysis. Cambridge University

Press, 1985.

[52] A. Karr, Probability. Springer, 1993.
[53] J. S. Rosenthal, A First Look at Rigorous Probability Theory. World

Scientiﬁc Publishing, 2011.

[54] M. Vidyasagar, Hidden Markov Processes: Theory and Applications to

Biology. Princeton University Press, 2014.

[55] B. Korte and J. Vygen, Combinatorial Optimization. Springer, 2012.
[56] J. B. Do Val, J. C. Geromel, and A. P. C. Gonçalves, “The H2-control
for jump linear systems: cluster observations of the Markov state,”
Automatica, vol. 38, no. 2, pp. 343–349, 2002.

[57] D. Li, D. Zhang, and H. Ji, “Stabilization of jump linear systems with
partial observation of Markov mode,” Int. J. Pure Appl. Math., vol. 27,
pp. 31–38, 2006.

APPENDIX

The following result provides lower- and upper-bounds for
the long-run average of the product of two binary-valued
processes.

Lemma A.1: For all binary-valued processes
t∈N0 that satisfy
0, 1

t∈N0 and

ξ2(t)

0, 1

}}

{

∈ {

}}

ξ1(t)

{

∈

[35] A. Polanski, “Lyapunov function construction by linear programming,”
IEEE Trans. Autom. Control, vol. 42, no. 7, pp. 1013–1016, 1997.
[36] X. Liu, “Stability analysis of switched positive systems: A switched
linear copositive Lyapunov function method,” IEEE Trans. Circuits Syst.
II, Exp. Briefs., vol. 56, no. 5, pp. 414–418, 2009.

[37] R. Baier, L. Grüne, and S. Hafstein, “Linear programming based
inclusions,” Discrete

Lyapunov function computation for differential
Contin. Dyn. Syst. Ser. B, vol. 17, no. 1, pp. 33–56, 2012.

[38] S. Zhu, Q.-L. Han, and C. Zhang, “l1-gain performance analysis and
positive ﬁlter design for positive discrete-time Markov jump linear
systems: A linear programming approach,” Automatica, vol. 50, no. 8,
pp. 2098–2107, 2014.

[39] P. Bolzern, P. Colaneri, and G. De Nicolao, “On almost sure stability of
discrete-time Markov jump linear systems,” in Proc. IEEE Conf. Dec.
Contr, pp. 3204–3208, 2004.

[40] Y. Huang, J. Luo, T. Huang, and M. Xiao, “The set of stable switching
sequences for discrete-time linear switched systems,” J. Math. Anal.
Appl., vol. 377, no. 2, pp. 732–743, 2011.

[41] J.-W. Lee and G. E. Dullerud, “Uniform stabilization of discrete-time
switched and Markovian jump linear systems,” Automatica, vol. 42,
no. 2, pp. 205–218, 2006.

[42] M. Philippe, R. Essick, G. E. Dullerud, and R. M. Jungers, “Stability of
discrete-time switching systems with constrained switching sequences,”
Automatica, vol. 72, pp. 242–250, 2016.

[43] B. C. Levy and M. Zorzi, “A contraction analysis of the convergence of
risk-sensitive ﬁlters,” SIAM J. Control Optim., vol. 54, no. 4, pp. 2154–
2173, 2016.

[44] M. Zorzi and B. C. Levy, “On the convergence of a risk sensitive like

ﬁlter,” in Proc. IEEE Conf. Dec. Contr., pp. 4990–4995, 2015.

k−1

ξi(t)

ςi,

≥

lim inf
k→∞

1
k

lim sup
k→∞

1
k

t=0
X
k−1

t=0
X

ξi(t)

̺i,

≤

i

1, 2

,

}

∈ {

almost surely with ςi, ̺i

[0, 1], i

1, 2

}

∈ {

∈

, we have

lim inf
k→∞

lim sup
k→∞

1
k

1
k

k−1

t=0
X
k−1

t=0
X

ξ1(t)ξ2(t)

max
{

0, ς1 + ς2 −

1

,

}

≥

ξ1(t)ξ2(t)

min
{

̺1, ̺2}

,

≤

almost surely.

Proof: To show (76), ﬁrst note that

(74)

(75)

(76)

(77)

lim inf
k→∞

1
k

k−1

t=0
X

ξ1(t)ξ2(t) = 1

lim sup
k→∞

−

1
k

k−1

t=0
X

(1

−

ξ1(t)ξ2(t)) .

(78)

, i

= j, we have

19

For all i, j

1, 2

}
k−1

∈ {
1
k

lim sup
k→∞

(1

ξ1(t)ξ2(t))

−

t=0
X
1
k

= lim sup

k→∞

lim sup
k→∞

≤

1
k

+ lim sup

k→∞

k−1

t=0
X
k−1

k−1

t=0
X
1
k

(ξi(t)(1

(ξi(t)(1

−

−

ξj(t)) + (1

ξi(t)))

−

ξj(t)))

(1

ξi(t)) .

(79)

−

t=0
X
ξi(t) and ξi(t)(1

Since ξi(t)(1
by (75), we have

−

ξj(t))

≤

ξj(t))

1

−

≤

ξj(t),

−

(ξi(t)(1

ξj(t)))

lim sup
k→∞

≤

−

and by (74), we have

lim sup
k→∞

1
k

k−1

t=0
X

lim sup
k→∞

1
k

k−1

t=0
X

(ξi(t)(1

ξj(t)))

lim sup
k→∞

≤

−

= 1

lim inf
k→∞

−

Therefore,

1
k

k−1

t=0
X

ξj(t)

1

−

≤

ςj.

1
k

1
k

k−1

t=0
X

k−1

t=0
X

ξi(t)

̺i,

≤

(1

−

ξj (t))

lim sup
k→∞

1
k

k−1

(ξi(t)(1

t=0
X
Furthermore, since lim supk→∞
it follows from (78)–(80) that

ξj(t)))

min
{

≤

̺i, 1

ςj

.

}

−

(80)

−

1
k

k−1
t=0 (1

ξi(t))

ςi,

1

−

≤

−

P

lim inf
k→∞

1
k

k−1

ξ1(t)ξ2(t)

t=0
X
min
{

̺i, 1

= ςi

−
Now, noting that
lim inf k→∞
(76) from (81).

1
k

P

1

−

≥

(min

̺i, 1

ςj

}

−

+ 1

−

ςi)

{

ςj

}

= max

ςi

{

−
ςi

̺i
−
k−1
t=0 ξ1(t)ξ2(t)

≤
≥

−
0,

̺i, ςi + ςj

1

.

(81)

−
}
1, 2

i

, and
∈ {
0, almost surely, we have

}

Next, we prove (77). Since ξ1(t)ξ2(t)

ξ1(t)ξ2(t)

≤

ξ2(t), we obtain

lim sup
k→∞

1
k

k−1

ξ1(t)ξ2(t)

lim sup
k→∞

1
k

≤

t=0
X
It
.
for
1, 2
i
}
∈
k−1
t=0 ξ1(t)ξ2(t)
lim supk→∞
surely, which then implies (77).
P

1
k

{

then follows
̺i, i

≤

ξ1(t) and

≤

k−1

ξi(t),

(82)

t=0
X

from (75)
1, 2

that
, almost

∈ {

}

6
