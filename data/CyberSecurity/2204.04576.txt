Adaptable Plug and Play Security Operations Center Leveraging a 
Novel Programmable Plugin-based Intrusion Detection and Prevention 
System 

Ahmed S. Shatnawia,*,1,  Basheer Al-Duwairib,2,  Mahmoud M. Almazarib,3,  Mohammad 
S. Alshakhatrehb,4,  Ahmad N. Khaderb,5 and  Abdullah A. Abdullahb,6

aDepartment of Software Engineering & Security, Jordan University of Science & Technology, Irbid, Jordan 
bDepartment of Network Engineering, Jordan University of Science & Technology, Irbid, Jordan 

A R T I C L E  I N F O 

Keywords: 
Security Operations Center 
cyber security 
Threat Mitigation 
Attack Detection 
Automation 

A B S T R A C T 

The number of cyber-attacks have substantially increased over the past decade resulting in huge orga- 
nizational financial losses. Indeed, it is no longer a matter of “if” but “when” a security incident will 
take  place. A  Security  Operations  Center(SOC)  adoption  will  help  in  the  detection,  identification, 
prevention, and resolution of issues before they end up causing extensive cyber-related damage.  In 
this paper, our proposed framework is brought about to address the problem that current open-source 
SOC implementations are plagued with.  These include lack of ability to be strengthened on the fly, 
slow development processes, and their ineptness for continuous timely updates.  We, herein, propose 
a framework that would offer a fully automated open-source SOC deployment; otherwise dubbed, a 
“plug-and-play framework”;  full horizontal scalability incorporating a modular architecture.  These 
underpinning features are meant to mitigate underlying SOC challenges, which often emerge as a re- 
sult of many pre-determined and repeated processes, bolstering their ability for expansion with new 
tools.  This is on top of enhancing their ability to handle more servers in the clusters as a single log- 
ical unit.  We also introduce a new system of its kind called a Programmable Plugin-based Intrusion 
Detection and Prevention System (PPIDPS). This system will extend a SOC’s ability to add any tool 
to the monitored devices while collecting logs that can trigger alerts whenever a suspicious behavior 
is detected. 

1.  Introduction 

The number of security-threatening attacks has increased 
substantially  in  recent  years;  the  expense  of  these  attacks 
on  companies  has  increased  drastically  [12].  Every  orga- 
nization needs improvements in security incident detection 
and prevention through continuous monitoring, data analy- 
sis,  and  oversight  of  network  activities.  Such  security  im- 
provements  can  be  achieved  leveraging  a  very  well  struc- 
tured methodology renowned as a SOC center; a robust de- 
fensive  strategy  recognized  throughout  the  field  of  Cyber- 
security.  Recently,  attacks  including  Advanced  Persistent 
Threats (APT) that simultaneously utilize a varied range of 
attack vectors and patterns have surfaced [14].  Thus, their 
detection by point solutions is almost an unachievable task; 
these kinds of attacks are well organized, directed, financed, 
silent,  unexpected,  and  very  patient. Indeed,  it  is  not  any- 
more a matter of “if” but “when” a security incident will take 
place.  Recent events are manifested in the massive breach 
that took place in the U.S during late 2020, where many firms 
including the US Departments of Treasury and of homeland 
security, state and defense are known to have been targeted. 
Around 58 percent of the healthcare sector in many coun- 
tries experienced one form or another of a cyber-attack last 

*Ahmed S. Shatnawi 

 ahmedshatnawi@just.edu.jo (A.S.  Shatnawi);  basheer@just.edu.jo 

(B. Al-Duwairi); mahmoudmalmazari@gmail.com (M.M. Almazari); 
hmodaa.sha@hotmail.com (M.S.  Alshakhatreh);  mahmoudmalmazari@gmail.com 
(A.N. Khader); abdullahanashaj@gmail.com (A.A. Abdullah) 

ORCID(s): 

year [39]. 

To deal with such situations, government agencies and 
industries can get empowered by readily installable and eas- 
ily  manageable  SOCs  adaptable  to  various  organizational 
budgets.  What  currently  exists  on  the  market  to  help  mit- 
igate such cyber-crimes and help companies and organiza- 
tions monitor and manage all aspects of their security con- 
cerns in real-time, either in the form of commercial products, 
i.e., SOC (Security Operations Center) usually costing them 
a fortune, or open source products that would burden the IT 
people handling these open source products. It is, therefore, 
fairly easy for SOC managers to get caught up by the false 
positive alerts, and be overwhelmed with the bombardment 
of buzzing configuration errors.  In all, these considerations 
will lead to scenarios in which SOC administrators and other 
security concerned leaders would lose perspective on what 
actually matters, including knowledge of their risk profiles, 
taking the proper procedures in the face of threats, and build- 
ing up systems and mechanisms to  resolve severe security 
problems. 

Machines are excellent at quickly performing redundant 
and laborious tasks, as manual human interactions commonly 
incur devastating consequences commensurate with the er- 
rors that can come about in the process. Consequently, such 
tasks should not be performed by the security analysts them- 
selves. Automating the inner workings of low hanging fruit 
spontaneously allows security experts to focus more on context- 
essential tasks.  Automation of a SOC ensures that both the 
acting staff and computing needs can be appropriately stream- 

A. Shatnawi et al.:  Preprint submitted to Elsevier 

Page 1 of 21

 
 
 
 
 
 
 
 
 
 
Adaptable Plug and Play SOC

lined. Firmly aligned, the personnel and tools will do better 
and keep frequently encountered critical mistakes to a mini- 
mum. This may just be the absent piece in the whole puzzle 
that enables a SOC to be more proactive. 

Furthermore, the proposed SOC architecture is one that 
would offer adaptability. Towards that end, different institu- 
tions have different requirements, risk profiles, departments, 
technologies,  and  budgets,  all  of  which  are  essential  con- 
siderations  when  designing  a  SOC  architecture.  Hence,  a 
full-fledged assessment with reports from the organizational 
security  experts  regarding  the  risk  profiles  must  be  made. 
This will eventually allow the SOC to handle any risk and 
implement any countermeasures in the face of any threat to 
the SOC system.  A method has yet to be found that makes 
network engineers and system administrators more capable 
of updating their intrusion detection techniques to mitigate 
the  more  progressively  persistent  attacks  that  may  rely  on 
zero-day vulnerabilities.  Therefore, we propose a technique 
to  enable  any kind  of  code  to  be  executed  and gather  any 
type of information to log them into the SOC center to en- 
hance the intrusion detection or attack prevention methods. 
The technique can more incessantly monitor the end devices 
to detect anomalous behaviors and offer an intrusion preven- 
tion mechanism in due time. In this manner, our objective is 
to add some level of automation to the SOC, releasing some 
essential time to be invested more efficiently to securing the 
system. 

This paper addresses a robust implementation of a fully 
automated  SOC  deployment,  offering  adaptability  in  han- 
dling the diversity of risk profiles of different organizations. 
Moreover, the proposed framework adds new security func- 
tionality to existing Open-Source Security Information and 
Event  Management  (SIEM)  implementations.  This,  inher- 
ently will allow SOC managers to feel more confident about 
having a better leverage in securing the devices their teams 
are constantly monitoring. 

The main contributions of this paper are as follows: 

1.  A new dynamic architecture framework that allows a 
security operations center’s deployment on the fly, en- 
abling horizontal scalability and expanding the secu- 
rity operations center toolchain. 

2.  A novel security operations center subsystem to adapt 

to different risk profiles and threats. 

3.  A new, a one-of-a-kind, framework that enables threat 
mitigation  and  collaboration between  different  secu- 
rity researchers and SOC teams around the globe by 
seamless SOC integration through a business commu- 
nication platform. 

This  paper  is  organized  as  follows.  In  Section  2,  we 
present background information and survey earlier research 
around the topic.  Section 3 elaborates the analysis and de- 
sign  of  the  proposed  solution. Section  4  reveals  details  of 
the proposed framework implementation;  In Section 5, we 
discuss our testing criteria and evaluation. Finally, section 6 
wraps up the main discussion and summarizes the contribu- 
tions of our research endeavor. 

2.  Background and Related Work 

In this  section,  we  harness essential  background  infor- 
mation together with relevant research that holds some sig- 
nificance towards understanding the issues addressed in this 
paper. 

A Security Operations Center (SOC) is neither a prede- 
fined  entity  nor  a  particular  technological  system  that  can 
be deployed to defend against specific security threats.  In- 
stead, a SOC is a static organizational structure underpinned 
by technological solutions to manage and enhance an orga- 
nization’s  overall  security  posture. In  the  proposed  frame- 
work, we plan to introduce and build adaptive SOC architec- 
ture irrespective of the organization’s particular needs or to 
counter any potential threats.  Adaptive SOC solutions will 
inherently address and tackle the multitude of varying orga- 
nizational profiles [1]. 

A  SIEM  is  a  bundle  of  complex  technologies  that,  to- 
gether,  can  provide  a  comprehensive  security  layer  in  to- 
day’s  threat  environment.  Thus,  the  role  of  a  SIEM  com- 
ponent of a SOC cannot be overemphasized, and, as such, it 
must be carefully chosen. A modern open-source SIEM like 
Wazuh [15] has a centralized cross-platform architecture that 
allows it to control, handle and detect intrusions, threats, and 
behavioral anomalies on multiple platforms.  Wazuh started 
as  a  fork  of  an  OSSEC  HIDS  [40],  adding  more  reliabil- 
ity and scalability  to the project and providing an integra- 
tion  with  the  Elastic  Stack  as  a  log  management  solution 
and a RESTful API for easier task configuration and admin- 
istration.  Wazuh  has  two  components:  the  Wazuh  server 
component, which integrates closely with Elasticsearch and 
Kibana, while the Wazuh agent is capable of many security- 
related tasks such as log analysis, rootkit detection, listening 
port detection, and file integrity monitoring. For this project, 
we will utilize these capabilities to trigger alerts. 

Furthermore,  Wazuh  provides  the  following  mappings 

against regulatory compliance requirements: 

•  Payment Card Industry Data Security Standard (PCI 

DSS). 

•  NIST Special Publication 800-53 (NIST 800-53). 
•  General Data Protection Regulation (GDPR). 
•  Good Practice Guide 13 (GPG13). 
•  Health Insurance Portability and Accountability Act 

(HIPAA). 

•  Trust Services Criteria (TSC SOC2). 

Although there is considerable amount of literature avail- 
able to provide guidance on SOC implementation guidelines, 
there  is  little  mention  of  any  SOC  automation  for  enabling 
horizontal scalability, expanding the security operations cen- 
ter toolchain, and supporting different risk profiles and threats. 
The  SIEM  log  management  solution,  and  the  systems 
adopted  in  our  proposed  framework  abide  by  and  readily 
comply with the guidelines and requirements in the resources 
as described below. This offers an excellent resource for de- 
veloping SOC requirements: 

A. Shatnawi et al.:  Preprint submitted to Elsevier 

Page 2 of 21

 
 
 
Adaptable Plug and Play SOC

•  NIST Special Publication (SP) 800-92, Guide to Com- 
puter Security Log Management: provides guidelines 
on developing procedures for business logging and au- 
diting [19]. 

•  NIST Special Draft Publication (SP) 800-94 Revision 
1,  Guide to Intrusion Detection and Prevention Sys- 
tems: recommendations are provided to plan, incorpo- 
rate, configure, protect, track and manage IDPS tech- 
nologies [35]. 

•  NIST Special Publication (SP) 800-83 Revision 1, 

Guide to Malware Incident Prevention and Handling 
for Desktops and Laptops: provides recommendations 
for enhancing the security mechanisms of malware pre- 
vention by an organization and provides recommenda- 
tions for improving the current incident management 
and response capabilities of an organization [38]. 

•  NIST Special Publication (SP) 800-61 Revision 2, 

Computer Security Incident Handling Guide: provides 
guidelines to help companies build information secu- 
rity incident management, handling and response ca- 
pabilities to resolve incidents quickly and effectively [29]. 

Slack [37], as a channel-based messaging platform, has 
been determined as one robust candidate to incorporate into 
our proposed framework.  The primary value proposition of 
Slack is a tool for communications. This offers a communi- 
cation mechanism that directly promotes workplace commu- 
nication.  It is evident, as a working piece of software, that 
Slack executes these roles incredibly well. As a result, Slack 
was well-positioned to address the surging demand on this 
requirement rather more effectively as offshore development 
teams in startups and working from home policies started to 
surface. Slack  allows  creating  special  channels  for  private 
communication between groups. These private channels can 
readily be used to organize big teams.  Slack allows groups 
or teams to join a Workspace – a group of related channels 
via a URL or invitation issued by a team administrator. 

Further, Slack offers users an application programming 
interface (API) to add apps and automate operations, such as 
sending automatic notifications based on human input and 
sending  messages  when  a  specific  condition  is  met.  The 
Slack API is one that offers great compatibility with vari- 
ous kinds of programs,  platforms,  and utilities. In  our on- 
going research endeavor we have sought to use Slack as a 
ticketing system for our SOC deployment.  Further, our so- 
lution will automatically send any imminent alerts directly 
to Slack, where the SOC analysts can further investigate the 
nature of an alert and establish a ticket when necessary. 

Ticket opening works by adding the Halp [11] which is 
a modern ticketing help desk to a Slack channel.  The peo- 
ple of pertinence or the resident engineers at the customer 
organization are added to the channel, where they can view 
the open tickets and respond to the analysts during the time 
an issue is being addressed. In the sequel we leverage well- 
established results in certain pieces of the literature with the 
objective of better understanding SOCs, proposing suitable 
SOC frameworks, and assessing their immediate challenges. 

In [6],  the  authors  interview  security  analysts,  in order 
to  identify  the  technological  and  organizational  limitations 
inside the SOC center.  They propose a new workflow that 
ensures  effective  collaboration  between  the  tiers  in  a  SOC 
and the associated security incident correlations.In [17], the 
authors review existing, industry-accepted maturity models 
wherein  the  proposed  SOC  classification  model  complies 
with  this  approach.  In  [36],  the  authors  define  their  SOC 
and demonstrate a method for assessment of any SOC, where 
they suggest a SOC framework commensurate with their con- 
jecture.  In [7],  the author presents the initial model as de- 
veloped  by  the  WLCG  SOC  Working  Group,  for  a  mini- 
mally  viable  SOC,  where  he  starts  out  with  the  design  of 
different  stages,  elaborating  upon  the  individual  stages  in- 
volved.  In  [3,  4],  SOC  experts  have  evaluated  the  use  of 
Sonification as a form of human-computer interaction to im- 
prove upon the findings of the SOC research communities in 
anomaly detection, monitoring, and alerts discovery.  In [2], 
the authors have noted the necessity regarding the existence 
of  a  SOC  at  educational  institutions,  by  proposing  threat- 
addressing courses, with current security tools in use, while 
proposing their own SOC model. 

In [23], the authors propose a SOC architecture, together 
with its mission and key roles that act as the appropriate in- 
cident response mechanisms to recognize incidents of infor- 
mation security, resolve potential vulnerabilities, and restore 
compromised Internet of Things infrastructures. In [20], sev- 
eral methods of data retrieval are proposed to enable a data 
triage by retrieving the security analysts’ pertinent historical 
data triage of operations involved.  In [22] the authors con- 
duct an  interview that  deliberate  what organizations  ought 
to do to reap full benefits from their investments in SOCs, 
where  it  further  addresses  the  common  mistakes  security 
personnel often make when implementing a SOC. 

In [27], the authors address the risks of cyber-attacks on 
businesses and the costs they tally upon the economy.  The 
authors also suggest the adoption of SOCs to regularly and 
diligently track the vital and essential digital business ser- 
vices undertaken to protect and secure the best interest of the 
underlying business operations.  They also suggest dividing 
a SOC into three significant categories: collecting informa- 
tion, running it through the appropriate analytics, in addition 
to  monitoring  and  responding  with  countermeasures.  Fur- 
ther, the paper addresses the role of each security personnel 
involved in administering the SOC. 

In [24], , the authors give a brief overview of informa- 
tion security and then move on to the concept of SIEM solu- 
tions; deemed as central to the health of a functioning SOC. 
In  [25],  the  authors  discuss  the  risks  of  cyber-attacks  and 
their financial impacts on the economy.  Several SOC tools 
were brought to bear, along with best practices in applying 
processes and procedures. 

In  [10],  ,  the  authors  introduce  a  user-centric  machine 
learning system that leverages big data to classify and iden- 
tify a risky user from different security logs collected, issue 
alerts,  share  relevant  information,  and  offer  analyst  exper- 
tise all to determine user risks leveraging actual and real-life 

A. Shatnawi et al.:  Preprint submitted to Elsevier 

Page 3 of 21

 
 
 
Adaptable Plug and Play SOC

industrial data. In [18], , the authors elaborate upon some se- 
curity threats stages towards SOC and suggest several solu- 
tions to safeguard the system, including Standard Operating 
Procedures (SOP) that make the SOC process and its associ- 
ated actions more explicit. They also discuss regular training 
for employees on the company’s functions, resources, poli- 
cies, and standard rules in institutional operations. In [8], the 
authors propose an innovative intelligent framework referred 
to as Network Flow Forensics Framework (NF3). According 
to  the  authors,  this  framework  is  considered  effective  and 
accurate due to harnessed machine learning, network traffic 
analysis, and encrypted traffic identification.  In [9], the au- 
thors introduce a novel intelligence-driven cognition-based 
computing SOC that is essentially based on progressive and 
entirely automated procedures.  This is based on using two 
precise new and innovative artificial intelligence algorithms, 
wherein it harnesses the Lambda machine learning architec- 
ture that can process a combination of batch and streaming 
data simultaneously. 

In [5],the SIAC architecture presented addresses an en- 
terprise SIEM built on open-source technology that heavily 
leverages Wazuh’s SIAC’s main contribution, where it illus- 
trates  how  open-source  tools  can  be  used  to  build  a  SOC 
with upscale information security capabilities. It further in- 
troduces the concept of automated SOC deployment via shell 
scripts and later reveals that it can be imported into config- 
uration  management/orchestration  tools  easily;  however,  it 
does not provide any actual implementation details. 

It is important to note, nonetheless, that many of the pro- 
vided scripts are either considered obsolete by today’s oper- 
ational frames or are not needed for Wazuh installation alto- 
gether. The following list offers a brief comparison between 
the two solutions: 

•  Our proposed solution, herein, is fully scalable at all 
levels  including  horizontal  scalability  with  the  abil- 
ity to enhance the toolchain, add plugins, handle more 
agents, and support servers and clusters.  In compar- 
ison,  SIAC is scalable in terms of the ability to add 
Linux agents by only providing a shell script to install 
the agent with the needed tools to configure them. 

•  Our proposed solution offers the ability to create new 
alerts that can be mapped to the sought-after compli- 
ance requirements. In comparison, a SIAC entirely re- 
lies on already implemented mappings in Wazuh with- 
out providing any changes. 

•  From a holistic perspective, we have fully automated 
the proposed solution from A to Z. It is user-friendly, 
where the less-experienced users can leverage our pro- 
posed framework to configure any network regardless 
of its size. In the meantime, SIAC provides some sim- 
ple scripts to install the required packages in case of 
any automation procedure requirements. However, the 
underlying codes are obsolete and require manual han- 
dling. 

•  In  terms  of  adaptability,  our  solution  is  found  to  be 
fully adaptable in terms of risk profiles, network size, 

technological diversities, varying organizational require- 
ments, and fluctuating organizational budgets. Mean- 
while, SIAC can run in the cloud, on bare metal, or in 
a hybrid environment, that is supported by the open- 
source solution currently in use. However, SIAC does 
not seems to offer much in terms of adaptability. 

•  Regarding configurations, we have not paid any heed 
opposite particular unique configurations as it falls out- 
side the realm of the immediate focus of our project. 
Nonetheless, many configurations are being consid- 
ered towards achieving adaptability. SIAC, on the other 
hand,  adds in a new plugin for better dashboard vi- 
sualization (Kibana Network Plugin) together with a 
new package (Packetbeat) to enhance the logging pro- 
cesses and management side only. 

•  Regarding cloud support,  it is readily seen that both 
solutions do, in fact, support cloud deployment. How- 
ever, SIAC supports the cloud through the capability 
of the used open-source SIEM itself. 

•  Opposite the issue of modularity, we offer a fully flex- 
ible and automated solution in terms of architectural 
modularity. Any new module can be readily added to 
the deployed agents and the toolchain. In comparison, 
SIAC’s capability of improving the toolchain is done 
by altering the provided scripts. However, since these 
are regarded as bash scripts, this method is again lim- 
ited solely to Linux machines. 

•  We provide modifications to the existing solution whereby 
a new subsystem is added to the SIEM and provide 
new frameworks to enhance the overall capabilities of 
SOC. SIAC, on the other hand, offers nothing more 
than FOSS packages and configuration files with no 
significant modifications in the process. 

3.  Analysis and Design 

The design of our proposed framework is intended to be 
as simple as possible,  making the deployment of a SOC a 
straightforward matter.  Yet, the design will leverage a pow- 
erful process to achieve what we refer to as an Adaptive SOC 
implementation.  Automation  of  the  underlying  process  is 
meant to cover the vital parts in a SOC deployment.  Here, 
configuration  of  the  monitored  devices  should  entail  fully 
automated processes.  This encompasses agent installations 
on the client devices and configuration of network and se- 
curity  attributes  in  a  manner  that  would  allow  the  logs  to 
continually update the central SIEM; a process that is nor- 
mally rather tedious with repetitive task executions making 
it more error prone. 

Furthermore, our framework design aims to reinforce an 
open-source-based  SOC’s  operational  and  functional  envi- 
ronment. This is done by fostering a plugins system that can 
interact with established applications, execute custom codes, 
and enhance the SIEM functionality. 

1.  Our SOC should be capable of the following: 

A. Shatnawi et al.:  Preprint submitted to Elsevier 

Page 4 of 21

 
 
 
 
Adaptable Plug and Play SOC

•  SIEM:  provides  the  necessary  security  analyt- 
ics including monitoring, and event correlation 
by allowing log collection, aggregation, parsing, 
storage, analysis, search, correlation, archiving, 
and disposal. 

•  Log management:  helps ensure that records are 
stored  in  sufficient  detail.  The  collection  pro- 
cesses  will  handle  the  logs;  it  will  gather  data 
from  different  sensors  and  convert  them  into  a 
unified standard format. 

•  File Integrity Monitoring (FIM): checks crucial 
files (e.g., operating system’s files) to determine 
whether they have been tampered with or gotten 
corrupted. 

•  Incident Response: a system that facilitates, rec- 
ognizes  and  responds  to  facilities,  staff,  proto- 
cols and communications to operate coherently 
in an emergency. 

•  Asset  Discovery  &  Asset  Management:  keeps 
track of all active and inactive assets in order to 
continuously check the adherence of each asset 
to the overall security policy and to take appro- 
priate action if the asset deviates from the policy. 
•  Threat Intelligence: provides evidence-based in- 
formation  of  a  current  or  emerging  threat,  in- 
cluding context, mechanisms, indicators, conse- 
quences, and actionable recommendations. 

•  Rich  Analytical  Dashboards  &  Data  Visualiza- 
tion: visually presents the complex data sets and 
outcomes of the analysis done by other SOC com- 
ponents. 

•  Real-time and Configurable Alerts & Reporting 
tools: provide real-time notifications of detected 
anomalous events, with information regarding what, 
where and when events happened. 

2.  Regulatory compliance:  the conformity of an entity 
to rules, regulations, standards, and requirements ap- 
plicable to its business processes.  Some compliance 
regulations are explicitly intended to ensure the secu- 
rity of records and protection of data. Bad compliance 
practices for data breaches can harm customer satis- 
faction and adversely affect a company’s bottom line. 
As data breaches continue to rise in frequency, cus- 
tomers become more inclined to investing more confi- 
dence in enterprises that strictly obey regulatory com- 
pliance  mandates  intended  to  safeguard  and  protect 
personal data.  Data privacy-specific regulatory com- 
pliance mandates, such as General Data Protection Reg- 
ulations (GDPR), have become more prominent as the 
processing of users’ sensitive data by corporations is 
becoming more scrutinized. Given that a SOC is a re- 
quirement that must be met by hospitals, banks, and 
other governmental organizations, the proposed SOC 
implementation would readily provide vendors with 
features that reflect conformity to regulations.   This 
is owed to the fact that clarity in compliance to proce- 

dures often gives clients more confidence in the under- 
lying  business  processes.  Besides,  compliance  with 
legislation serves as one of the elements that ensures 
security of the data involved. 

3.  The Ticketing System: It is expected that a SOC team 
will monitor potential incidents identified by tools or 
reported by charged personnel. To guarantee that events 
are properly handled, a case must be established, al- 
located, and monitored before completion. Both tools 
and personnel involved should help fulfill the processes 
involved,  provided that the proper equipment,  juris- 
diction, and integration of incident response and case 
management procedures are in place.  A crucial fac- tor 
to remember is that remediation for some incidents might 
require resources outside the reach of SOC ana- lysts’ 
reach. Therefore, the effectiveness of case man- agement 
is manifested in its ability to assign these re- 
sponsibilities to their respective lines of authority. Thus, 
the ticketing system, which is used to track events through 
its incidents history as well as a contact point between 
the impacted segment and the SOC, sits at the fore- 
front of the a SOC incident handling process. 

4.  Automation:  One of this  framework’s main goals is 
to  achieve  a  fully  automated  SOC  deployment,  bet- 
ter known as a plug-and-play property.  This automa- 
tion feature aims to aid the SOC to meet the challenges 
that emerge from many determined and repeated pro- 
cesses.  Therefore, the deployment and configuration 
of  the  monitored  devices  should  be  fully  automated 
offering high-velocity tasks. This requires that we es- 
tablish  the  first  pillar  of  the  Adaptive  SOC  tooling, 
which shall henceforth be referred to as the “Autocon- 
fig Tool”. 
The proposed framework should be able to fully auto- 
mate the following processes: 

(a)  Configuring the entire SOC stack. 
(b)  Deploying agents on monitored devices. 
(c)  Configuring monitored devices for agent-less mon- 

itoring. 

(d)  Deploying and integrating the SIEM with a tick- 

eting system. 

(e)  Modifying the configuration of the SOC compo- 

nents at any time. 

With this property, becoming active, the SOC will achieve: 

•  Configuration management and full SOC deploy- 

ment in minutes. 

•  Help bridge the cyber skills gap through automa- 

tion that lessens the burden on humans. 

5.  Contriving Horizontal Scalability & Modular Archi- 
tecture:  The  SOC’s  security  space  should  foster  the 
ability to be expanded with new tools.  Furthermore, 
the SOC should possess the versatility to increase its 
capacity and include more servers on clusters as a sin- 
gle logical unit. Here, improving the capacity, as well 
as improving the security space, should be very seam- 
less processes without any added complexities. 

A. Shatnawi et al.:  Preprint submitted to Elsevier 

Page 5 of 21

 
 
 
Adaptable Plug and Play SOC

6.  Fostering Adaptability: Exposure to the Internet is presently  While both SIEM solutions above are very powerful, OS- 
SIM has clear disadvantages.  This is attributed to lack of a 
centralized  log  management  system.  However,  the  defini- 
tive factor is, unlike Wazuh, which functions in a Manager- 
Worker fashion,  OSSIM  works  in  a  single  server  architec- 
ture.  Having  single-server  architecture  deployment  readily 
implies  all  computations  will  take  place  on  a  single  node, 
requiring a very high-end machine to accommodate the bur- 
den; worse yet, it renders the network in a severely congested 
state. 

a fact of life inherently posing numerous threats upon 
system  integrity.  SIEM  solutions  can  provide  much 
information to help the end user quickly take actions 
against security threats and accurately identify the at- 
tacks, all from a single console.  Yet that may not be 
enough; the SOC should enhance its maturity and abil- 
ity to mitigate incidents.  In order to have a proactive 
defensive strategy against the different risk profiles of 
different organizations, or even against the unexpected 
threats, the SIEM must be able to work together with 
another module; a module that can provide a broader 
range  of  contextual  information  —  about  identities, 
users, device types, privilege levels, conditions of net- 
works and events –a functionality usually embodied in 
the SIEM. 
This requirement originated from the problem that the 
current open source based SOC implementations lacks 
the ability to be strengthened on the fly, and since their 
development  is  usually  a  slow  process,  complicated 
with  the  unavailability  of  receiving  frequent  updates 
(as the commercial ones), the need for a tool that can 
promote the capabilities of the security solutions, with- 
out needing to upgrade the SOC, is a must. 

The subsections in the sequel outline the different design 

strategy and the reasoning for each of our these choices. 

3.1.1.  Pull vs. Push Automation 

The managed devices can receive their configuration pa- 
rameters in two ways: the first being the Push model, which 
is the one we adopted in our research, with the latter being 
the Pull model, where the contrast is depicted in Fig. 1. 

The  Adaptability  enforced  by  what  we  refer  to  as  the 
“Plugins System” behavior will stand as the second pillar for 
an Adaptive SOC tooling. It enables every SOC manager to 
adapt to different risk profiles and to deploy new functionali- 
ties that can assess security threats and take immediate reme- 
diation actions on the monitored devices in the form of plu- 
gins, in real-time. These plugins should be easy to develop, 
easy  to  expand,  and  easy  to  maintain.  Furthermore,  these 
plugins should be easy to share; to enable a security ecosys- 
tem of collaborative defense that extends available security 
solutions with easy to install plugins.  Such transparent and 
collaborative strategy spurs the development of new plugins 
that further enrich the cyber defense world. 

With this property on hand, the SOC ultimately becomes: 

•  Adaptable to different risk profiles and varying orga- 

nizational needs. 

•  Amenable to deliver deep visibility and actionable in- 

sights into the complex threat landscape. 

•  Versatile to increased efficiency and performance for 

an SIEM solution with ready-to-install plugins. 

•  Amenable to a sharable experience in code develop- 
ment,  exchange  of  best  practices,  gain  insights  and 
learn from others. 

Before choosing a SIEM to satisfy our design require- 
ments, we have conducted a thorough comparison between 
the available open source SIEMS. Our choices were broken 
down to: 

•  Wazuh 
•  Open-Source Security Information Management (OS- 

SIM) 

Figure 1:  Push vs.  Pull Configuration Management. 

The push model requires nothing more than having the 
configuration tool and the SSH credentials available for the 
managed devices; it simply will log on to the managed de- 
vices, do the configuration, and the process is complete. Mean- 
while, the Pull model requires far more than that in the Push 
model.   Here,  the managed devices would need to have a 
special  agent  that  can  communicate  with  the  active  man- 
ager,  which  means  one  level  less  of  automation.   This  is 
because  the managed  devices  will  need  to  have  the  agent 
deployed before even starting the automated configuration 
process.  Other disadvantages accruing from the use of the 
Push Model also include its difficulty to use, its slower per- 
formance, and its requirement for an SSL certificates man- 
agement handler. 

3.1.2.  SIEM Integration vs. Host Plugins 

Recent entrants to the SIEM landscape are adding tech- 
nology that offers unnecessarily higher levels of sophistica- 
tion for analytical use cases. These technologies can extend 
the SIEM functionality in two ways.  The first uses an inte- 
gration module while allowing the SIEM and other security 
applications to have third-party applications running on top 
of them or exchanging data with them via APIs. 

However, the second approach is designed to deliver these 

technologies and applications and make them run locally on 

A. Shatnawi et al.:  Preprint submitted to Elsevier 

Page 6 of 21

 
 
 
 
 
 
 
 
 
Adaptable Plug and Play SOC

Automation  Push 

SIEM 

Adaptability 

No  software  is  needed  to  manage  clients, simpler to
use, and scripts written using YAML. 

Wazuh 
Under   active   development,   well documented,   very
powerful  and  has  scalable  architecture. 
Plugins 
Plugins  can  work  as  a  separate system  and  can  trig‐
ger  the  SIEM  solution.  Plugins are  used  to  add  new 
features  inside  the  SIEM  solutions  to  help  the  SOC  in 
general and add new security tools as a means of threat 
detection and prevention based on the active response. 

Pull
Needs special software on both the manager and man‐
aged devices,  uses a unique syntax (scripting language) 
and  has  needless  complexity. 
OSSIM
No log management, no  frequent  updates, no manual
or  documentation  and  has  Single‐Server  architecture. 
Integrations
Integration  triggered  by  the  SIEM  solution  itself.   In‐
tegrations  can  enhance  the  SIEM  itself  by  adding  a 
specific job into the SIEM solution without the ability 
to add new features or change the SIEM functionality 
(e.g.,  scan  a  file  or  send  alerts  into  and  outside  the 
SIEM). 

Table  1 
Different Design Approaches with Advantages and Disadvantages. 

the monitored devices or hosts through the SIEM. This ap- 
proach will allow the SIEM to have a broader view of what is 
happening on these devices. As such, it will continue to en- 
hance the investigative capabilities and, consequently, will 
introduce a form of plugins for response actions.  This is a 
powerful feature as it reduces the time to respond to security 
events in stopping attacks and protecting critical data rather 
more efficiently.  From our own perspective, the Adaptable 
SOC will need to have both features on board. On this note, 
while the current SOC market is geared towards SIEM inte- 
gration and empowering the SIEM with more sophisticated 
tools that pop everywhere, the second approach has been sig- 
nificantly less popular. 

this role, which takes place using Ansible [32] – renowned 
as  a  powerful  push  configuration  tool.  The  result  will  be 
manifested in deploying and configuring the different SOC 
components and, hence, culminating into a fully operational 
SOC just via the sheer implementation of this particular tool. 
To satisfy the modular architecture and horizontal scalability 

Table 1 summarizes the different design approaches cit- 

Figure  2:  Autoconfig  Tool  Design. 

ing advantages and disadvantages for each approach. 

To satisfy the automation requirement, Fig. 2 shows the 
design details for the Autoconfig tool that is responsible for 
the Plug and Play SOC deployment and the horizontal scal- 
ability  of  the  SOC.  The  tool  will  have  a  list  of  IPs  of  the 
monitored devices and the SOC servers, SSH logins, along 
with their corresponding roles as input; these roles include: 

•  The SOC component, e.g., SIEM server, Log manage- 

ment server. 

•  The network device operating system, e.g., IOS, JunOS. 
•  The endpoint device operating system, e.g., Linux, Win- 

dows. 

•  The security device. 

The tool will then forward every IP address to the appro- 
priate configuration module, which will take care of config- 
uring the device either by setting up Syslog,  deploying an 
agent, or configuring the SOC components and connecting 
them together. 

As  shown  in  Fig.  2,  the  tool  will  receive  the  required 
SOC topology as input. The SOC topology is a text file with 
a particular format to declare the devices IP addresses and 
their roles in the SOC; i.e., agent IP, SIEM IP, and so forth. 
The tool will have a parser that will read the topology file and 
parse the fields to choose the proper deployment module for 

requirements, the tool does not only support the initial SOC 
deployment, but also supports the capability of adding more 
tools to the SOC stack, deploying more agents and changing 
the configuration of existing deployments,  as illustrated in 
Fig. 3. 

Figure  3:  Horizontal Scalability with Autoconfig Tool. 

This  allows  the  SOC  manager  to  deploy  a  new  set  of 
agents on-the-fly,  add new monitoring tools to already ex- 
isting functioning agents, add new integrations with SIEM, 
and expand the SOC clusters to adapt to the needs. The tool 
also follows and adheres to the following best practices: 

•  Safeguarding Sensitive Data in Encrypted Files:  The 
Autoconfig  Tool  will  need  to  use  sensitive  data,  and 
the  login  credentials  to  configure  the  monitored  de- 
vices in a seamless manner.  Such sensitive data will 

A. Shatnawi et al.:  Preprint submitted to Elsevier 

Page 7 of 21

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Adaptable Plug and Play SOC

be stored on the local file system for safeguarding pur- 
poses; these will be encrypted and require a passphrase 
to get them decrypted. 

•  Using  SSH  Keys  in  lieu  of  Passwords:  In  our  pro- 
posed design, we abide by the best practice of using 
the Secure Shell (SSH), which implies an SSH key au- 
thentication  mechanism  instead  of  using  passwords. 
Here,  SSH  key  authentication  is  much  more  robust, 
and when sensitive data is transmitted across the net- 
work, security is of paramount importance. 

The Programmable Plugin-based Intrusion Detection and 
Prevention System (PPIDPS) is designed specifically for se- 
curity engineers. It offers the ability to design any threat de- 
tection mechanism.  Also, it provides a prevention capabil- 
ity by triggering an active response technique. Furthermore, 
it lends itself well to programmability since it becomes the 
security engineer’s responsibility to write the detection code 
and design the specific detection mechanism. Moreover, it is 
plugin-based, so security engineers worldwide can exchange 
these plugins and leverage them against different threats. 

This system will act as a host-based intrusion detection 
system and a host-based/network-based intrusion prevention 
system (Depends on the programming) simultaneously. With 
this, it will run on all monitored devices with the purpose of 
adding the ability of enhancing the SIEM functionality and 
executing  security  functions  directly  on  the  monitored  de- 
vice themselves.  The system will enable the SOC manager 
to  execute  custom  code  written  in  a  scripting  language  or 
health check scripts as a form of a plugin on the monitored 
devices or a subset thereof and check the results in real-time. 
The results will be returned in logs through a secure channel 
and will then be fed to the dashboards. The design schematic 
shown  in  Fig.  4  presents  code  reuse  with  code  sharing  in 
mind; we believe, with this specific design strategy on hand, 
SOC engineers and analysts can readily share their plugins 
on threat intelligence or other platforms with great ease. 

Figure 4: Programmable Plugin‐based Intrusion Detection and 
Prevention System Design. 

Our Plugin System uses a RESTful API that runs on the 
Wazuh manager.  This RESTful API will use an encrypted 
channel to push data to the monitored devices. The data can 
be  some  custom  scripts  written  in  a  platform-independent 
language (e.g., Python3), or health check codes, or simply a 
series of commands. The plugins can be fed into the Plugin 

System using the RESTful API. A web interface is provided 
to allow the users to configure, edit, and push new plugins 
into the system using a simple User Interface (UI). The plu- 
gins are pushed as packages into the system; these packages 
include: 

•  The script that is going to run on the agent machine 

and report for possible threats. 

•  The  needed  decoders  and  rulesets  for  the  logs  pro- 

duced by the plugin. 

•  The needed scripts to execute a proper incident han- 

dling mechanism to resolve the threat. 

The  SOC  manager  would  enable  those  plugins  to  run 
on the deliberated devices.  Enabling the plugin will signal 
the agents on the monitored devices to download the plugin 
and execute it during every configurable period. The needed 
decoders and rulesets to produce alerts are pushed into the 
SIEM  once  the  plugin  is  enabled.  The  scripts  will  check 
on the monitored devices or, in the case of a new threat ap- 
pearance,  run  custom  scripts  to  make  these  devices  threat 
immune. The agent on the monitored devices will keep run- 
ning the scripts, and upon discovering a threat, the agent will 
send the alert data in the form of Syslog to the SIEM. The 
SIEM will use the associated decoders and rulesets to create 
proper alerts and push them on the dashboards to give the 
security analysts a holistic picture of available information. 
The Plugin System’s triggered alert will open a ticket using 
the Ticketing System, with the highest priority – “critical”. 
The Plugin System will also take any required incident han- 
dling measures to prevent the threat from migrating or mov- 
ing to other parts of the system;  for instance, upon adding 
new configurations into the firewall. 

Since the needed decoders and rulesets are bundled to- 
gether with the plugin scripts, this renders the plugins fully 
programmable. Any part of the plugin can be altered to sat- 
isfy the different needs and different risk profiles of different 
organizations. For example, the decoders and rulesets can be 
modified to trigger different alerts that are more suited for a 
particular organization.  The alert levels can be tweaked to 
fulfill the needs of the risk profile of a specific organization; 
better yet, the alerts can be mapped onto regulatory compli- 
ance requirements that a specific organization has to adhere 
to. 

3.1.  Engineering Standards 

Our framework follows the following Engineering Stan- 
dards in order to provide a stable continually evolving foun- 
dation that enables entire industries to develop and thrive. 

List of these Engineering standards include: 

1.  Log  Format: The  format  of  logs  for  Linux  systems 
and  network  devices  sent  by  the  underlying  tools  in 
the proposed framework will follow the message log- 
ging standard, Syslog as defined in [13]. Since Syslog 
provides no data encryption by default, the Syslog im- 
plementation as defined in [26] uses TLS to encrypt 

A. Shatnawi et al.:  Preprint submitted to Elsevier 

Page 8 of 21

 
 
 
 
 
 
 
 
 
Adaptable Plug and Play SOC

the Syslog traffic. For the Windows operating system, 
Eventlog is used. 

2.  Transmission Control Protocol (TCP): The exchanged 
data in  the  communication medium  will be handled 
using the TCP protocol as presented in [16]. 

3.  Secure Shell: Secure Shell (SSH) is a communication 
protocol for remote login that is handled securely over 
insecure  networks,  as  defined  in  [42].  SSH  will  be 
used  for  configuration  management  automation  pur- 
poses. 

4.  Encrypted Channels: All the catered for tools will have 
to  exchange  information  across  the  network,  be  it  in 
the parameter configuration and the custom codes to 
be executed on the monitored devices, including other 
private information. These exchanged data packets are 
considered sensitive and therefore must be maintained 
confidential; hence, we add SSL encryption to all our 
tools communications. 

4.  Implementation 

In this Section, we reveal the implementation details of 
our framework; towards the end, we present a use case that 
shows how the entire system will function, as one entity, to 
yield the desired outcomes. 

4.1.  The Autoconfig Tool Implementation 
4.1.1.  Ansible 

Ansible [32] is a push model configuration tool, that has 
recently prevailed and became one of the pillars of the De- 
vOps world. It can configure systems, deploy software, and 
orchestrate IT tasks. Ansible was built with simplicity at its 
core,  with  its  operation  not  needing  any  client  or  agent  to 
be installed on the target machines.  Unlike other tools, in- 
cluding Chef [30] or Puppet [21],  it only requires an SSH 
connection for it to execute its allocated tasks. 

4.1.2.  Ansible Architecture 

Ansible uses SSH for communication with the target ma- 
chines, where it can run commands directly on them, or re- 
ceive the information that they send. Ansible has a very sim- 
ple architecture, which consists of three main components: 

1.  Inventories: These are used to save the host informa- 
tion  as  text.  The  information  might  include  the  IP 
addresses,  the  SSH  keys,  the  username,  passwords, 
URLs,  checksums,  etc.  The  hosts  inside  the  inven- 
tory can be divided into groups to reflect correspond- 
ing configuration needs. 

2.  Playbooks: These are units of scripts that will define 
what  configuration  or  any  piece  thereof  will  run  on 
the target machines.  These playbooks are defined in 
YAML format and extensively make use of the Mod- 
ules. 

3.  Modules: These are standalone scripts, written in 

Python, which can be used by the Ansible-Playbooks. 
These modules can control services or daemons that 
run on different operating systems, system resources, 

filesystem content, or for installing packages, etc. and 
can  execute  raw  commands.  Ansible  comes  with  a 
large  set  of  ready  modules  that  can  be  extended  by 
adding one’s own modules. 

Furthermore, Ansible can execute raw commands using the 
shell  or  command  line.  Fig.  5  clarifies  the  interaction  be- 
tween various Ansible components. 

Figure 5:  Ansible Architecture. 

4.1.3.  Ansible Vault 

Ansible-Vault is Ansible’s mechanism of providing en- 
cryption and security to the sensitive data across inventories, 
in a user-friendly manner [33].  Vault will ensure file-level 
encryption of sensitive files and require the same passphrase 
for encrypting as well as decrypting the files. Ansible-Vault 
will  be  used  to  ensure  security  of  SSH  keys  in  the  imple- 
mented tools. 

4.1.4.  Jinja2 Templating Engine 

Ansible uses Jinja2 [28] templating engine to replace the 
placeholders  with  appropriate  values.  This,  offers  greater 
flexibility in the written playbooks. For example {{ wazuh_ip 
}} will be replaced by the value of the wazuh_ip variable. 
Furthermore, this engine will bolster the ability of using con- 
ditional statements (e.g., if statements) and flow control state- 
ments (e.g., for loops) [34]. 

4.2.  The Automation Engine 

Given Ansible’s great potential and automation capabili- 
ties, as described in [41],it is readily evident that Ansible can 
reduce the time for configuration and provide easier network 
devices maintenance. This is on top of the added capabilities 
afforded to legacy network elements to operate in a similar 
manner commensurate with upscale network devices,  with 
Software-defined networking (SDN), performance. The Au- 
toconfig  tool,  under  the  proposed  architecture  will  heavily 
leverage Ansible as an Automation Engine. In so doing, one 
would be able to automate every phase of Wazuh’s deploy- 
ment, execute endpoint configurations, and do necessary in- 

A. Shatnawi et al.:  Preprint submitted to Elsevier 

Page 9 of 21

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Adaptable Plug and Play SOC

tegrations  with  external  APIs. Hence,  the  following  set  of 
Ansible-Playbooks will be provided: 

1.  Wazuh all-in-one deployment playbook 
2.  Wazuh distributed deployment (Wazuh clusters) play- 

book 

3.  Wazuh Windows agent deployment playbook 
4.  Wazuh Linux agent deployment playbook 
5.  CiscoIOS configuration playbook 
6.  JunOS configuration playbook 
7.  Wazuh  integration  with  a  Ticketing  System  (Slack) 

playbook 

8.  Wazuh integration with VirusTotal playbook 

Each playbook will harness different modules and configu- 
ration parameters that are mostly suited for the task on hand. 
These playbooks will decouple the deployment process from 
the lower details of how the agents or the Syslog configura- 
tion works for different platforms.  At any point in time, be 
it at the initial deployment of the SOC or when expanding 
a SOC with new monitored devices, the SOC manager will 
only need to gather their IPs and SSH keys and get the job 
done in a matter of seconds.  The same procedure applies if 
the SOC manager decided to extend the SOC with a Ticket- 
ing System integration or another API. Here, the SOC man- 
ager will not have to go through the cumbersome process of 
remembering lengthy details of how a particular task would 
be done. This will also spare the extra time normally needed 
in  searching  within  the  docs.  In  summary,  all  that  needs 
to  be done  would  be  to run  the relevant  playbook  and  get 
things done,  as  per  the  characterizing  plug-and-play prop- 
erty. Fig. 6 illustrates the entire process in detail. 

Figure 6:  Automated Configuration Process. 

In executing the processes seamlessly, the different roles 
of an Automation Engine are split into different directories 
to evade any repetitive activities and to aid into the process of 
integrating the engine. The file structure of the Automation 
Engine is shown in Fig. 7: 

•  playbook  directory  contains  all  the  playbooks  that 
covers the different cases of deployment; this includes 
the agents, the Wazuh and Elasticsearch clusters, etc. 

Figure  7:  The  Automation  Engine  File  Structure. 

•  vars directory contains the needed variables that will 
be replaced in the appropriate playbook, e.g., IP ad- 
dresses. 

•  tasks directory contains common tasks to be imported 
by the playbooks, to evade needless repetitive execu- 
tions of the same codes, e.g., installation of the Elas- 
ticsearch package. 

•  tmp directory contains configuration files that will be 
pushed into the deployed machines to adjust their con- 
figs to a client’s needs, e.g., Filebeat configurations. 

•  creds directory contains the credentials that will be 
used by the playbooks to gain access to the machines; 
these files will be encrypted using Ansible Vault, e.g., 
SSH keys. 

If  the  SOC  manager  wants  to  deploy  an  Elasticsearch 
node,  he  or  she  would  simply  run  the  relevant  playbook. 
In  this  case,  the  “elastic_search.yml”  playbook. The  play- 
book will import the needed variables and tasks from /vars 
and /tasks, respectively, and will use the relevant credentials 
from  the  /cred  directory  to  login  to  the  specified  machine 
in the playbook and run the tasks; this, in turn, will deploy 
Elasticsearch.  In the process, the defaults configuration of 
Elasticsearch will be replaced by the appropriate ones in the 
/tmp directory. 

While users can install and deploy any of the components 
by running its playbook at any time, the users may, at some 
point, want to make a huge deployment of different compo- 
nents, e.g., during the initial deployment phase.  Therefore, 
we provide an interactive utility which the user can run prior 
to making the deployments called formatter.py.  This utility 
works interactively with the user, while helping abstract the 
tool and serves as an interface.  It will ask the user for the 
number of Wazuh servers needed and the number of Elastic- 
search clusters to be deployed, and the integrations that are 
desired for adding to Wazuh. Finally, it will ask the user for 
the number of agents of a specific type that will be deployed. 
For each type of deployment, the tool would also ask for 
the machines’ IP addresses, along with the path for the SSH 
keys and the SSH username. Alternately, formatter.py could 

A. Shatnawi et al.:  Preprint submitted to Elsevier 

Page 10 of 21

 
 
 
 
 
 
 
 
 
 
 
 
 
Adaptable Plug and Play SOC

3.  The  SOCreative  Web  Interface:  This  is  a  web  in- 
terface that will be used by SOC engineers. It is used 
to interact with the API itself and manage the plugins 
system with ease. 

4.  The Agent Daemon:  This is a daemon that runs lo- 
cally  on  the  agents.  Its  purpose  is  to  keep  track  of 
which plugins to download from the API and to exe- 
cute those plugins on regular basis and report the re- 
sults to the Wazuh manager. 

4.4.  Plugins 

All the internal codes to build this plugin system are im- 
plemented defensively, i.e., the codes will exit gracefully if 
they fail during execution and print where they failed on the 
screen. 

4.4.1.  Structures 

The plugins system directory will have the needed files 
and sub directories that will be used by the plugins system: 

•  The  plugins  implemented  by  the  security  engineers 
should be located at /var/ossec/plugins directory, each 
of which will be identified by a unique ID. 

•  Every agent that is intended to receive a plugin will 
have a JSON file named pursuant with its ID and lo- 
cated in the /var/ossec/etc/shared/default/plugins di- 
rectory. This directory is shared between the manager 
and the agents using the Wazuh daemons. 

•  The new decoders will be installed and located in the 

/var/ossec/etc/decoders/local_decoder.xml   file. 

•  The  new  ruleset  will  be  installed  in  the  /var/ossec/ 

etc/rules/local_rules.xmlfile. 

•  The scripts that are intended to be executed for active 
response purposes will be located at the /var/ossec/ 
activeresponse/plugins directory, each of which will 
be named by the plugin’s ID they relate to. 

The plugins will be pushed to the /var/ossec/plugins di- 
rectory.  Every plugin will be named after its assigned id. 
The plugins directory structure is shown in Fig 9. The plugin 
can be pulled by the agent using a GET request to the REST- 
ful API, where the agent will receive a minimal size of the 
plugin.  This includes only the <plugin’s id>/script.py and 
the <plugin’s id>/metadata.json. Other files are only needed 
by the Wazuh servers. The decoders.xml and rules.xml will 
contain the needed decoders and rules templates by the Wazuh 
server to interpret the received logs by the plugin and trigger 
the appropriate alerts.  The template in Fig. 10 will be fol- 
lowed by the decoders in the decoders.xml file. In addition, 
the template in Fig. 11 will be used in the alerts.xml file. 

The script.py is the script that will be executed locally 
on the agents. The script will contain the required function- 
ality to do the health check or identify an attack.  The script 
will also contain the required code to provide the ability to 
achieve remediation and apply any needed countermeasures. 

Figure  8:  Autoconfig  Tool  Workflow. 

run with -a or -agents options for the sole purpose of acquir- 
ing input for the agents. 

The result from this utility is a text file (by default called 
topology.txt) which contains the entered information in the 
format shown below: 

IP: SSH Key Path: Device Type: SSH User 

The Device Type defines the role of the machine.  It can 

be one of the following: 

1.  Linux (agent), with the ability to distinguish between 

the different distributions. 

2.  Windows (agent) 
3.  Cisco 
4.  Juniper 
5.  Elastic (server) 
6.  Kibana (server) 
7.  Wazuh (server) 

The resulting text file from running the formatter.py will 
be fed into the deployment script – deploy.py, which will in- 
voke the actual deployment process.  Depending on the De- 
vice Type, the script will forward the information to the ap- 
propriate  Ansible-Playbook,  which,  in  turn,  will  take  care 
of both the configuration and deployment processes.  Fig. 8 
illustrates the two scripts in action. 

4.3.  PPIDPS Implementation 

The PPIDPS is implemented by four major components: 

1.  The  Plugins:  These  reside  on  the  Wazuh  manager. 
They  contain  the  actual  threat  detection  capabilities 
and are used by the agents. 

2.  The SOCreative API: A RESTful API that runs on 
the Wazuh manager. It is used to interact with the plu- 
gins system through HTTP requests. It can be used to 
push, pull or update plugins. “SOCreative” is a name 
that has been introduced, by the authors, for the API. 

A. Shatnawi et al.:  Preprint submitted to Elsevier 

Page 11 of 21

 
 
 
 
 
 
 
 
 
 
 
 
Adaptable Plug and Play SOC

1    { "id": "0bab811d−dc33−45b8−970b−e15ef64cb12d", 
2 

"name": "Plugin Name", 
"description":  "Plugin  Description", 
"version":  "0.0.1", 
"enabled":  false, 
"script":  {"interval":  60}, 
"agents":  ["001",  "002"] 

3 

4 

5 

6 

7 
8     } 

Figure 12:  PPIDPS METADATA Template. 

the plugin; it is either enabled and, hence, executed by the 
agents or is not enabled, altogether.  The interval represents 
the period frequency in seconds in which the script will be 
re-executed. The  agents  represent  a  list  of  agents’  ids  that 
will receive this plugin and have it activated. 

4.5.  Active Response Mechanism 

We have implemented our own active response system 
with  the  purpose  of  gaining  more  fine  grain  control  over 
the monitored devices and react accordingly in the case of 
a  threat. In  other  words,  to  enable  an  appropriate  incident 
handling mechanism. 

The system can take effect on both the agent device and 
on the Wazuh manager itself. It takes place on the agent de- 
vice by including it in the main plugin script; i.e., script.py, 
where the  script will  have all  the needed logic  to take  the 
proper  actions  to  react  and  do  the  needed  remediation  ac- 
tions once it detects a threat. It will then send a request to the 
Wazuh manager along with a list of arguments that might be 
needed – to start executing the active response on the Wazuh 
manager locally. 

The active-response directory (inside the plugins direc- 
tory) will contain the required scripts that need to take place 
on the Wazuh manager (e.g., adding firewall rules or quaran- 
tining the device) and will be applied by running the active- 
response/script.py script. It will have the structure shown in 
Fig. 13. 

where the active-response scripts will be named after the 

plugin’s id that they are associated with. 

4.6.  SOCreative API 

We  have  used  a  high-performance  Python  framework, 
called FastAPI [31], to run the RESTful API on the Wazuh 
manager  machine  on  port  55002.  Through  this  API,  the 
SOC team will be able to directly export/import the plugins 
from/to Wazuh. The API will have the following endpoints: 

•  /plugins/ - GET: retrieve a list of the enabled plugins. 

•  /plugins/ - POST: import a zipped plugin. 

•  /plugins/{plugin_id} - DELETE: disable and then re- 

move the plugin’s directory and files. 

•  /plugins/template-plugin.zip - GET: retrieve the tem- 
plate to create plugins, this becomes handy to use as a 
guide to create new plugins easily. 

Figure  9:  Plugins  Directory  Hierarchy. 

1  <decoder    name="DecoderNameForThePlugin"> 
2  <prematch>\.∗SOC_NES:  (\.+)</prematch> 
3  </decoder> 
4  <decoder    name="DecoderNameForThePlugin"> 
5  <parent>DecoderNameForThePlugin</parent> 
6  <regex>(TheNameOfThePlugin): (Value_1) (Value_2) 
7 
8  <order>pluginName,   val1,   val2,   val3</order> 
9  </decoder> 

(Value_3)</regex> 

Figure 10:  PPIDPS Decoder Template. 

"AlertLevelToBeTriggered"> 

1  <rule   id="ruleID_For_DecoderX"   level= 
2 
3  <decoded_as>DecoderNameForThePlugin</decoded_as> 
4  <description>TheNameOfThePlugin  has  been  triggered 
5  </description> 
6  <field   name="pluginName">TheNameOfThePlugin</field> 
7  <field  name="val1">The  Value  Of  val1  variable</field> 
8  <field  name="val2">The  Value  Of  val2  variable</field> 
9  <field  name="val3">The  Value  Of  val3  variable</field> 
10  <group>TheNameOfThePlugin</group> 
11  </rule> 

Figure 11:  PPIDPS Rule Template. 

The metadata.json will contain metadata about the plugin 
and will have a structure as the one shown in Fig. 12. 

The  id,  name,  and  description  represent  the  unique  id 
of the plugin, the given name to the plugin and a short de- 
scription about the plugin’s functionality, respectively.  The 
version reveals the version of the plugin and must be in in- 
cremental order. The enabled represents the current state of 

A. Shatnawi et al.:  Preprint submitted to Elsevier 

Page 12 of 21

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Adaptable Plug and Play SOC

where  it  will  ultimately  be  used.  Here,  every  added 
agent will be notified about the update. The directory 
will have the structure shown in Fig. 14. 
Every {ID}.json file will have all the enabled plugins 
for  this  agent.  The  structure  of  the  file  is  illustrated 
in Fig. 15, where the “ID” represents the identifier of 
the plugin to use. However, having the “version” vari- 
able available which caters for different versions of the 
same plugin for different use cases. 

Figure 13:  Plugins Active Response Hierarchy. 

•  /plugins/{plugin_id}.zip?size={size} - GET: 

–  plugin_id: the id of the plugin to be exported. 

–  size:  the size of the exported plugin can be full 
or minimal; the minimal size includes only the 
script.py  and  the  metadata.json,  which  are  in- 
tended for the agents since the daemon that runs 
on the agent device requires just the availability 
of these two files. 

•  /plugins/{plugin_id}.json  - GET,  POST:  retrieve  or 
update the plugin metadata e.g.  enabling the plugin, 
changing the agents list or version. 

•  /plugins/{plugin_id}/ar - POST: retrieve the arguments 

needed to run the active response scripts. 

4.6.1.  Enabling Plugins 

Whenever a new plugin is enabled (using the /plugins/ 
{plugin_id}.jsonendpoint) or when the plugins are declared 
as  enabled once  they  get  imported  unto  the system  (using 
the  /plugins/  endpoint),  the  following  actions  would  auto- 
matically take place: 

Figure  14:  The  Shared  Directory  Structure  and  The 
Distribution  of  The  Flag  Files. 

[ { "id": "0bab811ddc3345b8970be15ef64cb12d", 

"version": "0.0.1"}, 

{ "id": "3cd6bbc9ad8e4d908077f5a45462d647", 

"version": "0.1.0"} 

] 

Figure  15:  PPIDPS  Flag  File. 

1.  The local decoders and local rules of the Wazuh sys- 
tem, /var/ossec/etc/decoders/local_decoder.xml and 
/var/ossec/etc/rules/local_rules.xml, will be appended 
by decoders.xml and rules.xml, respectively, things that 
are provided by the enabled plugin. 

2.  The active-response/script.py file will be moved to the 

/var/ossec/active-response/plugins/ directory and will 
be named {pluginID}.py. 

3.  Wazuh manager will restart the wazuh-manager ser- 

vice to apply the changes. 

4.  For  every  agent  defined  in  the  agents’  list  at  meta- 
data.json, a new {ID}.json file will be pushed into the 
shared directory, /var/ossec/etc/shared/default/plugins, 
where  {ID}  represents  the  id  of  the  intended  agent 

4.6.2.  SOCreative Kibana Plugin 

To make the interaction with the API more convenient, 
we have embedded a web interface that is intended to inter- 
connect with the API natively into Kibana’s web interface. 
SOCreative Kibana Plugin is compatible with Kibana’s ver- 
sion 7.9.1. Using this interface, SOC engineers will be able 
to import new plugins, remove those unneeded, enable and 
disable existing ones, while updating others.  The main in- 
terface is shown in the Fig. 16.  Meanwhile, by clicking on 
the “Plugins” module, the window in Fig. 17 will appear. 

As shown in Fig. 17,  and by using (1),  the SOC team 
can view existing plugins. The “Enable” button can be used 
to enable or disable the corresponding plugin.  Whenever a 
plugin is disabled, the following actions occur: 

A. Shatnawi et al.:  Preprint submitted to Elsevier 

Page 13 of 21

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Adaptable Plug and Play SOC

Figure  16:  PPIDPS  Main  Interface. 

1.  The API will remove the decoders.xml and rules.xml 

contents from /var/ossec/etc/decoders/local_decoder. 
xml and /var/ossec/etc/rules/local_rules.xml files at the 
manager. 

2.  Restart Wazuh manager service to apply changes. 
3.  Remove the disabled plugin id from the agents JSON 

Figure 18:  PPIDPS Plugins Editing Interface. 

files at the shared directory /var/ossec/etc/shared/defaul 
plugins. 

t/ 

4.  The agents will be notified of the change and disable 

the plugin. 

Figure 17:  PPIDPS Plugins Interface. 

Furthermore,  the  SOC  team  can  download  the  plugin  and 
view it locally or remove the plugin entirely (which will trig- 
ger the same actions as disabling a plugin plus removing the 
plugins files) or just simply edit the plugin.  Using the edit 
module will readily open the tab as shown in Fig. 18. How- 
ever, by using this tab, SOC engineers can change the meta- 
data.json file contents directly.  The name, description, ver- 
sion, the agents’ list, and the code interval can be changed 
altogether.  Here,  whenever  the  agents  list  is  updated,  the 
following mathematical operations set will be applied: 

R = 0 − (N n 0) 

A = 0 − N 

Where R is the set of agents which will have the plu- 
gin removed, A is the set of agents that will have the plugin 
installed, 0 is the old agents set and N is the new agents set. 
Then the IDs defined in set A will be added to  /plugins- 
system/default/plugins with the plugin ID and version and 
automatically distributed to the agents by the daemons. The 
IDs defined in set R will be removed from the directory and 
automatically removed by the daemons from the agents. 

Lastly, (2) is used to download the template plugin lo- 
cally, and (3) is, then, used to import a new plugin as a zipped 
archive. Figure 19 shows the import module just referenced. 

Figure  19:  PPIDPS  Plugins  Importing  Interface. 

4.7.  Agent Daemon 

We  have  implemented  a  new  daemon  that  will  run  on 
the agents, using Python 3, called agentd. This daemon will 
be responsible for pulling  the scripts,  executing them,  and 
sending the resulting logs to the manager. 

4.7.1.  Structure 

The daemon will create the following directories and sub- 

directories to use them for its operations: 

1.  /shared/plugins:  This directory will receive the new 
plugin IDs, and their version numbers, which are in- 
tended to be used by the agent from the daemons. The 
data will be contained in a JSON file named by the ID 
of the agent. This file is a clone of the shared directory 
at the manager. 

2.  /plugin_download: This  directory  will  be  filled  by 
the activated plugins for the agent. Every plugin’s di- 
rectory will be named pursuant with its plugin ID. 

These directories will be automatically created by the dae- 
mon upon its initiation. For Windows, these will be created 
under  C:\Program  Files  (x86)\ossec-agent,  and  for  Linux 
they will be created under /var/ossec/etc/. 

4.7.2.  Installation 

To install or delete the agentd on the agents, the follow- 

ing command is used: 

user@nes# ./agentd.py <argument> 

A. Shatnawi et al.:  Preprint submitted to Elsevier 

Page 14 of 21

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Adaptable Plug and Play SOC

The argument can be “startup” to install itself and run 
as  a daemon. Also,  it  can  be  “delstartup” to  remove  itself 
and  disable  the  daemon.  The  daemon  installation  will  be 
fully automated, and will, by default, be configured to run 
during the deployment phase using the Autoconfig tool. The 
daemon will have the ability to identify the underlying op- 
erating system, be it Linux or Windows.  The difference in 
behavior is described below: 

•  In the case of Linux OS: 

1.  The path of the agents OSSEC directory will be 

set to /var/ossec. 

2.  The daemon will use the systemd to daemonize 
itself and run upon startup. The name of the dae- 
mon will be soc_plugin_system.service. 

3.  The resulting logs of the execution will be sent to 
Wazuh using Syslog and will be in the following 
format: 

MON DAY HH:MM:SS HOSTNAME USERNAME: 
SOC_NES: PLUGIN_NAME: MSG 

•  In the case of Windows OS: 

1.  The path of the agents OSSEC directory will be 

set to C:\Program Files (x86)\ossec-agent. 

2.  The daemon will use the scheduled tasks (schtasks) 
to persist and run itself upon startup. The name 
of the scheduled task will be SOC Plugin System. 
3.  The resulting logs of the execution will be logged 
at a file called “plugin_syslog.log”, which is lo- 
cated within the OSSEC directory.  The file will 
be  monitored  by  the  agent  daemons  by  adding 
the configuration in Fig. 20 into ossec.conf  and 
the log will be sent in the same Syslog format. 

1 

2 

3 

4 

<localfile> 

<location>plugin_syslog.log</location> 
<log_format>syslog</log_format> 

</localfile> 

Figure 20:  Windows Syslog File Configuration. 

4.7.3.  Retrieving New Plugins 

To avoid wasting network resources, the daemon will not 
be polling the Wazuh manager and asking for its {ID}.json 
and check on whether it has any updates; instead, the updates 
will be automatically pushed into the agents by utilizing the 
Wazuh daemons.  The agent will continuously read its local 
shared directory  contents (currently  every 3 seconds),  and 
whenever it spots a change, it will go through each plugin 
defined and compare the versions of the plugins to see if it 
must update any plugins or to pull new ones. Three cases are 
possible: 

1.  There is a totally new plugin: the plugin will run in a 

new process. 

2.  The new version is not equal to the old one:  the old 
version process will be terminated, and a new version 
will run as a new process. 

3.  The plugin is deleted,  where it is not intended to be 
used by the agent once more: the plugin’s process will 
be terminated. 

The agentd will be able to automatically get the Wazuh 
manager IP address from the ossec.conf file,and will be used 
to connect to the manager API. In order to run the new plu- 
gin, the daemon will fork a new process and pass the new 
plugin id and request the plugins from the API. The plug- 
ins will be shipped to agents in a zipped format; therefore, 
the agents will have to unzip the plugin and create the file 
structure locally. 

4.7.4.  Plugin Execution 

.  The daemon will use the Python’s subprocess module 
to execute script.py. The subprocess will run the plugin code 
every “interval” defined in the metadata.json and capture its 
output.  The script must print its output directly to the con- 
sole/stdout.  The output will be redirected by the agent dae- 
mon  without  any  special  communication  between  the  two 
processes.  Then, it will be analyzed and sent to the Wazuh 
manager. The output will exhibit the following form: 

LOG: The Log That Should Be Sent To SOC 
ARY: Arg1 Arg2 Arg3 ... 

Where  “LOG”  is  the  logs  that  will  be  sent  to  Wazuh, 
using  Syslog,  which  will  be  decoded  to  produce  the  cor- 
responding  alerts,  and  present  them  visually  on  the  dash- 
boards.  The Active Response Yes (ARY) will be sent as a 
POST  request  to  the  API’s  /{plugin_id}/ar  endpoint.  The 
Arg1, Arg2 and Arg3 will be sent to the Wazuh manager in 
order to be passed to the active response code which will ex- 
ecute any needed countermeasures on the Wazuh manager. 
Here,  the  arguments’  values  must  not  contain  any  spaces. 
The Active Response No (ARN) is reserved for future use. 
At this point, the script will further execute any counter mea- 
sures that are needed locally at the Wazuh agent machine to 
safeguard the machine against further threat. 

4.7.5.  PPIDPS Interaction Showcase 

Consider Fig. 21, which shows the possible interactions 
in the API and how they affect the Wazuh manager and the 
agents. 

Assume that the plugin system already possesses a plu- 

gin with an id of 0bab811d, which is currently disabled. 

The interactions will take place using the API’s web in- 
terface, which is embedded into Kibana.  The web interface 
will have a continually updated list of the installed plugins 
on the system via the /plugins/ API endpoint, where the SOC 
engineer can issue the desired changes and updates to those 
plugins or import new ones. 

The  effect of enabling  the  plugin  with  id 0bab811d  is 
shown  in  Blue. First,  in  (1),  using  the  web  interface. The 
user will enable the interface, which will result in sending 

A. Shatnawi et al.:  Preprint submitted to Elsevier 

Page 15 of 21

 
 
 
 
 
 
 
 
 
 
 
 
 
 
Adaptable Plug and Play SOC

a request to the /plugins/0bab811d.json to modify its meta- 
data.json, changing its “enabled” property to “true”. 

In (2), the local decoders and local alerts, which are part 
of the Analysis Engine, will be modified and appended by 
the ones defined in the plugin’s decoders.xml and rules.xml 
files. Here, the active-response script will be pushed onto its 
appropriate place /active-response/plugins, and be named by 
the id of the plugin; in this case, 0bab811d.py.  Lastly, the 
Wazuh manager service will be restarted, and the plugin is 
ready to use; hence, new {ID}.json files will be created at the 
shared directory – /shared/default/plugins - for every agent 
id defined in the “agents” element of metadata.json. Finally, 
the Wazuh daemons will execute their tasks and distribute 
them to the agents instructing them to use the plugins. 

The  retrieval  of  the  enabled  plugin  by  an  agent  (id  = 
002)  is  shown  in  Green. The  agent,  responsible  for  moni- 
toring any changes in its 002.json file will spot the changes 
once the manager has pushed the new JSON files into the 
shared directory. This is shown in step (1). In (2), the agent 
will send a request – /plugins/0bab811d.zip?size=minimal, 
to the API to download the plugin.  In (3), the API will re- 
spond by sending the plugin’s script and metadata in a zipped 
format.  In (4), the agent will create a directory for the plu- 
gin, named pursuant with its id, and unzip the plugin inside 
the directory. In (5), the delivered script.py will be executed 
by the gentd and consequently capture its output. The script 
will detect whether the system is being attacked by the type 
of attack that it is intended to detect and execute any possi- 
ble remediation actions to salvage the system. Lastly, in (6), 
the resulting output from executing the script will be sent by 
the agentd to the Wazuh manager.  The LOG will be sent to 
the analysis engine for further analysis and, in the process, 
triggering alerts that will be posted to the dashboards.  The 
ARY will be sent through a request – /0bab811d/ar  to the 
API, which will, in turn, pass it to the active response script 
and execute it (this is not shown in the figure to avoid making 
it messy) accordingly. 

A SOC engineer requesting to download the plugin with 
id 0bab811d, can accomplish that using the web interface. 
This  is  done  perhaps  to  modify  the  script  or  add  new  de- 
coders and rules. This is illustrated in purple. The web inter- 
face will send a request – /plugins/0bab811d.zip?size=full to 
the API, which will cause the system to send the entire plu- 
gin contents, in zipped format, as shown in (1). It then sends 
it to the SOC engineer for download, as shown in (2). 

In the figure,  a SOC engineer,  as marked in RED, has 
implemented a new plugin which he wants to import to the 
system  with  id  of  3cd6bbc9,  using  the  web  interface. The 
plugin would be imported as a zip file, which will cause a 
request – /plugins/  to the API with the zipped file as data. 
The Wazuh manager will receive the zipped plugin, create a 
directory using its id – 3cd6bbc9, unzip it to the same direc- 
tory location, and create the proper file structure, as shown 
in  (1)  and  (2).  If  the  plugin  is  enabled,  the  same  process 
described earlier (Blue) will take place. 

Figure 21:  The PPIDPS Workflow. 

4.7.6.  Essence of The Design 

As  is  readily  evident,  the  design,  and,  hence,  the  im- 
plementation, is very agile, cohesive, and is platform inde- 
pendent.  Further, the system can be expanded to work with 
more scripting languages easily; something commonly done 
to  meet  the  needs  of  different  security  engineers.  This  al- 
lows for exchange of the plugins between the various SOC 
teams  to  be  a  very  simple  and  seamless  process,  where  a 
SOC team can receive a set of plugins and are able to mod- 
ify them, including those of the triggered alerts’ levels; this 
will adapt to varying risk profiles and needs, as the plugin 
continues to execute!  In fact, this is particularly part of our 
plans to extend the plugin system with a web store, which 
we call a Security Operations Center Intrusion Detection and 
Prevention Plugins Store (SOC-IDPPS), which would con- 
tain hundreds of plugins that can detect and prevent possible 
threats where teams can also share plugins for various use 
cases; and, hence, enhance the security for any kind of or- 
ganization to meet its risk profiles.  The store will be fully 
embedded into the Wazuh web interface as well, making it 
an easy task to grab a plugin with a single mouse click. 

5.  Testing and Evaluation 

This section will go through the process of running the 
Autoconfig tool, providing the needed input and testing the 
deployed  environment  against  simple  attacks  to  show  that 
the environment is operating effectively.  Also, we will as- 
semble (design) a simple plugin on the PPIDPS in order to 
detect sophisticated attacks that may rely on zero-day vul- 
nerabilities. 

The environment we use in the testing is deployed in the 
Amazon Web Services (AWS) cloud and is shown in Fig. 22. 
The same environment is used in the tests conducted in 
all subsequent subsections. The environment is a distributed 
Wazuh deployment, where we have a separate server for each 
component;  a  Wazuh  Manager,  an  Elasticsearch,  and  the 
Kibana component. The environment also includes a limited 

A. Shatnawi et al.:  Preprint submitted to Elsevier 

Page 16 of 21

 
 
 
 
 
 
 
 
 
Adaptable Plug and Play SOC

set of two agents to test the effectiveness of our tools against 
both Linux and Windows 10 machines. The last component 
is  a  CISCO1  router  that runs  locally  as  a virtual  machine, 
which will also be used to test the auto-configuration pro- 
cess. 

Figure  22:  SOC  Environment  Topology  in  The  Cloud. 

In each test, we will mimic simple attack scenarios against 
the Linux  and Windows  agents  to  demonstrate  associated 
alert firing responses on Wazuh. 

5.1.  Deploying the Clusters and Agents 

First, and as precursor to deploying the system, the fol- 

lowing must be manually done/known: 

•  The SSH daemon must be installed and enabled on all 
the machines (servers and agents) and configured to 
accept SSH keys login. 

•  All the SSH keys must be gathered and added to the 

/creds directory of the Automation Engine file-structure. 

•  Python3 must be installed on all the machines. It is in- 
stalled by default on the latest Linux machines; how- 
ever, it must be installed manually on Windows agent 
machines and outdated Linux machines. 

•  The user should be aware of the IP addresses of the 

machines that will be deployed. 

•  The user who will use  the Autoconfig  tool needs to 
have Ansible packages installed prior to using the tool. 

At this point, we would be ready to run the formatting 
tool – formatter.py to create the applicable formatting to be 
fed into the Autoconfig tool. 

As shown in Fig. 23a,  the required IPs along with the 
SSH users and SSH key paths (hidden) were inserted into 
the tool that will result in the creation of the topology.txt, 
which would readily include the information in encrypted 
and proper formats.  Following this, we would be ready to 
run the Autoconfig tool, which will read the topology.txt file 
to initiate the deployment process. The deployment will start 
with Elasticsearch server installation and configuration as 

1We found that the predefined set of decoders delivered with Wazuh 
does not fully cover the different Cisco IOS log formats. Therefore, we had 
to manually alter these decoders to make the logs decoded and tested against 
the rule-set. 

shown  in  Fig.  23b.  This  will  be  followed  by  the  Kibana 
server installation and configuration as shown in Fig. 23c, 
and finally the deployment of the Wazuh Manager server as 
shown in Fig. 23d. 

With the deployment of Wazuh and configuration of its 
components, the tool will ask the users whether they would 
be interested in integrating the system with Slack, as a tick- 
eting system, and with VirusTotal, respectively.  Fig. 24 il- 
lustrates the process of approval to add both integrations. 

5.2.  Autoconfig Tool Performance 

Every component in the SOC will be handled by the ap- 
propriate  Ansible-Playbook.  Since  the  implemented  play- 
books  are  commonly  designed  with  a  level  of  intelligence 
to differentiate between the different platforms they run on, 
e.g., prior agent installation, the tool can readily determine 
whether the OS is Windows or Linux. Furthermore, the tool 
will also differentiate between various Linux distributions, 
e.g., CentOS, RedHat, Ubuntu, etc.  Moreover, the tool will 
have  a  total  error  probability  of  zero  opposite  the  deploy- 
ment  and  configuration  operations.  Nonetheless,  the  tool 
is usually prone to human typing errors,  since the format- 
ter.py  script  often  requires  manual  input  from  users.  The 
entire SOC deployment and configuration processes during 
the testing stage, have been found to consume approximately 
12 minutes towards a successful completion. The 12-minute 
period mentioned herein includes the time to download the 
packages/tools from their source,  time to install them,  and 
finally time needed to configure them.  Hence, the time per- 
formance of the tool is directly affected by the network band- 
width and the endpoints/servers’ specs. 

We, also, illustrate the ease with which system scaling is 
accomplished; for instance, through deployment of two more 
Linux agents,  we ran the formatter tool with the -a option 
for the purpose of adding agents and running the Autoconfig 
tool to deploy them. Fig. 25 reveals that the total number of 
active agents manifested amounts to four as reflected on the 
Wazuh web interface. 

5.3.  Testing Against SSH Login - Linux OS 

In this subsection, we demonstrate system response to an 
attempted login leveraging SSH, as shown in Fig. 26, to an 
nonexistent ‘test’ user on a Linux- based platform. As shown 
in Fig. 27, an alert with level 5 is generated on the Wazuh 
manager,  which  reveals the time the attempt was initiated, 
by which user, together with its place of origin. 

5.4.  Testing Against Backdoor - Windows OS 

In  this  subsection,  we  test  against  a  Backdoor  invasion 
on  a  Windows  platform  by  executing  a  malicious  file.  As 
soon as a Trojan or a Backdoor attack is executed, it will add 
itself with the name winhelp32.exe to the following path: 

C:\ProgramData\Microsoft\Windows\Start      Menu\Programs\Startup 

Any  executable  in  this  path  will  be  executed  following  a 
user’s  log  in.  The  trojan  would  immediately  need  to  root 
itself in the system. The special thing about this path is that 
it does not require a privilege to write any executable file 

A. Shatnawi et al.:  Preprint submitted to Elsevier 

Page 17 of 21

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Adaptable Plug and Play SOC

(a) Formatter Tool. 

(b) Elastic Search Deployment. 

(c) Kibana Deployment. 

(d) Wazuh Server Deployment. 

Figure  23:   Deploying  Wazuh  Automatically  for  Formatter  Tool,  Elastic  Search  Deploy‐ 
ment,Kibana Deployment, and Wazuh Server Deployment 

Figure  24:  Adding  Integrations  to  the  SOC  Stack. 

ing a level 5 alert. 

Figure 27:  Alert for SSH Login Fail on Linux Agent. 

Figure 25:  Agents Successfully Added ‐ Main Interface. 

Figure 26:  SSH Attempt. 

on it. For that reason, the trojan will use this directory to be 
launched unto the system. For this reason, this folder was in- 
herently set to be monitored in real-time by the File Integrity 
Monitoring (FIM) module in the Wazuh Windows agent dur- 
ing the configuration and deployment phase.  Fig. 28 shows 
that Wazuh instantly detects the file-system changes trigger- 

Figure 28:  Alert for Integrity Violation on Windows Agent. 

5.5.  VirusTotal Integration Test 

The  previously  tested  executable  is  a  slightly mutated 
version of the Bifrose Backdoor trojan citeBackdoor42:online. 
The Windows Defender Antivirus, alone, failed to detect this 
version of the malware when it was downloaded.  But since 
we had added the VirusTotal integration to the SOC stack, 
any FIM triggered alert will also cause the modified files to 
be passed to and scanned by VirusTotal.  The mutated mal- 
ware was detected by 45 Antivirus engines on VirusTotal. 

A. Shatnawi et al.:  Preprint submitted to Elsevier 

Page 18 of 21

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
This is illustrated in Fig. 29. From the figure, a detailed alert 
manifestation is evident opposite the malware caught. 

status, which would readily be changed to ‘Closed’ upon re- 
solving the issue. 

Adaptable Plug and Play SOC

Figure 29:  Alert due to Malware Detection by VirusTotal. 

5.6.  Testing Against Configuration Changes - 

Cisco Router 

To mimic a test scenario against the Cisco router, we had 
created an SSH login with the name admin. Any configura- 
tion attempt by the new user (and any other user), using the 
command “configure terminal” to access the Global Con- 
figuration Mode on Cisco IOS, will result in sending a log 
that triggers an alert on Wazuh. Following a successful SSH 
login to the Cisco router an alert is generated and is shown 
in Fig. 30 

Figure 30:  Alert Generated due to Configurations Change At‐ 
tempt. 

5.7.  Real-World Attacks Test 

It has been found that our IP addresses for our Amazon 
AWS  servers  were  being  SSH  brute-forced  by  distributed 
bots. Fig. 31 shows the total number of alerts generated due 
to brute-force attacks. 

Figure  31:  Total  Authentication  Failure  Alerts. 

5.9.  Programmable Plugin-based IDPS Test 

Our plugin architecture serves as an extra layer of pro- 
tection between the kernel layer and the user-space layer.  It 
will hook and manipulate the system to identify the “read” 
operations on specific files.  In our case, the plugin is pro- 
grammed to generate alerts each time the PASSWD file is ac- 
cessed successfully. Furthermore, it is programmed to create 
an alert and trigger the active response if the SHADOW file 
is accessed.  In connection with the active response mecha- 
nism, it is programmed to send emails reporting the security 
event that took place.  The plugin can easily be modified to 
be activated on the “writing” operation or even on querying 
the file’s size or name. 

To test our programmable plugin-based IDPS, we started 
out by importing the ZeroDayFileWatch plugin into our SOC. 
After  the  plugin  is  imported  and  its  status  is  enabled,  we, 
also,  considered  mimicking  the  “vsftpd”  vulnerability  as  a 
zero-day vulnerability.  We used Kali Linux and Metasploit 
to  perform  our  attack  by  setting  the  required  configuration 
using Kali and Metasploit. The vulnerability being exploited 
is illustrated in Fig. 32a. Following the read operation of the 
PASSWD file, leveraging the cat command, an alert is im- 
mediately generated as shown in Fig. 32b.  This alert serves 
as an indication of system intrusion.  However, the plugin is 
programmed just to set an alert of level 10 if the PASSWD 
file is read, and in the case of a shadow file read, it will set 
an alert with level 15 and activate the active-response code. 
The active-response code will, in turn, generate an alert and 
send an email to the SOC people as shown in Figs. 32c and 
32d. 

It  is  worthy  of  noting,  however,  that  in  our  test  case, 
the plugin  was  designed to detect  intrusions based on  any 
file system read operation executed  on numerous sensitive 
files.  Meanwhile, another design can be contrived:  for in- 
stance,  a  plugin  can  detect  intrusions  commensurate  with 
TCP/UDP connection tables for susceptible and monitored 
servers. This can be done by hooking the connection system 
calls; i.e., hooking the “connect”, “accept”, and “socket” ker- 
nel functions. If any of these functions are called under cer- 
tain conditions, an alert or/and active response would readily 
take place. 

6.  Conclusion 

5.8.  Ticketing System Test 

Upon adding the Slack integration, the Autoconfig tool is 
used to configure the system to issue an alert for any level- 
5 threat, or above, automatically to Slack.  These alerts will 
be further investigated by SOC analysts, and where they are 
able to identify any suspicious irregularities, they would read- 
ily be able to instantly open a ticket directly with the resident 
engineers at the organization. As a result of our test, a ticket 
created for an alert previously is pushed to Slack, where the 
SOC analyst reported a need for further investigation.  The 
ticket, as assigned to a SOC analyst, was issued with ‘Open’ 

Results  presented  in  this  paper  have  addressed  the  de- 
velopment of a low-cost, fully adaptive, plug-and-play, fully 
operating Security Operations Center (SOC). Automation is 
simply one part of a much-needed effort to shore up SOC 
effectiveness, and it certainly offers an essential component 
that can help make a big difference in the process.  Conse- 
quently, automation for low-risk, high-yield tasks has been 
provided.  Meanwhile, other parts have also been addressed 
with the purpose of contriving a new SOC design with the 
necessary software and tools onboard to achieve an adaptive 
security operations center. Building an adaptable system to 

A. Shatnawi et al.:  Preprint submitted to Elsevier 

Page 19 of 21

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Adaptable Plug and Play SOC

(a) Matasploit Exploit. 

(b) PASSWD File Alert. 

(c) Shadow File Alert. 

(d) Active Response Email Notification. 

Figure 32: Programmable Plugin‐based IDPS Test Scenarios 

meet any organizational deployment needs is considered the 
project’s core goal. We have discussed in detail our proposed 
framework which is used to deploy the SOC and extend its 
components with powerful horizontal scalability techniques; 
all within few minutes and with no possibilities for human 
error. Additionally, we have demonstrated the adaptability in 
terms of budgeting aspects, so that any organization would 
be able to access it as an open-source security solution. 

Furthermore,  to  handle  the  diversity  of  organizational 
threats and risk-profiles, a one-of-a-kind feature, which we 
have dubbed a “Programmable Plugin-based Intrusion De- 
tection and Prevention System (PPIDPS)” was introduced. 
Using the PPIDPS will further offer the ability to add any 
tool to the monitored devices while also getting logs that can 
trigger alerts when something goes wrong.  In other words, 
the SOC is no longer a static module with fixed protection 
criteria. This gives an organization the ability to detect zero- 
day  vulnerabilities  and  customize  the  SIEM.  As  such,  the 
system  is  made  fully  programmable  to  meet  the  organiza- 
tions and risk-profiles set by the security engineers.  More- 
over, the PPIDPS is offered in a plugin-based environment 
making it the first system of its kind in enabling risk-profile, 
and  threat  mitigations  between  SOCs  across  the  globe  all 
without  limits.  The  system  can  activate  a  programmable 
active-response; whenever an anomaly or threat is detected, 
the active-response code will run on the Wazuh Manager de- 
vice and execute any needed counter tasks. The plugin intro- 
duced is fully programmable; a security engineer can readily 
design the protection criteria that would execute the proper 
incident handling mechanism, as appropriate, where all that 
is done aboard the agent device itself. 

As future work, We are planning establish an online plat- 
form  called  Security  Operations  Center  -  Intrusion  Detec- 
tion And Prevention Plugins Store (SOC-IDPPS), where the 
SOC security engineers and analysts can push their custom 
plugins,  which  they  frequently  use  with  the  implemented 
(PPIDPS). These plugins can be added to Wazuh on the fly 

through the web interface, where the users can see the up- 
dated and newly added plugins as they are pushed.  Further- 
more, these plugins will be tested to ensure their functional- 
ity and rated and reviewed by the community. 

References 
[1]  Agyepong,  E.,  Cherdantseva,  Y.,  Reinecke,  P.,  Burnap,  P.,  2020. 
Challenges and performance metrics for security operations center an- 
alysts: a systematic review. Journal of Cyber Security Technology 4, 
125–152. 

[2]  Aijaz, L., Aslam, B., Khalid, U., 2015.  Security operations center — 

a  need  for  an  academic  environment,  pp.  1–7.  doi:10.1109/WSCNIS.  
2015.7368297. 

[3]  Axon, L., Alahmadi, B., Nurse, J., Goldsmith, M., Creese, S., 2018. 
Sonification in security operations centres:  what do security practi- 
tioners think? . 

[4]  Axon, L., Happa, J., Rensburg, A., Goldsmith, M., Creese, S., 2019. 
Sonification  to  support  the  monitoring  tasks  of  security  operations 
centres.  IEEE  Transactions  on  Dependable  and  Secure  Computing 
PP,  1–1.  doi:10.1109/TDSC.2019.2931557. 

[5]  citybasebrooks,  2018.  Siem  in  a  can  (siac).  URL:  https://github.  

com/citybasebrooks/SIAC. 

[6]  Crémilleux, D., Bidan, C., Majorczyk, F., Prigent, N., 2018. Enhanc- 
ing collaboration between security analysts in security operations cen- 
ters, in: CRiSIS. 

[7]  Crooks,  D.,  Vâlsan,  L.,  2019.  Building  a  minimum  viable  security 

operations  centre  for  the  modern  grid  environment,  p.  010.  doi:10.  
22323/1.351.0010. 

[8]  Demertzis, K., Kikiras, P., Tziritas, N., Sanchez, S., Iliadis, L., 2018. 
The  next  generation  cognitive  security  operations  center:  Network 
flow forensics using cybersecurity intelligence. Big Data and Cogni- 
tive Computing 2.  doi:10.3390/bdcc2040035. 

[9]  Demertzis, K., Tziritas, N., Kikiras, P., Sanchez, S., Iliadis, L., 2019. 
The  next  generation  cognitive  security  operations  center:  Adaptive 
analytic  lambda  architecture  for  efficient  defense  against  adversar- 
ial  attacks.  Big  Data  and  Cognitive  Computing  3,  6.  doi:10.3390/  
bdcc3010006. 

[10]  Feng,  C.,  Wu,  S.,  Liu,  N.,  2017.  A  user-centric  machine  learning 

framework for cyber security operations center, pp. 173–175. doi:10.  
1109/ISI.2017.8004902. 

[11]  Fletcher Richman, T.R., Rashidov, K., 2017.  Halp ticketing.  URL: 

https://halp.com. 

A. Shatnawi et al.:  Preprint submitted to Elsevier 

Page 20 of 21

 
 
 
 
 
 
 
 
 
 
 
 
Adaptable Plug and Play SOC

[12]  GAO, U., 2019. Federal information security, in: Agencies and OMB 
Need to Strengthen Policies and Practices, United States Government 
Accountability Office. pp. 13–14. 

[13]  Gerhards, R., 2009.  The Syslog Protocol.  RFC 5424. RFC Editor. 

Https://www.rfc-editor.org/rfc/rfc5424.txt. 

[14]  Hussain, S., Ahmad, M.B., Ghouri, S.S.U., 2021. Advance persistent 
threat—a systematic review of literature and meta-analysis of threat 
vectors. Advances in Computer, Communication and Computational 
Sciences , 161–178. 

vention and handling for desktops and laptops.  URL: https://csrc.  
nist.gov/publications/detail/sp/800-83/rev-1/final. 

[39]  Stefanova,  D.,  2020.  The  2020  must-know  security    breach 
statistics  |  logsentinel  siem.  https://logsentinel.com/blog/    2020-
data-breach-statistics/.  (Accessed  on 03/03/2021). 

[40]  TEAM,  O.P.,  2008.  Ossec  -  world’s  most  widely  used  host  intru- 
sion  detection  system  -  hids.  https://www.ossec.net/.  (Accessed  on 
05/18/2020). 

[41]  Wijaya,  J.,  2018.   Network automation with ansible.   URL:  https: 

[15]   Inc., W., 2016.   Wazuh ∙ the open source security platform.   https: 

//osf.io/u8cdm. 

[42]  Ylonen,  T.,  Lonvick,  C.,  2006.  The  Secure  Shell  (SSH)  Trans- 
port  Layer  Protocol.  RFC  4253.  RFC  Editor.  Https://www.rfc- 
editor.org/rfc/rfc4253.txt. 

//wazuh.com/.  (Accessed on 11/12/2020). 

[16]  Information  Sciences  Institute,  U.o.S.C.,  1981.  TRANSMISSION 
CONTROL PROTOCOL.  RFC 793. RFC Editor.  Https://www.rfc- 
editor.org/rfc/rfc793.txt. 

[17]  Jacobs, P., Arnab, A., Irwin, B., 2013.  Classification of security op- 

eration centers, pp. 1–7.  doi:10.1109/ISSA.2013.6641054. 

[18]  Janos, F., Nguyen, P.D., 2018. Security concerns towards security op- 
erations centers, pp. 000273–000278. doi:10.1109/SACI.2018.8440963. 
[19]  Kent, K., Souppaya, M., 2006. Sp 800-92, guide to computer security 

log  management  |  csrc.  https://csrc.nist.gov/publications/detail/  
sp/800-92/final.  (Accessed on 10/27/2020). 

[20]  Lin, T., Zhong, C., Yen, J., Liu, P., 2018.  Retrieval of Relevant His- 
torical Data Triage Operations in Security Operation Centers: Essays 
Dedicated to Sushil Jajodia on the Occasion of His 70th Birthday. pp. 
227–243.    doi:10.1007/978-3-030-04834-1_12. 

[21]  Loope, J., 2011.  Managing infrastructure with puppet:  configuration 

management at scale. " O’Reilly Media, Inc.". 

[22]  Mansfield-Devine, S., 2016. Creating security operations centres that 
work.   Network  Security  2016,  15–18.   doi:10.1016/S1353-4858(16) 
30049-6. 

[23]  Miloslavskaya, N., 2016.  Security operations centers for information 

security incident management.  doi:10.1109/FiCloud.2016.26. 

[24]  Miloslavskaya,  N.,  2018.   Analysis of siem systems and their usage 
in security operations and security intelligence centers, pp. 282–288. 
doi:10.1007/978-3-319-63940-6_40. 

[25]  Mutemwa, M., Mtsweni, J., Zimba, L., 2018.  Integrating a security 
operations centre with an organization’s existing procedures, policies 
and  information  technology  systems,  pp.  1–6.  doi:10.1109/ICONIC.  
2018.8601251. 

[26]  New, D., Rose, M., 2001.  Reliable Delivery for syslog.  RFC 3195. 

RFC Editor. Https://www.rfc-editor.org/rfc/rfc3195.txt. 

[27]  Onwubiko, C., 2015. Cyber security operations centre: Security mon- 
itoring for protecting business and supporting cyber defense strategy, 
pp.  1–10.  doi:10.1109/CyberSA.2015.7166125. 

[28]  Pallets, 

. 

Jinja 

documentation 

(2.11.x). 

https://jinja.  

palletsprojects.com/en/2.11.x/.  (Accessed  on  05/05/2021). 

[29]  Paul  Cichonski,  Thomas  Millar,  T.G.,  Scarfone,  K.,  2012.  Com- 

puter security incident handling guide.  URL: https://csrc.nist.gov/  
publications/detail/sp/800-61/rev-2/final. 

[30]  Preston, S., 2016.  Configuration management using chef, in:  Using 

Chef with Microsoft Azure. Springer, pp. 1–28. 

[31]  Ramírez,  S.,  2019.  Fastapi  framework.  https://fastapi.tiangolo.  

com/. (Accessed on 04/20/2021). 

[32]  Red  Hat,  I.,  2012a.  Ansible  official  website.  URL:  https://www.  

ansible.com. 

[33]  Red Hat,  I.,  2012b.   Encrypting content with ansible-vault.   URL: 
https://docs.ansible.com/ansible/latest/user_guide/vault.html. [34]  

Ronacher, A., 2008.  Jinja2 templating engine.  URL: https://jinja. 

palletsprojects.com/en/2.11.x. 

[35]  Scarfone,  K.,  Mell,  P.,  2007.  Guide  to  intrusion  detection  and  pre- 

vention  systems  (idps).  URL:  https://csrc.nist.gov/publications/  
detail/sp/800-94/final. 

[36]  Schinagl, S., Schoon, K., Paans, R., 2015. A framework for designing 

a security operations centre (soc), pp. 2253–2262. doi:10.1109/HICSS.  
2015.270. 

[37]  Slack Technologies, I., 2013.   Slack official website.   URL: https: 

//slack.com. 

[38]  Souppaya, M., Scarfone, K., 2013.  Guide to malware incident pre- 

A. Shatnawi et al.:  Preprint submitted to Elsevier 

Page 21 of 21

 
 
 
