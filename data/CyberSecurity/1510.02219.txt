On Summarizing Graph Streams

Nan Tang

Qing Chen∗ Prasenjit Mitra

Qatar Computing Research Institute
{ntang, qchen, pmitra}@qf.org.qa

5
1
0
2

t
c
O
8

]

B
D
.
s
c
[

1
v
9
1
2
2
0
.
0
1
5
1
:
v
i
X
r
a

ABSTRACT
Graph streams, which refer to the graph with edges being
updated sequentially in a form of a stream, have wide ap-
plications such as cyber security, social networks and trans-
portation networks. This paper studies the problem of sum-
marizing graph streams. Speciﬁcally, given a graph stream
G, directed or undirected, the objective is to summarize G as
SG with much smaller (sublinear) space, linear construction
time and constant maintenance cost for each edge update,
such that SG allows many queries over G to be approxi-
mately conducted eﬃciently. Due to the sheer volume and
highly dynamic nature of graph streams, summarizing them
remains a notoriously hard, if not impossible, problem. The
widely used practice of summarizing data streams is to treat
each element independently by e.g., hash- or sampling-based
method, without keeping track of the connections between
elements in a data stream, which gives these summaries
limited power in supporting complicated queries over graph
streams. This paper discusses a fundamentally diﬀerent phi-
losophy for summarizing graph streams. We present gLava, a
probabilistic graph model that, instead of treating an edge (a
stream element) as the operating unit, uses the ﬁner grained
node in an element. This will naturally form a new graph
sketch where edges capture the connections inside elements,
and nodes maintain relationships across elements. We dis-
cuss a wide range of supported graph queries and establish
theoretical error bounds for basic queries.

1.

INTRODUCTION

Massive graphs arise in many applications e.g., network
traﬃc data, social networks, citation graphs, and trans-
portation networks. These graphs are highly dynamic: Net-
work traﬃc data averages to about 109 packets per hour
per router for large ISPs [18]; Twitter sees 100 million users
login daily, with around 500 millions tweets per day [1].

∗Qing is a QCRI intern, from Fudan University, China.

.

Example 1: We consider a graph stream1 as a se-
quence of elements (x, y; t), which indicates that the
edge (x, y) is encountered at time t. A graph stream
h(a, b; t1), (a, c; t2), · · · (b, a; t14)i is depicted in Fig. 1, where
all timestamps are omitted for simplicity. Each edge is as-
✷
sociated with a weight, which is 1 by default.

Queries over big graph streams have many important ap-
plications, e.g., monitoring cyber security attack and traﬃc
networks. Unfortunately, in a recent survey for businesses in
analyzing big data streams [2], although 41% of respondents
stated that the ability to analyze and act on streaming data
in minutes was critical, 67% also admitted that they do not
have the infrastructure to support that goal. The situation
is more complicated and challenging when handling graph
streams. It poses unique space and time constraints on stor-
ing, summarizing, maintaining and querying graph streams,
due to its sheer volume, high velocity, and the complication
of various queries.

In fact, for the applications of data streams, fast and ap-
proximated answers are often preferred than exact answers.
Hence, sketch synopses have been widely studied for esti-
mations over data streams. Although they allow false posi-
tives, the space savings normally prevail over this drawback,
when the probability of an error is suﬃciently low. There
exist many sketches: AMS [5], Lossy Counting [23], Count-
Min [10], Bottom-k [9] and gSketch [31]. They have also
been used in commercial tools, e.g., CountMin is in Cisco
OpenSOC2 cyber security analytics framework.
Example 2: Consider the graph stream in Example 1 and
Fig. 1. CountMin treats each element in the stream indepen-
dently, and maps them to w hash buckets, by using the pairs
of node labels as hash keys. Assume there are w = 4 hash
buckets. The set of values to be hashed is {ab, ac, bc, · · · },
where the value ab is to concatenate two node labels for the
element (a, b; t1). A hash function is used to put these val-
ues in 4 buckets, i.e., h(·) → [1, 4], as shown in Fig. 2. The
ﬁrst bucket aggregates the weights of values starting with
a and e, and similar for other buckets. Note that, for sim-
plicity, we use only one hash function for illustration.
In
fact, CountMin uses d pairwise independent hash functions
to alleviate the problem of hash key collisions.

CountMin, and its variant gSketch, can be used for esti-
mating certain types of graph queries. (a) Edge query. It
can estimate the weight of particular edges: 5 for ab, and 1

1Without loss of generality, we use a directed graph for il-
lustration. Our method can also work on undirected graphs.
2http://opensoc.github.io/

 
 
 
 
 
 
a

1

b

d

1

1

1

1

1

j❚❚❚❚❚❚❚❚❚❚❚❚❚❚❚❚❚❚❚❚❚
d❏❏❏❏❏❏❏❏❏❏❏
$❏❏❏❏❏❏❏❏❏❏❏
✼✼✼✼✼✼✼✼✼✼✼✼✼✼✼✼
j❚❚❚❚❚❚❚❚❚❚❚❚❚❚❚❚❚❚❚❚❚
$■■■■■■■■■■■
:✉✉✉✉✉✉✉✉✉✉✉

e

1

1

1

1

1

1

1

c

1

/ f

g

Figure 1: A sample graph stream

h(·)
I

5
ab, ac, ed, eb, ef

5
bc, bd, ba, bf, f a

3
ce, cf, gb

1
dg

Figure 2: A hash-based sketch

3

2

1

I(ae)

1

II(bf )

2

1

1

1

1

1

IV (d)

- III(cg)

Figure 3: An example of our proposed sketch

for dg. (b) Aggregate subgraph query. It can answer queries
like: What is the aggregated weight for a graph with two
edges (a, c) and (c, e)? It will give 5 + 3 = 8 as the esti-
✷
mated weight for the graph.

Example 2 shows the applicability of CountMin on some
query estimation over graph streams. However, their (and
other sketch synopses’) main weakness is that they are el-
ement (or edge) independent. That is, they fall short of
maintaining the connections between streaming elements,
thus fail in estimating many important queries, such as node
monitoring, path queries (e.g., reachability) and more com-
plicated graph analytics (see Section 3.4 for a detailed dis-
cussion).

Challenges. Designing a graph sketch to support a wide
range of applications requires to satisfy the following con-
(1) Space constraint: sublinear upper bound is
straints.
needed. (2) Time constraint: linear construction time is re-
quired. Noticeably, this is stronger than the constraint with
(3) Maintenance
only a constant passes over the stream.
constraint: to maintain it for one element insertion/deletion
should be in constant time. (4) Element connectivity: the
connectivity between elements should be maintained.

To this end, we present gLava, a novel generalized graph
sketch to meet the above required constraints.
Instead of
treating elements (edges) in a graph stream independently
as those prior art, the key idea of gLava is to compress a
graph stream based on a ﬁner grained item, the node in a
stream element.

Example 3: Again, consider the graph stream in Fig. 1.
Our proposed sketch is shown in Fig. 3. For each edge
(x, y; t), gLava uses a hash function to map each node la-

bel to 4 node buckets i.e., h′(·) → [1, 4]. Node I is the
summary of two node labels a and e, assuming h′(a) = 1
and h′(e) = 1. The other compressed nodes are computed
similarly. The edge weight denotes the aggregated weights
from stream elements, e.g., the number 3 from node I to II
means that there are three elements as (x, y; t) where the
✷
label of x (resp. y) is a or e (resp. b or f ).

Remark. (1) It is readily to see that estimation for edge fre-
quencies, as what CountMin supports, can be easily achieved
by gLava. Better still, the idea of using multiple hash func-
tions to alleviate hash collisions can be easily applied to
gLava. (2) gLava is represented as a graph, which captures
not only the connections inside elements, but also the links
across elements. These make it an ideal sketch to support
a much wider range of applications, compared with those
prior art (see Section 3.4 for a discussion).

Contributions. This paper presents a novel graph sketch
for supporting a wide range of graph stream applications.

(1) We introduce gLava, a novel graph sketch (Section 3.3).
As shown in Fig. 3, the proposed sketch naturally preserves
the graphical connections of the original graph stream,
which makes it a better ﬁt than traditional data stream
sketches to support analytics over graph streams. We fur-
ther categorize its supported graph queries (Section 3.4).

(2) We describe algorithms to process various graph ana-
lytics on top of gLava (Section 4). The general purpose is,
instead of proposing new algorithms, to show that gLava can
easily be used to support many graph queries, and oﬀ-the-
shelf graph algorithms can be seamlessly integrated.

(3) We perform theoretical analysis to establish error bounds
for basic queries, speciﬁcally, the edge frequency estimation
and point query estimation (Section 5).

(4) We describe implementation details (Section 6). This is
important to ensure that the new sketch can be constructed
and maintained under the hard time/space constraints to
support streaming applications. Moreover, we propose to
use non-square matrices, using the same space, to improve
the accuracy of estimation.

In this history of graph problems over streams, unfortu-
nately, most results showed that a large amount of space is
required for complicated graph problems [4,24]. The present
study ﬁlls a gap in the literature by analyzing various graph
problems in a small amount of space. We thus contend that
gLava will shed new light on graph stream management.

Organization. Section 2 discusses related work. Section 3
deﬁnes the new sketch and queries to be solved. Section 4
describes algorithms using gLava. Section 5 makes theoret-
ical analysis. Section 6 describes implementation details.
Finally, Section 7 concludes the paper with a summary of
our ﬁndings.

2. RELATED WORK

We categorize related work as follows.

Sketch synopses. Given a data stream, the aim of sketch
synopses is to apply (linear) projections of the data into
lower dimensional spaces that preserve the salient features
of the data. A considerable amount of literature has been
published on general data streams such as AMS [5], lossy
counting [23], CountMin [10] and bottom-k [9]. The work

t
t
(cid:15)
(cid:15)
/
/
(cid:27)
(cid:27)
$
4
4
$
O
O
(cid:15)
(cid:15)
d
j
:
/
j
v
v
(cid:7)
(cid:7)
(
(
(cid:23)
(cid:23)
7
7
'
'
-
l
l
h
h
@
@
gSketch [31] improves CountMin for graph streams, by as-
suming that data samples or query samples are given. Bloom
ﬁlters have been widely used in a variety of network problems
(see [7] for a survey). There are also sketches that maintain
counters only for nodes, e.g., using a heap for maintaining
the nodes the largest degrees for heavy hitters [11].

As remarked earlier, gLava is more general, since it main-
tains connections inside and across elements, without assum-
ing any sample data or query is given. None of existing
sketches maintains both node and edge information.

Graph summaries. Summarizing graphs has been widely
studied. The most proliﬁc area is in web graph compression.
The papers [3, 27] encode Web pages with similar adjacency
lists using reference encoding, so as to reduce the number
of bits needed to encode a link. The work [25] groups Web
pages based on a combination of their URL patterns and k-
means clustering. The paper [13] compresses graphs based
on speciﬁc types of queries. There are also many clustering
based methods from data mining community (see e.g., [19]),
with the basic idea to group similar nodes together.

These data structures are designed for less dynamic

graphs, which are not suitable for graph stream scenarios.

Graph pattern matching over streams. There have been sev-
eral work on matching graph patterns over graph streams,
based on either the semantics of subgraph isomorphism [8,
15, 30] or graph simulation [26]. The work [30] assumes that
queries are given, and builds node-neighbor tree to ﬁlter false
candidate results. The paper [15] leverages a distributed
graph processing framework, Giraph, to approximately eval-
uate graph quereis. The work [8] uses the subgraph distri-
butional statistics collected from the graph streams to opti-
mize a graph query evaluation. The paper [26] uses ﬁltering
methods to ﬁnd data that potentially matches for a speciﬁc
type of queries, namely degree-preserving dual simulation
with timing constraints.

Firstly, all the above algorithms are designed for a certain
type of graph queries. Secondly, most of them assume the
presence of queries, so they can build indices to accelerate.
In contrast, gLava aims at summarizing graph streams in a
generalized way, so as to support various types of queries,
without any assumption of queries.

Graph stream algorithms. There has also been work on al-
gorithms over graph streams (see [24] for a survey). This
includes the problems of connectivity [14], trees [28], span-
ners [12], sparsiﬁcation [20], counting subgraphs e.g., trian-
gles [6,29]. However, they mainly focus on theoretical study
for best approximation bound, mostly on O(n polylog n)
space, with one to multiple passes over the data stream.

In fact, gLava is a friend, instead a competitor, of them.
As will be seen later (Section 4), gLava can treat existing
algorithms as black-boxes to help solve existing problems.

Distributed graph systems. Many distributed graph comput-
ing systems have been proposed to conduct data processing
and data analytics in massive graphs, such as Pregel [22], Gi-
raph3, GraphLab [21], Power-Graph [16] and GraphX [17].
They have been proved to be eﬃcient on static graphs,
but are not ready for doing analytics over big graph streams
with real-time response. In fact, they are complementary to
and can be used for gLava in distributed settings.

3. GLAVA AND SUPPORTED QUERIES

We ﬁrst deﬁne graph streams (Section 3.1) and state the
studied problem (Section 3.2). We then introduce our pro-
posed graph sketch model (Section 3.3). Finally, we discuss
the queries supported by our new sketch (Section 3.4).

3.1 Graph Streams

A graph stream is a sequence of elements e = (x, y; t)
where x, y are node identiﬁers (labels) and edge (x, y) is
encountered at time-stamp t. Such a stream,

G = he1, e2, · · · , emi

naturally deﬁnes a graph G = (V, E) where V is a set of
nodes and E = {e1, · · · , em}. We write ω(ei) the weight for
the edge ei, and ω(x, y) the aggregated edge weight from
node x to node y. We call m the size of the graph stream,
denoted by |G|.

Intuitively, the node label, being treated as an identiﬁer,
uniquely identiﬁes a node, which could be e.g., IP addresses
in network traﬃc data or user IDs in social networks. Note
that, in the graph terminology, a graph stream is a multi-
graph, where each edge can occur many times, e.g., one IP
address can send multiple packets to another IP address.
We are interested in properties of the underlying graph. The
causes a main challenge with graph streams where one nor-
mally does not have enough space to record the edges that
have been seen so far. Summarizing such graph streams in
one pass is important to many applications. Moreover, we
do not explicitly diﬀerentiate whether (x, y) is an ordered
pair or not. In other words, our approach applies naturally
to both directed and undirected graphs.

For instance, in network traﬃc data, a stream element ar-
rives at the form: (192.168.29.1, 192.168.29.133, 62, 105.12)4,
where node labels 192.168.29.1 and 192.168.29.133 are IP
addresses, 62 is the number of bytes sent from 192.168.29.1
to 192.168.29.133 in this captured packet (i.e., the weight of
the directed edge), and 105.12 is the time in seconds that
this edge arrived when the server started to capture data.
Please see Fig. 1 for a sample graph stream.

3.2 Problem statement

The problem of summarizing graph streams is, given a
graph stream G, to design another data structure SG from
G, such that:

1. |SG| ≪ |G|: the size of SG is far less than G, preferably

in sublinear space.

2. The time to construct SG from G is in linear time.

3. The update cost of SG for each edge insertion/deletion

is in constant time.

Intuitively, a graph stream summary has to be built and
maintained in real time, so as to deal with big volume and
In fact, the Count-
high velocity graph stream scenarios.
Min [23] and its variant gSketch [31] satisfy the above con-
ditions (see Example 2 for more details). Unfortunately, as
discussed earlier, CountMin and gSketch can support only
limited types of graph queries.

3http://giraph.apache.org

4We omit port numbers and protocols for simplicity.

3.3 The gLava Model

The graph sketch. A graph sketch is a graph SG(V, E ),
where V denotes the set of vertices and E its edges. For ver-
tex v ∈ V, we simply treat its label as its node identiﬁer (the
same as the graph stream model). Each edge e is associated
with a weight, denoted as ω(e).

In generating the above graph sketch SG from a graph
G, we ﬁrst set the number of nodes in the sketch, i.e., let
|V| = w. For an edge (x, y; t) in G, we use a hash function
h to map the label of each node to a value in [1, w], and the
aggregated edge weight is calculated correspondingly.

Please refer to Fig. 3 as an example, where we set w = 4.

Discussion about edge weight. The edge weight for an edge e
in the graph sketch is computed by an aggregation function
of all edge weights that are mapped to e. Such an aggre-
gation function could be min(·), max(·), count(·), average(·),
sum(·) or other functions. In this paper, we use sum(·) by
default to explain our method. The other aggregation func-
tions can be similarly applied. In practice, which aggrega-
tion function to use is determined by applications. For a
more general setting that requires to maintain multiple ag-
gregated functions in a graph sketch, we may extend our
model to have multiple edge weights e.g., ω1(e), · · · , ωn(e),
with each ωi(e) corresponds to an aggregation function.

Remark. One may observe that the graph sketch model is
basically the same as the graph stream model, with the main
diﬀerence that the time-stamps are not maintained. This
makes it very useful and applicable in many scenarios when
querying a graph stream for a given time window. In other
words, for a graph analytics method M that needs to run
on a streaming graph G, denoted as M (G), one can run it
on its sketch SG, i.e., M (SG), to get an estimated result,
without modifying the method M .

Example 4: Consider the graph stream in Fig 1 and its
sketch in Fig. 3. Assume that query Q1 is to estimate the
aggregated weight of edges from b to c. In Fig. 3, one can
map b to node II, c to node III, and get the estimated
weight 1 from edge (II, III), which is precise. Now consider
Q2, which is to compute the aggregated weight from g to b.
One can locate the edge (III, II), and the estimated result
is 2, which is not accurate since the real weight of (g, b) in
✷
Fig 1 is 1.

The above result is expected, since given the compres-
sion, no hash function can ensure that the estimation on
the sketch can be done precisely. Along the same line of
CountMin [10], we use multiple independent hash functions
to reduce the probability of hash collisions.

The gLava model. A gLava sketch is a set of graph sketches
{S1(V1, E1), · · · , Sd(Vd, Ed)}. Here, we use d hash functions
h1, · · · , hd, where hi (i ∈ [1, d]) is used to generate Si. Also,
h1, · · · , hd are chosen uniformly at random from a pairwise-
independent family (see Section 6.2 for more details).

Example 5: Figure 4 shows another two sketches for Fig. 1.
Again, consider the query Q2 in Example 4. Using S1 in
Fig. 4 (a), one can locate edge (III, II) for (g, b), which
gives 1. Similarly, S2 in Fig. 4 (b) will also give 1 from edge
(iii, i), where g (resp. b) maps to iii (resp. i). The minimum
✷
of the above two outputs is 1, which is correct.

Example 5 shows that using multiple hash functions can

indeed improve the accuracy of estimation.

1

II(bc)

2

3

1

1

2

1

ii(cd)

3

A✂✂✂✂✂✂✂

1

1

(cid:30)❂❂❂❂❂❂❂

2

i(ab)

1

iii(g)

1
I(af )

^❂❂❂❂❂❂❂

1

1

III(dg)

1

1

IV (e)

(a) Sketch S1

2

1

iv(ef )

1

(b) Sketch S2

Figure 4: A gLava sketch with 2 hash functions

3.4 Supported Graph Queries

As remarked in Section 3.3,

for any graph analytics
method M to run over G, i.e., M (G), it is possible to run
M on each sketch directly and individually, and then merge
the result as: ˜M (G) = Γ(M (S1), · · · , M (Sd)), where ˜M (G)
denotes the estimated result over G, and Γ(·) an aggrega-
tion function (e.g., min, max, conjunction) to merge results
returned from d sketches.

Whilst the exercise in this section only substantiates sev-
eral types of graph queries to be addressed in this work, it
is evident that the power of gLava is far beyond what are
listed below.

Edge frequency. Given two node labels a and b, we write
fe(a, b) to denote the exact weight from a a-node to a b-node.
We write ˜fe(a, b) the estimated weight from a sketch.

One application of such queries, taking social networks
for example, is to estimate the communication frequency
between two speciﬁc friends.

Point queries. For a directed graph, given a node label a,
we study a boolean query fv(a, ←) > θ (resp. fv(a, →) < θ),
which is to monitor whether the aggregated edge weight to
from) a node with label a is above (resp. below) a
(resp.
given threshold θ in the graph stream G. For an undirected
graph, we write fv(a, ⊥) > θ and fv(a, ⊥) < θ correspond-
ingly. Similarly, we use ˜fv(a, ←), ˜fv(a, →), ˜fv(a, ⊥) for esti-
mated numbers using sketches.

One important application of such queries is DoS (Denial-
of-service) attacks in cyber security, which typically ﬂood a
target source (i.e., a computer) with massive external com-
munication requests.

Path queries. Given two node labels a and b, a (boolean)
reachability query r(a, b) is to tell whether they are con-
nected. Also, we write ˜r(a, b) as the estimated reachability.
One important monitoring task, for the success of multi-
cast deployment in the Internet, is to verify the availabil-
ity of service in the network, which is usually referred to
as reachability monitoring. Another reachability application
that needs to consider edge weights is IP routing, which is
to determine the path of data ﬂows in order to travel across
multiple networks.

Aggregate subgraph query. The aggregate subgraph
query is considered in gSketch [31].
It is to compute
the aggregate weight of the constituent edges of a sub-
graph Q = {(x1, y1), · · · , (xk, yk)}, denoted by f (Q) =
Ω(fe(x1, y1), · · · , fe(xk, yk)). Here, the function Ω(·) is to
merge weights from all fe(xi, yi) for i ∈ [1, k]. We write

{
{
(cid:7)
(cid:7)
%
%
(cid:23)
(cid:23)
(cid:31)
(cid:31)
;
;
e
e
(cid:14)
(cid:14)
F
F
^
K
K
(cid:7)
(cid:7)
(cid:30)
A
(cid:23)
(cid:23)
#
#
l
l
d
d
G
G
K
K
Symbols
G, SG
ω(e)
fe(a, b)
fv(a, ←)
fv(a, →)
fv(a, ⊥)
r(a, b)
f (Q)

Notations
a graph stream, and a graph sketch
weight of the edge e
edge weight
node in-ﬂow weight (directed graphs)
node out-ﬂow weight (directed graphs)
node ﬂow weight (undirected graphs)
whether b is reachable from a
weight of subgraph Q

Table 1: Notations

˜f (Q) for estimation over sketches.

Note that, gSketch simply merges all estimated weights
in G, e.g., the sum of all weights, even if one edge is miss-
ing (i.e., ˜f (xi, yi) = 0 for some edge ei). However, we use
if ˜f (xi, yi) = 0,
a diﬀerent query semantics in this work:
the estimated aggregate weight should be 0, since the query
graph Q does not have an exact match. We use this revised
semantics since it is a more practical setting.

Example 6: Consider a subgraph with two edges as Q :
{(a, b), (a, c)}. The query Q3 : ˜f (Q) is to estimate the ag-
gregate weight of Q. The precise answer is 2, which is easy
✷
to check from Fig. 1.

Extensions. We consider an extension of the above aggregate
subgraph query, which allows a wildcard ∗ in the node labels
that are being queried. More speciﬁcally, for the subgraph
query Q = {(x1, y1), · · · , (xk, yk)}, each xi or yi is either a
constant value, or a wildcard ∗ (i.e., match any label). A
further extension is to bound the wildcards to be matched
to the same node, by using a subscript to a wildcard as
∗j . That is, two wildcards with the same subscripts enforce
them to be mapped to the same node.
Example 7: A subgraph query Q4 : ˜f ({(a, b), (b, c), (c, a)})
is to estimate the triangle, i.e., a 3-clique with three vertices
labeled as a, b, and c, respectively. Another subgraph query
Q5 : ˜f ({(∗, b), (b, c), (c, ∗)}) is to estimate paths that start
at node with an edge to b, and end at any node with an edge
from c, if the edge (b, c) exists in the graph. If one wants
to count the common neighbors of (b, c), the following query
Q6 : ˜f ({(∗1, b), (b, c), (c, ∗1)}) can enforce such a condition,
✷
which again is a case of counting triangles.

The extension is apparently more general, with the pur-
pose to cover more useful queries in practice. Unfortunately,
gSketch cannot support such extensions.
Summary of notations. The notations of this paper are sum-
marized in Table 1, which are for both directed and undi-
rected graphs, unless being speciﬁed otherwise.

4. QUERY PROCESSING

We consider the graph stream as G, and d graph sketches
{S1, · · · , Sd} of G, where Si is constructed using a hash
function hi(·). In this following, we discuss how to process
diﬀerent types of queries. Again, by default, we assume that
we use sum(·) as the default aggregation function. Also, to
facilitate the discussion, we assume that an adjacent matrix
is used for storing gLava.

4.1 Edge Query

To evaluate ˜fe(a, b), the edge weight of (a, b), is straight-

forward. It is to ﬁnd the estimated edge weight from each
sketch ωi(hi(a), hi(b)) and then use a corresponding function
Γ(·) to merge them, as the following:

˜fe(a, b) = Γ(ω1(h1(a), h1(b)), · · · , ωd(hd(a), hd(b)))

In this case, the function Γ(·) is to take the minimum.

Complexity. It is easy to see that estimating the aggregate
weight of an edge query is in O(d) time and in O(d) space,
where d is a constant.

4.2 Point Queries

Here, we only discuss the case ˜fv(a, ←) > θ. That is,
given a new element (x, y; t), estimate in real-time whether
the aggregate weight to node a is above the threshold θ. The
other cases, i.e., ˜fv(a, ←) < θ, ˜fv(a, →) > θ, ˜fv(a, →) < θ,
˜fv(a, ⊥) > θ and ˜fv(a, ⊥) < θ, can be similarly processed.

We use the following strategy to monitor ˜fv(a, ←) > θ,
given an incoming edge e : (x, y; t). Note that if y 6= a, we
simply update all d sketches in constant time, since this is
not about an edge to a. Next, we only describe the case of
edge e : (x, a; t).
Step 1. [Estimate current in-ﬂow.] We write ˜f i
v(a, ←) the es-
timated in-ﬂow from the i-th sketch. ˜f i
v(a, ←) can be com-
puted by ﬁrst locating the column in the adjacent matrix
corresponding to label a (i.e., hi(a)), and then sum up the
values in that column, i.e., ˜f i
w
j=1 Mi[j][hi(a)].
Here, w is the width of the adjacent matrix Mi. Then,

v(a, ←) = P

˜fv(a, ←) = Γ( ˜f 1

v (a, ←), · · · , ˜f w

v (a, ←))

In this case, the function Γ(·) is to take the minimum.
Step 2. [Monitor e.] We only send an alarm, if ˜fv(a, ←) +
ω(e) > θ.

Step 3. [Update all sketches.] Update all d sketches by ag-
gregating the new edge weight ω(e).

Complexity. It is easy to see that step 1 takes O(d + w)
time and O(d) space, where both d and w are constants.

4.3 Path Queries

We consider the reachability query ˜r(a, b), which is to es-
timate whether b is reachable from a. For such queries, we
treat any oﬀ-the-shelf algorithm reach(x, y) as a black-box
and show our strategy.
Step 1. [Map.] We invoke reachi(hi[a], hi[b]) on the i-th
sketch (for i ∈ [1, d]), to decide whether the mapped node
hi[b] is reachable from the mapped node hi[a].
Step 2. [Reduce.] We merge individual results as follows:

˜r(a, b) = reach1(h1[a], h1[b]) ∧ · · · ∧ reachd(hd[a], hd[b])

That is, the estimated result is true only if the mapped nodes
are reachable from all d sketches.

The complexity of the above strategy is determined by the

algorithm reach().

4.4 Aggregate Subgraph Query

We next consider the aggregate subgraph query ˜f (Q),
which is to compute the aggregate weight of the constituent
edges of a sub-graph Q. The process is similar to the above
path queries, by using any existing algorithm subgraph(Q).

Step 1. [Map.] We ﬁrst invoke subgraph(Q) at each sketch to
ﬁnd subgraph matches, and calculate the aggregate weight,
denoted by weighti(Q) for the i-th sketch.
Step 2. [Reduce.] We merge individual results as follows:

˜f (Q) = min(weight1(Q), · · · , weightd(Q))
Note that, running a graph algorithm on a sketch is only
applicable to gLava.
It is not applicable to gSketch since
gSketch by nature is an array of frequency counting, without
maintaining the graphical structure as gLava does. Also,
in the case weighti(Q) from some sketch that says that a
subgraph match does not exist, we can terminate the whole
process, which provides chances for optimization.

Optimization. Recall that a subgraph Q is deﬁned as con-
stituent edges as {(x1, y1), · · · , (xk, yk)} (Section 3.4). An
alternative way of estimating the aggregate subgraph query
is to ﬁrst compute the minimum value of each value and sum
them up. We denote this approach by ˜f ′(Q) as follows:

˜f ′(Q) =

k

X
i=1

˜fe(xi, yi)

It is readily to see that ˜f ′(Q) ≤ ˜f (Q). Recall that there
are two extensions of the subgraph queries (Section 3.4). For
the ﬁrst extension that a wildcard ∗ is used, the above op-
timization can be used. For instance, the edge frequency of
˜fe(x, ∗) for a directed graph is indeed ˜fv(x, →). For the sec-
ond extension that multiple wildcards ∗i are used to bound
to the same node, this optimization cannot be applied.

5. ERROR BOUNDS

We study the error bounds for two basic types of queries:
edge queries and point queries. Although gLava is more
general, we show that theoretically, it has the same error
bounds as CountMin.

5.1 Edge Frequency

Our proof for the error bound of edge frequency queries is
an adaption of the proof used in CountMin in Sec. 4.1 of [10].
Theorem 1: The estimation ˜fe(j, k) of the cumulative
edge weight of the edge (j, k) has the following guaran-
tees, fe(j, k) ≤ ˜fe(j, k) with probability at least 1 − δ, s.t.,
fe(j, k) ≤ ˜fe(j, k) + ǫ ∗ n, where fe(j, k) is the exact answer
to the cumulative edge weight of the edge (j, k), n denotes
the number of nodes, and the error in answering a query is
within a factor of ǫ with probability δ5.
✷

Proof. For any query edge fe(j, k),

for each hash
for any stream edge e :
function hi, by construction,
(j, k; t), where ω(e) is the edge weight that is added to
count(hi(j), hi(k)). Therefore, by construction, the answer
to fe(j, k) is less than or equal to mini(count(hi(j), hi(k)))
for i ∈ [1, d] where d is the number of hash functions.

Consider two edges (j, k) and (l, m). We deﬁne an in-
dicator variable Ii,j,k,l,m, which is 1 if there is a collision
between two distinct edges, i.e., (j 6= l) ∧ (k 6= m) ∧ (hi(j) =
hi(l) ∧ hi(k) = hi(l)) , and 0 otherwise. By pairwise inde-
pendence of the hash functions,

E(Ii,j,k,l,m) = P r[(hi(j) = hi(l) ∧ hi(k) = hi(m)]
5The parameters ǫ and δ are usually set by the user.

≤ (1/range(hi))2 = ǫ′2/e2 P

where e is the base used to compute natural logarithm,
and range(hi) is the number of hash buckets of function
hi. Deﬁne the variable Xi,j,k (random over choices of hi)
to count the number of collisions with the edge (j, k), which
is formalized as Xi,j,k = Σl=1...n,m=1...nIi,j,k,l,mal,m, where
n is the number of nodes in the graph. Since all ai’s are
non-negative in this case, Xi,j,k is non-negative. We write
count[i, hi(j), hi(k)] as the count in the hash bucket relative
to hash function hi. By construction, count[i, hi(j), hi(k)] =
fe(j, k) + Xi,j,k. So clearly, mini(count[i, hi(j), hi(k)]) ≥
fe(j, k).

E(Xi,j,k)

= E(Pl=1...n,m=1...n Ii,j,k,lfe(l, m)) P
≤ (Pl=1...n,m=1...n E(Ii,j,k,l).fe(l, m)) ≤ (ǫ′/e)2 ∗ n P

by pairwise independence of hi, and linearlity of expectation.

Let, ǫ′2 = ǫ. By the Markov inequality,

P r[ ˜fe(j, k) > fe(j, k) + ǫ ∗ n]

= P r[∀i.count[i, hi(j), hi(k)] > fe(j, k) + ǫ ∗ n] P
= P r[∀i.fe(j, k) + Xi,j,k > fe(j, k) + ǫ ∗ n] P
= P r[∀i.Xi,j,k > e ∗ E(Xi,j,k)] < e−d ≤ δ P

Our algorithm generates the same number of collisions and
the same error bounds under the same probabilistic guaran-
tees as CountMin for edge frequency queries.

5.2 Point Queries

We ﬁrst discuss the query for node out-degree,

i.e.,
fv(a, →). Consider the stream of edges e : (a, ∗; t), i.e.,
edges from node a to any other node indicated by a wild-
card ∗. Drop the destination (i.e., the wildcard) of each
edge. The stream now becomes a stream of tuples (a, ω(t))
where ω(t) is the edge weight from node a at time t. When
a query is posed to ﬁnd the out-degree of node a, Count-
Min [10] returns the minimum of the weights in diﬀerent
hash buckets as the estimation of the ﬂow out of node a.

If the number of unique neighbors (i.e., connected using
one hop ignoring the weights) is sought, we adapt the proce-
dure above by replacing ω(t) with 1 in the stream above for
all nodes. Clearly, by construction, the answer obtained is
an over-estimation of the true out-degree because of two rea-
sons: (a) collisions in the hash-buckets, and (b) self-collision,
i.e., we do not know if an edge has been seen previously and
thus count the outgoing edge again even if we have seen it.
The case for in-degree point queries is similar. To compute
the in-degree of a node, we simply adapt the stream to create
a one-dimensional stream as in the case above. Drop the
source for each edge to create a stream. The variations in
the case of out-degree for the total in-ﬂow and the number
of neighbors with in-links to a node can be estimated as in
the case of out-degree outlined above.

The error estimates for point queries (see Sec. 4.1 of [10])

hold for these cases.

Lemma 5.2: The estimated out-degree (in-degree) is within
a factor of ǫ with probability δ if we use d = ⌈ln(1/δ)⌉ rows
of pair-wise independent hash functions and w = ⌈e/ǫ⌉. ✷

j from \ to

I(af )
II(bc)
III(dg)
IV (e)

I(af )
1
3
0
1

II(bc)
2
1
1
1

III(dg)
0
1
1
1

IV (e)
0
1
0
0

Figure 5: The adjacent matrix of S1

6.

IMPLEMENTATION DETAILS

In this section, we ﬁrst discuss the data structures used to
implement gLava (Section 6.1). We then introduce the deﬁ-
nition of pairwise independent hash functions (Section 6.2).
We also discuss its potential extension in a distributed en-
vironment (Section 6.3).

6.1 Adjacent Matrix and Its Extension

Using hash-based methods, although it is evident that it
only requires 1-pass of the graph stream to construct/update
a gLava. However, the linear time complexity of construct-
ing and updating a gLava depends on the data structures
used. For example, the adjacent list may not be a ﬁt, since
searching a speciﬁc edge is not in constant time.

6.1.1 Adjacent Matrix

An adjacency matrix is a means of representing which

nodes of a graph are adjacent to which other vertices.

Example 8: Consider the sketch S1 in Fig. 4 (a) for exam-
✷
ple. Its adjacent matrix is shown in Fig. 5.

Example 8 showcases a directed graph. In the case of an

undirected graph, it will be a symmetric matrix.

Construction. Consider a graph stream G = he1, e2,
· · · , emi where ei = (xi, yi; ti). Given a number of nodes
w and a hash function h(·) → [1, w]. We use the following
strategy.
Step 1. [Initialization.] Construct a w × w matrix M, with
all values initialized to be 0.
Step 2. [Insertion of ei.] Compute h(xi) and h(yi). Increase
the value of M[h(xi)][h(yi)] by ω(ei), the weight of ei.

In the above strategy, step 1 will take constant time to
allocate a matrix. Step 2 will take constant time for each ei.
Hence, the time complexity is O(m) where m is the number
of edges in G. The space used is O(w2).
Deletions. [Deletion of ei.] Insertions have been discussed
in the above step 2. For the deletion of an ei that is not of
interest (e.g., out of a certain time window), it is simply to
decrease the value of M[h(xi)][h(yi)] by ω(ei) in O(1) time.
Alternatively, one may consider to use an adjacent hash-
list is to maintain, for each vertex, a list of its adjacent
nodes using a hash table. Given an edge ei(xi, yi; ti), two
hash operations are needed: The ﬁrst is to locate xi, and the
second is to ﬁnd yi from xi’s hash-list. Afterwards, it up-
dates the corresponding edge weight. Adjacent list is known
to be suitable when graph is sparse. However, in terms of
compressed graph in our case, as will be shown later in ex-
periments, most sketches are relatively dense, which makes
the adjacent matrix the default data structure to manage
our graph sketches.

j from \ to

I(a)
II(b)
III(c)
IV (d)
IV (e)
IV (f )
IV (g)

i(abcd)
2
3
0
0
2
1
1

ii(ef g)
0
1
2
1
1
0
0

Figure 6: A non-square matrix

When using a classical square matrix for storing a sketch,
we have an n ∗ n matrix. Consider all edges from node a
such as (a, ∗). Using any hash function will inevitably hash
all of these edges to the same row. For example, in Fig. 5,
all edges (a, ∗) will be hashed to the ﬁrst row of the matrix.
When there is only one hash function to use, due to the
lack of a priori knowledge of data distribution, it is hard to
decide the right shape of a matrix. However, the applica-
tion of d sketches provides us an opportunity to heuristically
reduce the chance of combined hash collisions.

The basic idea is, instead of using an n ∗ n matrix with
one hash function, we use an m ∗ p matrix with two hash
functions: h1(·) → [1, m] on the from nodes and h2(·) →
[1, p] on the to nodes.

Example 9: Consider the graph stream in Fig.1. Assume
that we use two hash functions: h1(·) → [1, 7] and h2(·) →
✷
[1, 2]. The non-square matrix is shown in Fig. 6.

In practice, when we can generate multiple sketches, we
heuristics use matrices n ∗ n, 2n ∗ n/2, n/2 ∗ 2n, 4n ∗ n/4,
n/4 ∗ 4n, etc. That is, we use matrices with the same sizes
but diﬀerent shapes.

6.2 Pairwise Independent Hash Functions

Here, we only borrow the deﬁnition of pairwise indepen-
dent hash functions6, while relying on existing tools to im-
plement them.

A family of functions H = {h|h(·) → [1, w]} is called
a family of pairwise independent hash functions if for two
diﬀerent hash keys xi, xj, and k, l ∈ [1, w],

Prh←H[h(xi) = k ∧ h(xj) = l] = 1/w

2

Intuitively, when using multiple hash functions to con-
struct sketches, the hash functions used should be pairwise
independent in order to reduce the probability of hash col-
lisions. Please refer to [10] for more details.

6.3 Discussion: Distributed Environment

In this paper, we mainly discuss how to implement gLava
in a centralized environment. However, it is easy to ob-
serve that gLava can be easily applied to a distributed en-
vironment, since the construction and maintenance of each
sketch is independent of each other. Assuming that we have
d sketches in one computing node, when m nodes are avail-
able, we can use d × m pairwise independent hash functions,
which may signiﬁcantly reduce the probability of errors.

7. CONCLUSION

6.1.2 Using Non-Square Matrices

6http://people.csail.mit.edu/ronitt/COURSE/S12/handouts/lec5.pdf

graphlab: A framework for machine learning in the
cloud. PVLDB, 5(8), 2012.

[22] G. Malewicz, M. H. Austern, A. J. C. Bik, J. C.
Dehnert, I. Horn, N. Leiser, and G. Czajkowski.
Pregel: a system for large-scale graph processing. In
SIGMOD, pages 135–146, 2010.

[23] G. S. Manku and R. Motwani. Approximate frequency

counts over data streams. In VLDB, 2002.

[24] A. McGregor. Graph stream algorithms: a survey.

SIGMOD Record, 43(1):9–20, 2014.

[25] S. Raghavan and H. Garcia-Molina. Representing web

graphs. In ICDE, 2003.

[26] C. Song, T. Ge, C. X. Chen, and J. Wang. Event

pattern matching over graph streams. PVLDB, 8(4),
2014.

[27] T. Suel and J. Yuan. Compressing the graph structure
of the web. In Data Compression Conference, 2001.
[28] R. E. Tarjan. Data structures and network algorithms.

In SIAM. 1983.

[29] C. E. Tsourakakis, U. Kang, G. L. Miller, and
C. Faloutsos. DOULION: counting triangles in
massive graphs with a coin. In SIGKDD, 2009.
[30] C. Wang and L. Chen. Continuous subgraph pattern

search over graph streams. In ICDE, 2009.

[31] P. Zhao, C. C. Aggarwal, and M. Wang. gSketch: On
query estimation in graph streams. PVLDB, 5(3),
2011.

We have proposed a new graph sketch for summarizing
graph streams. We have demonstrated its wide applicability
to many emerging applications.

8. REFERENCES
[1] Tweet statistics. http://expandedramblings.com/

index.php/march-2013-by-the-numbers-a-few-amazing-
twitter-stats/10/.

[2] Vitria. http://www.vitria.com/solutions/streaming-

big-data-analytics/beneﬁts/.

[3] M. Adler and M. Mitzenmacher. Towards compressing
web graphs. In Data Compression Conference, 2001.

[4] C. C. Aggarwal, editor. Data Classiﬁcation:

Algorithms and Applications. CRC Press, 2014.
[5] N. Alon, Y. Matias, and M. Szegedy. The space

complexity of approximating the frequency moments.
J. Comput. Syst. Sci., 58(1):137–147, 1999.

[6] V. Braverman, R. Ostrovsky, and D. Vilenchik. How
hard is counting triangles in the streaming model? In
ICALP, 2013.

[7] A. Z. Broder and M. Mitzenmacher. Survey: Network

applications of bloom ﬁlters: A survey. Internet
Mathematics, 1(4):485–509, 2003.

[8] S. Choudhury, L. B. Holder, G. C. Jr., K. Agarwal,

and J. Feo. A selectivity based approach to continuous
pattern detection in streaming graphs. In EDBT, 2015.

[9] E. Cohen and H. Kaplan. Tighter estimation using

bottom k sketches. PVLDB, 1(1), 2008.

[10] G. Cormode and S. Muthukrishnan. An improved

data stream summary: the count-min sketch and its
applications. J. Algorithms, 55(1):58–75, 2005.
[11] G. Cormode and S. Muthukrishnan. Space eﬃcient
mining of multigraph streams. In PODS, 2005.
[12] M. Elkin. Streaming and fully dynamic centralized
algorithms for constructing and maintaining sparse
spanners. ACM Transactions on Algorithms, 7(2):20,
2011.

[13] W. Fan, J. Li, X. Wang, and Y. Wu. Query preserving

graph compression. In SIGMOD, 2012.

[14] J. Feigenbaum, S. Kannan, A. McGregor, S. Suri, and
J. Zhang. On graph problems in a semi-streaming
model. Theor. Comput. Sci., 348(2-3):207–216, 2005.
[15] J. Gao, C. Zhou, J. Zhou, and J. X. Yu. Continuous
pattern detection over billion-edge graph using
distributed framework. In ICDE, 2014.

[16] J. E. Gonzalez, Y. Low, H. Gu, D. Bickson, and

C. Guestrin. Powergraph: Distributed graph-parallel
computation on natural graphs. In OSDI, 2012.
[17] J. E. Gonzalez, R. S. Xin, A. Dave, D. Crankshaw,
M. J. Franklin, and I. Stoica. Graphx: Graph
processing in a distributed dataﬂow framework. In
OSDI, 2014.

[18] S. Guha and A. McGregor. Graph synopses, sketches,

and streams: A survey. PVLDB, 5(12), 2012.

[19] A. K. Jain and R. C. Dubes. Algorithms for Clustering

Data. Prentice-Hall, 1988.

[20] J. A. Kelner and A. Levin. Spectral sparsiﬁcation in

the semi-streaming setting. Theory Comput. Syst.,
53(2):243–262, 2013.

[21] Y. Low, J. Gonzalez, A. Kyrola, D. Bickson,

C. Guestrin, and J. M. Hellerstein. Distributed

