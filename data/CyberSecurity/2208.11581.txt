2
2
0
2

g
u
A
4
2

]

R
C
.
s
c
[

1
v
1
8
5
1
1
.
8
0
2
2
:
v
i
X
r
a

“Please help share!”: Security and Privacy Advice on Twitter during the 2022
Russian Invasion of Ukraine

Juliane Schmüser ∗, Noah Wöhler ∗, Harshini Sri Ramulu †, Christian Stransky ‡,
Dominik Wermke ∗, Sascha Fahl ∗, and Yasemin Acar †
∗CISPA Helmholtz Center for Information Security, Germany,
{juliane.schmueser,noah.woehler,dominik.wermke,sascha.fahl}@cispa.de
†George Washington University, United States, {acar, sharshini}@gwu.edu
‡CISPA Helmholtz Center for Information Security, Germany, stransky@sec.uni-hannover.de

Abstract—The Russian Invasion of Ukraine in early 2022
resulted in a rapidly changing (cyber) threat environment.
This changing environment incentivized the sharing of security
advice on social media, both for the Ukrainian population,
as well as against Russian cyber attacks at large. Previous
research found a signiﬁcant inﬂuence of online security advice
on end users.

We collected 8,920 tweets posted after the Russian Invasion
of Ukraine and examined 1,228 in detail, including qualitatively
coding 232 relevant tweets and 140 linked documents for
security and privacy advice. We identiﬁed 221 unique pieces of
advice which we divided into seven categories and 21 subcat-
egories, and advice targeted at individuals or organizations.
We then compared our ﬁndings to those of prior studies,
ﬁnding noteworthy similarities. Our results conﬁrm a lack
of advice prioritization found by prior work, which seems
especially detrimental during times of crisis. In addition, we
ﬁnd offers for individual support to be a valuable tool and
identify misinformation as a rising threat in general and for
security advice speciﬁcally.

1. Introduction

In the early hours of 24th February 2022, Russian Pres-
ident Vladimir Putin announced a “special military opera-
tion”, launching a large-scale military invasion of neighbor-
ing Ukraine. Following cruise and ballistic missile strikes di-
rected at Ukrainian airﬁelds, military headquarters, and mil-
itary depots, Russian troops entered Ukraine from four main
directions: north from Belarus, northeast from Russia, east
from the Donetsk People’s Republic (DPR) and Luhansk
People’s Republic (LPR), and south from the annexed region
of Crimea. Russia’s invasion follows the 2014 annexation of
the Crimean peninsula, which was itself followed by eight
years of support for separatist rebels in eastern Ukraine.

This change in the global threat environment was accom-
panied by a sudden change in the cyber threat environment:
the invasion was preceded and accompanied by intensiﬁed
cyber attacks, some of which had physical consequences.
For instance, in early February malware targeting several
Ukrainian Government and IT organizations was detected

and a distributed denial-of-service (DDoS) attack made
multiple government and banking websites inaccessible for
hours. These attacks impacted Ukraine’s energy, media,
ﬁnancial, and business sectors. Furthermore, several cyber
threats and attacks continued after the invasion as well,
impacting the distribution of food, medicines, and supplies.
During this period, other malicious activities like disinfor-
mation through deep fake technology, phishing emails, use
of surveillance software and data-wiper malware, etc., were
detected [1].

The invasion resulted in a heightened threat environment
for companies outside of Russia and Ukraine, as well. This
change in threat level was also highlighted by a number
of advisories by national agencies, including from the US,
UK, Germany, Canada, and Australia [2]–[6]. The advisories
warn that Russian state-sponsored threat actors and aligned
cybercrime groups might be targeting critical industries and
organizations in the United States and other Western nations.
One example of an attack such adversaries carried out
in the past is the SolarWinds incident which was one of the
most detrimental attacks on the supply chain network. It was
found that advanced persistent threat (APT) actors created a
backdoor hidden in a software update of SolarWinds’ Orion
system of. This attack affected almost 18,000 customers
worldwide [7]. The NotPetya attack in 2017 which had an
impact globally is another example of a supply chain attack.
A backdoor was planted in an accounting software mostly
used by Ukrainian accounting ﬁrms [8].

Following these incidents and attacks, many instances
of security-related advice were shared on news sources and
social networks like Twitter. In some cases, security-related
advice and information online were conﬂated with misin-
formation. For instance, rumors about Signal, an instant
messaging platform, being hacked were widespread. This
was in fact dismissed by Signal as a part of a coordinated
misinformation campaign to encourage users to use less
secure methods for communication [9].

In this paper, we examine the security and privacy
advice provided around Russia’s 2022 Invasion of Ukraine
on the social media platform Twitter. This is especially
relevant given the connection of cyber attacks, the success
of their mitigation, and global physical consequences of the

 
 
 
 
 
 
invasion. We base our research approach on the following
research questions:
RQ1. “What security and privacy advice was shared on
Twitter related to the 2022 Russian Invasion of Ukraine?”
We are interested in what security and privacy advice was
shared on Twitter between February and May 2022, espe-
cially in relation to the heightened cyber threat resulting
from the invasion. We are interested in the tweets as well as
resources provided such as linked documents and websites,
and the targets of the advice such as companies or individ-
uals, including those in Ukraine as well as other directly or
indirectly affected people.
RQ2. “How does the advice compare to security and
privacy advice shared in other contexts?” We explore if
the advice around the invasion resembles or differs from
security and privacy advice collected at different times and
in different contexts. To this end, we compare our data to
that of previous studies. Additionally, we investigate the
relationship between advice and its frequency in our data,
and evaluation and prioritization of advice in prior work. As
far as possible, we seek to understand if and how the advice
was tailored to the situation at hand.

For this, we create a taxonomy of 221 pieces of advice
during the invasion. In seven main categories, we ﬁnd a
wide range of advice including messaging & social media,
organizational policies, and meta advice on sharing security
advice. The majority of advice was rather generic, leading to
a low correlation with Redmiles et al.’s user priority ranking,
which was based on actionability among other criteria [10].
By contrast, we ﬁnd some signiﬁcant correlation with their
expert priority ranking, as well as advice frequency in
the advice for non-tech-savvy users collected by Reeder et
al. [11].

This work is structured as follows: After this general
introduction (Section 1), we discuss related work in the
areas of security perceptions & behavior, social media &
information sharing in crises, as well as security & privacy
advice (Section 2). We describe our approach (Section 3)
and highlight the ﬁndings (Section 4). Finally, we discuss
our ﬁndings (Section 5) and draw a conclusion (Section 6).

2. Related Work

We present and discuss previous work in three related
ﬁelds: investigations into security-related user perceptions
and behavior, research involving content on social media and
information sharing in crises, and security or privacy advice
for users. In this section, we also put our work into context
and highlight some novel contributions of our research.
Inﬂuences on Security Behavior. Prior work has investi-
gated how security behavior is inﬂuenced both in general
and in vulnerable populations. Previous studies established
connections between user behavior and the user’s perception
of risk [12]–[14], (security) fatigue [15], and social inﬂu-
ence effects [16]–[19]. Howe et al. performed a literature
review of studies investigating factors that inﬂuence security
decisions, ﬁnding delivery of security measures to users

as an important factor [20]. In the context of scams and
vulnerable populations, Vitak et al. conducted interviews
with 52 families from high-poverty communities, ﬁnding
a complex relationship between participants’ negative ex-
periences, their perceptions and their general mistrust of
sharing data through online channels [21]. Further research
into methods for inﬂuencing security behavior includes
nudges and warnings. Previous studies include a literature
assessment [22], experiments reminding users of updates
and two-factor authentication (2FA) [23], and security di-
alog attractors [24], [25]. Vulnerable persons and helpers
are often the target of scams and phishing attacks during
crises. Egelman et al. examined in a lab study with 60
participants the effectiveness of phishing warnings, ﬁnding
that 97% participants fell for at least one of the phishing
messages [26]. These prior studies on how security behavior
is inﬂuenced inform our view on and discussion of the
advice we collected.
Social Media & Information Sharing in Crises. Social
media reactions to the events around the 2014 Russian
annexation of the Crimea peninsula have been extensively
investigated in research [27], [28], speciﬁcally, topics [29],
hashtags [30], images [31], and memes [32]. Twitter and
other social media are a common data source for research,
including newcomers’ experiences [33], audience percep-
tions [34], information sharing [35], [36], and rumors [37].
This includes speciﬁc user types such as journalists [38] or
government departments [39]. Sit et al. introduce a labeled
dataset of disaster-related tweets and present a series of deep
learning and machine learning methods for a binary classiﬁ-
cation of disaster relatedness [40]. Imran et al. surveyed the
state of the art regarding computational methods to process
social media messages and highlight both their contribu-
tions and shortcomings [41]. In the area of crisis research,
multiple publications systematize previous work based on
social media data [42]–[44]. Works speciﬁcally investigated
information aggregation on Reddit [45], and Twitter posts
around crises [46] and their comprehension [47]. Speciﬁc
cases discussed include 2012 Hurricane Sandy [48], the
2013 Gezi Park protests in Turkey [49], and the 2015–
2016 Zika virus outbreak [50]. The spread of misinformation
during crises was studied in relation to the emotional prox-
imity of users [51], and with regard to Russian inﬂuence
operations within #BlackLivesMatter [52].

The 2022 Russian Invasion of Ukraine went hand-in-
hand with surveillance and censorship by the Russian state.
Speciﬁcally for Russian internet
infrastructure, prior re-
search considered internet governance [53], [54], throttling
of Twitter domains [55], and deployed trafﬁc ﬁltering so-
lutions [56]. Ermoshina et al. analyzed internet censorship-
resistance tactics by Russian users, content produces, and
service providers [57]. More recently, Gabdulhakov investi-
gated a wave of social media user arrests in Russia in semi-
structured in-depth interviews with lawyers, rights defend-
ers, academics, non-government organizations (NGOs), and
law enforcement authorities [58]. Akbari et al. present an
analysis of the challenges faced by the Telegram messenger
in Russia and Iran [59].

Security & Privacy Advice. Previous research investigated
security advice in the context of experts vs. users [60], [61],
and for older adults [62]. Multiple publications investigated
the adoption and impact of security practices [63]–[65].
Respondents’ security advice sources were investigated in
interviews [66] and surveys [67], [68], as well as speciﬁc
advice for developers [69]. Herley postulates that by evalu-
ating (security) advice solely on beneﬁt, we have implicitly
valued user time and effort at zero [70]. This becomes and
important aspect in the light of recent studies, which ﬁnd a
large number of advice pieces.

Tahaei et al. qualitatively analyzed 119 privacy-related
accepted answers on Stack Overﬂow, extracting 148 pieces
of advice [71].

Reeder et al. collected 152 pieces of advice by asking
security experts for the top three recommendations they
would give to non-tech-savvy users [11]. Redmiles et al.
conducted a measurement study to identify 374 unique rec-
ommended behaviors contained within 1,264 documents of
online security and privacy advice and evaluated the security
advice in a user-study with 1,586 users and 41 professional
security experts [10]. Boyd et al. collected 41 safety guides
distributed during Black Lives Matter (BLM) protests and
surveyed 167 protesters, ﬁnding that many were unaware of
key advice like using end-to-end encrypted messengers [72].
We compare our collection of pieces of advice and
online documents shared on Twitter during the 2022 Russian
Invasion of Ukraine to these prior studies, and provide novel
insight on what security and privacy advice is distributed
during crises that directly impact the cyber threat environ-
ment.

3. Methodology

In this section, we provide an overview of our methodol-
ogy for assessing online security and privacy advice related
to the 2022 Russian Invasion of Ukraine, including data
collection from Twitter and documents linked on Twitter
between February and May 2022. We also detail our qual-
itative codebook and coding process, highlight our ethical
considerations, and discuss the limitations of our work.

3.1. Study Setup

To gain insight into security and privacy advice shared
around the 2022 Russian Invasion of Ukraine, we collected
and analyzed 8,920 tweets for their relevance and exam-
ined 232 posts in detail for security and privacy advice.
As we were especially interested in widely shared advice
and resources, we decided to study public data on Twitter.
Twitter had been successfully used to analyze the spread of
information during crises in several prior studies [46], [50],
[52], [72], [73].
Data Collection. We collected security and privacy advice
and resources shared on Twitter during the 2022 Russian
Invasion of Ukraine from February to May 2022. The tweets
were collected using the ofﬁcial Twitter API for Academic

Research1 and Twitter Streams2 using the Python library
Tweepy3. The results were further enhanced by using the
unofﬁcial Twitter API and the Python library Twint4, which
allows scraping by hashtags. We used a list of keywords
aiming to cover and gather all relevant tweets. This resulted
in 8,920 tweets that could possibly be relevant. Following
this, we applied a manual ﬁltering process: In a ﬁrst round,
each tweet was marked as security/privacy advice if at least
one of two coders deemed it relevant. Tweets that did not in-
clude or refer to security and privacy advice were discarded.
In a second round, one coder veriﬁed if the remaining
tweets mentioned Ukraine or the 2022 Russian Invasion of
Ukraine in any way. A second coder crosschecked >10%
of the tweets that the ﬁrst coder had categorized as non-
related to ensure that no relevant data was missed, ﬁnding
no additional relevant data points. After this manual ﬁltering
process, we had 232 tweets remaining. From these tweets,
we additionally collected any links to external documents,
which resulted in a total of 140 documents. Both the tweets
and the documents (denoted with preﬁxes T and D, respec-
tively) were then analyzed as detailed below and as depicted
in Figure 1. We make no further distinction between the two
and collectively call them resources in our results.
Ethical Considerations & Data Protection. Our insti-
tutions did not require Institutional Review Board (IRB)
approval for this type of public information measurement
study.

When working with data during a crisis, ethical con-
siderations are essential to the study design, analysis, and
reporting. Due to the potential of targeted threats from
sophisticated attackers, our focus was on ensuring that
reporting in this study would not harm the population as
a whole or particular individuals more. As such, we do
not report potentially compromising data. Out of ethical
concerns, we decided against contacting people who live in
a war zone or had recently ﬂed one for interviews or other
direct interaction to avoid bothering potentially traumatized
people and focused on publicly available data instead [74].
We stored all data protected from unauthorized access by
encryption and access control. While all data was public
at the time of collection, we refrain from republishing it
alongside this work to preserve people’s privacy and control
over how their identiﬁable data is shared, as well as their
ability to delete their data.

3.2. Data Analysis

We outline our data analysis pipeline below and in
Figure 1. Our goal in analyzing the security and privacy
advice was to create a taxonomy of the different types of
advice shared during the invasion and to compare it to types
of advice that prior work has found.

1. https://developer.twitter.com/en/products/twitter-api/academic-

research

2. https://developer.twitter.com/en/docs/tutorials/stream-tweets-in-real-

time

3. https://github.com/tweepy/tweepy
4. https://github.com/twintproject/twint

Initial Codebook
Creation of initial codebook based on previous related
work.

1. Data Collection
The initial dataset consisted of 8,920 tweets retrieved
between February and May 2022 via the Twitter Academic
Researcher API, Twitter Stream.

2. Preﬁltering
Pre-selection of 1,228 relevant tweets based on keywords
and other metrics such as likes and retweets.

3. Relevance Evaluation
Manual evaluation of tweets for security & privacy advice
in relation to the 2022 Russian Invasion of Ukraine and
extraction of linked documents.

4a. Tweets
Evaluation dataset of 232
relevant tweets.

4b. Documents
Evaluation dataset of 140
directly linked documents.

5. Qualitative Coding
Qualitative open coding coding with seven coders, re-
solving conﬂicts as they emerge, and adding codes as
necessary.

6a. Tweet Coding
Tweets were assigned a
total of 888 codes, 161
unique codes.

6b. Document Coding
Documents were assigned
a total of 917 codes, 212
unique codes.

7. Afﬁnity Merge
To investigate emerging themes and directions, we con-
ducted a code merge and afﬁnity diagramming session,
creating seven categories and 21 subcategories.

Taxonomy of Advice
Based on the ﬁnal codebook including 451 ﬁnal codes in
seven categories, we developed a taxonomy of security &
privacy advice.

Comparison to Prior Work
We compared our results to those of prior studies qualita-
tively and using correlation.

Figure 1: Illustration of the data analysis pipeline. Based on
the ﬁnal codes, we created a taxonomy of security & privacy
advice surrounding the 2022 Russian Invasion of Ukraine,
and conducted a comparison with prior work.

approach does not necessitate the reporting of intercoder
agreement, because each conﬂict is resolved as it emerges,
resulting in a hypothetical ﬁnal agreement of 100% [78].
Our ﬁnal codebook consisted of 451 unique codes. Seven
codes served to distinguish sources and targets of advice.
Of the 444 codes referring to pieces of advice, 221 were
assigned at least once. Unused codes from prior work were
kept at count zero for the comparison.

To investigate emerging themes and directions in our
codes, we used the afﬁnity diagramming method [79] on
the codes we had assigned at least once. We conducted
a collaborative afﬁnity diagramming session with ﬁve re-
searchers and iteratively established seven categories and
21 subcategories. An overview is presented in Table 4.
Finally, in order to compare our ﬁndings with prior work, we
manually matched our codebook to theirs. We qualitatively
analyzed the top ten corresponding codes from each data
set and computed correlation using Spearman’s correlation
coefﬁcient [80]. Frequencies of advice were normalized for
the number of resources that were coded in each data set,
and advice not present in at least one codebook was omitted.

3.3. Limitations

Our work includes a number of limitations typical for
this type of measurement study and should be interpreted in
context. Given our method of data collection, it is possible
that we have missed some advice or types of advice. Even
though Twitter data is commonly used during crises around
the world [46], [50], [52], [72], [73] and gave us rich insights
into advice targeted at those affected by the invasion, data
obtained from Twitter may not be representative of all
available advice sources, meaning that our data set may not
fully represent the entirety of advice given in the context
of the Ukraine war. To mitigate this risk, we only applied
very broad ﬁlters to our initial data collection, and thereafter
manually coded data points for their relevance. Additionally,
we followed links to advice sources outside of Twitter and
included these documents in our data set. As none of us
speak Ukrainian, we may have encountered a language bar-
rier. We did, however, include translated search terms during
data collection and received useful results from automated
translation tools, which allowed us to code tweets in various
languages. Finally, errors or misunderstandings may have
occurred during our manual coding process. We minimized
this risk by having independently coded each tweet and
document by at least two researchers and resolving any
emerging conﬂicts.

For our study with advice and resource artifacts, we
evaluated both qualitative and quantitative data points. We
analyzed all collected tweets and documents in an iterative
open coding approach [75]–[77]. All researchers together
created an initial codebook based on previous work that
collected pieces of advice from Twitter data as well as other
sources ([10], [11], [65], [67]). Tweets and linked documents
were then coded by seven coders, resolving conﬂicts by
consensus decision or by introducing new (sub)codes. This

4. Results

In this section, we present the results of our analysis
of the ﬁnal corpus of 232 coded tweets and 140 coded
documents. The set of coded tweets has a median number of
likes of 56 (sd: 5,151) and a median number of retweets of
30 (sd: 2,468). We ﬁrst report on the taxonomy of the advice
we created, detailing what advice was shared in connection
to the invasion by and for whom (Subsection 4.1). Secondly,

we describe the results of comparing our data to previously
collected security and privacy advice and its evaluation
(Subsection 4.2). While we do give indications how many
resources contained advice, our ﬁndings are qualitative in
nature.

Target

Source

Company
NPO
Government
News
Individual

Individuals Organizations Total

221
42
36
19
44
91

135
26
8
47
19
41

372
57
44
57
53
116

4.1. Analysis of Advice

In our analysis, we identiﬁed ﬁve types of advice sources
and distinguished between advice targeted at individuals and
organizations. We present an overview in Table 1.

Below, we present our ﬁndings in detail. The reporting
is structured following the categories and subcategories of
advice we identiﬁed through the afﬁnity diagramming of our
codes (see Table 4). For each category, we analyze advice for
individuals as well as recommendations made to companies
and organizations. Figure 2 shows an overview of the counts
of assigned codes. In cases where the advice for both target
groups was very similar, we merge the reporting to avoid
repetition. In addition, we provide noteworthy insights on
advice sources where appropriate.

Figure 2: Heatmap of code categories and the number of
times they appeared in advice resources, differentiated by
target group.

4.1.1. Messaging & Social Media. The largest portion
of advice (101 resources) targeted individuals and dealt
with their social life online. We identiﬁed three key areas
of advice on this topic: recommendations regarding secure

TABLE 1: Overview of sources and targets of advice.

instant messaging, advice on social media proﬁles and shar-
ing practices, and pointers regarding misinformation. While
some of the resources also addressed organizations, none of
them directed this type of advice towards them.
Secure Messaging. Recommendations regarding (secure)
instant messaging were focused around which applications
one should or should not use, with a total of 36 resources
advocating for or against the use of at least one speciﬁc
application. They mostly originated from nonproﬁt organi-
zations (NPOs), news outlets, and individuals and mentioned
13 distinct applications. Six resources warned that phone
and SMS services were insecure and not private. Signal (9
times) and WhatsApp (7 times) were generally endorsed as
secure, but there were also claims of insecurities that both
companies called out as false. One individual tweeted that
“@WhatsApp seems to be monitored by Russians,” (T2745)
to which WhatsApp said in their Twitter thread on the
Ukraine war that

“As always, your personal messages and calls are
protected with end-to-end encryption by default so
they cannot be intercepted by any government.” —
T4048

Similarly, there were claims that “Signal Russia has been
breached.” (T2766) Signal promptly refuted this:

“This is false. Signal is not hacked. We believe these
rumors are part of a coordinated misinformation
campaign meant to encourage people to use less
secure alternatives.” — T2763
Telegram was the most discussed application (15 re-
sources). All advice related to Telegram mentioned risks
associated with the default settings of the application, which
do not enable encryption of messages. Several also pointed
out prevalent user misconceptions regarding this setting,
e. g., that through “misleading marketing and press, most
people [in Ukraine] believe it’s an encrypted app,” (T2757)
with one person taking it one step further claiming “that
branding may literally cost lives.” (T2745) Outside of high-
lighting the risks of using Telegram, a few news resources
discussed the importance of the app in the distribution of
information in Ukraine, both from individuals and govern-
ment channels, stating that the uses may outweigh security
concerns. Unfortunately, only one document provided a
step-by-step guide to turning on encryption for chats in
Telegram.

In general, the most frequently (11 times) recommended
feature for secure instant messaging was (end-to end) en-
cryption, followed by self-destructing messages (7 times),

IndividualsOrganizationsTotalTargetMessaging&SocialMediaSafeonlinebehaviorAuthenticationHardware&SoftwareStoringDataOrganizationalPoliciesLearning&TeachingCategory10191047126843931594237662430445242550649220406080100HeatmapofAdviceCategoriesandTargetsfor which some companies speciﬁcally posted guides on
how to turn them on. Peer-to-peer messaging applications
were promoted as a means of communications in case of
internet shut-downs or outages (7 times).

Advice for Social Media. The advice around social me-
dia proﬁles and sharing practices centered on privacy and
controlling what information people shared to whom. Indi-
viduals and social media companies were the main sources
the latter predominantly shared
for this type of advice;
feature descriptions and usage guides for their own products.
14 resources recommended that people should review their
privacy settings or tighten visibility on their content. To
this end, Meta introduced a region-bound new feature for
locking Facebook proﬁles and hiding their content from the
public that was recommended seven times. For Twitter users,
deactivating their proﬁle to hide old content was suggested
four times. The measures were recommended to anyone in
contact with people “in Ukraine to help protect people from
being targeted,” (T4053) and revealed a general concern that
private information already available online may now lead
to physical harm.

Advice on sharing practices called for being aware
of what is shared (5 times). It extended from cautioning
against posting sensitive information (6 times) to war-related
speciﬁcs, e. g., location information and its potentially dam-
aging role to military strategies was a focus. “Everyone is
a target. DO NOT share locations of military operation in
#Ukraine in real time.” (T8925) Accordingly, people were
asked not to add meta data to posts (7 times), to remove meta
data from previous posts (4 times), and not to live-tweet (4
times). One news article as well as one individual warned
people against sharing videos or pictures of prisoners of
war, “which some experts have argued violates the Geneva
Conventions.” (D112)

Bewaring of Misinformation. Related to war news and
information shared online, misinformation was a common
topic. A total of 44 resources warned that wrong information
was frequently shared and must be watched out for, with
16 speciﬁcally mentioning Russian disinformation. While
most resources left it at this rather generic warning, some
questions for spotting fake claims, such as “Does it look
like Ukraine? Does it look like February time?” (T1004)
could be found, along with the advice to not share anything
one had not veriﬁed (4 times). Two resources recommend
reverse image searches to quickly ﬁnd out if material had
been put online previously in other contexts, and two re-
sources recommended reporting accounts that shared fake
information to combat its spread.

Key Insights: Messaging & Social Media.
• Secure messaging advice focused on the usage of speciﬁc

applications.

• Social media advice focused on features to protect private

information.

• Warnings about misinformation were common but often

generic.

4.1.2. Safe Online Behavior. At 84 resources, a signiﬁcant
portion of advice was on safe online behaviors and being
careful with trust online. We divided this advice into the
three major subcategories phishing, malware, and connec-
tions and anonymity. Most of this advice (71 resources)
targeted individuals, while 26 resources addressed organi-
zations and companies.

Phishing. Phishing was widely considered to be a signiﬁcant
threat that would become more prevalent as scammers tried
to proﬁt from the war, with 54 resources calling for height-
ened vigilance of people (42 times) and organizations (23
times). The advice for both target groups was very similar,
with companies being additionally told to spread the advice
to their employees. Most advice came from government
institutions (13 resources), companies (11 resources), and
news outlets (11 resources).

The most general pieces of advice included to think
before clicking (7 times), to not click links from unknown
sources (3 times), to watch out for phishing (8 times), and to
be suspicious of, e. g., unknown people, popups, requests,
and things that are too good to be true (7 times). Seven
resources advised to report any phishing attempts to author-
ities, and six resources cautioned against revealing personal
information unless one was certain who was receiving them.
Many resources (35) regarded emails as the most likely
medium for phishing. Of these, 19 generally said to be alert
to phishing emails. More speciﬁcally, 10 resources noted
that one should be suspicious of emails asking one to click
links, with three resources going as far as saying one should
not click links in emails at all. The sender was another aspect
that advice focused on, recommending to be wary of false or
unusual emails from trusted institutions (7 times), to verify
suspicious senders and not trust sender addresses (2 times),
and to not open emails from unknown senders (1 time).

Aside from email, resources also warned about phishing
through instant messages (6 times) and social media plat-
forms (3 times).

Malware. We found that a rise in the threat of malicious
software was widely reported as a consequence of the war
(47 resources). Both individuals (23 times) and organiza-
in very
tions (32 times) were warned about
similar ways, and a majority of the warnings originated from
news articles (18 resources) and government institutions (9
resources), with the latter mainly targeting organizations and
companies.

this threat

Of the 47 resources, 14 only generally talked about mal-
ware as a risk to be aware of, without providing mitigation
strategies. The others focused on two main vectors through
which malware could be introduced to a system: installing
software, and email attachments. Regarding email attach-
ments, 12 resources advised varying degrees of cautiousness,
ranging from being suspicious of email attachments (11
times) over not opening attachments from unknown senders
(5 times) to not opening any unnecessary attachments (1
time). For installing software (21 resources), the general
advice of only installing software from trusted sources (11
resources) was extended in multiple ways speciﬁc to the

crisis at hand. About half of the resources (11) discouraged
the usage of software that came from Russia. A prominent
example that most of them (9 resources) referenced was se-
curity software from the Russian provider Kaspersky, which
multiple Western government agencies spoke out against,
recommending

“replacing applications from Kaspersky’s portfolio
of antivirus software with alternative products
over doubts about the reliability of the manufac-
turer” — D42.

Two resources asked people to beware of offers providing
free software, like VPN services, pointing out that scam-
mers may exploit people’s acute need for such services to
plant malicious software. One news article described how
scammers also exploited people’s wishes to help Ukraine by
“promot[ing] a fake DDoS tool on Telegram that installs a
password and information-stealing trojan.” (D9). Both this
article and one Twitter user generally discouraged people
from participating in any cyber attacks, as they are illegal
and can be a big risk, especially to non-experts.
Connections & Anonymity. Advice regarding the safety of
internet connections and being anonymous on the network
appeared in 35 resources, of which 34 targeted individuals.
Only six of the resources directed advice at organizations,
with no remarkable differences in the advice for individuals.
A majority (27 resources) recommended using speciﬁc
types of software to secure connections and preserve privacy.
The most common were VPN services (17 resources). Six of
these were advertisements from a company providing VPN
services. The others originated from NPOs, news outlets,
and individuals. They described two different use cases
of VPNs. One was to circumvent local censorship, telling
people to “set up VPN services to help you access blocked
sites during a partial [internet] shutdown.” (D129) One
person explained how they used “a VPN to a Western State
to avoid Russian censorship.” (T2893) The other was to
secure communications and preserve anonymity, explaining
that “When conﬁgured correctly, a VPN will secure all of
your communications from local interception,” (D140) and

“It hides your IP address and your location. It also
encrypts your data after leaving your device and
traveling to whatever website you’re visiting.” —
D69

Another software that NPOs, news outlets, and individuals
commonly recommended for online anonymity was the TOR
browser (12 resources). It was seen as a tool to circumvent
censorship, with one user tweeting “Tor is a mean of ac-
cessing truth safely. Tor is the equivalent of hidden atenas
[sic] in the WWII.” (T6901) Six tweets drew attention to a
special project offering an uncensored and privacy protected
way to browse Twitter using Tor.

Next to the software recommendations, there was also
some general advice reminding people that internet connec-
tions could be a security risk (10 resources). Speciﬁcally,
they said to not
trust open networks (2 times) and to
only use trusted networks (2 times). Additionally, it was

recommended to turn off network features including WiFi,
mobile internet, and Bluetooth whenever they were not used
(3 times), as they may still disclose one’s location. A very
situation-speciﬁc advice that appeared twice was to hide Star
Link ground stations Ukrainians received to ensure internet
access and to use them sparingly, as they might become
targets for military attacks.

Key Insights: Safe Online Behavior.
• There were many warnings about intensiﬁed phishing and

malware distribution but few actionable imperatives.

• To preserve conﬁdentiality and anonymity, VPNs and Tor

Browser were common suggestions.

4.1.3. Authentication. In 59 resources talking about au-
thentication, we identiﬁed three subcategories of security
advice: advice regarding account credentials, recovery, and
multi-factor authentication (MFA). Individuals (39 times)
and organizations (31 times) were targeted by this advice
alike, mostly by government agencies (17 times), companies
(10 times), and individuals (10 times).
Passwords. Security advice on credentials was mostly fo-
cused on passwords, with 34 resources advocating the use of
strong passwords. Speciﬁc criteria as to what constitutes a
strong password were rarely given. The resources mentioned
randomness, length, and including a combination of letters,
numbers, and special characters. Using unique passwords for
each account was mentioned a total of 18 times across our
dataset, while fewer resources (11) recommended the use of
a password manager. Of those recommending a password
manager, eight emphasized that choosing strong passwords
was still vital: “Have a strong, unique password that you
store in a password manager.” (D124)

The documents targeted at companies and organizations
included policy directives such as ensuring that password
policies are in place and being enforced: “Ensure you
have a strong password policy that is policed and main-
tained.” (D20) Updating or resetting employees’ passwords
frequently was among the least frequently shared pieces of
advice, with two documents mentioning it. In both cases,
the advice was motivated in the context of possibly exposed
credentials through security breaches via known vulnerabil-
ities.
Recovery. One company shared advice to their users on
how to make account recovery more resilient to attacks by
enabling a setting which requires either the associated email
address or phone number to be entered on password reset
attempts, whereas usually the username sufﬁces.

In an attempt to thwart brute-force attacks and in re-
sponse to a recent Russian state-sponsored attack on an
NGO, a government institution recommended the use of
time-outs for repeated failed login attempts (D99).
Multi-Factor Authentication. Advice around enabling
MFA was prevalent with 30 occurrences across all resources.
While the authors mentioned hardware tokens a few times,
most chose to recommend 2FA without going into further
detail. Companies themselves recommended that their users
enable MFA for their services nine times, notable examples

being Twitter and WhatsApp (Meta), while government in-
stitutions recommended it in a more general sense, mostly to
businesses (14 times). A notable exception is the following
tweet that is targeted at the broader population: “Implement-
ing multi-factor authentication on your accounts makes it
99% less likely you’ll get hacked.” (T1183) In this case,
the exaggerated claim of effectiveness might be an attempt
to increase adoption, although it is supported by data from
Microsoft [81].

We identiﬁed 16 resources that mentioned enforcing
MFA for (privileged) accounts as a security measure for
companies, while 20 mentioned it in total. A majority of
these resources (10) was documents shared by government
institutions. One individual on Twitter suggested an initial
“crash deployment” of MFA that would begin a staggered
roll-out for privileged accounts and then extend it to ac-
counts with access to conﬁdential data as well as to em-
ployees who may be targeted by phishing attacks (T564).

Key Insights: Authentication.
• Choosing strong passwords was the most common advice but

mostly lacked speciﬁc criteria.

• MFA was ascribed a very high effectiveness in securing ac-

counts.

4.1.4. Hardware & Software. Advice regarding device
security, mainly related to hardware and software, was
split into three categories, namely: updating software and
systems, using security software, and bolstering device and
hardware security. The three categories of advice we found
are discussed below.
Software & System Updates. Updating software and de-
vices regularly were some of the common pieces of advice
that we encountered. Advice regarding updates for individ-
uals included keeping general software and devices up-to-
date (17 resources). Additionally, individuals were advised
to install updates for friends and families (1 resource).

“Update your own software on your phones, lap-
tops, desktops, smart devices. Updates patch
known security ﬂaws. Once you’ve updated your
own software, do it for your parents, aunts, uncles.
This is actual self-defense.” — T4098

Keeping systems and software updated and patched, and
updating devices and device ﬁrmware was mentioned for
organizations as well (10 resources). For instance, some of
the advice indicated a sense of urgency in their messaging:

“I cannot emphasize enough. Everyone, all your
companies, all your phones, everything, update
your virus protection and download your security
patches IMMEDIATELY.” — T4064

Additionally, using automatic updates for devices and soft-
ware was mentioned in six resources, and considering the
availability of automatic updates when buying a new device
was mentioned two times. A majority of the advice was also
about reminding individuals and organizations to keep their
security software like antivirus up-to-date (19 resources).

Security Software. In order to bolster the security of com-
panies and individuals, three resources focused on advice
to developers. This advice included building security into
products from the ground-up, conducting regular penetration
tests and audits, and minimizing the complexity of systems
and services used.

“Build security into your products from the ground
up — “bake it in, don’t bolt it on” — to pro-
tect both your intellectual property and your cus-
tomers’ privacy.” — D116.

In addition to advice provided to organizations, eight
resources mentioned changing settings of anti-virus and
anti-malware software to run periodic scans, checking for
anti-virus signatures and patches, and disabling Microsoft
macros (two resources each).

“Implement mitigations against phishing and spear
phishing attacks. Disable Microsoft Ofﬁce macros
by default and limit user privileges. Ensure that
staff report all suspicious emails received, links
clicked, or documents opened.” — D31

Additionally, a majority of the advice (21 resources) was
also directed at individuals installing and using security
software. Two resources mentioned use security software
without adding any further details. However, using anti-
virus software (10 times), anti-malware software (5 times),
ﬁrewalls (8 times), vulnerability scanning software (3 times),
spam-ﬁltering services (3 times), integrity monitoring soft-
ware (1 time), and a virtual machines (1 time) were specif-
ically mentioned in the context of security software to
strengthen individuals’ security.
Device & Hardware Security. In terms of device and hard-
ware security, some of the advice for individuals mentioned
locking their devices. Locking devices without any further
mention of the best practices or methods surfaced three
times. Locking smartphones using a passcode or touch ID
appeared two times. Furthermore, individuals were advised
to set up auto-lock timers for their smartphones (1 resource).
While some advice focused on using passcodes and touch
IDs, we also found one resource catered to journalists that
talked about disabling biometrics on devices:

“I can tell you that independent Russian newsrooms
all instruct their employees in Russia to disable all
biometrics on their smart devices, to prevent the
cops from smashing your ﬁnger on Touch ID or
holding your phone in front of you for Face ID.”
— T972

Enabling biometrics for software access appeared once.
Additionally, a facet of advice about being careful while
plugging external devices into computers appeared in 10
resources. This advice further included scanning external
devices before plugging them into personal computers (1
resource). Two resources also mentioned avoiding plugging
external devices into computer systems altogether. Finally,
one resource also mentioned using a data blocker before
using USB charging ports. Other advice targeted towards

individuals included discarding devices with security weak-
nesses (2 resources), factory resetting devices to remove
malware (2 resources), factory resetting cellphones (1 re-
source), and keeping work and personal devices separate
(2 resources). We encountered one resource from a news
agency that provided advice for protecting devices in case
people are arrested or detained and in case their devices may
be “conﬁscated and searched.” (D133) They speciﬁcally
mentioned not using devices that are no longer supported
by the manufacturer, using devices that support setting
passwords, and enabling remote wiping of devices.

Some of the resources (10) also advised turning off lo-
cation services on devices to disable tracking. Additionally,
one resource from an individual advised people to not use
cell phones in safe houses.

Key Insights: Hardware & Software.
• Software advice focused on using security software such as
antivirus and on making regular software secure from the
beginning or through updates.

• Device security was centered around preventing unwanted

access and tracking.

4.1.5. Storing Data. Advice regarding what data to store
and how appeared in 44 resources. It targeted both indi-
viduals (24 resources) and organizations (30 resources). We
divided the advice into three distinct categories: backups,
logging, and preventing unwanted access.
Backups. A total of 30 resources advised individuals (16
resources) and organizations (23 resources) about backing
up their data. Most prevalent was the general recommenda-
tion to have backups (22 resources), which was similar for
both target groups. Contrastingly, the more speciﬁc advice
differed. Organizations received recommendations tailored
to professional data handling, such as testing the backup and
restore process (12 resources) and isolating backups from
their network (6 resources), e. g.

“Test backup procedures to ensure that critical
data can be rapidly restored if the organization
is impacted by ransomware or a destructive cy-
berattack; ensure that backups are isolated from
network connections.” — D89

Advice for individuals was more diverse and often focused
on speciﬁc actions rather than a broader strategy. Examples
include “Scan or take photos of all important docs and send
them to your own email account.” (T534) and “Back up all
your devices to an external hard drive or to the cloud.”
(D43)
Logging. Advice to store logging data was mainly given to
organizations and companies (14 resources) and mostly orig-
inated from government institutions (11 times). The general
advice to verify that logging was done and how and for how
long the logs were stored (7 resources) was supplemented
with pointers on what to log. Recommendations included
key functions (4 resources), network activity (4 resources),
authentication activity (2 resources), access to personnel
information (1 resource), and changes to security-enabled
groups (1 resource).

Preventing Access. Of the nine resources giving advice
on how to prevent unwanted access to data, all targeted
individuals, and one also targeted organizations. A majority
of them (6) came from NPOs. There were two strategies,
minimizing how much data was stored and thus available
(7 resources) and encrypting the data that was stored (7
resources). For data minimization, recommendations were
to remove sensitive ﬁles from devices, not to store data
unnecessarily, and to disconnect from accounts (4 resources
each). Less common were pointers to rename contacts to
hide their identity (2 resources) and to regularly delete one’s
browser history (1 resource). Advice on encryption focused
on what to encrypt and named device data (7 resources),
backups (4 resources), hard drives (2 resources), and cloud
data (2 resources). One resource recommended to “activate
the protocol to delete the information after a few wrong
[decryption attempts].” (T3033)

Key Insights: Storing data.
• Advice focused on preserving data and preventing unwanted

access.

• There was a stark contrast between professional strategies
recommended to organizations and singular quick-and-easy
actions recommended to individuals.

4.1.6. Organizational Policies. We found 25 resources giv-
ing advice about policies that only applied to organizations
and grouped them into the two categories incident response
and recovery plans as well as access and network policies.
About two thirds (15) of the resources gave advice coming
from government organizations.
Incident Response & Recovery Plans. A vast majority
of resources that dealt with organizational policies (23)
contained information about responding to security incidents
and having plans for recovery from such incidents. Of these,
11 recommended developing an incident response plan,
while nine advised to verify that a plan existed and was
up to date. Regarding the content of the plan, six resources
said it should be known and actionable, and six stressed
the importance of having contact information for essential
personnel available. Three resources mentioned that routes
of an incident response plan should be accessible even
if systems had been shut down. Another three resources
suggested practicing the response plan in the organization,
i. e., the US agency CISA recommended to “Conduct a
tabletop exercise to ensure that all participants understand
their roles during an incident.” (D89)
Access & Network Policies. A majority of resources (16)
made recommendations regarding access control and net-
work policies. For internal access, eight resources advised
that the principle of least privilege access should be fol-
lowed. Keeping track of authorization and timely removing
accounts of leavers and unused accounts was recommended
by eight resources as well. Two resources mentioned that
next to digital access control, preventing unauthorized phys-
ical access to systems was an important measure. For
networks, six resources advised to isolate them, and four
resources recommended to disable any unused ports and

protocols on the network. In addition to general network
security measures, the US agency CISA included isolation
and extra careful inspection of trafﬁc from Ukrainian organi-
zations and blocking activity from VPN or Tor connections
into their situation-speciﬁc recommendations.

Key Insights: Organizational Policies.
• Advice focused on up-to-date, properly communicated plans

for incident response and recovery.

• Isolating networks and strict authorization were recommended

defenses.

4.1.7. Learning & Teaching. Finally, advice on usage and
distribution of security information, learning, and teaching
in our data collection, as various entities
was prevalent
offered, referenced, and commented on advice resources.
We collected 92 resources with such content, targeted at
individuals (50 times) and organizations and companies (64
times). They had diverse sources, the most common being
government agencies (24 resources) and individuals (21
resources), followed by NPOs (14 resources) and companies
(13 resources). We identiﬁed four subcategories: meta ad-
vice about sharing security advice during crises, awareness
and resources, learning, and building a threat model.
Recommendations for Sharing Advice During Crises.
Some of the tweets dealt with the topic of sharing security
advice during crises itself, wherein the authors gave other
to share advice, guidance
professionals, who may want
on how to prioritize classes of advice and what topics or
phrasings to avoid. Four authors of advice resources asked
that the readers pass on the given advice to friends and
family. Advice givers should do their due diligence and
refrain from recommending single tools while drastically
overstating their efﬁcacy with respect to security or privacy,
especially during the current situation in Ukraine. One Twit-
ter user pointed out that giving digital security advice was
a major responsibility and that “[one should not] encourage
people to entrust their safety to one thing. Especially not in
conﬂict.” (T504).

In line with this, three resources encouraged others to
give realistic as well as actionable advice that takes into
account that security and privacy priorities may be different
for people in Ukraine and that is more speciﬁc than, e. g.,
following all the advice that has been reiterated for years.
Correspondingly, one individual focused on actionable ad-
vice and called on companies to prioritize a fast roll-out
of basic security measures in the face of emerging cyber
threats: “We need to make things BETTER, NOW! We can
tweak and harden later, when we have the basics deployed.”
(D112). Nine resources, which were mostly shared by com-
panies citing government institutions (3) or by government
institutions themselves (2), also recommended that compa-
nies raise awareness for increased risks by, e. g., performing
employee training. However, the resources mainly pointed
to conveying current security best practices without going
into further detail.
Awareness & Resources. 58 resources did not offer advice
themselves but rather raised awareness for resources pro-

vided by others. 43 resources offered help in the form of
technical guidance or support, often directly to Ukrainian
companies. Government institutions were most notable here
(14 times), followed by fellow companies and NPOs (8
times each). For the former, this took the form of, e. g.,
accepting forwarded websites, emails, and texts in an ef-
fort to support Ukraine by not falling victim to attacks
(T8889). Companies offered free services like ﬁrewalls and
VPNs. Offers for individual consulting on security were
common as well. In four resources, the advice givers warned
that “there’ll be well-intentioned twitter connectivity advice.
Some great. Some not.” (T504) Others reported advice they
had come across that may be impractical or even actively
damaging to the individual’s or company’s security:

“[. . . ] Lots of great info but please don’t follow
their mitigation advice for ICS. It’s not practical
& in some cases dangerous. [. . . ]” — T617

Five resources in total advocated that companies and or-
ganizations follow current best practices in security without
giving speciﬁcs. Also in ﬁve cases, government institutions
set up newsletters for companies to receive updates on
emerging threats and advisories. In contrast to the efforts
around offering support, two Twitter users told companies
and organizations that the steps to protect from cybercrime
had not changed:

“Contrary to the marketing emails that’ll ﬂood your
inbox in the coming days inviting you to a webcast
on how to protect against Russian attacks, the
measures to protect your org haven’t changed a
bit since the war started.” — T3978

Learning. General advice related to learning about security
appeared in nine resources in total.

Staying up-to-date with security and privacy develop-
ments and to keep learning was shared in four documents
from companies, NPOs, government institutions, and news
sites (1 time each). D139 as a security guide for journalists
is an example of a learning resource that became highly ap-
plicable again in light of the invasion. It dedicates an entire
section to technology security in conﬂict areas, ranging from
threat modeling, secure communications, over mobile device
security to malware, data integrity, and secure credentials.
Written by a NPO with a target group of journalists in
general, it was shared again on Twitter by the NPO, this
time speciﬁcally mentioning reporters in Ukraine.

Five documents, with four being targeted at companies,
endorsed learning and getting advice from security experts
as well as professionals. In two, government institutions
pointed to their own services, while a news site indicated
urgency but stayed vague:

“If you don’t have a competent security team to
help (and most don’t), you absolutely must ﬁnd a
reputable security partner immediately.” — D17.

Threat Modeling. Advice on building threat models as a
foundation for choosing security advice to apply appeared

in 28 resources and was a category with notable distinc-
tions between advice targeted at individuals and advice for
organizations.

Of the advice targeting individuals (14 resources), the
majority (7 resources) generally recommended thinking
about threats when making security choices and came from
individuals (4 times) and NPOs (3 times). More speciﬁc
pointers such as that average people may be targeted by
advanced persistent
threats or scammers and bots were
rare (3 and 2 times) and came mostly from news outlets
and government institutions. One individual stressed: “To a
human scammer or a bot, they/it don’t care who you are,
you’re just a vulnerable victim. Practice safe computing.”
(T4098)

Organizations and companies were targeted in 23 re-
sources. For them, general pointers to think about threats
were less prevalent (6 resources). Instead, most of the re-
sources were more speciﬁc, with 10 referring to advanced
persistent threats, three to the software supply chain as a
potential attack vector, two to scammers and bots, and one
to overseas attackers. Most of this information originated
from government institutions (7 times) and was shared by
news (4 times), individuals, NPOs, and the government itself
(1 time each).

Key Insights: Learning & Teaching.
• Several resources called for giving advice responsibly and

making it actionable.

• Offers for free individual support and consulting were ex-

tended to affected people and organizations.

• There was a disagreement between people calling for immedi-
ate measures and people saying the measures to take had not
changed at all.

• Having a threat model was sometimes recommended, but there

was no actionable guidance on prioritizing advice.

4.2. Comparison with Prior Work

To answer our second research question, we compare our
ﬁndings for advice targeting individuals to those of two other
papers that have investigated this kind of advice sharing.
While Reeder et al. collected advice by asking experts to
name the top three pieces of advice they would give non-
tech-savvy users in 2017 [11], Boyd et al.
investigated
advice shared on Twitter in the context of the BLM protests
in 2020 [72]. Additionally, we evaluate the advice from
our data collection t hat was targeted at individuals using
data from Redmiles et al. on advice priority as well as
uselessness and harmfulness of advice [10].

4.2.1. Comparing Data Collections. In this section, we
present the comparison of our data to that of prior work.
The top ten most frequent pieces of advice from each data
set can be found in Table 2.
Advice for Non-tech-savvy Users. In their analysis of
advice for non-tech-savvy users. Reeder et al. collected and
coded 231 expert responses for the advice they contained,
using 152 unique codes. Of these, 56 match codes from

our codebook. The frequencies with which advice appeared
in their and our data collection were moderately correlated
(Spearman, r = 0.44, p = 0.004), with notable similarities
in the most frequent advice. Of their top ten, all pieces of
advice were present in our data collection. Our top ten pieces
of advice included their top four as well as one other of their
pieces of advice. Of our top ten pieces of advice, those on
the topic of misinformation, pointers to support with cyber
security, insecurity of Telegram messenger, and VPN usage
were not part of the data collected by Reeder et al.
Advice Shared in the Context of BLM Protests. Of the
193 unique codes Boyd et al. assigned, only 26 matched
codes in our codebook, which in part stems from them cod-
ing speciﬁcally for rationales of advice, while we did not. Of
the matching advice, the frequencies in our data collection
do not correlate with those in their collection in a statistically
signiﬁcant way (Spearman, r = 0.278, p = 0.16). Of our top
ten pieces of advice, only two occurred in their data. Of the
advice that matched, all that belonged to the top ten during
the BLM protests were present in our data collection, but
only one was also among our top ten most frequent pieces
of advice, with the others having low counts in our data
collection.

Key Insights: Comparing Data Collections.
• The most frequent advice was similar to that Reeder et al.

found for non-tech-savvy users.

• There were few similarities between the advice around the

invasion and that shared during the BLM protests.

4.2.2. Evaluation of Advice. In their paper “A Compre-
hensive Quality Evaluation of Security and Privacy Advice
on the Web”, Redmiles et al. provide detailed insights into
how end users and security experts evaluate security advice
for end users from internet sources [10]. We mapped 241
pieces of advice from their data set to 451 of our own unique
codes. 102 of their advice imperatives matched one of our
221 assigned codes that refer to advice content. An overview
of the top ten pieces of advice can be found in Table 3.
Priority Rankings. With their replication package, Red-
miles et al. provide separate priority rankings of advice
for expert and end user evaluation, which combine their
more ﬁne-grained ratings. We look at the overall correlation
between the rank a piece of advice got from experts as
well as users and its frequency in our data. Additionally,
we analyze the overlap and differences in the top ten advice
pieces from each of the rankings and our data (see Table 3).
the expert priority ranking moderately
correlates with the number of times advice was present in
our data (Spearman, r = 0.424, p < 0.0005). Nine out of the
top ten advice pieces from the expert ranking were present
in our data collection. Two of them, namely “Use different
passwords for each account” and “Use strong passwords”,
were among our top ten most frequently shared advice.

We ﬁnd that

The user priority ranking of advice only very weakly
correlates with the frequencies in our data collection (Spear-
man, r = 0.181, p = 0.004). Of the top ten advice pieces,
seven occurred in our data collection, albeit in overall much

smaller quantities than those from the expert rankings. None
could be found in our top ten most frequent pieces of advice.
In our top ten advice pieces, six were rated by users and
experts. As expected given the correlations described before,
they have rather high ranks in the expert ranking with the
highest being ﬁrst and the lowest at rank 53. By contrast,
they are spread out through the user ranking with the highest
at 22 and the lowest at 190. The other four top pieces of
advice deal with misinformation, instant messenger recom-
mendations, and pointers to sources of support. These topics
are notably absent from the data Redmiles et al. collected via
user search queries and expert recommendations for advice
sources in 2017. The low correlation with the user ranking,
which Redmiles et al. based partly on user-perceived action-
ability of advice, aligns with our general ﬁnding that advice
we collected was often very generic.
Useless or Harmful Advice. Next to the priority rankings,
Redmiles et al. also provide data on which advice was
deemed useless or harmful by at least one of the security
experts they asked. Of the 25 pieces of advice labeled
useless, only “shut down your computer” was part of our
data collection (1 resource). Of the advice categorized as
harmful, four pieces can be found in our data: “Use Tor” (12
resources), “don’t open attachments from unknown senders”
(5 resources), “change passwords frequently” (1 resource),
and “buy devices with passwords” (1 resource). This shows
that usefulness is a debated topic. To some extent, advice
that some experts have deemed harmful or useless will
continue to be circulated.

Key Insights: Evaluation of Advice.
• Advice frequently shared during the invasion was given high

priority by experts in the study of Redmiles et al. [10].

• Much of the very frequent advice scored low on a user
priority ranking based on i.a. perceived actionability and time
consumption [10].

5. Discussion

We analyzed 232 tweets and 145 linked documents
shared around the 2022 Russian Invasion of Ukraine re-
garding the security and privacy advice they contained. In
221 unique pieces of advice, we ﬁnd a large variety of
recommendations that ﬁve different types of sources gave
to individuals and organizations. In addition, we ﬁnd note-
worthy similarities to the advice for non-tech-savvy users
by Reeder et al. [11], and signiﬁcant differences to advice
collected in the context of BLM protests by Boyd et al. [72].
We note a stronger correlation of advice frequency to the
priority ranking of experts than to that of users presented
by Redmiles et al. [10]. From our ﬁndings, we derive the
following main insights.
The lack of prioritization becomes even more apparent
and detrimental during a crisis. The 221 unique pieces
the security
of advice in our data collection show that
advice shared around the invasion lacks focus. A plethora of
companies, NPOs, government agencies, news outlets, and
individuals shared advice they believed relevant, resulting

in a large amount of advice without any obvious way to
prioritize. The various sources failed to ﬁnd a consensus
or rally behind a common set of measures to take. Fre-
quently,
they stressed the importance of following their
advice immediately to counter the threat, contributing to an
abundance of advice marked as high priority. Much of this
advice is too generic to be actionable and a reiteration of
long-established security measures that have been shown to
struggle with adoption in the past [68]. In this, the advice
shows similarities to that collected by Reeder et al. [11]
and Redmiles et al. [68]. Both ﬁnd a need for a clear,
consistent set of advice to provide to end users [10], [11].
We ﬁnd that advice for organizations could similarly proﬁt
from consistency and prioritization.
In the face of an acute crisis,

it seems even more
detrimental to overload advice recipients, as the additional
pressure during a crisis can be expected to make it much
harder to deal with. We argue that
in a war zone and
during other crises, the amount of time and resources that
can be spent on the implementation of measures is even
more constrained than usual for both individuals and orga-
nizations. Being overwhelmed is not helpful and may add
additional pressure. We suggest the involvement of people
with relevant experiences in the development of guidelines
to giving advice during crises, to account for the special
circumstances recipients of the advice might face.

In addition, we re-emphasize the need for empirical
research into the impact of security measures with the goal
of establishing an agreed-upon core set of high priority
security and privacy advice such as suggested by Redmiles
et al. [10]. If tailored to each target group, such a core
set could then serve as a baseline for advice given to both
individuals and organizations.

Offers for individual support and counseling can be a
valuable tool. In addition to advice imperatives, we found
offers for free security support and counseling on security
threats and countermeasures. In contrast to broadcast guide-
lines, these can take individual needs and circumstances into
account and can be a highly effective method if conducted
by qualiﬁed experts. We suggest investigating the adoption
and effectiveness of such offers in future work and to
consider funding them as long-term initiatives if proven
successful. In the meantime, we encourage the security
community to keep making such generous offers to people
facing war and other crises.

Misinformation is a rising threat. While misinforma-
tion, and speciﬁcally misinformation on social media during
crises, has been studied in various contexts [51], [82], [83],
the topic was not present in any of the related work on
security and privacy advice that we compared our data to.
Prior work ﬁnds a lack of actionable countermeasures [82],
and we argue that this is an important issue that should con-
cern the information security community. While the focus
previously appeared to lie with political opinions and real
life events, the claim that Signal had been breached and the
subsequent dismissal of that statement as misinformation
by the company show that security advice and practices

# Our Data

Reeder et al. [11]

Boyd et al. [72]

1 Beware of disinformation
2 Support pointers
3 Use strong passwords
4 Use multi-factor authentication
5 Keep systems and software up-to-date/patched Use antivirus software

Keep systems and software up to date
Use unique passwords
Use strong passwords
Use multi-factor authentication

6 Use a VPN
7 Beware of Russian disinformation
8 Be alert to phishing email
9 Telegram is insecure
10 Use different passwords for each account

Use a password manager
Use HTTPS
Use only software from trusted sources
Use automatic updates
Be careful/think before you click

Disable biometric unlocking
Use E2EE messaging app
Use Signal
Turn off location
Avoid identiﬁable people (in social media
posts)
Remove metadata (from social media posts)
Encrypt device
Turn off Bluetooth and WiFi
Use a strong password
Disconnect cellular data

TABLE 2: Top ten pieces of advice compared by frequency of appearance.

# Our Data

Expert Priority [10]

User Priority [10]

1 Beware of disinformation
2 Support pointers
3 Use strong passwords
4 Use multi-factor authentication
5 Keep systems and software up-to-date/patched Never give your credentials to third parties

Use different passwords for each account
Update devices and device ﬁrmware
Use anti-malware software
Scan attachments you open for viruses

Never give your credentials to third parties
Buy devices with security-focused platforms
Don’t open unnecessary attachments
Use anti-virus software
Don’t click random or unfamiliar links from
unknown senders

6 Use a VPN

Use unique passwords for different accounts Verify suspicious emails, senders, and email

7 Beware of Russian disinformation

8 Be alert to phishing email

9 Telegram is insecure

Use (end-to-end) encryption for communica-
tion
Keep anti-virus software installed and up-to-
date
Use strong passwords

10 Use different passwords for each account

Turn on automatic updates for devices

contents
Not open email from unknown senders

Don’t friend/put in your contacts people you
don’t know
Be suspicious if something is too good to be
true
Set your antivirus/anti-malware to run periodic
full scans

TABLE 3: Top ten pieces of advice compared to user and expert priority rankings in Redmiles et al. [10].

can be inﬂuenced just as much. Misinformation pointers
were a prevalent topic in our analysis and are an important
factor for safe social media usage. During a war or crisis,
access to information can be vital, and the ability to tell
information and misinformation apart is thus critical [51],
[84]. Unfortunately, actionable advice on how to do that was
rare in our resources. In addition, the given measures such
as verifying details and reverse image searches are time-
consuming and thus unlikely to be adopted for the many
posts and many pieces of advice that users see [85]. As
a research community, we should contribute to combating
misinformation by measuring its impact on security behav-
iors and developing mitigation strategies for security experts
as well as users.

cant similarities to two of them as well as newly emerging
topics. Unfortunately, we conﬁrm previous ﬁndings that
overwhelming amounts of advice are shared. Most are called
high priority, leaving no pointers for effective prioritiza-
tion. This appears even more detrimental in stressful and
resource-constrained situations like wars and other crises.
We ﬁnd that in light of this, offers for individual support
could be a valuable tool, the adoption, and effectiveness of
which should be part of further research. In addition, we
identify misinformation as a rising threat that may corrupt
efforts to educate populations on security and privacy mea-
sures. As such, it should be addressed by the information
security community in future research on its impact, and
possible mitigation strategies and their effectiveness.

6. Conclusion

References

In this paper, we studied security and privacy advice that
was shared around the 2022 Russian Invasion of Ukraine.
Speciﬁcally, we analyzed 232 tweets and 140 linked docu-
ments using qualitative open coding. We distinguished ad-
vice targeted at individuals and organizations, as well as ﬁve
types of sources: companies, NPOs, government agencies,
news outlets, and individuals. Using afﬁnity diagramming,
we created a taxonomy containing 221 unique pieces of
advice, clustered into seven categories. We then compared
our ﬁndings to those of three prior studies, ﬁnding signiﬁ-

[1] P. Jakub, Russia’s war on ukraine: Timeline of cyber-

attacks, 2022.

[2] Cybersecurity and Infrastructure Security Agency
(CISA), SHIELDS UP, https://www.cisa.gov/shields-
up, Accessed 2022-06-02, May 2022.

[3] Australian Cyber Security Center (ACSC), Australian
organisations encouraged to urgently adopt an en-
hanced cyber security posture, https : / / www. cyber.
gov . au / acsc / view - all - content / alerts / australian -
organisations- encouraged- urgently- adopt- enhanced-

cyber- security - posture, Accessed 2022-06-02, Mar.
2022.

[4] National Cyber Security Centre (NCSC), Uk organ-
isations encouraged to take action in response to
current situation in and around ukraine, https://www.
ncsc . gov . uk / news / uk - organisations - encouraged -
to - take - action - around - ukraine - situation, Accessed
2022-08-09, Jan. 2022.

[5] Bundesamt

für

Informationssicherheit

(BSI), Ein-
schätzung der aktuellen Cyber-Sicherheitslage in
Deutschland nach dem russischen Angriff auf die
Ukraine, https : / / www . bsi . bund . de / DE / Service -
Navi/Presse/Pressemitteilungen/Presse2022/220225_
Angriff- Ukraine- Statement.html?nn=1025778, Ac-
cessed 2022-08-09, May 2022.

[6] Canadian Centre for Cyber Security, Cyber threat bul-
letin: Cyber centre reminds canadian critical infras-
tructure operators to raise awareness and take mit-
igations against known russian-backed cyber threat
activity, https://cyber.gc.ca/en/guidance/cyber-threat-
bulletin - cyber - centre - reminds - canadian - critical -
infrastructure- operators, Accessed 2022-08-09, Feb.
2022.

[7] R. Alkhadra, J. Abuzaid, M. AlShammari, and N.
Mohammad, “Solar winds hack: In-depth analysis and
countermeasures,” in 2021 12th International Confer-
ence on Computing Communication and Networking
Technologies (ICCCNT), IEEE, 2021, pp. 1–7.
[8] M. Crosignani, M. Macchiavelli, and A. F. Silva,
“Pirates without borders: The propagation of cyber-
attacks through ﬁrms’ supply chains,” FRB of New
York Staff Report, no. 937, 2021.

[9] Shikhar Mehrotra), Russia-Ukraine War: Signal Says
Hack Claims Part Of ’coordinated Misinformation
Campaign’, https://www.republicworld.com/world-
news / russia - ukraine - crisis / russia - ukraine - war -
signal - says - hack - claims - part - of - coordinated -
misinformation - campaign - articleshow . html, Ac-
cessed 2022-07-27, Mar. 2022.

[10] E. M. Redmiles, N. Warford, A. Jayanti, A. Koneru,
S. Kross, M. Morales, R. Stevens, and M. L. Mazurek,
“A comprehensive quality evaluation of security and
privacy advice on the web,” in 29th USENIX Security
Symposium (USENIX Security 20), 2020, pp. 89–108.
[11] R. W. Reeder, I. Ion, and S. Consolvo, “152 simple
steps to stay safe online: Security advice for non-
tech-savvy users,” IEEE Security & Privacy, vol. 15,
no. 5, pp. 55–64, 2017.

[12] K. Aytes and T. Conolly, “A research model for inves-
tigating human behavior related to computer security,”
Aug. 2003.

[13] O. Beris, A. Beautement, and M. A. Sasse, “Em-
ployee rule breakers, excuse makers and security
champions: Mapping the risk perceptions and emo-
tions that drive security behaviors,” in Proceedings
of the 2015 New Security Paradigms Workshop, 2015,
pp. 73–84.

[14] E. M. Redmiles, M. L. Mazurek, and J. P. Dickerson,
“Dancing pigs or externalities? measuring the ratio-
nality of security decisions,” in Proceedings of the
2018 ACM Conference on Economics and Computa-
tion, 2018, pp. 215–232.

[15] B. Stanton, M. F. Theofanos, S. S. Prettyman, and
S. Furman, “Security fatigue,” It Professional, vol. 18,
no. 5, pp. 26–32, 2016.

[16] S. Das, T. H.-J. Kim, L. A. Dabbish, and J. I. Hong,
“The effect of social inﬂuence on security sensitivity,”
in 10th Symposium On Usable Privacy and Security
(SOUPS 2014), 2014, pp. 143–157.

[17] S. Das, A. D. Kramer, L. A. Dabbish, and J. I. Hong,
“Increasing security sensitivity with social proof: A
large-scale experimental conﬁrmation,” in Proceed-
ings of the 2014 ACM SIGSAC conference on com-
puter and communications security, 2014, pp. 739–
749.

[18] S. Das, A. D. Kramer, L. A. Dabbish, and J. I. Hong,
“The role of social inﬂuence in security feature adop-
tion,” in Proceedings of the 18th ACM conference
on computer supported cooperative work & social
computing, 2015, pp. 1416–1426.

[19] S. Das, L. A. Dabbish, and J. I. Hong, “A typology of
perceived triggers for End-User security and privacy
behaviors,” in Fifteenth Symposium on Usable Pri-
vacy and Security (SOUPS 2019), 2019, pp. 97–115.
[20] A. E. Howe, I. Ray, M. Roberts, M. Urbanska, and
Z. Byrne, “The psychology of security for the home
computer user,” in 2012 IEEE Symposium on Security
and Privacy, IEEE, 2012, pp. 209–223.
J. Vitak, Y. Liao, M. Subramaniam, and P. Kumar, “‘I
Knew It Was Too Good to Be True’: The challenges
economically disadvantaged internet users face in
assessing trustworthiness, avoiding scams, and devel-
oping self-efﬁcacy online,” Proceedings of the ACM
on human-computer interaction, vol. 2, no. CSCW,
pp. 1–25, 2018.

[21]

[22] A. Acquisti, I. Adjerid, R. Balebako, L. Brandimarte,
L. F. Cranor, S. Komanduri, P. G. Leon, N. Sadeh,
F. Schaub, M. Sleeper, et al., “Nudges for privacy and
security: Understanding and assisting users’ choices
online,” ACM Computing Surveys (CSUR), vol. 50,
no. 3, pp. 1–41, 2017.

[23] A. Frik, S. Egelman, M. Harbach, N. Malkin, and
E. Peer, “Better late (r) than never: Increasing cyber-
security compliance by reducing present bias,” in
Symposium on Usable Privacy and Security, 2018,
pp. 12–14.

[24] C. Bravo-Lillo, S. Komanduri, L. F. Cranor, R. W.
Reeder, M. Sleeper, J. Downs, and S. Schechter,
“Your attention please: Designing security-decision
uis to make genuine risks harder to ignore,” in Pro-
ceedings of the Ninth Symposium on Usable Privacy
and Security, 2013, pp. 1–12.

[25] K. Busse, D. Wermke, S. Amft, S. Fahl, E. von
Zezschwitz, and M. Smith, “Replication: Do we
lose? modelling risk with in-
snooze if we can’t

centives in habituation user studies,” in Proceedings
of the 2019 Workshop on Usable Security (USEC),
USEC 2019, San Diego, CA, USA, February 24, 2019,
Feb. 2019.

[26] S. Egelman, L. F. Cranor, and J. Hong, “You’ve been
warned: An empirical study of the effectiveness of
web browser phishing warnings,” in Proceedings of
the SIGCHI Conference on Human Factors in Com-
puting Systems, 2008, pp. 1065–1074.

[27] A. Ronzhyn, “The use of facebook and twitter during
the 2013-2014 protests in ukraine,” in Proceedings
of the European Conference on Social Media, 2014,
pp. 442–449.

[28] M. D. Suslov, ““Crimea Is Ours!” russian popular
geopolitics in the new media age,” Eurasian geog-
raphy and economics, vol. 55, no. 6, pp. 588–609,
2014.

[29] A. Mishler, E. S. Crabb, S. Paletz, B. Hefright, and E.
Golonka, “Using structural topic modeling to detect
events and cluster twitter users in the ukrainian cri-
sis,” in International conference on human-computer
interaction, Springer, 2015, pp. 639–644.

[30] M. Makhortykh and Y. Lyebyedyev, “#Savedonbass-
people: Twitter, propaganda, and conﬂict in eastern
ukraine,” The Communication Review, vol. 18, no. 4,
pp. 239–270, 2015.

[31] M. Pantti, “The personalisation of conﬂict reporting:
Visual coverage of the ukraine crisis on twitter,”
Digital Journalism, vol. 7, no. 1, pp. 124–145, 2019.
[32] B. E. Wiggins, “Crimea river: Directionality in
memes from the russia-ukraine conﬂict,” Interna-
tional Journal of Communication, vol. 10, p. 35,
2016.

[33] M. Burke, C. Marlow, and T. Lento, “Feed me:
Motivating newcomer contribution in social network
sites,” in Proceedings of the SIGCHI conference on
human factors in computing systems, 2009, pp. 945–
954.

[34] M. S. Bernstein, E. Bakshy, M. Burke, and B. Karrer,
“Quantifying the invisible audience in social net-
works,” in Proceedings of the SIGCHI conference on
human factors in computing systems, 2013, pp. 21–
30.

[35] E. Christoﬁdes, A. Muise, and S. Desmarais, “Hey
mom, what’s on your facebook? comparing facebook
disclosure and privacy in adolescents and adults,”
Social Psychological and Personality Science, vol. 3,
no. 1, pp. 48–54, 2012.

[36] S. Y. Syn and S. Oh, “Why do social network
site users share information on facebook and twit-
ter?” Journal of Information Science, vol. 41, no. 5,
pp. 553–569, 2015.

[37] A. Zubiaga, A. Aker, K. Bontcheva, M. Liakata, and
R. Procter, “Detection and resolution of rumours in
social media: A survey,” ACM Computing Surveys
(CSUR), vol. 51, no. 2, pp. 1–36, 2018.
J. Lee, “The double-edged sword: The effects of
journalists’ social media activities on audience per-

[38]

ceptions of journalists and their news products,” Jour-
nal of Computer-Mediated Communication, vol. 20,
no. 3, pp. 312–329, 2015.

[39] N. DePaula and E. Dincelli, “Information strategies
and affective reactions: How citizens interact with
government social media content,” First Monday,
2018.

[40] M. A. Sit, C. Koylu, and I. Demir, “Identifying
disaster-related tweets and their semantic, spatial and
temporal context using deep learning, natural lan-
guage processing and spatial analysis: A case study
of hurricane irma,” International Journal of Digital
Earth, 2019.

[41] M. Imran, C. Castillo, F. Diaz, and S. Vieweg, “Pro-
cessing social media messages in mass emergency: A
survey,” ACM Computing Surveys (CSUR), vol. 47,
no. 4, pp. 1–38, 2015.

[42] Z. Wang and X. Ye, “Social media analytics for
natural disaster management,” International Journal
of Geographical Information Science, vol. 32, no. 1,
pp. 49–72, 2018.

[43] C. Reuter and M.-A. Kaufhold, “Fifteen years of so-
cial media in emergencies: A retrospective review and
future directions for crisis informatics,” Journal of
contingencies and crisis management, vol. 26, no. 1,
pp. 41–57, 2018.

[44] C. Reuter, A. L. Hughes, and M.-A. Kaufhold, “So-
cial media in crisis management: An evaluation and
analysis of crisis informatics research,” International
Journal of Human–Computer Interaction, vol. 34,
no. 4, pp. 280–294, 2018.

[45] A. Leavitt and J. J. Robinson, “The role of infor-
mation visibility in network gatekeeping: Information
aggregation on reddit during crisis events,” in Pro-
ceedings of the 2017 ACM conference on computer
supported cooperative work and social computing,
2017, pp. 1246–1261.

[46] A. Olteanu, S. Vieweg, and C. Castillo, “What to
expect when the unexpected happens: Social media
communications across crises,” in Proceedings of the
18th ACM conference on computer supported cooper-
ative work & social computing, 2015, pp. 994–1009.
I. Temnikova, S. Vieweg, and C. Castillo, “The case
for readability of crisis communications in social
media,” in Proceedings of the 24th international con-
ference on world wide web, 2015, pp. 1245–1250.

[47]

[48] A. Leavitt and J. A. Clark, “Upvoting hurricane
sandy: Event-based news production processes on
a social news site,” in Proceedings of the SIGCHI
conference on human factors in computing systems,
2014, pp. 1495–1504.

[49] O. Ozduzen and A. McGarry, “Digital traces of “twit-
ter revolutions”: Resistance, polarization, and surveil-
lance via contested images and texts of occupy gezi,”
International Journal of Communication, vol. 14,
pp. 2543–2563, 2020.

[50] L. Hagen, T. Keller, S. Neely, N. DePaula, and
C. Robert-Cooperman, “Crisis communications in

the age of social media: A network analysis of
zika-related tweets,” Social science computer review,
vol. 36, no. 5, pp. 523–541, 2018.

[62]

[51] Y. L. Huang, K. Starbird, M. Orand, S. A. Stanek,
and H. T. Pedersen, “Connected through crisis: Emo-
tional proximity and the spread of misinformation
online,” in Proceedings of the 18th ACM Confer-
ence on Computer Supported Cooperative Work &
Social Computing, ser. CSCW ’15, Vancouver, BC,
Canada: Association for Computing Machinery, 2015,
pp. 969–980.

[52] A. Arif, L. G. Stewart, and K. Starbird, “Acting
the part: Examining information operations within
#blacklivesmatter discourse,” Proc. ACM Hum.-
Comput. Interact., vol. 2, no. CSCW, Nov. 2018.
J. Kukkola, “Civilian and military information in-
frastructure and the control of the russian segment
of internet,” in 2018 International Conference on
Military Communications and Information Systems
(ICMCIS), IEEE, 2018, pp. 1–8.

[53]

[54] E. Claessen, “Reshaping the internet–the impact of
the securitisation of internet
infrastructure on ap-
proaches to internet governance: The case of russia
and the eu,” Journal of Cyber Policy, vol. 5, no. 1,
pp. 140–157, 2020.

[55] D. Xue, R. Ramesh, L. Evdokimov, A. Viktorov, A.
Jain, E. Wustrow, S. Basso, and R. Ensaﬁ, “Throttling
twitter: An emerging censorship technique in russia,”
in Proceedings of the 21st ACM Internet Measure-
ment Conference, 2021, pp. 435–443.

[56] K. Ermoshina, B. Loveluck, and F. Musiani, “A mar-
ket of black boxes: The political economy of internet
surveillance and censorship in russia,” Journal of
Information Technology & Politics, vol. 19, no. 1,
pp. 18–33, 2022.

[57] K. Ermoshina and F. Musiani, “Migrating servers,
elusive users: Reconﬁgurations of the russian internet
in the post-snowden era,” Media and Communication,
vol. 5, no. 1, pp. 42–53, 2017.

[58] R. Gabdulhakov, “(con)trolling the web: Social me-
dia user arrests, state-supported vigilantism and citi-
zen counter-forces in russia,” Global Crime, vol. 21,
no. 3-4, pp. 283–305, 2020.

[59] A. Akbari and R. Gabdulhakov, “Platform surveil-
lance and resistance in iran and russia: The case of
telegram,” Surveillance & Society, vol. 17, no. 1/2,
pp. 223–231, 2019.
I. Ion, R. Reeder, and S. Consolvo, “‘... No one Can
Hack My Mind’: Comparing expert and Non-Expert
security practices,” in Eleventh Symposium On Usable
Privacy and Security (SOUPS 2015), 2015, pp. 327–
346.

[60]

[61] K. Busse, J. Schäfer, and M. Smith, “Replication: No
one can hack my mind revisiting a study on expert
and Non-Expert security practices and advice,” in
Fifteenth Symposium on Usable Privacy and Security
(SOUPS 2019), 2019, pp. 117–136.

J. Nicholson, L. Coventry, and P. Briggs, ““If It’s
Important It Will Be A Headline”: Cybersecurity
information seeking in older adults,” in Proceedings
of the 2019 CHI Conference on Human Factors in
Computing Systems, 2019, pp. 1–11.

[63] M. Fagan and M. M. H. Khan, “Why do they do
what they do?: A study of what motivates users to
(not) follow computer security advice,” in Twelfth
symposium on usable privacy and security (SOUPS
2016), 2016, pp. 59–75.

[64] L. F. DeKoven, A. Randall, A. Mirian, G. Akiwate,
A. Blume, L. K. Saul, A. Schulman, G. M. Voelker,
and S. Savage, “Measuring security practices and how
they impact security,” in Proceedings of the Internet
Measurement Conference, 2019, pp. 36–49.

[65] Y. Zou, K. Roundy, A. Tamersoy, S. Shintre, J. Ro-
turier, and F. Schaub, “Examining the adoption and
abandonment of security, privacy, and identity theft
protection practices,” in Proceedings of the 2020 CHI
Conference on Human Factors in Computing Systems,
2020, pp. 1–15.

[66] E. M. Redmiles, A. R. Malone, and M. L. Mazurek,
“I think they’re trying to tell me something: Ad-
vice sources and selection for digital security,” in
2016 IEEE Symposium on Security and Privacy (SP),
IEEE, 2016, pp. 272–288.

[67] E. Rader and R. Wash, “Identifying patterns in in-
formal sources of security information,” Journal of
Cybersecurity, vol. 1, no. 1, pp. 121–144, 2015.
[68] E. M. Redmiles, S. Kross, and M. L. Mazurek,
“How i learned to be secure: A census-representative
survey of security advice sources and behavior,” in
Proceedings of the 2016 ACM SIGSAC Conference
on Computer and Communications Security, 2016,
pp. 666–677.

[69] Y. Acar, C. Stransky, D. Wermke, C. Weir, M. L.
Mazurek, and S. Fahl, “Developers need support, too:
A survey of security advice for software developers,”
in 2017 IEEE Cybersecurity Development (SecDev),
IEEE, 2017, pp. 22–26.

[70] C. Herley, “So long, and no thanks for the exter-
nalities: The rational rejection of security advice by
users,” in Proceedings of the 2009 workshop on New
security paradigms workshop, 2009, pp. 133–144.

[71] M. Tahaei, T. Li, and K. Vaniea, “Understanding
privacy-related advice on stack overﬂow,” Proceed-
ings on Privacy Enhancing Technologies, vol. 1,
p. 18, 2022.

[72] M. J. Boyd, J. L. Sullivan Jr, M. Chetty, and B.
Ur, “Understanding the security and privacy advice
given to black lives matter protesters,” in Proceedings
of the 2021 CHI Conference on Human Factors in
Computing Systems, 2021, pp. 1–18.

[73] R. Schroeder, S. Everton, and R. Shepherd, Mining
twitter data from the arab spring, Combating Terror-
ism Exchange 2.4 (2012): 54-64, 2012.

[74] R. Bhalerao, V. Hamilton, A. McDonald, E. M.
Redmiles, and A. Strohmayer, “Ethical practices for

security research with at-risk populations,” in 2022
IEEE European Symposium on Security and Privacy
Workshops (EuroS&PW), 2022, pp. 546–553.
[75] K. Charmaz, Constructing Grounded Theory. Sage,

2014.

[76] A. Strauss and J. M. Corbin, Grounded theory in

[77]

practice. Sage, 1997, p. 288.
J. Corbin and A. Strauss, “Grounded theory research:
Procedures, canons and evaluative criteria,” Qualita-
tive Sociology, vol. 19, no. 6, pp. 418–427, 1990.

[78] N. McDonald, S. Schoenebeck, and A. Forte, “Re-
liability and inter-rater reliability in qualitative re-
search: Norms and guidelines for cscw and hci prac-
tice,” Proc. ACM Hum.-Comput. Interact., vol. 3,
no. CSCW, Nov. 2019.

[79] H. Beyer and K. Holtzblatt, Contextual Design:
Deﬁning Customer-Centered Systems. San Francisco,
CA, USA: Morgan Kaufmann Publishers Inc., 1997.
[80] C. Spearman, “The proof and measurement of asso-
ciation between two things,” The American Journal
of Psychology, vol. 100, no. 3/4, pp. 441–471, 1987.
[81] Alex Weinert, Your Pa$$word doesn’t matter, https:
//techcommunity.microsoft.com/t5/microsoft- entra-
azure - ad - blog / your- pa - word - doesn - t - matter / ba -
p/731984, Accessed 2022-08-18, Jul. 2019.

[82] K. Starbird, “Disinformation’s spread: Bots, trolls and
all of us,” Nature, vol. 571, pp. 449–450, Jul. 2019.
[83] S. Houlden, J. Hodson, G. Veletsianos, D. Reid,
and C. Thompson-Wagner, “The health belief model:
How public health can address the misinformation
crisis beyond covid-19,” Public Health in Practice,
vol. 2, p. 100 151, 2021.

[84] K. Starbird, J. Maddock, M. Orand, P. Achterman,
and R. Mason, “Rumors, false ﬂags, and digital
vigilantes: Misinformation on twitter after the 2013
boston marathon bombing,” IConference, Mar. 2014.
[85] C. Geeng, S. Yee, and F. Roesner, “Fake news
on facebook and twitter: Investigating how people
(don’t) investigate,” ser. CHI ’20, Honolulu, HI, USA:
Association for Computing Machinery, 2020, pp. 1–
14.

Appendix A.
Taxonomy

The table below shows the categories and subcategories
of our taxonomy, as well as the two most frequently as-
signed codes as examples. The column count contains the
total number of resources a code was assigned to. For
the categories and subcategories, the count is an aggregate
of all codes they contain. The columns Individuals and
Organizations contain the number of resources that were
assigned the respective code as well as this target.

Category

Subcategory

Code

Count Individuals Organizations

Messaging & Social
Media

104

101

Secure Messaging

Advice for Social Media

Misinformation

Safe online behavior

Phishing

Malware

Connections & Anonymity

Authentication

Passwords

Recovery

Multi-Factor Authentication

Hardware & Software

Software & System Updates

Storing Data

Security Software

Device and Hardware Security

Backups

Logging

Preventing Access

Organizational Policies

Incident & Recovery Plans

Access & Network Policies

Learning & Teaching

Recommendations for Sharing Ad-
vice During Crises

Don’t use Telegram/Telegram is insecure
Use (end-to-end) encryption for communication

Review privacy settings
Don’t post photos/test with metadata

Disinformation
Beware of Russian disinformation

Be alert to phishing email
Be suspicious of emails asking you to click links

Don’t use software from Russia
Be suspicious of attachments

Use a VPN
Use anonymity systems (Use TOR/Psiphon)

Use strong passwords
Use different passwords for each account

Require email and phone number for a password reset
Enable timeouts and lock-outs for failed log-in attempts

Use MFA
Enforce MFA for privileged accounts/services/systems

Keep systems/software up to date
Keep anti-virus software installed and up-to-date

Use anti-virus software
Use anti-malware software

Turn off location devices
Lock devices

Backup your data
Test backup/restore

Ensure logging is done, storage, retention periods
Log key functions

Encrypt your device data
Log out of accounts

Incident Response Plans
Verify an incident response plan exists and is up to date

Apply least privilege access
Track authorization and access, remove leavers

Awareness & Resources

Learning

Threat Modeling

Alert users about increased risks
Share advice with friends and family

Support pointers
Guidelines

Seek professional help for cyber security issues
Always keep learning about security and privacy

Threat model
Advanced persistent threat groups

TABLE 4: Taxonomy.

44
15
11
31
12
7
44
28
16

84
54
19
10
47
11
11
35
17
12

59
40
34
18
4
3
1
45
30
20

66
42
34
11
27
10
5
22
10
3

44
30
22
13
17
7
4
9
5
4

25
23
11
9
16
8
7

92
18

9
4
58
43
5
9
5
4
28
10
10

43
15
11
31
12
7
42
26
16

71
42
15
9
23
6
10
34
16
12

39
29
24
14
3
3
0
28
20
9

42
22
17
7
12
7
3
19
10
3

24
16
13
4
4
0
0
9
5
4

5
5
3
1
0
0
0

50
11

3
3
31
25
1
5
2
3
14
7
2

9

3
1
1
1
0
0
6
6
0

26
23
7
4
32
10
5
6
3
2

31
17
15
7
1
0
1
26
15
16

37
31
27
6
21
7
4
4
0
0

30
23
18
12
14
7
4
1
1
0

24
22
10
9
16
8
7

64
13

9
1
40
27
5
6
4
2
23
6
10

