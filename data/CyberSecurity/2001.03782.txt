Optimizing Investments in Cyber Hygiene
for Protecting Healthcare Users

Sakshyam Panda1, Emmanouil Panaousis2,
George Loukas2, and Christos Laoudias3

1 University of Surrey, UK
s.panda@surrey.ac.uk
2 University of Greenwich, UK
{e.panaousis,g.loukas}@greenwich.ac.uk
3 University of Cyprus, Cyprus
laoudias.christos@ucy.ac.cy

Abstract. Cyber hygiene measures are often recommended for strength-
ening an organization’s security posture, especially for protecting against
social engineering attacks that target the human element. However, the
related recommendations are typically the same for all organizations and
their employees, regardless of the nature and the level of risk for diﬀer-
ent groups of users. Building upon an existing cybersecurity investment
model, this paper presents a tool for optimal selection of cyber hygiene
safeguards, which we refer as the Optimal Safeguards Tool (OST). The
model combines game theory and combinatorial optimization (0-1 Knap-
sack) taking into account the probability of each user group to being
attacked, the value of assets accessible by each group, and the eﬃcacy of
each control for a particular group. The model considers indirect cost as
the time employees could require for learning and trainning against an
implemented control. Utilizing a game-theoretic framework to support
the Knapsack optimization problem permits us to optimally select safe-
guards’ application levels minimizing the aggregated expected damage
within a security investment budget.
We evaluate OST in a healthcare domain use case. In particular, on the
Critical Internet Security (CIS) Control group 17 for implementing se-
curity awareness and training programs for employees belonging to the
ICT, clinical and administration personnel of a hospital. We compare
the strategies implemented by OST against alternative common-sense de-
fending approaches for three diﬀerent types of attackers: Nash, Weighted
and Opportunistic. Our results show that Nash defending strategies are
consistently better than the competing strategies for all attacker types
with a minor exception where the Nash defending strategy, for a spe-
ciﬁc game, performs at least as good as other common-sense approaches.
Finally, we illustrate the alternative investment strategies on diﬀerent
Nash equilibria (called plans) and discuss the optimal choice using the
framework of 0-1 Knapsack optimization.

Keywords: Cybersecurity, Cyber hygiene, Healthcare, Optimization,
Training and awareness, CIS control, Game theory

0
2
0
2

n
a
J

1
1

]

R
C
.
s
c
[

1
v
2
8
7
3
0
.
1
0
0
2
:
v
i
X
r
a

 
 
 
 
 
 
2

1

Panda et al.

Introduction

In the last few years, several cybersecurity incidents have taken place in the
healthcare sector, including the WannaCry ransomware, which inﬂuenced glob-
ally the cybersecurity landscape4. The 2018 Ponemon Cost of a Data Breach
study5 shows that the healthcare industry has the highest cost per record breached
in a cyber incident, at $408. This is almost twice the equivalent cost per record
breached in the ﬁnancial sector. This calls for the eﬀective preparation of health-
care organizations in an ever-evolving cyber attack landscape. An example project
that is addressing this from the perspective of training the users in the sector
is H2020 CUREX project6, which allows a healthcare provider to assess the
realistic cybersecurity and privacy risks they are exposed to [1].

Yet, a recent report from Mckinsey7 states that almost all companies sys-
tematically over-invest in the protection of assets that have no risk while at the
same time they under-fund the protection of high-risk assets. Furthermore, re-
garding bearing costs of cybersecurity controls, in a survey from KPMG8, 43%
of correspondents stated that they did not increase their cybersecurity budget
even though high proﬁle security breaches have been widely known. So, eﬀective
risk management is not only about assessing the risk correctly but also about
selecting the controls that are optimal given the cost constraints of adopting
them. To address the challenge of optimal control selection, in this paper, we
formulate a model and tool for suggesting mathematically optimal cyber hygiene
strategies minimising the cyber risk.

Regarding cyber hygiene, we adopt the recent deﬁnition proposed by [2],
which relates it to “the cyber security practices that online consumers should
engage in to protect the safety and integrity of their personal information on
their Internet enabled devices from being compromised in a cyber-attack.”

Towards the goal of optimizing cyber hygiene, we extend the model presented

in [3] so that:

– the Attacker’s target is a user group (focusing on social engineering attacks)

instead of (asset, vulnerability) pair of the system;

– the Indirect cost of a safeguards’ application depends not only on the safe-
guard itself but also on the size of the user group (i.e., number of users) and
more speciﬁcally it increases with the group size;

– we adopt an aggregated risk model, as the objective function of Knapsack op-
timization problem, rather than the weakest-link defending against a variety
of attacks that can cause, in total, highest aggregated damage and;

– we use a “small” healthcare case study as a preliminary example to evaluate
the OST against other common-sense approaches for a number of attacking
strategies that have not been simulated in [3].

4

5

6

7

8

https://www.telegraph.co.uk/technology/2018/10/11/wannacry-cyber-attack-cost-nhs-92m-
19000-appointments-cancelled.
https://securityintelligence.com/series/ponemon-institute-cost-of-a-data-breach-2018.
https://cordis.europa.eu/project/rcn/220350/factsheet/en.
https://www.mckinsey.com/business-functions/risk/our-insights/cyber-risk-measurement-and-
the-holistic-cybersecurity-approach.
https://advisory.kpmg.us/content/dam/advisory/en/pdfs/cyber-report-healthcare.pdf.

Optimizing Investments in Cyber Hygiene for Protecting Healthcare Users

3

Our analysis results show that the game-theoretic approach increases risk
control eﬃcacy, by selecting an optimal combination of safeguard application
levels, compared with alternative common-sense approaches. In addition, our
use case designed for the healthcare domain exhibits a number of interchange-
ably optimal investment strategies subject to a budget constraint under the
framework of 0-1 Knapsack optimization.

The remainder of this paper is organized as follows. Section 2 presents the re-
lated work in both the ﬁelds of (i) user-oriented cybersecurity safeguards and (ii)
optimization of cybersecurity countermeasures including security investments.
Section 3 presents both the game-theoretic model used to determine optimal
cybersecurity safeguard plans as well as the optimization problem modeled and
solved to derive the best ways to invest in these safeguards given a limited
available budget. In Section 4, we undertake comparisons of the game-theoretic
defending strategies against alternative common-sense approaches as well as we
plot the results of the Knapsack optimization to illustrate the optimal invest-
ment solutions. Finally, Section 5 concludes this paper by summarizing its main
contributions and highlighting future work to be undertaken to further improve
the performance and the usability of our model.

2 Related Work

This work has been inspired by a previous work of Fielder et al. [3] where the
authors have proposed decision support methodologies for the optimal choice
of cybersecurity controls within an investment budget. They have addressed
cybersecurity investment decisions by proposing diﬀerent approaches; a game-
theoretic approach, a combinatorial optimization approach and a mix of both
called hybrid. This paper utilizes the latter method to recommend the optimal
choice of safeguards for healthcare organizations. In this section, we discuss two
classes of work relevant to this paper: literature on cyber hygiene in healthcare
- more speciﬁcally on the user-oriented cybersecurity safeguards, and literature
on optimal selection of cybersecurity safeguards. Note that the literature covered
on optimal selection of cybersecurity safeguards mainly highlight work beyond
the literature covered in [3].

2.1 Cyber Hygiene in Healthcare

There have been growing concerns that the existing cybersecurity posture of
healthcare organizations are insuﬃcient and this has already impacted the con-
ﬁdentiality [4] and integrity of medical data [5]. Further, many healthcare orga-
nizations are still using legacy systems such as Windows XP and Windows NT
3.1 which Microsoft has long stopped supporting9, allowing adversaries to easily
breach the defenses (e.g., WannaCry attacks on NHS10). In general, healthcare

9

10

https://www.itpro.co.uk/public-sector/27740/nine-in-10-nhs-trusts-still-use-windows-xp.
https://www.nao.org.uk/wp-content/uploads/2017/10/Investigation-WannaCry-cyber-attack-
and-the-NHS-Summary.pdf.

4

Panda et al.

organizations being rich sources of valuable data and relatively weaker security
postures have become attractive targets for cybercrime [6]. The weaker secu-
rity posture that they exhibit is primarily due to lack of adequate cybersecurity
budget resulting in limited access to technology and expertise [7].

Besides, investment in cybersecurity has not been traditionally considered es-
sential for healthcare systems as emphasis has predominantly been upon provid-
ing patient care and people believed that there would be no motivation to attack
them. On the other hand, the increasing use of Internet of Things (IoT) technolo-
gies in healthcare has widened the attack surface beyond electronic health record
databases and privacy issues to physical safety [8]. Alongside technical aspects,
the role of the user in cybersecurity is paramount, as a signiﬁcant proportion
of attacks target the users directly through deceptive means such as application
masquerading and spear-phishing. This is particularly the case in healthcare as
deceiving a nurse, doctor, healthcare IT professional or administrator can impact
the privacy and physical safety of patients [9].

With the increasing usage of technology, the role that humans play in un-
derlying security processes will continually expand. Heartﬁeld and Loukas [10]
have developed a framework involving humans to eﬀectively detect and report
semantic social engineering attacks against them. Their results illustrate that
involving users signiﬁcantly improves the cyber threat detection rate aﬃrming
the importance of the human in cybersecurity. This further depicts that humans
can no longer be seen as a threat and/or vulnerability in cybersecurity.

Acknowledging the importance of human in cybersecurity along with the
increase in the severity of breaches, security experts, policymakers and govern-
ments are urging to improve cyber hygiene. Such et al. [11] have demonstrated
that Cyber Essentials11 have worked well for SMEs in mitigating threats ex-
ploiting vulnerabilities remotely using commodity-level exploitation tools. From
a human-cyber interaction perspective, Vishwanath et al. [2] have demonstrated
that cyber hygiene practices positively impact individuals’ cyber attitude which
is pivotal to cyber safety. These studies have actively exhibited that even general
concepts of basic cyber hygiene work in diﬀerent organizational contexts and can
convincingly reduce cyber risk.

Security training in healthcare has been studied for over 20 years. It ranges
from an exploratory analysis of the factors that healthcare professionals need
to focus on, up to highly targeted digital applications (e.g., [12]) and platforms
for raising awareness of healthcare data privacy and security risks. Furnell et
al. [13] discussed the necessity to promote information security issues and the
need for appropriate training and awareness initiatives in healthcare institutions.
They have highlighted factors to consider while designing training and awareness
programmes to familiarize healthcare personnel with basic security concepts and
procedures.

The eﬀect to which security training and awareness programmes work for
diﬀerent users has been studied from multiple angles. The authors have shown
that speciﬁcally for deception-based attacks, such as semantic social engineering

11

https://www.gov.uk/government/publications/cyber-essentials-scheme-overview.

Optimizing Investments in Cyber Hygiene for Protecting Healthcare Users

5

[14], where self-study and work-based training are considerably more eﬀective
than formal education in cybersecurity [15]. Besides, the perceived origin of
training materials i.e., from security experts, third party agencies, or peers can
have large impacts on security outcomes [16].

2.2 Optimal Selection of Cybersecurity Controls

Cybersecurity has become a key factor in determining the growth of organiza-
tions relying on information systems as it is not only a defensive measure but also
has become a strategic decision providing a competitive advantage over rivalry
ﬁrms. Further, the potential loss due to cyber incidents has encouraged organi-
zations to imperatively consider cybersecurity investment decisions, especially in
deriving the optimum level of investments between risk treatment options. The
objective of cybersecurity investment methodologies is to compute an optimal
distribution of cybersecurity budget and one of the initial work studying this
was performed by Gordon and Loeb [17].

Beyond previous works such as [3,18,19] and the related work investigated
there, Nagurney et al. [20] have proposed a game-theoretic supply chain net-
work model with retailers competing to maximize their expected proﬁts. This
maximization is based on determining optimal product transactions and cyber-
security investments under budget constraints. Along the direction of optimal
cybersecurity investments, Wang [21] investigated the cybersecurity investment
balance between acquiring knowledge and expertise, and deploying mitigation
techniques. On the other hand, Chronopoulos et al. [22] have opted a real options
approach to analyze the performance of optimal cybersecurity controls on orga-
nizations. In particular, the authors have analyzed the eﬀects of the cost of cyber
attacks and the time of arrival of cybersecurity controls on the organization’s
optimal strategy. Similar to these papers, our work also considers the choice
of the optimal strategy based on the eﬃcacy of the control towards mitigating
cyber risks.

Most closely, in terms of methodology, related recent work on optimal cy-
bersecurity investment is [23] where the authors have investigated the balance
between investing in self-protection and cyber insurance. The key diﬀerence is
that their optimization minimizes expected risk and cyber insurance premium,
while our model optimizes considering the eﬃcacy of control in mitigating the
aggregated residual risk and the security investment budget. Besides this, our
work uses a unique combination of game theory and combinatorial optimization
inspired by [3].

3 Optimal Cyber Hygiene Safeguards Model

3.1 System Model

Our model assists in acquiring an optimal selection of safeguards using game
be the set of potential
theory and combinatorial optimization. We assume

U

6

Panda et al.

user groups consisting of employees of a healthcare organization. Any employee
of a user group being susceptible to malicious activities can use any of the safe-
to improve their defense posture.
guards from the set of available safeguards
However, each safeguard has a set of implementation levels
with each level
having diﬀerent eﬃcacies in improving the security posture of user groups.

L

S

Each user group i is associated with an impact value which expresses the
level of expected damage to the healthcare organization, given a successful at-
tack against a user of a group i. This impact is equivalent to the overall asset
value in association with user group i and may relate to conﬁdentiality, integrity,
and availability. We further consider Ai to be a random variable that expresses
the overall value of the assets that the user group i has access to. For simplicity,
we let the users of a group have the same access privileges, thus having access
to assets of the same value. Users of diﬀerent groups have diﬀerent access priv-
ileges due to their diﬀerent roles (e.g., IT personnel, healthcare practitioners,
and administration) and access to diﬀerent assets. The vulnerability of a user
group i, i.e., the probability of being compromised by an attack, is captured by
the security level Si exhibited by the user group i. We assume that Si increases
with the number of safeguards applied as well as their application level.

Furthermore, we denote Ri as the threat occurrence, i.e., the probability of
a threat to attack the i user group, and Li as the expected loss associated with
a user group i. Using the well-known risk assessment formula, risk = (likelihood
of being attacked) x (probability of success of this attack) x probable loss [24],
we compute the risk as

Li = Ri Si Ai.

(1)

An attack against a user group i is partially mitigated by the eﬃcacy value of
the implemented cybersecurity safeguard pcj. The eﬃcacy parameter, modeled
as a random variable, depends on the selected application level and can be
represented as E(j, i) :
[0, 1). It is evident from real-world practices
that diﬀerent implementation levels work diﬀerently on diﬀerent users and this
has motivated us in considering E(j, i) rather than a single eﬃcacy value for the
level j against all user groups i. Note that E(j, i) is determined by the application
level j and the user group i. Due to the existence of 0-day vulnerabilities, we
assume that E(j, i)

L × U →

= 1.

Remark 1. Diﬀerent users have diﬀerent likelihood of adopting a measure. A
cyber hygiene measure works only when it is adopted, and this adaption rate
distinguishes human users from systems. For example, a user may decide not
to implement a cyber hygiene measure due to unﬁtting usability (e.g, hard to
remember complex passwords) even if the optimization framework recommends
otherwise.

Let S(j, i) be the security level of a user group i when level j is implemented
and can be expressed as S(j, i) = 1
E(j, i). Replacing Li and Si as L(j, i)
−
and S(j, i), respectively, in formula 1, we compute the cybersecurity loss for a

(cid:54)
Optimizing Investments in Cyber Hygiene for Protecting Healthcare Users

7

safeguard application level j and target i as

L(j, i) = Ri Ai [1

E(j, i)].

−

(2)

Equation 2 implies the expected damage of the Defender when a user group
i is successfully compromised given the investigated safeguard has been applied
at level j.

While the application of a cybersecurity safeguard strengthens the defense of
the healthcare organization, it is associated with two types of cost namely; indi-
rect and direct. Examples of indirect cost are System Performance and Usability.
We express the indirect cost of an application level j by the random variable
Z+. Note that C(j, i) adheres to the deﬁned property for any
C :
safeguard against a user group i. Further, the indirect cost increases with an
increase in the level of application of the safeguard i.e.,

C × L × U →

j > j(cid:48)

C(j, i)

C(j(cid:48), i),

= j(cid:48).

(3)

⇔

≥

j
∀

From the above, we derive the overall expected loss of the organization when

application level j is applied on user group i as

|U |

L(j, i) + C(j, i).

(4)

i=1
(cid:88)

Each level has also a direct cost expressed by the random variable F :

Z+
that maps the safeguards and application levels to the monetary cost of the plan.
In this paper, we refer the direct cost to be the available investment budget of
the organization. For reference purposes, the symbols used throughout this paper
are described in Table 1.

L →

3.2 Game-Theoretic Model for Selection of Safeguards Levels

This section presents a formal model for the selection of safeguard implementa-
tion levels for each of the available safeguards. The Defender chooses to imple-
ment (or apply as in this paper we use these two terms interchangeably) a cyber
, while the Attacker chooses to attack a user group from
hygiene safeguard from
. The Defender must decide to apply this safeguard at a speciﬁc level (pure
U
strategy) or combination of diﬀerent levels (mixed strategy) both from
. The
higher the level, the greater is the applied degree of a cyber hygiene safeguard.
We refer to the application of a safeguard s at a certain level j as cybersecurity
safeguard plan. This strategic interaction is modeled as a game where the De-
fender chooses the level of a safeguard to implement rather than the safeguards
from

L

S

.

We deﬁne the Cyber Safeguard Game (CSG) between Defender and Attacker,
as an one-shot, bimatrix game of complete information played for any of the
safeguards leading to a total number of
independent games. For simplicity, we
S
have assumed no inter-dependencies between the safeguards, i.e., each safeguard
mitigates a portion of the overall risk inﬂicted by the Attacker [25].

S

(cid:54)
8

Panda et al.

Symbol Description

S
U
L
Ri
Si
Ai
λ
Ud
Ua
δσ,j
α
α(i)
Li

Set of safeguards
Set of users
Set of safeguard implementation levels
Probability of group i to be attacked
Security level of group i
Asset value that group i has access to
Maximum application level
Utility of the Defender
Utility of the Attacker
Randomized Safeguard Strategy for safeguard σ at application level j
Randomized Attacking Strategy
Probability of attacking group i
Expected loss from group i

L(j, i) Expected loss from group i when choosing application level j
L(δσ,j, i) Expected loss from group i when choosing Safeguards Plan δσ,j

Indirect cost of level j when applied to group i

C(j, i)
E(j, i) Eﬃcacy of application level j on group i
E(δσ,j, i) Eﬃcacy of safeguards plan δσ,j on group i

Γσ,λ
δN E
σ,λ

Cyber Safeguard Game for safeguard σ and maximum application level λ
Nash Safeguards Plan

F (δσ,j) Financial cost of Safeguards Plan δσ,j
F (σ, j) Financial cost of safeguard σ when applied at level j

B

Available ﬁnancial budget to invest in Nash Safeguards Plans

Table 1: List of Symbols

∈ U

∈ L

The set of pure strategies of the Defender consists of all possible application
, while the Attacker’s pure strategies are the diﬀerent user groups
which could be targeted using attacks such as social engineering. Thus, in

levels, j
i
CSG a pure strategy proﬁle is a pair of Defender and Attacker actions, (j, i)

giving a pure strategy space of size

∈
. For the rest of the paper,
L × U
we adopt the convention where the Defender is the row player and the Attacker
is the column player.

|L| × |U|

≥

→

→

R− and Ua : (j, i)

Ud(j(cid:48), i). In general, given the set

Each player’s preferences are speciﬁed by a payoﬀ function deﬁned as Ud :
R+ for the Defender and Attacker, respectively,
(j, i)
for the pure strategy proﬁle (j, i). According to [26], we deﬁne a preference
relation (cid:37), when i is chosen by the Attacker, deﬁned by j (cid:37) j(cid:48), if and only if
of all available application levels
Ud(j, i)
of a safeguard, a rational Defender can choose a level (i.e., pure strategy) j∗ that
= j∗;
is feasible, that is j∗
, j
alternatively she solves the problem maxj∈L Ud(l, i), for a user group i
.
∈ U
Likewise, we deﬁne the preference relation for the Attacker, where i (cid:37) i(cid:48)
⇐⇒
Ua(j, i)
. CSG is a game deﬁned for
each cyber hygiene safeguard and it is realistic to assume that all levels may
be available for selection by the Defender. Their availability depends on the

L
, and optimal in the sense that j∗ (cid:37) j,

Ua(j, i(cid:48)), for an application level j

∈ L

∈ L

∈ L

j
∀

≥

(cid:54)
Optimizing Investments in Cyber Hygiene for Protecting Healthcare Users

9

investment budget of the Defender and the overall ﬁnancial cost of the game
solution.

To derive optimal strategies for the Defender, we deploy the notion of mixed
strategies. Since players act independently, we can enlarge their strategy spaces
to allow them to base their decisions on the outcome of random events that create
uncertainty to the opponent about individual strategic choices maximizing their
payoﬀs. Hence, both Defender and Attacker deploy randomized (i.e., mixed)
strategies. The mixed strategy δ of the Defender is a probability distribution over
the diﬀerent application levels (i.e. pure strategies) where δ(j) is the probability
of applying level j under mixed strategy δ. We refer to a mixed strategy of the
Defender as a Randomized Safeguard Strategy (RSS). For the ﬁnite nonempty
, let ΠL represent the set of all probability distributions over it, i.e.,
set

L

ΠL :=

δ
{

∈

R+R

|

.
δ(j) = 1
}

(cid:88)j∈L

(5)

Therefore a member of ΠL is a mixed strategy of the Defender. Likewise, the
Attacker’s mixed strategy is a probability distribution over the diﬀerent available
user groups. This is denoted by α, where α(i) is the probability of attacking the
i-th user group under mixed strategy α. We refer to a mixed strategy of the
Attacker as the Randomized Attacking Strategy (RAS). Alike (5), we express
ΠU as the set of all probability distributions over the set of all Attacker’s pure
). Therefore, a member of ΠU is as a mixed strategy
strategies (i.e., given by
of the Attacker. From the above, the set of mixed strategy proﬁles of CSG is the
Cartesian product of the individual mixed strategy sets, ΠL

ΠU .

U

×

, and it is denoted by supp(δ).
δ(j) > 0
}
|

Deﬁnition 1. (Support of RSS) The support of δ is the set of application levels
j
{
Deﬁnition 2. (Support of RAS) The support of α is the set of healthcare user
groups

α(i) > 0

, and it is denoted by supp(α).
}

i
|
{

The above deﬁnitions state that the subset of applications levels (resp. user
groups) that are assigned positive probability by the mixed strategy δ (resp. α)
is called the support of δ (resp. α)). Note that a pure strategy is a special case
of a mixed strategy, in which the support is a single action.

Now that we have deﬁned the mixed strategies of the players, we deﬁne CSG

as the ﬁnite strategic game

Γ :=

(Defender, Attacker), ΠL
(cid:104)
For a given mixed strategy proﬁle (δ, α)
ΠU , we denote by Ud(δ, α),
and Ua(δ, α) the expected payoﬀ values of the Defender and Attacker, where
the expectation is due to the independent randomization according to mixed
strategies δ, and α. This can be formally represented as

.
ΠU , (Ud, Ua)
(cid:105)

×
ΠL

(6)

×

∈

Ud(δ, α) :=

Ud(j, i) δ(j) α(i),

(cid:88)j∈L

(cid:88)i∈U

(7)

10

Panda et al.

and similarly

Ua(δ, α) :=

Ua(j, i) δ(j) α(i).

(cid:88)j∈L

(cid:88)i∈U

(8)

By using the preference relation we can say that, for an Attacker’s mixed
strategy α, the Defender prefers to follow the RSS δ as opposed to δ(cid:48) (i.e.,
δ (cid:37) δ(cid:48)), if and only if Ud(δ, α)
Ud(δ(cid:48), α).

≥

Deﬁnition 3. The Defender’s (resp. Attacker’s) best response to the mixed strat-
egy α (resp. δ) of the Attacker (resp. Defender) is an RSS (resp. RAS) δBR
ΠL (resp. αBR
Ud(δ, α),

ΠU ) such that Ud(δBR, α)

ΠL (resp. Ua(δ, αBR)

Ud(δ, α),

∈
ΠU ).

≥

α

∈

∈

∀

δ

∀

∈

≥

Remark 2. The game-theoretic solutions that we propose in the next section
involve randomization. For instance, in a mixed equilibrium, each player’s ran-
domization leaves the other indiﬀerent across her randomization support. These
choices can be deliberately randomized, however these are not the only equi-
libria interpretations. For instance, the probabilities over the pure actions (i.e.,
application level or user group pure selections) can represent (i) time averages
of an “adaptive” player, (ii) a vector of fractions of a “population”, where each
player type adopts pure strategies and, (iii) a “belief” vector that each player
has about the other regarding their behavior.

3.3 CSG solutions

Given the deﬁnition of CSG and its components, we derive optimal strategies for
the Defender. First, we investigate the problem of determining best RSSs and
RASs (i.e., mixed strategies), for the Defender and the Attacker respectively,
when both players are strategic and play simultaneously.

As we have not explicitly deﬁned the strategic type of Attacker, we consider
diﬀerent types of solutions based on various Attacker behaviors. This analysis
will allow us to draw robust conclusions regarding the overall optimal Defender
strategy, which will minimize expected damages regardless of the Attacker type.
The most commonly used solution concept in game theory is that of Nash
Equilibrium (NE) [26]. This concept captures a steady state of the play of the
CSG in which both Defender and Attacker hold the correct expectation about the
other players’ behavior and they act rationally. A NE dictates optimal responses
to each other’s actions, keeping the others’ strategies ﬁxed, i.e., strategy proﬁles
that are resistant against unilateral deviations of players.

Deﬁnition 4. In any Cyber Safeguard Game, a mixed strategy proﬁle (δNE, αNE)
of Γ is a mixed NE if and only if

1. δNE (cid:37) δ,

δ

∀

∈

ΠL, when the Attacker chooses αNE, i.e.

Ud(δNE, αNE)

∀δ∈ΠL Ud(δ, αNE);

≥

(9)

Optimizing Investments in Cyber Hygiene for Protecting Healthcare Users

11

2. αNE (cid:37) α,

α

∀

∈

ΠU , when the Defender chooses δNE, i.e.

Ua(δNE, αNE)

∀α∈ΠU Ua(δNE, α).

(10)

≥
Deﬁnition 5. The Nash Safeguards Plan (NSP), denoted by δNE, is a probabil-
ity distribution over the diﬀerent levels, as determined by the NE of the CSG.

Example 1. For a safeguard with 3 application levels including level 0, which
corresponds to not applying the safeguard at all, an NSP (0, 0.2, 0.8) dictates
that 20% of the users will be strengthened (e.g., trained) at j = 1 (e.g., once
when they join the organization), while 80% of the users will be applied a higher
level of the safeguard j = 2 (e.g., attending training once per year).

3.4 Optimality analysis

We model complete information Nash CSGs, according to which both players
know the game matrix, which contains the utilities of both players for each
pure strategy proﬁle. The utility function of the Defender is determined by the
probability of failing to protect a user group and the indirect costs of the chosen
application levels. We consider a zero-sum CSG, where the Attacker’s utility is
the opposite of the Defender’s utility. The rationale behind the zero-sum CSG
is that when the Defender is uncertain about the Attacker type, she considers
the worst case scenario, which can be formulated by a zero-sum game where the
Attacker can cause her maximum damage. The idea behind a zero-sum game like
this is that the Attacker focuses on causing maximum corruption to cyberspace,
while the Defender aims at minimizing the damage. Due to the Attacker’s goal
being conﬂicting to the Defender’s objective, the application of game theory to
study the selection of safeguards application levels is convenient. While in most
security situations the interests of the players are neither in strong conﬂict nor
in complete identity, the zero-sum game provides important insights into the
notion of “optimal play”, which is closely related to the minimax theorem [27].

In the zero-sum CSG,

Γ0 =

,
d, a
}

(cid:104){

L × U

Ud,

,

{

,
Ud}(cid:105)

−

(11)

the Attacker’s gain is equal to the Defender’s security loss, and vice versa. We
deﬁne the utility of the Defender in Γ0 as

U Γ0

d (j, i) :=

wL L(j, i)

−

−

wC C(j, i).

(12)

The ﬁrst term of (12) is the expected loss of the Defender inﬂicted by the At-
tacker when attempting to compromise user group i, while the second term
expresses the aggregated indirect cost of the safeguard application irrespective
[0, 1] are importance weights, which can
of the attacking strategy. Let wL, wC ∈
facilitate the Defender with setting her preferences in terms of security loss, and
indirect cost, accordingly.

12

Panda et al.

For a mixed proﬁle (δ, α), the utility of the Defender equals

U Γ0

d (δ, α)

(7)
=

(cid:88)

(cid:88)

U Γ0

d (j, i)δ(j) α(i)

j∈L
(cid:88)

i∈U
(cid:88)

(12)
=

[−wL L(j, i) − wc C(j)] δ(j) α(i)

(13)

j∈L

= −wL

i∈U
(cid:88)

(cid:88)

j∈L

i∈U

L(j, i) δ(j) α(i) − wC

C(j, i) δ(j).

(cid:88)

j∈L

As Γ0 is a zero-sum game, the Attacker’s utility is given by U Γ0
Since the Defender’s equilibrium strategies maximize her utility, given that the
Attacker maximizes her own utility, we will refer to them as optimal strategies.
As Γ0 is a two-person zero-sum game with a ﬁnite number of actions for
both players, according to Nash [28], it admits at least a NE in mixed strategies
and saddle-points correspond to Nash equilibria as discussed in [29] (p. 42). The
following result from [30], establishes the existence of a saddle (equilibrium)
solution in the games, we examine and summarizes their properties.

a (δ, α) =

−

U Γ0

d (δ, α).

Deﬁnition 6 (Saddle point of the CSG). The Γ0 Cyber Safeguard Game
(CSG) admits a saddle point in mixed strategies, (δNE
Γ0 ), with the property
that

Γ0 , αNE

∀
∀

α, and
δ.

– δNE
– αNE

The pair of saddle point strategies (δNE

Γ0 = arg maxδ∈∆L minα∈∆U U Γ0
Γ0 = arg maxα∈∆U minδ∈∆L U Γ0

d (δ, α),
a (δ, α),
Then, due to the zero-sum nature of the game, the minimax theorem [27] holds,
i.e. maxδ∈∆L minα∈∆U U Γ0

d (δ, α) .
Γ0 ) are at the same time security
strategies for the players, i.e. they ensure a minimum performance regardless of
the actions of the other. Furthermore, if the game admits multiple saddle points
(and strategies), they have the ordered interchangeability property, i.e. the player
achieves the same performance level independent from the other player’s choice
of saddle point strategy.

d (δ, α) = minα∈∆U maxδ∈∆L U Γ0
Γ0 , αNE

The minimax theorem [27] states that for zero-sum games, NE and mini-
max solutions coincide. Therefore, δNE
a (δ, α). This
means that regardless of the strategy the Attacker chooses, NSP is the Defender’s
security strategy that guarantees a minimum performance.
Formally, the Defender seeks to solve the following LP:

Γ0 = arg minδ∈∆L maxα∈∆U U Γ0

max
δ∈∆L


d (δ,ˆi )
U Γ0

min
α∈∆U
d (δ, 1) − minα∈∆U U Γ0
U Γ0
...
d (δ, |U|) − minα∈∆U U Γ0
U Γ0
δe = 1
δ ≥ 0.




d (δ,ˆi)e ≥ 0

d (δ,ˆi)e ≥ 0

subject to

(14)

In this problem, e is a vector of ones of size

.

|U|

Optimizing Investments in Cyber Hygiene for Protecting Healthcare Users

13

3.5 Multiple Games Per Safeguard

Given that we have to allocate a budget in applying diﬀerent safeguards, we may
come across the challenge of not having enough monetary resources to select
some of the equilibria of the CSG. Therefore, one has to derive the ﬁnancial cost
of equilibrium and assess its feasibility by comparing its ﬁnancial cost to the
available remaining budget. We refer to “remaining” budget as we expect that
the Defender will have to select among a number of equilibria, one per safeguard,
as we show later in this section.

To provide to the Defender a wider variety, in terms of ﬁnancial cost, of
equilibria per safeguard, we deﬁne a number of CSGs per safeguard. Each of
these games has a diﬀerent number of application levels available to the Defender.
Aligned with [3], for each safeguard σ, we study

CSGs.

|L|

Deﬁnition 7. To diﬀerentiate among diﬀerent safeguards and implementations
levels, we denote the CSG by Γσ,λ, where the safeguard σ can be applied up to
λ

[0,

].

∈

|L|

Note that we allow λ = 0 so that the Defender has the option to avoid
selecting a safeguard should this violate some budget constraints. A Knapsack
optimisation is used in the second phase of the model to select the equilibria, at
most one per safeguard. In this way, we manage to have
NSPs per safeguard,
each of a diﬀerent ﬁnancial cost. Each Γσ,λ is a game where (i) Defender’s pure
strategies correspond to consecutive application levels of safeguard σ starting
always from 0 and including all levels up to λ and, (ii) Attacker’s pure strategies
are the diﬀerent targets akin to user groups. Figure 1 illustrates the diﬀerent
Cybersecurity Safeguards Games along with the utilities of the Defender.

|L|

Let δN E

σ,λ be the equilibrium of Γσ,λ then

σ,λ = [δN E
δN E

σ,0 , δN E

σ,1 , . . . , δN E
σ,λ ].

(15)

Let F (δσ,λ) be the ﬁnancial cost of the safeguards plan δσ,λ which can be de-
rived by summing the ﬁnancial costs of all application levels j
for
safeguard σ contributed proportionally by using the corresponding probability
from δσ,λ, i.e., δσ,j. Let F (σ, j) denote the ﬁnancial cost of safeguard σ then

1, 2, . . . , λ

∈ {

}

F (δσ,λ) =

δσ,j F (σ, j).

(16)

(cid:88)j∈{1,2,...,λ}

3.6 Investment in Nash Safeguards Plans

be the set of all available safeguards to the Defender. We can solve all
CSGs and derive a set of equilibria per safeguard σ represented as

Let

S
|S| × |L|
follows

σ,1 , δN E
δN E

σ,2 , . . . , δN E

.
σ,|L|}

{

(17)

14

Panda et al.

Fig. 1: Illustration of the safeguard-centered model of OST used to devise game-
theoretic strategies for the Defender.

For all safeguards

NSPs, is available

1, 2, . . . ,
{

|S|}

the following set of sets of equilibria, i.e.,

{
(cid:110)

1,0 , δN E
δN E

1,1 , . . . , δN E

1,|L|}

,

2,0 , δN E
δN E
{

2,1 , . . . , δN E

2,|L|}

, . . . ,

|S|,0, δN E
δN E
{

|S|,1, . . . , δN E

|S|,|L|}

.

(18)
(cid:111)
Optimal budget allocation in cybersecurity can be tackled by combinatorial
optimization as previously investigated by Smeraldi and Malacaria [25]. We are
concerned with the challenge of protecting multiple targets, in our case user
groups, with the use of a number of NSPs that interact between them in diﬀerent
ways. In the following, we model the challenge of investing in these diﬀerent
NSPs in a way that at most one NSP per safeguard is chosen and the sum of
ﬁnancial costs of these NSPs ﬁts an available cybersecurity budget. We have used
0-1 Knapsack Optimization to solve this problem. As opposed to the solution

 <latexit sha1_base64="cNUg6UhGCC7rWHB/yN0CSQAAHw0=">AAAB7XicbVDJSgNBEK2JW4xb1KOXxiB4CjMu6DHoxWMEs0AyhJ5OT9Kml6G7RwhD/sGLB0W8+j/e/Bs7yRw08UHB470qqupFCWfG+v63V1hZXVvfKG6WtrZ3dvfK+wdNo1JNaIMornQ7woZyJmnDMstpO9EUi4jTVjS6nfqtJ6oNU/LBjhMaCjyQLGYEWyc1u4YNBO6VK37VnwEtkyAnFchR75W/un1FUkGlJRwb0wn8xIYZ1pYRTielbmpogskID2jHUYkFNWE2u3aCTpzSR7HSrqRFM/X3RIaFMWMRuU6B7dAselPxP6+T2vg6zJhMUkslmS+KU46sQtPXUZ9pSiwfO4KJZu5WRIZYY2JdQCUXQrD48jJpnlWD8+rl/UWldpPHUYQjOIZTCOAKanAHdWgAgUd4hld485T34r17H/PWgpfPHMIfeJ8/nqOPKg==</latexit>j=0<latexit sha1_base64="8XKQBGeHLeGg/jFEYtaglIOuDkg=">AAAB6nicbVDJSgNBEK2JW4xb1KOXxiB4CjMu6EUIevEY0SyQDKGnU5O06ekZunuEMOQTvHhQxKtf5M2/sbMcNPFBweO9KqrqBYng2rjut5NbWl5ZXcuvFzY2t7Z3irt7dR2nimGNxSJWzYBqFFxizXAjsJkopFEgsBEMbsZ+4wmV5rF8MMME/Yj2JA85o8ZK949XbqdYcsvuBGSReDNSghmqneJXuxuzNEJpmKBatzw3MX5GleFM4KjQTjUmlA1oD1uWShqh9rPJqSNyZJUuCWNlSxoyUX9PZDTSehgFtjOipq/nvbH4n9dKTXjpZ1wmqUHJpovCVBATk/HfpMsVMiOGllCmuL2VsD5VlBmbTsGG4M2/vEjqJ2XvtHx+d1aqXM/iyMMBHMIxeHABFbiFKtSAQQ+e4RXeHOG8OO/Ox7Q158xm9uEPnM8fw2ONdg==</latexit>j=1<latexit sha1_base64="0Se2ZAX4YJFFzXBHjRYRAAcHni8=">AAAB6nicbVDJSgNBEK2JW4xb1KOXxiB4CjMu6EUIevEY0SyQDKGnU5O06ekZunuEMOQTvHhQxKtf5M2/sbMcNPFBweO9KqrqBYng2rjut5NbWl5ZXcuvFzY2t7Z3irt7dR2nimGNxSJWzYBqFFxizXAjsJkopFEgsBEMbsZ+4wmV5rF8MMME/Yj2JA85o8ZK949XXqdYcsvuBGSReDNSghmqneJXuxuzNEJpmKBatzw3MX5GleFM4KjQTjUmlA1oD1uWShqh9rPJqSNyZJUuCWNlSxoyUX9PZDTSehgFtjOipq/nvbH4n9dKTXjpZ1wmqUHJpovCVBATk/HfpMsVMiOGllCmuL2VsD5VlBmbTsGG4M2/vEjqJ2XvtHx+d1aqXM/iyMMBHMIxeHABFbiFKtSAQQ+e4RXeHOG8OO/Ox7Q158xm9uEPnM8fxOeNdw==</latexit>j=0<latexit sha1_base64="8XKQBGeHLeGg/jFEYtaglIOuDkg=">AAAB6nicbVDJSgNBEK2JW4xb1KOXxiB4CjMu6EUIevEY0SyQDKGnU5O06ekZunuEMOQTvHhQxKtf5M2/sbMcNPFBweO9KqrqBYng2rjut5NbWl5ZXcuvFzY2t7Z3irt7dR2nimGNxSJWzYBqFFxizXAjsJkopFEgsBEMbsZ+4wmV5rF8MMME/Yj2JA85o8ZK949XbqdYcsvuBGSReDNSghmqneJXuxuzNEJpmKBatzw3MX5GleFM4KjQTjUmlA1oD1uWShqh9rPJqSNyZJUuCWNlSxoyUX9PZDTSehgFtjOipq/nvbH4n9dKTXjpZ1wmqUHJpovCVBATk/HfpMsVMiOGllCmuL2VsD5VlBmbTsGG4M2/vEjqJ2XvtHx+d1aqXM/iyMMBHMIxeHABFbiFKtSAQQ+e4RXeHOG8OO/Ox7Q158xm9uEPnM8fw2ONdg==</latexit>j=1<latexit sha1_base64="0Se2ZAX4YJFFzXBHjRYRAAcHni8=">AAAB6nicbVDJSgNBEK2JW4xb1KOXxiB4CjMu6EUIevEY0SyQDKGnU5O06ekZunuEMOQTvHhQxKtf5M2/sbMcNPFBweO9KqrqBYng2rjut5NbWl5ZXcuvFzY2t7Z3irt7dR2nimGNxSJWzYBqFFxizXAjsJkopFEgsBEMbsZ+4wmV5rF8MMME/Yj2JA85o8ZK949XXqdYcsvuBGSReDNSghmqneJXuxuzNEJpmKBatzw3MX5GleFM4KjQTjUmlA1oD1uWShqh9rPJqSNyZJUuCWNlSxoyUX9PZDTSehgFtjOipq/nvbH4n9dKTXjpZ1wmqUHJpovCVBATk/HfpMsVMiOGllCmuL2VsD5VlBmbTsGG4M2/vEjqJ2XvtHx+d1aqXM/iyMMBHMIxeHABFbiFKtSAQQ+e4RXeHOG8OO/Ox7Q158xm9uEPnM8fxOeNdw==</latexit>j=2<latexit sha1_base64="cY398UGPAAwdYVlXe8DNaB2/XYU=">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoPgKexGRS9C0IvHiOYByRJmJ51kzOzsMjMrhCWf4MWDIl79Im/+jZNkDxotaCiquunuCmLBtXHdLye3tLyyupZfL2xsbm3vFHf3GjpKFMM6i0SkWgHVKLjEuuFGYCtWSMNAYDMYXU/95iMqzSN5b8Yx+iEdSN7njBor3T1cVrrFklt2ZyB/iZeREmSodYufnV7EkhClYYJq3fbc2PgpVYYzgZNCJ9EYUzaiA2xbKmmI2k9np07IkVV6pB8pW9KQmfpzIqWh1uMwsJ0hNUO96E3F/7x2YvoXfsplnBiUbL6onwhiIjL9m/S4QmbE2BLKFLe3EjakijJj0ynYELzFl/+SRqXsnZTPbk9L1assjjwcwCEcgwfnUIUbqEEdGAzgCV7g1RHOs/PmvM9bc042sw+/4Hx8A8ZrjXg=</latexit>j=0<latexit sha1_base64="8XKQBGeHLeGg/jFEYtaglIOuDkg=">AAAB6nicbVDJSgNBEK2JW4xb1KOXxiB4CjMu6EUIevEY0SyQDKGnU5O06ekZunuEMOQTvHhQxKtf5M2/sbMcNPFBweO9KqrqBYng2rjut5NbWl5ZXcuvFzY2t7Z3irt7dR2nimGNxSJWzYBqFFxizXAjsJkopFEgsBEMbsZ+4wmV5rF8MMME/Yj2JA85o8ZK949XbqdYcsvuBGSReDNSghmqneJXuxuzNEJpmKBatzw3MX5GleFM4KjQTjUmlA1oD1uWShqh9rPJqSNyZJUuCWNlSxoyUX9PZDTSehgFtjOipq/nvbH4n9dKTXjpZ1wmqUHJpovCVBATk/HfpMsVMiOGllCmuL2VsD5VlBmbTsGG4M2/vEjqJ2XvtHx+d1aqXM/iyMMBHMIxeHABFbiFKtSAQQ+e4RXeHOG8OO/Ox7Q158xm9uEPnM8fw2ONdg==</latexit>j=1<latexit sha1_base64="0Se2ZAX4YJFFzXBHjRYRAAcHni8=">AAAB6nicbVDJSgNBEK2JW4xb1KOXxiB4CjMu6EUIevEY0SyQDKGnU5O06ekZunuEMOQTvHhQxKtf5M2/sbMcNPFBweO9KqrqBYng2rjut5NbWl5ZXcuvFzY2t7Z3irt7dR2nimGNxSJWzYBqFFxizXAjsJkopFEgsBEMbsZ+4wmV5rF8MMME/Yj2JA85o8ZK949XXqdYcsvuBGSReDNSghmqneJXuxuzNEJpmKBatzw3MX5GleFM4KjQTjUmlA1oD1uWShqh9rPJqSNyZJUuCWNlSxoyUX9PZDTSehgFtjOipq/nvbH4n9dKTXjpZ1wmqUHJpovCVBATk/HfpMsVMiOGllCmuL2VsD5VlBmbTsGG4M2/vEjqJ2XvtHx+d1aqXM/iyMMBHMIxeHABFbiFKtSAQQ+e4RXeHOG8OO/Ox7Q158xm9uEPnM8fxOeNdw==</latexit>j=2<latexit sha1_base64="cY398UGPAAwdYVlXe8DNaB2/XYU=">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoPgKexGRS9C0IvHiOYByRJmJ51kzOzsMjMrhCWf4MWDIl79Im/+jZNkDxotaCiquunuCmLBtXHdLye3tLyyupZfL2xsbm3vFHf3GjpKFMM6i0SkWgHVKLjEuuFGYCtWSMNAYDMYXU/95iMqzSN5b8Yx+iEdSN7njBor3T1cVrrFklt2ZyB/iZeREmSodYufnV7EkhClYYJq3fbc2PgpVYYzgZNCJ9EYUzaiA2xbKmmI2k9np07IkVV6pB8pW9KQmfpzIqWh1uMwsJ0hNUO96E3F/7x2YvoXfsplnBiUbL6onwhiIjL9m/S4QmbE2BLKFLe3EjakijJj0ynYELzFl/+SRqXsnZTPbk9L1assjjwcwCEcgwfnUIUbqEEdGAzgCV7g1RHOs/PmvM9bc042sw+/4Hx8A8ZrjXg=</latexit>  ,1<latexit sha1_base64="W2hyXUzgfeXvyyAfIUwf2E9p7u8=">AAAB+nicbVDLSsNAFJ3UV62vVJdugkVwISXxgS6LLnRZwT6gCeFmOm2HzkzCzEQpsZ/ixoUibv0Sd/6N0zYLbT1w4XDOvdx7T5QwqrTrfluFpeWV1bXiemljc2t7xy7vNlWcSkwaOGaxbEegCKOCNDTVjLQTSYBHjLSi4fXEbz0QqWgs7vUoIQGHvqA9ikEbKbTL/g1wDmHmK9rncOyNQ7viVt0pnEXi5aSCctRD+8vvxjjlRGjMQKmO5yY6yEBqihkZl/xUkQTwEPqkY6gATlSQTU8fO4dG6Tq9WJoS2pmqvycy4EqNeGQ6OeiBmvcm4n9eJ9W9yyCjIkk1EXi2qJcyR8fOJAenSyXBmo0MASypudXBA5CAtUmrZELw5l9eJM2TqndaPb87q9Su8jiKaB8doCPkoQtUQ7eojhoIo0f0jF7Rm/VkvVjv1sestWDlM3voD6zPH9fik7w=</latexit>  ,2<latexit sha1_base64="C7aLMWoFoBP8tW1mzzugM2B1ej4=">AAAB+nicbVBNS8NAEN34WetXqkcvi0XwICWpih6LHvRYwX5AE8Jku22X7iZhd6OU2J/ixYMiXv0l3vw3btsctPXBwOO9GWbmhQlnSjvOt7W0vLK6tl7YKG5ube/s2qW9popTSWiDxDyW7RAU5SyiDc00p+1EUhAhp61weD3xWw9UKhZH93qUUF9AP2I9RkAbKbBL3g0IAUHmKdYXcFIdB3bZqThT4EXi5qSMctQD+8vrxiQVNNKEg1Id10m0n4HUjHA6LnqpogmQIfRpx9AIBFV+Nj19jI+M0sW9WJqKNJ6qvycyEEqNRGg6BeiBmvcm4n9eJ9W9Sz9jUZJqGpHZol7KsY7xJAfcZZISzUeGAJHM3IrJACQQbdIqmhDc+ZcXSbNacU8r53dn5dpVHkcBHaBDdIxcdIFq6BbVUQMR9Iie0St6s56sF+vd+pi1Lln5zD76A+vzB9lnk70=</latexit>  ,1<latexit sha1_base64="aL0iBEJyrmECxjj4C+q8oJmkZyY=">AAACB3icbVDLSsNAFJ34rPUVdSlIsAgupCQ+0GXRjcsK9gFNKJPJpB06jzAzEUrIzo2/4saFIm79BXf+jZM2C209MMzhnHu5954woURp1/22FhaXlldWK2vV9Y3NrW17Z7etRCoRbiFBheyGUGFKOG5poinuJhJDFlLcCUc3hd95wFIRwe/1OMEBgwNOYoKgNlLfPvBDQSM1ZubL/AhTDfN+5isyYPDEy/t2za27EzjzxCtJDZRo9u0vPxIoZZhrRKFSPc9NdJBBqQmiOK/6qcIJRCM4wD1DOWRYBdnkjtw5MkrkxEKax7UzUX93ZJCpYlVTyaAeqlmvEP/zeqmOr4KM8CTVmKPpoDiljhZOEYoTEYmRpmNDIJLE7OqgIZQQaRNd1YTgzZ48T9qnde+sfnF3Xmtcl3FUwD44BMfAA5egAW5BE7QAAo/gGbyCN+vJerHerY9p6YJV9uyBP7A+fwDdo5nw</latexit>  ,2<latexit sha1_base64="9vPWhOS/Hho4TRoJplM9asGPXJE=">AAACB3icbVDLSsNAFJ3UV62vqEtBBovgQkpSFV0W3bisYB/QhDCZTNqhk0yYmQglZOfGX3HjQhG3/oI7/8ZJm4W2HhjmcM693HuPnzAqlWV9G5Wl5ZXVtep6bWNza3vH3N3rSp4KTDqYMy76PpKE0Zh0FFWM9BNBUOQz0vPHN4XfeyBCUh7fq0lC3AgNYxpSjJSWPPPQ8TkL5CTSX+YEhCmUe5kj6TBCp83cM+tWw5oCLhK7JHVQou2ZX07AcRqRWGGGpBzYVqLcDAlFMSN5zUklSRAeoyEZaBqjiEg3m96Rw2OtBDDkQr9Ywan6uyNDkSxW1ZURUiM57xXif94gVeGVm9E4SRWJ8WxQmDKoOCxCgQEVBCs20QRhQfWuEI+QQFjp6Go6BHv+5EXSbTbss8bF3Xm9dV3GUQUH4AicABtcgha4BW3QARg8gmfwCt6MJ+PFeDc+ZqUVo+zZB39gfP4A3yiZ8Q==</latexit>SafeguardAvailable safeguard application levelsGameRandomized Safeguard Strategyi<latexit sha1_base64="IX26zSJF1vrmN7wLtaFmxfv2Aw4=">AAAB6HicbVDLSgNBEOz1GeMr6tHLYBA8hV0f6DHoxWMC5gHJEmYnvcmY2dllZlYIS77AiwdFvPpJ3vwbJ8keNLGgoajqprsrSATXxnW/nZXVtfWNzcJWcXtnd2+/dHDY1HGqGDZYLGLVDqhGwSU2DDcC24lCGgUCW8Hobuq3nlBpHssHM07Qj+hA8pAzaqxU571S2a24M5Bl4uWkDDlqvdJXtx+zNEJpmKBadzw3MX5GleFM4KTYTTUmlI3oADuWShqh9rPZoRNyapU+CWNlSxoyU39PZDTSehwFtjOiZqgXvan4n9dJTXjjZ1wmqUHJ5ovCVBATk+nXpM8VMiPGllCmuL2VsCFVlBmbTdGG4C2+vEya5xXvonJVvyxXb/M4CnAMJ3AGHlxDFe6hBg1ggPAMr/DmPDovzrvzMW9dcfKZI/gD5/MH0cGM9A==</latexit>UD(0,i)=RiAi 1 E(0,i)  C(0,i)<latexit sha1_base64="mks0Usha5QmmbaB4FRGlno81DVc=">AAACHXicbVDLSgMxFM3UV62vUZdugkWo0JYZrehGqFbBZRX7gE4ZMmmmDc08SDJCGfojbvwVNy4UceFG/BvT6Sy09UDIuefcS3KPEzIqpGF8a5mFxaXllexqbm19Y3NL395piiDimDRwwALedpAgjPqkIalkpB1ygjyHkZYzrE381gPhggb+vRyFpOuhvk9dipFUkq1XGvZVwSjSw/M7m0KrCC+ml+XQvhWbpevETKoxLMFaUtp63igbCeA8MVOSBynqtv5p9QIcecSXmCEhOqYRym6MuKSYkXHOigQJER6iPuko6iOPiG6cbDeGB0rpQTfg6vgSJurviRh5Qow8R3V6SA7ErDcR//M6kXTPujH1w0gSH08fciMGZQAnUcEe5QRLNlIEYU7VXyEeII6wVIHmVAjm7MrzpHlUNo/LJ7eVfPUyjSML9sA+KAATnIIquAF10AAYPIJn8AretCftRXvXPqatGS2d2QV/oH39ACpvnQM=</latexit>UD(1,i)=RiAi 1 E(1,i)  C(1,i)<latexit sha1_base64="fiQedHczFe7CbIrRNbcBPjuH/1k=">AAACHXicbVDLSgMxFM3UV62vUZdugkWo0JYZrehGqFbBZRX7gE4ZMmmmDc08SDJCGfojbvwVNy4UceFG/BvT6Sy09UDIuefcS3KPEzIqpGF8a5mFxaXllexqbm19Y3NL395piiDimDRwwALedpAgjPqkIalkpB1ygjyHkZYzrE381gPhggb+vRyFpOuhvk9dipFUkq1XGvZVwSzSw/M7m0KrCC+ml+XQvhWbpevETKoxLMFaUtp63igbCeA8MVOSBynqtv5p9QIcecSXmCEhOqYRym6MuKSYkXHOigQJER6iPuko6iOPiG6cbDeGB0rpQTfg6vgSJurviRh5Qow8R3V6SA7ErDcR//M6kXTPujH1w0gSH08fciMGZQAnUcEe5QRLNlIEYU7VXyEeII6wVIHmVAjm7MrzpHlUNo/LJ7eVfPUyjSML9sA+KAATnIIquAF10AAYPIJn8AretCftRXvXPqatGS2d2QV/oH39AC8/nQY=</latexit>UD(0,i)=RiAi 1 E(0,i)  C(0,i)<latexit sha1_base64="mks0Usha5QmmbaB4FRGlno81DVc=">AAACHXicbVDLSgMxFM3UV62vUZdugkWo0JYZrehGqFbBZRX7gE4ZMmmmDc08SDJCGfojbvwVNy4UceFG/BvT6Sy09UDIuefcS3KPEzIqpGF8a5mFxaXllexqbm19Y3NL395piiDimDRwwALedpAgjPqkIalkpB1ygjyHkZYzrE381gPhggb+vRyFpOuhvk9dipFUkq1XGvZVwSjSw/M7m0KrCC+ml+XQvhWbpevETKoxLMFaUtp63igbCeA8MVOSBynqtv5p9QIcecSXmCEhOqYRym6MuKSYkXHOigQJER6iPuko6iOPiG6cbDeGB0rpQTfg6vgSJurviRh5Qow8R3V6SA7ErDcR//M6kXTPujH1w0gSH08fciMGZQAnUcEe5QRLNlIEYU7VXyEeII6wVIHmVAjm7MrzpHlUNo/LJ7eVfPUyjSML9sA+KAATnIIquAF10AAYPIJn8AretCftRXvXPqatGS2d2QV/oH39ACpvnQM=</latexit>UD(1,i)=RiAi 1 E(1,i)  C(1,i)<latexit sha1_base64="fiQedHczFe7CbIrRNbcBPjuH/1k=">AAACHXicbVDLSgMxFM3UV62vUZdugkWo0JYZrehGqFbBZRX7gE4ZMmmmDc08SDJCGfojbvwVNy4UceFG/BvT6Sy09UDIuefcS3KPEzIqpGF8a5mFxaXllexqbm19Y3NL395piiDimDRwwALedpAgjPqkIalkpB1ygjyHkZYzrE381gPhggb+vRyFpOuhvk9dipFUkq1XGvZVwSzSw/M7m0KrCC+ml+XQvhWbpevETKoxLMFaUtp63igbCeA8MVOSBynqtv5p9QIcecSXmCEhOqYRym6MuKSYkXHOigQJER6iPuko6iOPiG6cbDeGB0rpQTfg6vgSJurviRh5Qow8R3V6SA7ErDcR//M6kXTPujH1w0gSH08fciMGZQAnUcEe5QRLNlIEYU7VXyEeII6wVIHmVAjm7MrzpHlUNo/LJ7eVfPUyjSML9sA+KAATnIIquAF10AAYPIJn8AretCftRXvXPqatGS2d2QV/oH39AC8/nQY=</latexit>UD(2,i)=RiAi 1 E(2,i)  C(2,i)<latexit sha1_base64="JdmQYAxFAwUjUceU8ckIY3xOPiE=">AAACHXicbVDLSgMxFM34rPU16tJNsAgV2jJTK7oRqlVwWcU+oFOGTJppQzMPkoxQhv6IG3/FjQtFXLgR/8Z0OgttPRBy7jn3ktzjhIwKaRjf2sLi0vLKamYtu76xubWt7+w2RRBxTBo4YAFvO0gQRn3SkFQy0g45QZ7DSMsZ1iZ+64FwQQP/Xo5C0vVQ36cuxUgqydYrDfsqXy7Qo/M7m0KrAC+ml+XQvhWbxevETKoxLMJaUtp6zigZCeA8MVOSAynqtv5p9QIcecSXmCEhOqYRym6MuKSYkXHWigQJER6iPuko6iOPiG6cbDeGh0rpQTfg6vgSJurviRh5Qow8R3V6SA7ErDcR//M6kXTPujH1w0gSH08fciMGZQAnUcEe5QRLNlIEYU7VXyEeII6wVIFmVQjm7MrzpFkumcelk9tKrnqZxpEB++AA5IEJTkEV3IA6aAAMHsEzeAVv2pP2or1rH9PWBS2d2QN/oH39ADQPnQk=</latexit>UD(0,i)=RiAi 1 E(0,i)  C(0,i)<latexit sha1_base64="mks0Usha5QmmbaB4FRGlno81DVc=">AAACHXicbVDLSgMxFM3UV62vUZdugkWo0JYZrehGqFbBZRX7gE4ZMmmmDc08SDJCGfojbvwVNy4UceFG/BvT6Sy09UDIuefcS3KPEzIqpGF8a5mFxaXllexqbm19Y3NL395piiDimDRwwALedpAgjPqkIalkpB1ygjyHkZYzrE381gPhggb+vRyFpOuhvk9dipFUkq1XGvZVwSjSw/M7m0KrCC+ml+XQvhWbpevETKoxLMFaUtp63igbCeA8MVOSBynqtv5p9QIcecSXmCEhOqYRym6MuKSYkXHOigQJER6iPuko6iOPiG6cbDeGB0rpQTfg6vgSJurviRh5Qow8R3V6SA7ErDcR//M6kXTPujH1w0gSH08fciMGZQAnUcEe5QRLNlIEYU7VXyEeII6wVIHmVAjm7MrzpHlUNo/LJ7eVfPUyjSML9sA+KAATnIIquAF10AAYPIJn8AretCftRXvXPqatGS2d2QV/oH39ACpvnQM=</latexit>UD(1,i)=RiAi 1 E(1,i)  C(1,i)<latexit sha1_base64="fiQedHczFe7CbIrRNbcBPjuH/1k=">AAACHXicbVDLSgMxFM3UV62vUZdugkWo0JYZrehGqFbBZRX7gE4ZMmmmDc08SDJCGfojbvwVNy4UceFG/BvT6Sy09UDIuefcS3KPEzIqpGF8a5mFxaXllexqbm19Y3NL395piiDimDRwwALedpAgjPqkIalkpB1ygjyHkZYzrE381gPhggb+vRyFpOuhvk9dipFUkq1XGvZVwSzSw/M7m0KrCC+ml+XQvhWbpevETKoxLMFaUtp63igbCeA8MVOSBynqtv5p9QIcecSXmCEhOqYRym6MuKSYkXHOigQJER6iPuko6iOPiG6cbDeGB0rpQTfg6vgSJurviRh5Qow8R3V6SA7ErDcR//M6kXTPujH1w0gSH08fciMGZQAnUcEe5QRLNlIEYU7VXyEeII6wVIHmVAjm7MrzpHlUNo/LJ7eVfPUyjSML9sA+KAATnIIquAF10AAYPIJn8AretCftRXvXPqatGS2d2QV/oH39AC8/nQY=</latexit>UD(2,i)=RiAi 1 E(2,i)  C(2,i)<latexit sha1_base64="JdmQYAxFAwUjUceU8ckIY3xOPiE=">AAACHXicbVDLSgMxFM34rPU16tJNsAgV2jJTK7oRqlVwWcU+oFOGTJppQzMPkoxQhv6IG3/FjQtFXLgR/8Z0OgttPRBy7jn3ktzjhIwKaRjf2sLi0vLKamYtu76xubWt7+w2RRBxTBo4YAFvO0gQRn3SkFQy0g45QZ7DSMsZ1iZ+64FwQQP/Xo5C0vVQ36cuxUgqydYrDfsqXy7Qo/M7m0KrAC+ml+XQvhWbxevETKoxLMJaUtp6zigZCeA8MVOSAynqtv5p9QIcecSXmCEhOqYRym6MuKSYkXHWigQJER6iPuko6iOPiG6cbDeGh0rpQTfg6vgSJurviRh5Qow8R3V6SA7ErDcR//M6kXTPujH1w0gSH08fciMGZQAnUcEe5QRLNlIEYU7VXyEeII6wVIFmVQjm7MrzpFkumcelk9tKrnqZxpEB++AA5IEJTkEV3IA6aAAMHsEzeAVv2pP2or1rH9PWBS2d2QN/oH39ADQPnQk=</latexit>Defender’s UtilityAi<latexit sha1_base64="q7aLxAyZzIPruUfKgfyWGNj9QxY=">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoPgKez6QI9RLx4jmgckS5id9CZDZmeXmVkhLPkELx4U8eoXefNvnCR70GhBQ1HVTXdXkAiujet+OYWl5ZXVteJ6aWNza3unvLvX1HGqGDZYLGLVDqhGwSU2DDcC24lCGgUCW8HoZuq3HlFpHssHM07Qj+hA8pAzaqx0f9XjvXLFrbozkL/Ey0kFctR75c9uP2ZphNIwQbXueG5i/Iwqw5nASambakwoG9EBdiyVNELtZ7NTJ+TIKn0SxsqWNGSm/pzIaKT1OApsZ0TNUC96U/E/r5Oa8NLPuExSg5LNF4WpICYm079JnytkRowtoUxxeythQ6ooMzadkg3BW3z5L2meVL3T6vndWaV2ncdRhAM4hGPw4AJqcAt1aACDATzBC7w6wnl23pz3eWvByWf24Recj28PCo2o</latexit>Ri<latexit sha1_base64="TeY6jDb/pxXyf0MCuCX0bDzpKTA=">AAAB6nicbVDJSgNBEK2JW4xb1KOXxiB4CjMu6DHoxWNcskAyhJ5OTdKkp2fo7hHCkE/w4kERr36RN//GTjIHjT4oeLxXRVW9IBFcG9f9cgpLyyura8X10sbm1vZOeXevqeNUMWywWMSqHVCNgktsGG4EthOFNAoEtoLR9dRvPaLSPJYPZpygH9GB5CFn1Fjp/q7He+WKW3VnIH+Jl5MK5Kj3yp/dfszSCKVhgmrd8dzE+BlVhjOBk1I31ZhQNqID7FgqaYTaz2anTsiRVfokjJUtachM/TmR0UjrcRTYzoiaoV70puJ/Xic14aWfcZmkBiWbLwpTQUxMpn+TPlfIjBhbQpni9lbChlRRZmw6JRuCt/jyX9I8qXqn1fPbs0rtKo+jCAdwCMfgwQXU4Abq0AAGA3iCF3h1hPPsvDnv89aCk8/swy84H98o8I25</latexit>Optimizing Investments in Cyber Hygiene for Protecting Healthcare Users

15

provided in [3], we have chosen the objective function of the Defender to consider
the sum of expected losses incurred from the diﬀerent user groups being attacked.
This is not to say that the proposed weakest-link model in [3] is not relevant
anymore but we realize the potential risk to have all user groups targeted by
the Attacker with the goal to maximize the collective damage over a number of
assets rather than trying to compromise the most precious asset. We argue that
such a goal to maximize the aggregated damage is more applicable in attacks
like Advanced Persistent Threat, where the goal is to maximize the Defender’s
overall loss in a number of diﬀerent ways.

|S| × |L|
|S|

The Knapsack Problem (KP) is an NP-hard problem [31]. There are several
applications of KP such as resource distribution, investment decision making
and budget controlling. In our model, we deﬁne KP as: Assuming that there is
a knapsack with a maximum capacity of B, which represents the budget of the
NSPs shown in (18), each Knap-
Defender. Given the set of all possible
sack candidate solution consists of at most
NSPs, one per each safeguard.
Each NSP reduces, to some degree, the overall cyber risk of the organization as
a result of reducing the individual risk on each user group. The problem is to
select a subset of NSPs that maximize the knapsack proﬁt without exceeding
the maximum capacity of the knapsack. We deﬁne an optimal solution to our
KP as Ψ =
. A solution Ψ takes exactly one solution
(i.e., equilibrium or cybersecurity plan) for each safeguard as a policy for imple-
mentation/application. To represent the cyber security investment problem, we
need to expand the deﬁnitions for both expected loss L and eﬀectiveness E to
incorporate the solutions of the diﬀerent CSGs. Hence, we expand L such that
L(δσ,λ, i) is the expected loss inﬂicted by compromising user group i given the
application of the plan δσ,λ. We also expand E such that E(δσ,λ, i) is the eﬃcacy
that δσ,λ brings when applied to user group i. From equation (2) the expected
loss on user group i when NSP δσ,λ is applied is given by

δN E
,
σ,λ }
{

∈ L

∈ S

λ

σ

∀

∀

,

L(δσ,λ, i) = Ri Ai [1

E(δσ,λ, i)]

−

(19)

A natural approach is the KP to seek a set of NSPs that minimize the aggregated
expected risks across all user groups. We assume that each NSP may protect
more than one user groups. We then seek optimal safeguards allocation for a
series of user groups each of which can be protected by a diﬀerent set of NSPs.
The latter may not necessarily have an additive eﬃcacy. The following illustrated
example considers two NSPs and explains how we have decided to combine their
eﬃcacy in a single formula that we then use in KP formulation.

Example 2. By slightly abusing notation, assume two NSPs δ, δ(cid:48) that mit-
igate 20% and 30% of the same user group risk, respectively. If the NSPs had
additive eﬃcacy the total expected loss on user group i when applying both δ, δ(cid:48)
equals Ri Ai
0.3) = 0.5 Ri Ai. In this
paper, we assume a more conservative expected loss mitigation function when
combining two or more NSPs as follows Ri Ai
=
Ri Ai ·

0.7 = 0.56 Ri Ai.
(cid:110)(cid:8)

0.3) = Ri Ai ·

E(δ, i) + E(δ(cid:48), i)

= Ri Ai (1

E(δ(cid:48), i)

E(δ, i)

0.2) (1

(cid:9)(cid:111)

(cid:9)(cid:111)

(cid:9) (cid:8)

0.8

0.2

(1

−

−

−

−

−

−

−

(cid:110)

(cid:8)

1

1

1

·

16

Panda et al.

Given the above, if we represent the solution Ψ by the bitvector z, we can

then represent the 0-1 KP as

max
z

|U |

|S|

λ

Ai Ri

i=0
(cid:88)
|U |

|L|

(cid:40)

1
σ=1 (cid:110)
(cid:89)

−

j=0
(cid:88)

E(δN E

σ,λ , i) zσ,λ

(cid:41)

(cid:111)

s.t.

|L|

σ=1
(cid:88)

(cid:88)λ=0

F (δσ,λ) zσ,λ ≤

B,

zσ,λ = 1, zσ,λ ∈ {

0, 1

,
}

σ = 1, 2, . . . ,

∀

.
|S|

(20)

(cid:88)λ=0

where B is the available budget of the Defender to be spent in cyber safeguards
and zσ,λ = 1 holds when δN E
Ψ . Among KP solutions that all maximize the
overall expected loss, we choose the solution with the lowest ﬁnancial cost as
this will be, in overall, the best advice to the defender producing same beneﬁt
for lower price.

σ,λ ∈

4 Model Evaluation

We have developed the proposed models as part of the Optimal Safeguards Tool
(OST) proposed in [1]. OST computes Nash Safeguards Plans as well as the
Knapsack solutions. OST aims at oﬀering realistic actionable advice to health-
care organizations. The following represents a case study based on Critical In-
ternet Security (CIS) 17 Control “Implement a Security Awareness and Training
Program”.

4.1 Use Case

User groups. Here, we assume a representative (non-exhaustive) set of three
user groups, denoted by i, in decreasing order of access privileges:

– i = 1; ICT: The information and communication technology professionals
responsible for the systems, networks and software. They set up digital sys-
tems, support staﬀ who use them, diagnose and address faults, as well as
set up and maintain security provisions. In addition to the ICT infrastruc-
ture, they may also interact with medical devices and electronic healthcare
record systems. We consider the value of corresponding assets that can be
aﬀected by an attack on this group to be the highest possible, A1 = 100
(e.g., $100k). At the same time, due to limited interaction with the public,
this is the group with the lowest visibility to attacks targeting the human,
and as such we can consider it as lower risk, R1 = 0.2.

– i = 2; Clinical: Nurses, doctors and other clinical staﬀ have access to medi-
cal devices and electronic healthcare records. We consider the value of corre-
sponding assets that can be aﬀected by an attack on this group to be A2 = 50
(e.g., $50k). As a result of visibility due to interaction with the patients and
presence on the hospital’s website, this group has a moderate risk, R2 = 0.5.

Optimizing Investments in Cyber Hygiene for Protecting Healthcare Users

17

– i = 3; Administration: Receptionists, medical secretaries and other admin-
istration roles involve access to electronic healthcare records. We consider the
value of corresponding assets that can be aﬀected by an attack on this group
to be A3 = 25 (e.g., $25k). This group of users may have high interaction
with the public and volume of email traﬃc (e.g., appointment requests) and
as such high risk, R3 = 0.8.

Control level

Role

\

Low (once per year)

Medium (twice per year)

High (once per month)

ICT Clinical Administration

E 0.35
C 1

E 0.6
C 2

E 0.8
C 12

0.3
30

0.5
60

0.7
360

0.3
10

0.5
20

0.7
120

Table 2: Evaluation parameters for control CIS-17.4.

We have assumed a user group ratio of size 1:30:10 that loosely follows the
corresponding breakdown of hospital workforce in the United States12: 81,790
computer, information system and security managers and analysts; 2,437,540
healthcare practitioners; 737,750 receptionists, healthcare record information
clerks and other oﬃce and administrative support staﬀ.

Control level

Role
\

Low (Tests)

Medium (Videos)

High (Games)

ICT Clinical Administration

E 0.25
C 1

E 0.7
C 2

E 0.6
C 4

0.2
30

0.6
60

0.5
120

0.2
10

0.6
20

0.5
40

Table 3: Evaluation parameters for control CIS-17.6.

Safeguards. As safeguards, we have considered a representative pair from the
SANS institute’s CIS-17 group of critical security controls13: CIS-17.4 “Update
Awareness Content Frequently” and CIS-17.6 “Train Workforce on Identifying
Social Engineering Attacks”. All values used in this case study, for these two
safeguards, are presented in Tables 2 and 3.

12

13

https://www.bls.gov/oes/current/naics3_622000.htm.
https://www.cisecurity.org/controls/implement-a-security-awareness-and-training-program/.

18

Panda et al.

For CIS-17.4, we set the frequency of completion of the updated training
(once per year, twice per year, or once per month - i.e., 12 times per year) as
the level of control. As indirect cost C(j, i), we consider the total time spent in
training by the employees in group i at application level j (in this case is fre-
quency), which is proportionate to the size of the group and the frequency of the
training. This time can be translated to some ﬁnancial cost (in $) resulting from
loss of productive working hours. In this way, the indirect cost can be subtracted
from the expected loss comprising the ﬁnal utility value of the Defender in each
cell of the game utility matrix.

For CIS-17.6, we set the nature of the work-based training (tests, videos,
games) as the levels of control. Further, we set the corresponding eﬃcacy val-
ues for each type roughly equivalent to their importance in helping predict user
susceptibility to semantic social engineering attacks. Speciﬁcally, [15] has iden-
tiﬁed work-based security training with videos as the best predictor out of the
three. In terms of eﬃcacy values, we have diﬀerentiated slightly between groups
based on our perceived rate of adoption of controls in each one. Speciﬁcally, we
assume that adoption is greater for ICT than for clinical and administration
employees. This is only for illustration purposes, so that the model can also take
into account the group at each level of control. We also assume, further, that
the primary indirect cost is employee time required, with a ratio of 1:2:4 for the
three control levels.

4.2 Comparison with Alternative Defense Strategies

In the following, we analyze the proposed model in two phases; (i) the game-
theoretic; and (ii) the 0-1 Knapsack optimization. The ﬁrst phase evaluates dif-
ferent cybersecurity safeguard selection strategies using the utility table of the
investigated Cybersecurity Safeguards Games (CSG) based on the use case dis-
cussed in the previous section. To evaluate our approach, we have created a
simulated environment in Python which performs the attack sampling. For all
comparisons performed, a sample size of 1,000 attacks was used. Such a sample is
referred to as a run in the results. In the following, we present the results, where
25 runs have been performed in each case and the average Defender Utility (in
$) seen across the runs have been plotted.

More speciﬁcally, we have simulated Γσ,2 and Γσ,3 (please see Table 1 for the
notation) for the two diﬀerent safeguards presented in the use case, i.e., CIS 17.4
(denoted as σ = 1) and 17.6 (denoted as σ = 2). The games Γ1,2, Γ2,2 exhibit
maximum safeguard application level of 2 (Medium), while the games Γ1,3, Γ2,3
are investigated up to application level 3 (High). Each CSG generates a utility
table that we use to derive three diﬀerent Defender application level selection
strategies:

– Nash Safeguard Strategy (NSS), as described in Section 3 and computed

using the the open source Nashpy Python library14.

14

https://nashpy.readthedocs.io/en/stable/index.html

Optimizing Investments in Cyber Hygiene for Protecting Healthcare Users

19

– the Weighted Safeguard Strategy (WSS), which distributes the choice of a
safeguard level over the weighted expected utility of the CSG by computing
probability δσ,j of choosing application level j of safeguard σ as follows:

δσ,j :=

|U |
i=1 Ud(j, i)
|U |
i=1 Ud(j, i)

|L|
(cid:80)
j=1
– the Cautious Safeguard Strategy (CSS), which always prefers the highest

(cid:80)

(cid:80)

application level of a safeguard.

Regarding adversarial strategies, we consider three proﬁles:

– the Nash Attacker who plays the Nash Attacking Strategy (NAS), presented

in Section 3 and computed using the Nashpy Python library.

– a Weighted Attacker who plays the Weighted Attacking Strategy (WAS) by
, i.e. the Attacker attacks
attacking a user group i with probability
the diﬀerent user groups proportionally based on the asset values they have
access to.

Ai
i∈U Ai

(cid:80)

– the Opportunistic Attacker who uniformly chooses the diﬀerent user groups

to attack.

Figure 2 illustrates the performance of NSS against WSS and CSS in terms
of average Defender’s utility over the 1,000 attacks for 25 runs. In all cases, we
contrast between Attackers who follow NAS and WAS.

Nash Attacker. The results, in Figure 2(a), show that NSS outperforms both
WSS and CSS when the Attacker chooses NAS. More speciﬁcally, the percent-
age improvement values, seen when choosing NSS, in comparison to WSS for the
diﬀerent games [Γ1,2, Γ1,3, Γ2,2, Γ2,3] are [20.2%, 79.78%, 16%, 52.12%], respec-
tively. Likewise, when choosing NSS over CSS, we observe improvement values of
[34.48%, 87.07%, 28.57%, 62.26%] for the diﬀerent games [Γ1,2, Γ1,3, Γ2,2, Γ2,3],
respectively.

Remark 3. These results demonstrate an average improvement of approximately
42% of NSS over WSS and 53% over CSS.

Comparably, the smallest average improvement for NSS over WSS is around
16% when playing Control 17.6 at the maximum application level of 2 (λ = 2).
Likewise, the minimum improvement of NSS over CSS, approximately equal to
28%, is for the same control and λ = 2. On the other hand, the maximum
improvement seen in NSS over CSS is approximately 87%, where the maximum
improvement over CSS does not exceed 80%, for Control 17.4. and λ = 3.

One of the primary reasons why naive-deterministic safeguard selection ap-
proaches perform poorly against the Nash Defending strategy is that they fail to
incorporate the opponent’s strategies. At the same time, we have considered CSG
as a zero-sum game. The class of zero-sum games oﬀers a degree of freedom as it
can be shown that assuming that the adversary’s intentions are exactly opposite
to the defender’s assets, i.e., the Attacker seeks to cause maximum damage, any
other incentive of the Attacker can only improve the Defender’s situation [32].

20

Panda et al.

(a)

(b)

(c)

Fig. 2: Game-theoretic optimization results: Average Utility of the Defender over
1,000 attacks for 25 runs. for various CSGs.

Weighted Attacker. When the Weighted Attacking Strategy is simulated, the
results demonstrate that NSS has higher eﬃcacy over WSS and CSS apart from
one game Γ2,2 in which both WSS and CSS perform approximately 2% better
than NSS (Figure 2(b)). This diﬀerence is negligible making NSS being at least
as good as the rest of the Defending strategies in all investigated games. Despite
the performance of NSS in Γ2,2, for the rest of the games, NSS performs sig-
niﬁcantly better than WSS and CSS. The percentage improvement values, seen
when choosing NSS, in comparison to WSS and CSS for [Γ1,2, Γ1,3, Γ2,2, Γ2,3] are
[7.34%, 70.25%, -2.25%, and 32.29%] and [15.1%, 80.44%, -2.1%, and 44.79%],
respectively.

Remark 4. These results demonstrate an average improvement of approximately
28% of NSS over WSS and 34% over CSS.

The smallest average improvements for NSS over WSS and CSS are approx-
imately 7% (in Γ1,2) and 15% (Γ1,2), respectively, and the maximum average
improvement values are 70% (in Γ1,3) and 80% (in Γ1,3).

CSG1CSG2CSG3CSG4Control Safeguards Game (CSG)350300250200150100500Defender's Expected Utility ($)vs Nash AttackerNSSWSSCSSCSG1CSG2CSG3CSG4Control Safeguards Game (CSG)120100806040200Defender's Expected Utility ($)vs Weighted AttackerNSSWSSCSSCSG1CSG2CSG3CSG4Control Safeguards Game (CSG)160140120100806040200Defender's Expected Utility ($)vs Opportunistic AttackerNSSWSSCSSOptimizing Investments in Cyber Hygiene for Protecting Healthcare Users

21

Opportunistic Attacker. Finally, when the Opportunistic Attacking Strategy
is simulated, the results demonstrate that NSS has higher eﬃcacy over WSS
and CSS (Figure 2(c)). The percentage improvement values, seen when choosing
NSS, in comparison to WSS and CSS for [Γ1,2, Γ1,3, Γ2,2, Γ2,3] are [13.3%, 74.24%,
5.4%, and 40.8%] and [23.73%, 83.4%, 12.33%, and 52.51%], respectively.

Remark 5. These results demonstrate an average improvement of approximately
33% of NSS over WSS and 43% over CSS.

The smallest average improvements for NSS over WSS and CSS are approx-
imately 5% (in Γ2,2) and 12% (Γ2,2), respectively, and the maximum average
improvement values are 74% (in Γ1,3) and 83% (in Γ1,3).

We notice that the highest improvements among the three diﬀerent Attacking
strategies are introduced by the ﬁrst scenario where Nash Attacker is simulated.
This was anticipated as at the Nash Equilibrium the Defender does the best
against a rational Attacker. Between the results for Weighted and Opportunis-
tic Attacker, NSS is more eﬃcient against an Opportunistic Attacker than a
Weighted one.

4.3 Analysis of the Investment Problem

The Knapsack optimization phase investigates the optimal investment in Nash
Safeguards Plans (NSPs) given a budget B (for details refer to section 3.6). The
Knapsack takes as input every NSP generated in the game-theoretic phase and
recommends a single solution which minimizes the aggregated risk of all the user
groups while satisfying the investment budget constraint. This is diﬀerent to the
weakest-link model investigated by [3].

(a)

(b)

Fig. 3: Knapsack selection over available candidate solutions.

Figure 3 presents the ﬁnancial cost and aggregated risk overall users for
each Knapsack candidate solution, i.e., a combination of NSPs for two diﬀerent

123456785.07.510.012.515.0Financial cost of Knapsack  candidate solution ($)Budget = 40$Financial cost12345678Number of candidate solution175150125100Aggregated riskAggregated risk123456785.07.510.012.515.0Financial cost of Knapsack  candidate solution ($)Budget = 100$Financial cost12345678Number of candidate solution175150125100Aggregated riskAggregated risk22

Panda et al.

available budget values. We notice that there are multiple Knapsack optimal
solutions, which are candidate solutions number 5, 6, 7 and 8. In the presence of
multiple optimal solutions, the Knapsack solver, we have implemented, chooses
the ﬁrst option. For both budgets 40 and 100, the Knapsack optimization rec-
ommends investing in both CIS controls 17.4 and 17.6 at application level 1 i.e.,
Low (once per year) and Low (Tests), respectively. Note here that the small size
of the use case eﬀectively prohibits high variability of the parametric values,
which led to the selection of only two types.

Note that the plots in Knapsack optimization only present the candidate
solutions for the Nash Defender against Nash Attacker, in contrast to the plots
in game-theoretic phase, (Figure 2), which presents all three Defender strategies.
This choice was made due to the Knapsack optimization not involving the notion
of CSG. As a result of this, it does not optimize the overall indirect cost of
safeguards when choosing NSPs which has been done in the previous phase. In
addition, Knapsack does not consider the behavior of the Attacker characterizing
all adversarial strategies as irrelevant to the Knapsack objective function.

5 Conclusions

In this paper, we have presented an approach, extending the previous work [3],
which implements a cybersecurity safeguards selection model along with game-
theoretic and Knapsack optimization tools. We have evaluated our model in a
healthcare use case using the CIS group 17 controls which attend to implementa-
tion of security awareness and training programs for employees. The simulation
results demonstrate that the Nash Safeguard Strategy comfortably outperforms
common-sense selection strategies, such as the Weighted and Cautious, in terms
of Defender’s expected utility over a large number of attacks. This work is our
step towards integrating the developed Optimal Safeguards Tool (OST) within
cybersecurity risk management and investment environments.

An interesting extension to this work would be to capture the real-world
uncertainty about an Attacker’s type, for example considering a Bayesian game
of application level selection. Furthermore, we plan to bring together several
objective functions for Knapsack to compare the performance of the investment
strategies. As the next steps, we aim at creating a use case with greater size of
safeguards in collaboration with healthcare organizations. We also aim at using
the well-known repository of cybersecurity safeguards like the 20 CIS controls
or a list of Privacy Enhancing Technologies (PETs) to support our research.

6 Acknowledgments

We thank the reviewers for their valuable feedback and comments.

Emmanouil Panaousis is partially supported by the European Commission as
part of the CUREX project (H2020-SC1-FA-DTS-2018-1 under grant agreement
No 826404). The work of Christos Laoudias has been partially supported by the

Optimizing Investments in Cyber Hygiene for Protecting Healthcare Users

23

CUREX project (under grant agreement No 826404), by the European Union’s
Horizon 2020 research and innovation programme (under grant agreement No
739551 (KIOS CoE)), and from the Republic of Cyprus through the Directorate
General for European Programmes, Coordination and Development.

References

1. Farnaz Mohammadi, Angeliki Panou, Christoforos Ntantogian, Eirini Karapistoli,
Emmanouil Panaousis, and Christos Xenakis. CUREX: seCUre and pRivate hEalth
In IEEE/WIC/ACM International Conference on Web Intelli-
data eXchange.
gence, volume 24800, pages 263–268, 2019.

2. Arun Vishwanath, Loo Seng Neo, Pamela Goh, Seyoung Lee, Majeed Khader,
Gabriel Ong, and Jeﬀery Chin. Cyber hygiene: The concept, its measure, and its
initial tests. Decision Support Systems, page 113160, 2019.

3. Andrew Fielder, Emmanouil Panaousis, Pasquale Malacaria, Chris Hankin, and
Fabrizio Smeraldi. Decision support approaches for cyber security investment.
Decision Support Systems, 86:13–23, 2016.

4. Clemens Scott Kruse, Benjamin Frederick, Taylor Jacobson, and D Kyle Monti-
cone. Cybersecurity in healthcare: A systematic review of modern threats and
trends. Technology and Health Care, 25(1):1–10, 2017.

5. `Oscar Solans Fern´andez, Carlos Gallego P´erez, Francesc Garc´ıa-Cuy`as,
N´uria Abd´on Gim´enez, Manel Berruezo Gallego, Adri`a Garcia Font,
Miquel Gonz´alez Quintana, Sara Hern´andez Corbacho, and Ester Sarquella Casel-
las. Shared medical record, personal health folder and health and social integrated
care in catalonia: ICT services for integrated care. In New Perspectives in Medical
Records, pages 49–64. Springer, 2017.

6. Lynne Coventry and Dawn Branley. Cybersecurity in healthcare: A narrative

review of trends, threats and ways forward. Maturitas, 113:48–52, 2018.

7. David Kotz, Carl A Gunter, Santosh Kumar, and Jonathan P Weiner. Privacy and

security in mobile health: a research agenda. Computer, 49(6):22–30, 2016.

8. George Loukas. Cyber-physical attacks: A growing invisible threat. Butterworth-

Heinemann, 2015.

9. Luanne Billingsley and Shawn A McKee. Cybersecurity in the clinical setting:
Nurses’ role in the expanding internet of things. The Journal of Continuing Edu-
cation in Nursing, 47(8):347–349, 2016.

10. Ryan Heartﬁeld and George Loukas. Detecting semantic social engineering attacks
with the weakest link: Implementation and empirical evaluation of a human-as-a-
security-sensor framework. Computers & Security, 76:101–127, 2018.

11. Jose M Such, Pierre Ciholas, Awais Rashid, John Vidler, and Timothy Seabrook.

Basic cyber hygiene: Does it work? Computer, 52(4):21–31, 2019.

12. Leming Zhou, Bambang Parmanto, Zakiy Alﬁkri, and Jie Bao. A mobile app for
assisting users to make informed selections in security settings for protecting per-
sonal health data: development and feasibility study. JMIR mHealth and uHealth,
6(12):e11210, 2018.

13. Steven Furnell, Peter Sanders, and Matthew Warren. Addressing information se-
curity training and awareness within the european healthcare community. Studies
in health technology and informatics, 43:707–711, 1997.

14. Ryan Heartﬁeld and George Loukas. A taxonomy of attacks and a survey of defence
mechanisms for semantic social engineering attacks. ACM Computing Surveys,
48(3):37, 2016.

24

Panda et al.

15. Ryan Heartﬁeld, George Loukas, and Diane Gan. You are probably not the weakest
link: Towards practical prediction of susceptibility to semantic social engineering
attacks. IEEE Access, 4:6910–6928, 2016.

16. Rick Wash and Molly M Cooper. Who provides phishing training?: Facts, stories,
and people like me. In Proceedings of the 2018 CHI Conference on Human Factors
in Computing Systems, page 492. ACM, 2018.

17. Lawrence A Gordon and Martin P Loeb. The economics of information security
investment. ACM Transactions on Information and System Security (TISSEC),
5(4):438–457, 2002.

18. Andrew Fielder, Sandra K¨onig, Emmanouil Panaousis, Stefan Schauer, and Stefan
Rass. Risk assessment uncertainties in cybersecurity investments. Games, 9(2):34,
2018.

19. Andrew Fielder, Emmanouil Panaousis, Pasquale Malacaria, Chris Hankin, and
Fabrizio Smeraldi. Game theory meets information security management. In IFIP
International Information Security Conference, pages 15–29. Springer, 2014.
20. Anna Nagurney, Patrizia Daniele, and Shivani Shukla. A supply chain network
game theory model of cybersecurity investments with nonlinear budget constraints.
Annals of operations research, 248(1-2):405–427, 2017.

21. Shaun S Wang.

Integrated framework for information security investment and

cyber insurance. Paciﬁc-Basin Finance Journal, 57:101173, 2019.

22. Michail Chronopoulos, Emmanouil Panaousis, and Jens Grossklags. An options

approach to cybersecurity investment. IEEE Access, 6:12175–12186, 2017.

23. Fabio Martinelli, Ganbayar Uuganbayar, and Artsiom Yautsiukhin. Optimal secu-
rity conﬁguration for cyber insurance. In IFIP International Conference on ICT
Systems Security and Privacy Protection, pages 187–200. Springer, 2018.

24. Michael E Whitman and Herbert J Mattord. Principles of information security.

Cengage Learning, 2011.

25. Fabrizio Smeraldi and Pasquale Malacaria. How to spend it: optimal investment
for cyber security. In Proceedings of the 1st International Workshop on Agents and
CyberSecurity, page 8. ACM, 2014.

26. M. J Osborne and A. Rubinstein. A course in game theory. MIT press, 1994.
27. J. Von Neumann and O. Morgenstern. Theory of games and economic behavior
(60th anniversary commemorative edition). Princeton university press, 2007.
28. J.F. Nash. Equilibrium points in n-person games. In Proc. of the National Academy

of Sciences, pages 48–49, 1950.

29. T. Alpcan and T. Basar. Network security: a decision and game-theoretic approach.

Cambridge University Press, 2010.

30. T. Basar and G. J. Olsder. Dynamic noncooperative game theory. London Academic

press, 1995.

31. David Pisinger. Where are the hard knapsack problems? Computers & Operations

Research, 32(9):2271–2284, 2005.

32. Stefan Rass and Sandra K¨onig. Password security as a game of entropies. Entropy,

20(5):312, 2018.

