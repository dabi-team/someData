2
2
0
2

r
p
A
3
1

]

R
C
.
s
c
[

3
v
4
4
0
0
0
.
3
0
1
2
:
v
i
X
r
a

Yoneda Hacking: The Algebra of Attacker Actions

GEORGIOS BAKIRTZIS, The University of Texas at Austin, USA
FABRIZIO GENOVESE, University of Pisa, Italy
CODY H. FLEMING, Iowa State University, USA

Our work focuses on modeling the security of systems from their component-level designs. Towards this
goal, we develop a categorical formalism to model attacker actions. Equipping the categorical formalism with
algebras produces two interesting results for security modeling. First, using the Yoneda lemma, we can model
attacker reconnaissance missions. In this context, the Yoneda lemma shows us that if two system represen-
tations, one being complete and the other being the attackerâ€™s incomplete view, agree at every possible test,
they behave the same. The implication is that attackers can still successfully exploit the system even with in-
complete information. Second, we model the potential changes to the system via an exploit. An exploit either
manipulates the interactions between system components, such as providing the wrong values to a sensor, or
changes the components themselves, such as controlling a global positioning system (GPS). One additional
beneï¬t of using category theory is that mathematical operations can be represented as formal diagrams, help-
ful in applying this analysis in a model-based design setting. We illustrate this modeling framework using an
unmanned aerial vehicle (UAV) cyber-physical system model. We demonstrate and model two types of attacks
(1) a rewiring attack, which violates data integrity, and (2) a rewriting attack, which violates availability.

CCS Concepts: â€¢ Security and privacy â†’ Formal security models; â€¢ Computer systems organization
â†’ Embedded and cyber-physical systems; â€¢ Theory of computation â†’ Semantics and reasoning; â€¢
Computing methodologies â†’ Modeling and simulation.

1 INTRODUCTION

In the past decade, there has been signiï¬cant eï¬€ort in adding formal underpinnings to security
modeling [41, 55]. This research trajectory is evidenced by the NSF/IARPA/NSA workshop on the
science of security, which underlines that there are three areas in need of innovation: metrics, for-
mal methods, and experimentation [26]. In addition, there is still an increasing need for deï¬ning
(in)security as a modeling problem [6, 13, 51]. This paper develops a formal method for model-
ing attacker actions at the abstraction level of component-level system models. Speciï¬cally, the
categorical result of the Yoneda lemma intuitively states that if two system representations agree
under any possible test, they behave equivalently. We use this notion to formally show that given
two diï¬€erent architectural representations of a system that agree on every test, an attacker can
still eï¬€ectively exploit a system, even with an inaccurate knowledge base of the architecture.

Security engineering has moved from the paradigm of securing a list of assets to modeling in
graphs of networked components, which is more congruent with attacker behavior [40]. These
graphs help analyze the systemâ€™s security posture [10]; however, we can improve them further
using the added structure that comes with categorical models of component-level system models,
which are by deï¬nition compositional; a valuable property for security modeling [24]. The basis
of the compositional framework lies in functorial semantics, relationships that add meaning to
arbitrary syntax based on an already known structure. In the context of security modeling, these
functorial semantics that comes with the category-theoretic modeling framework also explicitly
relate several essential views for modeling and analyzing cyber-physical systems (CPS), where
continuous and discrete behaviors interrelate to produce a total behavior.

The categorical structure comes in the form of decomposition rules between system behavior
and system architecture, which improves upon current practice where system behavior is disjoint
from system architecture. Additionally, this approach provides for early security modeling, where

Authorsâ€™ addresses: Georgios Bakirtzis, bakirtzis@utexas.edu, The University of Texas at Austin, USA; Fabrizio Genovese,
fabrizio@statebox.io, University of Pisa, Italy; Cody H. Fleming, ï¬‚emingc@iastate.edu, Iowa State University, USA.

 
 
 
 
 
 
2

Georgios Bakirtzis, Fabrizio Genovese, and Cody H. Fleming

engineering decisions are most eï¬€ective [12, 64], by operating on models instead of implementa-
tions. Early security modeling is possible because categorical semantics reside in a higher level of
abstraction than, for example, attack graphs [60], which work best after source code is available.
Implementing this category-theoretic modeling method allows us to use the Yoneda lemma to
show the impact of exploitable vulnerabilities from an attackerâ€™s perspective over a system model,
which can be incomplete or even partially erroneous compared to the system under attack.

An essential step to building a compositional security modeling framework is reformulating the
problem in terms of algebras, where the properties of sets and operations between them are de-
ï¬ned precisely. We develop algebras describing behaviors (block diagrams), architectures (graphs),
and security operations. We formalize diagrammatic reasoning and unify these diï¬€ering views of
the system (behavior and architecture, and attacker actions). This categorical formalization of di-
agrammatic reasoning has found success in, for example, manipulating quantum processes [2, 20]
and databases [59]. We posit a similar innovation would be useful in deï¬ning a high-level interpre-
tation of attacker actions diagrammatically. This categorical interpretation formalizes two attacker
actions; learning and hijacking. While this framework does not examine particular attacks by it-
self, attack pattern databases (for example, MITRE CAPEC [18]) and attacker modeling frameworks
(for example, MITRE ATT&CK [65]) can be used to augment the model with concrete examples of
attacker actions.

This paper develops the foundations of security within a compositional CPS theory modeling
framework [9], a ï¬‚avor of what Lee calls dynamical computational systems theory [42]. For-
mal composition rules could overcome some of the new challenges CPS introduces to cyberse-
curity [19, 33], including the intertwined nature of safety and security in this setting. Speciï¬cally,
our contributions are in the domain of formal methods for security to assist the model-based de-
sign of CPS using category theory. These contributions are still bound by well-known problems
of the foundations and general science of security, such as the lack of a well-deï¬ned common lan-
guage [37].

â€¢ Describing how fundamental concepts in category theory, such as functors to the category
of sets, can be interpreted as testing procedures and results like the Yoneda lemma can be
used to infer similarities between systems given the similarities between their test outcomes.
â€¢ Directly using these insights to model the most common phases of an attack that consist
of learning ï¬rst and on the attack itself afterward, thereby formally modeling from the at-
tackerâ€™s perspective.

â€¢ Extending the approach to CPS by wiring diagrams and their algebras [12], termed systems-
as-algebras, to provide compelling examples of how our mathematical formalization works
in practice, which gives rise to formal categorical methods for CPS security.

A concrete future result of this line of theoretical work would be the integration of security prim-
itives within systems modeling languages, which will be essential for assuring that CPS models
conform to security requirements. We show in a guided process how to achieve this by modeling
a rewiring attack and a component attack on an unmanned aerial vehicle (UAV) and how both
attacks can be represented diagrammatically as formal methods.

2 PROBLEM FORMULATION
Having ï¬xed some system, by an attack, we mean any procedure intended to change system be-
havior maliciously. This deï¬nition is expansive and ranges from privilege escalation in a computer
system to sabotaging a car. We consider an attacker any actor who performs any such process to
degrade a systemâ€™s behavior. Traditionally, attacking a system is viewed as an art, and as such, it

Yoneda Hacking: The Algebra of Attacker Actions

3

requires a certain degree of heuristics. Our goal is to formalize these heuristics mathematically,
using the attackerâ€™s point of view.

It makes sense to divide attacker capabilities into two distinct phases: learning and hijacking.
Learning is where the attacker gathers information about the target system in the hope of ï¬nding
a weakness. Hijacking is where the attacker exploits a given weakness to change the behavior of
some component, which reverberates on the system as a whole. The particulars of how learning
and hijacking phases are exercised and how they provide feedback to each other depend on the
capabilities and goal of the attacker. In defender terms, this would be the threat model.

To model the learning phase, we need a mathematical description of what probing a system
for information means. To model the hijacking phase, we need to mathematically express that the
attacker can act on a system to change it.

Crucially, there is an intermediate step between the two phases of how any given weakness
is turned into an exploiting procedure to change the behavior of some subsystem. The generality
of categorical structures models the steps an attacker takes to ï¬nd system weaknesses and how
the exploiting procedures reverberate in the system as a whole. The reason why this abstraction
level of modeling security is acceptable is threefold. First, turning a weakness into a viable exploit
depends heavily on implementation details, for example, the Spectre and Meltdown exploits [47].
Second, the largest class of attacker actions involves already developed exploits, either internally
or through a marketplace, deployed in some sequence to degrade the systemâ€™s behavior, without
necessarily the attacker knowing how they work [1]. Third, suppose a known attack violates a
system component. In that case, this intermediate step is unnecessary. At the same time, if it is
unknown, the formalism can add increasing levels of detail in the hierarchy to include, for example,
source code fragments.

For instance, an attacker may ï¬nd out by testing (phase 1) that a given laptop uses a particular
WiFi card model. The attacker can then purchase â€“ if it exists â€“ an exploit for the given card and
deploy it. At this point, the systemâ€™s behavior as a whole will change (phase 2), for example, by
giving the attacker the possibility to run any code on the machine. This example is taken straight
out of real experience [50]. Importantly, we claim that an attacker can hijack a system even with
an incomplete view of it, as long as the system and the mental model are behaviorally equivalent
from the attackerâ€™s point of view. Mathematically, this relies on the assumption that the exploit is
invariant under isomorphism of behavior.

assumptions
In practice, this means the following: we represent behaviors of systems using the
concept of categorical semantics (Section 3). This categorical semantics can be more or less granular,
depending on how low-level we want our descriptions to be. For instance, consider specifying
behavior in terms of automata. We can represent automata as theoretical objects, but we can also
view their implementation details. We can describe the system behavior under some formalism
and relate it to concrete elements. As a reductionist example, an automaton can be implemented
in either a system-on-chip or a ï¬eld-programmable gate array (FPGA). These would amount to
diï¬€erent choices of categorical semantics.

Two automata may be isomorphic in the former setting but not in the latter: this could result
in having two diï¬€erent implementations of the same theoretical concept (for example, this is the
case in considering the same automaton implemented in two diï¬€erent programming languages).
An attack exploiting the automaton design will be isomorphism-invariant in both settings: such an
attack exploits the idea that it is possible to start from a state of a given automaton and end up in
another state via a legitimate sequence of moves. An attack exploiting the automaton implemen-
tation (for example, some weakness of the programming language the automaton is implemented
in) will be isomorphism-invariant only in the latter setting. Our categorical semantics cannot â€œseeâ€

4

Georgios Bakirtzis, Fabrizio Genovese, and Cody H. Fleming

implementation diï¬€erences at the theoretical level. This amounts to saying that â€œan attack is pos-
sible even if the attacker has a diï¬€ering view of the system, as long as it is behaviorally equivalent
to the system itselfâ€ holds only if the categorical semantics developed for application are granular
enough to faithfully model the level of generality on which a given exploit acts.

The main mathematical tools used to build the proposed compositional modeling framework
for cybersecurity in CPS are: a compositional system model in the wiring diagram category; the
Yoneda lemma, which represents tests over the system model, and more speciï¬cally, the Yoneda
lemma fully determines a given object by its relationships [15]; and ï¬nally functors and natural
transformations to investigate the eï¬€ects of an exploit formally. We have decided to omit from the
main text these primitive deï¬nitions but have included a formal treatment (Appendix A) and refer
the reader to more comprehensive texts for missing details [28, 43].

3 SYSTEMS AS ALGEBRAS
We use the categorical structures to develop algebraic machinery such that it is possible to model
security violations over a CPS model. The one assumption we make is that an already existent
model of a CPS resides within a category. The motivation for this assumption is twofold. First,
through category theory, it is possible to unify behavioral models of control systems with models
of candidate concrete implementation of this behavior [9]. Uniï¬cation through the categorical for-
malism traces between algebras and their associated models necessary for the design of CPS [11].
Second, as it pertains to security assessment, it is helpful to see the eï¬€ects of an attack at the
behavioral level, even though most security assessment techniques apply to implementations â€“
this relationship builts in the intuition of the security analyst. By having a categorical systems
model, we can capture formally and, therefore, precisely the behavioral eï¬€ects of an attack from
the particular modeled implementation to the set of control behaviors.

We acknowledge that this assumption contains limitations (Section 4), including that systems
are often modeled after the fact in a largely informal manner. However, we posit that to move
the goal post towards a compositional CPS theory as deï¬ned in the introduction, we must move
towards a more formal treatment of both systems modeling and security analysis. Category theory
is but one possible formalism towards this direction. Category theory has the beneï¬t of relating
and transforming between diï¬€erent model types. This is an important attribute that can promote
and merge existing approaches from the areas of control, systems theory, and security instead of
requiring new developments in formalisms for each individual area.

This view is consistent with the concerns of the industry. Often, uniï¬ed languages are reduc-
tionist in practice, causing increased complexity and lower ï¬delity of models [48]. However, the
categorical framework we develop here (and others in the area of dynamical systems, for example,
by Spivak and Tan [61]) results in the ability to translate between already known and used models.
The categorical formalism could be in the backend of a modeling language without the system
designer or security analyst interacting with any unfamiliar syntax.

We now use category theory (Appendix A) to present this compositional theory of CPS. The
general systems-as-algebras paradigm was invented by Schultz et al. [58], and its particular devel-
opment for CPS was invented by Bakirtzis et al. [8, 12]. The wiring diagram is the cornerstone
category for developing a categorical argument for compositional security analysis for CPS mod-
els.

Systems as algebras provide a framework for compositional CPS models that further enable
the compositional study of security properties. In applied category theory, diagrams are not mere
pictures but instead mathematics in and of themselves [21]. Our choice of categorical structure
to represent system models is the category of wiring diagrams and labeled boxes, denoted W.

Yoneda Hacking: The Algebra of Attacker Actions

5

C

L

D

Fig. 1. A generic model of a UAV in the wiring diagram category treats the system as black boxes and the
connections between them.

Therefore, we present the inner workings of the wiring diagram category W as explicitly applied
to CPS before moving on to address security property modeling.

Deï¬nition 1. We deï¬ne the category of wiring diagrams, W, as follows:

â€¢ The objects of the category W are pairs of sets ğ‘‹ = (ğ‘‹in, ğ‘‹out), which we depict as labelled

boxes.

ğ‘‹in

ğ‘‹

ğ‘‹out

â€¢ The morphisms of the category W are functions. Particularly, a morphism ğ‘‹ â†’ ğ‘Œ is a pair
of morphisms (ğ‘“in : ğ‘‹out Ã— ğ‘Œin â†’ ğ‘‹in, ğ‘“out : ğ‘‹out â†’ ğ‘Œout) in Set that should be thought of as
providing the ï¬‚ow of information in a picture as follows.

ğ‘Œ

ğ‘‹

Moreover, the category W is monoidal and, therefore, comes equipped with a tensor product ğ‘‹ âŠ—
ğ‘Œ = (ğ‘‹in Ã— ğ‘Œin, ğ‘‹out Ã— ğ‘Œout), that formalizes two processes happening in parallel.

ğ‘‹

ğ‘Œ

The wiring diagram category, W, gives a formal composition rule for connecting labeled boxes
and wires. To add some meaning to those boxes, we need to develop an algebra that assigns some
form of behavior, for example, in the form of automata or state-space models. The semantics of
CPS will predominantly exist in the category of sets and functions Set and, because we are working
with control systems, the category of linear spaces and linear maps Lin.

ğ‘

, and applies the mathematical interpretation of behavior to it, ğ¹ (

The boxes at the current moment are uninhabited. Usually, we can describe the behavior of a
CPS mathematically via some equations. To assign some behavior to the boxes in the wiring dia-
gram category W, we need to construct an algebra of behaviors ğ¹ that takes an empty box, say
). Formally, we ex-
press this as a functor from W to Cat, which assigns to every box a category representing the kind
of systems that can inhabit it. Morphisms of W map to functors that build the category of possible
inhabitants of the total composite system from system components. Detailed examples working
out the assignment of behavior in the case of Moore machines [58], contract algebras [9], and
dynamical systems [22] have been already worked out in the literature. Our security framework
works in any system that such a functorial assignment represents.

ğ‘

6

Georgios Bakirtzis, Fabrizio Genovese, and Cody H. Fleming

Processor
ğ‘ƒ2

C

Servos
ğ‘‰

L

Processor
ğ‘ƒ1

IMU
ğ¼1
IMU
ğ¼2

GPS
ğº

UAV

D

Airframe
ğ¹

Aileron
ğ‘‹

Rudder
ğ‘Œ

Throttle
ğ‘

Elevator
ğ‘ˆ

Fig. 2. The hierarchical decomposition from behavior to system architecture is formally contained within
the slice category C/ğ‘ in which there exist all possible design decisions that adhere to the behavioral model.
We segment here to subsystems following a behavior decomposition to sensors L, controller C, and dynamics
D. Split wires indicate function duplication, Î”.

The other way around, one can formally decompose a box (which now is inhabited by math-
ematical processes) to a particular hardware and software architecture to implement a CPS. In
this paper, we use an example of a UAV, but the process is repeatable for any well-formed system
algebra that can take the following form.

ğ¹

W
ğ‘‹ =(ğ‘‹in, ğ‘‹out)
ğ‘“
ğ‘Œ =(ğ‘Œin, ğ‘Œout)

Cat

ğ¹ğ‘‹

ğ¹ (ğ‘“ )

ğ¹ğ‘Œ

inner box

wiring

outer box

subsystems category

composite system functor

resulting system category

The UAV is composed of a sensor unit, denoted L, of a controller unit, denoted C, and of a
dynamics unit, denoted D (Fig. 1). We have represented the assignment of behaviors to wiring
diagrams with a functor

ğ¹ : W â†’ Cat.

In our running example, ğ¹ (UAV) denotes the category of all the possible behaviors that we can
assign to the UAV box. Thus, our UAV is a pair (UAV, ğ‘†) with ğ‘† an object of ğ¹ (UAV) representing the
particular UAV model at hand. Each of these units is itself composed of various subsystems (Fig. 1).
Multiple possible system architectures can implement this higher-level behavior. We assume that
the attacker is familiar with the general class of vehicle CPS. We focus on one possible but relatively
simple system architecture for illustrative purposes. The slice category over the wiring diagram
gives one model of vertical composition using category theory.

For any category C and a ï¬xed object ğ¶ âˆˆ C, the slice category C/ğ¶ has as objects C-morphisms
with ï¬xed target ğ¶, for example ğ‘“ : ğ´ â†’ ğ¶, ğ‘” : ğµ â†’ ğ¶, Â· Â· Â· . The arrows in that category from some
ğ‘“ to some ğ‘” are C-morphisms ğ‘˜ : ğ´ â†’ ğµ between the domains, making the formed triangle

ğ´

ğ‘“

ğ‘˜

ğ¶

ğµ

ğ‘”

Yoneda Hacking: The Algebra of Attacker Actions

7

commute, namely ğ‘”â—¦ğ‘˜ = ğ‘“ . Intuitively, the slice category gives us a way of breaking up morphisms
into more morphisms leading to the decomposition to a particular architecture from a general
understanding of the behavioral view as recorded in the wiring diagram category, W. For our
running UAV example, we have multiple possible decompositions to the slice category, but we will
use one that is functionally complete (Fig. 2).

4 THE ALGEBRA OF ATTACKER ACTIONS
Using the Yoneda lemma (Appendix A.4) and wiring diagrams and their algebras (Section 3), we
will formalize attacks. This is the core of this work, and all the concepts presented from now on
are new developments.

In our eï¬€ort, we embrace the perspective of the attacker. For us, an attacker is simply an actor
wanting to inï¬‚uence or change the behavior of some given system. We do not distinguish between
attacks aiming at taking control of the system (as it is common in computer hacking) and attacks
seeking to inï¬‚uence its behavior to obtain a particular eï¬€ect (as in sabotage). Our framework mod-
els attacker actions to encompass both mechanisms and domains of attacks as deï¬ned in common
attack pattern enumeration and classiï¬cation (CAPEC) [18].

To describe the entire cycle of an attack, we split it into the two following main phases.

Phase 1) Learning (exploration), or information gathering, is concerned with probing/eavesdrop-
ping on the system to discern its behavior. We further divide this activity into general
learning, where the attacker focuses on gathering a broad understanding of the system
at hand, and speciï¬c learning, where the attacker probes the system to understand some
particular component design choices.

Phase 2) Hijacking (exploitation), where the attacker, having learned enough information to un-
derstand the weak spots of a system, deploys an exploit which takes advantage of a found
architectural ï¬‚aw to inï¬‚uence the behavior of the system in some way the attacker de-
sires.

Example 1. Consider an attacker wanting to take control (or sabotage) of a UAV. The attacker
starts by learning and gathering information about the target UAV (phase 1). General learning here
can be the attacker trying to understand if the UAV has a GPS module on board. If there is a GPS,
speciï¬c information gathering consists of understanding how the GPS module communicates with
surrounding units. This general-speciï¬c learning pattern can repeat arbitrarily: the attacker could
now focus on the GPS module to understand if some particular kind of integrated circuit is used
in its schematic.

Once an attacker is suï¬ƒciently informed about the system, the exploit can be deployed (phase
2). In our example, this may be rewriting the ï¬rmware of the GPS module over the air or supposing
that the attacker has physical access to the UAV, manually rewiring the module, or replacing some
integrated circuit in it.

One fundamental assumption is that we do not precisely model how a given exploit is developed
but only how it is administered and provide a compositional recipe to describe how this change
of behavior propagates to the whole system. In practice, this means postulating that the attacker
already has access to a knowledge database of tools made to take advantage of a given structural
ï¬‚aw in a given (sub)system. This postulate is not unthinkable; an attacker can hijack a system
without personally creating the exploit. For example, zero day exploits â€“ that is, exploits of a given
ï¬‚aw that is still unknown to the public, including the target manufacturer â€“ are common in hacking
and can be commonly bought over the web [1]. Another fundamental assumption of our model is
that it forms an algebra in the wiring diagram category. Again, we do not consider this restrictive
for reasons already pointed out by Bakirtzis et al. [12].

8

Georgios Bakirtzis, Fabrizio Genovese, and Cody H. Fleming

4.1 Phase 1 â€“ Learning (Exploration)
First, we model general learning. Assuming an attackerâ€™s perspective, we want to model what
an attacker does to understand the kind of system they want to attack. In practice, this includes
operations such as scanning a computer for open ports, investigating the ï¬rewall policies, ï¬nding
out what operating system is running on the system, and probing a piece of hardware to obtain
information about the systemâ€™s integrated circuits.

Functors W

ğ¹
âˆ’â†’ Cat, W-algebras, represent wiring diagrams together with semantics linking
any diagram to the category describing its possible behaviors. A particular wiring diagram is just
an object ğ‘‹ in W, ğ¹ğ‘‹ is a category: objects model general behavior assignments for ğ‘‹ , while
morphisms take mappings between them that preserve properties we care about. When focusing
on a particular system, we are ï¬xing a wiring diagram ğ‘‹ and one of the many possible behaviors
in the category ğ¹ğ‘‹ . Hence,

a system is a pair (ğ‘‹, ğ‘†), with ğ‘‹ an object
of W and ğ‘† an object of ğ¹ğ‘‹ .
Example 2. Consider ğ¹ to be the W-algebra assigning each wiring diagram ğ‘‹ = (ğ‘‹in, ğ‘‹out) to
the category of Moore machines with ğ‘‹in and ğ‘‹out as input and output alphabets, respectively,
as worked out in detail in [58]. In this setting, a system (ğ‘‹, ğ‘†) is given by a wiring diagram ğ‘‹ =
(ğ‘‹in, ğ‘‹out) and a chosen Moore machine having ğ‘‹in as input alphabet and ğ‘‹out as output alphabet,
respectively.

We suppose we have access to ğ‘‹ (this amounts to saying that we can distinguish the type of inputs
and outputs that our system has) and to ğ¹ğ‘‹ (we know what kind of system we are dealing with),
but not to ğ‘† (we do not know the speciï¬c behavior of the system at hand). The ï¬rst goal of the
attacker is to infer ğ‘† to the degree that an attack is viable.

First things ï¬rst, we select a subset of the objects of ğ¹ğ‘‹ , denoted ğ¾ğ¹ ğ‘‹ (from â€œknownâ€), represent-
ing the systems that the attacker knows or is familiar with. Notice that ğ¾ğ¹ ğ‘‹ should not, in general,
lift to a functor W â†’ Cat, since we do not assume the attacker knowledge to be compositional.
For the same reason, given that there will be an injection ğ¾ğ¹ ğ‘‹ â†©â†’ ğ¹ğ‘‹ representing how the sys-
tems known by the attacker embed in the bigger universe of the systems, we do not necessarily
assume the attacker to know this embedding.

Deï¬nition 2. Given a W-algebra W
is a subset ğ¾ğ¹ ğ‘‹ of the objects of ğ¹ğ‘‹ .

ğ¹
âˆ’â†’ Cat and an object ğ‘‹ in W, a knowledge database for ğ¹, ğ‘‹

An example knowledge database for ğ¹, ğ‘‹ is just a set of Moore machines (Example 2) having

Î˜
âˆ’â†’ Set.

ğ‘‹ = (ğ‘‹in, ğ‘‹out) as input/output alphabets, respectively. Next, we consider functors ğ¹ğ‘‹
These are interpreted as tests, or probes.

â€¢ Given ğ‘† in ğ¹ğ‘‹ , Î˜ğ‘† represents the information we get in probing ğ‘† with a test Î˜. For instance,
ğ‘† may represent a machine on a network, while Î˜ğ‘† could represent the output one gets by
running nmap on ğ‘†.

â€¢ If ğ‘†

ğ‘“
âˆ’â†’ ğ‘† â€² is a morphism of ğ¹ğ‘‹ , then Î˜ğ‘“ is a way to transform the information in Î˜ğ´ to
information in Î˜ğµ. Our tests are well suited to detect the properties we care about preserved
by morphisms of ğ¹ğ‘‹ .

â€¢ In this interpretation, functoriality holds on the nose. Transforming a system by â€œdoing noth-
ingâ€ (identity morphism) should give the same test outcome (functor identity law). Moreover,
composing transformations should amount to composing outcomes of the testing.

We package all this information as follows.

Yoneda Hacking: The Algebra of Attacker Actions

9

Deï¬nition 3. Given a W-algebra W
ğ¹ğ‘‹ â†’ Set.

ğ¹
âˆ’â†’ Cat and an object ğ‘‹ in W, a test for ğ¹, ğ‘‹ is a functor

A possible test is a functor mapping any Moore machine (Example 2) to its set of states. This test
is a functor because of how morphisms between Moore machines are deï¬ned; see, for instance,
Schultz et al. [58]. Again, the attacker does not have access to ğ‘† but has access to Î˜ğ‘† for some
tests Î˜. The tests represent the ability of the attacker to perform tests on the system. These tests
describe an ongoing reconnaissance mission, which often is the step that takes the longest time
and resources of the attacker. The goal of the attacker is to prove in some sense that ğ‘† â‰ƒ ğ‘† â€², for
some ğ‘† â€² in ğ¾ğ¹ ğ‘‹ . The system ğ‘† is an instance of a system ğ‘† â€² the attacker is familiar with. Given our
assumption, we can then postulate that the attacker knows an exploit for ğ‘† â€² to move to phase 2.
We make the assumption that, for any ğ‘† â€² âˆˆ ğ¾ğ¹ ğ‘‹ , the attacker has access to ğ‘† â€². This assumption
is natural, since ğ‘† â€² is by deï¬nition in the knowledge base of the attacker. In particular, we assume
that the attacker is able to perform any test to any known system, hence,

for any ğ‘† â€² âˆˆ ğ¾ğ¹ ğ‘‹ and ğ¹ğ‘‹
the attacker has access to Î˜ğ‘† â€².

Î˜
âˆ’â†’ Set,

We extend the example of Moore machines (Example 2) to include a knowledge database and
security tests. The attacker, therefore, knows the set of states of all Moore machines residing in
their knowledge database. The Yoneda lemma says that if Î˜ğ‘† â‰ƒ Î˜ğ‘† â€² for all Î˜, then ğ‘† â‰ƒ ğ‘† â€². In our
compositional framework, let us interpret what this means, considering some corner cases.

â€¢ Suppose that for some object ğ‘† in ğ¹ğ‘‹ there is an object ğ‘† â€² in ğ¾ğ¹ ğ‘‹ such that ğ‘† â‰ƒ ğ‘† â€². If the
attacker has access to Î˜ğ‘† for any Î˜, then the attacker will be able to conclude ğ‘† â‰ƒ ğ‘† â€² from
Î˜ğ‘† â‰ƒ Î˜ğ‘† â€². That is, if the attacker is free to perform any form of testing and possesses a vast
knowledge database, then ğ‘† can be determined with absolute precision.

â€¢ If the attacker has access to any Î˜, but there is no ğ‘† â€² in ğ¾ğ¹ ğ‘‹ such that ğ‘† â‰ƒ ğ‘† â€², then the
attacker will not be able to conclude ğ‘† â‰ƒ ğ‘† â€². Tests can be arbitrarily precise, but the attacker
cannot interpret them.

â€¢ If there is an object ğ‘† â€² in ğ¾ğ¹ ğ‘‹ such that ğ‘† â‰ƒ ğ‘† â€², but the attacker has no access to all Î˜, then it
will not be able to conclude with certainty that ğ‘† â‰ƒ ğ‘† â€², because the Yoneda lemma does not
hold in this setting. Still, after performing enough tests, the attacker may be prone to infer
that ğ‘† â‰ƒ ğ‘† â€² if Î˜ğ‘† â‰ƒ Î˜ğ‘† â€² for enough Î˜ ran. This inference comes with uncertainty, making
information gathering more of an art than a science.

The Yoneda lemma provides a formal justiï¬cation for the insuï¬ƒciency of extensively testing a
system to characterize its behavior adequately. We call this heuristic Yoneda reasoning.

Some tests are more informative than others. For instance, the â€œterminal testâ€ Î˜ sending any
ğ‘‹ to the singleton set {âˆ—} is maximally uninformative: the result of this test is the same for any
system. On the contrary, a functor that is injective on objects lifts to a test that yields the conclusion
ğ‘‹ = ğ‘Œ from ğ¹ğ‘‹ = ğ¹ğ‘Œ . Further formalizing the possible spectrum of tests, hopefully weighing them
with probability distributions to model their reliability, is an ongoing direction of future work. We
suppose that the attacker pinned down the target system ğ‘† with some precision. The next step
of an attack is harvesting information about the architectural design choices implementing the
system. After we know how ğ‘† works, we need to determine what ğ‘† is made of.

Previously, we modeled a system of an object ğ‘‹ in W together with an object ğ‘† of ğ¹ğ‘‹ , for some
W-algebra ğ¹ : W â†’ Cat. Now we consider the category of architectural choices for ğ‘‹ , that is, the

slice category W/ğ‘‹ . Objects of this category are morphisms Ã‹ğ‘– ğ‘‹ğ‘–

ğœ™
âˆ’â†’ ğ‘‹ , while morphisms are

10

Georgios Bakirtzis, Fabrizio Genovese, and Cody H. Fleming

morphisms of wiring diagrams making the following triangle commute.

Ã‹ğ‘– ğ‘‹ğ‘–

ğœ™

Ã‹ğ‘— ğ‘‹ ğ‘—

ğœ“

ğ‘“

ğ‘‹

Architectural choices form a category, so we can repeat the reasoning in the last section using W/ğ‘‹
as the category we probe. Again using Yoneda, the attacker can ascertain that a given system (ğ‘‹, ğ‘†)
is made of subsystems (ğ‘‹ğ‘–, ğ‘†ğ‘–), tensored and wired together by ğœ™. At this stage, the attacker still
does not know anything about the ğ‘†ğ‘–, so the process must repeat cyclically.

In practice, tests will not have to be materially re-run on every ğ¹ğ‘‹ğ‘–: the attacker likely has only
access to Î˜ğ‘† â€“ every (ğ‘‹ğ‘–, ğ‘†ğ‘–) being a subsystem of (ğ‘‹, ğ‘†) that may not necessarily be exposed to
Î˜ğ¹ ğœ™
âˆ’âˆ’âˆ’â†’ Î˜ğ¹ğ‘‹ , meaning
external testing. Nevertheless, it will always be the case that Î˜(ğ¹ Ã‹ğ‘– ğ‘‹ğ‘– )
that the outputs of tests over every ğ‘†ğ‘– will have to be reconstructed from tests over ğ‘†. This re-
construction adds another layer of uncertainty for the attacker, who has to devise tests for which
the mapping Î˜ğ¹ğœ™ acts as transparently as possible. Again, this backs up intuition: going back to
Example 1, if some system (ğ‘‹, ğ‘†) comprises a subsystem (ğ‘‹ğ‘–, ğ‘†ğ‘– ) (say, a GPS module), then we
could devise a test on ğ¹ğ‘‹ such that in Î˜ğ‘† the behavior of the subsystem ğ‘†ğ‘– is made apparent. Sim-
ilarly, when running nmap on a system, we can get extra information about which services are
running behind which port, for example, nginx behind port 80. By probing the composite system,
the attacker gets information about its subsystems.
Summarizing, phase 1 is modeled as follows.

(1) The attacker uses tests on ğ¹ğ‘‹ and Yoneda-reasoning to ï¬nd the system ğ‘† representing the

semantics of ğ‘‹ .

(2) The attacker uses tests on W/ğ‘‹ and Yoneda-reasoning to ï¬nd the wiring Ã‹ğ‘– ğ‘‹ğ‘–

resenting the implementation of ğ‘‹ .

ğœ™
âˆ’â†’ ğ‘‹ rep-

(3) The attacker repeats step 1 on any ğ¹ğ‘‹ğ‘– of interest to ï¬nd the precise behavior of the subsys-

tem marked with ğ‘‹ğ‘–.

(4) The attacker repeats step 2 on W/ğ‘‹ğ‘– to obtain more information about the subsystems mak-

ing up ğ‘‹ğ‘–.

(5) These steps iterate cyclically until the attacker has gathered enough information to exploit

the system.

4.2 Phase 2 â€“ Hijacking (Exploitation)
Now suppose that the attacker has a good grasp of the system behavior and architecture and
model the last step, in which the system is hijacked and exploited. We distinguish between two
main kinds of attacks.

Type 1) Rewriting attacks change the behavior of a (sub)system. Practical examples of this are,
for instance, exploiting a vulnerability in a WiFi card to rewrite its ï¬rmware and using
this change of behavior to progress towards obtaining administrative privileges over the
whole machine.

Type 2) Rewiring attacks modify the way subsystems communicate with each other.

Yoneda Hacking: The Algebra of Attacker Actions

11

C

L

âˆ’â†’

L

C

Fig. 3. A rewiring attack is modelled using endomorphisms of wiring diagrams.

Deï¬nition 4 (Rewriting Attack). Given a W-algebra ğ¹ , systems (ğ‘‹1, ğ‘†1), . . . , (ğ‘‹ğ‘›, ğ‘†ğ‘›) and a mor-
phism ğ‘‹1 âŠ— Â· Â· Â· âŠ—ğ‘‹ğ‘›
ğ‘– of ğ¹ğ‘‹ğ‘– for some ğ‘–. The resulting
system after the attack is given by the couple

ğ‘¤
âˆ’â†’ ğ‘‹ , a rewriting attack is a morphism ğ‘†ğ‘–

â„
âˆ’â†’ ğ‘† â€²

(cid:0)ğ‘‹, ğ¹ğ‘¤ (ğ‘†1, . . . , ğ‘† â€²

ğ‘– , . . . , ğ‘†ğ‘›)(cid:1) = (cid:0)ğ‘‹, (ğ¹ğ‘¤ (idğ‘†1, . . . , â„, . . . , idğ‘†ğ‘› )) (ğ‘†1, . . . , ğ‘†ğ‘›)(cid:1) .

ğ‘– . The result of swapping ğ‘†ğ‘– for ğ‘† â€²

In a rewriting attack, we do not change the possible behaviors assigned to wiring diagrams;
the functor ğ¹ stays ï¬xed. The pairs (ğ‘‹ğ‘–, ğ‘†ğ‘–) represent all the subsystems of our whole system,
that can be evaluated as (ğ‘‹, ğ¹ğ‘¤ (ğ‘†1, . . . , ğ‘†ğ‘›)). Here, the ï¬rst component of the couple represents
the shape of the box corresponding to the composite system. To pinpoint with precision the box
inhabitant, we use the wiring diagram ğ‘¤, lift it to a functor between behaviors ğ¹ğ‘¤, and evaluate
this functor on the subsystems at hand, ğ‘†1, . . . , ğ‘†ğ‘›. Then, a rewriting attack is nothing more than a
way, call it â„, to morph one of these ğ‘†ğ‘– into an ğ‘† â€²
ğ‘– can be evaluated
using the functoriality of ğ¹ğ‘¤ and the morphism â„. For Moore machines (Example 2), a set of
pairs (ğ‘‹1, ğ‘†1), . . . , (ğ‘‹ğ‘›, ğ‘†ğ‘›) now represent ğ‘› subsystems, each one with a ï¬xed choice of a Moore
machine â€“ of the right kind, since each ğ‘†ğ‘– âˆˆ ğ¹ğ‘‹ğ‘– â€“ inhabiting it. Each of these machines will have
its own set of states and state-transition function. The resulting Moore machine inhabiting ğ‘‹ will
be (ğ‘‹, ğ¹ğ‘¤ (ğ‘†1, . . . , ğ‘†ğ‘›)).
â„
âˆ’â†’ ğ‘† â€²
In the mapping ğ‘†ğ‘–

ğ‘– âˆˆ ğ¹ğ‘‹ğ‘– is just a Moore machine that has the same in-
put/output alphabets of ğ‘†ğ‘–, but possibly a diï¬€erent set of states or a diï¬€erent state-transition func-
tion. By replacing ğ‘†ğ‘– with ğ‘† â€²
ğ‘– is our rewriting attack, we are swapping the Moore machine ğ‘†ğ‘– in-
habiting the box ğ‘‹ğ‘– with ğ‘† â€²
ğ‘– . The eï¬€ect of this swap will reverberate on the overall system, and
can be calculated using ğ¹ğ‘¤. The Moore machine inhabiting ğ‘‹ is now (cid:0)ğ‘‹, ğ¹ğ‘¤ (ğ‘†1, . . . , ğ‘† â€²
1, . . . , ğ‘†ğ‘›)(cid:1).
Because of compositionality, the morphism ğ‘†ğ‘– â†’ ğ‘† â€²
ğ‘– between submachines lifts to a morphism
ğ¹ğ‘¤ (ğ‘†1, . . . , ğ‘†1, . . . , ğ‘†ğ‘›) â†’ ğ¹ğ‘¤ (ğ‘†1, . . . , ğ‘† â€²

1, . . . , ğ‘†ğ‘›) between the composed machines.

ğ‘– , the object ğ‘† â€²

In our deï¬nition of rewriting attack, we keep the functor ğ¹ ï¬xed, meaning that the category
of behaviors to which we map each wiring diagram stays the same. We could obtain more of a
granular deï¬nition of attack by considering, in addition to the elements considered in Deï¬nition 4,
also monoidal natural transformations between W-algebras. This amounts to having a procedure
to completely replace the kind of systems inhabiting our boxes. For instance, the attacker could
replace Moore machines (Example 2) with automata of some other kind.

Deï¬nition 5 (Rewiring Attack). Given a W-algebra ğ¹ , systems (ğ‘‹1, ğ‘†1), . . . , (ğ‘‹ğ‘›, ğ‘†ğ‘›) and a mor-
â„
phism ğ‘‹1 âŠ— Â· Â· Â· âŠ— ğ‘‹ğ‘›
âˆ’â†’ ğ‘‹ğ‘– for some ğ‘–. The resulting
system after the attack is given by the couple

ğ‘¤
âˆ’â†’ ğ‘‹ , a rewiring attack is a morphism ğ‘‹ğ‘–

(ğ‘‹, ğ¹ (ğ‘¤ â—¦ (id1 âŠ— Â· Â· Â· âŠ— â„ âŠ— Â· Â· Â· âŠ— idğ‘›)) (ğ‘†1, . . . , ğ‘†ğ‘›)) .

12

Georgios Bakirtzis, Fabrizio Genovese, and Cody H. Fleming

Câ€²

Lâ€²

Dâ€²

Fig. 4. The attackerâ€™s understanding of the system after the first cycle of learning.

In the case of a rewiring attack, we keep ğ‘†1, . . . , ğ‘†ğ‘› ï¬xed; we are not changing the speciï¬c objects
inhabiting each box. What the endomorphism â„ does is wrap a given object ğ‘† into new wiring
before composing it with the rest of the system (Fig. 3).

Both rewriting and rewiring attacks form categories. This conforms with our intuition that

attacks can be performed in batches or stacked one on top of each other.

5 COMPOSITIONAL SECURITY MODELING
To illustrate the above compositional security theory as a possible model for security tests and
exploitation methods, we use a system model of a UAV from the perspective of attacker actions
(Example 1).

Letâ€™s start with the minimum observability possible. The attacker knows that the system at hand
is a couple (UAV, ğ‘†): UAV with a two inputs and one output box, and ğ‘† is an object of ğ¹ (UAV), where
ğ¹ : W â†’ Cat maps system to the categories of behaviors relevant in our example. The ï¬rst step
of the attack is gathering information about ğ‘†.

The attacker uses Yoneda reasoning to infer ğ‘† in general information gathering. The attacker

must be able to perform a set of tests on the system (UAV, ğ‘†). Any of such tests is a functor

Î˜ : ğ¹ (UAV) â†’ Set
and the result of the test Î˜ applied to ğ‘† is denoted Î˜ğ‘† (in category theory practice, it is customary
to avoid parentheses whenever possible). In our particular case, Î˜ may be a test that analyzes the
aerodynamics of the UAV during ï¬‚ight. The more informative Î˜ is, and the bigger the number of
Î˜â€™s the attacker can access, the more likely it will infer ğ‘†. If the attacker ï¬nds that ğ‘† â‰ƒ ğ‘† â€² for some
ğ‘† â€² in their knowledge database, ğ¾ğ¹ (UAV) , then the attacker will know how the UAV behaves.

In practice, it is doubtful for the attacker to have access to every test Î˜. As we mention above
(Section 4), this entails that the attacker wonâ€™t be able to infer with certainty that ğ‘† â‰ƒ ğ‘† â€²: most
likely, the attacker will be prone to infer ğ‘† â‰ƒ ğ‘† â€² with a certain degree of conï¬dence. As such, the
outcome of testing is probabilistic more than deterministic. Assuming that the attacker inferred
ğ‘† â‰ƒ ğ‘† â€² for some system ğ‘† â€² in their knowledge database, the particular design choices making up
the UAV are still unknown to them. Applying Yoneda reasoning again to the category W/UAV,
they may be able to infer some of these design choices. For instance, it could be possible to infer
an initial understanding of what the UAV is composed of (Fig. 4). The attacker sees the system
as decomposed into boxes Lâ€², Câ€² and Dâ€², which will be behaviorally equivalent to L, C and D, of
Fig. 1, respectively. The inner workings of such boxes are still unknown to the attacker, which now
focuses on Lâ€². This amounts to repeating the same cycle of Yoneda reasoning, focusing on tests that
target L in particular (Section 4). After running these tests, the attacker sees a ï¬rst approximation
of the UAV (Fig. 5).

The initial understanding of the attacker is slightly erroneous since the two separated IMU units
in UAV conï¬‚ate into one. Still, the two wiring diagrams are behaviorally equivalent. This reï¬‚ects

Yoneda Hacking: The Algebra of Attacker Actions

13

Câ€²

Dâ€²

ğ¼ â€²

ğº â€²

Lâ€²
ğ‘ƒ â€²

Fig. 5. The architecture of the sensory system as understood by the attacker, which is in reality erroneous
but behaviorally equivalent. The attacker found that there is one IMU (when in reality there are two) and a
GPS.

Câ€²

Dâ€²

ğ¼ â€²

ğº â€²
ğ»

Lâ€²Lâ€²
ğ‘ƒ â€²

Fig. 6. The compromised UAV, with GPS firmware hacked and its input wires swapped.

the fact that, on the one hand, Yoneda reasoning is probabilistic, and on the other, identiï¬cation
of the system happens only up to behavioral equivalence.

Now, suppose the attacker decides to do two things: rewriting the ï¬rmware of the GPS module
G and swapping its feedback inputs. The ï¬rst is a rewriting attack, and the second is a rewiring
attack (Section 4).

The GPS module is a system (Gâ€², ğº â€²), where Gâ€² is a box with two inputs and one output, while
ğ» (ğ» stands for

ğº â€² is an object of ğ¹ Gâ€². The rewriting attack is represented by a morphism ğº â€² â†’ ğº â€²
â€œhackedâ€) in the category ğ¹ Gâ€². Denote with

Iâ€² âŠ— Gâ€² âŠ— Pâ€² âŠ— Câ€² âŠ— Dâ€² ğ‘¤ âŠ—idCâ€²âŠ—Dâ€²

âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ Lâ€² âŠ— Câ€² âŠ— Dâ€² ğ‘£

âˆ’â†’ UAV

the morphism putting together the system (Fig. 5). Then we have that

ğ¹ (ğ‘£ â—¦ (ğ‘¤ âŠ— idCâ€² âŠ—Dâ€²)) (ğ¼ â€², ğº â€², ğ‘ƒ â€², ğ¶ â€², ğ· â€²) = ğ‘† â€²

Where ğ¼ â€² is the system inhabiting Iâ€², ğº â€² inhabits Gâ€² and so on, with ğ‘† â€² behaviorally equivalent to
the system ğ‘† inhabiting UAV. The behavior of the UAV after the rewriting attack will be equivalent
to

ğ¹ (ğ‘£ â—¦ (ğ‘¤ âŠ— idCâ€² âŠ—Dâ€²)) (ğ¼ â€², ğº â€²

ğ» , ğ‘ƒ â€², ğ¶ â€², ğ· â€²).

14

Georgios Bakirtzis, Fabrizio Genovese, and Cody H. Fleming

Processor
ğ‘ƒ2

C

Servos
ğ‘‰

L

Processor
ğ‘ƒ1

IMU
ğ¼1
IMU
ğ¼2
GPS
ğºğ»

UAV

D

Airframe
ğ¹

Aileron
ğ‘‹

Rudder
ğ‘Œ

Throttle
ğ‘

Elevator
ğ‘ˆ

Fig. 7. The UAV (Fig. 2), after the attack.

The rewiring attack, instead, is a wiring diagram Gâ€² â„

âˆ’â†’ Gâ€². The following information speciï¬es

this.

Gğ‘–ğ‘› Ã— Gğ‘œğ‘¢ğ‘¡

â„ğ‘–ğ‘›âˆ’âˆ’â†’ Gğ‘–ğ‘›

â„ğ‘–ğ‘›
â†¦âˆ’âˆ’â†’ (ğ‘”2, ğ‘”1)
The resulting system is obtained by considering the wiring diagram

((ğ‘”1, ğ‘”2), ğ‘”3)

Gğ‘œğ‘¢ğ‘¡

â„ğ‘œğ‘¢ğ‘¡âˆ’âˆ’âˆ’â†’ Gğ‘œğ‘¢ğ‘¡

â„ğ‘œğ‘¢ğ‘¡
â†¦âˆ’âˆ’âˆ’â†’ ğ‘”

ğ‘”

Iâ€² âŠ— Gâ€² âŠ— Pâ€² âŠ— Câ€² âŠ— Dâ€²

and evaluating

âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ Iâ€² âŠ— Gâ€² âŠ— Pâ€² âŠ— Câ€² âŠ— Dâ€² ğ‘¤ âŠ—idCâ€²âŠ—Dâ€²
idIâ€² âŠ—â„ âŠ—idPâ€²âŠ—Câ€²âŠ—Dâ€²

âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ Lâ€² âŠ— Câ€² âŠ— Dâ€² ğ‘£

âˆ’â†’ UAV

ğ¹ (ğ‘£ â—¦ (ğ‘¤ âŠ— idCâ€² âŠ—Dâ€²) â—¦ (idIâ€² âŠ—â„ âŠ— idPâ€² âŠ—Câ€² âŠ—Dâ€²)) (ğ¼ â€², ğº â€²

ğ» , ğ‘ƒ â€², ğ¶ â€², ğ· â€²).

Which is the resulting system inhabiting UAV after applying both attacks (Fig. 6). The attacker
presumes how the system will behave after the exploit, assuming they have a correct system proï¬le
from phase 1. Since phase 1 has a margin for error, the attacker can re-probe the system to assure
that the perceived behavior is compatible with reality. This further round of testing is necessary
to assert with conï¬dence that the exploit has been deployed correctly.

In this example, we postulated that the attacker was indeed able to gather information about
the UAV correctly. Formally, we expressed this by stating what we consider to be the actual UAV
(Fig. 2) and the attackerâ€™s understanding of what the UAV is (Fig. 5) are behaviorally equivalent.
Because functors preserve isomorphisms, we can describe how the attack impacts the actual UAV
(Fig. 7).

We now describe several other possible attacks: one consists in feeding a counterfeit GPS signal
to the UAV to compromise it. This attack is documented â€œCAPEC-627: Counterfeit GPS Signalsâ€
and is considered diï¬ƒcult to realize. The wiring diagrams formalism gives us an idea of why:
feeding a counterfeit GPS signal does not involve modifying the GPS module. What changes is
the information traveling on the GPS wires, which communicate with the outside world. So, to
understand this attack properly, one needs to model how the UAV interacts with the environment
it is in (Fig. 8). Here, by Environment we mean a process that, given the UAV position in space and
time, returns the data sensed by the IMU and GPS units. We see that spooï¬ng a GPS signal does
not amount to intervening on the UAV but on the environment itself. Attackers rarely can control
the environment within a region of space and time â€“ radio waves from the GPS satellites in this
particular case â€“ that is big enough to inï¬‚uence the behavior of the single UAV.

Yoneda Hacking: The Algebra of Attacker Actions

15

UAV

Câ€²

Dâ€²

ğ¼ â€²

ğº â€²

Lâ€²
ğ‘ƒ â€²

Environment

Fig. 8. Feeding counterfeit GPS signals to the UAV hijacks Environment.

GCS

UAV

Câ€²

Dâ€²

ğ¼ â€²

ğº â€²

Lâ€²
ğ‘ƒ â€²

Fig. 9. Social engineering attacks may hijack the ground control station (GCS).

To conclude, we present another possible attack, performed using social engineering. As with the
previous example, social engineering does not exploit the UAV itself but instead takes advantage
of the human factor. Examples of this may include bribing whoever programs the UAV goals or
making the control tower believe that a given order has been oï¬ƒcially issued from whoever is in
command, for example, as deï¬ned in â€œCAPEC-137: Parameter Injectionâ€.

As in the previous case, the behavior of the UAV as a wiring diagram is unchanged. Instead, what
changes is the information traveling on the ï¬rst input wire of the UAV box. From our perspective,
this requires again to put the UAV into context (Fig. 9). An attack based on social engineering will
consist in rewriting the box GCS, which abstracts away a possible ground control station.

The categorical semantics of CPS security modeling for the UAV can be implemented algorith-

mically (Listing 1 & 2).

Listing 1. Modeling attacker learning

-- Define category of wiring diagrams
W : Category
W

= Definition 1

-- Define functor for UAV modeling
F : Functor W â†’ Cat
F = assignment of UAV behavior ( linear time invariant system ) to boxes

-- Model UAV as a 2 - input 1 - output W- box
: W
UAV
UAV = (2 ,1)

16

Georgios Bakirtzis, Fabrizio Genovese, and Cody H. Fleming

-- Knowledge database
ğ¾ğ¹ (UAV) : List ğ¹ (UAV)
ğ¾ğ¹ (UAV) = attacker knowledge for systems of type UAV

-- Compare tests with target S
CompareTests : ( Functor ğ¹ (UAV) â†’ Set) â†’ ğ¹ (UAV) â†’ Bool
CompareTests Î˜ S ' = Î˜(ğ¾ğ¹ (UAV) (ğ‘† â€²)) â‰ƒ Î˜(ğ‘†)

-- Yoneda reasoning
for each Î˜ : Functor ğ¹ (UAV) â†’ Set
filter ( CompareTests Î˜) K

-- Running security tests reveals the following boxes
Lâ€² , Câ€² , Dâ€²
Lâ€² , Câ€² = (2 ,1)
Dâ€² = (1 ,1)

: W

diagram : Morphism W (Lâ€² âŠ— Câ€² âŠ— Dâ€²) â†’ UAV
diagram = ( in , out )
where
in : Morphism Set UAVin Ã— (Lâ€²
ğ‘œğ‘¢ğ‘¡ Ã— Câ€²
in u1 u2 l c d = ( u2 , d , u1 , c)
out : Morphism Set (Lâ€²
ğ‘œğ‘¢ğ‘¡ Ã— Dâ€²
out l c d = d

ğ‘œğ‘¢ğ‘¡ Ã— Câ€²

ğ‘œğ‘¢ğ‘¡ ) â†’ UAVğ‘œğ‘¢ğ‘¡

ğ‘œğ‘¢ğ‘¡ Ã— Dâ€²

ğ‘œğ‘¢ğ‘¡ ) â†’ (Lâ€²

ğ‘–ğ‘› Ã— Câ€²

ğ‘–ğ‘› Ã— Dâ€²

ğ‘–ğ‘›)

Listing 2. Modeling hijacking

-- By iterating learning further decompose Lâ€²
Iâ€² , Gâ€² , Pâ€²
Iâ€² , Gâ€² , Pâ€² = (2 ,1)

: W

Ldiagram : Morphism W (Iâ€² âŠ— Gâ€² âŠ— Pâ€²) â†’ Lâ€²
Ldiagram = ( in , out )
where
in : Morphism Set (Lâ€²
in l1 l2 i g p = ( l1 , l2 , l1 , l2 , i , g )
out : Morphism Set (Iâ€²
ğ‘œğ‘¢ğ‘¡ ) â†’ Lâ€²
out i g p = p

ğ‘œğ‘¢ğ‘¡ Ã— Pâ€²

ğ‘œğ‘¢ğ‘¡ Ã— Gâ€²

ğ‘œğ‘¢ğ‘¡ Ã— Gâ€²

ğ‘œğ‘¢ğ‘¡ Ã— Pâ€²

ğ‘–ğ‘› Ã— (Iâ€²

ğ‘œğ‘¢ğ‘¡

ğ‘œğ‘¢ğ‘¡ ) â†’ (Iâ€²

ğ‘–ğ‘› Ã— Gâ€²

ğ‘–ğ‘› Ã— Pâ€²

ğ‘–ğ‘› ))

-- Rewriting attack
ğœ‚ : NatTrans ( Functor W â†’ Cat) â†’ ( Functor W â†’ Cat)

-- ğœ‚ is the identity on everything but G '
ğœ‚ Gâ€² : Morphism F Gâ€² â†’ F Gâ€²
ğœ‚ Gâ€² = firmware rewriting

-- Rewiring attack
Lattack : Morphism W (Iâ€² âŠ— Gâ€² âŠ— Pâ€²) â†’ Lâ€²
Lattack = ( in , out )
where
in : Morphism Set (Lâ€²
in l1 l2 i g p = (l1 , l2 , l1 , 0 , i , g )
out : Morphism Set (Iâ€²
out i g p = p

ğ‘œğ‘¢ğ‘¡ Ã— Pâ€²

ğ‘œğ‘¢ğ‘¡ Ã— Gâ€²

ğ‘œğ‘¢ğ‘¡ Ã— Pâ€²

ğ‘œğ‘¢ğ‘¡ Ã— Gâ€²

ğ‘–ğ‘› Ã— (Iâ€²

ğ‘œğ‘¢ğ‘¡ ) â†’ Lâ€²

ğ‘œğ‘¢ğ‘¡

ğ‘œğ‘¢ğ‘¡ ) â†’ (Iâ€²

ğ‘–ğ‘› Ã— Gâ€²

ğ‘–ğ‘› Ã— Pâ€²

ğ‘–ğ‘› )

Yoneda Hacking: The Algebra of Attacker Actions

17

Rewiring : Functor W â†’ W
Rewiring Ldiagram = Lattack

-- The modified behavior of the hijacked UAV
behavior : F (UAV)
behavior = ğœ‚ UAV ( F ( Rewiring (UAV) ) ) (S ')

limitations
Based on how we deï¬ned Yoneda reasoning, we identify several limitations. These
limitations can be overcome by enriching over metric spaces, which we will also discuss. The main
point of this paper is to set a solid theoretical footprint of category theory and the diagrammatic
reasoning that emerges in the application of securing CPS. Making the results probabilistically
concrete is a potential future topic that can be based on the above formal methods.

One such limitation can be inspected from the resulting algorithm (Listing 1). As output, we
may have that Yoneda reasoning returns no result (the list being ï¬ltered from K is empty, meaning
that the attacker does not have entries in the knowledge database that adequately model the target
system). However, we may also have that it returns more than one â€“ the list being ï¬ltered from
K having more than one element, meaning that the test performed was not ï¬ne-grained enough
to pinpoint the target system with deterministic accuracy. This discrepancy is mainly due to the
nature of the tests performed; some tests are more informative than others. Sending any system
in ğ¹ (UAV) to the one-element set deï¬nes a functor to Set and hence a valid test, which is though
maximally uninformative since the test outcome will be the same on all systems. Contrastly, any
injective-on-objects functor Î˜ allows us to conclude that Î˜ğ‘† = Î˜ğ‘† â€² implies ğ‘† = ğ‘† â€², and is maximally
granular. As we presented it, the formalism cannot express which subset of the tests allows us to
individuate the target system unambiguously.

Indeed, there are tests with diï¬€erent degrees of expressiveness, and the Yoneda lemma does not
account for this; we can conclude ğ‘† â‰ƒ ğ‘† â€² using Yoneda lemma if and only if ğ‘† and ğ‘† â€² agree on all
tests, including the maximally useless ones. These diï¬€erent results are why we speak of Yoneda
reasoning as a heuristic and not as a deterministic procedure.

Looking at things more abstractly, the reason for this shortcoming lies in the fact that in our def-
inition of the category, we considered homsets to be sets; that is, we speak of the set Hom C [ğ´, ğµ]
of all possible morphisms from ğ´ to ğµ in some category C. Sets have very little structure, and in
such an environment, we cannot formulate the Yoneda lemma to be more expressive.

In a probabilistic setting, what we would like to have is a version of Yoneda reasoning that gives
an interval of conï¬dence relating Î˜ğ‘† â‰ƒ Î˜ğ‘† â€² and ğ‘† â‰ƒ ğ‘† â€² for any possible test Î˜. In other words, we
want to attach to each Î˜ a measure of how informative Î˜ is in our context.

One possible solution is to resort to enriched category theory, which is a generalization of cate-
gory theory where homsets can have more structure. In particular, we can reformulate our theory
using categories enriched over metric spaces. Categories enriched over metric spaces give a nat-
ural way of talking about distances between sets, and this can be used to deï¬ne a measure on
the tests we can perform. In the context of enriched category theory, the Yoneda lemma can be
reformulated in what is informally known as ninja Yoneda lemma [49], which takes into account
this additional structure. We can use this to deï¬ne a version of Yoneda lemma that has a notion of
conï¬dence in the tests we perform over the CPS model and, therefore, have some granularity of
what it means for two systems to be behaviorally equivalent under some (informative) tests.

benefits While we show some limitations about the ï¬‚exibility of the model, it is essential to
point out that the same ï¬‚exibility can be beneï¬cial. Diï¬€erent formalisms can inhabit the boxes

18

Georgios Bakirtzis, Fabrizio Genovese, and Cody H. Fleming

deï¬ning a systemâ€™s behavior, from Petri nets to transition systems to ordinary diï¬€erential equa-
tions. Developing our formalisms will allow us to speak about all these representations within one
framework. For example, applications to security modeling using Petri nets [44] is currently con-
gruent with research in category theory and Petri nets [7, 30, 31, 62] and could be used to make
the application of the preceding formalism more concrete as a model of (mis-)behavior. Similarly,
both models of security violations in automata [67] and continuous controller behavior [53] can
be represented within our framework and, therefore, allow for a plethora of analyses within one
model.

However, to drill further in the possible directions of describing diï¬€erent types of continuous,
for example, false sensor data, or discrete, for example, transitioning the system to a hazardous
state, misbehaviors caused by exploitation require the ï¬rst formulation of security modeling cat-
egorically and algebraically. This paper serves this purpose. Relaxing some of the unrealistic as-
sumptions we made incorporates developing work from category theory.

Additionally, this security framework is part of an alternate paradigm of systems modeling that
has its foundations in categorical modeling. In this framework, it is possible to provide formal
traces of requirements, behaviors, and architectures [9] but also describe a vast amount of dynam-
ical systems with applications to robotics, event-based systems, and hybrid systems, to name a
few [22, 27, 46, 72].

Finally, this paper addresses the theoretical underpinnings of security modeling in category
theory. Nevertheless, the recent surge of categorical modeling languages and software, such as
Catlab [35] or idris-ct [29] or algebraic databases [59], can be used to create modeling tools and
security assessment methods based on the work presented in this paper practical within composi-
tional CPS theory.

6 RELATED WORK

In general, category theory is eï¬€ective in describing hybrid systems [4, 22, 66] and more recently
there has been successful work in modeling and analysis of CPS using category theory [12, 16,
17, 52]. An important motivation for developing a categorical modeling security framework is
the theory of co-design, a way of dealing with abstraction and reï¬nement in models, which has
recently been applied categorically to robotics [70, 71] and control system design [69].

To the best of our knowledge, there is little work at the intersection of category theory, CPS, and
security modeling. One such work uses the categorical interpretation of databases to share threat
information, but it does not propose how this paradigm improves upon graph methods for secu-
rity [5]. A line of work also uses category theory to study cryptographic functions, as illustrated,
for example, by Pavlovic [54]. The modeling approach presented in this paper does not develop se-
curity techniques for defenses but instead focuses on the dual of the research questions answered
by cryptography. While cryptography asks how we can communicate securely, systems modeling
and analysis ask how we can represent attacker actions over a behavioral and architectural model
in a traceable manner, such that we can examine what mitigation strategies to implement in the
design of the system. The same diï¬€erentiation applies to secure design using dependent types [36]
â€“ which are often formalized categorically â€“ and categorical data ï¬‚ow analysis [73].

On the side of attacker modeling for CPS, there is a vast area of research using graph formalisms.
Examples include attack graphs [60] and attack proï¬les using graph models as shown recently by
Weber et al. [68], including particular applications to industrial control systems [3]. Our wiring
diagram model can be thought of as a graph with extra structure, namely the added structure of
the category. Therefore such methods could also be incorporated into our algebraic security tests
paradigm.

Yoneda Hacking: The Algebra of Attacker Actions

19

From the controls or system behavior view, defenders can intercept the learning phase of at-
tacker actions by adding a privacy-enhancing signal into the controller [39]. From purely mod-
eling, which is more closely related to techniques from reliability and dependability, recent work
aims to merge attack trees with standard design practices for embedded systems [45]. These frame-
works are relevant to one abstraction level, that of system behavior, and could be subsumed by the
categorical formalism we present above. In the future, both the controls and modeling approaches
could be improved within our framework by providing formal composition and traceability be-
tween the expected behavior and the eventual synthesized design.

The intersection of formal methods, control, and CPS security is addressed through diï¬€erential
dynamic logic. Diï¬€erential dynamic logic has provided a plethora of veriï¬cation capabilities for
the continuous and discrete parts of CPS [57]. Diï¬€erential dynamic logic has also been applied
for security modeling [14]. We see diï¬€erential dynamic logic as complementary to our framework
and vice versa. Categorical primitives can become part of diï¬€erential dynamic logic, while dynamic
logic can provide richer semantics for how the behavior of the whole system changes based on
speciï¬c modeled attacks.

All in all, we perceive applications of category theory to model-based security as relatively
unï¬‚edged and hope to see category theory used as eï¬€ectively in security modeling as it has for
programming languages [29, 34, 56, 63] and cryptography [23, 32].

7 CONCLUSION

We develop a categorical semantics for CPS security modeling that can determine that two system
representations are behaviorally equivalent, provided that they agree on every test. This statement
implies that it is possible to model attacker actions without giving the attacker full observability
of the attack system. Additionally, we model two types of attacks on the incomplete but erroneous
view of the attacker and show its impact on (what we consider to be) the existing system. These
attacks can either (1) rewrite some system component or (2) rewire an input or output from or to
a component. This model is beneï¬cial for CPS. In the future, we would like to say how a particular
attack can change system behavior and, therefore, potentially transition it to a hazardous state.
Overall, we model how the attacker learns about a system and how an attacker then might attempt
to hijack the system from the knowledge that they were able to gather in a formal, uniï¬ed way.
Finally, the categorical formalism can be considered foundational. In addition to the contributions
above, it can subsume already developed formalisms for modeling attacker actions, such as attack
graphs, or augmenting the information contained in the model by using security frameworks.

ACKNOWLEDGMENTS
The authors thank D. Evans and C. Vasilakopoulou for constructive discussions and feedback.

REFERENCES
[1] L. Ablon, M. C. Libicki, and A. A. Golay. 2014. Markets for cybercrime tools and stolen data: Hackersâ€™ bazaar. Technical

Report RR-610-JNI. Rand Corporation. https://www.rand.org/pubs/research_reports/RR610.html

[2] S. Abramsky and B. Coecke. 2009. Categorical quantum mechanics. In Handbook of Quantum Logic and Quantum

Structures. Elsevier. https://doi.org/10.1016/B978-0-444-52869-8.50010-4

[3] A. T. Al Ghazo, M. Ibrahim, H. Ren, and R. Kumar. 2019. A2G2V: Automatic Attack Graph Generation and Visualization
and Its Applications to Computer and SCADA Networks. IEEE Transactions on Systems, Man, and Cybernetics: Systems
(2019). https://doi.org/10.1109/TSMC.2019.2915940

[4] A. D. Ames. 2006. A categorical theory of hybrid systems. Ph.D. Dissertation. University of California, Berkeley.
[5] Jean Andrian, Charles Kamhoua, Kevin Kiat, and Laurent Njilla. 2017. Cyber Threat Information sharing: A category-
theoretic approach. In Proceedings of the 2017 Third International Conference on Mobile and Secure Services (MobiSec-
Serv). IEEE, 1â€“5. https://doi.org/10.1109/MOBISECSERV.2017.7886562

20

Georgios Bakirtzis, Fabrizio Genovese, and Cody H. Fleming

[6] Algirdas Avizienis, Jean-Claude Laprie, Brian Randell, and Carl E. Landwehr. 2004. Basic Concepts and Tax-
IEEE Transactions on Dependable and Secure Computing (2004).

onomy of Dependable and Secure Computing.
https://doi.org/10.1109/TDSC.2004.2

[7] John C Baez and Jade Master. 2020. Open Petri nets. Mathematical Structures in Computer Science (2020).

https://doi.org/10.1017/S0960129520000043

[8] G Bakirtzis. 2021. Compositional Cyber-Physical Systems Theory. Ph.D. Dissertation. University of Virginia.
[9] G. Bakirtzis, C. H. Fleming, and C. Vasilakopoulou. 2021. Categorical Semantics of Cyber-Physical Systems Theory.

ACM Transactions on Cyber-Physical Systems (2021). https://doi.org/10.1145/3461669

[10] G. Bakirtzis, B. J. Simon, A. G. Collins, C. H. Fleming, and C. R. Elks. 2019. Data-Driven Vulnerability Exploration for

Design Phase System Analysis. IEEE Systems Journal (2019). https://doi.org/10.1109/JSYST.2019.2940145

[11] G. Bakirtzis, E. Subrahmanian, and C. Fleming. 2021. Compositional Thinking in Cyberphysical Systems Theory. IEEE

Computer (2021). https://doi.org/10.1109/MC.2021.3085532

[12] G. Bakirtzis, C. Vasilakopoulou, and C. H. Fleming. 2020. Compositional Cyber-Physical Systems Modeling. In Pro-
ceedings of the 2020 Applied Category Theory Conference (ACT 2020) (Electronic Proceedings in Theoretical Computer
Science). Open Publishing Association. https://doi.org/10.4204/EPTCS.333.9

[13] G. Bakirtzis, G. L. Ward, C. J. Deloglos, C. R. Elks, B. M. Horowitz, and C. H. Fleming. 2020. Fundamental Challenges of
Cyber-Physical Systems Security Modeling. In Proceedings of the 50th IFIP/IEEE International Conference on Dependable
Systems and Networks (DSN). IEEE. https://doi.org/10.1109/DSN-S50200.2020.00021

[14] B. Bohrer and A. Platzer. 2018.

In
the 33rd Annual ACM/IEEE Symposium on Logic in Computer Science (LICS 2018). ACM.

A Hybrid, Dynamic Logic for Hybrid-Dynamic Information Flow.

Proceedings of
https://doi.org/10.1145/3209108.3209151

[15] G. Boisseau and J. Gibbons. 2018. What you needa know about Yoneda: Profunctor optics and the Yoneda Lemma
(Functional Pearl). Proceedings of the ACM on Programming Languages (2018). https://doi.org/10.1145/3236779
[16] S. Breiner, O. Marie-Rose, B. S. Pollard, and E. Subrahmanian. 2020. Operadic diagnosis in hierarchical systems. In
Proceedings of the 2019 Applied Category Theory Conference (ACT 2019) (Electronic Proceedings in Theoretical Computer
Science). Open Publishing Association. https://doi.org/10.4204/EPTCS.323.5

[17] S. Breiner, R. D. Sriram, and E. Subrahmanian. 2019. Compositional Models for Complex Systems. In Artiï¬cial Intelli-

gence for the Internet of Everything. Elsevier. https://doi.org/10.1016/B978-0-12-817636-8.00013-2

[18] CAPEC 2022.

MITRE Common Attack Pattern Enumeration and Classiï¬cation (CAPEC).

URL

https://capec.mitre.org/.

[19] A. A. CÃ¡rdenas, S. Amin, and S. Sastry. 2008. Research Challenges for the Security of Control Systems. In Proceed-
ings of the 3rd USENIX Workshop on Hot Topics in Security (HotSec 2008), Niels Provos (Ed.). USENIX Association.
http://www.usenix.org/events/hotsec08/tech/full_papers/cardenas/cardenas.pdf

[20] B. Coecke. 2010. Quantum picturalism. Contemporary physics (2010). https://doi.org/10.1080/00107510903257624
[21] B. Coecke and Ã‰.O. Paquette. 2011. Categories for the Practising Physicist. In New Structures for Physics. Springer.

https://doi.org/10.1007/978-3-642-12821-9_3

[22] J. Culbertson, P. Gustafson, D. E. Koditschek, and P. F. Stiller. 2020.

Formal composition of hybrid systems.

arXiv:1911.01267 [math.CT].

[23] A. Datta, A. Derek, J. C. Mitchell, and D. Pavlovic. 2005. A derivation system and compositional logic for security

protocols. Journal of Computer Security (2005). https://doi.org/10.3233/JCS-2005-13304

[24] A. Datta, J. Franklin, D. Garg, L. Jia, and D. K. Kaynar. 2011. On Adversary Models and Compositional Security. IEEE

Security & Privacy (2011). https://doi.org/10.1109/MSP.2010.203

[25] Z. Diskin, T. Maibaum, and K. Czarnecki. 2015. A Model Management Imperative: Being Graphical Is Not Suï¬ƒcient,
You Have to Be Categorical. In Proceedings of the 11th European Conference on Modelling Foundations and Applications
(ECMFA). https://doi.org/10.1007/978-3-319-21151-0_11

[26] D.

Evans.

2008.

NSF/IARPA/NSA Workshop

on

the

Science

of

Security.

https://web.archive.org/web/20200705152357/https://sos.cs.virginia.edu/.

[27] B. Fong, A. Speranzon, and D. I. Spivak. 2019. Temporal Landscapes: A Graphical Temporal Logic for Reasoning.

arXiv:1904.01081 [math.LO].

[28] B. Fong and D. I. Spivak. 2019. An Invitation to Applied Category Theory: Seven Sketches in Compositionality. Cambridge

University Press.

[29] F. Genovese, A. Gryzlov, J. Herold, A. Knispel, M. Perone, R. Post, and A. Videla. 2020. idris-ct: A Library to do Category
Theory in Idris. In Proceedings of the 2019 Applied Category Theory Conference (ACT 2019) (Electronic Proceedings in
Theoretical Computer Science). Open Publishing Association. https://doi.org/10.4204/EPTCS.323.16

[30] F. Genovese, A. Gryzlov, J. Herold, M. Perone, E. Post, and A. Videla. 2019. Computational Petri Nets: Adjunctions

Considered Harmful. arXiv 1904.12974.

Yoneda Hacking: The Algebra of Attacker Actions

21

[31] F. Genovese and J. Herold. 2019. Executions in (Semi-)Integer Petri Nets Are Compact Closed Categories. Electronic

Proceedings in Theoretical Computer Science (2019). https://doi.org/10.4204/EPTCS.287.7

[32] F. Genovese, A. Knispel, and J. Fitzgerald. 2019. Mapping Finite State Machines to ZK-SNARKs Using Category Theory.

arXiv 1909.02893.

[33] J. Giraldo, E. Sarkar, A. A. CÃ¡rdenas, M. Maniatakos, and M. Kantarcioglu. 2017. Security and Privacy in Cyber-Physical

Systems: A Survey of Surveys. IEEE Design & Test (2017). https://doi.org/10.1109/MDAT.2017.2709310

[34] D. Gratzer, G. A. Kavvos, A. Nuyts, and L. Birkedal. 2020. Multimodal Dependent Type Theory. In Proceedings of 35th
Annual ACM/IEEE Symposium on Logic in Computer Science (LICS â€™20). ACM. https://doi.org/10.1145/3373718.3394736
[35] M. Halter, E. Patterson, A. Baas, and J. Fairbanks. 2020. Compositional Scientiï¬c Computing with Catlab and Semantic

Models. arXiv:2005.04831 [math.CT].

[36] M. Hennessy. 2005. The security pi-calculus and non-interference. The Journal of Logic and Algebraic Programming

(2005). https://doi.org/10.1016/j.jlap.2004.01.003

[37] C. Herley and P. C. van Oorschot. 2017.

SoK: Science, Security and the Elusive Goal of Security as a Scien-
tiï¬c Pursuit. In Proceedings of the 2017 IEEE Symposium on Security and Privacy (S&P). IEEE Computer Society.
https://doi.org/10.1109/SP.2017.38

[38] A.

Joyal

and R. Street.
https://doi.org/10.1006/aima.1993.1055

1993.

Braided tensor

categories.

Advances

in Mathematics

(1993).

[39] M. J. Khojasteh, A. Khina, M. Franceschetti, and T. Javidi. 2020. Learning-based attacks in cyber-physical systems.

IEEE Transactions on Control of Network Systems (2020). https://doi.org/10.1109/TCNS.2020.3028035

[40] John Lambert. 2015. Defenders think in lists. Attackers think in graphs. As long as this is true, attackers win.

https://perma.cc/6NZ2-A2HY.

[41] C. E. Landwehr. 2012. Cybersecurity: From engineering to science. Next Wave (2012).
[42] E. A. Lee. 2006. Cyber-physical systems â€“ Are computing foundations adequate. Position paper for NSF workshop

on cyber-physical systems: Research motivation, techniques and roadmap.

[43] Tom Leinster. 2014. Basic Category Theory. Cambridge University Press. https://doi.org/10.1017/CBO9781107360068
[44] V. Lesi, Z. Jakovljevic, and M. Pajic. 2020. Security Analysis for Distributed IoT-Based Industrial Automation. (2020).

arXiv:2006.00044.

[45] L. W. Li, F. Lugou, and L. Apvrille. 2018. Evolving Attacker Perspectives for Secure Embedded System Design. In
Proceedings of the 6th International Conference on Model-Driven Engineering and Software Development (MODELSWARD
2018). SciTePress. https://doi.org/10.5220/0006535802870294

[46] S. Libkind. 2020. An Algebra of Resource Sharing Machines. arXiv:2007.14442 [math.CT].
[47] M. Lipp, M. Schwarz, D. Gruss, T. Prescher, W. Haas, J. Horn, S. Mangard, P. Kocher, D. Genkin, Y. Yarom, M.
Hamburg, and R. Strackx. 2020. Meltdown: reading kernel memory from user space. Commun. ACM (2020).
https://doi.org/10.1145/3357033

[48] D. Long. 2020. MBSE: Simple, Complicated, or Complex? https://web.archive.org/web/20200409185640/http://community.vitechcorp.com/index.php/mbse-simple-complicated-or-complex.aspx.

[49] F. Loregian. 2019. Coend Calculus. arXiv 1501.02503.
[50] D. Maynor. 2007. OS X Kernel-Mode Exploitation in a Weekend. Technical Report. Errata Security.
[51] D. M. Nicol, W. H. Sanders, and K. S. Trivedi. 2004. Model-based evaluation: from dependability to security.

IEEE

Transactions on Dependable and Secure Computing (2004). https://doi.org/10.1109/TDSC.2004.11

[52] J. S. Nolan, B. S. Pollard, S. Breiner, D. Anand, and E. Subrahmanian. 2020. Compositional Models for Power Systems. In
Proceedings of the 2019 Applied Category Theory Conference (ACT 2019) (Electronic Proceedings in Theoretical Computer
Science). Open Publishing Association. https://doi.org/10.4204/EPTCS.323.10

[53] M. Pajic, J. Weimer, N. Bezzo, P. Tabuada, O. Sokolsky, and G. J. Pappas. 2014. Robustness of attack-resilient
state estimators. In ACM/IEEE International Conference on Cyber-Physical Systems (ICCPS). IEEE Computer Society.
https://doi.org/10.1109/ICCPS.2014.6843720

[54] D. Pavlovic. 2014. Chasing Diagrams in Cryptography. Springer. https://doi.org/10.1007/978-3-642-54789-8_19
[55] D. Pavlovic. 2015. Towards a science of trust. In Proceedings of the 2015 Symposium and Bootcamp on the Science of

Security (HotSoS 2015). ACM. https://doi.org/10.1145/2746194.2746197
[56] B. C. Pierce. 1991. Basic category theory for computer scientists. MIT press.
[57] A. Platzer. 2020.

foundations of cyber-physical systems.

Logical

Formal Aspects of Computing (2020).

https://doi.org/10.1007/s00165-020-00510-7

[58] P. Schultz, D. I. Spivak, and C. Vasilakopoulou. 2019. Dynamical systems and sheaves. Applied Categorical Structures

(2019). https://doi.org/DOI:10.1007/s10485-019-09565

[59] P. Schultz, D. I. Spivak, C. Vasilakopoulou, and R. Wisnesky. 2016. Algebraic Databases. Theory & Applications of

Categories (2016).

22

Georgios Bakirtzis, Fabrizio Genovese, and Cody H. Fleming

[60] O. Sheyner, J. Haines, S. Jha, R. Lippmann, and J. M. Wing. 2002. Automated generation and analysis of attack graphs.
In Proceedings 2002 IEEE Symposium on Security and Privacy. IEEE. https://doi.org/10.1109/SECPRI.2002.1004377
[61] D. I. Spivak and J. Tan. 2017. Nesting of dynamical systems and mode-dependent networks. Journal of Complex

Networks (2017). https://doi.org/10.1093/comnet/cnw022

[62] Statebox Team. 2019. The Mathematical Speciï¬cation of the Statebox Language. arXiv 1906.07629.
[63] M. Stay and J. Vicary. 2013. Bicategorical Semantics for Nondeterministic Computation. In Proceedings of the 29th
Conference on the Mathematical Foundations of Programming Semantics (MFPS 2013) (Electronic Notes in Theoretical
Computer Science). Elsevier. https://doi.org/10.1016/j.entcs.2013.09.022

[64] A. Strafaci. 2008. What does BIM mean for civil engineers. CE News, Transportation (2008).
[65] B. E. Strom, A. Applebaum, D. P. Miller, K. C. Nickels, A. G. Pennington, and C. B. Thomas. 2018. MITRE ATT&CK:

Design and philosophy. Technical Report MP180360. MITRE.

[66] P. Tabuada, G. J. Pappas, and P. U. Lima. 2002. Composing Abstractions of Hybrid Systems. In Proceedings of the 5th
International Workshop on Hybrid Systems: Computation and Control (HSCC 2002) (Lecture Notes in Computer Science).
Springer. https://doi.org/10.1007/3-540-45873-5_34

[67] Y. Wang and M. Pajic. 2019.

Supervisory control of discrete event

systems

IEEE 58th Conference on Decision and Control

in the presence of
IEEE.
(CDC).

sensor and actuator
https://doi.org/10.1109/CDC40024.2019.9029767

In 2019

attacks.

[68] M. Weber, B. Jin, G. Lederman, Y. Shoukry, E. A. Lee, S. Seshia, and A. Sangiovanni-Vincentelli. 2020. Gordian: For-
mal Reasoning-based Outlier Detection for Secure Localization. ACM Transactions on Cyber-Physical Systems (2020).
https://doi.org/10.1145/3386568

[69] G. Zardini, A. Censi, and E. Frazzoli. 2021.

lection to Control Synthesis.
https://doi.org/10.23919/ECC54610.2021.9654960

In Proceedings of

Co-Design of Autonomous Systems: From Hardware Se-
IEEE.
the 2021 European Control Conference (ECC 2021).

[70] G. Zardini, N. Lanzetti, M. Salazar, A. Censi, E. Frazzoli, and M. Pavone. 2020. On the Co-Design of AV-Enabled
Mobility Systems. In Proceedings of the 23rd IEEE International Conference on Intelligent Transportation Systems (ITSC
2020). IEEE. https://doi.org/10.1109/ITSC45102.2020.9294499

[71] G. Zardini, D. Milojevic, A. Censi, and E. Frazzoli. 2020. A Formal Approach to the Co-Design of Embodied Intelligence.

arXiv:2011.10756 [cs.RO].

[72] G. Zardini, D. I. Spivak, A. Censi, and E. Frazzoli. 2020. A Compositional Sheaf-Theoretic Framework for Event-
Based Systems. In Proceedings of the 2020 Applied Category Theory Conference (ACT 2020) (Electronic Proceedings in
Theoretical Computer Science). Open Publishing Association. https://doi.org/10.4204/EPTCS.333.10

[73] M. Zhu, P. Grogono, O. Ormandjieva, and P. Kamthan. 2014. Using Category Theory and Data Flow Analysis for
Modeling and Verifying Properties of Communications in the Process-Oriented Language Erasmus. In International C*
Conference on Computer Science & Software Engineering (C3S2E 2014). ACM. https://doi.org/10.1145/2641483.2641529

A CATEGORICAL PRELIMINARIES
A.1 Categories

Category theory is a framework to study patterns in mathematics. The fundamental deï¬nition is
the one of a category.

Deï¬nition 6. A category C is composed of:
â€¢ A collection of objects, denoted obj C;
â€¢ For each pair of objects ğ´, ğµ, a collection of morphisms from ğ´ to ğµ, denoted Hom C [ğ´, ğµ].

A morphism ğ‘“ in Hom C [ğ´, ğµ] is usually denoted as ğ´

ğ‘“
âˆ’â†’ ğµ;

â€¢ For each object ğ´, a morphism ğ´
â€¢ For each ğ´, ğµ, ğ¶ objects, an operation

idğ´âˆ’âˆ’â†’ ğ´;

â—¦ğ´,ğµ,ğ¶ : Hom C [ğµ, ğ¶] Ã— Hom C [ğ´, ğµ] â†’ Hom C [ğ´, ğ¶]

called composition. We usually omit the subscripts and just write ğ‘” â—¦ ğ‘“ to denote composition.

Composition is also denoted diagrammatically, as in ğ´

â€¢ Finally, we require the following equations to hold for each ğ´

ğ‘”
âˆ’â†’ ğ¶ and ğ¶

â„
âˆ’â†’ ğ·:

ğ‘“
âˆ’â†’ ğµ

ğ‘”
âˆ’â†’ ğ¶.
ğ‘“
âˆ’â†’ ğµ, ğµ
(â„ â—¦ ğ‘”) â—¦ ğ‘“ = â„ â—¦ (ğ‘” â—¦ ğ‘“ )

idğµ â—¦ğ‘“ = ğ‘“

ğ‘“ â—¦ idğ´ = ğ‘“

Yoneda Hacking: The Algebra of Attacker Actions

23

The interpretation we give to categories is the following: Objects can represent systems, states
of a given system, or, in general, entities we care about. Morphisms represent transformations
between these entities. The axioms amount to asking the following.

â€¢ For each system ğ´ there is a â€œdo nothingâ€ transformation, called idğ´.
â€¢ We can compose transformations whenever their domain and codomain match. This cap-
tures the idea of applying transformations sequentially, each transformation acting on the
result of the previous one. We require this composition to be associative.

Example 3. The simplest example of category in this context is Set, the category whose objects
are sets and morphisms are functions between them. For each set ğ´, idğ´ is the identity function
from ğ´ to itself; composition is function composition.

Example 4. Plenty of familiar structures in mathematics can be seen as categories. For instance,
a monoid can be seen as a category with only one object, call it âˆ—. Any element of the monoid is
interpreted as a morphism âˆ— â†’ âˆ—. The identity on âˆ— is the monoid unit, and composition is the
monoid operation. Indeed, categories can be thought of as generalized monoids with many objects.
Other familiar categories include groups and their homomorphisms, vector spaces and linear
maps between them, topological spaces and continuous functions, and the category of states and
transitions between them [25].

In general, the idea is that morphisms are transformations that preserve some properties possessed
by the objects, properties that we care about. So, for instance, if we were to deï¬ne a category of
topological spaces, we may require morphisms to be continuous functions or homotopies. If we de-
ï¬ne a category whose objects are algebras, we may require the morphisms to be homomorphisms
that preserve the relevant algebraic properties we want to study.

What happens when two objects behave exactly in the same way with respect to the properties

we are interested in? This notion can be categoriï¬ed as:

Deï¬nition 7. Given a category C, a morphism ğ´

ğ‘“
âˆ’â†’ ğµ is called an isomorphism if there is a

ğ‘“ âˆ’1
âˆ’âˆ’â†’ ğ´ such that the following square commutes, meaning that any two paths sharing

morphism ğµ
the same start and end points deï¬ne the same morphism:

ğ‘“

ğ´

ğµ

idğ´

ğ‘“ âˆ’1

idğµ

ğ´

ğ‘“

ğµ

If there is an isomorphism ğ´

ğ‘“
âˆ’â†’ ğµ, then we say that ğ´ and ğµ are isomorphic, and write ğ´ â‰ƒ ğµ.

Remark. Importantly, two isomorphic objects in a category behave exactly in the same way only
with respect to the structure captured by the category. For instance, R and R2 can be seen both as
objects in Set, the category of sets and functions, and as objects in VectR, the category of real vector
spaces and linear maps between them. They are isomorphic in Set, since bijective functions satisfy
Deï¬nition 7 and R and R2 are in bijection. Nevertheless, they are not isomorphic in VectR, since

24

Georgios Bakirtzis, Fabrizio Genovese, and Cody H. Fleming

an isomorphism in this category has to be a linear bijection, which in particular has to preserve
dimension. What is happening here is that since VectR keeps track of more structure than what
Set does, our ability to tell objects apart in VectR is ï¬ner than in Set.

A.2 Functors
Functors are morphisms between categories. As we said in the previous section, they should then
preserve the properties we care about when we study categories. Looking at Deï¬nition 6, these
are just identities and composition. Hence, we give the following deï¬nition.

Deï¬nition 8. Given categories C, D, a functor C
ğ¹
âˆ’â†’ obj D;

â€¢ A mapping obj C
â€¢ For each ğ´, ğµ âˆˆ obj C, a mapping

ğ¹
âˆ’â†’ D consists of the following information:

Hom C [ğ´, ğµ]

ğ¹
âˆ’â†’ Hom D [ğ¹ğ´, ğ¹ ğµ]

â€¢ We moreover require the following equations to hold:

ğ¹ (idğ´) = idğ¹ ğ´

ğ¹ (ğ‘” â—¦ ğ‘“ ) = ğ¹ (ğ‘”) â—¦ ğ¹ (ğ‘“ )

Functors are structure preserving maps that allow us to connect diï¬€erent model types by deï¬n-
ing the particular semantics of transformations that are necessary to change the domain of dis-
course (within a particular category, say Set â†’ Set, or between diï¬€erent categories, say C â†’ Set).

Remark. In category theory practice it is customary to omit parentheses when not strictly neces-
sary. As such, we will often write ğ¹ ğ‘“ instead of ğ¹ (ğ‘“ ) to denote the application of a functor ğ¹ to a
morphism ğ‘“ .

Example 5. There is a functor from VectR to Set that â€œforgets structureâ€: Any real vector space
is mapped to its underlying set, and any linear map between them is mapped to its underlying
function between sets.

Example 6. As we will see shortly, a very important functor in category theory is the hom-functor:
Fix an object ğ´ in a category C. Then we can deï¬ne a functor

Hom C [ğ´,âˆ’]
âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ Set

C

Which sends every object ğµ of C to the set of morphisms Hom C [ğ´, ğµ]. A morphism ğµ
to the function

Hom C [ğ´, ğµ]

Hom C [ğ´,ğ‘”]
âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ Hom C [ğ´, ğ¶]

ğ‘”
âˆ’â†’ ğ¶ is sent

Which acts by postcomposing: a morphism ğ´
from the composition and identity axioms of C.

ğ‘“
âˆ’â†’ ğµ is sent to ğ´

ğ‘“
âˆ’â†’ ğµ

ğ‘”
âˆ’â†’ ğ¶. Functoriality follows

Functors are also useful to supply a category with an additional operation alongside â—¦, which
intuitively models the idea of of considering multiple objects at the same time and performing
transformations in parallel.

Deï¬nition 9. A monoidal category V is a category that comes equipped with a monoidal product
functor

V Ã— V

âŠ—
âˆ’â†’ V

which can be thought of as multiplication of objects and morphisms, or more broadly as doing
operations in parallel. We require that, for any objects ğ‘‹, ğ‘Œ , ğ‘ ,

(ğ‘‹ âŠ— ğ‘Œ ) âŠ— ğ‘ â‰ƒ ğ‘‹ âŠ— (ğ‘Œ âŠ— ğ‘ )

Yoneda Hacking: The Algebra of Attacker Actions

25

Meaning that multiplying objects in any order gives isomorphic results.

We also require the existence of a distinguished object ğ¼ of V, called monoidal unit, such that

ğ¼ âŠ— ğ‘‹ â‰ƒ ğ‘‹ â‰ƒ ğ‘‹ âŠ— ğ¼

that is, ğ¼ acts like an identity for this multiplication. All this data must satisfy certain axioms [38],
that are beyond the scope of this paper.

Example 7. Widely used examples of monoidal categories include (Set, Ã—, {â˜…}), with the cartesian
product of sets and the singleton, as well as (VectR, âŠ—, R), with the tensor product of vector spaces.
Moreover Cat, the category of categories and functors between them, admits a monoidal structure
(Cat, Ã—, 1), where tensor is deï¬ned as the cartesian product of categories (similarly to that of sets),
and the tensor unit is the category 1 consisting of a single object together with its identity arrow.
In fact, all these are examples of symmetric monoidal categories, which come further equipped

with isomorphisms

ğ‘‹ âŠ— ğ‘Œ â‰ƒ ğ‘Œ âŠ— ğ‘‹ .

For example, for two sets it is ğ‘‹ Ã— ğ‘Œ â‰ƒ ğ‘Œ Ã— ğ‘‹ via the mapping (ğ‘¥, ğ‘¦) â†¦â†’ (ğ‘¦, ğ‘¥).

Now that we deï¬ned monoidal categories, that are nothing but categories together with some

additional structure, we have to reï¬ne our notion of functor accordingly.

Deï¬nition 10. A monoidal functor between two monoidal categories (V, âŠ—V, ğ¼ V)
is a functor that preserves the monoidal structure in a lax sense (meaning not up to isomorphism).
Namely, it comes equipped with morphisms

ğ¹
âˆ’â†’ (W, âŠ—W, ğ¼W)

ğ¹ (ğ¼ V)

ğœ™0âˆ’âˆ’â†’ ğ¼W

ğ¹ğ‘‹ âŠ—W ğ¹ğ‘Œ

ğœ™ğ‘‹ ,ğ‘Œ
âˆ’âˆ’âˆ’â†’ ğ¹ (ğ‘‹ âŠ—V ğ‘Œ )

with ğ‘‹, ğ‘Œ ranging over the objects of V, that express the relation between the image of the tensor
and the tensor of the images inside the target category W; these adhere to certain axioms [38].

A.3 Natural Transformations

In this work we will also use the fundamental concept of the natural transformation. A natural
transformation models the transformation between functors while preserving structure, otherwise
called morphism of functors.

Deï¬nition 11. Given functors C

ğ¹ ,ğº
âˆ’âˆ’âˆ’â†’ D, a natural transformation ğ¹

ğœ‚=â‡’ ğº consists, for each

object ğ´ of C, of a morphism ğ¹ğ´

ğœ‚ğ´
âˆ’âˆ’â†’ ğºğ´ in D such that, for each morphism ğ´

ğ‘“
âˆ’â†’ ğµ in C,

ğœ‚ğµ â—¦ ğ¹ ğ‘“ = ğº ğ‘“ â—¦ ğœ‚ğ´.

This is often expressed diagrammatically by saying that the following square has to commute:

ğœ‚ğ´

ğ¹ğ´

ğºğ´

ğ¹ ğ‘“

ğº ğ‘“

ğ¹ ğµ

ğœ‚ğµ

ğºğµ

26

Georgios Bakirtzis, Fabrizio Genovese, and Cody H. Fleming

Intuitively, the information contained in a natural transformation ğ¹

ğœ‚=â‡’ ğº is enough to guarantee
that any commutative diagram made of images of things in C via ğ¹ can be turned into a diagram
of images of things in C via ğº without breaking commutativity. An example is shown in the ï¬gure
below: The commutativity condition of ğœ‚ means that it doesnâ€™t matter in which order we will â€œwalk
throughâ€ these arrows, the result will be the same.

ğ¹ğ´

ğœ‚ğ´

ğ¹ ğ‘“

ğ¹â„

ğ¹ ğµ

ğœ‚ğµ

ğ¹ğ‘”

ğ¹ğ¶

ğœ‚ğ¶

ğºğ´

ğº ğ‘“

ğºâ„

ğºğµ

ğºğ‘”

ğºğ¶

A.4 The Yoneda Lemma

The Yoneda Lemma is arguably the most important result in category theory. It follows from a

clever observation: consider a functor C
transformation Hom C [ğ´, âˆ’]

ğœ‚=â‡’ ğ¹ has as components functions between sets Hom C [ğ´, ğµ]

ğ¹
âˆ’â†’ Set and an object ğ´ of C. By deï¬nition, any natural
ğœ‚ğµ
âˆ’âˆ’â†’ ğ¹ ğµ.

Moreover, for each ğ´
mation:

ğ‘“
âˆ’â†’ ğµ, the following diagram must commute because ğœ‚ is a natural transfor-

Hom C [ğ´, ğ´]

ğœ‚ğ´

Hom C [ğ´, ğ‘“ ]

ğ¹ğ´

ğ¹ ğ‘“

Hom C [ğ´, ğµ]

ğœ‚ğµ

ğ¹ ğµ

idğ´âˆ’âˆ’â†’ ğ´. This is an element of Hom C [ğ´, ğ´], and Hom C [ğ´, ğ‘“ ] sends it
In particular, consider ğ´
to ğ‘“ (which is by deï¬nition an element of Hom C [ğ´, ğµ]) since it acts by post-composition and
ğ‘“ â—¦ idğ´ = ğ‘“ . Hence, if ğœ‚ğ´ sends idğ´ to, say, ğ‘¥ âˆˆ ğ¹ğ´, then ğœ‚ğµ will have to send ğ‘“ to ğ¹ ğ‘“ (ğ‘¥), otherwise
the square will not commute. This reasoning can be repeated for any ğµ and any ğ‘“ , it follows that
the assignment ğœ‚ğ´ (idğ´) = ğ‘¥ completely determines ğœ‚. So we can have as many diï¬€erent ğœ‚s as there
are choices to which we can send idğ´. These are as many as the elements in ğ¹ğ´, and so we have:

Lemma 12 (Yoneda Lemma). There is a bijection1

Nat [Hom C [ğ´, âˆ’] , ğ¹ ] â‰ƒ ğ¹ğ´

Where Nat [ğ¹, ğº] denotes the set of natural transformations between any two functors ğ¹, ğº.

1For readers versed in category theory: Hom C [âˆ’, âˆ’] is a contravariant functor in the ï¬rst component and a covariant
functor in the second. It can be proven that the bijection is natural in ğ¹ and ğ´.

Yoneda Hacking: The Algebra of Attacker Actions

27

The consequences of Yoneda lemma are far reaching. In particular, the following corollary can

be proven:

Corollary 13. Given objects ğ´, ğµ of C, if it is2

Nat [Hom C [ğ´, âˆ’] , ğ¹ ] â‰ƒ Nat [Hom C [ğµ, âˆ’] , ğ¹ ]

for any functor C

ğ¹
âˆ’â†’ Set, then ğ´ â‰ƒ ğµ in C.

As we already stressed, isomorphic objects in a category behave as if they were the same. Repet-

itively applying Yoneda lemma one gets that

ğ¹ğ´ â‰ƒ Nat [Hom C [ğ´, âˆ’] , ğ¹ ] â‰ƒ Nat [Hom C [ğµ, âˆ’] , ğ¹ ] â‰ƒ ğ¹ ğµ

ğ¹
And hence ğ´ â‰ƒ ğµ if and only if ğ¹ğ´ â‰ƒ ğ¹ ğµ for any C
âˆ’â†’ Set. So, with respect to whatever it is that
we want to capture by deï¬ning a category C, the Yoneda lemma aï¬ƒrms that we can completely
characterize an object ğ´ by studying its images ğ¹ğ´ for any functor ğ¹ to Set.

We heavily rely on this to model attacker learning and interpreting functors to Set as testing

procedures (Section 4). Under this view, we summarize Yoneda lemma as:

If two objects agree under any possible test we can perform,
then they behave the same.

2For readers versed in category theory: This bijection is required to be natural in ğ¹ .

