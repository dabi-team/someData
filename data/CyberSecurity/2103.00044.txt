2
2
0
2

r
p
A
3
1

]

R
C
.
s
c
[

3
v
4
4
0
0
0
.
3
0
1
2
:
v
i
X
r
a

Yoneda Hacking: The Algebra of Attacker Actions

GEORGIOS BAKIRTZIS, The University of Texas at Austin, USA
FABRIZIO GENOVESE, University of Pisa, Italy
CODY H. FLEMING, Iowa State University, USA

Our work focuses on modeling the security of systems from their component-level designs. Towards this
goal, we develop a categorical formalism to model attacker actions. Equipping the categorical formalism with
algebras produces two interesting results for security modeling. First, using the Yoneda lemma, we can model
attacker reconnaissance missions. In this context, the Yoneda lemma shows us that if two system represen-
tations, one being complete and the other being the attacker’s incomplete view, agree at every possible test,
they behave the same. The implication is that attackers can still successfully exploit the system even with in-
complete information. Second, we model the potential changes to the system via an exploit. An exploit either
manipulates the interactions between system components, such as providing the wrong values to a sensor, or
changes the components themselves, such as controlling a global positioning system (GPS). One additional
beneﬁt of using category theory is that mathematical operations can be represented as formal diagrams, help-
ful in applying this analysis in a model-based design setting. We illustrate this modeling framework using an
unmanned aerial vehicle (UAV) cyber-physical system model. We demonstrate and model two types of attacks
(1) a rewiring attack, which violates data integrity, and (2) a rewriting attack, which violates availability.

CCS Concepts: • Security and privacy → Formal security models; • Computer systems organization
→ Embedded and cyber-physical systems; • Theory of computation → Semantics and reasoning; •
Computing methodologies → Modeling and simulation.

1 INTRODUCTION

In the past decade, there has been signiﬁcant eﬀort in adding formal underpinnings to security
modeling [41, 55]. This research trajectory is evidenced by the NSF/IARPA/NSA workshop on the
science of security, which underlines that there are three areas in need of innovation: metrics, for-
mal methods, and experimentation [26]. In addition, there is still an increasing need for deﬁning
(in)security as a modeling problem [6, 13, 51]. This paper develops a formal method for model-
ing attacker actions at the abstraction level of component-level system models. Speciﬁcally, the
categorical result of the Yoneda lemma intuitively states that if two system representations agree
under any possible test, they behave equivalently. We use this notion to formally show that given
two diﬀerent architectural representations of a system that agree on every test, an attacker can
still eﬀectively exploit a system, even with an inaccurate knowledge base of the architecture.

Security engineering has moved from the paradigm of securing a list of assets to modeling in
graphs of networked components, which is more congruent with attacker behavior [40]. These
graphs help analyze the system’s security posture [10]; however, we can improve them further
using the added structure that comes with categorical models of component-level system models,
which are by deﬁnition compositional; a valuable property for security modeling [24]. The basis
of the compositional framework lies in functorial semantics, relationships that add meaning to
arbitrary syntax based on an already known structure. In the context of security modeling, these
functorial semantics that comes with the category-theoretic modeling framework also explicitly
relate several essential views for modeling and analyzing cyber-physical systems (CPS), where
continuous and discrete behaviors interrelate to produce a total behavior.

The categorical structure comes in the form of decomposition rules between system behavior
and system architecture, which improves upon current practice where system behavior is disjoint
from system architecture. Additionally, this approach provides for early security modeling, where

Authors’ addresses: Georgios Bakirtzis, bakirtzis@utexas.edu, The University of Texas at Austin, USA; Fabrizio Genovese,
fabrizio@statebox.io, University of Pisa, Italy; Cody H. Fleming, ﬂemingc@iastate.edu, Iowa State University, USA.

 
 
 
 
 
 
2

Georgios Bakirtzis, Fabrizio Genovese, and Cody H. Fleming

engineering decisions are most eﬀective [12, 64], by operating on models instead of implementa-
tions. Early security modeling is possible because categorical semantics reside in a higher level of
abstraction than, for example, attack graphs [60], which work best after source code is available.
Implementing this category-theoretic modeling method allows us to use the Yoneda lemma to
show the impact of exploitable vulnerabilities from an attacker’s perspective over a system model,
which can be incomplete or even partially erroneous compared to the system under attack.

An essential step to building a compositional security modeling framework is reformulating the
problem in terms of algebras, where the properties of sets and operations between them are de-
ﬁned precisely. We develop algebras describing behaviors (block diagrams), architectures (graphs),
and security operations. We formalize diagrammatic reasoning and unify these diﬀering views of
the system (behavior and architecture, and attacker actions). This categorical formalization of di-
agrammatic reasoning has found success in, for example, manipulating quantum processes [2, 20]
and databases [59]. We posit a similar innovation would be useful in deﬁning a high-level interpre-
tation of attacker actions diagrammatically. This categorical interpretation formalizes two attacker
actions; learning and hijacking. While this framework does not examine particular attacks by it-
self, attack pattern databases (for example, MITRE CAPEC [18]) and attacker modeling frameworks
(for example, MITRE ATT&CK [65]) can be used to augment the model with concrete examples of
attacker actions.

This paper develops the foundations of security within a compositional CPS theory modeling
framework [9], a ﬂavor of what Lee calls dynamical computational systems theory [42]. For-
mal composition rules could overcome some of the new challenges CPS introduces to cyberse-
curity [19, 33], including the intertwined nature of safety and security in this setting. Speciﬁcally,
our contributions are in the domain of formal methods for security to assist the model-based de-
sign of CPS using category theory. These contributions are still bound by well-known problems
of the foundations and general science of security, such as the lack of a well-deﬁned common lan-
guage [37].

• Describing how fundamental concepts in category theory, such as functors to the category
of sets, can be interpreted as testing procedures and results like the Yoneda lemma can be
used to infer similarities between systems given the similarities between their test outcomes.
• Directly using these insights to model the most common phases of an attack that consist
of learning ﬁrst and on the attack itself afterward, thereby formally modeling from the at-
tacker’s perspective.

• Extending the approach to CPS by wiring diagrams and their algebras [12], termed systems-
as-algebras, to provide compelling examples of how our mathematical formalization works
in practice, which gives rise to formal categorical methods for CPS security.

A concrete future result of this line of theoretical work would be the integration of security prim-
itives within systems modeling languages, which will be essential for assuring that CPS models
conform to security requirements. We show in a guided process how to achieve this by modeling
a rewiring attack and a component attack on an unmanned aerial vehicle (UAV) and how both
attacks can be represented diagrammatically as formal methods.

2 PROBLEM FORMULATION
Having ﬁxed some system, by an attack, we mean any procedure intended to change system be-
havior maliciously. This deﬁnition is expansive and ranges from privilege escalation in a computer
system to sabotaging a car. We consider an attacker any actor who performs any such process to
degrade a system’s behavior. Traditionally, attacking a system is viewed as an art, and as such, it

Yoneda Hacking: The Algebra of Attacker Actions

3

requires a certain degree of heuristics. Our goal is to formalize these heuristics mathematically,
using the attacker’s point of view.

It makes sense to divide attacker capabilities into two distinct phases: learning and hijacking.
Learning is where the attacker gathers information about the target system in the hope of ﬁnding
a weakness. Hijacking is where the attacker exploits a given weakness to change the behavior of
some component, which reverberates on the system as a whole. The particulars of how learning
and hijacking phases are exercised and how they provide feedback to each other depend on the
capabilities and goal of the attacker. In defender terms, this would be the threat model.

To model the learning phase, we need a mathematical description of what probing a system
for information means. To model the hijacking phase, we need to mathematically express that the
attacker can act on a system to change it.

Crucially, there is an intermediate step between the two phases of how any given weakness
is turned into an exploiting procedure to change the behavior of some subsystem. The generality
of categorical structures models the steps an attacker takes to ﬁnd system weaknesses and how
the exploiting procedures reverberate in the system as a whole. The reason why this abstraction
level of modeling security is acceptable is threefold. First, turning a weakness into a viable exploit
depends heavily on implementation details, for example, the Spectre and Meltdown exploits [47].
Second, the largest class of attacker actions involves already developed exploits, either internally
or through a marketplace, deployed in some sequence to degrade the system’s behavior, without
necessarily the attacker knowing how they work [1]. Third, suppose a known attack violates a
system component. In that case, this intermediate step is unnecessary. At the same time, if it is
unknown, the formalism can add increasing levels of detail in the hierarchy to include, for example,
source code fragments.

For instance, an attacker may ﬁnd out by testing (phase 1) that a given laptop uses a particular
WiFi card model. The attacker can then purchase – if it exists – an exploit for the given card and
deploy it. At this point, the system’s behavior as a whole will change (phase 2), for example, by
giving the attacker the possibility to run any code on the machine. This example is taken straight
out of real experience [50]. Importantly, we claim that an attacker can hijack a system even with
an incomplete view of it, as long as the system and the mental model are behaviorally equivalent
from the attacker’s point of view. Mathematically, this relies on the assumption that the exploit is
invariant under isomorphism of behavior.

assumptions
In practice, this means the following: we represent behaviors of systems using the
concept of categorical semantics (Section 3). This categorical semantics can be more or less granular,
depending on how low-level we want our descriptions to be. For instance, consider specifying
behavior in terms of automata. We can represent automata as theoretical objects, but we can also
view their implementation details. We can describe the system behavior under some formalism
and relate it to concrete elements. As a reductionist example, an automaton can be implemented
in either a system-on-chip or a ﬁeld-programmable gate array (FPGA). These would amount to
diﬀerent choices of categorical semantics.

Two automata may be isomorphic in the former setting but not in the latter: this could result
in having two diﬀerent implementations of the same theoretical concept (for example, this is the
case in considering the same automaton implemented in two diﬀerent programming languages).
An attack exploiting the automaton design will be isomorphism-invariant in both settings: such an
attack exploits the idea that it is possible to start from a state of a given automaton and end up in
another state via a legitimate sequence of moves. An attack exploiting the automaton implemen-
tation (for example, some weakness of the programming language the automaton is implemented
in) will be isomorphism-invariant only in the latter setting. Our categorical semantics cannot “see”

4

Georgios Bakirtzis, Fabrizio Genovese, and Cody H. Fleming

implementation diﬀerences at the theoretical level. This amounts to saying that “an attack is pos-
sible even if the attacker has a diﬀering view of the system, as long as it is behaviorally equivalent
to the system itself” holds only if the categorical semantics developed for application are granular
enough to faithfully model the level of generality on which a given exploit acts.

The main mathematical tools used to build the proposed compositional modeling framework
for cybersecurity in CPS are: a compositional system model in the wiring diagram category; the
Yoneda lemma, which represents tests over the system model, and more speciﬁcally, the Yoneda
lemma fully determines a given object by its relationships [15]; and ﬁnally functors and natural
transformations to investigate the eﬀects of an exploit formally. We have decided to omit from the
main text these primitive deﬁnitions but have included a formal treatment (Appendix A) and refer
the reader to more comprehensive texts for missing details [28, 43].

3 SYSTEMS AS ALGEBRAS
We use the categorical structures to develop algebraic machinery such that it is possible to model
security violations over a CPS model. The one assumption we make is that an already existent
model of a CPS resides within a category. The motivation for this assumption is twofold. First,
through category theory, it is possible to unify behavioral models of control systems with models
of candidate concrete implementation of this behavior [9]. Uniﬁcation through the categorical for-
malism traces between algebras and their associated models necessary for the design of CPS [11].
Second, as it pertains to security assessment, it is helpful to see the eﬀects of an attack at the
behavioral level, even though most security assessment techniques apply to implementations –
this relationship builts in the intuition of the security analyst. By having a categorical systems
model, we can capture formally and, therefore, precisely the behavioral eﬀects of an attack from
the particular modeled implementation to the set of control behaviors.

We acknowledge that this assumption contains limitations (Section 4), including that systems
are often modeled after the fact in a largely informal manner. However, we posit that to move
the goal post towards a compositional CPS theory as deﬁned in the introduction, we must move
towards a more formal treatment of both systems modeling and security analysis. Category theory
is but one possible formalism towards this direction. Category theory has the beneﬁt of relating
and transforming between diﬀerent model types. This is an important attribute that can promote
and merge existing approaches from the areas of control, systems theory, and security instead of
requiring new developments in formalisms for each individual area.

This view is consistent with the concerns of the industry. Often, uniﬁed languages are reduc-
tionist in practice, causing increased complexity and lower ﬁdelity of models [48]. However, the
categorical framework we develop here (and others in the area of dynamical systems, for example,
by Spivak and Tan [61]) results in the ability to translate between already known and used models.
The categorical formalism could be in the backend of a modeling language without the system
designer or security analyst interacting with any unfamiliar syntax.

We now use category theory (Appendix A) to present this compositional theory of CPS. The
general systems-as-algebras paradigm was invented by Schultz et al. [58], and its particular devel-
opment for CPS was invented by Bakirtzis et al. [8, 12]. The wiring diagram is the cornerstone
category for developing a categorical argument for compositional security analysis for CPS mod-
els.

Systems as algebras provide a framework for compositional CPS models that further enable
the compositional study of security properties. In applied category theory, diagrams are not mere
pictures but instead mathematics in and of themselves [21]. Our choice of categorical structure
to represent system models is the category of wiring diagrams and labeled boxes, denoted W.

Yoneda Hacking: The Algebra of Attacker Actions

5

C

L

D

Fig. 1. A generic model of a UAV in the wiring diagram category treats the system as black boxes and the
connections between them.

Therefore, we present the inner workings of the wiring diagram category W as explicitly applied
to CPS before moving on to address security property modeling.

Deﬁnition 1. We deﬁne the category of wiring diagrams, W, as follows:

• The objects of the category W are pairs of sets 𝑋 = (𝑋in, 𝑋out), which we depict as labelled

boxes.

𝑋in

𝑋

𝑋out

• The morphisms of the category W are functions. Particularly, a morphism 𝑋 → 𝑌 is a pair
of morphisms (𝑓in : 𝑋out × 𝑌in → 𝑋in, 𝑓out : 𝑋out → 𝑌out) in Set that should be thought of as
providing the ﬂow of information in a picture as follows.

𝑌

𝑋

Moreover, the category W is monoidal and, therefore, comes equipped with a tensor product 𝑋 ⊗
𝑌 = (𝑋in × 𝑌in, 𝑋out × 𝑌out), that formalizes two processes happening in parallel.

𝑋

𝑌

The wiring diagram category, W, gives a formal composition rule for connecting labeled boxes
and wires. To add some meaning to those boxes, we need to develop an algebra that assigns some
form of behavior, for example, in the form of automata or state-space models. The semantics of
CPS will predominantly exist in the category of sets and functions Set and, because we are working
with control systems, the category of linear spaces and linear maps Lin.

𝑍

, and applies the mathematical interpretation of behavior to it, 𝐹 (

The boxes at the current moment are uninhabited. Usually, we can describe the behavior of a
CPS mathematically via some equations. To assign some behavior to the boxes in the wiring dia-
gram category W, we need to construct an algebra of behaviors 𝐹 that takes an empty box, say
). Formally, we ex-
press this as a functor from W to Cat, which assigns to every box a category representing the kind
of systems that can inhabit it. Morphisms of W map to functors that build the category of possible
inhabitants of the total composite system from system components. Detailed examples working
out the assignment of behavior in the case of Moore machines [58], contract algebras [9], and
dynamical systems [22] have been already worked out in the literature. Our security framework
works in any system that such a functorial assignment represents.

𝑍

6

Georgios Bakirtzis, Fabrizio Genovese, and Cody H. Fleming

Processor
𝑃2

C

Servos
𝑉

L

Processor
𝑃1

IMU
𝐼1
IMU
𝐼2

GPS
𝐺

UAV

D

Airframe
𝐹

Aileron
𝑋

Rudder
𝑌

Throttle
𝑍

Elevator
𝑈

Fig. 2. The hierarchical decomposition from behavior to system architecture is formally contained within
the slice category C/𝑐 in which there exist all possible design decisions that adhere to the behavioral model.
We segment here to subsystems following a behavior decomposition to sensors L, controller C, and dynamics
D. Split wires indicate function duplication, Δ.

The other way around, one can formally decompose a box (which now is inhabited by math-
ematical processes) to a particular hardware and software architecture to implement a CPS. In
this paper, we use an example of a UAV, but the process is repeatable for any well-formed system
algebra that can take the following form.

𝐹

W
𝑋 =(𝑋in, 𝑋out)
𝑓
𝑌 =(𝑌in, 𝑌out)

Cat

𝐹𝑋

𝐹 (𝑓 )

𝐹𝑌

inner box

wiring

outer box

subsystems category

composite system functor

resulting system category

The UAV is composed of a sensor unit, denoted L, of a controller unit, denoted C, and of a
dynamics unit, denoted D (Fig. 1). We have represented the assignment of behaviors to wiring
diagrams with a functor

𝐹 : W → Cat.

In our running example, 𝐹 (UAV) denotes the category of all the possible behaviors that we can
assign to the UAV box. Thus, our UAV is a pair (UAV, 𝑆) with 𝑆 an object of 𝐹 (UAV) representing the
particular UAV model at hand. Each of these units is itself composed of various subsystems (Fig. 1).
Multiple possible system architectures can implement this higher-level behavior. We assume that
the attacker is familiar with the general class of vehicle CPS. We focus on one possible but relatively
simple system architecture for illustrative purposes. The slice category over the wiring diagram
gives one model of vertical composition using category theory.

For any category C and a ﬁxed object 𝐶 ∈ C, the slice category C/𝐶 has as objects C-morphisms
with ﬁxed target 𝐶, for example 𝑓 : 𝐴 → 𝐶, 𝑔 : 𝐵 → 𝐶, · · · . The arrows in that category from some
𝑓 to some 𝑔 are C-morphisms 𝑘 : 𝐴 → 𝐵 between the domains, making the formed triangle

𝐴

𝑓

𝑘

𝐶

𝐵

𝑔

Yoneda Hacking: The Algebra of Attacker Actions

7

commute, namely 𝑔◦𝑘 = 𝑓 . Intuitively, the slice category gives us a way of breaking up morphisms
into more morphisms leading to the decomposition to a particular architecture from a general
understanding of the behavioral view as recorded in the wiring diagram category, W. For our
running UAV example, we have multiple possible decompositions to the slice category, but we will
use one that is functionally complete (Fig. 2).

4 THE ALGEBRA OF ATTACKER ACTIONS
Using the Yoneda lemma (Appendix A.4) and wiring diagrams and their algebras (Section 3), we
will formalize attacks. This is the core of this work, and all the concepts presented from now on
are new developments.

In our eﬀort, we embrace the perspective of the attacker. For us, an attacker is simply an actor
wanting to inﬂuence or change the behavior of some given system. We do not distinguish between
attacks aiming at taking control of the system (as it is common in computer hacking) and attacks
seeking to inﬂuence its behavior to obtain a particular eﬀect (as in sabotage). Our framework mod-
els attacker actions to encompass both mechanisms and domains of attacks as deﬁned in common
attack pattern enumeration and classiﬁcation (CAPEC) [18].

To describe the entire cycle of an attack, we split it into the two following main phases.

Phase 1) Learning (exploration), or information gathering, is concerned with probing/eavesdrop-
ping on the system to discern its behavior. We further divide this activity into general
learning, where the attacker focuses on gathering a broad understanding of the system
at hand, and speciﬁc learning, where the attacker probes the system to understand some
particular component design choices.

Phase 2) Hijacking (exploitation), where the attacker, having learned enough information to un-
derstand the weak spots of a system, deploys an exploit which takes advantage of a found
architectural ﬂaw to inﬂuence the behavior of the system in some way the attacker de-
sires.

Example 1. Consider an attacker wanting to take control (or sabotage) of a UAV. The attacker
starts by learning and gathering information about the target UAV (phase 1). General learning here
can be the attacker trying to understand if the UAV has a GPS module on board. If there is a GPS,
speciﬁc information gathering consists of understanding how the GPS module communicates with
surrounding units. This general-speciﬁc learning pattern can repeat arbitrarily: the attacker could
now focus on the GPS module to understand if some particular kind of integrated circuit is used
in its schematic.

Once an attacker is suﬃciently informed about the system, the exploit can be deployed (phase
2). In our example, this may be rewriting the ﬁrmware of the GPS module over the air or supposing
that the attacker has physical access to the UAV, manually rewiring the module, or replacing some
integrated circuit in it.

One fundamental assumption is that we do not precisely model how a given exploit is developed
but only how it is administered and provide a compositional recipe to describe how this change
of behavior propagates to the whole system. In practice, this means postulating that the attacker
already has access to a knowledge database of tools made to take advantage of a given structural
ﬂaw in a given (sub)system. This postulate is not unthinkable; an attacker can hijack a system
without personally creating the exploit. For example, zero day exploits – that is, exploits of a given
ﬂaw that is still unknown to the public, including the target manufacturer – are common in hacking
and can be commonly bought over the web [1]. Another fundamental assumption of our model is
that it forms an algebra in the wiring diagram category. Again, we do not consider this restrictive
for reasons already pointed out by Bakirtzis et al. [12].

8

Georgios Bakirtzis, Fabrizio Genovese, and Cody H. Fleming

4.1 Phase 1 – Learning (Exploration)
First, we model general learning. Assuming an attacker’s perspective, we want to model what
an attacker does to understand the kind of system they want to attack. In practice, this includes
operations such as scanning a computer for open ports, investigating the ﬁrewall policies, ﬁnding
out what operating system is running on the system, and probing a piece of hardware to obtain
information about the system’s integrated circuits.

Functors W

𝐹
−→ Cat, W-algebras, represent wiring diagrams together with semantics linking
any diagram to the category describing its possible behaviors. A particular wiring diagram is just
an object 𝑋 in W, 𝐹𝑋 is a category: objects model general behavior assignments for 𝑋 , while
morphisms take mappings between them that preserve properties we care about. When focusing
on a particular system, we are ﬁxing a wiring diagram 𝑋 and one of the many possible behaviors
in the category 𝐹𝑋 . Hence,

a system is a pair (𝑋, 𝑆), with 𝑋 an object
of W and 𝑆 an object of 𝐹𝑋 .
Example 2. Consider 𝐹 to be the W-algebra assigning each wiring diagram 𝑋 = (𝑋in, 𝑋out) to
the category of Moore machines with 𝑋in and 𝑋out as input and output alphabets, respectively,
as worked out in detail in [58]. In this setting, a system (𝑋, 𝑆) is given by a wiring diagram 𝑋 =
(𝑋in, 𝑋out) and a chosen Moore machine having 𝑋in as input alphabet and 𝑋out as output alphabet,
respectively.

We suppose we have access to 𝑋 (this amounts to saying that we can distinguish the type of inputs
and outputs that our system has) and to 𝐹𝑋 (we know what kind of system we are dealing with),
but not to 𝑆 (we do not know the speciﬁc behavior of the system at hand). The ﬁrst goal of the
attacker is to infer 𝑆 to the degree that an attack is viable.

First things ﬁrst, we select a subset of the objects of 𝐹𝑋 , denoted 𝐾𝐹 𝑋 (from “known”), represent-
ing the systems that the attacker knows or is familiar with. Notice that 𝐾𝐹 𝑋 should not, in general,
lift to a functor W → Cat, since we do not assume the attacker knowledge to be compositional.
For the same reason, given that there will be an injection 𝐾𝐹 𝑋 ↩→ 𝐹𝑋 representing how the sys-
tems known by the attacker embed in the bigger universe of the systems, we do not necessarily
assume the attacker to know this embedding.

Deﬁnition 2. Given a W-algebra W
is a subset 𝐾𝐹 𝑋 of the objects of 𝐹𝑋 .

𝐹
−→ Cat and an object 𝑋 in W, a knowledge database for 𝐹, 𝑋

An example knowledge database for 𝐹, 𝑋 is just a set of Moore machines (Example 2) having

Θ
−→ Set.

𝑋 = (𝑋in, 𝑋out) as input/output alphabets, respectively. Next, we consider functors 𝐹𝑋
These are interpreted as tests, or probes.

• Given 𝑆 in 𝐹𝑋 , Θ𝑆 represents the information we get in probing 𝑆 with a test Θ. For instance,
𝑆 may represent a machine on a network, while Θ𝑆 could represent the output one gets by
running nmap on 𝑆.

• If 𝑆

𝑓
−→ 𝑆 ′ is a morphism of 𝐹𝑋 , then Θ𝑓 is a way to transform the information in Θ𝐴 to
information in Θ𝐵. Our tests are well suited to detect the properties we care about preserved
by morphisms of 𝐹𝑋 .

• In this interpretation, functoriality holds on the nose. Transforming a system by “doing noth-
ing” (identity morphism) should give the same test outcome (functor identity law). Moreover,
composing transformations should amount to composing outcomes of the testing.

We package all this information as follows.

Yoneda Hacking: The Algebra of Attacker Actions

9

Deﬁnition 3. Given a W-algebra W
𝐹𝑋 → Set.

𝐹
−→ Cat and an object 𝑋 in W, a test for 𝐹, 𝑋 is a functor

A possible test is a functor mapping any Moore machine (Example 2) to its set of states. This test
is a functor because of how morphisms between Moore machines are deﬁned; see, for instance,
Schultz et al. [58]. Again, the attacker does not have access to 𝑆 but has access to Θ𝑆 for some
tests Θ. The tests represent the ability of the attacker to perform tests on the system. These tests
describe an ongoing reconnaissance mission, which often is the step that takes the longest time
and resources of the attacker. The goal of the attacker is to prove in some sense that 𝑆 ≃ 𝑆 ′, for
some 𝑆 ′ in 𝐾𝐹 𝑋 . The system 𝑆 is an instance of a system 𝑆 ′ the attacker is familiar with. Given our
assumption, we can then postulate that the attacker knows an exploit for 𝑆 ′ to move to phase 2.
We make the assumption that, for any 𝑆 ′ ∈ 𝐾𝐹 𝑋 , the attacker has access to 𝑆 ′. This assumption
is natural, since 𝑆 ′ is by deﬁnition in the knowledge base of the attacker. In particular, we assume
that the attacker is able to perform any test to any known system, hence,

for any 𝑆 ′ ∈ 𝐾𝐹 𝑋 and 𝐹𝑋
the attacker has access to Θ𝑆 ′.

Θ
−→ Set,

We extend the example of Moore machines (Example 2) to include a knowledge database and
security tests. The attacker, therefore, knows the set of states of all Moore machines residing in
their knowledge database. The Yoneda lemma says that if Θ𝑆 ≃ Θ𝑆 ′ for all Θ, then 𝑆 ≃ 𝑆 ′. In our
compositional framework, let us interpret what this means, considering some corner cases.

• Suppose that for some object 𝑆 in 𝐹𝑋 there is an object 𝑆 ′ in 𝐾𝐹 𝑋 such that 𝑆 ≃ 𝑆 ′. If the
attacker has access to Θ𝑆 for any Θ, then the attacker will be able to conclude 𝑆 ≃ 𝑆 ′ from
Θ𝑆 ≃ Θ𝑆 ′. That is, if the attacker is free to perform any form of testing and possesses a vast
knowledge database, then 𝑆 can be determined with absolute precision.

• If the attacker has access to any Θ, but there is no 𝑆 ′ in 𝐾𝐹 𝑋 such that 𝑆 ≃ 𝑆 ′, then the
attacker will not be able to conclude 𝑆 ≃ 𝑆 ′. Tests can be arbitrarily precise, but the attacker
cannot interpret them.

• If there is an object 𝑆 ′ in 𝐾𝐹 𝑋 such that 𝑆 ≃ 𝑆 ′, but the attacker has no access to all Θ, then it
will not be able to conclude with certainty that 𝑆 ≃ 𝑆 ′, because the Yoneda lemma does not
hold in this setting. Still, after performing enough tests, the attacker may be prone to infer
that 𝑆 ≃ 𝑆 ′ if Θ𝑆 ≃ Θ𝑆 ′ for enough Θ ran. This inference comes with uncertainty, making
information gathering more of an art than a science.

The Yoneda lemma provides a formal justiﬁcation for the insuﬃciency of extensively testing a
system to characterize its behavior adequately. We call this heuristic Yoneda reasoning.

Some tests are more informative than others. For instance, the “terminal test” Θ sending any
𝑋 to the singleton set {∗} is maximally uninformative: the result of this test is the same for any
system. On the contrary, a functor that is injective on objects lifts to a test that yields the conclusion
𝑋 = 𝑌 from 𝐹𝑋 = 𝐹𝑌 . Further formalizing the possible spectrum of tests, hopefully weighing them
with probability distributions to model their reliability, is an ongoing direction of future work. We
suppose that the attacker pinned down the target system 𝑆 with some precision. The next step
of an attack is harvesting information about the architectural design choices implementing the
system. After we know how 𝑆 works, we need to determine what 𝑆 is made of.

Previously, we modeled a system of an object 𝑋 in W together with an object 𝑆 of 𝐹𝑋 , for some
W-algebra 𝐹 : W → Cat. Now we consider the category of architectural choices for 𝑋 , that is, the

slice category W/𝑋 . Objects of this category are morphisms Ë𝑖 𝑋𝑖

𝜙
−→ 𝑋 , while morphisms are

10

Georgios Bakirtzis, Fabrizio Genovese, and Cody H. Fleming

morphisms of wiring diagrams making the following triangle commute.

Ë𝑖 𝑋𝑖

𝜙

Ë𝑗 𝑋 𝑗

𝜓

𝑓

𝑋

Architectural choices form a category, so we can repeat the reasoning in the last section using W/𝑋
as the category we probe. Again using Yoneda, the attacker can ascertain that a given system (𝑋, 𝑆)
is made of subsystems (𝑋𝑖, 𝑆𝑖), tensored and wired together by 𝜙. At this stage, the attacker still
does not know anything about the 𝑆𝑖, so the process must repeat cyclically.

In practice, tests will not have to be materially re-run on every 𝐹𝑋𝑖: the attacker likely has only
access to Θ𝑆 – every (𝑋𝑖, 𝑆𝑖) being a subsystem of (𝑋, 𝑆) that may not necessarily be exposed to
Θ𝐹 𝜙
−−−→ Θ𝐹𝑋 , meaning
external testing. Nevertheless, it will always be the case that Θ(𝐹 Ë𝑖 𝑋𝑖 )
that the outputs of tests over every 𝑆𝑖 will have to be reconstructed from tests over 𝑆. This re-
construction adds another layer of uncertainty for the attacker, who has to devise tests for which
the mapping Θ𝐹𝜙 acts as transparently as possible. Again, this backs up intuition: going back to
Example 1, if some system (𝑋, 𝑆) comprises a subsystem (𝑋𝑖, 𝑆𝑖 ) (say, a GPS module), then we
could devise a test on 𝐹𝑋 such that in Θ𝑆 the behavior of the subsystem 𝑆𝑖 is made apparent. Sim-
ilarly, when running nmap on a system, we can get extra information about which services are
running behind which port, for example, nginx behind port 80. By probing the composite system,
the attacker gets information about its subsystems.
Summarizing, phase 1 is modeled as follows.

(1) The attacker uses tests on 𝐹𝑋 and Yoneda-reasoning to ﬁnd the system 𝑆 representing the

semantics of 𝑋 .

(2) The attacker uses tests on W/𝑋 and Yoneda-reasoning to ﬁnd the wiring Ë𝑖 𝑋𝑖

resenting the implementation of 𝑋 .

𝜙
−→ 𝑋 rep-

(3) The attacker repeats step 1 on any 𝐹𝑋𝑖 of interest to ﬁnd the precise behavior of the subsys-

tem marked with 𝑋𝑖.

(4) The attacker repeats step 2 on W/𝑋𝑖 to obtain more information about the subsystems mak-

ing up 𝑋𝑖.

(5) These steps iterate cyclically until the attacker has gathered enough information to exploit

the system.

4.2 Phase 2 – Hijacking (Exploitation)
Now suppose that the attacker has a good grasp of the system behavior and architecture and
model the last step, in which the system is hijacked and exploited. We distinguish between two
main kinds of attacks.

Type 1) Rewriting attacks change the behavior of a (sub)system. Practical examples of this are,
for instance, exploiting a vulnerability in a WiFi card to rewrite its ﬁrmware and using
this change of behavior to progress towards obtaining administrative privileges over the
whole machine.

Type 2) Rewiring attacks modify the way subsystems communicate with each other.

Yoneda Hacking: The Algebra of Attacker Actions

11

C

L

−→

L

C

Fig. 3. A rewiring attack is modelled using endomorphisms of wiring diagrams.

Deﬁnition 4 (Rewriting Attack). Given a W-algebra 𝐹 , systems (𝑋1, 𝑆1), . . . , (𝑋𝑛, 𝑆𝑛) and a mor-
phism 𝑋1 ⊗ · · · ⊗𝑋𝑛
𝑖 of 𝐹𝑋𝑖 for some 𝑖. The resulting
system after the attack is given by the couple

𝑤
−→ 𝑋 , a rewriting attack is a morphism 𝑆𝑖

ℎ
−→ 𝑆 ′

(cid:0)𝑋, 𝐹𝑤 (𝑆1, . . . , 𝑆 ′

𝑖 , . . . , 𝑆𝑛)(cid:1) = (cid:0)𝑋, (𝐹𝑤 (id𝑆1, . . . , ℎ, . . . , id𝑆𝑛 )) (𝑆1, . . . , 𝑆𝑛)(cid:1) .

𝑖 . The result of swapping 𝑆𝑖 for 𝑆 ′

In a rewriting attack, we do not change the possible behaviors assigned to wiring diagrams;
the functor 𝐹 stays ﬁxed. The pairs (𝑋𝑖, 𝑆𝑖) represent all the subsystems of our whole system,
that can be evaluated as (𝑋, 𝐹𝑤 (𝑆1, . . . , 𝑆𝑛)). Here, the ﬁrst component of the couple represents
the shape of the box corresponding to the composite system. To pinpoint with precision the box
inhabitant, we use the wiring diagram 𝑤, lift it to a functor between behaviors 𝐹𝑤, and evaluate
this functor on the subsystems at hand, 𝑆1, . . . , 𝑆𝑛. Then, a rewriting attack is nothing more than a
way, call it ℎ, to morph one of these 𝑆𝑖 into an 𝑆 ′
𝑖 can be evaluated
using the functoriality of 𝐹𝑤 and the morphism ℎ. For Moore machines (Example 2), a set of
pairs (𝑋1, 𝑆1), . . . , (𝑋𝑛, 𝑆𝑛) now represent 𝑛 subsystems, each one with a ﬁxed choice of a Moore
machine – of the right kind, since each 𝑆𝑖 ∈ 𝐹𝑋𝑖 – inhabiting it. Each of these machines will have
its own set of states and state-transition function. The resulting Moore machine inhabiting 𝑋 will
be (𝑋, 𝐹𝑤 (𝑆1, . . . , 𝑆𝑛)).
ℎ
−→ 𝑆 ′
In the mapping 𝑆𝑖

𝑖 ∈ 𝐹𝑋𝑖 is just a Moore machine that has the same in-
put/output alphabets of 𝑆𝑖, but possibly a diﬀerent set of states or a diﬀerent state-transition func-
tion. By replacing 𝑆𝑖 with 𝑆 ′
𝑖 is our rewriting attack, we are swapping the Moore machine 𝑆𝑖 in-
habiting the box 𝑋𝑖 with 𝑆 ′
𝑖 . The eﬀect of this swap will reverberate on the overall system, and
can be calculated using 𝐹𝑤. The Moore machine inhabiting 𝑋 is now (cid:0)𝑋, 𝐹𝑤 (𝑆1, . . . , 𝑆 ′
1, . . . , 𝑆𝑛)(cid:1).
Because of compositionality, the morphism 𝑆𝑖 → 𝑆 ′
𝑖 between submachines lifts to a morphism
𝐹𝑤 (𝑆1, . . . , 𝑆1, . . . , 𝑆𝑛) → 𝐹𝑤 (𝑆1, . . . , 𝑆 ′

1, . . . , 𝑆𝑛) between the composed machines.

𝑖 , the object 𝑆 ′

In our deﬁnition of rewriting attack, we keep the functor 𝐹 ﬁxed, meaning that the category
of behaviors to which we map each wiring diagram stays the same. We could obtain more of a
granular deﬁnition of attack by considering, in addition to the elements considered in Deﬁnition 4,
also monoidal natural transformations between W-algebras. This amounts to having a procedure
to completely replace the kind of systems inhabiting our boxes. For instance, the attacker could
replace Moore machines (Example 2) with automata of some other kind.

Deﬁnition 5 (Rewiring Attack). Given a W-algebra 𝐹 , systems (𝑋1, 𝑆1), . . . , (𝑋𝑛, 𝑆𝑛) and a mor-
ℎ
phism 𝑋1 ⊗ · · · ⊗ 𝑋𝑛
−→ 𝑋𝑖 for some 𝑖. The resulting
system after the attack is given by the couple

𝑤
−→ 𝑋 , a rewiring attack is a morphism 𝑋𝑖

(𝑋, 𝐹 (𝑤 ◦ (id1 ⊗ · · · ⊗ ℎ ⊗ · · · ⊗ id𝑛)) (𝑆1, . . . , 𝑆𝑛)) .

12

Georgios Bakirtzis, Fabrizio Genovese, and Cody H. Fleming

C′

L′

D′

Fig. 4. The attacker’s understanding of the system after the first cycle of learning.

In the case of a rewiring attack, we keep 𝑆1, . . . , 𝑆𝑛 ﬁxed; we are not changing the speciﬁc objects
inhabiting each box. What the endomorphism ℎ does is wrap a given object 𝑆 into new wiring
before composing it with the rest of the system (Fig. 3).

Both rewriting and rewiring attacks form categories. This conforms with our intuition that

attacks can be performed in batches or stacked one on top of each other.

5 COMPOSITIONAL SECURITY MODELING
To illustrate the above compositional security theory as a possible model for security tests and
exploitation methods, we use a system model of a UAV from the perspective of attacker actions
(Example 1).

Let’s start with the minimum observability possible. The attacker knows that the system at hand
is a couple (UAV, 𝑆): UAV with a two inputs and one output box, and 𝑆 is an object of 𝐹 (UAV), where
𝐹 : W → Cat maps system to the categories of behaviors relevant in our example. The ﬁrst step
of the attack is gathering information about 𝑆.

The attacker uses Yoneda reasoning to infer 𝑆 in general information gathering. The attacker

must be able to perform a set of tests on the system (UAV, 𝑆). Any of such tests is a functor

Θ : 𝐹 (UAV) → Set
and the result of the test Θ applied to 𝑆 is denoted Θ𝑆 (in category theory practice, it is customary
to avoid parentheses whenever possible). In our particular case, Θ may be a test that analyzes the
aerodynamics of the UAV during ﬂight. The more informative Θ is, and the bigger the number of
Θ’s the attacker can access, the more likely it will infer 𝑆. If the attacker ﬁnds that 𝑆 ≃ 𝑆 ′ for some
𝑆 ′ in their knowledge database, 𝐾𝐹 (UAV) , then the attacker will know how the UAV behaves.

In practice, it is doubtful for the attacker to have access to every test Θ. As we mention above
(Section 4), this entails that the attacker won’t be able to infer with certainty that 𝑆 ≃ 𝑆 ′: most
likely, the attacker will be prone to infer 𝑆 ≃ 𝑆 ′ with a certain degree of conﬁdence. As such, the
outcome of testing is probabilistic more than deterministic. Assuming that the attacker inferred
𝑆 ≃ 𝑆 ′ for some system 𝑆 ′ in their knowledge database, the particular design choices making up
the UAV are still unknown to them. Applying Yoneda reasoning again to the category W/UAV,
they may be able to infer some of these design choices. For instance, it could be possible to infer
an initial understanding of what the UAV is composed of (Fig. 4). The attacker sees the system
as decomposed into boxes L′, C′ and D′, which will be behaviorally equivalent to L, C and D, of
Fig. 1, respectively. The inner workings of such boxes are still unknown to the attacker, which now
focuses on L′. This amounts to repeating the same cycle of Yoneda reasoning, focusing on tests that
target L in particular (Section 4). After running these tests, the attacker sees a ﬁrst approximation
of the UAV (Fig. 5).

The initial understanding of the attacker is slightly erroneous since the two separated IMU units
in UAV conﬂate into one. Still, the two wiring diagrams are behaviorally equivalent. This reﬂects

Yoneda Hacking: The Algebra of Attacker Actions

13

C′

D′

𝐼 ′

𝐺 ′

L′
𝑃 ′

Fig. 5. The architecture of the sensory system as understood by the attacker, which is in reality erroneous
but behaviorally equivalent. The attacker found that there is one IMU (when in reality there are two) and a
GPS.

C′

D′

𝐼 ′

𝐺 ′
𝐻

L′L′
𝑃 ′

Fig. 6. The compromised UAV, with GPS firmware hacked and its input wires swapped.

the fact that, on the one hand, Yoneda reasoning is probabilistic, and on the other, identiﬁcation
of the system happens only up to behavioral equivalence.

Now, suppose the attacker decides to do two things: rewriting the ﬁrmware of the GPS module
G and swapping its feedback inputs. The ﬁrst is a rewriting attack, and the second is a rewiring
attack (Section 4).

The GPS module is a system (G′, 𝐺 ′), where G′ is a box with two inputs and one output, while
𝐻 (𝐻 stands for

𝐺 ′ is an object of 𝐹 G′. The rewriting attack is represented by a morphism 𝐺 ′ → 𝐺 ′
“hacked”) in the category 𝐹 G′. Denote with

I′ ⊗ G′ ⊗ P′ ⊗ C′ ⊗ D′ 𝑤 ⊗idC′⊗D′

−−−−−−−→ L′ ⊗ C′ ⊗ D′ 𝑣

−→ UAV

the morphism putting together the system (Fig. 5). Then we have that

𝐹 (𝑣 ◦ (𝑤 ⊗ idC′ ⊗D′)) (𝐼 ′, 𝐺 ′, 𝑃 ′, 𝐶 ′, 𝐷 ′) = 𝑆 ′

Where 𝐼 ′ is the system inhabiting I′, 𝐺 ′ inhabits G′ and so on, with 𝑆 ′ behaviorally equivalent to
the system 𝑆 inhabiting UAV. The behavior of the UAV after the rewriting attack will be equivalent
to

𝐹 (𝑣 ◦ (𝑤 ⊗ idC′ ⊗D′)) (𝐼 ′, 𝐺 ′

𝐻 , 𝑃 ′, 𝐶 ′, 𝐷 ′).

14

Georgios Bakirtzis, Fabrizio Genovese, and Cody H. Fleming

Processor
𝑃2

C

Servos
𝑉

L

Processor
𝑃1

IMU
𝐼1
IMU
𝐼2
GPS
𝐺𝐻

UAV

D

Airframe
𝐹

Aileron
𝑋

Rudder
𝑌

Throttle
𝑍

Elevator
𝑈

Fig. 7. The UAV (Fig. 2), after the attack.

The rewiring attack, instead, is a wiring diagram G′ ℎ

−→ G′. The following information speciﬁes

this.

G𝑖𝑛 × G𝑜𝑢𝑡

ℎ𝑖𝑛−−→ G𝑖𝑛

ℎ𝑖𝑛
↦−−→ (𝑔2, 𝑔1)
The resulting system is obtained by considering the wiring diagram

((𝑔1, 𝑔2), 𝑔3)

G𝑜𝑢𝑡

ℎ𝑜𝑢𝑡−−−→ G𝑜𝑢𝑡

ℎ𝑜𝑢𝑡
↦−−−→ 𝑔

𝑔

I′ ⊗ G′ ⊗ P′ ⊗ C′ ⊗ D′

and evaluating

−−−−−−−−−−−−−→ I′ ⊗ G′ ⊗ P′ ⊗ C′ ⊗ D′ 𝑤 ⊗idC′⊗D′
idI′ ⊗ℎ ⊗idP′⊗C′⊗D′

−−−−−−−→ L′ ⊗ C′ ⊗ D′ 𝑣

−→ UAV

𝐹 (𝑣 ◦ (𝑤 ⊗ idC′ ⊗D′) ◦ (idI′ ⊗ℎ ⊗ idP′ ⊗C′ ⊗D′)) (𝐼 ′, 𝐺 ′

𝐻 , 𝑃 ′, 𝐶 ′, 𝐷 ′).

Which is the resulting system inhabiting UAV after applying both attacks (Fig. 6). The attacker
presumes how the system will behave after the exploit, assuming they have a correct system proﬁle
from phase 1. Since phase 1 has a margin for error, the attacker can re-probe the system to assure
that the perceived behavior is compatible with reality. This further round of testing is necessary
to assert with conﬁdence that the exploit has been deployed correctly.

In this example, we postulated that the attacker was indeed able to gather information about
the UAV correctly. Formally, we expressed this by stating what we consider to be the actual UAV
(Fig. 2) and the attacker’s understanding of what the UAV is (Fig. 5) are behaviorally equivalent.
Because functors preserve isomorphisms, we can describe how the attack impacts the actual UAV
(Fig. 7).

We now describe several other possible attacks: one consists in feeding a counterfeit GPS signal
to the UAV to compromise it. This attack is documented “CAPEC-627: Counterfeit GPS Signals”
and is considered diﬃcult to realize. The wiring diagrams formalism gives us an idea of why:
feeding a counterfeit GPS signal does not involve modifying the GPS module. What changes is
the information traveling on the GPS wires, which communicate with the outside world. So, to
understand this attack properly, one needs to model how the UAV interacts with the environment
it is in (Fig. 8). Here, by Environment we mean a process that, given the UAV position in space and
time, returns the data sensed by the IMU and GPS units. We see that spooﬁng a GPS signal does
not amount to intervening on the UAV but on the environment itself. Attackers rarely can control
the environment within a region of space and time – radio waves from the GPS satellites in this
particular case – that is big enough to inﬂuence the behavior of the single UAV.

Yoneda Hacking: The Algebra of Attacker Actions

15

UAV

C′

D′

𝐼 ′

𝐺 ′

L′
𝑃 ′

Environment

Fig. 8. Feeding counterfeit GPS signals to the UAV hijacks Environment.

GCS

UAV

C′

D′

𝐼 ′

𝐺 ′

L′
𝑃 ′

Fig. 9. Social engineering attacks may hijack the ground control station (GCS).

To conclude, we present another possible attack, performed using social engineering. As with the
previous example, social engineering does not exploit the UAV itself but instead takes advantage
of the human factor. Examples of this may include bribing whoever programs the UAV goals or
making the control tower believe that a given order has been oﬃcially issued from whoever is in
command, for example, as deﬁned in “CAPEC-137: Parameter Injection”.

As in the previous case, the behavior of the UAV as a wiring diagram is unchanged. Instead, what
changes is the information traveling on the ﬁrst input wire of the UAV box. From our perspective,
this requires again to put the UAV into context (Fig. 9). An attack based on social engineering will
consist in rewriting the box GCS, which abstracts away a possible ground control station.

The categorical semantics of CPS security modeling for the UAV can be implemented algorith-

mically (Listing 1 & 2).

Listing 1. Modeling attacker learning

-- Define category of wiring diagrams
W : Category
W

= Definition 1

-- Define functor for UAV modeling
F : Functor W → Cat
F = assignment of UAV behavior ( linear time invariant system ) to boxes

-- Model UAV as a 2 - input 1 - output W- box
: W
UAV
UAV = (2 ,1)

16

Georgios Bakirtzis, Fabrizio Genovese, and Cody H. Fleming

-- Knowledge database
𝐾𝐹 (UAV) : List 𝐹 (UAV)
𝐾𝐹 (UAV) = attacker knowledge for systems of type UAV

-- Compare tests with target S
CompareTests : ( Functor 𝐹 (UAV) → Set) → 𝐹 (UAV) → Bool
CompareTests Θ S ' = Θ(𝐾𝐹 (UAV) (𝑆 ′)) ≃ Θ(𝑆)

-- Yoneda reasoning
for each Θ : Functor 𝐹 (UAV) → Set
filter ( CompareTests Θ) K

-- Running security tests reveals the following boxes
L′ , C′ , D′
L′ , C′ = (2 ,1)
D′ = (1 ,1)

: W

diagram : Morphism W (L′ ⊗ C′ ⊗ D′) → UAV
diagram = ( in , out )
where
in : Morphism Set UAVin × (L′
𝑜𝑢𝑡 × C′
in u1 u2 l c d = ( u2 , d , u1 , c)
out : Morphism Set (L′
𝑜𝑢𝑡 × D′
out l c d = d

𝑜𝑢𝑡 × C′

𝑜𝑢𝑡 ) → UAV𝑜𝑢𝑡

𝑜𝑢𝑡 × D′

𝑜𝑢𝑡 ) → (L′

𝑖𝑛 × C′

𝑖𝑛 × D′

𝑖𝑛)

Listing 2. Modeling hijacking

-- By iterating learning further decompose L′
I′ , G′ , P′
I′ , G′ , P′ = (2 ,1)

: W

Ldiagram : Morphism W (I′ ⊗ G′ ⊗ P′) → L′
Ldiagram = ( in , out )
where
in : Morphism Set (L′
in l1 l2 i g p = ( l1 , l2 , l1 , l2 , i , g )
out : Morphism Set (I′
𝑜𝑢𝑡 ) → L′
out i g p = p

𝑜𝑢𝑡 × P′

𝑜𝑢𝑡 × G′

𝑜𝑢𝑡 × G′

𝑜𝑢𝑡 × P′

𝑖𝑛 × (I′

𝑜𝑢𝑡

𝑜𝑢𝑡 ) → (I′

𝑖𝑛 × G′

𝑖𝑛 × P′

𝑖𝑛 ))

-- Rewriting attack
𝜂 : NatTrans ( Functor W → Cat) → ( Functor W → Cat)

-- 𝜂 is the identity on everything but G '
𝜂 G′ : Morphism F G′ → F G′
𝜂 G′ = firmware rewriting

-- Rewiring attack
Lattack : Morphism W (I′ ⊗ G′ ⊗ P′) → L′
Lattack = ( in , out )
where
in : Morphism Set (L′
in l1 l2 i g p = (l1 , l2 , l1 , 0 , i , g )
out : Morphism Set (I′
out i g p = p

𝑜𝑢𝑡 × P′

𝑜𝑢𝑡 × G′

𝑜𝑢𝑡 × P′

𝑜𝑢𝑡 × G′

𝑖𝑛 × (I′

𝑜𝑢𝑡 ) → L′

𝑜𝑢𝑡

𝑜𝑢𝑡 ) → (I′

𝑖𝑛 × G′

𝑖𝑛 × P′

𝑖𝑛 )

Yoneda Hacking: The Algebra of Attacker Actions

17

Rewiring : Functor W → W
Rewiring Ldiagram = Lattack

-- The modified behavior of the hijacked UAV
behavior : F (UAV)
behavior = 𝜂 UAV ( F ( Rewiring (UAV) ) ) (S ')

limitations
Based on how we deﬁned Yoneda reasoning, we identify several limitations. These
limitations can be overcome by enriching over metric spaces, which we will also discuss. The main
point of this paper is to set a solid theoretical footprint of category theory and the diagrammatic
reasoning that emerges in the application of securing CPS. Making the results probabilistically
concrete is a potential future topic that can be based on the above formal methods.

One such limitation can be inspected from the resulting algorithm (Listing 1). As output, we
may have that Yoneda reasoning returns no result (the list being ﬁltered from K is empty, meaning
that the attacker does not have entries in the knowledge database that adequately model the target
system). However, we may also have that it returns more than one – the list being ﬁltered from
K having more than one element, meaning that the test performed was not ﬁne-grained enough
to pinpoint the target system with deterministic accuracy. This discrepancy is mainly due to the
nature of the tests performed; some tests are more informative than others. Sending any system
in 𝐹 (UAV) to the one-element set deﬁnes a functor to Set and hence a valid test, which is though
maximally uninformative since the test outcome will be the same on all systems. Contrastly, any
injective-on-objects functor Θ allows us to conclude that Θ𝑆 = Θ𝑆 ′ implies 𝑆 = 𝑆 ′, and is maximally
granular. As we presented it, the formalism cannot express which subset of the tests allows us to
individuate the target system unambiguously.

Indeed, there are tests with diﬀerent degrees of expressiveness, and the Yoneda lemma does not
account for this; we can conclude 𝑆 ≃ 𝑆 ′ using Yoneda lemma if and only if 𝑆 and 𝑆 ′ agree on all
tests, including the maximally useless ones. These diﬀerent results are why we speak of Yoneda
reasoning as a heuristic and not as a deterministic procedure.

Looking at things more abstractly, the reason for this shortcoming lies in the fact that in our def-
inition of the category, we considered homsets to be sets; that is, we speak of the set Hom C [𝐴, 𝐵]
of all possible morphisms from 𝐴 to 𝐵 in some category C. Sets have very little structure, and in
such an environment, we cannot formulate the Yoneda lemma to be more expressive.

In a probabilistic setting, what we would like to have is a version of Yoneda reasoning that gives
an interval of conﬁdence relating Θ𝑆 ≃ Θ𝑆 ′ and 𝑆 ≃ 𝑆 ′ for any possible test Θ. In other words, we
want to attach to each Θ a measure of how informative Θ is in our context.

One possible solution is to resort to enriched category theory, which is a generalization of cate-
gory theory where homsets can have more structure. In particular, we can reformulate our theory
using categories enriched over metric spaces. Categories enriched over metric spaces give a nat-
ural way of talking about distances between sets, and this can be used to deﬁne a measure on
the tests we can perform. In the context of enriched category theory, the Yoneda lemma can be
reformulated in what is informally known as ninja Yoneda lemma [49], which takes into account
this additional structure. We can use this to deﬁne a version of Yoneda lemma that has a notion of
conﬁdence in the tests we perform over the CPS model and, therefore, have some granularity of
what it means for two systems to be behaviorally equivalent under some (informative) tests.

benefits While we show some limitations about the ﬂexibility of the model, it is essential to
point out that the same ﬂexibility can be beneﬁcial. Diﬀerent formalisms can inhabit the boxes

18

Georgios Bakirtzis, Fabrizio Genovese, and Cody H. Fleming

deﬁning a system’s behavior, from Petri nets to transition systems to ordinary diﬀerential equa-
tions. Developing our formalisms will allow us to speak about all these representations within one
framework. For example, applications to security modeling using Petri nets [44] is currently con-
gruent with research in category theory and Petri nets [7, 30, 31, 62] and could be used to make
the application of the preceding formalism more concrete as a model of (mis-)behavior. Similarly,
both models of security violations in automata [67] and continuous controller behavior [53] can
be represented within our framework and, therefore, allow for a plethora of analyses within one
model.

However, to drill further in the possible directions of describing diﬀerent types of continuous,
for example, false sensor data, or discrete, for example, transitioning the system to a hazardous
state, misbehaviors caused by exploitation require the ﬁrst formulation of security modeling cat-
egorically and algebraically. This paper serves this purpose. Relaxing some of the unrealistic as-
sumptions we made incorporates developing work from category theory.

Additionally, this security framework is part of an alternate paradigm of systems modeling that
has its foundations in categorical modeling. In this framework, it is possible to provide formal
traces of requirements, behaviors, and architectures [9] but also describe a vast amount of dynam-
ical systems with applications to robotics, event-based systems, and hybrid systems, to name a
few [22, 27, 46, 72].

Finally, this paper addresses the theoretical underpinnings of security modeling in category
theory. Nevertheless, the recent surge of categorical modeling languages and software, such as
Catlab [35] or idris-ct [29] or algebraic databases [59], can be used to create modeling tools and
security assessment methods based on the work presented in this paper practical within composi-
tional CPS theory.

6 RELATED WORK

In general, category theory is eﬀective in describing hybrid systems [4, 22, 66] and more recently
there has been successful work in modeling and analysis of CPS using category theory [12, 16,
17, 52]. An important motivation for developing a categorical modeling security framework is
the theory of co-design, a way of dealing with abstraction and reﬁnement in models, which has
recently been applied categorically to robotics [70, 71] and control system design [69].

To the best of our knowledge, there is little work at the intersection of category theory, CPS, and
security modeling. One such work uses the categorical interpretation of databases to share threat
information, but it does not propose how this paradigm improves upon graph methods for secu-
rity [5]. A line of work also uses category theory to study cryptographic functions, as illustrated,
for example, by Pavlovic [54]. The modeling approach presented in this paper does not develop se-
curity techniques for defenses but instead focuses on the dual of the research questions answered
by cryptography. While cryptography asks how we can communicate securely, systems modeling
and analysis ask how we can represent attacker actions over a behavioral and architectural model
in a traceable manner, such that we can examine what mitigation strategies to implement in the
design of the system. The same diﬀerentiation applies to secure design using dependent types [36]
– which are often formalized categorically – and categorical data ﬂow analysis [73].

On the side of attacker modeling for CPS, there is a vast area of research using graph formalisms.
Examples include attack graphs [60] and attack proﬁles using graph models as shown recently by
Weber et al. [68], including particular applications to industrial control systems [3]. Our wiring
diagram model can be thought of as a graph with extra structure, namely the added structure of
the category. Therefore such methods could also be incorporated into our algebraic security tests
paradigm.

Yoneda Hacking: The Algebra of Attacker Actions

19

From the controls or system behavior view, defenders can intercept the learning phase of at-
tacker actions by adding a privacy-enhancing signal into the controller [39]. From purely mod-
eling, which is more closely related to techniques from reliability and dependability, recent work
aims to merge attack trees with standard design practices for embedded systems [45]. These frame-
works are relevant to one abstraction level, that of system behavior, and could be subsumed by the
categorical formalism we present above. In the future, both the controls and modeling approaches
could be improved within our framework by providing formal composition and traceability be-
tween the expected behavior and the eventual synthesized design.

The intersection of formal methods, control, and CPS security is addressed through diﬀerential
dynamic logic. Diﬀerential dynamic logic has provided a plethora of veriﬁcation capabilities for
the continuous and discrete parts of CPS [57]. Diﬀerential dynamic logic has also been applied
for security modeling [14]. We see diﬀerential dynamic logic as complementary to our framework
and vice versa. Categorical primitives can become part of diﬀerential dynamic logic, while dynamic
logic can provide richer semantics for how the behavior of the whole system changes based on
speciﬁc modeled attacks.

All in all, we perceive applications of category theory to model-based security as relatively
unﬂedged and hope to see category theory used as eﬀectively in security modeling as it has for
programming languages [29, 34, 56, 63] and cryptography [23, 32].

7 CONCLUSION

We develop a categorical semantics for CPS security modeling that can determine that two system
representations are behaviorally equivalent, provided that they agree on every test. This statement
implies that it is possible to model attacker actions without giving the attacker full observability
of the attack system. Additionally, we model two types of attacks on the incomplete but erroneous
view of the attacker and show its impact on (what we consider to be) the existing system. These
attacks can either (1) rewrite some system component or (2) rewire an input or output from or to
a component. This model is beneﬁcial for CPS. In the future, we would like to say how a particular
attack can change system behavior and, therefore, potentially transition it to a hazardous state.
Overall, we model how the attacker learns about a system and how an attacker then might attempt
to hijack the system from the knowledge that they were able to gather in a formal, uniﬁed way.
Finally, the categorical formalism can be considered foundational. In addition to the contributions
above, it can subsume already developed formalisms for modeling attacker actions, such as attack
graphs, or augmenting the information contained in the model by using security frameworks.

ACKNOWLEDGMENTS
The authors thank D. Evans and C. Vasilakopoulou for constructive discussions and feedback.

REFERENCES
[1] L. Ablon, M. C. Libicki, and A. A. Golay. 2014. Markets for cybercrime tools and stolen data: Hackers’ bazaar. Technical

Report RR-610-JNI. Rand Corporation. https://www.rand.org/pubs/research_reports/RR610.html

[2] S. Abramsky and B. Coecke. 2009. Categorical quantum mechanics. In Handbook of Quantum Logic and Quantum

Structures. Elsevier. https://doi.org/10.1016/B978-0-444-52869-8.50010-4

[3] A. T. Al Ghazo, M. Ibrahim, H. Ren, and R. Kumar. 2019. A2G2V: Automatic Attack Graph Generation and Visualization
and Its Applications to Computer and SCADA Networks. IEEE Transactions on Systems, Man, and Cybernetics: Systems
(2019). https://doi.org/10.1109/TSMC.2019.2915940

[4] A. D. Ames. 2006. A categorical theory of hybrid systems. Ph.D. Dissertation. University of California, Berkeley.
[5] Jean Andrian, Charles Kamhoua, Kevin Kiat, and Laurent Njilla. 2017. Cyber Threat Information sharing: A category-
theoretic approach. In Proceedings of the 2017 Third International Conference on Mobile and Secure Services (MobiSec-
Serv). IEEE, 1–5. https://doi.org/10.1109/MOBISECSERV.2017.7886562

20

Georgios Bakirtzis, Fabrizio Genovese, and Cody H. Fleming

[6] Algirdas Avizienis, Jean-Claude Laprie, Brian Randell, and Carl E. Landwehr. 2004. Basic Concepts and Tax-
IEEE Transactions on Dependable and Secure Computing (2004).

onomy of Dependable and Secure Computing.
https://doi.org/10.1109/TDSC.2004.2

[7] John C Baez and Jade Master. 2020. Open Petri nets. Mathematical Structures in Computer Science (2020).

https://doi.org/10.1017/S0960129520000043

[8] G Bakirtzis. 2021. Compositional Cyber-Physical Systems Theory. Ph.D. Dissertation. University of Virginia.
[9] G. Bakirtzis, C. H. Fleming, and C. Vasilakopoulou. 2021. Categorical Semantics of Cyber-Physical Systems Theory.

ACM Transactions on Cyber-Physical Systems (2021). https://doi.org/10.1145/3461669

[10] G. Bakirtzis, B. J. Simon, A. G. Collins, C. H. Fleming, and C. R. Elks. 2019. Data-Driven Vulnerability Exploration for

Design Phase System Analysis. IEEE Systems Journal (2019). https://doi.org/10.1109/JSYST.2019.2940145

[11] G. Bakirtzis, E. Subrahmanian, and C. Fleming. 2021. Compositional Thinking in Cyberphysical Systems Theory. IEEE

Computer (2021). https://doi.org/10.1109/MC.2021.3085532

[12] G. Bakirtzis, C. Vasilakopoulou, and C. H. Fleming. 2020. Compositional Cyber-Physical Systems Modeling. In Pro-
ceedings of the 2020 Applied Category Theory Conference (ACT 2020) (Electronic Proceedings in Theoretical Computer
Science). Open Publishing Association. https://doi.org/10.4204/EPTCS.333.9

[13] G. Bakirtzis, G. L. Ward, C. J. Deloglos, C. R. Elks, B. M. Horowitz, and C. H. Fleming. 2020. Fundamental Challenges of
Cyber-Physical Systems Security Modeling. In Proceedings of the 50th IFIP/IEEE International Conference on Dependable
Systems and Networks (DSN). IEEE. https://doi.org/10.1109/DSN-S50200.2020.00021

[14] B. Bohrer and A. Platzer. 2018.

In
the 33rd Annual ACM/IEEE Symposium on Logic in Computer Science (LICS 2018). ACM.

A Hybrid, Dynamic Logic for Hybrid-Dynamic Information Flow.

Proceedings of
https://doi.org/10.1145/3209108.3209151

[15] G. Boisseau and J. Gibbons. 2018. What you needa know about Yoneda: Profunctor optics and the Yoneda Lemma
(Functional Pearl). Proceedings of the ACM on Programming Languages (2018). https://doi.org/10.1145/3236779
[16] S. Breiner, O. Marie-Rose, B. S. Pollard, and E. Subrahmanian. 2020. Operadic diagnosis in hierarchical systems. In
Proceedings of the 2019 Applied Category Theory Conference (ACT 2019) (Electronic Proceedings in Theoretical Computer
Science). Open Publishing Association. https://doi.org/10.4204/EPTCS.323.5

[17] S. Breiner, R. D. Sriram, and E. Subrahmanian. 2019. Compositional Models for Complex Systems. In Artiﬁcial Intelli-

gence for the Internet of Everything. Elsevier. https://doi.org/10.1016/B978-0-12-817636-8.00013-2

[18] CAPEC 2022.

MITRE Common Attack Pattern Enumeration and Classiﬁcation (CAPEC).

URL

https://capec.mitre.org/.

[19] A. A. Cárdenas, S. Amin, and S. Sastry. 2008. Research Challenges for the Security of Control Systems. In Proceed-
ings of the 3rd USENIX Workshop on Hot Topics in Security (HotSec 2008), Niels Provos (Ed.). USENIX Association.
http://www.usenix.org/events/hotsec08/tech/full_papers/cardenas/cardenas.pdf

[20] B. Coecke. 2010. Quantum picturalism. Contemporary physics (2010). https://doi.org/10.1080/00107510903257624
[21] B. Coecke and É.O. Paquette. 2011. Categories for the Practising Physicist. In New Structures for Physics. Springer.

https://doi.org/10.1007/978-3-642-12821-9_3

[22] J. Culbertson, P. Gustafson, D. E. Koditschek, and P. F. Stiller. 2020.

Formal composition of hybrid systems.

arXiv:1911.01267 [math.CT].

[23] A. Datta, A. Derek, J. C. Mitchell, and D. Pavlovic. 2005. A derivation system and compositional logic for security

protocols. Journal of Computer Security (2005). https://doi.org/10.3233/JCS-2005-13304

[24] A. Datta, J. Franklin, D. Garg, L. Jia, and D. K. Kaynar. 2011. On Adversary Models and Compositional Security. IEEE

Security & Privacy (2011). https://doi.org/10.1109/MSP.2010.203

[25] Z. Diskin, T. Maibaum, and K. Czarnecki. 2015. A Model Management Imperative: Being Graphical Is Not Suﬃcient,
You Have to Be Categorical. In Proceedings of the 11th European Conference on Modelling Foundations and Applications
(ECMFA). https://doi.org/10.1007/978-3-319-21151-0_11

[26] D.

Evans.

2008.

NSF/IARPA/NSA Workshop

on

the

Science

of

Security.

https://web.archive.org/web/20200705152357/https://sos.cs.virginia.edu/.

[27] B. Fong, A. Speranzon, and D. I. Spivak. 2019. Temporal Landscapes: A Graphical Temporal Logic for Reasoning.

arXiv:1904.01081 [math.LO].

[28] B. Fong and D. I. Spivak. 2019. An Invitation to Applied Category Theory: Seven Sketches in Compositionality. Cambridge

University Press.

[29] F. Genovese, A. Gryzlov, J. Herold, A. Knispel, M. Perone, R. Post, and A. Videla. 2020. idris-ct: A Library to do Category
Theory in Idris. In Proceedings of the 2019 Applied Category Theory Conference (ACT 2019) (Electronic Proceedings in
Theoretical Computer Science). Open Publishing Association. https://doi.org/10.4204/EPTCS.323.16

[30] F. Genovese, A. Gryzlov, J. Herold, M. Perone, E. Post, and A. Videla. 2019. Computational Petri Nets: Adjunctions

Considered Harmful. arXiv 1904.12974.

Yoneda Hacking: The Algebra of Attacker Actions

21

[31] F. Genovese and J. Herold. 2019. Executions in (Semi-)Integer Petri Nets Are Compact Closed Categories. Electronic

Proceedings in Theoretical Computer Science (2019). https://doi.org/10.4204/EPTCS.287.7

[32] F. Genovese, A. Knispel, and J. Fitzgerald. 2019. Mapping Finite State Machines to ZK-SNARKs Using Category Theory.

arXiv 1909.02893.

[33] J. Giraldo, E. Sarkar, A. A. Cárdenas, M. Maniatakos, and M. Kantarcioglu. 2017. Security and Privacy in Cyber-Physical

Systems: A Survey of Surveys. IEEE Design & Test (2017). https://doi.org/10.1109/MDAT.2017.2709310

[34] D. Gratzer, G. A. Kavvos, A. Nuyts, and L. Birkedal. 2020. Multimodal Dependent Type Theory. In Proceedings of 35th
Annual ACM/IEEE Symposium on Logic in Computer Science (LICS ’20). ACM. https://doi.org/10.1145/3373718.3394736
[35] M. Halter, E. Patterson, A. Baas, and J. Fairbanks. 2020. Compositional Scientiﬁc Computing with Catlab and Semantic

Models. arXiv:2005.04831 [math.CT].

[36] M. Hennessy. 2005. The security pi-calculus and non-interference. The Journal of Logic and Algebraic Programming

(2005). https://doi.org/10.1016/j.jlap.2004.01.003

[37] C. Herley and P. C. van Oorschot. 2017.

SoK: Science, Security and the Elusive Goal of Security as a Scien-
tiﬁc Pursuit. In Proceedings of the 2017 IEEE Symposium on Security and Privacy (S&P). IEEE Computer Society.
https://doi.org/10.1109/SP.2017.38

[38] A.

Joyal

and R. Street.
https://doi.org/10.1006/aima.1993.1055

1993.

Braided tensor

categories.

Advances

in Mathematics

(1993).

[39] M. J. Khojasteh, A. Khina, M. Franceschetti, and T. Javidi. 2020. Learning-based attacks in cyber-physical systems.

IEEE Transactions on Control of Network Systems (2020). https://doi.org/10.1109/TCNS.2020.3028035

[40] John Lambert. 2015. Defenders think in lists. Attackers think in graphs. As long as this is true, attackers win.

https://perma.cc/6NZ2-A2HY.

[41] C. E. Landwehr. 2012. Cybersecurity: From engineering to science. Next Wave (2012).
[42] E. A. Lee. 2006. Cyber-physical systems – Are computing foundations adequate. Position paper for NSF workshop

on cyber-physical systems: Research motivation, techniques and roadmap.

[43] Tom Leinster. 2014. Basic Category Theory. Cambridge University Press. https://doi.org/10.1017/CBO9781107360068
[44] V. Lesi, Z. Jakovljevic, and M. Pajic. 2020. Security Analysis for Distributed IoT-Based Industrial Automation. (2020).

arXiv:2006.00044.

[45] L. W. Li, F. Lugou, and L. Apvrille. 2018. Evolving Attacker Perspectives for Secure Embedded System Design. In
Proceedings of the 6th International Conference on Model-Driven Engineering and Software Development (MODELSWARD
2018). SciTePress. https://doi.org/10.5220/0006535802870294

[46] S. Libkind. 2020. An Algebra of Resource Sharing Machines. arXiv:2007.14442 [math.CT].
[47] M. Lipp, M. Schwarz, D. Gruss, T. Prescher, W. Haas, J. Horn, S. Mangard, P. Kocher, D. Genkin, Y. Yarom, M.
Hamburg, and R. Strackx. 2020. Meltdown: reading kernel memory from user space. Commun. ACM (2020).
https://doi.org/10.1145/3357033

[48] D. Long. 2020. MBSE: Simple, Complicated, or Complex? https://web.archive.org/web/20200409185640/http://community.vitechcorp.com/index.php/mbse-simple-complicated-or-complex.aspx.

[49] F. Loregian. 2019. Coend Calculus. arXiv 1501.02503.
[50] D. Maynor. 2007. OS X Kernel-Mode Exploitation in a Weekend. Technical Report. Errata Security.
[51] D. M. Nicol, W. H. Sanders, and K. S. Trivedi. 2004. Model-based evaluation: from dependability to security.

IEEE

Transactions on Dependable and Secure Computing (2004). https://doi.org/10.1109/TDSC.2004.11

[52] J. S. Nolan, B. S. Pollard, S. Breiner, D. Anand, and E. Subrahmanian. 2020. Compositional Models for Power Systems. In
Proceedings of the 2019 Applied Category Theory Conference (ACT 2019) (Electronic Proceedings in Theoretical Computer
Science). Open Publishing Association. https://doi.org/10.4204/EPTCS.323.10

[53] M. Pajic, J. Weimer, N. Bezzo, P. Tabuada, O. Sokolsky, and G. J. Pappas. 2014. Robustness of attack-resilient
state estimators. In ACM/IEEE International Conference on Cyber-Physical Systems (ICCPS). IEEE Computer Society.
https://doi.org/10.1109/ICCPS.2014.6843720

[54] D. Pavlovic. 2014. Chasing Diagrams in Cryptography. Springer. https://doi.org/10.1007/978-3-642-54789-8_19
[55] D. Pavlovic. 2015. Towards a science of trust. In Proceedings of the 2015 Symposium and Bootcamp on the Science of

Security (HotSoS 2015). ACM. https://doi.org/10.1145/2746194.2746197
[56] B. C. Pierce. 1991. Basic category theory for computer scientists. MIT press.
[57] A. Platzer. 2020.

foundations of cyber-physical systems.

Logical

Formal Aspects of Computing (2020).

https://doi.org/10.1007/s00165-020-00510-7

[58] P. Schultz, D. I. Spivak, and C. Vasilakopoulou. 2019. Dynamical systems and sheaves. Applied Categorical Structures

(2019). https://doi.org/DOI:10.1007/s10485-019-09565

[59] P. Schultz, D. I. Spivak, C. Vasilakopoulou, and R. Wisnesky. 2016. Algebraic Databases. Theory & Applications of

Categories (2016).

22

Georgios Bakirtzis, Fabrizio Genovese, and Cody H. Fleming

[60] O. Sheyner, J. Haines, S. Jha, R. Lippmann, and J. M. Wing. 2002. Automated generation and analysis of attack graphs.
In Proceedings 2002 IEEE Symposium on Security and Privacy. IEEE. https://doi.org/10.1109/SECPRI.2002.1004377
[61] D. I. Spivak and J. Tan. 2017. Nesting of dynamical systems and mode-dependent networks. Journal of Complex

Networks (2017). https://doi.org/10.1093/comnet/cnw022

[62] Statebox Team. 2019. The Mathematical Speciﬁcation of the Statebox Language. arXiv 1906.07629.
[63] M. Stay and J. Vicary. 2013. Bicategorical Semantics for Nondeterministic Computation. In Proceedings of the 29th
Conference on the Mathematical Foundations of Programming Semantics (MFPS 2013) (Electronic Notes in Theoretical
Computer Science). Elsevier. https://doi.org/10.1016/j.entcs.2013.09.022

[64] A. Strafaci. 2008. What does BIM mean for civil engineers. CE News, Transportation (2008).
[65] B. E. Strom, A. Applebaum, D. P. Miller, K. C. Nickels, A. G. Pennington, and C. B. Thomas. 2018. MITRE ATT&CK:

Design and philosophy. Technical Report MP180360. MITRE.

[66] P. Tabuada, G. J. Pappas, and P. U. Lima. 2002. Composing Abstractions of Hybrid Systems. In Proceedings of the 5th
International Workshop on Hybrid Systems: Computation and Control (HSCC 2002) (Lecture Notes in Computer Science).
Springer. https://doi.org/10.1007/3-540-45873-5_34

[67] Y. Wang and M. Pajic. 2019.

Supervisory control of discrete event

systems

IEEE 58th Conference on Decision and Control

in the presence of
IEEE.
(CDC).

sensor and actuator
https://doi.org/10.1109/CDC40024.2019.9029767

In 2019

attacks.

[68] M. Weber, B. Jin, G. Lederman, Y. Shoukry, E. A. Lee, S. Seshia, and A. Sangiovanni-Vincentelli. 2020. Gordian: For-
mal Reasoning-based Outlier Detection for Secure Localization. ACM Transactions on Cyber-Physical Systems (2020).
https://doi.org/10.1145/3386568

[69] G. Zardini, A. Censi, and E. Frazzoli. 2021.

lection to Control Synthesis.
https://doi.org/10.23919/ECC54610.2021.9654960

In Proceedings of

Co-Design of Autonomous Systems: From Hardware Se-
IEEE.
the 2021 European Control Conference (ECC 2021).

[70] G. Zardini, N. Lanzetti, M. Salazar, A. Censi, E. Frazzoli, and M. Pavone. 2020. On the Co-Design of AV-Enabled
Mobility Systems. In Proceedings of the 23rd IEEE International Conference on Intelligent Transportation Systems (ITSC
2020). IEEE. https://doi.org/10.1109/ITSC45102.2020.9294499

[71] G. Zardini, D. Milojevic, A. Censi, and E. Frazzoli. 2020. A Formal Approach to the Co-Design of Embodied Intelligence.

arXiv:2011.10756 [cs.RO].

[72] G. Zardini, D. I. Spivak, A. Censi, and E. Frazzoli. 2020. A Compositional Sheaf-Theoretic Framework for Event-
Based Systems. In Proceedings of the 2020 Applied Category Theory Conference (ACT 2020) (Electronic Proceedings in
Theoretical Computer Science). Open Publishing Association. https://doi.org/10.4204/EPTCS.333.10

[73] M. Zhu, P. Grogono, O. Ormandjieva, and P. Kamthan. 2014. Using Category Theory and Data Flow Analysis for
Modeling and Verifying Properties of Communications in the Process-Oriented Language Erasmus. In International C*
Conference on Computer Science & Software Engineering (C3S2E 2014). ACM. https://doi.org/10.1145/2641483.2641529

A CATEGORICAL PRELIMINARIES
A.1 Categories

Category theory is a framework to study patterns in mathematics. The fundamental deﬁnition is
the one of a category.

Deﬁnition 6. A category C is composed of:
• A collection of objects, denoted obj C;
• For each pair of objects 𝐴, 𝐵, a collection of morphisms from 𝐴 to 𝐵, denoted Hom C [𝐴, 𝐵].

A morphism 𝑓 in Hom C [𝐴, 𝐵] is usually denoted as 𝐴

𝑓
−→ 𝐵;

• For each object 𝐴, a morphism 𝐴
• For each 𝐴, 𝐵, 𝐶 objects, an operation

id𝐴−−→ 𝐴;

◦𝐴,𝐵,𝐶 : Hom C [𝐵, 𝐶] × Hom C [𝐴, 𝐵] → Hom C [𝐴, 𝐶]

called composition. We usually omit the subscripts and just write 𝑔 ◦ 𝑓 to denote composition.

Composition is also denoted diagrammatically, as in 𝐴

• Finally, we require the following equations to hold for each 𝐴

𝑔
−→ 𝐶 and 𝐶

ℎ
−→ 𝐷:

𝑓
−→ 𝐵

𝑔
−→ 𝐶.
𝑓
−→ 𝐵, 𝐵
(ℎ ◦ 𝑔) ◦ 𝑓 = ℎ ◦ (𝑔 ◦ 𝑓 )

id𝐵 ◦𝑓 = 𝑓

𝑓 ◦ id𝐴 = 𝑓

Yoneda Hacking: The Algebra of Attacker Actions

23

The interpretation we give to categories is the following: Objects can represent systems, states
of a given system, or, in general, entities we care about. Morphisms represent transformations
between these entities. The axioms amount to asking the following.

• For each system 𝐴 there is a “do nothing” transformation, called id𝐴.
• We can compose transformations whenever their domain and codomain match. This cap-
tures the idea of applying transformations sequentially, each transformation acting on the
result of the previous one. We require this composition to be associative.

Example 3. The simplest example of category in this context is Set, the category whose objects
are sets and morphisms are functions between them. For each set 𝐴, id𝐴 is the identity function
from 𝐴 to itself; composition is function composition.

Example 4. Plenty of familiar structures in mathematics can be seen as categories. For instance,
a monoid can be seen as a category with only one object, call it ∗. Any element of the monoid is
interpreted as a morphism ∗ → ∗. The identity on ∗ is the monoid unit, and composition is the
monoid operation. Indeed, categories can be thought of as generalized monoids with many objects.
Other familiar categories include groups and their homomorphisms, vector spaces and linear
maps between them, topological spaces and continuous functions, and the category of states and
transitions between them [25].

In general, the idea is that morphisms are transformations that preserve some properties possessed
by the objects, properties that we care about. So, for instance, if we were to deﬁne a category of
topological spaces, we may require morphisms to be continuous functions or homotopies. If we de-
ﬁne a category whose objects are algebras, we may require the morphisms to be homomorphisms
that preserve the relevant algebraic properties we want to study.

What happens when two objects behave exactly in the same way with respect to the properties

we are interested in? This notion can be categoriﬁed as:

Deﬁnition 7. Given a category C, a morphism 𝐴

𝑓
−→ 𝐵 is called an isomorphism if there is a

𝑓 −1
−−→ 𝐴 such that the following square commutes, meaning that any two paths sharing

morphism 𝐵
the same start and end points deﬁne the same morphism:

𝑓

𝐴

𝐵

id𝐴

𝑓 −1

id𝐵

𝐴

𝑓

𝐵

If there is an isomorphism 𝐴

𝑓
−→ 𝐵, then we say that 𝐴 and 𝐵 are isomorphic, and write 𝐴 ≃ 𝐵.

Remark. Importantly, two isomorphic objects in a category behave exactly in the same way only
with respect to the structure captured by the category. For instance, R and R2 can be seen both as
objects in Set, the category of sets and functions, and as objects in VectR, the category of real vector
spaces and linear maps between them. They are isomorphic in Set, since bijective functions satisfy
Deﬁnition 7 and R and R2 are in bijection. Nevertheless, they are not isomorphic in VectR, since

24

Georgios Bakirtzis, Fabrizio Genovese, and Cody H. Fleming

an isomorphism in this category has to be a linear bijection, which in particular has to preserve
dimension. What is happening here is that since VectR keeps track of more structure than what
Set does, our ability to tell objects apart in VectR is ﬁner than in Set.

A.2 Functors
Functors are morphisms between categories. As we said in the previous section, they should then
preserve the properties we care about when we study categories. Looking at Deﬁnition 6, these
are just identities and composition. Hence, we give the following deﬁnition.

Deﬁnition 8. Given categories C, D, a functor C
𝐹
−→ obj D;

• A mapping obj C
• For each 𝐴, 𝐵 ∈ obj C, a mapping

𝐹
−→ D consists of the following information:

Hom C [𝐴, 𝐵]

𝐹
−→ Hom D [𝐹𝐴, 𝐹 𝐵]

• We moreover require the following equations to hold:

𝐹 (id𝐴) = id𝐹 𝐴

𝐹 (𝑔 ◦ 𝑓 ) = 𝐹 (𝑔) ◦ 𝐹 (𝑓 )

Functors are structure preserving maps that allow us to connect diﬀerent model types by deﬁn-
ing the particular semantics of transformations that are necessary to change the domain of dis-
course (within a particular category, say Set → Set, or between diﬀerent categories, say C → Set).

Remark. In category theory practice it is customary to omit parentheses when not strictly neces-
sary. As such, we will often write 𝐹 𝑓 instead of 𝐹 (𝑓 ) to denote the application of a functor 𝐹 to a
morphism 𝑓 .

Example 5. There is a functor from VectR to Set that “forgets structure”: Any real vector space
is mapped to its underlying set, and any linear map between them is mapped to its underlying
function between sets.

Example 6. As we will see shortly, a very important functor in category theory is the hom-functor:
Fix an object 𝐴 in a category C. Then we can deﬁne a functor

Hom C [𝐴,−]
−−−−−−−−−→ Set

C

Which sends every object 𝐵 of C to the set of morphisms Hom C [𝐴, 𝐵]. A morphism 𝐵
to the function

Hom C [𝐴, 𝐵]

Hom C [𝐴,𝑔]
−−−−−−−−−→ Hom C [𝐴, 𝐶]

𝑔
−→ 𝐶 is sent

Which acts by postcomposing: a morphism 𝐴
from the composition and identity axioms of C.

𝑓
−→ 𝐵 is sent to 𝐴

𝑓
−→ 𝐵

𝑔
−→ 𝐶. Functoriality follows

Functors are also useful to supply a category with an additional operation alongside ◦, which
intuitively models the idea of of considering multiple objects at the same time and performing
transformations in parallel.

Deﬁnition 9. A monoidal category V is a category that comes equipped with a monoidal product
functor

V × V

⊗
−→ V

which can be thought of as multiplication of objects and morphisms, or more broadly as doing
operations in parallel. We require that, for any objects 𝑋, 𝑌 , 𝑍 ,

(𝑋 ⊗ 𝑌 ) ⊗ 𝑍 ≃ 𝑋 ⊗ (𝑌 ⊗ 𝑍 )

Yoneda Hacking: The Algebra of Attacker Actions

25

Meaning that multiplying objects in any order gives isomorphic results.

We also require the existence of a distinguished object 𝐼 of V, called monoidal unit, such that

𝐼 ⊗ 𝑋 ≃ 𝑋 ≃ 𝑋 ⊗ 𝐼

that is, 𝐼 acts like an identity for this multiplication. All this data must satisfy certain axioms [38],
that are beyond the scope of this paper.

Example 7. Widely used examples of monoidal categories include (Set, ×, {★}), with the cartesian
product of sets and the singleton, as well as (VectR, ⊗, R), with the tensor product of vector spaces.
Moreover Cat, the category of categories and functors between them, admits a monoidal structure
(Cat, ×, 1), where tensor is deﬁned as the cartesian product of categories (similarly to that of sets),
and the tensor unit is the category 1 consisting of a single object together with its identity arrow.
In fact, all these are examples of symmetric monoidal categories, which come further equipped

with isomorphisms

𝑋 ⊗ 𝑌 ≃ 𝑌 ⊗ 𝑋 .

For example, for two sets it is 𝑋 × 𝑌 ≃ 𝑌 × 𝑋 via the mapping (𝑥, 𝑦) ↦→ (𝑦, 𝑥).

Now that we deﬁned monoidal categories, that are nothing but categories together with some

additional structure, we have to reﬁne our notion of functor accordingly.

Deﬁnition 10. A monoidal functor between two monoidal categories (V, ⊗V, 𝐼 V)
is a functor that preserves the monoidal structure in a lax sense (meaning not up to isomorphism).
Namely, it comes equipped with morphisms

𝐹
−→ (W, ⊗W, 𝐼W)

𝐹 (𝐼 V)

𝜙0−−→ 𝐼W

𝐹𝑋 ⊗W 𝐹𝑌

𝜙𝑋 ,𝑌
−−−→ 𝐹 (𝑋 ⊗V 𝑌 )

with 𝑋, 𝑌 ranging over the objects of V, that express the relation between the image of the tensor
and the tensor of the images inside the target category W; these adhere to certain axioms [38].

A.3 Natural Transformations

In this work we will also use the fundamental concept of the natural transformation. A natural
transformation models the transformation between functors while preserving structure, otherwise
called morphism of functors.

Deﬁnition 11. Given functors C

𝐹 ,𝐺
−−−→ D, a natural transformation 𝐹

𝜂=⇒ 𝐺 consists, for each

object 𝐴 of C, of a morphism 𝐹𝐴

𝜂𝐴
−−→ 𝐺𝐴 in D such that, for each morphism 𝐴

𝑓
−→ 𝐵 in C,

𝜂𝐵 ◦ 𝐹 𝑓 = 𝐺 𝑓 ◦ 𝜂𝐴.

This is often expressed diagrammatically by saying that the following square has to commute:

𝜂𝐴

𝐹𝐴

𝐺𝐴

𝐹 𝑓

𝐺 𝑓

𝐹 𝐵

𝜂𝐵

𝐺𝐵

26

Georgios Bakirtzis, Fabrizio Genovese, and Cody H. Fleming

Intuitively, the information contained in a natural transformation 𝐹

𝜂=⇒ 𝐺 is enough to guarantee
that any commutative diagram made of images of things in C via 𝐹 can be turned into a diagram
of images of things in C via 𝐺 without breaking commutativity. An example is shown in the ﬁgure
below: The commutativity condition of 𝜂 means that it doesn’t matter in which order we will “walk
through” these arrows, the result will be the same.

𝐹𝐴

𝜂𝐴

𝐹 𝑓

𝐹ℎ

𝐹 𝐵

𝜂𝐵

𝐹𝑔

𝐹𝐶

𝜂𝐶

𝐺𝐴

𝐺 𝑓

𝐺ℎ

𝐺𝐵

𝐺𝑔

𝐺𝐶

A.4 The Yoneda Lemma

The Yoneda Lemma is arguably the most important result in category theory. It follows from a

clever observation: consider a functor C
transformation Hom C [𝐴, −]

𝜂=⇒ 𝐹 has as components functions between sets Hom C [𝐴, 𝐵]

𝐹
−→ Set and an object 𝐴 of C. By deﬁnition, any natural
𝜂𝐵
−−→ 𝐹 𝐵.

Moreover, for each 𝐴
mation:

𝑓
−→ 𝐵, the following diagram must commute because 𝜂 is a natural transfor-

Hom C [𝐴, 𝐴]

𝜂𝐴

Hom C [𝐴, 𝑓 ]

𝐹𝐴

𝐹 𝑓

Hom C [𝐴, 𝐵]

𝜂𝐵

𝐹 𝐵

id𝐴−−→ 𝐴. This is an element of Hom C [𝐴, 𝐴], and Hom C [𝐴, 𝑓 ] sends it
In particular, consider 𝐴
to 𝑓 (which is by deﬁnition an element of Hom C [𝐴, 𝐵]) since it acts by post-composition and
𝑓 ◦ id𝐴 = 𝑓 . Hence, if 𝜂𝐴 sends id𝐴 to, say, 𝑥 ∈ 𝐹𝐴, then 𝜂𝐵 will have to send 𝑓 to 𝐹 𝑓 (𝑥), otherwise
the square will not commute. This reasoning can be repeated for any 𝐵 and any 𝑓 , it follows that
the assignment 𝜂𝐴 (id𝐴) = 𝑥 completely determines 𝜂. So we can have as many diﬀerent 𝜂s as there
are choices to which we can send id𝐴. These are as many as the elements in 𝐹𝐴, and so we have:

Lemma 12 (Yoneda Lemma). There is a bijection1

Nat [Hom C [𝐴, −] , 𝐹 ] ≃ 𝐹𝐴

Where Nat [𝐹, 𝐺] denotes the set of natural transformations between any two functors 𝐹, 𝐺.

1For readers versed in category theory: Hom C [−, −] is a contravariant functor in the ﬁrst component and a covariant
functor in the second. It can be proven that the bijection is natural in 𝐹 and 𝐴.

Yoneda Hacking: The Algebra of Attacker Actions

27

The consequences of Yoneda lemma are far reaching. In particular, the following corollary can

be proven:

Corollary 13. Given objects 𝐴, 𝐵 of C, if it is2

Nat [Hom C [𝐴, −] , 𝐹 ] ≃ Nat [Hom C [𝐵, −] , 𝐹 ]

for any functor C

𝐹
−→ Set, then 𝐴 ≃ 𝐵 in C.

As we already stressed, isomorphic objects in a category behave as if they were the same. Repet-

itively applying Yoneda lemma one gets that

𝐹𝐴 ≃ Nat [Hom C [𝐴, −] , 𝐹 ] ≃ Nat [Hom C [𝐵, −] , 𝐹 ] ≃ 𝐹 𝐵

𝐹
And hence 𝐴 ≃ 𝐵 if and only if 𝐹𝐴 ≃ 𝐹 𝐵 for any C
−→ Set. So, with respect to whatever it is that
we want to capture by deﬁning a category C, the Yoneda lemma aﬃrms that we can completely
characterize an object 𝐴 by studying its images 𝐹𝐴 for any functor 𝐹 to Set.

We heavily rely on this to model attacker learning and interpreting functors to Set as testing

procedures (Section 4). Under this view, we summarize Yoneda lemma as:

If two objects agree under any possible test we can perform,
then they behave the same.

2For readers versed in category theory: This bijection is required to be natural in 𝐹 .

