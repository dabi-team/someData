2
2
0
2

n
u
J

2
1

]

R
C
.
s
c
[

1
v
9
7
6
5
0
.
6
0
2
2
:
v
i
X
r
a

Exploration of Enterprise Server Data to Assess Ease of Modeling
System Behavior

Enes Altinisik, Husrev Taha Sencar∗, Mohamed Nabeel, Issa Khalil, and Ting Yu
Qatar Computing Research Institute

Abstract

1

Introduction

Enterprise networks are one of the major targets for
cyber attacks due to the vast amount of sensitive and
valuable data they contain. A common approach to
detecting attacks in the enterprise environment relies
on modeling the behavior of users and systems to
identify unexpected deviations. The feasibility of this
approach crucially depends on how well attack-related
events can be isolated from benign and mundane
system activities. Despite the signiﬁcant focus on
end-user systems, the background behavior of servers
running critical services for the enterprise is less stud-
ied. To guide the design of detection methods tailored
for servers, in this work, we examine system event
records from 46 servers in a large enterprise obtained
over a duration of ten weeks. We analyze the rareness
characteristics and the similarity of the provenance
relations in the event log data. Our ﬁndings show
that server activity, in general, is highly variant over
time and dissimilar across diﬀerent types of servers.
However, careful consideration of proﬁling window of
historical events and service level grouping of servers
improve rareness measurements by 24.5%. Further,
utilizing better contextual representations, the similar-
ity in provenance relationships could be improved. An
important implication of our ﬁndings is that detection
techniques developed considering experimental setups
with non-representative characteristics may perform
poorly in practice.

∗For further information and questions, please contact
Enes Altinisik (ealtinisik@hbku.edu.qa) or Husrev Taha Sencar
(hsencar@hbku.edu.qa).

Detection of and response to cyber attacks in the
enterprise continue to be challenging despite the vast
array of security solutions available today. The scale
of the enterprise environment in terms of the number
and diversity of end-user devices and the variety of
applications and services, coupled with human fac-
tors that impact security, creates a very wide attack
surface. Signiﬁcant research and development eﬀort
has been devoted to build capabilities that help de-
tect, assess, investigate and respond to sophisticated
attacks such as Advanced Persistent Threats (APTs).
An important focus of enterprise security has been
on developing techniques that combine rule- and
anomaly-based approaches to detect targeted attacks
[1–16]. These approaches can be divided into two
general groups. The ﬁrst group is centered around
the actions of a user by developing models repre-
senting normal user behavior of interacting with sys-
tems [13, 17, 18]. These models are essentially driven
by baseline parameters obtained from observed user
activities on these systems. Inevitably, the success
of such user behavior models depends on three main
factors: how well they can capture dynamics of user
actions, their ability to correctly identify the context
within which the actions are taken, and their capac-
ity to distinguish user behavior from the innocuous
background behavior of the system.

The other group of approaches is more system-
centric and mainly seeks to developing capabilities
that can either identify suspicious patterns in system
execution in relation to previously observed attacker
actions [6, 19–21] or characterize the normal system

1

 
 
 
 
 
 
behavior through developing models [8, 22–24]. More
recently, as part of DARPA’s Transparent Computing
(TC) program [25, 26] a new wave of techniques based
on data provenance analysis has appeared. Such ap-
proaches showed that a causality analysis framework
can also be used to detect anomalies in system ex-
ecution caused by an APT attack. All the above
approaches to enterprise security mainly considered
end-user systems in their analyses as they provide a
convenient entry point into the enterprise network for
attackers.

In principle, such approaches can also be applied
to organizational servers that provide services to the
whole enterprise, although, their dynamic and central
nature requires special consideration. In this regard,
a thorough understanding of the server environment
is key for developing solutions that will be eﬀective in
practice. Moreover, the eﬀectiveness of such solutions
on servers is much more critical than end-user systems
as the value of compromising a domain controller or a
database server is much higher and accessing servers
is among the end-goals of an attacker. To address this,
the TC program generated much needed datasets in
the ﬁeld that simulated the enterprise environment
by also including some security-critical services such
as WEB, SSH, and Exchange servers in addition to
end-host systems. However, the benign state of the
systems was generated by running a scripted set of
activities on each server. One drawback of this is that
it makes it relatively easy to model benign behavior
as it does not represent the actual server behavior in
terms of the amount of workload, types of activity, and
variety of applications, thereby creating a favorable
scenario for detecting traces of an attack.

In fact, one of the major obstacles in enterprise
security research is the lack of realistic and up-to-date
datasets to facilitate the design and evaluation of new
methods [27]. Given the challenges of obtaining ac-
tual enterprise data that can drive research, a feasible
solution is to create realistic synthetic data. This
essentially requires accurately proﬁling the execution
behavior of servers to create formal models that can
be used in the generation of synthetic datasets. As
an example, the widely used CERT dataset [28] used
for insider threat detection is aimed at simulating
human behavior based on observations made by ear-

lier work on the network and host events in a large
enterprise [29–31]. The ability to create such datasets
with a high degree of realism requires extending such
measurements to servers as the most important com-
ponents of an enterprise network.

With these motivations, in this work we study sys-
tem audit data obtained from 46 servers in a large
organization. The data under investigation spans a
ten-week period and includes various aspects of activ-
ities performed by both administrator and standard
users on those servers. Our observations show that
servers exhibit quite a high variation in their behav-
ior depending on the services they are running. In
this regard, user logins to systems do not exhibit an
apparent pattern on most servers which indicating
the diﬃculty of modeling logon behavior. Our analy-
sis of the server data with respect to the rareness of
observed events and the similarity of the created prove-
nance graphs representing system activity [32,33] over
time further supports this ﬁnding. In terms of system
activity, it is determined that on average 90%, 60%,
30%, and %15 of the registry, ﬁle, process, and net-
work events, respectively, are encountered for the ﬁrst
time when event occurrences are evaluated with re-
spect to previous weeks. The graph similarity between
weekly generated provenance graphs, assessed using
a histogram similarity measure based on subgraph
representations of 2-hop node neighborhoods [2, 8],
is found to be on average 29% with the highest in-
dividual value being 65%. Overall, this work brings
to light a less examined side of server activity in an
enterprise.

Our paper is organized as follows. In the next sec-
tion (§ 2), we provide a description of what our data
comprises and discuss the categorization of servers.
We then provide statistics on users’ logon activity
(§ 3.1) and examine how ﬁle, process, network, and
registry operations vary across these categories over
time across servers (§ 3.2). Results for the analysis
of data in terms of rareness of events (§ 4.2) and self-
similarity of provenance graphs (§ 4.3) are provided
next (§ 4). The paper is then concluded with a dis-
cussion of ﬁndings that may guide further research in
this ﬁeld.

2

2 Enterprise Server Log Data

To understand and study the enterprise server envi-
ronment, we used event logs containing records of
activities carried out by a variety of servers in a large
healthcare organization. The log data was collected
over a period of 10 weeks in early 2019 from 46 physical
systems. These servers perform 23 diﬀerent services
that are widely used in and essential for the enterprise
environment with some services running on multiple
servers such as WEB servers, exchange servers, do-
main controllers, and database servers. The collected
log data are intended to support auditing and cy-
ber security incident investigations and archived in a
central log storage system.

2.1 Source and Composition of Logs

All the servers in the organization run Windows oper-
ating system (OS), one of the most commonly used
server OS worldwide [34]. Windows provides two
powerful system services to collect event logs, called
Event Tracing for Windows (ETW) and System Mon-
itor (Sysmon). ETW is a built-in tracing facility to
log kernel, application, and system activities for diag-
nostic purposes. It can provide extensive information
about the runtime state of a system and might be
conﬁgured to collect event logs from selected sources.
Sysmon is the other system service focusing primar-
ily on the collection of security-related events that
are widely used for threat detection and forensics pur-
poses [35]. It is provided as a system utility tool by
Microsoft and must be installed independently. Since
Sysmon is mainly developed for security monitoring,
its logs provide a richer description of the event con-
text than the Windows event logs provided by the
ETW. For example, a process creation event can be
logged by both ETW (event ID 4668) and Sysmon
(event ID 1), however, the hash of the process and
command line arguments to the parent process are
readily available only in the latter.

The logs collected by these services provide detailed
information about user logons, process creations, net-
work connections, ﬁle operations, and registry opera-
tions. Computing systems can generate huge volumes
of log data, and this imposes a signiﬁcant storage

and analysis challenge, especially for large-scale enter-
prises such as the one under examination. Therefore,
to maintain the long-term investigation capability,
event logs deemed not to be related to security inci-
dents are typically ﬁltered out before being sent to the
central security information and event management
(SIEM) system.

Our event log data are generated using both ETW
and Sysmon and include activities of 18 system admin-
istrators and 1,580 standard users performed on these
servers during the 10-week period. To avoid redun-
dancy in collected event data, both collection services
are conﬁgured to selectively monitor diﬀerent kinds
of activities. In our environment, user logon/logoﬀ
events are collected by ETW and all network and
registry events are logged via Sysmon. Process and
ﬁle events are monitored using both services.

The organization also implements ﬁltering of event
logs to eliminate mundane or benign system activities
and to reduce the amount of data that needs to be
stored. For this purpose, ETW is conﬁgured to collect
process activity related to administrators and opera-
tions on ﬁles located in selected system and applica-
tion directories. By contrast, logon and logoﬀ events
are collected without any ﬁltering. Sysmon events are
collected after application of a rule set [36] that is
extensively deployed by organizations [37, 38]. These
rules are mainly designed to improve the visibility of
unusual system activities and are derived from inci-
dent reports. Accordingly, most of the process events
commonly related to Windows system as well as those
related to regular activities are eliminated, and only
non-standard process events are logged. That is, im-
portant process and ﬁle activities are largely preserved.
By contrast, network and registry activities are logged
more conservatively as they contribute signiﬁcantly to
the overall volume. In this regard, network activity is
logged only if the path or name of the source process is
deﬁned as possibly suspicious or if the destination port
is associated with a potentially harmful application.
Similarly, due to the extensive amount of registry
events in normal operation, only write activities on
selected registry entries are monitored.

The trade-oﬀ imposed by the need to perform long-
term analysis and the ﬁltering of event logs ultimately
brings with it the risk of missing attack activities

3

and limits the forensic utility of data. However, the
need to reduce log data is inevitable in the enterprise
environment with possibly thousands of host systems
and tens of servers to ensure that records can support
future investigations. Overall, our enterprise log data
includes all the critical process and ﬁle-related event
logs essential for analysis. Further, since the servers
are deployed within the enterprise network to provide
internal users with well-deﬁned tasks, they inherently
have limited external network interactions compared
to end-user systems.

2.2 Categorization of Servers

An analysis of logs at the server level will not be
feasible due to the number of servers. Therefore,
we consider grouping them to explore their behav-
ior categorically. An end-user system’s behavior is
mainly determined by the diversity of user actions,
and a degree of similarity among hosts is expected
depending on the user’s role and the functional unit in
the enterprise they belong to. In contrast, a server’s
behavior is diﬀerentiated by the service it provides
and the interactions with users of this service. Since
at the service level each server will be more or less
unique, the basis of categorization must be the latter.
From the user perspective, some servers may require
application-level authentication whereas others may
involve operating-system-level authentication. These
two modes of operation will have a diﬀerent reﬂection
on the event logs, with the latter leaving more visible
traces on the system execution.

Hence, considering activities of administrator and
standard users, we group servers into three categories
as displayed in Table 1. To diﬀerentiate between
administrator and standard users, we used process
creation events logged by both Sysmon (event ID 1)
and ETW (event ID 4688) together. In our environ-
ment, the latter was conﬁgured to only log activity
by administrator users, thereby making it possible to
identify user roles. The ﬁrst group includes 26 servers
that mainly run core infrastructure services as well
as those that perform central services. These servers
typically require application-level authentication for
all users. Therefore, standard users do not need to
logon to these systems, and user activity can only be

discriminated through application logs. The second
category includes task-oriented servers used by a small
subset of standard users who connect these systems
remotely and run interactive sessions. This category
includes 12 servers that are used for development and
testing of diﬀerent enterprise applications and those
that support them. User activities on these servers
are expected to be similar to those on end-user sys-
tems. The last category includes the remaining eight
servers that run mission critical services for the enter-
prise network. All users need to frequently interact
with these systems, typically, through non-interactive
logons. In common, all these servers are maintained
by a group of administrator users that access these
servers to perform administration and conﬁguration
tasks.

The three categories of servers listed in Table 1 (ﬁrst
column) largely overlap with an energy consumption-
based categorization of servers with ﬁrst category
servers consuming the least energy followed in order
by the servers in the two other categories [39]. It must
be added that the 46 servers comprise 23 diﬀerent
services with 1-4 instances for each type of server.
Those servers with multiple instances in some cases
support diﬀerent applications, such as the WEB and
SQL servers, and in others they are located at diﬀerent
physical locations of the enterprise, such as the domain
controllers (DCs) and some development servers. In
this regard, WEB and SQL servers deliver services for
diﬀerent applications and DC and some development
servers are deployed at diﬀerent physical locations of
the enterprise. Finally, it must also be noted that
some types of servers appear in diﬀerent categories as
they exhibit diﬀerent user-access patterns.

3 Overview of Server Activity

We provide an overview of user activity on servers in
terms of the number and duration of logon sessions as
well as how the number of process creations, ﬁle opera-
tions, network connections, and registry modiﬁcations
varies across servers over time.

4

Table 1: Distribution of servers across three diﬀerent
categories based on access pattern of administrator
users and standard users.

Name

Abbreviation

Access
Pattern

Systems Group Infrastructure
Structured Query Language
Key Management Service
Quality Management Test
Endpoint Security Solution
WEB
SQL Developer (DEV)
Application
Dynamic Host Conﬁguration Protocol
Production
Backup
Oﬃce Online Server
SharePoint (SP) Production Application
CISCO Performance Visibility Manager
SharePoint Developer
User Acceptance Testing
WEB Data Management
Backup
Production Web
Local Administrator Password Server
Production
SharePoint Production Application
Mail Exchange
System Center Conﬁguration Manager
Domain Controller
File Server

STG
SQL
KMS
QMTEST
ESS
WEB
SQLDEV
APP
DHCP
PROD
BKP
OOS
SPPRODAPP
CPVM
SPDEV
UAT
WEBDM
BKP
PRODWEB
LAPSVR
PROD
SPPRODAPP
EX
SCCM
DC
FILESVR

/

s
n
i
m
d
A
y
l
n
O

/

s
r
e
s
U
e
m
o
S
&
s
n
i
m
d
A
/

s
r
e
s
U

l
l

A

1

y
r
o
g
e
t
a
C

2

y
r
o
g
e
t
a
C

3

y
r
o
g
e
t
a
C

# of
Servers
2
4
1
1
4
4
2
3
1
1
1
1
1
1
3
1
1
1
2
1
1
1
2
1
4
1

3.1 Logon Statistics

Since a server must respond to user actions and re-
quests, the access behavior of users determines the
level of system activity. Users can log on to servers
through many methods depending on what task they
will perform. However, unlike in end-user systems
where most logons are performed locally, servers are
mostly accessed from the network. Our examination
of the logon types revealed that almost all server
logons are network logons.

The logon behavior of users of end-user systems is
successfully utilized to detect attacks that leverage
compromised credentials or insider threats [12, 18, 40,
41]. These approaches need to be further comple-
mented with user logon patterns to servers. Hence,
to evaluate the logon behavior, we compute three
measures from the server logon records of users. In
doing this, we excluded all logons that were made by
service accounts (such as a Web server account that
regularly logs on to an SQL server) and only included
logons of actual users in the enterprise. These include
the number of times a speciﬁc user logs on to a server

5

Table 2: Average Weekly Logon Statistics for Three
Server Categories

Server
Type

Category
1
Category
2
Category
3

User
Type

Standard
Admin
Standard
Admin
Standard
Admin

Avg. No. Logons Avg. No. Total
Distinct Users
-
0.84
1.85
0.99
1,219
14.99

Per-User
-
9.68
37.7
11.95
173.25
247.15

Avg. Logon
Duration (mins)
-
7.82
17.57
21.38
4.07
4.02

on average per week, the average number of distinct
users who logon to each server per week, and dura-
tions between logon and logoﬀ. Since system activity
may vary signiﬁcantly from day to day, we performed
the analysis at the weekly resolution where activity is
expected to remain relatively stable across weeks.

Values obtained for each measure by averaging
across all servers in the three categories are given
in Table 2. Most notably, these results show that
in the ﬁrst two categories, administrators log on to
servers around once a week with each logon session
lasting for 7-17 minutes. For the third category, this
number increases to almost 34 logons per day, though
for shorter durations. This trend also holds true for
standard users. This may be explained by the more
central role of this group of servers in daily activities,
which includes access to ﬁle and exchange servers.
It must also be noted that the number of logons to
servers is typically much higher than end-user sys-
tems. This can be attributed to the fact that these
are mostly non-interactive logons performed by user
applications on behalf of the user to access shared
resources and use common services. Another inter-
esting ﬁnding is that administrators log on to these
servers more frequently than standard users, indicat-
ing that this category of servers requires more regular
monitoring and maintenance.

Fig. 1 displays the variation of these measurements
over time. The highest variance is observed in the
second category since these servers are mainly used
for innovation activities. This is followed by the ﬁrst
category of servers that only includes administrator lo-
gons, and measurements show that their activities on
these servers show signiﬁcant variation over time. In
contrast, the variance is relatively low for the third cat-
egory as a very large number of users regularly access

Figure 1: Weekly logon statistics over the weeks.

these servers. These variations concerning adminis-
trators and standard users in the ﬁrst two categories
can be attributed to the varying nature of their daily
tasks. This essentially means user behavior cannot
be solely modeled based on historic data in a reliable
manner. Therefore, attack detection systems need to
incorporate other auxiliary information about user
activities when assessing abnormal behavior. We also
explored how logon statistics vary during work and
oﬀ-work hours. We determined that user logons don’t
show a signiﬁcant variation during the day for servers
in the last category. For the other two categories,
most of the logon events take place during work hours
as expected.

Figure 2: Sever activity measured in terms of process,
ﬁle, network, and registry operations across weeks

the service oriented nature of these servers with few
out-of-routine processes running on them. Finally,
we determine that except for the second category of
servers, system activity does not show signiﬁcant vari-
ation across day and night. For the third category
of servers, this indiﬀerence is most likely due to the
inclusion of activity related to system accounts which
perform most of the tasks on the system.

4 Analysis of Audit Data

3.2 System Activity

Next, we examine the number of operations related
to processes, ﬁles, network connections, and registries
performed on each server. All measurements concern-
ing system activity are obtained considering all users
in the system, including system accounts as well, to
have a more holistic view. Fig. 2 shows the variation
in system activity across the three categories of servers.
In all cases, ﬁle operations dominate the overall ac-
tivity. This is followed by network operations in the
servers comprising the ﬁrst and the third categories.
In the second category of servers, however, ﬁle oper-
ations are followed by process creations in line with
strong developer activity performed on these servers.
We also observe that in the third group, ﬁle operations
and network connections closely follow each other. In
addition, the least number of process creation events
are observed in this category of servers. This indicates

Enterprise system data have been analyzed for two
main aspects. The ﬁrst is a user-centric analysis to
mainly detect insider threats and system compromises.
This approach uses features obtained from user ac-
tivities such as logons, ﬁle accesses, and network con-
nections to create an individual or role-based baseline
model and to capture large deviations [15, 16, 42, 43]
and outlier events [18, 44–46].

The other aspect is system-centric and involves the
analysis of system logs to identify anomalous events
at the system level. One approach in this direction is
based on learning the complex causal relationships be-
tween log entries through dependency-analysis meth-
ods [9,47,48]. To facilitate better causality assessment,
more recently data provenance analysis gained signif-
icant attraction. In this approach, system logs are
parsed into provenance graphs to analyze the rela-
tionship between system events and to create a more
holistic view of system execution [49]. Since a graph

6

representation allows a better basis for contextual
analysis, several methods have been proposed to de-
tect anomalous events in provenance graphs either
through identifying rare occurrences [22, 23, 50] or
based on clustering of sub-graph sketches for outlier
detection [2, 8].

Although most of these analysis methods are mainly
developed considering end-user systems, they can in
principle be applied to server data. The server envi-
ronment, however, provides limited visibility of overall
user activities as compared to end-user systems, and
thus, server data is of lesser utility for detection of
anomalies in user behavior when considered alone.
Therefore, in our exploration, we adopt ideas from
provenance and causality analysis approaches to eval-
uate the variation in server activity over time and
across servers.

We must note here that although our enterprise
deploys several state-of-the-art host- and network-
based security solutions to protect against attacks,
the collected server logs may nevertheless include at-
tack events. To further validate this, we applied sigma
signatures [51] to event logs from all servers to verify
that no attack events were present. Although it is pos-
sible that these measures missed some attack-related
events, it is very unlikely that all the servers would be
aﬀected by such activity during the whole duration of
data collection. In this regard, our analysis should be
expected to provide the general degree of variability
and self-similarity of activity in servers. The inherent
consistency in activity is particularly relevant in the
context of detecting changes in system behavior as
any change below the level of normal variation cannot
be reliably detected. This is an important considera-
tion in detecting APT type attacks which are often
slow and stealthy and usually evade existing security
solutions.

4.1 Representation of Log Data

Our analysis starts by mapping server log data into
a provenance graph representation. System audit log
events, whether obtained through Sysmon or ETW,
follows a basic form that can be simpliﬁed as a 3-
tuple (subject, relation, object) where the subject is
a process, object may be another process or one of

the ﬁles, registries, or networks sockets, and the re-
lation is the system call that shows the interaction
of subject with objects, such as read, write, or mod-
ify, depending on the object’s context. A provenance
graph essentially represents the execution of a system
by mapping such 3-tuples representing events into a
heterogeneous graph where nodes represent objects or
subjects and edges are the relations [2, 49, 52]. These
nodes are further annotated with attributes available
in the event logs, such as timestamps, process IDs
and port numbers. On the graphs, processes and ﬁles
are represented by their paths, network objects by
their source and destination IPs, and registry objects
by their keys and subkeys. Also, to eliminate server
speciﬁc information, host and user names are removed
from paths of processes and ﬁles by replacing them
with generic identiﬁers. The edges in the graph are
directed to show the direction of information ﬂow,
and the graph is acyclic because edges are added only
when new nodes are created.

4.2 Rareness of Events

Rare events in system execution are typically indica-
tive of a problem in the system. Therefore, the
rareness of system events has been used to detect
potential anomalies in system behavior by prioritizing
analysis of those events. The feasibility of this ap-
proach crucially depends on the assumption that the
number of events that occur infrequently is few. That
is, encountering many rare events in a system curtails
the eﬀectiveness of this approach in practice. With
this perspective, we use the occurrence frequency of
events as one measure to proﬁle server activity.

Rareness of an event can be deﬁned in several ways.
All deﬁnitions, however, rely on a historic time period
that reﬂects the normal operation of a system to
compute a baseline for the commonly occurring events.
[22,23,50,53] For more reliable assessment of rareness,
the event context can also be incorporated by assessing
the fan-in and fan-out activity related to each subject
and object of an event on a provenance graph [22, 23,
50]. To exploit the presence of multiple similar hosts
and to better deﬁne normality, the evaluation can
be performed also taking into account the number of
hosts that encountered a particular event [22, 50].

7

In our examination of the data, we adopted these
approaches of these works. However, since the log data
is partly ﬁltered, the complete provenance graphs of
systems cannot be obtained. This may prevent correct
evaluation of the context of an event as some nodes
and edges in the graph are missing. Therefore, so
as to not introduce a bias in rareness measurements,
event frequencies are not weighted using fan-in and
It must,
fan-out structures of nodes in the graph.
however, be noted that ﬁltering does not aﬀect the
frequency of observed events.

4.2.1 Event Frequencies

The ﬁrst measure calculates the rareness score of an
event as the inverse of the number of time epochs,
such as weeks, in which this event occurs on every
server running the same type of service during a des-
ignated reference time period [22]. For this, the data
from 46 servers are divided into 31 groups based on
the service they run and their physical location in
the organization, obtained from server naming con-
ventions of the enterprise. Than the rareness score of
an event is computed as

r(e) = 1 −

(cid:80)W

i=1
(cid:80)W

i=1

(cid:80)S

j=1 Ie
j=1 1

(cid:80)S

(1)

where W in the ﬁrst sum refers to the total number
of weeks in the training period; S in the second sum
represents the number of servers in a group taking the
value of one or two in our data; and Ie is an indicator
function that takes the value of 1 if an observed event
occurred at least once during week i on server j. It
must be remembered here that the 46 servers provide
23 diﬀerent services with up to four servers running
the same service. In our grouping, servers operating
at diﬀerent physical locations of the enterprise are
held separate as they serve diﬀerent organizational
units. We further discuss in §5 how observed behavior
changes depending on the grouping of servers.

Here, regardless of the frequency of an event in a
week, it is only counted once since repetitive activities
will yield low rareness scores even though they may
appear only during a very short duration of time. For
each week from the ﬁfth to the tenth, the rareness

8

scores of events are calculated while the data from all
previous weeks are set apart to serve as a reference
model.

Fig. 3 provides the rareness scores obtained from all
servers in a combined manner. The ratio of previously
unseen events, i.e., those with rareness score of 1, to
the overall number of events are given in Fig. 3(a)
considering diﬀerent event types for an increasing
reference time period. To better characterize this
trend, we repeated the measurements on each of the
ten weeks while treating the neighboring weeks as the
reference time period and obtaining an average. For
a given week, when the number of preceding weeks
was less than what is needed for the reference period,
data from the upcoming weeks were used. As can
be seen in this ﬁgure, over a training period of four
to nine weeks (W in Eq. 2), a great majority of ﬁle
and registry events have not been seen during the
reference time period and around 15% of the network
events and 30% of the process events remain quite rare.
Since during its operation, a system is expected to
access many diﬀerent registries and ﬁles, this ﬁnding
is reasonable.

What is more noteworthy is that increasing the
reference time period to several weeks causes only a
very slow and almost linear reduction in the ratio of
rare events. It must be noted, however, that observed
rare event ratios would have been much lower if event
ﬁltering was not applied. Elimination of commonly
occurring and mundane system tasks causes an overall
decrease in the number of events, thereby increasing
the visibility of rare occurrences. Moreover, ﬁltering
rules are mainly tuned to capture and log suspicious
events, which results in relatively high numbers of
rare events.

Therefore, the number of events with high rareness
scores, rather than the ratio, is more relevant in prac-
tice as it is expected to correlate with the number
of cases that will potentially require further investi-
gation. Event rarity distributions for diﬀerent event
types obtained from all servers are given in Fig. 3(b).
These rareness scores are computed by retaining event
logs of the ﬁrst nine weeks as reference and assess-
ing if and how frequently events of the last week are
observed during this training period. Measurements
show that events with high rareness scores constitute

(a)

(b)

(c)

Figure 3: Rareness scores computed based on event occurrences observed during the reference time period.
(a) The ratio of previously unseen events to all events for diﬀerent types of events when the reference time
period varies between 4 and 9 weeks. The scores reﬂect averages obtained by testing over all weeks. (b)
Distribution of the rareness scores when the ﬁrst nine weeks are used as a reference window and the tenth
week is used for testing. (c) The ratio of previously unseen events to all events for each of the 46 servers in
the three categories.

a large part of all events with those relating to ﬁle
operations forming the majority. Accordingly, there
are more than 250K ﬁle operations that were not
encountered in previous weeks. A more critical as-
pect concerns the process activity as it is central to
the analysis of system behavior and anomaly detec-
tion. We determine that previously unseen processes
are only around 200 which ultimately is a reasonable
number for investigation.

We further examine to see how rare events are
distributed across servers. Fig. 3(c) shows the ratio
of rare events with a score of one to all events for
increasing duration of the reference period. As can be
seen in this ﬁgure, some servers are more prevalent in
their behavior. In fact, our analysis revealed that 89%
of the unseen events are sourced from ﬁve servers that
perform many ﬁle operations, including a ﬁle server,
a backup server, and three servers related to deployed
endpoint security solution. In contrast, we determined
that task speciﬁc servers such as SQL or WEB servers
yield very low rareness scores. Overall, these results
show that using ﬁle or registry events at server side
is going to induce a large variation to the model as
more than 60% of their events are new in the following
week, whereas this number is quite low for process
and network events. So, when modeling behavior,
changes related to those latter events should be more

substantially reﬂected in the evaluation methodology.

4.2.2 Contextual Rareness

As an alternative to measuring the frequency of an
event, i.e., the 3-tuple of (subject, relation, object),
among all events that occurred in a server, we also
evaluated rareness of an event in the context of sim-
ilar events with matching (subject, relation) couple.
In other words, we assess how commonly a process
performs a given task in general as opposed to on a
speciﬁc object. This measure computes occurrence
probability P (e) of an event e within a more speciﬁc
context as the ratio of the number of weeks a speciﬁc
event is seen to have occurred to the number of weeks
the particular subject performs the same relation on
all objects during the training period [23]. This oc-
currence probability, P (e), is subtracted from 1 to
obtain a rareness score r(e) thereby assigning higher
scores to increasingly rare events as

r(e) = 1 −

(cid:80)W

i=1

(cid:80)W

i=1

(cid:80)S

(cid:80)S

j=1 Ie
j=1 Ie(cid:48)

(2)

considering a W -week training period and assuming S
servers are present in the same group. Similar to Eq.
(1), the indicator functions Ie and Ie(cid:48), respectively,
denote the occurrence of a speciﬁc event deﬁned as

9

contextual information of each node in the graph,
the subtrees of each node at varying depths are con-
sidered [2, 8]. To this end, each node is combined
with its incoming edges in a time-sorted manner along
with their source nodes into a compact representation.
This process is repeated iteratively until reaching the
desired path depth that covers larger neighborhoods
rooted at a node as demonstrated in Fig. 5. Over-
all, this yields a subgraph representation that can
be assigned labels to create a histogram character-
izing a server’s behavior. To evaluate the similarity
among histograms, we use the normalized min-max
similarity [54] as a measure.

a 3-tuple and any of similar events represented by
the corresponding 2-tuple, respectively. Fig. 4(a)
shows the distribution of obtained rareness scores
for event data collected in the 10th week while using
the previous nine weeks as the reference time period.
This measure also shows that there are many events
with very high rareness scores. More speciﬁcally, this
indicates that many processes are very active and
touch many objects in all weeks.

To add better contextual information, one can al-
ternatively examine event chains with low occurrence
probability [23]. For this, we examined rareness scores
of chains including two connected events that can be
obtained in terms of event occurrence probabilities
similar to Eq. (2), i.e., 1 − P (e1)P (e2) for two arbi-
trary events e1 and e2. Fig. 4(b) displays the corre-
sponding distribution of rareness scores. Accordingly,
the number of event chains with rareness score higher
than 0.90 is determined to be 441, out of which 434
were completely unseen. This indicates that taking a
chain of events into account yields a more favorable
context for analysis.

(a)

(b)

Figure 4: Distribution of rareness scores for (a) events
and (b) event chains in tenth week when using the
ﬁrst nine weeks as the reference time period.

4.3 Similarity of Provenance Graphs

Another approach to analyze server behavior is based
on evaluating the structural similarity of the prove-
nance graphs generated from event logs of a server.
The change in provenance graphs over time provides
another aspect of the variability of a server’s behav-
ior. For this, we create a histogram representation
of provenance graphs and assess the degree of simi-
larity among those histograms. In order to capture

Figure 5: Depiction of how subgraph representations
are obtained. The green circles represent nodes or
0-hop node neighborhoods, orange circles represent
1-hop node neighborhoods, and the 2-hop node neigh-
borhood is represented by the blue circle.

We obtained these subgraph representations span-
ning 0- to 3-hop node neighborhoods and created
histograms of daily and weekly activities of servers.
Computed similarities between histograms created for
subsequent days and weeks are given, respectively, in
Figs. 6 and 7. Accordingly, average similarity consid-
ering 0-hop and 1-hop node neighborhoods over all
servers shows a similar trend, and for the 1-hop case
the similarity at the weekly level is measured to be
around 40% which is in line with our earlier ﬁndings
in Figs 4(a) and 3(b) which show that 47% of events
encountered every week have a rareness score of one.
In the case of 1- to 3-hop neighborhoods, however,
measured similarities decrease for most of the servers.
It must be remembered here that due to the ﬁltering of
audit data, we can only generate partial system prove-

10

nance graphs. Hence, for increasing hop counts the
number of labels in the histograms decreases for some
of the servers. To more reliably observe the similarity
of system activity, we identiﬁed eight servers 1 with a
large number of labels computed both at the daily and
weekly levels. Table 3 provides the average similarity
scores obtained from multi-hop neighborhoods con-
sidering all the servers and the selected eight servers.
It can be seen that as more contextual information
is captured (with each histogram label corresponding
to a larger neighborhood of nodes in the provenance
graph) the similarity unsurprisingly decreases. There-
fore, when more static environments are considered,
where the background behavior is more stationary
such as the Engagement datasets of the DARPA’s
TC Program, larger hop-count neighborhoods may be
more preferable as dissimilar events will be more visi-
ble. For environments like ours, using a low hop-count
yields more similarity, thereby making analysis easier.
It is also found that the eight servers exhibit a more
similar behavior than others. This can be attributed
to the fact that these servers perform more regular
tasks.

Table 3: Average Min-Max Similarities for Subgraphs
for Varying Sizes in Hop-Counts

Hop
Count
0
1
2
3

Weekly

Daily

46 Servers
47
37
29
15

8 Servers
52
46
35
20

46 Servers
44
38
29
7

8 Servers
58
55
38
24

To assess the impact of the length of the reference
time period, labels obtained from two subsequent
weeks are combined together and the similarity of re-
sulting histogram is evaluated with that of the follow-
ing week. This resulted in a slightly decreased overall
similarity as the ratio of rare events has relatively
increased. To also evaluate changes due to concept
drift, similarity scores are measured by skipping weeks
between training and testing weeks. By leaving a gap
of eight weeks between the two, we determined that

1These servers include four database servers (SQL), a ﬁle
server (FileSVR), two Exchange servers (EX), and an authenti-
cation server (LapSVR).

Figure 6: Daily min-max similarity for (a) 0-hop, (b)
1-hop, (c) 2-hop, and (d) 3-hop node neighborhoods
of all servers.

the overall similarity reduced to 30%.

Another important point is the similarities between
servers running the same service. For 15 groups of
servers (out of 31) that include two servers, similari-
ties are evaluated for the same weeks. This yielded
an average similarity of 17% which shows that despite
oﬀering the same service, individual server activity
diﬀers noticeably. Since ﬁle events contribute signiﬁ-
cantly to the variation in activity in each group, we
also examined the similarity only in the context of

11

guide the development of better analysis methods of
server data.

Impact of Event Filtering: Filtering of log
events during data collection limits our visibility on
the overall server activity. For example, the dataset
collected from the real end-user systems in [22] shows
that, on average, a machine generates up to millions
events per day. However, this number decreases to
around 4 thousand for our dataset, mostly because
of the ﬁltering process. However, the storage require-
ments for generated logs from potentially thousands of
systems force enterprises to accept a trade-oﬀ between
reducing the utility of log data and maintaining a long-
term analysis capability to investigate past incidents.
The problem of reducing system audit data while
preserving the forensic utility is in fact an open re-
search problem with some proposed solutions [55–59].
In practice, however, enterprises rely on public rule
sets [36, 51, 60] or implement their own log collection
policies by selectively capturing what they identify as
more critical.

In relation to our analysis of log data, the reduction
operation cannot induce a rarity in the system. That
is, if an event is observed once, its later occurrences
are guaranteed to be captured. Therefore, our ﬁnd-
ings on rareness of events may only miss some other
rare events that were not logged by system utilities.
In the case of similarity of server activity, the elimina-
tion of system events prevents us from observing the
full scope of provenance relations in the data. This
results in a reduced overall similarity as some common
events cannot be taken into account. Nevertheless, a
large degree of dissimilarity among histogram labels
obtained from partial provenance graphs shows that
the server activity is quite non-stationary.

Leveraging Logon Statistics: Several studies
proposed anomaly detection methods to identify the
change in a user’s logon activity pattern [12,16,23,61].
Since users perform most of their activity on dedi-
cated end-user systems, they perform fewer logons
that last longer durations. Our ﬁndings show that
logon patterns on servers vary signiﬁcantly from this
behavior with the frequency of logons changing be-
tween once an hour to a week or even a month and
each logon session lasting seconds to hours depending
on the server type. The correct modeling of logon be-

Figure 7: Weekly min-max similarity for (a) 0-hop, (b)
1-hop, (c) 2-hop, and (d) 3-hop node neighborhoods
of all servers.

process activity. This resulted with an average sim-
ilarity of 48% which further supports the idea that
these servers operate diﬀerently within the enterprise.

5 Discussion of Findings

So far we have analyzed the system audit data to un-
derstand logon behavior and system execution activity
of servers. Below, we further examine our ﬁndings to

12

havior on servers is in fact very critical as the shared
resources and services hosted by servers are of high
interest to attackers. As it is evident in the Mitre’s
enterprise matrix [19], several techniques2 relate to
attack activity on servers. Therefore, it is critical to
incorporate the logon behavior of a user with respect
to diﬀerent servers to user-based anomaly detection
approaches. This is also important for synthetic data
generators to ensure the creation of realistic back-
ground behaviors and to complement eﬀorts such as
the CERT Insider Threat Dataset [28].

Detecting Anomalies in Server Data: Our
analysis of the logon behavior of administrator and
standard users to servers shows that logons do not
exhibit a regularity that can be easily modeled. This
gets more visible on the second category of servers
mainly used for innovation and development activity.
It is plausible that user activity on servers is mainly
driven by users’ daily tasks. For example, in our envi-
ronment, there are (SharePoint) development servers
used for developing diﬀerent applications. It is ob-
served that some developers access only one of these
servers whereas others access any number of them
with overall activity changing from week to week. We
also determined that some development servers are
only accessed by administrators in an irregular man-
ner. Similarly, for some servers especially in the ﬁrst
category, we observed very few logons during the 10-
week duration. This may indicate that administrator
users logon to those servers on an as-needed basis.
These ﬁndings crucially reveal that reliable anomaly
detection based on user activity must incorporate
server activity with other information sources that
drive user activity. In this regard, the incident man-
agement systems used by IT teams to monitor and
manage servers and the daily tasks of developers can
be used to support such decision systems.

In terms of server activity, the most critical aspect
concerns the complexity of audit data for anomaly
detection. That is, does server activity provide a suit-
able baseline to reliably detect anomalies in system
execution? Our rareness measurements show that
a very large number of rare events are encountered

2Most notably, these include techniques such as T1190,

T1606, T1021, T1039, T1114, T1102, T1567, T1505.

on a weekly basis. This shows that detection of at-
tacks solely based on event-level analyses will yield
a huge volume of cases for investigation. Our results
also demonstrate that the similarity of provenance
graphs generated daily is around 40%. Even when
only process-creation events are considered, the simi-
larity increases to 48%. In other words, this implies
the presence of a very fast concept drifts in data. Over-
all, it is evident that anomaly detection approaches
need to focus on obtaining better contextual represen-
tations for events. However, due to the diversity of
events, this may be a more challenging task than it is
assumed to be.
Duration

of Reference Time Period:
Rareness scores given in Fig.
3(a) show that
when 4-9 weeks are used as a historic time window,
the number of rare events decreases slowly with the
duration of the reference period. This indicates
that further extending the duration of the reference
window will potentially reduce the number of rare
events. The ideal duration should be determined as
the number of weeks at which a plateau is obtained.
This issue needs to be further studied on more
extensive datasets than ours.

Resolution of Reference Time Period: As-
sessing the rareness of events requires splitting the
reference time window into intervals, such as days or
weeks, when checking the occurrence of a query event
as deﬁned in Eqs. 1 and 2. In this regard, choosing
shorter intervals is expected to yield more rare events.
For example, if an event occurs on one day of every
week, its rareness score will be 0 and around 0.85
when the interval is set to a day. The changes in the
distribution of rareness scores computed with respect
to Eq. (1) are shown in Figs. 8(a) and 8(b) when
the time resolution is set to both days and weeks. It
is evident choosing a longer duration yields a more
favorable analysis setting.

In the case of similarity of the provenance graphs,
daily and weekly measurements yielded very similar
measurements as presented in Table 3. This essentially
indicates that a number of events repeat almost on
a daily level, thereby creating a baseline of activity
that warrants a similar level of activity both at the
daily and weekly level. Events other than those are
most likely the rare ones that cause a reduction in the

13

(a)

(b)

(c)

Figure 8: Rareness score of events based on diﬀerent window sizes and grouping approaches. (a) Rareness
scores are measured daily with grouping similar servers. (b) Rareness scores are measured weekly with
grouping similar servers. (c) Rareness scores are measured weekly using all servers in the enterprise.

measured similarity. Hence, applying graph similarity
at a daily basis is more preferable as it will make the
analysis easier due to the smaller overall graph sizes.
Server/Group Level or Enterprise-wide As-
sessment: Another related issue concerning compu-
tation of rareness scores is to consider a single server
or all available servers when evaluating the occurrence
frequency of events. Extending the event context to
all servers will in fact contribute to the rareness of
events, especially for those that are speciﬁc to a server.
This is because such events will be designated frequent
when evaluated locally but will appear as rare when
considered in the global context as the ratio of the
servers that encountered those events will be low. At
the same time, however, evaluation of the frequency
of events using data from multiple systems with a
similar setup will help more accurately identify rare
events. This can be realized by grouping together
servers that are expected to operate similarly. Figures
8(b) and 8(c) demonstrate the change in distribution
of rareness scores when only servers in the same ser-
vice group and all the servers are taken into account.
Further, the fact that all events are assigned a high
rareness score in Fig. 8(c) also shows that there are
really few common events between diﬀerent types of
servers.

To identify the appropriate grouping scheme for
servers, we computed average rareness scores for diﬀer-
ent event types from servers in an individual manner,
by grouping them based on the service they provide
and their location, and by allowing the group to in-

clude all servers in the enterprise. As can be seen
in Table 4, increasing the number of servers in the
group results in an increase in the average rareness
scores of events encountered on a server. This ﬁnding
is consistent with our previous result that common
events are rare between diﬀerent servers. Hence, when
the grouping is completely removed and the data from
each server is analyzed by isolating the reference time
window of each server to historic data from itself, the
lowest rareness scores are obtained. However, this
basic setting makes poisoning attacks easier because
attackers can repetitively perform certain tasks on a
server they control to hide their activities. Therefore,
it is more desirable to group together servers that run
the same service under similar conditions together,
striking a balance between the ability detect poisoning
attacks and the number of rate events.

Table 4: Average rareness scores for diﬀerent event
types obtained by applying diﬀerent grouping ap-
proaches

Grouping Approach
(No. groups)
Server Level (46)
Same Type & Location (31)
Same Type (23)
All Servers

Avg. of Rareness Scores
File Process Network Registry
0.66
0.78
0.88
0.99

0.37
0.57
0.68
0.98

0.66
0.76
0.82
0.99

0.91
0.93
0.95
0.99

14

6 Conclusions

In this work, we perform the ﬁrst feasibility study
of utilizing server activity in an enterprise to detect
anomalies. From a corpus of 10-week enterprise net-
work logs, we analyze the server logon activities, the
rareness of observed server events, and the similarity
of the provenance graphs for system activities. Our
observations show that servers, in general, exhibit
high variation in their behavior. However, careful
consideration of training parameters and grouping
of servers, we show that the rareness measurement
improves by 24.5% on average with our data. Fur-
ther, we observe an improvement of 5.5% on average
in the similarity of provenance graphs when proﬁled
daily compared to weekly basis. While some of the
results are encouraging, we believe more needs to be
done in order to improve the rareness score and prove-
nance similarity, potentially utilizing unﬁltered data
as well as additional contextual information, in order
to complement existing user based enterprise anomaly
detection techniques.

References

[1] J. Dai, X. Sun, and P. Liu, “Patrol: Revealing zero-day at-
tack paths through network-wide system object dependen-
cies,” in European Symposium on Research in Computer
Security. Springer, 2013, pp. 536–555.

[2] E. Manzoor, S. M. Milajerdi, and L. Akoglu, “Fast
memory-eﬃcient anomaly detection in streaming heteroge-
neous graphs,” in Proceedings of the 22nd ACM SIGKDD
International Conference on Knowledge Discovery and
Data Mining, 2016, pp. 1035–1044.

[3] G. Berrada and J. Cheney, “Aggregating unsupervised
provenance anomaly detectors,” in 11th International
Workshop on Theory and Practice of Provenance (TaPP
2019), 2019.

[4] C. Xiong, T. Zhu, W. Dong, L. Ruan, R. Yang, Y. Chen,
Y. Cheng, S. Cheng, and X. Chen, “Conan: A practical
real-time apt detection system with high accuracy and
eﬃciency,” IEEE Transactions on Dependable and Secure
Computing, 2020.

[5] M. N. Hossain, S. M. Milajerdi, J. Wang, B. Eshete,
R. Gjomemo, R. Sekar, S. Stoller, and V. Venkatakr-
ishnan, “{SLEUTH}: Real-time attack scenario recon-
struction from {COTS} audit data,” in 26th {USENIX}
Security Symposium ({USENIX} Security 17), 2017, pp.
487–504.

[6] S. M. Milajerdi, R. Gjomemo, B. Eshete, R. Sekar, and
V. Venkatakrishnan, “Holmes: real-time apt detection
through correlation of suspicious information ﬂows,” in
2019 IEEE Symposium on Security and Privacy (SP).
IEEE, 2019, pp. 1137–1152.

[7] X. Han, T. Pasquier, and M. Seltzer, “Provenance-based
intrusion detection: opportunities and challenges,” in 10th
{USENIX} Workshop on the Theory and Practice of
Provenance (TaPP 2018), 2018.

[8] X. Han, T. Pasquier, A. Bates, J. Mickens, and M. Seltzer,
“Unicorn: Runtime provenance-based detector for advanced
persistent threats,” 2020.

[9] M. Du, F. Li, G. Zheng, and V. Srikumar, “Deeplog:
Anomaly detection and diagnosis from system logs through
deep learning,” in Proceedings of the 2017 ACM SIGSAC
Conference on Computer and Communications Security,
2017, pp. 1285–1298.

[10] L. Liu, O. De Vel, C. Chen, J. Zhang, and Y. Xiang,
“Anomaly-based insider threat detection using deep au-
toencoders,” in 2018 IEEE International Conference on
Data Mining Workshops (ICDMW).
IEEE, 2018, pp.
39–48.

[11] Q. Hu, B. Tang, and D. Lin, “Anomalous user activ-
ity detection in enterprise multi-source logs,” in 2017
IEEE International Conference on Data Mining Work-
shops (ICDMW).

IEEE, 2017, pp. 797–803.

[12] L.-P. Yuan, E. Choo, T. Yu, I. Khalil, and S. Zhu,
“Time-window group-correlation support vs. individual fea-
tures: A detection of abnormal users,” arXiv preprint
arXiv:2012.13971, 2020.

[13] B. Sharma, P. Pokharel, and B. Joshi, “User behavior ana-
lytics for anomaly detection using lstm autoencoder-insider
threat detection,” in Proceedings of the 11th International
Conference on Advances in Information Technology, 2020,
pp. 1–9.

[14] M. Corney, G. Mohay, and A. Clark, “Detection of anoma-
lies from user proﬁles generated from system logs,” in
Proceedings of the Ninth Australasian Information Secu-
rity Conference:. Australian Computer Society, 2011, pp.
23–31.

[15] A. Tuor, S. Kaplan, B. Hutchinson, N. Nichols, and
S. Robinson, “Deep learning for unsupervised insider
threat detection in structured cybersecurity data streams,”
2017.

[16] T. Rashid, I. Agraﬁotis, and J. R. Nurse, “A new take
on detecting insider threats: exploring the use of hidden
markov models,” in Proceedings of the 8th ACM CCS In-
ternational workshop on managing insider security threats,
2016, pp. 47–56.

[17] M. A. Maloof and G. D. Stephens, “Elicit: A system
for detecting insiders who violate need-to-know,” in In-
ternational Workshop on Recent Advances in Intrusion
Detection. Springer, 2007, pp. 146–166.

15

[18] F. Liu, Y. Wen, D. Zhang, X. Jiang, X. Xing, and D. Meng,
“Log2vec: a heterogeneous graph embedding based ap-
proach for detecting cyber threats within enterprise,” in
Proceedings of the 2019 ACM SIGSAC Conference on
Computer and Communications Security, 2019, pp. 1777–
1794.

[19] “Mitre att&ck®,” https://attack.mitre.org/matrices/en

terprise/, (Accessed on 06/18/2021).

[20] K. Pei, Z. Gu, B. Saltaformaggio, S. Ma, F. Wang,
Z. Zhang, L. Si, X. Zhang, and D. Xu, “Hercule: At-
tack story reconstruction via community discovery on
correlated log graph,” in Proceedings of the 32Nd Annual
Conference on Computer Security Applications, 2016, pp.
583–595.

[21] S. M. Milajerdi, B. Eshete, R. Gjomemo, and V. Venkatakr-
ishnan, “Poirot: Aligning attack behavior with kernel au-
dit records for cyber threat hunting,” in Proceedings of
the 2019 ACM SIGSAC Conference on Computer and
Communications Security, 2019, pp. 1795–1812.

[22] Y. Liu, M. Zhang, D. Li, K. Jee, Z. Li, Z. Wu, J. Rhee,
and P. Mittal, “Towards a timely causality analysis for
enterprise security.” in NDSS, 2018.

[23] W. U. Hassan, S. Guo, D. Li, Z. Chen, K. Jee, Z. Li, and
A. Bates, “Nodoze: Combatting threat alert fatigue with
automated provenance triage,” in Network and Distributed
Systems Security Symposium, 2019.

[24] J. Zeng, Z. L. Chua, Y. Chen, K. Ji, Z. Liang, and J. Mao,
“Watson: Abstracting behaviors from audit logs via aggre-
gation of contextual semantics.”

[25] “Transparent computing,” https://www.darpa.mil/progra

m/transparent-computing, (Accessed on 06/18/2021).

[26] “darpa-i2o/transparent-computing: Material from the
darpa transparent computing program,” https://gith
ub.com/darpa-i2o/Transparent-Computing, (Accessed on
06/12/2021).

[27] A. Kenyon, L. Deka, and D. Elizondo, “Are public intru-
sion datasets ﬁt for purpose characterising the state of the
art in intrusion event datasets,” Computers & Security, p.
102022, 2020.

[28] J. Glasser and B. Lindauer, “Bridging the gap: A prag-
matic approach to generating insider threat data,” in 2013
IEEE Security and Privacy Workshops.
IEEE, 2013, pp.
98–104.

[29] K. V. Vishwanath and A. Vahdat, “Swing: Realistic and
responsive network traﬃc generation,” IEEE/ACM Trans-
actions on Networking, vol. 17, no. 3, pp. 712–725, 2009.

[30] C. V. Wright, C. Connelly, T. Braje, J. C. Rabek, L. M.
Rossey, and R. K. Cunningham, “Generating client work-
loads and high-ﬁdelity network traﬃc for controllable,
repeatable experiments in computer security,” in Interna-
tional workshop on recent advances in intrusion detection.
Springer, 2010, pp. 218–237.

[31] M. B. Salem and S. J. Stolfo, “Modeling user search behav-
ior for masquerade detection,” in International Workshop
on Recent Advances in Intrusion Detection.
Springer,
2011, pp. 181–200.

[32] A. Gehani and D. Tariq,

for
provenance auditing in distributed environments,” in
ACM/IFIP/USENIX International Conference on Dis-
tributed Systems Platforms and Open Distributed Process-
ing. Springer, 2012, pp. 101–120.

Support

“Spade:

[33] Z. Li, Q. A. Chen, R. Yang, Y. Chen, and W. Ruan,
“Threat detection and investigation with system-level prove-
nance graphs: a survey,” Computers & Security, p. 102282,
2021.

[34] “Global server share by os 2018-2019,” (Accessed on
04/27/2021). [Online]. Available: https://www.statista
.com/statistics/915085/global-server-share-by-os/#:∼:
text=Global%20server%20share%20by%20operating%20
system%202018%2D2019&text=In%202019%2C%20the
%20Windows%20operating,to%20their%20overall%20m
arket%20share

[35] “Sysmon - windows sysinternals,” https://docs.micro
soft.com/en-us/sysinternals/downloads/sysmon#:∼:
text=System%20Monitor%20(Sysmon)%20is%20a,ch
anges%20to%20file%20creation%20time, (Accessed on
04/27/2021).

[36] “Github - swiftonsecurity/sysmon-conﬁg: Sysmon conﬁgu-
ration ﬁle template with default high-quality event tracing,”
https://github.com/SwiftOnSecurity/sysmon-config, (Ac-
cessed on 04/27/2021).

[37] “Hta-t09-how-to-go-from-responding-to-hunting-with-

sysinternals-sysmon,” https://published-prd.lanyonevents
.com/published/rsaus17/sessionsFiles/5011/HTA-T09-
How-to-go-from-responding-to-hunting-with-Sysinterna
ls-Sysmon.pdf, (Accessed on 04/27/2021).

[38] “A holistic methodology for proﬁling ransomware through
endpoint detection,” https://scholar.dsu.edu/cgi/view
content.cgi?article=1324&context=theses, (Accessed on
04/27/2021).

[39] M. Uddin and A. A. Rahman, “Server consolidation: An
approach to make data centers energy eﬃcient and green,”
International Journal of Scientiﬁc and Engineering Re-
search, 2010.

[40] A. Bohara, M. A. Noureddine, A. Fawaz, and W. H.
Sanders, “An unsupervised multi-detector approach for
identifying malicious lateral movement,” in 2017 IEEE
36th Symposium on Reliable Distributed Systems (SRDS).
IEEE, 2017, pp. 224–233.

[41] H. Siadati and N. Memon, “Detecting structurally anoma-
lous logins within enterprise networks,” in Proceedings of
the 2017 ACM SIGSAC Conference on Computer and
Communications Security, 2017, pp. 1273–1284.

[42] C. Wang, G. Zhang, and L. Liu, “A detection method for
the resource misuses in information systems,” in Aﬀective
Computing and Intelligent Interaction. Springer, 2012,
pp. 545–552.

16

[56] S. Ma, X. Zhang, and D. Xu, “Protracer: Towards prac-
tical provenance tracing by alternating between logging
and tainting.” in NDSS, 2016.

[57] Z. Xu, Z. Wu, Z. Li, K. Jee, J. Rhee, X. Xiao, F. Xu,
H. Wang, and G. Jiang, “High ﬁdelity data reduction for
big data security dependency analyses,” in Proceedings
of the 2016 ACM SIGSAC Conference on Computer and
Communications Security, 2016, pp. 504–516.

[58] M. N. Hossain, J. Wang, O. Weisse, R. Sekar, D. Genkin,
B. He, S. D. Stoller, G. Fang, F. Piessens, E. Downing
et al., “Dependence-preserving data compaction for scal-
able forensic analysis,” in 27th {USENIX} Security Sym-
posium ({USENIX} Security 18), 2018, pp. 1723–1740.

[59] W. U. Hassan, A. Bates, and D. Marino, “Tactical prove-
nance analysis for endpoint detection and response sys-
tems,” in 2020 IEEE Symposium on Security and Privacy
(SP).

IEEE, 2020, pp. 1172–1189.

[60] “olafhartong/sysmon-modular: A repository of sysmon
conﬁguration modules,” https://github.com/olafhartong
/sysmon-modular, (Accessed on 06/19/2021).

[61] T. E. Senator, H. G. Goldberg, A. Memory, W. T. Young,
B. Rees, R. Pierce, D. Huang, M. Reardon, D. A. Bader,
E. Chow et al., “Detecting insider threats in a real corpo-
rate database of computer usage activity,” in Proceedings
of the 19th ACM SIGKDD international conference on
Knowledge discovery and data mining, 2013, pp. 1393–
1401.

[43] G. Gavai, K. Sricharan, D. Gunning, R. Rolleston, J. Han-
ley, and M. Singhal, “Detecting insider threat from enter-
prise social and online activity data,” in Proceedings of
the 7th ACM CCS international workshop on managing
insider security threats, 2015, pp. 13–20.

[44] H. Eldardiry, K. Sricharan, J. Liu, J. Hanley, B. Price,
O. Brdiczka, and E. Bart, “Multi-source fusion for anomaly
detection: using across-domain and across-time peer-group
consistency checks.” J. Wirel. Mob. Networks Ubiquitous
Comput. Dependable Appl., vol. 5, no. 2, pp. 39–58, 2014.

[45] D. C. Le and A. N. Zincir-Heywood, “Evaluating insider
threat detection workﬂow using supervised and unsuper-
vised learning,” in 2018 IEEE Security and Privacy Work-
IEEE, 2018, pp. 270–275.
shops (SPW).

[46] N. K. Ahmed, R. A. Rossi, J. B. Lee, T. L. Willke, R. Zhou,
X. Kong, and H. Eldardiry, “role2vec: Role-based network
embeddings,” in Proc. DLG KDD, 2019, pp. 1–7.

[47] Y. Shen, E. Mariconti, P. A. Vervier, and G. Stringhini,
“Tiresias: Predicting security events through deep learning,”
in Proceedings of the 2018 ACM SIGSAC Conference on
Computer and Communications Security, 2018, pp. 592–
605.

[48] M. Du, Z. Chen, C. Liu, R. Oak, and D. Song, “Lifelong
anomaly detection through unlearning,” in Proceedings
of the 2019 ACM SIGSAC Conference on Computer and
Communications Security, 2019, pp. 1283–1297.

[49] S. T. King and P. M. Chen, “Backtracking intrusions,” in
Proceedings of the nineteenth ACM symposium on Oper-
ating systems principles, 2003, pp. 223–236.

[50] Q. Wang, W. U. Hassan, D. Li, K. Jee, X. Yu, K. Zou,
J. Rhee, Z. Chen, W. Cheng, C. Gunter et al., “You
are what you do: Hunting stealthy malware via data
provenance analysis,” in Symposium on Network and Dis-
tributed System Security (NDSS), 2020.

[51] “Sigmahq/sigma: Generic signature format for siem sys-
tems,” https://github.com/SigmaHQ/sigma, (Accessed
on 06/19/2021).

[52] M. Barre, A. Gehani, and V. Yegneswaran, “Mining data
provenance to detect advanced persistent threats,” in 11th
International Workshop on Theory and Practice of Prove-
nance (TaPP 2019), 2019.

[53] D. Tariq, B. Baig, A. Gehani, S. Mahmood, R. Tahir,
A. Aqil, and F. Zaﬀar, “Identifying the provenance of
correlated anomalies,” in Proceedings of the 2011 ACM
Symposium on Applied Computing, 2011, pp. 224–229.

[54] G. Cormode and S. Muthukrishnan, “An improved data
stream summary: the count-min sketch and its applica-
tions,” Journal of Algorithms, vol. 55, no. 1, pp. 58–75,
2005.

[55] K. H. Lee, X. Zhang, and D. Xu, “Loggc: garbage collect-
ing audit log,” in Proceedings of the 2013 ACM SIGSAC
conference on Computer & communications security, 2013,
pp. 1005–1016.

17

