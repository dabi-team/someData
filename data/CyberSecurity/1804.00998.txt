1

Optimal Cyber-Insurance Contract Design for

Dynamic Risk Management and Mitigation

Rui Zhang, Quanyan Zhu

9
1
0
2

y
a
M
7

]

R
C
.
s
c
[

3
v
8
9
9
0
0
.
4
0
8
1
:
v
i
X
r
a

Abstract

With the recent growing number of cyberattacks and the constant lack of effective defense methods,

cyber risks become ubiquitous in enterprise networks, manufacturing plants, and government computer

systems. Cyber-insurance provides a valuable approach to transfer the cyber risks to insurance companies

and further improve the security status of the insured. The designation of effective cyber-insurance

contracts requires the considerations from both the insurance market and the dynamic properties of the

cyber risks. To capture the interactions between the users and the insurers, we present a dynamic moral-

hazard type of principal-agent model incorporated with Markov decision processes, which are used to

capture the dynamics and correlations of the cyber risks as well as the user’s decisions on the protections.

We study and fully analyze a case with a two-state two-action user under linear coverage insurance,

and we further show the risk compensation, Peltzman effect, linear insurance contract principle, and

zero-operating proﬁt principle in this case. Numerical experiments are provided to verify our conclusions

and further extend to cases of a four-state three-action user under linear coverage insurance and threshold

coverage insurance.

Index Terms

Cyber-Insurance, Markov Decision Processes, Principal-Agent Problem, Moral Hazard, Information

Asymmetry, Mechanism Design

I. INTRODUCTION

Cyber risks created by malicious attackers such as ransomware [1], data breaches [2], and denial-

of-service [3], have become severe threats to the security of important devices and private data

in Internet of things (IoT) and cyber-physical systems (CPS) [4]. For example, the CryptoLocker

R. Zhang and Q. Zhu are with the Department of Electrical and Computer Engineering, New York University, Brooklyn, NY,

11201 E-mail:{rz885,qz494}@nyu.edu.

 
 
 
 
 
 
2

ransomware attack has caused an estimated loss of $3 million [5]. The 2016 Dyn cyberattack

has resulted in the disruption of major Internet platforms and services to large swathes of users

in Europe and North America [6].

Although various defense methods such as ﬁrewalls [7], intrusion detection systems [8], and

moving-target defenses [9], have been deployed to detect the intrusion attempts and protect

the networked devices, they cannot eliminate the cyber risks due to the complexities of cyber-

environments [10]. Moreover, cyber threats are becoming stealthier, more strategic and purposeful

as exempliﬁed by the advanced persistent threats such as Stuxnet attacks on Iranian nuclear

power plant in 2009 and the Ukrainian power plant attack in 2015 [11], [12].

Recently emerged cyber-insurance provides an economically viable solution to further mitigate

the cyber risks and improve network resiliency [13]–[17]. The insured network users could

quickly recover from severe cyber-incidents since part of the losses have been covered by the

insurers. However, like the classic insurance, the insurers may suffer from offering coverage to

reckless users due to the information asymmetry that the insurers cannot directly observe the

users’ protections [18]–[20].

Moreover, as suggested by the theory of risk compensation in traditional insurance scenarios

[21], the users may become less careful against cyberattacks knowing that insurers will cover

their losses, for example, users may click more phishing emails, ignore the warnings of upgrading

ﬁrewalls or systems, and reduce the frequency of scanning viruses or worms. As a result, the

users may encounter more severe cyber-incidents and the insurers may bear extra cyber risks.

Thus, it is imperative to study cyber-insurance contracts and its impacts on the users’ cyber-risk

statuses. However, classic risk analysis and insurance frameworks cannot be directly applied to

cyber risks and cyber-insurance as cyber risks are dynamically evolving and strongly correlated

[22]–[25]. For example, an adversary can ﬁrst launch a node capture attack to compromise the

system [26], [27], and then gain the administration to the devices [28], steal private information

[29], or inject Ransomware worms or viruses [30].

In this paper, we capture the correlations and dynamics of the cyber risks as well as the users’

decisions on the protections with the Markov decision processes (MDP) [31], [32]. Different states

of the MDP are used to capture the different cyber risks from various sources, such as service

failures, attackers, or network connections. The transitions of states capture the connections of

different cyber risks, and they are affected by the user’s actions of protections at different times.

To further mitigate the cyber risks, the user has a choice of purchasing cyber-insurance. After

paying a premium, the user could receive ﬁnancial coverages from the insurer to reimburse his

losses caused by various cyber risks as shown in Fig. 1. The objective of the user is to ﬁnd an

optimal deployment of protections and cyber-insurance that minimizes his cyber-losses.

3

Fig. 1. Cyber-insurance example. The blue, red, and green icons represent user, attacker, and insurer, respectively. A user pays a

premium to an insurer to purchase the cyber-insurance. Then, the user could receive ﬁnancial coverages from the insurer to cover

part of his losses caused by cyberattacks.

A rational user selects a cyber-insurance from which he could beneﬁt more, i.e., contracts with

a low premium and a high coverage. However, an insurer tends to offer an insurance contract

that has a high premium and a low coverage, as the insurer aims to maximize his operating

proﬁt. Moreover, similar to the traditional insurance scenarios, the insurer is not aware of the

local protections of the user, and an inappropriate insurance contract could largely damage the

insurer’s proﬁt.

We address such conﬂicting interests and the information asymmetry between the user and the

insurer with a moral hazard type of principal-agent problem [19], [20], [33], [34]. The analysis,

as well as the solution of the problem, is important to study the impacts of cyber-insurance

to the user and design effective insurance contracts. The major contributions of this work are

summarized as follows:

• We integrate Markov Decision Processes (MDP) into a moral hazard type of principal-agent

model to investigate the impacts of cyber-insurance on the user’s cyber risks and design

effective cyber-insurance contracts for the insurer.

• We fully characterize a case between a two-state two-action user and a linear coverage insurer.

The results of this case indicate that the optimal insurance contracts follow linear insurance

4

contract principle and zero-operating proﬁt principle. The analysis also demonstrates the

existence of risk compensation and Peltzman effect in cyber-insurance.

• We develop computational tools to solve problems involving multiple cyber-risk states,

various protection choices, and complex insurance contracts. Our numerical experiments

illustrate risk compensation, Peltzman effect, and zero-operating proﬁt principle in cases

of a four-state three-action user under linear coverage insurance and threshold coverage

insurance.

A. Organization of the Paper

The rest of this paper is organized as follows. Section II presents the related works. Section

III and Section IV discuss the user’s problem and the insurer’s problem, respectively. Section

V presents a case study of a linear coverage insurance contract on a two-state two-action user.

Section VI and Section VII present numerical results and concluding remarks, respectively.

Appendices A, B, and C provide the proofs of the Proposition 2, and Theorem 1, and Proposition

4, respectively. We provide a summary of notations in the following table for convenience.

II. RELATED WORKS

Recently, with fast-growing types and amounts of the networked devices and shortages of

effective and state-of-art defense methods, cyber-insurance has drawn huge attention as it can

transfer the unexpected cyber risks to the insurance companies [13]–[17], [25], [35]–[39]. The

existing insurance framework could bring useful insights on modeling the cyber-insurance [13],

[40]. The moral hazard models in the economics literature are good tools to capture the information

asymmetry between the insured and the insurers [18]–[20]. Various frameworks and methodologies

have been brought up to investigate cyber-insurance contracts and their impacts to cyber risks.

Several works have studied cyber-insurance through market-based approaches by analyzing the

supply and demand relations between insurers and insureds [14], [16], [25], [35]. In [16], Pal et

al., have analyzed regulated monopolistic and competitive cyber-insurance markets, and showed

that cyber-insurance can improve the network security but the insurer can make zero expected

proﬁts in monopoly markets. In [14], [25], [35], B¨ohme et al., have presented several market

models of cyber-insurance with the consideration of interdependency between cyber risks and

information asymmetries between insurers and insureds, and showed analytical results on the

impacts of cyber-insurance to cyber-security and the vialibity of a market for cyber-insurance.

5

t
S , N

Sn

s, st
X

Xn

x, xt

p(st , st+1)
A , M

Am

a, at

Summary of Notations

Time t

Set and Number of All Possible States

State n (1 ≤ n ≤ N)
State, State at Time t (s, st ∈ S )

Set of Direct Losses at All Possible States

Direct Loss at State Sn

Direct Loss, Direct Loss at Time t

Transition Probability from st to st+1

Set and Number of All Possible Protections

Protection m (1 ≤ m ≤ M)
Protection, Protection at Time t (a, at ∈ A )

p(st , at , st+1)

Transition Probability from st to st+1 under at

c(a)

αs

Ω

π

ρ

R

r(x), K

r0(x)

R

l(s, a, r)

V (s, π, r)

π ∗
r
SGB

SG, SB
s, sc

XG, XB
AHL

AH , AL

αG, αB

αs, αsc

RG, RB

Cost Function
Stationary State Protection at State s (αs ∈ A )

Set of All Possible Stationary Protection Policies
Stationary Protection Policy (π(s) = αs, ∀s ∈ S )

Value of Transition Probabilities

Set of All Possible Coverage Functions
Coverage Function (r ∈ R), Premium (K ∈ R≥0)
Zero Coverage Function (r0(x) = 0, ∀x ∈ R≥0)

Coverage Level (r(x) = Rx)

Effective Loss Function

Expected Cumulative Effective Loss Function

Optimal Stationary Protection Policy Under Coverage r
Set of Two States (SGB = {SG, SB})

Good State, Bad State
One State, The Other State (s, sc ∈ SGB; sc (cid:54)= s)

Direct Losses at Good State, Bad State
Set of Two Actions (AHL = {AH , AL})

Strong Protection, Weak Protection

Stationary State Protections at Good State, Bad State

Stationary State Protections

Threshold Coverage Levels at Good State, Bad State

6

Game theory has been used to capture the interactions between insurers and insureds of

cyber-insurance [17], [36], [39]. In [39], Laszka et al., have used a two-player signaling game

to capture the information asymmetry between a potential client and an insurer, and further

studied incentives for auditing potential clients before cyber-insurance premium calculations. In

[36], Grossklags et al., have presented several security games to capture the decision-making of

network users on protections and insurance. The equilibrium analysis shows that users may seek

to self-protect themselves at just slightly above the lowest protection level in the weakest-target

game. In [17], Zhang et al. have studied the interactions between insureds, attackers, and insurers

with a bi-level game-theoretic framework in a networked environment and demonstrated the

impacts of network connections to the three types of players.

Most previous works have focused on the information asymmetry and interdependencies of

cyber risks, however, their models have not captured the dynamics and correlations of the cyber

risks, which have been studied with different methodologies and models [41]–[45]. In [44],

Poolsappasit et al. have used a bayesian attack graphs model to analyze the network security

risk assessment and mitigation. In [45], the authors have used a differential epidemic model to

capture the spreading of viruses and worms in computer networks. These works aim to reduce

the impacts of cyber risks through local protections, such as ﬁrewalls [7], intrusion detection

[28], or moving target defenses [9], which cannot fully mitigate the risks of cyberattacks.

In this work, we focus on studying the dynamics and correlations of the cyber risks and

analyzing the impacts of the cyber-insurance to both the insureds and the insurers. We ﬁrst capture

the cyber risks as well as the user’s deployments of local protections with Markov decision

processes, which have been used variously to analyze cybersecurity [46], [47]. We then use the

existing moral hazard type of principal-agent model to capture the interactions between the user

and the insurer with incomplete information. The analysis of both the optimal insurance contract

and the user’s response to it provides useful insights on the designation of the cyber-insurance

contracts in the real world.

III. USER’S OPTIMAL PROTECTION POLICIES

We use discrete Markov decision processes (MDP) to capture the evolvements of the user’s
cyber risks with time, and an illustration is provided in Fig. 2. Let st ∈ S denote the user’s
cyber-risk state at time t ∈ Z≥0, where S ≡ {Sn|1 ≤ n ≤ N} is the set of all possible cyber-risk
states. Different cyber-risk states may incur various types of losses, e.g., data breaches, physical

device damages, and compromised ﬁnancial accounts. In this paper, we consider that all types

of losses are measurable and can be quantiﬁed by monetary direct losses. We assume that each
cyber-risk state Sn ∈ S is associated with a ﬁxed direct loss Xn ∈ R≥0, and the user’s direct loss
at time t can be denoted by xt ∈ X , where X ≡ {Xn|1 ≤ n ≤ N}.

7

Fig. 2.

Illustration of cyber-insurance. The dynamics of the user’s cyber risks are captured by MDP with st denoting the

cyber-risk state at time t, which is associated with a direct loss xt . The user can choose various protections at to reduce the future

losses. The objective of the user is to ﬁnd the optimal protection sequence {at }t≥0 which minimizes his cumulative losses. The

user can also purchase cyber-insurance to mitigate his losses. The insurer ﬁrst announces the insurance contract {K, r}, where

K and r indicate the premium and the coverage function, respectively. The user can decide whether to purchase the insurance

or not. If the user chooses to purchase the insurance, he must pay a premium K, and when he faces a loss of x, the insurer

should provide a coverage of r(x) to him. The objective of the insurer is to maximize his proﬁt. Note that the insurer has no

information of the user’s protection sequences.

The user can adopt different protections, such as ﬁrewalls, intrusion detection systems, and

moving-target defenses, to reduce the possibilities of entering cyber-risk states that can incur
severe losses. Let at ∈ A denote the protections at time t, where A ≡ {Am|1 ≤ m ≤ M} is the
set of all available protections. The transition probability p(st, at, st+1) denotes the probability

that the user goes to state st+1 at time t + 1 when he is currently in state st and adopts protection

at, which naturally captures the correlations among different cyber-risk states under different
n=1 p(st, at, Sn) = 1 as the user can only enter states within S at time
protections. Note that ∑N
t + 1.

8

We further provide two examples to illustrate the states S and protections A of the user.

Example 1. Suppose a customer whose computer faces threats of Ransomware. In this example,
the customer has S = {S1, S2} and A = {A1, A2}. States S1 and S2 denote that the computer is
secure and compromised, respectively. The customer can choose to do nothing A1 or add ﬁrewalls

A2. The computer has a lower probability of facing Ransomware, i.e., entering state S2, if the

customer deploys ﬁrewalls. When the computer is compromised, the customer needs to either pay

the money or replace the computer, which can be covered if he has purchased cyber-insurance.

Example 2. Consider a cloud center who aims to protect itself from the damages caused by po-
tential attackers. In this example, the cloud center has S = {S1, S2, S3} and A = {A1, A2, A3, A4}.
State S1 denotes the situation when it is safe and faces no cyberattacks. However, the cloud

center may encounter data breaches and denial-of-services, which are represented by states S2
and S3, respectively. Each state Sn ∈ S is associated with a direct loss Xn. For example, at time
t, st = S2 indicates that the cloud center faces data breaches which inﬂict X2 direct losses to

it. Specially, the direct loss X1 = 0 at state S1, which indicates that the cloud center has no

loss when it faces no cyberattacks. To defend against these cyberattacks, the cloud center may

deploy ﬁrewalls, intrusion detection systems, and moving-target defense, which are represented

by protections A2, A3, and A4, respectively. Specially, the cloud center can also choose to do

nothing, which is denoted as A1. The cloud center has smaller probabilities of entering states

with high losses if he deploys protections, however, these protections are also costly. The cloud

center can also purchase cyber-insurance to cover part of its losses and help it recover from

cyber-incidents. The objective of the cloud center is to ﬁnd an optimal deployment of protections

and cyber-insurance such that its future cumulative losses are minimized. Cases involve other
cyber risks or protections can be extended through increasing the size of S and A .

Besides the protections, the user can also mitigate his losses through purchasing cyber-insurance.

After paying a premium to an insurer, the user could receive a coverage of r(xt) from the insurer
when he faces a direct loss of xt, where r : R≥0 → R≥0 is the coverage function of the insurance.
The objective of the user is to ﬁnd an optimal sequence of protections {at}t∈Z≥0 that minimizes
the expected cumulative effective losses given the initial state s0 ∈ S , which can be captured as

(cid:40) ∞
∑
t=0

E

min
{at }

δ t (xt − r(xt) + c(at))

(cid:41)

,

(cid:12)
(cid:12)
(cid:12)s0

(1)

9

where function c(at) returns the cost of protection at, and δ ∈ (0, 1) is the discount factor which

indicates that future losses are valued less at time 0.

In this paper, we consider that the user decides his protections contingent on his current states.

Such feedback strategy allows the user to maintain his security level by adopting the necessary

protections that can reduce the losses from cyberattacks and save the costs of protections at
the same time. The strategy is usually denoted by a stationary protection policy π : S → A ,

e.g., π(Sn) = Am indicates that the user always takes protection Am at state Sn. As a result, the

expected cumulative effective losses of the user under a stationary protection policy can be

captured as

V (s0, π, r) = E

(cid:26) ∞
∑
t=0

δ t (xt − r (xt) + c (π (st)))

(cid:27)

.

(cid:12)
(cid:12)
(cid:12)s0

(2)

The user aims to ﬁnd an optimal stationary protection policy π ∗

r ∈ Ω that minimizes his
expected cumulative effective losses given the coverage function r, and such objective can be

captured as

π ∗
r ∈ arg min
π∈Ω

V (s0, π, r),

(3)

where Ω denotes the set of all possible stationary policies.

A rational user purchases the insurance only when the expected cumulative effective losses

plus the premium under the insurance is lower than the losses without insurance, which can be

captured as

V (s0, π ∗

r , r) + K ≤ V (s0, π ∗
r0

, r0),

(4)

where K ∈ R≥0 is the premium of the insurance and r0 indicates a zero coverage function, i.e.,
r0(X) = 0 for all X ∈ R≥0, which corresponds to the case when there is no insurance. The fact
that the user purchases the insurance only when inequality (4) is satisﬁed must be considered by

the insurer while designing effective insurance contracts.

The optimal protection policy π ∗

r could be obtained by solving (3) with either dynamic
programming or linear programming [48], and we summarize both approaches in the following

subsections.

A. Dynamic Programming Approach

Recall equation (2), let us deﬁne the loss function l(st, at, r) = xt − r (xt) + c (at) which indicates

the effective loss at time t under the coverage function r. Note that l(st, at, r) does not take xt as

variable since the direct loss xt is uniquely determined by the user’s cyber-risk state st. Thus, we

can express the expected cumulative effective losses as

V (s0, π, r) = E

δ tl(st, π(st), r) |s0

(cid:27)

(cid:26) ∞
∑
t=0

= l(s0, π(s0), r) + δ ∑
s(cid:48)∈S

p(s0, π(s0), s(cid:48))V (s(cid:48), π, r),

(5)

10

where l(s0, π(s0), r) and δ ∑
s∈S

p(s0, π(s0), s)V (s, π, r) capture the effective loss at time 0 and the

future expected cumulative effective losses, respectively. As a result, given a coverage function r,
the optimal protection policy π ∗

r can be found by the following dynamic programming operators

[48].

(cid:26)

π ∗
r (s) ∈ arg min
a∈A
r , r) = l(s, π ∗

V (s, π ∗

l(s, a, r) + δ ∑
s(cid:48)∈S

r (s), r) + δ ∑
s(cid:48)∈S

p(s, a, s(cid:48))V (s(cid:48), π ∗

r , r)

(cid:27)

,

p(s, π ∗

r (s), s(cid:48))V (s(cid:48), π ∗

r , r).

(6)

(7)

By iterating (6) and (7) for all states s ∈ S until no further changes take place, we can achieve
π ∗
r and V (s, π ∗

r , r), and the convergence to the optimum is guaranteed [48].

B. Linear Programming Approach

Besides the dynamic programming, we can also use linear programming to solve the user’s

problem (3). Problem (3) can be reformulated into a linear programming problem in the standard

form as [48]

with its dual problem

dT η

min
η

s.t. Oη = b, η ≥ 0,

bT θ

max
θ

s.t. d − OT θ ≥ 0,

where η ∈ RNM×1 and θ ∈ RN×1 are denoted as the prime variable and the dual variable,
respectively. Note that N and M are the sizes of S and A , respectively. Vector b ∈ RN×1 is a
column vector of size N with all the elements equal to 1. Vector d ∈ RNM×1 is a column vector

of size NM which captures the per-state and per-action losses, and the (N(n − 1) + m)-th element

of it equals l(Sn, Am, r), where 1 ≤ n ≤ N and 1 ≤ m ≤ M. Matrix O = E − δ P, where matrix
E ∈ RN×NM has that En,N(n−1)+m = 1 for 1 ≤ n ≤ N and 1 ≤ m ≤ M and all the other elements are
0, and matrix P ∈ RN×NM is the transition probability matrix where Pn(cid:48),N(n−1)+m = p(n, am, n(cid:48)),
1 ≤ n ≤ N, 1 ≤ n(cid:48) ≤ N, and 1 ≤ m ≤ M.

11

The optimal primal variable η ∗ represents the optimal state-action frequencies; the optimal
dual variable θ ∗ represents the expected cost-to-go values of the states for the given coverage
function r, i.e., θ ∗
n = V (Sn, π ∗
optimal protection policy π ∗

r , r) for 1 ≤ n ≤ N. After solving the dual problem, we can ﬁnd the
r by plugging V (Sn, π ∗

r , r) into (6).

IV. INSURER’S OPTIMAL INSURANCE CONTRACTS

In this section, we present and analyze the insurer’s problem of designing cyber-insurance

contracts. An illustration of the interactions between the user and the insurer has been provided

in Fig. 2. Note that the insurer ﬁrst announces the insurance contract {K, r}, and the user then

makes the decision of purchasing the insurance based on the expected cumulative effective losses

under that insurance contract. If the user chooses to purchase the insurance, the insurer instantly

earns a proﬁt of K at time 0, but the insurer is required to pay the coverage of r(xt) when the

user faces a loss of xt at time t. As a result, the insurer’s operating proﬁt can be captured as
K − E (cid:8)

(cid:12)s0} denotes the expected cumulative coverage

(cid:9), where E{∑∞

t=0 δ tr(xt)(cid:12)
∑∞
(cid:12)s0

t=0 δ tr(xt)(cid:12)

provided by the insurer to the user. The objective of the insurer is to ﬁnd an optimal insurance
contract {K∗, r∗} that maximizes his operating proﬁt. As a result, the insurer’s problem can be

captured as

(cid:27)

K − E

(cid:26) ∞
∑
t=0
(cid:26) ∞
∑
t=0
r , r) + K ≤ V (s0, π ∗
r0
Constraint (8a) captures the insurer’s individual rationality that he chooses not to provide the

max
{K,r}
s.t. K − E

δ tr(xt)(cid:12)
(cid:12)s0

δ tr(xt)(cid:12)
(cid:12)s0

V (s0, π ∗

, r0).

(8a)

(8b)

≥ 0;

(8)

(cid:27)

insurance if he has a negative proﬁt. Constraint (8b) captures the user’s individual rationality on

purchasing the insurance and it comes from inequality (4).

By solving problem (8), the insurer can ﬁnd an optimal insurance contract which maximizes

his operating proﬁt and is acceptable by the user. After combing the user’s problem and the

insurer’s problem, the interactions of the user and the insurer can be captured by the following

principal-agent problem.

max
{K,r}
s.t. K − E

(cid:26) ∞
∑
t=0

δ tr(xt)(cid:12)
(cid:12)s0
(cid:27)

δ tr(xt)(cid:12)
(cid:12)s0

K − E
(cid:26) ∞
∑
t=0
r , r) + K ≤ V (s0, π ∗
r0
V (s0, π, r).

≥ 0;

V (s0, π ∗
π ∗
r ∈ arg min
π∈Ω

, r0);

(9b)

(9c)

(cid:27)

(9a)

(9)

12

Problem (9) is an optimization problem nested with various sub-optimization problems. The

solution of Problem (9) captures both the user’s objective of minimizing his expected cumulative

effective losses and the insurer’s objective of maximizing his own proﬁt with the consideration

of the user’s rational choice of purchasing the insurance. To ﬁnd the solution of problem (9),
we can ﬁrst solve the user’s problem (3) and obtain the optimal protection policies π ∗
corresponding losses V (s0, π ∗
the insurer’s problem (8).

r and the
r , r) to the coverage function r, and then achieve {K∗, r∗} by solving

We can simplify the insurer’s problem (8) by exploring the expected cumulative effective

losses and the optimal protection policies as discussed in the following subsection.

A. Insurer’s Problem: Simpliﬁcations and Direct Conclusions

We ﬁrst notice that the expected cumulative coverage is equal to the expected cumulative

direct losses minus the expected cumulative effective losses, i.e.,

E

(cid:27)

(cid:27)

= E

δ tr(xt) |s0

δ t (xt + c(π ∗

(cid:26) ∞
∑
t=0
(cid:26) ∞
∑
t=0
= V (s0, π ∗
r , r0) can be interpreted as the expected cumulative effective losses given the optimal
r and the zero coverage function r0. Thus, Problem (8) can be rewritten as

δ t (xt − r(xt) + c(π ∗

r , r0) −V (s0, π ∗

(cid:26) ∞
∑
t=0

r (st))) |s0

r (st))) |s0

r , r),

− E

(cid:27)

where V (s0, π ∗
protection policy π ∗

follows.

K − (V (s0, π ∗

r , r0) −V (s0, π ∗

r , r))

max
{K,r}
s.t. K − (V (s0, π ∗
V (s0, π ∗

r , r0) −V (s0, π ∗
r , r) + K ≤ V (s0, π ∗
r0

r , r)) ≥ 0;
, r0).

(10a)

(10b)

(10)

Constraint (10b) indicates that the maximum premium that can be charged by the insurer for a

coverage function r is

Kmax = V (s0, π ∗
r0

, r0) −V (s0, π ∗

r , r).

(11)

The user chooses not to purchase the insurance with a premium K > Kmax because the losses

and the premium under the insurance are higher than the losses without insurance.

As a result, problem (8) is equivalent to the following problem after letting K be equal to

Kmax and plugging (11) into its objective function and constraint.

V (s0, π ∗
r0

max
r∈R
s.t. V (s0, π ∗
r0

, r0) −V (s0, π ∗

r , r0)

, r0) −V (s0, π ∗

r , r0) ≥ 0,

(12)

13

where R denotes the set of all possible coverage functions, and the constraint indicates that the

proﬁt of the insurer cannot be negative. After solving (12), we can ﬁnd the optimal coverage
function r∗, and then the optimal premium can be computed through (11). Similarly, the principal-

agent problem (9) can also be rewritten as

max
r∈R

V (s0, π ∗
r0

, r0) −V (s0, π ∗

r , r0)

s.t. V (s0, π ∗
r0
π ∗
r ∈ arg min
π∈Ω
Comparing to (8) and (9), we only need to ﬁnd the optimal protection policies π ∗
optimal insurance contract {K∗, r∗} through (12) and (13).

, r0) −V (s0, π ∗
V (s0, π, r).

r , r0) ≥ 0;

(13b)

(13a)

(13)

r to obtain the

One useful insight regarding the operating proﬁt could be obtained without solving (12) or

(13), which is summarized in the following remark and proposition.

Remark 1. Any coverage function r that yields π ∗

r = π ∗
r0

, i.e., the user has the same optimal protec-

tion policy between the case under the coverage function r and the case under no insurance, is a
feasible solution with the corresponding premium K = V (s0, π ∗
r0
, r) ≥ 0 as V (s0, π ∗
V (s0, π ∗
r0
r0
that insurance contract as V (s0, π ∗
r0

, r0)−V (s0, π ∗
, r0), and the insurer has a zero operating proﬁt under

r , r0) = V (s0, π ∗
r0

r , r) = V (s0, π ∗
r0

, r0) −V (s0, π ∗
r0

, r) ≤ V (s0, π ∗
r0

, r0) −V (s0, π ∗

, r0) = 0.

, r0)−

Proposition 1. Any insurance contract {K, r} that yields π ∗

r = π ∗
r0

and meets (11) is optimal for

the insurer, and the insurer has a zero operating proﬁt under that contract.

Proof. The operating proﬁt of the insurer has that V (s, π ∗
r0
π ∗
∈ arg min
r0
π∈Ω
if the user has π ∗

r , r0) ≤ 0 from (13b), i.e.,
V (s, π, r0). Thus, the maximum proﬁt that the insurer can achieve is 0. As a result,
r0 under an insurance contract {K, r}, that contract is feasible from Remark

, r0) −V (s, π ∗

r = π ∗
1 and it is also optimal.

Remark 1 indicates that the insurer has a zero operating proﬁt when the user has the same

protection policies with or without insurance, which explains market neutrality. Proposition 1

indicates that the insurance contract in Remark 1 is optimal for the insurer. We denote this

conclusion as the zero operating proﬁt principle.

V. CASE STUDY: TWO-STATE TWO-ACTION USER AND LINEAR COVERAGE INSURER

In this section, we present a representative case where the user has two states and two actions

and the insurer provides the linear coverage. Analysis of this case provides structural insights of the

14

insurance contracts. Recall Section III, the user in this case has the set of states SGB ≡ {SG, SB},
where SG and SB indicate good state and bad state, respectively. The losses that associated with

the states can be further identiﬁed as XG and XB. The difference between the good state and

the bad state is that the user has lower losses at the good state than that at the bad state, i.e.,

0 ≤ XG < XB.

To reduce the losses, the user can choose to take a strong protection AH or a weak protection AL,
in other words, the user has the action set AHL = {AH, AL}. We further use shorthand notations
CH and CL to represent the costs of protections AH and AL, respectively, i.e, c(AH) = CH and

c(AL) = CL. The differences between a strong protection and a weak protection can be identiﬁed

in detail as follows:

• p(s, AH, SB) < p(s, AL, SB), ∀s ∈ SGB, which indicates that the user has a higher probability

of going to the bad state when he has a weak protection.

• p(s, AL, SG) < p(s, AH, SG), ∀s ∈ SGB, which indicates that the user has a higher probability

of going to the good state when he has a strong protection.

• 0 ≤ CL < CH, which indicates that the cost of a strong protection is higher than the cost of

a weak protection.

These differences capture the fact that a strong protection can make the user more secure but its

cost is also higher.

With two states and two actions, the user has only four possible stationary protection policies,

i.e., Ω = {ΠHH, ΠHL, ΠLH, ΠLL}, where

• ΠHH(SG) = AH and ΠHH(SB) = AH;

• ΠHL(SG) = AH and ΠHL(SB) = AL;

• ΠLH(SG) = AL and ΠLH(SB) = AH;

• ΠLL(SG) = AL and ΠLL(SB) = AL.

An optimal protection policy π ∗ ∈ Ω can be achieved by solving Problem (3) which minimizes

the user’s expected cumulative effective losses.

Besides protections, the user can also purchase the insurance to further mitigate his losses. We

consider that the insurer offers a linear coverage with R ∈ [0, 1] denoting the coverage level of

the insurance, i.e., r(x) = Rx. Specially, R = 0 and R = 1 indicate no coverage and full coverage,

respectively.

Methods in Sections III and IV can be used to ﬁnd the optimal protection policy of the user

and the optimal insurance contract for the insurer. Since there are only two states and two actions

15

for the user, we can ﬁnd them analytically.

A. User’s Optimal Protection Policy

We ﬁrst introduce several notations to simplify representations. Since the user has only two
states SG and SB, we use sc (cid:54)= s to denote the other state for a given state s ∈ SGB. Since the
user adopts a stationary protection policy, i.e., he has ﬁxed protections at each state, we identify

his state protections as αG and αB for the good state and the bad state, respectively. We further

deﬁne the action dependent expected cumulative effective loss function as follows

V (s, αs; αsc, R)

= l(s, αs, R) + δ p(s, αs, SG)V (SG, αG; αB, R) + δ p(s, αs, SB)V (SB, αB; αG, R).

(14)

Remark 2. For a protection policy π that has π(SG) = αG and π(SB) = αB, the expected

cumulative effective loss function (5) is equivalent to the action dependent expected cumulative

effective loss function (14), i.e.,

V (SG, π, R) = V (SG, π(SG); π(SB), R) = V (SG, αG; αB, R);

V (SB, π, R) = V (SB, π(SB); π(SG), R) = V (SB, αB; αG, R).

As a result, the dynamic programming operators (6) and (7) can be written as

π ∗
R(SG) ∈ arg min
αG∈AHL

V (SG, αG; π ∗

R(SB), R);

π ∗
R(SB) ∈ arg min
αB∈AHL

V (SB, αB; π ∗

R(SG), R),

where

V (SG, αG; αB, R) = l(SG, αG, R)

+δ p(SG, αG, SG)V (SG, αG; αB, R) + δ p(SG, αG, SB)V (SB, αB; αG, R);

V (SB, αB; αG, R) = l(SB, αB, R)

+δ p(SB, αB, SG)V (SG, αG; αB, R) + δ p(SB, αB, SB)V (SB, αB; αG, R).

(15)

(16)

(17)

(18)

Both (17) and (18) are linear equations on V (SG, αG; αB, R) and V (SB, αB; αG, R), thus, we can

solve them together and achieve

V (SG, αG; αB, R) = (1−δ p(SB,αB,SB))l(SG,αG,R)+δ p(SG,αG,SB)l(SB,αB,R)

Ip(αG,αB)

V (SB, αB; αG, R) = δ p(SB,αB,SG)l(SG,αG,R)+(1−δ p(SG,αG,SG))l(SB,αB,R)

Ip(αG,αB)

;

,

(19)

(20)

where

Ip(αG, αB) =

(cid:16)

1 − δ p(SG, αG, SG)

1 − δ p(SB, αB, SB)

(cid:17)(cid:16)

16

− δ 2 p(SG, αG, SB)p(SB, αB, SG).

(21)

(cid:17)

As a result, we can ﬁnd π ∗

R by solving (15) and (16) with (19) and (20), respectively. Since
there are only two protection choices AH and AL, we can ﬁnd the optimal protection policy by

comparing the action dependent expected cumulative effective losses under AH and AL.

Lemma 1. The optimal protection policy π ∗
follows:

R given the coverage level R can be summarized as

• π ∗

• π ∗

• π ∗

• π ∗

R = ΠLL if and only if V (SG, AH ; AL, R) ≥ V (SG, AL; AL, R) and V (SB, AH ; AL, R) ≥ V (SB, AL; AL, R);
R = ΠLH if and only if V (SG, AH ; AH , R) ≥ V (SG, AL; AH , R) and V (SB, AH ; AL, R) < V (SB, AL; AL, R);
R = ΠHL if and only if V (SG, AH ; AL, R) < V (SG, AL; AL, R) and V (SB, AH ; AH , R) ≥ V (SB, AL; AH , R);
R = ΠHH if and only if V (SG, AH ; AH , R) < V (SG, AL; AH , R) and V (SB, AH ; AH , R) < V (SB, AL; AH , R).

Proof. The user chooses a protection policy with lower expected cumulative effective losses in

both good state and bad state.

We consider that the user always takes AL when V (s, AH; αsc, R) = V (s, AL; αsc, R). We can

further simplify the comparisons in Lemma 1 as shown in the following proposition.

Proposition 2. Let us deﬁne function h : S × A × R → R as

h(s, αsc, R) = (1 − R)δ (p(s, AH, sc) − p(s, AL, sc)) (Xsc − Xs)

+(1 − δ + δ p(SB, αsc, SG) + δ p(SG, αsc, SB))(CH −CL),

the optimal protection policy π ∗

R can be summarized as follows:

• π ∗ = ΠLL if and only if h(SG, AL, R) ≥ 0 and h(SB, AL, R) ≥ 0;
• π ∗ = ΠLH if and only if h(SG, AH, R) ≥ 0 and h(SB, AL, R) < 0;
• π ∗ = ΠHL if and only if h(SG, AL, R) < 0 and h(SB, AH, R) ≥ 0;
• π ∗ = ΠHH if and only if h(SG, AH, R) < 0 and h(SB, AH, R) < 0.

Proof. See Appendix A.

Thus, we could obtain the optimal protection policy of the user by analyzing h(s, αsc, R), and

we further have the following observation on it.

Proposition 3. Function h(s, αsc, R) is linearly increasing on the coverage level R.

17

Proof. We can see that h(s, αsc, R) is linear on R with a slope of
− δ (p(s, AH, sc) − p(s, AL, sc)) (Xsc − Xs). From the properties of protections and direct losses,

we have p(SG, AH, SB) − p(SG, AL, SB) < 0, XB − XG > 0, p(SB, AH, SG) − p(SB, AL, SG) > 0, and
XG − XB < 0. As a result, −δ (p(s, AH, sc) − p(s, AL, sc))(Xsc − Xs) > 0 and h(s, αsc, R) is linearly
increasing on R.

Before we obtain the optimal protection policy π ∗

R, we note the following proposition regarding

the uniqueness of π ∗
R.

Theorem 1. The optimal protection policy π ∗

R is unique.

Proof. See Appendix B.

With Lemma 1, Proposition 3, and Theorem 1, we can obtain the optimal protection policies

of the user with respect to the coverage level as stated in the following proposition.

Proposition 4. Let us deﬁne the value of transition probabilities as

ρ = p(SB, AH, SG) + p(SG, AH, SB) − p(SB, AL, SG) − p(SG, AL, SB).

(22)

The user’s optimal protection policies with respect to the insurer’s coverage level can be

summarized with the following cases as also shown in Fig. 3.
Case 1: If h(SG, AL, 0) ≥ 0 and h(SB, AL, 0) ≥ 0, the optimal protection policies π ∗
R ∈ [0, 1].

R = ΠLL for

Case 2: If h(SG, AL, 0) < 0 and h(SB, AH, 0) ≥ 0, we have ρ < 0 in this case. The optimal
protection policies π ∗

R = ΠHL for R ∈ [0, RG) and π ∗

R = ΠLL for R ∈ [RG, 1], where

RG = 1 − (1−δ +δ p(SB,AL,SG)+δ p(SG,AL,SB))(CH −CL)

δ (p(SG,AL,SB)−p(SG,AH ,SB))(XB−XG)

.

Case 3: If h(SG, AH, 0) ≥ 0 and h(SB, AL, 0) < 0, we have ρ > 0 in this case. The optimal
protection policies π ∗

R = ΠLH for R ∈ [0, RB) and π ∗

R = ΠLL for R ∈ [RB, 1], where

RB = 1 − (1−δ +δ p(SG,AL,SB)+δ p(SB,AL,SG))(CH −CL)

δ (p(SB,AH ,SG)−p(SB,AL,SG))(XB−XG)

.

Case 4: If h(SG, AH, 0) < 0 and h(SB, AH, 0) < 0,

• Case 4(a): If ρ < 0, π ∗

R = ΠHH for R ∈ [0, RB), π ∗

R = ΠHL for R ∈ [RB, RG), and π ∗

R = ΠLL

for R ∈ [RG, 1], where

RG = 1 − (1−δ +δ p(SB,AL,SG)+δ p(SG,AL,SB))(CH −CL)

δ (p(SG,AL,SB)−p(SG,AH ,SB))(XB−XG)

,

RB = 1 − (1−δ +δ p(SG,AH ,SB)+δ p(SB,AH ,SG))(CH −CL)

δ (p(SB,AH ,SG)−p(SB,AL,SG))(XB−XG)

.

18

• Case 4(b): If ρ > 0, π ∗

R = ΠHH for R ∈ [0, RG), π ∗

R = ΠLH for R ∈ [RG, RB), and π ∗

R = ΠLL

for R ∈ [RB, 1], where

RG = 1 − (1−δ +δ p(SB,AH ,SG)+δ p(SG,AH ,SB))(CH −CL)

δ (p(SG,AL,SB)−p(SG,AH ,SB))(XB−XG)

,

RB = 1 − (1−δ +δ p(SG,AL,SB)+δ p(SB,AL,SG))(CH −CL)

δ (p(SB,AH ,SG)−p(SB,AL,SG))(XB−XG)

.

• Case 4(c): If ρ = 0, π ∗

R = ΠHH for R ∈ [0, Rs) and π ∗

R = ΠLL for R ∈ [Rs, 1], where

Rs = RG = 1 − (1−δ +δ p(SB,AH ,SG)+δ p(SG,AH ,SB))(CH −CL)
δ (p(SG,AL,SB)−p(SG,AH ,SB))(XB−XG)
= RB = 1 − (1−δ +δ p(SG,AH ,SB)+δ p(SB,AH ,SG))(CH −CL)

δ (p(SB,AH ,SG)−p(SB,AL,SG))(XB−XG)

Proof. See Appendix C.

(a) Case 1

(b) Case 2

(c) Case 3

(d) Case 4(a)

(e) Case 4(b)

(f) Case 4(c)

Fig. 3. All possible cases of the user’s optimal protection policies with respect to the insurer’s coverage level. A detailed

discussion is provided in Proposition 4.

We can see from Proposition 4 that the user tends to take weak protections with the increase of

the coverage level in all cases, and this reckless behavior is often referred as the risk compensation

[21]. One critical impact of the risk compensation is the Peltzman effect as shown in the following

theorem.

Theorem 2. Peltzman effect: The user faces higher cyber risks under cyber-insurance. Such

19

phenomena exists in the following cases:

• R ∈ [RG, 1] in Case 2 and Case 4(b);

• R ∈ [RB, 1] in Case 3 and Case 4(a);

• R ∈ [Rs, 1] in Case 4(c).

Proof. We only need to prove that the user has higher expected cumulative direct losses in these

cases. Let Vd(s, π) and Vc(π) denote the expected cumulative direct losses and the expected

cumulative costs given the initial state s and the protection policy π. We have that Vd(s, π) +
Vc(π) = V (s, π, 0). Recall that the optimal protection policy π ∗
0 without insurance has V (s, π ∗
0 , 0) ≤
V (s, π, 0) for π ∈ Ω, thus, when the user has a different optimal protection policy π ∗
R (cid:54)= π ∗
0
given the coverage level R, we have V (s, π ∗
R, 0). As a result, we can achieve
R). Note that Vc(π ∗
0 ) ≤ Vd(s, π ∗
Vd(s, π ∗
R) in these cases as Vc(ΠHH) >
Vc(ΠHL) > Vc(ΠLL) and Vc(ΠHH) > Vc(ΠLH) > Vc(ΠLL) from CH > CL. Thus, we have Vd(s, π ∗
0 ) <
Vd(s, π ∗

R) and the user faces higher cyber risks.

0 , 0) ≤ V (s, π ∗

0 ) > Vc(π ∗

0 ) +Vc(π ∗

R) +Vc(π ∗

B. Optimal Insurance Contract

Recall Section IV, the insurer’s problem (12) in this case can be written as follows:

max
R∈[0,1]

τ(R) = V (SG, π ∗

0 , 0) −V (SG, π ∗

R, 0)

(23)

s.t. τ(R) ≥ 0,

where τ(R) denotes the operating proﬁt of the insurer if he provides a coverage level of R. Note

that SG in τ(R) indicates that the initial state of the user is the good state.

Proposition 5. The optimal insurance contract {K∗, R∗} for each case in Proposition 4 can be

summarized as follows:

• Case 1: R∗ ∈ [0, 1] and K∗ = R∗k(SG, AL; AL),
• Case 2: R∗ ∈ [0, RG] and K∗ = R∗k(SG, AH; AL),
• Case 3: R∗ ∈ [0, RB] and K∗ = R∗k(SG, AL; AH),
• Case 4(a): R∗ ∈ [0, RB] and K∗ = R∗k(SG, AH; AH),
• Case 4(b): R∗ ∈ [0, RG] and K∗ = R∗k(SG, AH; AH),

• Case 4(c): R∗ ∈ [0, Rs] and K∗ = R∗k(SG, AH; AH),

where

k(SG, αG; αB) = (1−δ p(SB,αB,SB))XG+δ p(SG,αG,SB)XB

Ip(αG,αB)

.

20

(24)

For all the cases, the operating proﬁt under the optimal insurance contract is 0, i.e., τ(R∗) = 0.

Proof. We can obtain the optimal insurance contract for all cases using the results from
Proposition 1. In Case 1, any coverage level R∗ ∈ [0, 1] is optimal, and the associated pre-
mium K∗ = V (SG, ΠLL, 0)−V (SG, ΠLL, R) = V (SG, AL; AL, 0)−V (SG, AL; AL, R) = R∗k(SG, AL; AL),
where k(SG, AL; AL) comes from (27) in Appendix A. Similarly, we can obtain the optimal

insurance contracts in Cases 2, 3, and 4.

We can see from the optimal insurance contracts that the premium is linear on the coverage

level, which can be summarized as the linear insurance contract principle. Moreover, all the

optimal insurance contracts lead to a zero operating proﬁt for the insurer, which indicates a

zero-operating proﬁt principle. The optimal insurance contracts usually provide limited coverage

levels. When the coverage level is high, the user tends to act recklessly, which induces high risks

and high direct losses of the user as shown in Theorem 2, and the insurer is required to cover

the extra losses caused by that, which induces a negative proﬁt of him. As a result, the insurer

chooses not to provide the insurance to the user in that case.

VI. NUMERICAL EXAMPLES

In this section, we ﬁrst present numerical experiments on a two-state two-action user and

a linear coverage insurer to verify our previous analytical results. We then present numerical

experiments on a four-state three-action user with a linear coverage insurer and a threshold

coverage insurer.

A. Two-State Two-Action User and Linear Coverage Insurer

In this subsection, we aim to verify our analysis on the two-state two-action user and the linear

coverage insurer with numerical experiments. We assume that the user has δ = 0.9, XG = 0,

XB = 10, CL = 0, CH = 1, p(SG, AL, SB) = p(SG, AL, SG) = 0.5, p(SB, AL, SG) = p(SB, AL, SB) = 0.5,

p(SG, AH, SB) = 1 − p(SG, AH, SG) = 0.2, and p(SB, AH, SG) = 1 − p(SB, AH, SB) = 0.6. We can

achieve that ρ = −0.20, h(SG, AH, 0) = −1.88, h(SG, AL, 0) = −1.70, h(SB, AH, 0) = −0.08, and

h(SB, AL, 0) = 0.10. Thus, the user’s optimal protection policies can be described as the Case 4(a) in

21

Proposition 4. The optimal insurance contract {K∗, R∗} has R∗ ∈ [0, RB] and K∗ = R∗k(SG, AH; AH),
where RB = 0.0889 and k(SG, AH; AH) = 21.9512 from Proposition 5.

With the dynamic programming approach or linear programming approach in Section III, we

can compute the optimal protection policies and the expected cumulative effective losses of the

user as shown in Figs.4(a,b). We can further calculate the premium and the operating proﬁt of

the insurer as shown in Figs.4(c,d). We can see that the numerical results coincide with our

analytical results.

(a)

(c)

(b)

(d)

Fig. 4. Two-State Two-Action User and Threshold Coverage Insurer. The horizontal axis in Figs. (a), (b), (c), (d) represents the

coverage level R. The green area denotes the region of optimal insurance contracts.

B. Four-State Three-Action User and Linear Coverage Insurer

In this subsection, we consider a more complicated example where the user has four states

and three actions, and the insurer provides linear coverage. We show that our model can be used

to analyze the interactions between the user and the insurer in a numerical way.

22

We assume that the user’s states can be identiﬁed as SG, SB,1, SB,2, and SB,3 with the state losses

XG = 0, XB,1 = 4, XB,2 = 8, and XB,3 = 16, respectively. SG indicates the good state, while SB,i

indicates the bad states with i capturing the level of the damage. The user can take no protection

A0, weak protection AL, or strong protection AH, and the costs of them can be identiﬁed as

c(A0) = 0, c(AL) = 0.3, and c(AH) = 0.6, respectively. Different actions have different impacts

on the transition probabilities. For convenience, we summarize the transition probabilities by the

following matrix:










Pa =

p(SG, a, SG)

p(SG, a, SB,1)

p(SG, a, SB,2)

p(SG, a, SB,3)

p(SB,1, a, SG) p(SB,1, a, SB,1) p(SB,1, a, SB,2) p(SB,1, a, SB,3)

p(SB,2, a, SG) p(SB,2, a, SB,1) p(SB,2, a, SB,2) p(SB,2, a, SB,3)

p(SB,3, a, SG) p(SB,3, a, SB,1) p(SB,3, a, SB,2) p(SB,3, a, SB,3)










(25)

The user has a larger probability of going to the good state and a smaller probability of going to

the bad state with better protections. We then take the following transition probabilities in this

example:

PA0 =










0.25 0.25 0.25 0.25

0.25 0.25 0.25 0.25

0.25 0.25 0.25 0.25

0.25 0.25 0.25 0.25










;

PAL =

PAH =



















0.4 0.3 0.2 0.1

0.4 0.3 0.2 0.1

0.4 0.3 0.2 0.1

0.4 0.3 0.2 0.1

0.8 0.2 0.0 0.0

0.7 0.2 0.1 0.0

0.6 0.2 0.1 0.1

0.5 0.2 0.2 0.1










;










.

Let δ = 0.9, the optimal protection policies and the expected cumulative effective losses of the

user are shown in Figs.5(a,b). We can see from (a,b) that the user decreases his protections with

the increase of the coverage level, and the user also has lower expected cumulative effective

losses with higher coverage levels. The premium and the operating proﬁt of the insurer are shown

in Figs.5(c,d). We can see that with the increase of the coverage level, the premium is linearly

23

increasing. Moreover, the maximum operating proﬁt that can be achieved by the insurer is 0. We

can also observe that the optimal insurance contract tends to provide limited coverage levels,

and higher coverage levels can lead to negative operating proﬁts of the insurer. Thus, the risk

compensation, the zero-operating proﬁt principle, and the linear insurance contract principle still

hold in this example.

(a)

(c)

(b)

(d)

Fig. 5. Four-State Three-Action User and Linear Coverage Insurer. The horizontal axis in Figs. (a), (b), (c), (d) represents the

coverage level R. The green area denotes the region of optimal insurance contracts.

C. Four-State Three-Action User and Threshold Coverage Insurer

In this subsection, we consider a threshold coverage insurance and show its impact on the

four-state three-action user and the insurer.

We use the same settings for the user as in the previous subsection. The threshold insurance

contract has two coverage levels R0 = 0 and R1 = 0.9, which are distinguished by a threshold

XR ∈ [0, 20]. When the loss of the user x ≤ XR, the insurer provides no coverage R0x, otherwise,

24

the insurer provides a coverage R1x. A lower XR indicates that the insurance has a higher coverage

for smaller losses. The objective of the insurer is to maximize his operating proﬁt by ﬁnding the
optimal threshold X ∗

R and the associated premium K∗.

The optimal protection policies and the expected cumulative effective losses of the user are

shown in Fig.6(a,b), and we can see from them that the user decreases his protections with

the decrease of the threshold XR, which indicates that the user tends to act recklessly knowing

that the insurer provides a high coverage even he has a small loss from cyber risks. Moreover,

we can see that the premium is a staircase function on the threshold XR, and it decreases with

the increase of XR, which shows that the insurer charges a higher premium to provide a higher

coverage level. The maximum operating proﬁt that can be achieved by the insurer is 0. As a

result, this example shows the similar risk compensation and zero-operating proﬁt principle as

in the previous examples. Note that the gray area has XR > XB,3, i.e., the insurer provides no

coverage for the user at any states, which is equivalent to the case when there is no insurance.

VII. CONCLUSION

In this paper, we have presented a dynamic moral-hazard type of principal-agent model to

study the cyber-insurance and its impacts on the cyber-security. The dynamics and correlations

of the cyber risks have been modeled by Markov decision processes where the user aims to ﬁnd

the optimal protection policy to mitigate the impacts of cyberattacks. Both the computational

and analytical tools have been presented to design the optimal cyber-insurance contracts. We

have studied and fully analyzed a case where the user has two states and two actions, and the

insurer provides linear coverage insurance. We have further demonstrated the Peltzman effect

that the user has higher cyber risks under insurance due to risk compensation, i.e., the user

tends to act more recklessly knowing he is protected. We have presented the linear insurance

contract principle and the zero-operating proﬁt principle of the optimal cyber-insurance contract.

Numerical experiments have been used to corroborate our results and further demonstrate the

case study with a four-state three-action user and his interactions with linear coverage insurance

and threshold coverage insurance. The risk compensation and the zero-operating proﬁt principle

have been shown to hold in these cases. One direction of future research is the investigation of

cyber-insurance contracts over complex networks such as scale-free and small-world networks

with dynamic cyber risks.

25

(a)

(c)

(b)

(d)

Fig. 6. Four-State Three-Action User and Threshold Coverage Insurer. The horizontal axis in Figs. (a), (b), (c), (d) represents

the threshold XR. The green area denotes the region of optimal insurance contracts.

APPENDIX A. PROOF OF PROPOSITION 2

To simplify the notation in this proof, we deﬁne the discounted transition probabilities as

(cid:98)p(s, αs, s) = 1 − δ p(s, αs, s),
(cid:98)p(s, αs, sc) = δ p(s, αs, sc).

Remark 3. The following facts hold for (cid:98)p:
(i) (cid:98)p(SG, αG, SG) − (cid:98)p(SG, αG, SB) = (cid:98)p(SB, αB, SB) − (cid:98)p(SB, αB, SG) = 1 − δ ;
(ii) If δ = 1, we have (cid:98)p(SG, αG, SG) = (cid:98)p(SG, αG, SB) and (cid:98)p(SB, αB, SB) = (cid:98)p(SB, αB, SG).

Thus, (21) can be written as

Ip(αG, αB) = (cid:98)p(SG, αG, SG) (cid:98)p(SB, αB, SB) − (cid:98)p(SG, αG, SB) (cid:98)p(SB, αB, SG).

26

Remark 4. The following facts hold for Ip:

(i) Ip(αG, αB) = (1 − δ + (cid:98)p(SG, αG, SB))(1 − δ + (cid:98)p(SB, αB, SG)) − (cid:98)p(SG, αG, SB) (cid:98)p(SB, αB, SG) =

(1 − δ )2 + (1 − δ )( (cid:98)p(SG, αG, SB) + (cid:98)p(SB, αB, SG)) > 0 when 0 ≤ δ < 1;

(ii) Ip(AH, αB) − Ip(AL, αB) = (1 − δ )( (cid:98)p(SG, AH, SB) − (cid:98)p(SG, AL, SB));
(iii) Ip(αG, AH) − Ip(αG, AL) = (1 − δ )( (cid:98)p(SB, AH, SG) − (cid:98)p(SB, AL, SG)).

The action dependent expected cumulative effective losses (19) and (20) can be rewritten as

follows:

where

Note that

V (s, αs; αsc, R) = (1 − R)k(s, αs; αsc) + b(s, αs; αsc),

k(s, αs; αsc) = (cid:98)p(SB,αB,sc)XG+ (cid:98)p(SG,αG,sc)XB

Ip(αG,αB)

;

b(s, αG; αsc) = (cid:98)p(SB,αB,sc)c(αG)+ (cid:98)p(SG,αG,sc)c(αB)

Ip(αG,αB)

.

− (cid:98)p(SB,αB,SB)XG+ (cid:98)p(SG,AL,SB)XB
Ip(AL,αB)

k(SG, AH; αB) − k(SG, AL; αB)
= (cid:98)p(SB,αB,SB)XG+ (cid:98)p(SG,AH ,SB)XB
Ip(AH ,αB)
= (cid:98)p(SB,αB,SB)Ip(AL,αB)XG+ (cid:98)p(SG,AH ,SB)Ip(AL,αB)XB
Ip(AH ,αB)Ip(AL,αB)
= (cid:98)p(SB,αB,SB)(Ip(AL,αB)−Ip(AH ,αB))XG
Ip(AH ,αB)Ip(AL,αB)
= (1−δ ) (cid:98)p(SB,αB,SB)( (cid:98)p(SG,AL,SB)− (cid:98)p(SG,AH ,SB))XG
Ip(AH ,αB)Ip(AL,αB)
= (1−δ ) (cid:98)p(SB,αB,SB)( (cid:98)p(SG,AL,SB)− (cid:98)p(SG,AH ,SB))(XG−XB)
Ip(AH ,αB)Ip(AL,αB)

,

− (cid:98)p(SB,αB,SB)Ip(AH ,αB)XG+ (cid:98)p(SG,AL,SB)Ip(AH ,αB)XB
Ip(AH ,αB)Ip(AL,αB)

+ (cid:98)p(SG,AH ,SB)Ip(AL,αB)XB− (cid:98)p(SG,AL,SB)Ip(AH ,αB)XB
Ip(AH ,αB)Ip(AL,αB)

+ (1−δ ) (cid:98)p(SB,αB,SB)( (cid:98)p(SG,AH ,SB)− (cid:98)p(SG,AL,SB))XB
Ip(AH ,αB)Ip(AL,αB)

(26)

(27)

(28)

(29)

where the fourth equality is achieved by plugging Remark 4(i)(ii). Similarly, we can achieve that

k(SB, AH; αG) − k(SB, AL; αG) = (1−δ ) (cid:98)p(SG,αG,SG)( (cid:98)p(SB,AH ,SG)− (cid:98)p(SB,AL,SG))(XG−XB)

Ip(αG,AH )Ip(αG,AL)

;

(30)

b(SG, AH; αB) − b(SG, AL; αB) = (1−δ ) (cid:98)p(SB,αB,SB)( (cid:98)p(SB,αB,SB)+ (cid:98)p(SG,αB,SB))(CH −CL)

Ip(AH ,αB)Ip(AL,αB)

;

b(SB, AH; αG) − b(SB, AL; αG) = (1−δ ) (cid:98)p(SG,αG,SG)( (cid:98)p(SG,αG,SG)+ (cid:98)p(SB,αG,SG))(CH −CL)

Ip(αG,AH )Ip(αG,AL)

.

As a result, we have

V (SG, AH; αB, R) −V (SG, AL; αB, R)

= (1 − R) (k(SG, AH; αB) − k(SG, AL; αB)) + b(SG, AH; αB) − b(SG, AL; αB)
= (1−δ ) (cid:98)p(SB,αB,SB)

Ip(AH ,αB)Ip(AL,αB)h(SG, αB, R);

V (SB, AH; αG, R) −V (SB, AL; αG, R) = (1−δ ) (cid:98)p(SG,αG,SG)

Ip(αG,AH )Ip(αG,AL)h(SB, αG, R),

(31)

(32)

(33)

(34)

27

where h(s, αsc, R) has been deﬁned in Proposition 2. Since 1 − δ > 0, (cid:98)p(s, αs, s) > 0, and
Ip(αs, αsc) > 0, we have that V (s, AH; αsc, R) < V (s, AL; αsc, R) if h(s, αsc, R) < 0 and V (s, AH; αsc, R) ≥

V (s, AL; αsc, R) if h(s, αsc, R) ≥ 0. Proposition 2 holds.

APPENDIX B. PROOF OF THEOREM 1

Recall the value of transition probabilities ρ from (22) in Proposition 4. Besides Proposition

3, we note that h(s, αsc, R) has the following extra facts.

h(SG, AH, R) − h(SG, AL, R) = h(SB, AH, R) − h(SB, AL, R) = ρδ (CH −CL);

h(SG, AH, R) − h(SB, AH, R) = h(SG, AL, R) − h(SB, AL, R) = ρδ (1 − R)(XB − XG);

h(SG, AH, R) − h(SB, AL, R) = ρδ ((CH −CL) + (1 − R)(XB − XG)) ;

h(SB, AH, R) − h(SG, AL, R) = ρδ ((CH −CL) − (1 − R)(XB − XG)) .

(35)

(36)

(37)

(38)

If π ∗
and π ∗
R (cid:54)= ΠLH and π ∗
π ∗
uniqueness of π ∗
same time and (ii). π ∗
R = ΠLH and π ∗

If π ∗

R = ΠHL, we have h(SG, AL, R) < 0 and h(SB, AH, R) ≥ 0 from Proposition 2. Thus, π ∗
R (cid:54)= ΠHH. Similarly, if π ∗
R = ΠLH, we have π ∗
R = ΠHH, we have π ∗
R (cid:54)= ΠHL; if π ∗
R, we only need to prove that (i). π ∗

R (cid:54)= ΠLL
R = ΠLL, we have
R (cid:54)= ΠHL. Thus, to prove the
R = ΠHL cannot exist at the

R (cid:54)= ΠLH and π ∗
R = ΠLH and π ∗

R (cid:54)= ΠLL and π ∗

R (cid:54)= ΠHH; if π ∗

R = ΠLL and π ∗
R = ΠHL at the same time, we have h(SG, AH, R) ≥ 0, h(SB, AL, R) < 0,
h(SG, AL, R) < 0, and h(SB, AH, R) ≥ 0 from Proposition 2, which indicates that ρ > 0 from

R = ΠHH cannot exist at the same time.

(37) as h(SG, AH, R) > h(SB, AL, R) and ρδ ((CH −CL) − (1 − R)(XB − XG)) > 0 from (38) as

h(SG, AL, R) < h(SB, AH, R). Thus, we can achieve that (CH −CL) > (1 − R)(XB − XG). However,

h(SG, AL, R)

= (1 − R)δ (p(SG, AH, SB) − p(SG, AL, SB))(XB − XG)

+(1 − δ + δ p(SB, AL, SG) + δ p(SG, AL, SB))(CH −CL)

> (1 − R)δ (p(SG, AH, SB) − p(SG, AL, SB))(XB − XG)

(39)

+ (1 − δ + δ p(SB, AL, SG) + δ p(SG, AL, SB)) (1 − R)(XB − XG)

= (1 − R)(XB − XG) (1 − δ + δ p(SG, AH, SB) + δ p(SB, AL, SG))

> 0,

which violates h(SG, AL, R) < 0. As a result, π ∗

R = ΠLH and π ∗

R = ΠHL cannot exist at the same

time.

If π ∗

R = ΠLL and π ∗

R = ΠHH at the same time, we have h(SG, AL, R) ≥ 0, h(SB, AL, R) ≥ 0,
h(SG, AH, R) < 0, and h(SB, AH, R) < 0, which indicates that ρ < 0 from (35) and ρδ ((CH −CL) − (1 − R)(XB − XG)) <

28

0 from (38). Thus, we can achieve that (CH −CL) − (1 − R)(XB − XG) > 0. However,

h(SB, AH, R)

= (1 − R)δ (p(SB, AH, SG) − p(SB, AL, SG))(XG − XB)

+(1 − δ + δ p(SB, AH, SG) + δ p(SG, AH, SB))(CH −CL)

> (1 − R)δ (p(SB, AH, SG) − p(SB, AL, SG))(XG − XB)

+ (1 − δ + δ p(SB, AH, SG) + δ p(SG, AH, SB)) (1 − R)(XB − XG)

= (1 − R)(XB − XG) (1 − δ + δ p(SG, AH, SB) + δ p(SB, AL, SG))

> 0,

which violates h(SB, AH, R) < 0. As a result, π ∗

R = ΠLL and π ∗

R = ΠHH cannot exist at the same

time. Thus, Theorem 1 holds.

APPENDIX C. PROOF OF PROPOSITION 4

There are only four possible protection policies ΠLL, ΠHL, ΠLH, and ΠHH. Thus, the optimal

protection policy π ∗

0 without insurance has only four cases: Case 1, Case 2, Case 3, and Case 4
as presented in Proposition 4, which are determined by h(s, αsc, 0) in Proposition 2. As a result,
we only need to prove the trends of π ∗

R with respect to R in different cases.

We ﬁrst note that when R = 1, we have h(SG, αB, 1) > 0 and h(SB, αG, 1) > 0, which indicates

that π ∗

R=1 = ΠLL. Moreover, if the user has π ∗
(cid:98)R

= ΠLL for a coverage level of (cid:98)R ∈ [0, 1], we have
h(SG, AL, (cid:98)R) ≥ 0 and h(SB, AL, (cid:98)R) ≥ 0 from Proposition 2. Since h(s, αsc, R) is linearly increasing
on R as shown in Proposition 3, we have h(SG, AL, R) ≥ 0 and h(SB, AL, R) ≥ 0 for R ≥ (cid:98)R, which
indicates that π ∗
R = ΠLL when R is sufﬁciently
large and the user chooses not to change his policy with the increase of R once he achieves
π ∗
R = ΠLL for all cases.
To prove Cases 2, 3, and 4, recall the value of transition probabilities ρ from (22). If ρ < 0, we

R = ΠLL for R ≥ (cid:98)R. Thus, we can conclude that π ∗

have h(SG, AH, R) < h(SB, AL, R) from (37). However, when π ∗
R = ΠLH, we have h(SG, AH, R) ≥ 0
and h(SB, AL, R) < 0 from Proposition 2, which violates h(SG, AH, R) < h(SB, AL, R). Thus, we
have π ∗
R (cid:54)= ΠLH if ρ < 0. As a result, Case 2 and Case 4(a) has ρ < 0 and the user have π ∗
in these cases. Since h(SB, AH, 0) ≥ 0 when π ∗
increasing on R, h(SB, AH, R) ≥ 0 for R ∈ [0, 1]. Thus, the user has π ∗

R (cid:54)= ΠLH
0 = ΠHL in Case 2 and h(SB, AH, R) is linearly
R (cid:54)= πHH in Case 2 and Case
2 holds. The threshold RG is achieved by solving h(SG, AL, R) = 0. Case 4(a) holds from Case

29

2, and the thresholds RG and RB are achieved by solving h(SG, AL, R) = 0 and h(SB, AH, R) = 0,

respectively.

If ρ > 0 and π ∗

R = ΠHL, we have h(SG, AL, R) < 0 and h(SB, AH, R) ≥ 0 from Proposition 2
and thus h(SB, AH, R) − h(SG, AL, R) = ρδ ((CH −CL) − (1 − R)(XB − XG)) > 0 from (38), which

indicates that (CH −CL) − (1 − R)(XB − XG) > 0. However, we could obtain that h(SG, AL, R) > 0
following similar arguments as in (39), which violates h(SG, AL, R) < 0. Thus, we have π ∗
R (cid:54)= ΠHL
if ρ > 0. As a result, Case 3 and Case 4(b) have ρ > 0 and the user has π ∗
R (cid:54)= ΠHL in these
cases. Since h(SG, AH, R) ≥ 0 when π ∗
0 = ΠLH in Case 3 and h(SG, AH, R) is linearly increasing
on R, h(SG, AH, R) ≥ 0 for R ∈ [0, 1]. Thus, the user has π ∗
R (cid:54)= πHH in Case 3 and Case 3 holds.
The threshold RB is achieved by solving h(SB, AL, R) = 0. Case 4(b) holds from Case 3, and the

thresholds RB and RG are achieved by solving h(SB, AL, R) = 0 and h(SG, AH, R) = 0, respectively.

If ρ = 0, we have h(SG, AH, R) = h(SG, AL, R) = h(SB, AH, R) = h(SB, AL, R) from (35)-(38).

However, ΠLH and ΠHL indicate that h(SG, AH, R) ≥ 0 > h(SB, AL, R) and h(SG, AL, R) < 0 ≤
h(SB, AH, R), respectively. Thus, we have π ∗
4(c) has ρ = 0 and the user has π ∗

R (cid:54)= ΠLL if ρ = 0. As a result, Case
R (cid:54)= ΠLH. Thus, Case 4(c) holds, and the thresholds

R (cid:54)= ΠHH and π ∗

R (cid:54)= ΠHL and π ∗

RG and RB are achieved by solving h(SG, AH, R) = 0 and h(SB, AH, R) = 0, respectively.

REFERENCES

[1] G. O’Gorman and G. McDonald, Ransomware: A growing menace. Symantec Corporation, 2012.

[2] S. Romanosky, D. Hoffman, and A. Acquisti, “Empirical analysis of data breach litigation,” Journal of Empirical Legal

Studies, vol. 11, no. 1, pp. 74–104, 2014.

[3] Ł. Apiecionek, J. M. Czerniak, and H. Zarzycki, “Protection tool for distributed denial of services attack,” in International

Conference: Beyond Databases, Architectures and Structures, pp. 405–414, Springer, 2014.

[4] M. H. Manshaei, Q. Zhu, T. Alpcan, T. Bacs¸ar, and J.-P. Hubaux, “Game theory meets network security and privacy,” ACM

Computing Surveys (CSUR), vol. 45, no. 3, p. 25, 2013.

[5] L. Kelion, “Cryptolocker ransomware has’ infected about 250,000 pcs’,” BBC News techology, 2013.

[6] S. Hilton, “Dyn analysis summary of friday october 21 attack,” Dyn Blog. Dyn News, vol. 26, 2016.

[7] W. R. Cheswick, S. M. Bellovin, and A. D. Rubin, Firewalls and Internet security: repelling the wily hacker. Addison-Wesley

Longman Publishing Co., Inc., 2003.

[8] C. H. Rowland, “Intrusion detection system,” June 11 2002. US Patent 6,405,318.

[9] S. Jajodia, A. K. Ghosh, V. Subrahmanian, V. Swarup, C. Wang, and X. S. Wang, Moving Target Defense II: Application

of Game Theory and Adversarial Modeling, vol. 100. Springer, 2012.

[10] V. Kumar, J. Srivastava, and A. Lazarevic, Managing cyber threats: issues, approaches, and challenges, vol. 5. Springer

Science & Business Media, 2006.

[11] J. P. Farwell and R. Rohozinski, “Stuxnet and the future of cyber war,” Survival, vol. 53, no. 1, pp. 23–40, 2011.

30

[12] A. Beelitz and D. M. Merkl-Davies, “Using discourse to restore organisational legitimacy:‘ceo-speak’after an incident in a

german nuclear power plant,” Journal of Business Ethics, vol. 108, no. 1, pp. 101–120, 2012.

[13] J. Kesan, R. Majuca, and W. Yurcik, “Cyberinsurance as a market-based solution to the problem of cybersecurity: a case

study,” in Proc. WEIS, pp. 1–46, 2005.

[14] R. B¨ohme, G. Schwartz, et al., “Modeling cyber-insurance: Towards a unifying framework.,” in WEIS, 2010.

[15] N. Shetty, G. Schwartz, M. Felegyhazi, and J. Walrand, “Competitive cyber-insurance and internet security,” Economics of

Information Security and Privacy, pp. 229–247, 2010.

[16] R. Pal, L. Golubchik, K. Psounis, and P. Hui, “Will cyber-insurance improve network security? a market analysis,” in

INFOCOM, 2014 Proceedings IEEE, pp. 235–243, IEEE, 2014.

[17] R. Zhang, Q. Zhu, and Y. Hayel, “A bi-level game approach to attack-aware cyber insurance of computer networks,” IEEE

Journal on Selected Areas in Communications, vol. 35, no. 3, pp. 779–794, 2017.

[18] M. Rothschild and J. Stiglitz, “Equilibrium in competitive insurance markets: An essay on the economics of imperfect

information,” in Uncertainty in economics, pp. 257–280, Elsevier, 1978.

[19] B. Holmstrom et al., “Moral hazard and observability,” Bell journal of Economics, vol. 10, no. 1, pp. 74–91, 1979.

[20] B. Holmstrom, “Moral hazard in teams,” The Bell Journal of Economics, pp. 324–340, 1982.

[21] F. Ewold, “Insurance and risk,” The Foucault effect: Studies in governmentality, pp. 197–210, 1991.

[22] S. Xu, “Cybersecurity dynamics,” in Proceedings of the 2014 Symposium and Bootcamp on the Science of Security, p. 14,

ACM, 2014.

[23] D. Fava, J. Holsopple, S. J. Yang, and B. Argauer, “Terrain and behavior modeling for projecting multistage cyber attacks,”

in Information Fusion, 2007 10th International Conference on, pp. 1–7, IEEE, 2007.

[24] S. Cheung, U. Lindqvist, and M. W. Fong, “Modeling multistep cyber attacks for scenario recognition,” in DARPA

information survivability conference and exposition, 2003. Proceedings, vol. 1, pp. 284–292, IEEE, 2003.

[25] R. B¨ohme and G. Kataria, “Models and measures for correlation in cyber-insurance.,” in WEIS, 2006.

[26] P. Tague and R. Poovendran, “Modeling node capture attacks in wireless sensor networks,” in Communication, Control,

and Computing, 2008 46th Annual Allerton Conference on, pp. 1221–1224, IEEE, 2008.

[27] P. Tague, M. Li, and R. Poovendran, “Mitigation of control channel jamming under node capture attacks,” IEEE Transactions

on Mobile Computing, vol. 8, no. 9, pp. 1221–1234, 2009.

[28] A. K. Jones and R. S. Sielken, “Computer system intrusion detection: A survey,” Computer Science Technical Report,

pp. 1–25, 2000.

[29] S. Romanosky, R. Telang, and A. Acquisti, “Do data breach disclosure laws reduce identity theft?,” Journal of Policy

Analysis and Management, vol. 30, no. 2, pp. 256–286, 2011.

[30] A. Gazet, “Comparative analysis of various ransomware virii,” Journal in computer virology, vol. 6, no. 1, pp. 77–90, 2010.

[31] M. L. Puterman, Markov decision processes: discrete stochastic dynamic programming. John Wiley & Sons, 2014.

[32] S. Roy, C. Ellis, S. Shiva, D. Dasgupta, V. Shandilya, and Q. Wu, “A survey of game theory as applied to network security,”

in System Sciences (HICSS), 2010 43rd Hawaii International Conference on, pp. 1–10, IEEE, 2010.

[33] S. J. Grossman and O. D. Hart, “An analysis of the principal-agent problem,” Econometrica: Journal of the Econometric

Society, pp. 7–45, 1983.

[34] J.-J. Laffont and D. Martimort, The theory of incentives: the principal-agent model. Princeton university press, 2009.

[35] R. B¨ohme, “Cyber-insurance revisited.,” in WEIS, 2005.

[36] J. Grossklags, N. Christin, and J. Chuang, “Secure or insure?: a game-theoretic analysis of information security games,” in

Proceedings of the 17th international conference on World Wide Web, pp. 209–218, ACM, 2008.

31

[37] D. K. Tosh, S. Shetty, S. Sengupta, J. P. Kesan, and C. A. Kamhoua, “Risk management using cyber-threat information

sharing and cyber-insurance,” in International Conference on Game Theory for Networks, pp. 154–164, Springer, 2017.

[38] J. P. Kesan and C. M. Hayes, “Strengthening cybersecurity with cyberinsurance markets and better risk assessment,” Minn.

L. Rev., vol. 102, p. 191, 2017.

[39] A. Laszka, E. Panaousis, and J. Grossklags, “Cyber-insurance as a signaling game: Self-reporting and external security

audits,” in Proceedings of the 9th Conference on Decision and Game Theory for Security (GameSec 2018), Springer, 2018.

[40]

I. Ehrlich and G. S. Becker, “Market insurance, self-insurance, and self-protection,” Journal of political Economy, vol. 80,

no. 4, pp. 623–648, 1972.

[41] W. Stallings, Network and internetwork security: principles and practice, vol. 1. Prentice Hall Englewood Cliffs, New

Jersey, 1995.

[42] A. Perrig, J. Stankovic, and D. Wagner, “Security in wireless sensor networks,” Communications of the ACM, vol. 47,

no. 6, pp. 53–57, 2004.

[43] Q. Zhu, C. Fung, R. Boutaba, and T. Basar, “Guidex: A game-theoretic incentive-based mechanism for intrusion detection

networks,” IEEE Journal on Selected Areas in Communications, vol. 30, no. 11, pp. 2220–2230, 2012.

[44] N. Poolsappasit, R. Dewri, and I. Ray, “Dynamic security risk management using bayesian attack graphs,” IEEE Transactions

on Dependable and Secure Computing, vol. 9, no. 1, pp. 61–74, 2012.

[45] J. Kim, S. Radhakrishnan, and S. K. Dhall, “Measurement and analysis of worm propagation on internet network topology,” in

Computer Communications and Networks, 2004. ICCCN 2004. Proceedings. 13th International Conference on, pp. 495–500,

IEEE, 2004.

[46] Y. Wu, B. Wang, and K. R. Liu, “Optimal defense against jamming attacks in cognitive radio networks using the markov

decision process approach,” in Global Telecommunications Conference (GLOBECOM 2010), 2010 IEEE, pp. 1–5, IEEE,

2010.

[47] D. Shen, G. Chen, E. Blasch, and G. Tadda, “Adaptive markov game theoretic data fusion approach for cyber network

defense,” in Military Communications Conference, 2007. MILCOM 2007. IEEE, pp. 1–7, IEEE, 2007.

[48] J. Filar and K. Vrieze, Competitive Markov decision processes. Springer Science & Business Media, 2012.

