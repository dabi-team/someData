9
1
0
2

r
a

M
8
1

]

R
C
.
s
c
[

1
v
7
2
7
7
0
.
3
0
9
1
:
v
i
X
r
a

An Adversarial Risk Analysis Framework for Cybersecurity

1, D. Rios Insua1, A. Couce-Vieira1, J.A. Rubio2, W. Pieters3, K. Labunets3, and D. G.

Rasines4

1Instituto de Ciencias Matem´aticas, Consejo Superior de Investigaciones Cient´ıﬁcas, Madrid, Spain,

david.rios@icmat.es, aitor.couce@icmat.es

2Analysis, Security and Systems Group, Complutense University of Madrid, Spain, joseantonio.rubio@fdi.ucm.es

3Safety & Security Science Group, Delft University of Technology, Delft, The Netherlands, w.pieters@tudelft.nl,

4Department of Mathematics, Imperial College, London, UK, daniel.garcia-rasines16@imperial.ac.uk

k.labunets@tudelft.nl

Abstract

Cyber threats aﬀect all kinds of organisations. Risk analysis is an essential methodology for cybersecurity

as it allows organisations to deal with the cyber threats potentially aﬀecting them, prioritise the defence

of their assets and decide what security controls should be implemented. Many risk analysis methods are

present in cybersecurity models, compliance frameworks and international standards. However, most of

them employ risk matrices, which suﬀer shortcomings that may lead to suboptimal resource allocations.

We propose a comprehensive framework for cybersecurity risk analysis, covering the presence of both

adversarial and non-intentional threats and the use of insurance as part of the security portfolio. A case

study illustrating the proposed framework is presented, serving as template for more complex cases.

Keywords: cybersecurity, risk analysis, adversarial risk analysis, cyber insurance, resource allocation

1 INTRODUCTION

At present, all kinds of organisations are being critically impacted by cyber threats [3, 4]. The Cyberspace is

even described as a ﬁfth military operational space in which movements by numerous countries are common

[25]. Risk analysis is a fundamental methodology to help manage such issues [11]. With it, organizations

can assess the risks aﬀecting their assets and what security controls should be implemented to reduce the

likelihood of such threats and/or their impacts, in case they are produced.

1

 
 
 
 
 
 
Numerous frameworks have been developed to screen cybersecurity risks and support resource allocation,

including CRAMM [7], ISO 27005 [23], MAGERIT [29], EBIOS [1], SP 800-30 [32], or CORAS [26]. Simil-

arly, several compliance and control assessment frameworks, like ISO 27001 [22], Common Criteria [10], or

CCM [9] provide guidance on the implementation of cybersecurity best practices. These standards suggest

detailed security controls to protect an organisation’s assets against risks. They have virtues, particularly

their extensive catalogues of threats, assets and security controls providing detailed guidelines for the imple-

mentation of countermeasures and the protection of digital assets. Even though, much remains to be done

regarding cybersecurity risk analysis from a methodological point of view. Indeed, a detailed study of the

main approaches to cybersecurity risk management and control assessment reveals that they often rely on

risk matrices, with shortcomings well documented in Cox [12]: compared to more stringent methods, the

qualitative ratings in risk matrices (likelihood, severity and risk) are more prone to ambiguity and subjective

interpretation, and very importantly for our application area, they systematically assign the same rating to

quantitatively very diﬀerent risks, potentially inducing suboptimal security resource allocations. Hubbard

and Seiersen [20] and Allodi an Massacci [2] provide additional views on the use of risk matrices in cyber-

security. Moreover, with counted exceptions like IS1 [33], those methodologies do not explicitly take into

account the intentionality of certain threats. Thus, ICT owners may obtain unsatisfactory results in relation

with the proper prioritisation of risks and the measures they should implement.

In this context, a complementary way for dealing with cyber risks through risk transfer is emerging:

cyber insurance products, of very diﬀerent nature and not in every country, have been introduced in recent

years by companies like AXA, Generali, Allianz, or Zurich. However, cyber insurance has yet to take oﬀ [27].

In this paper we propose a more rigorous framework for risk analysis in cybersecurity. We emphasise

adversarial aspects for better prediction of threats as well as include cyber insurance. Sect. 2 presents our

framework, supported by a case study in Sect. 3. We conclude with a brief discussion.

2 A CYBERSECURITY ADVERSARIAL RISK ANALYSIS FRAMEWORK

We introduce our integrated risk analysis approach to facilitate resource allocation decision-making regarding

cybersecurity. Our aim is to improve current cyber risk analysis frameworks, introducing dynamic schemes

that incorporate all relevant parameters, including decision-makers’ preferences and risk attitudes [8] and

the intentionality of adversaries. Moreover, we introduce decisions concerning cyber insurance adoption to

complement other risk management decisions through risk transfer. Fielder et al. [17] review and introduce

various approaches to cyber security investment, which cover optimisation and/or game theoretic elements,

under strong common knowledge assumptions. Our framework combines optimisation with an adversarial

2

Figure 1: Basic inﬂuence diagram for performance evaluation.

Figure 2: Cybersecurity attributes for performance evaluation.

risk analysis (ARA) approach to deal with adversarial agents.

We present the framework stepwise, analysing the elements involved progressively. We describe the

models through inﬂuence diagrams (ID) and bi-agent inﬂuence diagrams (BAID) [6] detailing the relevant

elements: assets, threats, security controls, costs and beneﬁts. We provide a brief verbal description of the

diagrams introduced and a generic mathematical formulation at each step.

2.1 System performance evaluation

Fig. 1 describes the starting outline for a system under study. Costs associated with system operation

over the relevant planning period are indicated by c. Such costs are typically uncertain, modelled with a

probability distribution p(c). We introduce a utility function u(c) [34] over costs to cater for risk attitudes.

The evaluation of system performance under normal conditions, i.e. in absence of relevant cyber incidents,

is based on its associated expected utility [18]

(cid:90)

ψn =

u(c) p(c) dc.

This basic scheme can be sophisticated in several directions. For example, there could be several performance

functions. A typical case is to consider attributes concerning information availability (a), integrity (i) and

conﬁdentiality (s) [31], Fig. 2. These nodes could be, in turn, antecessors of the cost node. We use p(a, i, s) as

the distribution modelling uncertainty about system performance. If u(a, i, s) represents the corresponding

multi-attribute utility, the expected utility would be

(cid:90) (cid:90) (cid:90)

ψn =

u(a, i, s) p(a, i, s) da di ds.

3

Costp(c)Utilityu(c)Availabilityp(a)Integrityp(i)Conﬁdentialityp(s)Utilityu(a,i,s)We use p(a, i, s) if interrelationships between such attributes are expected. If this were not so, e.g. in the

case of independence, we would describe graphically the model as in Fig. 2, through

p(a, i, s) = p(a) p(i) p(s).

2.2 Cybersecurity risk assessment

Adopting the basic scheme in Fig. 1, on which we focus to simplify the exposition, we consider the problem

of cybersecurity risk assessment in Fig. 3. For instance, consider a model with just two threats, one of

them (t1) physical (e.g., ﬁre) and another one (t2) cyber (e.g., DDoS attack1). Both t1 and t2 are random

variables. We also consider two types of assets, one traditional (e.g., facilities) and the other cyber (e.g.,

computers). Impacts over these assets are, respectively, ct and cc and, typically, uncertain. If there is a

relationship between them given either threat, the corresponding model would be of the form

p(ct, cc|

t1, t2) p(t1, t2),

where p(t1, t2) describes the probability of the threats happening, and p(ct, cc|
over asset impacts, given the eventual occurrence of threats. Costs are added at the total cost node c, which

t1, t2) describes the probability

aggregates those under normal circumstances with those due to the incidents. Then, the expected utility

taking into account the threats and speciﬁc dependencies in Fig. 3 would be

(cid:90)

(cid:90)

ψr =

· · ·

u(cn + ct + cc) p(cn) p(ct|

t1, t2) p(cc|

t1, t2) p(t1) p(t2) dt2 dt1 dcc dct dcn.

We have assumed that consequences are additive, but we could have a generic utility u(cn, cc, ct). Finally,

we evaluate the loss ψn −
When it is suﬃciently large, incidents are expected to harm the system signiﬁcantly and we should manage

ψr in expected utility considering the threats against that under normal conditions.

such risks.

The model can be extended to include a bigger number of threats and assets, as well as additional types of

costs. Finally, several utility nodes could be incorporated to describe the preferences of multiple stakeholders.

2.3 Risk mitigation in cybersecurity risk management

The next step adds security controls to the model. We introduce a portfolio of them to reduce the likelihood

of threats and/or their impact (Fig. 4). Examples of controls include ﬁrewalls, employee training, or making

1A distributed denial of service (DDoS) is a network attack consisting of a high number of infected computers ﬂooding with

network traﬃc a victim computer or network device, making it inaccessible.

4

Figure 3: Risk assessment in cybersecurity.

regular backups. For simplicity, in Fig. 4 we assume that all controls inﬂuence over all events and impacts.

It will not always be so: a ﬁre detector makes less harmful, but not less likely, a ﬁre; resource accounting

mechanisms [30] managing access based on user privileges, make less likely a DDoS, but usually not less

harmful. Node e describes the portfolio of controls, whose cost we model through the distribution p(ce|
Controls might inﬂuence on threat likelihoods p(t1|
p(ct|
assumptions.

t1, t2, e). All costs are aggregated in the total cost node c, under appropriate additivity

e), as well as on asset impact likelihoods

t1, t2, e) and p(cc|

e) and p(t2|

e).

In this case, the expected utility when portfolio e is implemented is

(cid:90)

(cid:90)

ψ(e) =

...

u(cn + ce + ct + cc) p(cn) p(ce|

e) p(ct|

t1, t2, e) p(cc|

t1, t2, e) p(t1|

e) p(t2|

e) dt2 dt1 dce dct dcc dcn.

We would then look for the maximum expected utility portfolio solving for

ψ∗

e = max
e∈E

ψ(e),

being E the set of feasible portfolios. Based on the available controls, we deﬁne portfolios that meet diﬀerent

constraints which may be economic (e.g., not exceeding a budget), legal (e.g., complying with data protection

laws), logistic or physical.

5

Physicalthreatp(t1)Cyberthreatp(t2)Costontraditionalassetp(ct|t1,t2)Costoncyberassetp(cc|t1,t2)Normalconditionscostp(cn)Totalcostsc=cn+ct+ccUtilityu(c)Figure 4: Risk assessment of cybersecurity controls.

2.4 Cyber insurance in cybersecurity risk management

As a relevant element of increasing interest, we introduce cyber insurance. Its costs will typically depend on

the implemented portfolio of controls, as in Fig. 5: the better such portfolio is, the lower the premium will be.

This cost will also depend on the assets to be protected. We could include the insurance within the portfolio

of controls; however, it is convenient to represent them separately, since premiums will typically depend on

the controls deployed. Decision node i describes the cyber insurance adopted, with entailed costs ci with

i, e), although they will usually be deterministic. In addition, insurance and security controls

probability p(ci|
will typically aﬀect impacts, modelled through p(ct|
the total cost node c. The expected utility when portfolio e is implemented together with insurance i is

t1, t2, e, i). Costs are aggregated in

t1, t2, e, i) and p(cc|

(cid:90)

(cid:90)

ψ(e, i) =

· · ·

u(cn + ci + ce + ct + cc) p(cn) p(ci|

i, e) p(ce|

e) p(ct|

t1, t2, e, i) p(cc|

t1, t2, e, i)

×

We seek the maximum expected utility portfolio-insurance pair through

p(t1|

e) p(t2|

×

e) dt2 dt1 dcc dct dce dci dcn.

max
e∈E,i∈I

ψ(e, i),

6

SecuritycontrolsportfolioePhysicalthreatp(t1|e)Cyberthreatp(t2|e)Costontraditionalassetp(ct|t1,t2,e)Costoncyberassetp(cc|t1,t2,e)Securitycontrolsportfoliocostp(ce|e)Normalconditionscostp(cn)Totalcostsc=cn+ce+ct+ccUtilityu(c)Figure 5: Cyber insurance in cybersecurity risk assessment.

where I represents the insurance catalogue. The pair (e, i) could be further restricted jointly, e.g., by a

common budget constraint or legal requirements.

2.5 Adversarial risk analysis in cybersecurity

As discussed previously, intentionality is a key factor when analysing certain cyber threats. We shall use

ARA [6] to model the intentions and strategic behaviour of adversarial cyber threats. Under ARA, the

attacker has his own utility function uA, seeking to maximise the eﬀectiveness of his attack. This paradigm

is applicable to multiple types of strategic interactions between attackers and defenders. Two of them are

specially relevant in cybersecurity. First, the sequence defence-attack, in which the Defender deploys her

security controls and the Attacker is able to observe them prior to attacking. Second, the sequence defence-

attack-defence, in which the Defender deploys her preventive controls, then the Attacker observes them to

decide his attack and, ﬁnally, the Defender recovers from the attack, should it be successful.

2.5.1 Defence-attack model

The original examples, Figs. 3 and 4 evolve into Fig. 6, modelling an adversarial case through a BAID

with a Defender and an Attacker: physical threat t1 remains unintentional whereas cyber threat t2 becomes

7

SecuritycontrolsportfolioeInsuranceiPhysicalthreatp(t1|e)Cyberthreatp(t2|e)Costontraditionalassetp(ct|t1,t2,i,e)Costoncyberassetp(cc|t1,t2,i,e)Securitycontrolsportfoliocostp(ce|e)Insurancecostp(ci|i,e)Normalconditionscostp(cn)Totalcostsc=cn+ci+ce+ct+ccUtilityu(c)Figure 6: Adversarial risk analysis in cybersecurity: defence-attack problem.

adversarial through a decision node for the Attacker, who needs to decide whether or not to launch an attack

to his beneﬁt. It corresponds to a sequential defence-attack model [6]. The Defender problem is described in

Fig. 4. Its resolution was covered in Sect. 2.3. There, the cyber attack is described probabilistically through

e), which represents the probability that the Defender assigns to cyber threat t2 materialising, had

p(t2|
portfolio e been adopted. However, the strategic nature of this problem, Fig. 6, requires the analysis of the

Attacker decision about which attack to perform. Under the ARA defence-attack paradigm, the Defender

should analyse the Attacker strategic problem in Fig. 7.

Speciﬁcally, given portfolio e, and assuming that the Attacker maximizes expected utility, the Defender

would compute for each attack t2, the expected utility for the Attacker

(cid:90) (cid:90) (cid:90)

ψA(t2|

e) =

uA(t2, ct, cc) pA(ct|

t1, t2, e) pA(cc|

t1, t2, e) pA(t1|

e) dt1 dcc dct,

where uA and pA are, respectively, the utilities and probabilities of the Attacker. The Defender must then

ﬁnd the attack maximising the Attacker’s expected utility,

max
t2∈T2

ψA(t2|

e),

8

Physicalthreatp(t1|e)Cyberattackt2|eSecuritycontrolsportfolioeCostontraditionalassetp(ct|t1,t2,e)Costoncyberassetp(cc|t1,t2,e)Securitycontrolsportfoliocostp(ce|e)Normalconditionscostp(cn)Totalcostsc=cn+ce+ct+ccAttackerutilityu(t2,ct,cc)Defenderutilityu(c)Figure 7: Attacker problem in the defence-attack model.

where T2 is the attack set.

However, the Defender will not typically know uA and pA. Suppose we are capable of modelling her

uncertainty about them with random probabilities PA and a random utility function UA [6]. Then, the

optimal random attack given e is

T ∗
2 (e) = arg max
t2∈T2

(cid:90) (cid:90) (cid:90)

UA(t2, ct, cc) PA(ct|

t1, t2, e) PA(cc|

t1, t2, e) PA(t1|

e) dt1 dcc dct.

Finally, the distribution over attacks that we were looking for satisﬁes

e) = P (cid:0)T ∗

2 (e) = t2

(cid:1),

p(t2|

assuming that T2 is discrete (e.g., when referring to attack options), and, similarly, if they are continuous

(e.g., when referring to attack eﬀorts). Such distribution could be estimated through Monte Carlo (MC)

simulation as in Algorithm 1 (Appendix), where the distribution of random utilities and probabilities is

designated by

(cid:16)

F =

UA(t2, ct, cc), PA(ct|

t1, t2, e), PA(cc|

e)
t1, t2, e), PA(t1|

(cid:17)

9

Physicalthreatp(t1|e)Cyberattackt2|eSecuritycontrolsportfoliop(e)Costontraditionalassetp(ct|t1,t2,e)Costoncyberassetp(cc|t1,t2,e)Attackerutilityu(t2,ct,cc)Figure 8: Adversarial risk analysis in cybersecurity: defence-attack-defence problem..

2.5.2 Defence-attack-defence model

As mentioned, cybersecurity risk management also comprises reactive measures that can be put in place to

counter an attack, should it happen. Therefore, we split the security portfolio into two groups: preventive

security controls ep and reactive security controls er|
defence model [6] in which the ﬁrst move is by the Defender (preventive portfolio ep), the second is by the

t2. This corresponds to a sequential defence-attack-

Attacker (attack after observing preventive controls, t2|
portfolio er|
the security control node. Speciﬁcally, the expected utility when portfolio e = (ep, er) is implemented is

t2). The Defender problem is solved similarly to Sect. 2.3, reﬂecting changes caused by splitting

ep) and the third one is by the Defender (reactive

(cid:90)

(cid:90)

ψ(e) =

...

u(cn + ce + ct + cc) p(cn) p(ce|

ep, er) p(ct|

t1, t2, ep, er) p(cc|

t1, t2, ep, er)

×

p(t1|

ep) p(t2|

ep) dt2 dt1 dcc dct dce dcn.

×

10

Physicalthreatp(t1|ep)Cyberattackt2|epPreventivesecuritycontrolsportfolioepReactiveSecuritycontrolsportfolioer|t2Costontraditionalassetp(ct|t1,t2,ep,er)Costoncyberassetp(cc|t1,t2,ep,er)Securitycontrolsportfoliocostp(ce|ep,er)Normalconditionscostp(cn)Totalcostsc=cn+ce+ct+ccAttackerutilityu(t2,ct,cc)Defenderutilityu(c)We would then look for the maximum expected utility portfolio

(e∗

p, e∗

r) = arg max

(ep,er)∈Ep×Er

ψ(ep, er),

where Ep and Er, respectively, deﬁne constraints for preventive and reactive portfolios, some of which could

be joint. The Attacker problem providing p(t

ep) would be solved in a similar fashion than in the defence-
|

attack case.

3 A CASE STUDY TEMPLATE

We illustrate our framework for cybersecurity risk analysis with a defend-attack case study, which can serve

as a template for more complex cases. The Defender is an SME dedicated to document management with

60 people and 90 computers. A cyber attack might aﬀect, mainly, the online document management service.

For conﬁdentiality reasons, the number of relevant issues has been simpliﬁed and data conveniently masked.

This simpliﬁcation will allow us to better illustrate key modelling concepts and the overall scheme to follow

for other case studies. Moreover, we include uncertain phenomena in which data are available and others in

which it is not and, thus, we shall need to rely on expert judgement [14]. Prices and rates refer to Spain,

where the incumbent SME is located.

In essence, we ﬁrst structure the problem identifying assets, threats and security controls. The later may

have implementation costs in exchange of reducing the threat likelihoods and/or eventual impacts. Sub-

sequently, we assess the impacts that may have an eﬀect on asset values to ﬁnd the optimal risk management

portfolio. Since adversarial threats are included, we also model the Attacker decision problem. Indeed, in this

case there is a single potential Attacker which contemplates a DDoS attack with the objective of disrupting

the SME services, causing an operational disruption and reputational damage with the consequent loss of

customers, which would head to competitors, besides incurring in contractual penalties potentially aﬀecting

its continuity. Then, we simulate from this problem to obtain the attack probabilities, which feed back the

Defender problem. In this way an optimal defence can be obtained. We consider a one-year planning horizon.

The problem we focus is on ﬁnding the optimal security portfolio and insurance product for the company,

in the sense of maximising expected utility. Other formulations are discussed in Sect. 3.5.

3.1 Problem structuring

We structure the problem through the BAID in Fig. 9. Lighter nodes refer to issues concerning solely the

Defender; darker nodes refer to issues relevant only for the Attacker; nodes with an stripped background

11

aﬀect both. Should there be several attackers, we would use more background patterns or colours. Arcs have

the same interpretation as in [38]. The only non-standard arc is that linking the security controls node and

the attack node, meaning that the Attacker will implement his action once he identiﬁes the controls adopted

by the Defender.

Figure 9: Case problem structure as a BAID.

3.1.1 Assets

We ﬁrst identify the Defender assets at risk. We could obtain them from catalogues like those of the

methodologies mentioned in the Introduction. Here we consider:

Facilities: Oﬃces potentially aﬀected by threats. Without them, the organisation could not operate.

Computer equipment: The data centre and workstations essential for this organisation. Should they

be aﬀected, costs could be substantial.

Market share, directly impacting the company proﬁts.

•

•

•

Other assets not considered in this case include the company’s development software, business informa-

tion, the mobile computing elements or the staﬀ.

12

SecuritycontrolssInsuranceiInsurancecostci|iSecuritycontrolscostcs|sFirep(f)Firedurationp(o|f,s)Computervirusp(v|s)Competitorattacka|sDurationDDoSp(l|a,s)Detectionofattackerp(t|a)Impactoverfacilitiesp(b|o)Insurableimpactovercomputersp(qi|o,v)Non-insurableimpactovercomp.p(qn|v)Impactovermarketsharep(m|l)Costswhendetectedp(ct|t)Insurancecoveragegi|i,b,qiAttackerearningse|mResultoftheattackcaTotalcostscdDefenderutilityu(cd)Defenderutilityu(ca)3.1.2 Non-intentional threats

We consider threats over the identiﬁed assets deemed relevant and having non-intentional character. This

may include threats traditionally insurable as well as new ones potentially cyber insurable. We use a

simpliﬁcation of the catalogues in the methodologies in the introduction:

•

•

Fire: It may aﬀect facilities, as well as computers, which could even destroyed. No impact over market

share is contemplated, as the organisation has a backup system. We assume that a ﬁre can occur only

by accident, not considering the possibility of sabotage.

Computer virus: Aimed at disrupting normal operations of computer systems. We consider this threat

non-intentional, as most viruses propagate ubiquitously: their occurrence tends to be random from the

defender perspective. It may degrade computer performance.

We model each threat with a probabilistic node associated with the Defender problem. Other non-intentional

threats, not considered here, could be water damage, power outages or employee errors.

3.1.3

Intentional threats

This category may include both cyber and physical threats. Again, we may use catalogues from, e.g.,

MAGERIT. We should identify the corresponding attackers, as well as their attack options available. In our

case, we just consider a relevant attacker.

Competitor attack : Our competitor may attempt a DDoS, to undermine the availability of the De-

•

fender’s site, compromising her customer services. Should it happen, it would impact negatively the

Defender’s market share, damaging its reputation and, consequently, loosing customers to be gained

by the Attacker. The decision is whether to launch the attack and the number of attempts.

We integrate attack options into a single decision node associated with the Attacker problem. Other in-

tentional attacks, not modelled here, could include an abuse of access privileges, launching an advanced

persistent threat, insiders or bombs.

3.1.4 Uncertainties aﬀecting threats

We consider now those uncertainties aﬀecting the Defender’s assets.

Duration of DDoS, will depend on the number of attacks and security controls deployed.

Fire duration, which can be reduced with an anti-ﬁre system.

•

•

13

Each one is modelled with a probabilistic node. Other related uncertainties could come, e.g., from a more

detailed modelling of the virus (e.g., infection probability given the OS) or the ﬁre propagation to adjacent

buildings.

3.1.5 Attacker uncertainties

Additionally, we consider uncertainties that the Attacker might ﬁnd relevant in his problem and aﬀect only

him.

•

Detection of Attacker. If detected, his reputation would suﬀer and might face legal prosecution.

Each of them is modelled with a probabilistic node. Other attacker uncertainties include the number of

customers aﬀected by the DDoS or the performance of the attack platform.

3.1.6 Relevant security controls

We identify security controls relevant to counter the threats. We may use listings from the above mentioned

methodologies. In our case we consider:

•

•

•

•

Anti-ﬁre system. It can detect a ﬁre facilitating early mitigation.

Firewall. It protects a network from malicious traﬃc.

Implementation of risk mitigation procedures for cybersecurity and ﬁre protection.

Cloud-based DDoS protection, diverting DDoS traﬃc from the target to a cloud-based site absorbing

malicious traﬃc.

We associate a Defender decision node with the security controls. Other measures, not included here, could

be a system resource management policy, a cryptographic data protocol or a wiring protection.

3.1.7

Insurance

We also consider the possibility of purchasing insurance to transfer risk. The premium will depend on

the protected assets and contextual factors such as location, company type and, quite importantly, the

implemented controls. Available insurance products are in Table 1.

We associate a Defender decision node with the insurance to be contracted. As its cost depends on the

implemented controls, we include the corresponding decision node as a predecessor.

14

Product
No insurance

Coverage
None

Traditional
insurance

Cyber
insurance

80% of hired capital in buildings and
contents; ﬁreﬁghters; movement of
furniture.

80% of these expenses: Those re-
lated with conﬁdential data viola-
tion,
investigation and legal costs;
losses caused by threats and extor-
sion; removal of computer viruses;
measures related to data protection
law procedures; computer fraud.

Comprehensive
insurance

All of the above.

Table 1:

Insurance product features.

3.1.8

Impacts for Defender

Having identiﬁed threats and assets, we present their potential impacts over the Defender’s interests:

Impact over facilities: Economic losses caused by ﬁre over them.

Impact over computers: Economic losses caused by ﬁre or viruses over computers. We split them

into insurable impacts and non-insurable ones. We need this split to calculate the eventual insurance

coverage.

Impact over market share: Costs due to market share lost.

•

•

•

We model each impact with a probabilistic node. We also consider the impacts associated with safeguards.

Cost of security controls implemented by Defender.

Cost of insurance acquired.

Insurance coverage.

•

•

•

Finally, a node aggregates all Defender’s consequences:

Total costs: It summarises the above to establish the ﬁnal monetary impact of the Defender problem.

•

The above cost nodes will be deterministic. Besides, we could also include other types such as corporate

image or staﬀ safety.

3.1.9

Impacts for Attacker

We consider the following impacts:

Attacker earnings from increasing market share, transferred from that lost by the Defender.

•

15

•

•

Costs when detected, covering eventual sanctions by the regulator, legal costs as well as loss of customers

and reputation, if detected.

The ﬁnal results of attack combines all previous earnings and costs, as well as those of undertaking the

attack, such as acquiring malicious tools or hiring hackers.

We model the costs when detected as a probabilistic node. The remaining nodes are deterministic.

3.1.10 Preferences

Value nodes describe how the corresponding agent evaluates consequences. We use the expected utility

paradigm [18]. We, therefore, include these nodes:

Utility of Defender: Models the Defender preferences and risk attitudes over the total costs.

Utility of Attacker: It describes the Attacker preferences and risk attitudes.

•

•

We include a value node for each of the utility functions.

3.1.11 Defender and Attacker problems

Figs. 10 and 11 respectively represent the Defender and Attacker problems derived from the strategic problem

in Fig. 9. For the Defender problem, this converts the Attacker’s decision nodes into chance nodes and

eliminates the Attacker’s nodes not aﬀecting the Defender problem, as well as the corresponding utility

node. Similarly for the Attacker. We use both diagrams to guide judgement elicitation from the Defender.

3.2 Assessing the Defender’s non-strategic beliefs and preferences

We provide now the quantitative assessment of the Defender beliefs and preferences not requiring strategic

analysis. Some of them will be based on data and expert judgement, others just on expert judgement due

to the lack of data typical in many cybersecurity environments. As a consequence, we populate most nodes

in her problem. We incorporate in Sect. 3.3 those requiring strategic analysis. Finally, in Sect 3.4 we

analyse the Defender problem to ﬁnd the optimal controls and insurance. When incumbent, we provide the

pertinent utility u(), random utility UA(), probability p(), random probability PA() or deterministic model

at the corresponding node.

3.2.1 Economic value of Defender assets

We consider the following values for the assets at risk:

16

Figure 10: Defender problem.

Facilities: Their value is 5,000,000e, reﬂecting only acquisition costs.

Computer equipment: Valued at 200,000e, under similar considerations.

Market share: Currently estimated at 50%. Translated into next year foreseen proﬁts, we value it at

•

•

•

1,500,000e.

3.2.2 Modelling security controls

Security controls decision, s: The security portfolios that the Defender could implement derive from

these options:

Install an anti-ﬁre system.

Install a ﬁrewall to protect the infrastructure.

Train employees on safety and cybersecurity procedures.

Subscribe a cloud-based DDoS protection system with choice (2, 5, 10 or 1000) gbps.

•

•

•

•

We thus have 40 portfolios. These could be further constrained by, e.g., a budget, as in Sect. 3.5.

17

SecuritycontrolssInsuranceiInsurancecostci|iSecuritycontrolscostcs|sFirep(f)Firedurationp(o|f,s)Computervirusp(v|s)Competitorattackp(a|s)DurationDDoSp(l|a,s)Impactoverfacilitiesp(b|o)Insurableimpactovercomputersp(qi|o,v)Non-insurableimpactovercomp.p(qn|v)Impactovermarketsharep(m|l)Insurancecoveragegi|i,b,qiTotalcostscdDefenderutilityu(cd)Figure 11: Attacker problem.

Security control
Anti-ﬁre system
Firewall
Risk mitigation proc.

Cloud-based DDoS
protection

Cost
e 1,500
e 2,250
e 2,000

e 2,400 for 2 gbps,
e 3,600 for 5 gbps,
e 4,800 for 10 gbps,
e 12,000 for 1 tbps.

Table 2: Cost of individual security controls.

Cost of security controls, cs|
their costs, from which we derive the portfolio costs.

s: This node models the cost of implemented controls. Table 2 provides

3.2.3 Modelling the insurance product

Insurance decision, i: This refers to the insurance product that the Defender could purchase (Table 3)

once the controls have been selected.

Insurance cost, ci|
the organisation (Table 3).

i: This models the insurance premiums. It depends on the controls implemented by

Insurance coverage, gi|
Traditional and comprehensive insurances cover 80% of burnt facilities and computer costs. The cyber and

i, b, qi: This node models gi, the insurance product coverage reﬂected in Table 1.

18

Securitycontrolsp(s)Competitorattacka|sDurationDDoSPA(l|a,s)DetectionofattackerPA(t|a)ImpactovermarketsharePA(m|l)Costswhendetectedp(ct|t)Attackerearningse|mResultoftheattackcaDefenderutilityUA(ca)Prod.

None
Trad.
Cyber
Compr.

Security controls

None

Anti-ﬁre

e 0
e 500
e 300
e 700

e 0
e 300
e 300
e 500

Firewall or
DDoS prot.
e 0
e 500
e 200
e 600

Proc.

e 0
e 500
e 250
e 650

Table 3:

Insurance product cost.

Year Buildings
2005
2006
2007
2008
2009

1220
1266
1320
1347
1314

Fires
32
29
30
28
28

Table 4:

Industrial ﬁre data in Vitoria (2005-2009).

comprehensive insurances will cover 80% of the expenses related with virus removal.

3.2.4 Modelling ﬁre risk

Fire likelihood, p(f ): This node provides the annual probability of suﬀering a ﬁre in our facility. We use

data from the Vitoria ﬁre brigade [13], concerning interventions on industrial buildings (Table 4).

The ﬁre rate remains fairly stable over the years. We estimate the probability that an organization suﬀers

a ﬁre in a year using a beta-binomial model with prior βe(1/2, 1/2). The posterior would be

f

data
|

∼

(cid:16)

βe

1/2 +

5
(cid:88)

i=1

xi, 1/2 +

5
(cid:88)

i=1

(ni −

(cid:17)

xi)

≡

βe(147.5, 6320.5),

where xi designates the number of ﬁres aﬀecting industrial buildings and ni, that of such buildings in the

th year, i = 1, ..., 5. Such distribution can be reasonably summarised through its posterior expectation,

i
−
ˆp = 0.022, since the posterior variance is small. Its value is estimated from the probability that there are no

ﬁres, p(0) = 1

−

ˆp = 0.978. The number of ﬁres can be approximated with a Poisson

(0.022) distribution.

P

However, we consider only the probability that one ﬁre occurs, since probabilities beyond that are tiny

(p(f > 1) = 0.00024. Thus, the number f of ﬁres will follow

min[1,

f

∼

P

(0.022)].

Fire duration, p(o

f, s):

|

It is a major impact determinant [5]: the longer the ﬁre, the more damaging it

will be. To study its duration, we employ the above Vitoria data. Fig. 12 presents the histogram of industrial

ﬁre durations, with modal duration between 30 minutes and one hour. Adopting the approach in [41], we

19

Figure 12: Industrial ﬁre duration histogram. Vitoria, Spain (2005-2009).

model ﬁre duration with a gamma Γ(shape = γ, scale = γ/µ) distribution. We assume a non-informative,

but proper, prior γ

Exp(0.01) and µ

Inv-Γ(1, 1). No analytical expression for the posterior distribution

∼
data and γ
is available, but we can introduce a Markov chain MC scheme to sample from µ
|

∼

data, [41]. Based

|

on this, we estimate that E(γ

data)
|

0.85 and E(µ
|

≈

data)

≈

78.

The only security control among the proposed ones that may have an eﬀect on ﬁre duration is the anti-ﬁre

system, which enables faster ﬁre detection. Using expert judgement [14], we determine its threshold duration

under the proposed system with, respectively, suggested minimum, modal and maximum durations of 1, 10

and 60 min. To mitigate expert overconﬁdence [19], we consider a triangular distribution with quantiles

0.05 at 1 and 0.95 at 60 min, resulting in T ri(0.8, 63, 10), which models the ﬁre duration o if there is a ﬁre

(f = 1) and portfolio s contains the anti-ﬁre system. On the other hand,

Γ(0.85, 0.01089)

o

∼

if the portfolio does not contain the anti-ﬁre system.

Fire impact:

It models the impacts assuming that the fraction of aﬀected assets is related with ﬁre

duration. After consulting with experts, we consider that a ﬁre lasting 120 minutes would degrade the

facilities by 100% in absence of controls. To simplify, we assume that the eﬀect of ﬁre duration is linear.

This impact will be assessed in Sect. 3.2.7.

Additionally, the impact over computer equipment derives from the percentage of facility degradation

caused by ﬁre. Assuming that computers are evenly distributed through the premises, a ﬁre lasting 120

minutes would also degrade computer equipment by 100%. This impact is potentially insurable and will be

20

modelled in Sect. 3.2.7.

3.2.5 The computer virus risk

Computer virus likelihood, p(v

s): This node provides the number of virus infections during a year in
|

the organisation. The probability that a computer is infected in a month follows a binomial distribution

(m, q), where q represents the probability that a computer gets infected. For infection duration, we assume

B
that the virus remains active until detected through appropriate controls. Then, it becomes eradicated by

the system administrator. Various statistics suggest that the rate of virus infections worldwide is 33% [35],

so we adopt ˆq = 0.33 as the probability that a computer is infected a certain month. The organisation has 90

computers, which we assume have the same security controls and are equally likely of being infected. Since

the analysis is for 12 months, we use m = 12

·

90 = 1080. Additionally, we consider the eﬀect of our controls:

1. If a ﬁrewall is implemented, the probability that a computer gets infected is reduced to ˆp = 0.005,

not completely eliminating the threat, even if this includes continuous updating based on latest virus

signatures.

2. If maintenance is implemented, the infection probability gets reduced by 50%, with ﬁrewall or not, as

this control entails improvements in the organisation such as imposing safety requirements on acquired

systems.

The number v of infections is, therefore, modelled as in Table 5.

Sec. controls in s

Distribution

Firewall and proc.

v ∼ B(1080, 0.0025)

Firewall

Procedure

Otherwise

v ∼ B(1080, 0.005)

v ∼ B(1080, 0.1666)

v ∼ B(1080, 0.33)

Table 5: Number of annual virus infections.

Computer virus impact: Viruses may aﬀect the three information security dimensions.The impact on

integrity and availability could lead to information corrupting or unavailability. Impacts over conﬁdentiality

are variable, as they depend on the stolen information. The average daily cost of these infections was

estimated at e 2.683 [39], although this one varies according to the monetary value of the information

and services the victim systems support. Bigger losses come from sophisticated campaigns (e.g., global

ransomware like WannaCry) or targeted malware which, under our paradigm, should be better modelled

as an adversarial threat. In our case, repairing a computer infected by a virus costs e 31 (two technician

21

hours).

Insurance options potentially cover the removal of computer viruses. Therefore, this impact is

modelled within the insurable aspects in Sect. 3.2.7.

Most computer viruses cause performance reduction in aspects such as initialisation of OS. Although

small, this causes time losses to the user. We assume that most of the work time of the organisation is

in front of a computer (70%), and that it would take, on average, ﬁve days (40 h of work) to detect the

problem. We also assume that when a computer is infected, 28 hours of its usage are aﬀected by the virus.

We model the time loss as a uniform distribution

U

(0, 0.05), representing that the percentage of lost time

caused by a virus is between 0 and 5 %. The hourly cost of the employee is e 20/hour. Therefore, for each

virus infection, the cost would be 20

28

×

× U

(0, 0.05). Insurance options in node i do not cover this loss

and, thus, we modelled it within the non-insurable aspects in Sect. 3.2.7.

3.2.6 Modelling the DDoS threat

We consider now non-strategic aspects of the DDoS threat. A model for the DDoS likelihood is in Sect. 3.3.

DDoS Duration, p(l

|

a, s): This node models the duration l in hours of all successful DDoS attacks.

Its length will depend on the intensity of the attacking campaign, how well crafted is the attack and the

security controls implemented by the targeted organisation. Typical controls mitigating DDoS attacks involve

conﬁguring the digital system so that users and processes dedicate some resources for a certain period of time

or distributing loads through a load balancer. An emerging alternative are cloud-based systems absorbing

traﬃc from its customer site when they become victims of a DDoS. Otherwise, if no control is deployed,

it would be virtually impossible to block such attack. Based on information in [24, 40], the average attack

lasts 4 hours, averaging 1 gbps, with peaks of 10 gbps. We model lj, the length of the j-th individual DDoS

attack as a Γ(4, 1), so that its average duration is 4 hours. This duration is conditional on whether the attack

actually saturates the target, which depends on the capability of the DDoS platform minus the absorption of

the cloud-based system. We assume that the Attacker uses a professional platform capable of 5 gbps attacks,

modelled through a Γ(5, 1) distribution. We then subtract the sgbps absorbed by the protection system to

determine whether the DDoS is successful, which happens when its traﬃc overﬂows the protection system.

Since the campaign might take a attacks, the output of this node is

l =

a
(cid:88)

j

lj,

with lj ∼

Γ(4, 1) if Γ(5, 1)

−

sgbps > 0, and lj = 0, otherwise.

22

DDoS impact: The DDoS duration might cause a reputational loss that would aﬀect the organisation

market share. Recall that the current market share is 50% valued at e 1,500,000. To simplify, we assume

that all market share is fully lost at a linear rate until lost in, say, 5-8 days of unavailability (120-192 hours

of DDoS duration): in the fastest case the loss rate would be 0.5/120 = 0.00417 per hour, whereas in the

slowest one it would be 0.0026. We model this with a uniform distribution

(0.0026, 0.00417).

U

3.2.7 Modelling impacts over assets

We recall now the impacts over the assets.

Impact over facilities, p(b

o): This node models monetary losses b due to the degradation of facilities
|

by ﬁre. Following Sect. 3.2.4, we model b through

5000000

b

∼

(cid:16)

1,

min

(cid:17)

.

o
120

×

Insurable impacts over computers, p(qi|
of computers to be covered by an insurance. This may be caused by ﬁre, Sect. 3.2.4, and by repairing the

o, v): This models the monetary losses qi due to degradation

computers infected with viruses, Sect. 3.2.5. We then model qi through

31v + 200000

qi ∼

(cid:16)

1,

min

(cid:17)

.

o
120

×

Non-insurable impacts over computers, p(qn|
gradation of computers not covered by insurance, due to the lost time caused by viruses over computer

v): This models the monetary losses qm caused by de-

systems. Following Sect. 3.2.5, we model qn through

qn ∼

560v

× U

(0, 0.05).

Impact over market share, p(m

l): This models the monetary value m of market share lost. Following
|

Sect. 3.2.6, we use

m

∼

min[1500000, l

× U

(0.0026, 0.00417)].

Total costs for the Defender, cd|
through

gi, ci, cs, m, b, qi, qn: This models the costs cd suﬀered by the Defender

cd = m + b + qi + qn + cs + ci −

gi,

23

being cs the cost of security controls, ci the cost of insurance, gi the insurance coverage (which reduces

losses) and m, b, qi and qn the impacts over assets earlier described.

3.2.8 Defender utility, u(cd):

The organisation is constant risk averse over costs. Its utility function is strategically equivalent to

u(cd) = a

b exp(k(

−

−

cd)),

We adjust it calibrating the function with three costs: worst, best, and an intermediate one. The worst

reasonable loss max cd is based on the sum of all costs and impacts (except the computer virus one) which

is equal to e 6,755,300. Computer virus impacts do not have an upper limit; based on simulations, it is

reasonable to assume that they would not exceed e 50,000. Giving an additional margin, we assume that

max cd = 7000000. The best loss is min cd = 0. For an intermediate cost c∗

d, we ﬁnd its probability equivalent

[34] α so that u(c∗

d) = α. For instance, asking the company, we have u(c∗

d = 2660000)

.5. Additionally, we

(cid:39)

rescale the costs to the (0,1) range through 1

u(cd) =

1

−

e

cd

7000000 . Then, the utility function is

(cid:32)
1

exp

cd
7000000

−

(cid:33)

(cid:35)
.

1

−

−

(cid:34)

1

3.3 Assessing the Attacker’s random beliefs and preferences

In the Defender problem, the competitor attack is a probabilistic node modelling the number of attacks

launched by the Attacker, given the security controls implemented by the Defender. We model the Attacker

problem and simulate it to forecast its actions to obtain the probability distribution.

We must estimate the probability that the Attacker executes the DDoS, given the Defender controls

implemented. For that, we consider his decision problem in Fig. 11. Its solution would give the Attacker’s

optimal action. However, as argued in Sect. 2.5, we model our uncertainty about his preferences and beliefs

through random utilities and probabilities to ﬁnd the random optimal attack.

3.3.1 Defender’s security controls

This node is probabilistic for the Attacker. However, we assume that he may observe through network

exploration tools whether the Defender has implemented relevant controls against his attack.

24

3.3.2 Competitor attack decision: a
s
|

In the attacker problem, it is reﬂected in a decision node, modelling how many attacks (between 0 and 30)

the DDoS campaign will consist of. Attackers usually give up once the attack has been mitigated and move

onto the next target or try other disruption methods. However, when the sole objective is the victim, the

Attacker might continue the campaign for several days, causing a pervasive impact. In our case, we assume

that a DDoS platform would need a day to deploy their resources to launch a powerful and hidden DDoS.

3.3.3 Duration of the DDoS: PA(l

a, s)
|

We base our estimation on that of the Defender (Sect. 3.2.6). The length of the j-th individual DDoS attack

is modelled through a random gamma distribution Γlength(υ, υ/µ) with υ

(3.6, 4.8) and υ/µ

(0.8, 1.2),

∼ U

∼ U

so that we add uncertainty about the average duration (between 3 and 6 hours) and the dispersion. Similarly,

the attack gbps are modelled through a random gamma distribution Γgbps(ω, ω/η) with ω

(4.8, 5.6) and

∼ U

ω/η

∼

U (0.8, 1.2). Next, we subtract sgbps to Γgbps to determine whether the DDoS is successful, which

happens when its traﬃc overﬂows the protection system. As in Sect. 3.2.6, the number l of hours for which

the site is unavailable during the campaign is modelled as

l =

a
(cid:88)

j

lj,

with lj ∼

Γlength if Γgbps −

sgbps > 0, and lj = 0 otherwise.

3.3.4

Impact over market share: PA(m
l)
|

We base our estimation on that of the Defender (Sect. 3.2.7), adding some uncertainty around such assess-

ment. The market share value and percentage are not aﬀected by the uncertainty, as this information is

available to both agents. However, we model uncertainty in the market loss rate so that the fastest one (5

days in the Defender problem) is between 4 and 6 days in the Attacker problem and the slowest one (8 for

Defender) is between 7 and 9. Therefore, the random distribution describing the market loss m is

m

∼

min

(cid:104)

1500000, l

(cid:105)

(α, β)

× U

with α

∼ U

(0.0021, 0.0031) and β

∼ U

(0.00367, 0.00467).

25

3.3.5 Attacker earnings: e
|

m

This node models the Attacker gain e in terms of market share, derived from the DDoS duration. As the sole

competitor, we assume that e corresponds to the share lost by the defender e = m. The random uncertainty

in the earnings is derived from the randomness of the preceding nodes.

3.3.6 Detection of Attacker: PA(t
|

a)

This node represents the chance of the Attacker being detected. In most cyber attacks, the attacker is not

identiﬁed or prosecuted2. Detection probabilities are estimated via expert judgement at 0.2%, should the

Attacker attempt a DDoS. He actually gambles his detection through a binomial distribution

(a, 0.002)

B

where the number of trials is the number a of attacks and the detection probability is 0.002. To add some

uncertainty, we model the detection probability for each attack through a beta distribution βe(2, 998)3.

Therefore, the distribution determining the detection of the attacker t is modelled through a random binomial

distribution that produces the output detected if

(a, φ) > 0 with φ

B

∼

βe(2, 998), and not detected, otherwise.

3.3.7 Costs for Attacker when detected: pA(ct|

t)

This node models the consequences associated with being detected when executing a DDoS. As a competitor,

if the Attacker is disclosed, it would entail a serious discredit, together with compensation and legal costs

besides incurring criminal responsibilities. To ﬁx ideas, we use this cost decomposition:

•

•

•

•

Expected reputational costs, due to the necessary communication actions to preserve credibility: e

550,000.

Expected legal costs: e 30,000.

Expected civil indemnities and regulatory penalties: e 350,000.

Expected suspension costs, related with losses derived from prohibition to operate for some time: e

1,500,000.

To add uncertainty, we model the costs as a normal distribution with mean 2430000 and standard deviation

400000, i.e.,

2For instance, the FBI Internet Crime Compliant Center prosecuted two cases, and investigated 73, of nearly 298,728

t
ct|

∼ N

(2430000, 400000).

complaints received in 2016 [16]

3Its mean is 0.002

26

3.3.8 Result of attack: ca|

e, ct, a

This node combines the attacker earnings and costs if detected, as well as the cost of undertaking the attacks.

To estimate these, we consider that using a botnet to launch the DDoS attack would cost on average around

e 33 per hour [21]. Each attack would take one day, entailing costs of e 792. Therefore,

ca = e

ct −

−

792a.

3.3.9 Attacker’s random utility: UA(ca)

We assume that the Attacker is risk prone, with utility function strategically equivalent to

u(ca) = (c(cid:48)

a)ka ,

k > 1,

where c(cid:48)

a are the costs ca normalised to [0, 1], and ka the risk seeking attitude of the attacker. To induce

uncertainty, we assume ka follows a

U

(8, 10) distribution. Therefore, the attacker random utility is

UA(ca) = (c(cid:48)

a)Ka

with Ka ∼ U

(8, 10).

3.3.10 Simulating the Attacker problem

Summarising the earlier assessments, the distribution of random utilities and probabilities in the Attacker

problem is

(cid:16)

F =

UA(ca), pA(ct|

t), PA(t
|

a), PA(m
|

l), PA(l

|

(cid:17)

a, s)

.

We calculate the random optimal attack, given the security controls s implemented, as

A∗(s) = arg max

a

(cid:90)

(cid:90)

· · ·

UA(ca) pA(ct|

t) PA(t

a) PA(m
|

l) PA(l
|

|

a, s) dl dm dt dct.

To approximate it, we may use an MC approach as in Algorithm 1 (see Appendix), which we implemented

in R. For each s, the size of the DDoS protection system, we can assess the distribution of the random

optimal attack. Table 6 displays the probabilities of the attacks, conditional on the protection implemented,

with K = 1000. For instance, if the security portfolio contains no DDoS-protection system, an attack seems

certain and its duration would be between 18 and 30 attacks (being 29 and 30 the most likely attack sizes).

From this, we create the probability distribution p(a

s), so that the Defender problem is fully speciﬁed and
|

27

ready to be solved.

DDoS
prot. system

Number of attempts
6

5

3

0

4

2

1

7
1 tbps 1.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000
10 gbps 0.000 0.001 0.003 0.003 0.004 0.005 0.012 0.012 0.015 0.013 0.017 0.024 0.024 0.022 0.030 0.035
5 gbps 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.001 0.001 0.002
2gbps 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000
none 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000

11

13

14

10

12

15

8

9

DDoS
prot. system

16

17

18

19

20

21

Number of attempts
25

24

23

22

26

27

28

29

30

1 tbps 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000
10 gbps 0.026 0.041 0.025 0.044 0.042 0.053 0.050 0.048 0.047 0.060 0.050 0.059 0.065 0.081 0.089
5 gbps 0.008 0.006 0.012 0.017 0.007 0.028 0.031 0.055 0.070 0.061 0.096 0.117 0.143 0.141 0.203
2gbps 0.000 0.000 0.002 0.001 0.002 0.013 0.013 0.020 0.034 0.069 0.091 0.112 0.144 0.223 0.276
none 0.000 0.000 0.003 0.001 0.004 0.008 0.010 0.022 0.042 0.058 0.081 0.105 0.173 0.246 0.247

Table 6: Conditional probability table for random optimal attacks.

3.4 Solution of the Defender problem

Summarising earlier assessments about the Defender problem, the corresponding probabilities are

(cid:16)

G =

p(m
|

l), p(qn|

v), p(qi|

o, v), p(b

o), p(l
|

a, s), p(a
|
|

s), p(v

|

s), p(o

(cid:17)

f, s), p(f )
|

.

The expected utility when the security portfolio s is implemented together with insurance i is

(cid:90)

(cid:90)

ψ(s, i) =

...

u(cd) p(m

l) p(qn|
|

v) p(qi|

o, v) p(b

o) p(l
|

s) p(v
a, s) p(a
|
|

|

s) p(o

|

f, s) p(f )

df do dv da dl db dqi dqn dm.

We can calculate the optimal allocation as the maximum expected utility portfolio-insurance pair

(s∗, i∗) = arg max
s,i

ψ(s, i).

We may use Algorithm 2 (see Appendix), to approximate the portfolio expected utilities and the optimal

portfolio for the Defender. We have implemented it in R to calculate them (Table 7). Speciﬁcally, the best

portfolio consists of:

1 tpbs cloud-based DDoS protection system.

Firewall.

Anti-ﬁre system.

•

•

•

28

Comprehensive insurance.

•

Anti-ﬁre
anti-ﬁre
anti-ﬁre
no anti-ﬁre
. . .
no anti-ﬁre
no anti-ﬁre
anti-ﬁre

Firewall
ﬁrewall
ﬁrewall
ﬁrewall
. . .
no ﬁrewall
ﬁrewall
no ﬁrewall

Procedure
no procedure
no procedure
no procedure
. . .
no procedure
no procedure
no procedure

DDoS protection
1 tbps
1 tbps
1 tbps
. . .
no protection
no protection
no protection

Insurance
comprehensive
traditional
comprehensive
. . .
no insurance
cyber
no insurance

Expected utility
0.9954
0.9950
0.9949
. . .
0.8246
0.8246
0.8242

Table 7: Expected utility for 3 best and worst combinations of controls and insurance.

Besides the ranking of countermeasures, we can obtain additional information from the simulation. For

instance, the best security controls contain a ﬁrewall, 1 tbps DDoS protection and no risk management

procedure. Additionally, the best portfolios also includes insurance, either traditional or comprehensive.

3.5 Further analysis

The previous ARA model can be used to perform other relevant analysis, as we brieﬂy discuss.

3.5.1 Sensitivity analysis

By introducing variations in the probabilities (e.g., probability of ﬁre), we can evaluate the robustness of

the previous solution by checking whether variations in the probabilities and parameters of the model alter

the optimal solution or the relevance of diﬀerent controls. This is specially relevant in a case like ours

with little diﬀerences in expected utility among top alternatives and many inputs are purely of judgemental

nature. The approach would require the implementation of additional algorithms for sensitivity analysis that

indicate whether a small deviation in a parameter may lead to a large eﬀect in the outcome of the model

[36]. Additionally, sensitivity analysis can be used to explore the maximum cyber insurance price that the

Defender would be willing to pay. This may be used to price insurance products, as well as for ﬁnding the

best portfolio for diﬀerent cybersecurity budgets.

3.5.2

Introducing constraints

As we mentioned, we may introduce constraints over the security portfolios. For example, we could add to

the problem a budget limit of, say, e15,000. Then, our problem could involve only those portfolios satisfying

such constraint. We can also consider constraints of insurance on security controls as in insurance policies

there are some requirements regarding controls that the company should comply with to be insured. Other

types of constraints could be dealt with similarly.

29

3.5.3 Return on security investment

Our formulation focused on choosing the best portfolio, but an additional aspect that could be addressed

with our model is calculating the return on security investment (ROSI) to assess the cost eﬀectiveness of a

cybersecurity budget [15, 37]. Calculating the optimal solution over a range of budgets (e.g., from e5,0000

to e25,000) allows generating a function that, for a given budget, gives the optimal solution and expected

utility to explore the return on risk mitigation investments. Additionally, we could ﬁnd the optimal increase

in the portfolio so as to attain a certain expected utility level or reach a certain risk appetite level.

4 DISCUSSION

Current cybersecurity risk analysis frameworks provide a thorough knowledge base for understanding cy-

ber threats, security policies and impacts over assets that depend on the digital infrastructure. However,

such frameworks provide risk analysis methods that are not suﬃciently formalised, neither comprehensive

enough. Most of them suggest risk matrices as their main analytic basis, which provide a fast but frequently

rudimentary study of risks.

Hence, we present an ARA framework providing a formal method supporting all steps relevant to un-

dertake a comprehensive cybersecurity risk analysis.

It implies structuring the cybersecurity problem as

a decision model based on a multiagent inﬂuence diagrams. ARA enables the assessment of beliefs and

preferences of the organisation regarding cybersecurity risks as well as the security portfolio and insurance

they can implement to treat such risks. It takes into account, in addition to non-intentional threats, the

strategic behaviour of adversarial threats. We model the intentional factor through the decision problems of

the Attackers. The case introduced is a simpliﬁcation of a real example but serves as a template for other

cases. Among other things, we had to rely on expert judgement for the uncertainty nodes for which we

lacked data.

From the decision-making point of view, ARA enables the calculation of optimal cybersecurity resource

allocations, facilitating the selection of security and insurance portfolios. Furthermore, it also enables sens-

itivity analysis to evaluate whether the optimal portfolio remains as optimal, in case diﬀerent elements

aﬀecting risk change. This may be used for insurance pricing.

Future work involves the application of this paradigm to study other cybersecurity adversarial problems.

The proposed problem refers to strategic/tactical decisions; it would be interesting to develop dynamic

schemes integrating strategic and operational decisions. Similarly, we shall address the development of

parametric cyber insurance schemes, aimed at supporting the obtention of premiums that, as complement

of the implemented controls, facilitate more eﬀective risk management. Another relevant activity would be

30

the development of a software environment that supports the implementation of the ARA framework for

cybersecurity based on the R routines developed, as well as optimisation algorithms beyond enumeration, to

reduce computational burden.

When compared with standard approaches in cybersecurity, our paradigm entails a more comprehensive

method leading to a more detailed modelling of risk problems, yet more demanding in terms of analysis.

We believe, though, that at many organisations, especially, critical infrastructures and sectors, the stakes at

play are so high that the entailed additional work should be worth the eﬀort.

REFERENCES

[1] Agence Nationale de la S´ecurit´e des Syst`emes d’Information (France). 2010. Expression des Besoins et

Identiﬁcation des Objectifs de S´ecurit´e.

[2] Allodi, L., Massacci, F. 2017. “Security Events and Vulnerability Data for Cybersecurity Risk Estima-

tion”. Risk Analysis, Vol. 37, pp. 1606–1627.

[3] Anderson, R. 2008. Security Engineering, Wiley.

[4] Andress, J. and Winterfeld, S. 2013. Cyber Warfare: Techniques, Tactics and Tools for Security Prac-

titioners. Elsevier.

[5] Bagchi, A., Sprintson, A. and Singh, C. 2013. “Modeling the Impact of Fire Spread on an Electrical

Distribution Network”. Electric Power Systems Research, Vol. 100, pp. 15–24.

[6] Banks, D., R´ıos, J. and R´ıos Insua, D. 2015. Adversarial Risk Analysis. Francis and Taylor.

[7] Central Communication and Telecommunication Agency (UK). 2003. Risk Analysis and Management

Method.

[8] Clemen, R. T., Reilly, T. 2013. Making Hard Decisions with Decision Tools. Cengage Learning.

[9] Cloud Security Alliance. 2016. Cloud Controls Matrix.

[10] The Common Criteria Recognition Agreement Members. 2009. Common Criteria for Information Tech-

nology Security Evaluation, Version 3.1 Release 4.

[11] Cooke, R. and Bedford. T. 2001. Probabilistic Risk Analysis: Foundations and Methods. Cambridge

University Press.

[12] Cox, L. A. 2008. “What’s Wrong with Risk Matrices?”. Risk Analysis, Vol. 28, No. 2, pp. 497–512.

[13] Departamento de Seguridad Ciudadana, Ayto. de Vitoria-Gasteiz (Spain). 2009. Memoria 2009 del

Servicio de Prevenci´on Extinci´on de Incendios y Salvamentos

[14] Dias, L.C., Morton, A. and Quigley, J. 2018. Elicitation: State of the Art and Science. Springer.

31

[15] European Network and Information Security Agency. 2012. Introduction to Return on Security Invest-

ment.

[16] Federal Bureau of Investigation, Internet Crime Compliant Center (USA). 2016. 2016 Internet Crime

Report

[17] Fielder, A., Panaousis, E., Malacaria, P., Hankin, C. and Smeraldi, F. 2016. “Decision Support Ap-

proaches for Cyber Security Investment”. Decision Support Systems, Vol. 86, pp. 13-23.

[18] French, S. and R´ıos Insua, D. 2000. Statistical Decision Theory. Wiley.

[19] Galway, L. A. 2007. Subjective probability distribution elicitation in cost risk analysis: A review. Tech.

Rep. 410, Rand Corporation.

[20] Hubbard, D.W. and Seiersen, R. 2016. How to Measure Anything in Cybersecurity Risk. John Wiley &

Sons.

[21] Incapsula (USA). 2015. Global DDoS Threat Landscape Report: Attacks Resemble Advanced Persistent

Threats.

[22] International Organization for Standardization. 2013. ISO/IEC 27001 – Information Security Manage-

ment Systems - Requirements.

[23] International Organization for Standardization. 2013. ISO/IEC 27005. Information Security Risk Man-

agement.

[24] Kaspersky, Securelist (Russia). 2016. DDoS attacks in Q4 2016.

[25] Leak Source. 2014. “CSEC Document Reveals Suspected France Intelligence Spyware “Babar””. [Re-

trieved 25/Sep/2017]

[26] Lund, M.S., Solhaug, B. and Stølen, K. 2010. Model-driven risk analysis: the CORAS approach Springer.

[27] Marotta, A., Martinelli, F., Nanni, S., Orlando, A. and Yautsiukhin, A. 2017. “Cyber-insurance survey”.

Computer Science Review. Vol. 24, pp 35–61

[28] Milke, J. A., Kodur, V. and Marrion, C. 2002. “An overview of ﬁre protection in buildings”. Appendix

A, World Trade Center Building Performance Study. Federal Emergency Management Agency (USA).

[29] Ministerio de Hacienda y Administraciones P´ublicas (Spain). 2012. Metodolog´ıa de An´alisis y Gesti´on

de Riesgos de los Sistemas de Informaci´on, version 3.

[30] Mirkovic, J. and Reiher, P. 2004. “A taxonomy of DDoS attack and DDoS defense mechanisms.” ACM

SIGCOMM Computer Communication Review Vol.34, pp 39–45.

[31] Mowbray, T. J. 2013. Cybersecurity: Managing Systems, Conducting Testing, and Investigating Intru-

sions. Wiley.

[32] National Institute of Standards and Technology (USA) NIST SP 800-30 Rev. 1 – Guide for Conducting

Risk Assessments.

32

[33] National Technical Authority for Information Assurance (UK). 2012. HMG IA Standard Number 1.

[34] Ortega, J., Radovic, V. and Rios Insua, D. 2018. “Utility elicitation”. In: D´ıas, L., Morton, A. and

Quigley, J., editors. Handbook of judgement elicitation. Springer.

[35] Panda Security (Spain). 2015. Informe PandaLabs Q2 2015.

[36] Rios Insua, D. 1990. Sensitivity Analysis in Multi-objective Decision Making. Springer.

[37] Schatz, D. and Bashroush, R. 2017. “Economic valuation for information security investment: a sys-

tematic literature review”. Information Systems Frontiers, Vol. 19, No. 5, pp 1205–1228.

[38] Shachter, R.D. 1986. “Evaluating inﬂuence diagrams”. Operations Research Vol. 34, No. 6, pp 871–882.

[39] Solutionary (US). 2013. Global Threat Intelligence Report.

[40] Verisign (USA). 2017. Q1 2017 DDoS Trends Report

[41] Wiper, M, Rios Insua, D. and Ruggeri F. 2001. “Mixtures of gamma distributions with applications.”

Journal of Computational and Graphical Statistics Vol. 10, pp. 440–454.

33

APPENDIX

Algorithm 1 Estimating distribution over attacks (defence-attack).
For each defence e
For i = 1, . . . , K
Generate

(cid:16)

U i

A(t2, ct, cc), P i

A(ct|

t1, t2, e), P i

t1, t2, e), P i

A(cc|

e)
A(t1|

(cid:17)

F

∼

(cid:90) (cid:90) (cid:90)

ti
2 = arg max

t2

Compute

end
Approximate

end

U i

A(t2, ct, cc) P i

A(ct|

t1, t2, e) P i

t1, t2, e) P i

e)dt1 dcc dct

A(cc|

A(t1|

ˆpA(t2|

e) =

#

ti
2 = t2}
{
K

Algorithm 2 Approximation of Defender’s optimal portfolio.
ψ(s, i) = 0
For each (s, i)

For j = 1, . . . , 1000

Generate

Compute

Compute

Compute

end

end
Approximate

(cid:0)mj, qj

n, qj

i , bj, lj, aj, vj, oj, f j(cid:1)

G

∼

s,

cj
s|

i,

cj
i |

i, bj, qj
i

gj
i |

d = mj + bj + qj
cj

i + qj

n + cj

s + cj

i −

gj
i

ψ(s, i) = ψ(s, i) +

u(cj
d)
1000

(ˆs∗,ˆi∗) = arg max
s,i

ψ(s, i)

34

