Link prediction in dynamic networks
using random dot product graphs

Francesco Sanna Passino1, Anna S. Bertiger2, Joshua C. Neil*2, and Nicholas A. Heard1

1Department of Mathematics, Imperial College London
2Microsoft 365 Defender, Microsoft Corporation, Redmond (WA)

1
2
0
2

l
u
J

3
1

]
P
A

.
t
a
t
s
[

4
v
9
1
4
0
1
.
2
1
9
1
:
v
i
X
r
a

Abstract

The problem of predicting links in large networks is an impor-
tant task in a variety of practical applications, including social
sciences, biology and computer security. In this paper, statis-
tical techniques for link prediction based on the popular ran-
dom dot product graph model are carefully presented, anal-
ysed and extended to dynamic settings. Motivated by a practi-
cal application in cyber-security, this paper demonstrates that
random dot product graphs not only represent a powerful tool
for inferring differences between multiple networks, but are
also efﬁcient for prediction purposes and for understanding
the temporal evolution of the network. The probabilities of
links are obtained by fusing information at two stages: spec-
tral methods provide estimates of latent positions for each
node, and time series models are used to capture temporal
dynamics.
In this way, traditional link prediction methods,
usually based on decompositions of the entire network adja-
cency matrix, are extended using temporal information. The
methods presented in this article are applied to a number of
simulated and real-world graphs, showing promising results.

Keywords — adjacency spectral embedding, dynamic net-

works, link prediction, random dot product graph.

1

Introduction

Link prediction is deﬁned as the task of predicting the pres-
ence of an edge between two nodes in a network, based on
latent characteristics of the graph (Liben-Nowell and Klein-
berg, 2007). The problem has been widely studied in the lit-
erature (Lü and Zhou, 2011; Menon and Elkan, 2011), and
has relevant applications in a variety of different ﬁelds.
In
this paper, the discussion about link prediction is motivated
by applications in cyber-security and computer network mon-

*The author is currently at Securonix Threat Labs, Securonix Inc., Addi-
son (TX). This work was completed when the author was at Microsoft 365
Defender, Microsoft Corporation, Redmond (WA).

1

itoring (Jeske et al., 2018). The ability to correctly predict and
associate anomaly scores with the connections in a network is
valuable for the cyber-defence of enterprises. In cyber set-
tings, adversaries may introduce changes in the structure of
an enterprise network in the course of their attack. Therefore,
predicting links in order to identify signiﬁcant deviations in
expected behaviour could lead to the detection of an otherwise
extremely damaging network breach. In particular, it is nec-
essary to correctly score new links (Metelli and Heard, 2019),
representing previously unobserved connections. The task is
particularly important since it is common to observe mali-
cious activity associated with new links (Neil et al., 2013),
and it is therefore crucial to understand the normal process of
link formation in order to detect a cyber-attack.

∈

−

i, j

In this article, it is assumed that snapshots of a dynamic
network are observed at discrete time points t = 1, . . . , T ,
obtaining a sequence of graphs Gt = (V, Et). The set V rep-
resents the set of nodes, which is invariant over time, whereas
Et for
the set Et is a time dependent edge set, where (i, j)
V , if i connected to j at least once during the time pe-
i, j
∈
1, t]. Each snapshot of the graph can be characterised
riod (t
n, where n =
by the adjacency matrix At
0, 1
and
∈ {
n, Aijt = 1Et{
, such that Aijt = 1
for 1
}
if a link between the nodes i and j exists in (t
1, t], and
Aijt = 0 otherwise. The graph is said to be undirected if
(i, j)
Et, implying that At is symmetric;
otherwise, the graph is said to be directed. It will be assumed
that the graph has no self-edges, implying At is a hollow ma-
trix. Similarly, bipartite graphs Gt = (V1, V2, Et) can be
represented using two node sets V1 and V2, and rectangular
, n2 =
V2|
adjacency matrices At
,
|
1, t].
where Aijt = 1 if i

n1
0, 1
∈ {
}
V1 connects to j

V1|
|
V2 in (t

n
×
}
(i, j)

n2, n1 =
×

(j, i)

⇐⇒

V
|

Et

≤

≤

−

∈

∈

|

∈

∈

−

This paper discusses methods for temporal link prediction
(Dunlavy et al., 2011): given a sequence of adjacency matri-
ces A1, . . . , AT observed over time, the main objective is to
reliably predict AT +1. In this article, temporal link predic-
tion techniques based on random dot product graphs (RDPG,
Young and Scheinerman, 2007) are discussed and compared.

 
 
 
 
 
 
Link prediction in dynamic networks using random dot product graphs

[0, 1]

RDPGs are a class of latent position models (Hoff et al.,
2002), and have been extensively studied because of their ana-
lytical tractability (Athreya et al., 2018). Each node i is given
a latent position xi in a d-dimensional latent space X such
X. The edges between pairs
that x(cid:62)x(cid:48)
∈
of nodes are generated independently, with probability of a
link between nodes i and j obtained through the inner product
P(Aij = 1) = x(cid:62)i xj. In matrix notation, the latent position
Xn,
can be arranged in a n
and the expected value of a single realised adjacency matrix
A is expressed as E(A) = XX(cid:62).

d matrix X = [x1, . . . , xn](cid:62)

x, x(cid:48)

×

∈

∈

∀

Random dot product graph models and spectral embedding
methods are often the ﬁrst step in the analysis of a graph, be-
cause of their simplicity and ease of implementation, since
intensive hyperparameter tuning is not required. RDPGs are
extensively applied in neuroscience (see, for example, Priebe
et al., 2017). Furthermore, they have appealing theoretical
statistical properties in terms of consistency of the estimated
latent positions. Therefore, it is of interest to understand their
performance for link prediction purposes.

RDPGs models for multiple heterogeneous graphs on the
same node set have recently been proposed in the litera-
ture, but these models have not been formally extended to
a dynamic setting for link prediction purposes. Early ex-
amples discuss methods for clustering and community de-
tection with multiple graphs (Tang et al., 2009; Shiga and
Mamitsuka, 2012; Dong et al., 2014). More recently, the fo-
cus has been on testing for differences in brain connectivity
networks (Arroyo-Relión et al., 2019; Ginestet et al., 2017;
Durante and Dunson, 2018; Kim and Levina, 2019). Levin
et al. (2017) propose an omnibus embedding in which the
different graphs are jointly embedded into a common latent
space, providing distinct representations for each graph and
for each node. Wang et al. (2021) propose the multiple ran-
dom eigen graph (MREG) model, where a common set of
d-dimensional latent features X is shared between the graphs,
and the inner product between the latent positions is weighted
differently across the networks, obtaining E(At) = XRtX(cid:62),
where Rt is a d
d diagonal matrix. Nielsen and Witten
(2018) propose the multiple random dot product graph (multi-
RDPG), which more naturally extends the RDPG to the multi-
graph setting. Their formulation is similar to the MREG of
Wang et al. (2021), but X is modelled as an orthogonal ma-
trix, and Rt is constrained to be positive semi-deﬁnite. The
model is further extended in common subspace independent
edge (COSIE) graphs (Arroyo-Relión et al., 2020), in which
Rt does not need to be a diagonal matrix. More recently,
Jones and Rubin-Delanchy (2021) proposed the Unfolded Ad-
jacency Spectral Embedding (UASE) for the multilayer ran-
dom dot product graph (MRDPG), which is also applied to
a link prediction example within a cyber-security context. In
this work, existing methods for RDPG-based inference, for
example omnibus embeddings (Levin et al., 2017) and COSIE

×

graphs (Arroyo-Relión et al., 2020), will be analysed for link
prediction purposes, and compared to standard spectral em-
bedding techniques.

The main contribution of this work is to adapt the exist-
ing methods for multiple RDPG graph inference for temporal
link prediction. Furthermore, this article proposes methods to
combine the information obtained via spectral methods with
time series models, to capture the temporal dynamics of the
observed graphs. The proposed methodologies will be exten-
sively compared on real world and simulated networks. It will
be shown that this approach signiﬁcantly improves the predic-
tive performance of multiple RDPG models, especially when
the network presents a seasonal or temporal evolution. Over-
all, this article provides insights into the predictive capability
of random dot product graphs, and gives guidelines for prac-
titioners on the optimal choice of the embedding for temporal
link prediction.

Importantly, the strategies for combination of individual
embeddings, and their time series extensions, can in principle
be applied to any embedding method for static graphs, despite
the main focus on RDPGs of this article. This article primarily
focuses on RDPGs because of the wide variety of embedding
techniques which have been suggested in the literature under
this model, but that so far have not been compared for link
prediction purposes.

The article is organised as follows: Section 2 discusses
related literature around link prediction, and Section 3 in-
troduces background on the generalised random dot product
graph and adjacency spectral embeddings, the main statistical
tools used in this paper. Methods for link prediction based on
random dot product graphs are discussed in Section 4. Sec-
tion 5 presents techniques to improve the predictive perfor-
mance of the RDPG models, based on time series models. Re-
sults and applications on simulated and real world networks
are ﬁnally discussed in Section 6.

2 Related literature

Many other models other than RDPGs have been proposed
in the literature for link prediction. Traditionally, the tem-
poral link prediction task is tackled using tensor decompo-
sitions (Dunlavy et al., 2011). Dynamic models have also
been proposed in the literature of Poisson matrix factorisa-
tion and recommender systems (Charlin et al., 2015; Hos-
seini et al., 2020), and extended to Bayesian tensor decom-
positions (Schein et al., 2015).
In general, including time
has been shown to signiﬁcantly improve the predictive perfor-
mance in a variety of model settings, for example stochastic
blockmodels (Ishiguro et al., 2010; Xu and Hero III, 2014;
Xing et al., 2010). More generic latent feature models for dy-
namic networks have also been extensively discussed in the
literature (Sarkar and Moore, 2006; Krivitsky and Handcock,

2

Link prediction in dynamic networks using random dot product graphs

2014; Sewell and Chen, 2015).

Latent features are usually obtained via matrix factori-
sation, considering constant and time-varying components
within the decomposition (Deng et al., 2016; Yu et al.,
2017a,b). Usually, a Markov assumption is placed on the evo-
lution of the latent positions (Zhu et al., 2016; Chen and Li,
2018). Gao et al. (2011) propose to combine node features
into a temporal link prediction framework based on matrix
factorisation. Nonparametric (Sarkar et al., 2014; Durante and
Dunson, 2014) and deep learning (Li et al., 2014) approaches
have also been considered.

More recently, advancements have been made in the ap-
plication of deep learning to graph-valued data. In particular,
deep learning methods on graphs are classiﬁed by Zhang et al.
(2020) into ﬁve categories: graph recurrent neural networks,
graph convolutional networks, graph autoencoders, graph re-
inforcement learning, graph adversarial methods. A compre-
hensive survey of existing static network embedding meth-
ods, including deep learning techniques, is provided in Cai
et al. (2018). Commonly used static embedding methods in
machine learning are DeepWalk (Perozzi et al., 2014), SDNE
(Wang et al., 2016), node2vec (Grover and Leskovec, 2016),
GraphSAGE (Hamilton et al., 2017), graph convolutional net-
works (GCN, Kipf and Welling, 2017), and Watch Your Step
with Graph Attention (WYS-GA, Abu-El-Haija et al., 2018).
Many of such methods could be uniﬁed under a matrix fac-
torisation framework (Qiu et al., 2018). A systematic com-
parison of some of the aforementioned methodologies for un-
supervised network embedding is provided in Khosla et al.
(2021). Methodologies have also been recently proposed in
the dynamic network setting, within the context of representa-
tion learning (for example, Nguyen et al., 2018; Kumar et al.,
2019; Liu et al., 2019; Qu et al., 2020), and deep generative
models (for example, Zhou et al., 2020). The interested reader
is referred to the survey of Kazemi et al. (2020) and references
therein.

Again, it is emphasised that the objective of this paper is not
to claim that the RDPG is superior to competing models, but
to provide guidelines for practitioners using RDPGs in their
application domains, offering insights on the performance of
these models for link prediction purposes.

3 Random dot product graphs and
adjacency spectral embedding

In this section, the generalised random dot product graph
(Rubin-Delanchy et al., 2017) and methods for estimation of
the latent positions are formally introduced. Suppose A
0, 1
{
graph with n nodes.

∈
n is a symmetric adjacency matrix of an undirected

n
}

×

GRDPG). Let d+ and d
−
. Let X
d = d+ + d
−
)x(cid:48)
x(cid:62)I(d+, d
0

−

≤

≤

⊆
1, where

be non-negative integers such that
X,

Rd such that

x, x(cid:48)

∀

∈

I(p, q) = diag(1, . . . , 1,

1, . . . ,

1)

−

−

with p ones and q minus ones. Let (cid:70) be a probability mea-
sure on X, A
n be a symmetric matrix and X =
n
0, 1
}
Xn. Then (A, X)
(x1, . . . , xn)(cid:62)
GRDPGd+,d− ((cid:70))
∼
(cid:70) and for i < j, P(Aij = 1) =
if x1, . . . , xn
x(cid:62)i I(d+, d

)xj independently.

∈ {
∈
iid
∼

×

−

The adjacency spectral embedding (ASE) provides con-
sistent estimates of the latent positions in GRDPGs (Rubin-
Delanchy et al., 2017), up to indeﬁnite orthogonal transfor-
mations.

1, . . . , n
}
ˆΛ
⊥

Deﬁnition 2 (Adjacency spectral embedding – ASE). For
, consider the spectral decomposition A =
d
∈ {
ˆΓ ˆΛˆΓ(cid:62) + ˆΓ
, where ˆΛ is a d
ˆΓ(cid:62)
d diagonal matrix
⊥
⊥
containing the top d eigenvalues in magnitude, in decreasing
order, ˆΓ is a n
d matrix containing the corresponding or-
thonormal eigenvectors, and the matrices ˆΛ
contain
the remaining n
d eigenvalues and eigenvectors. The adja-
cency spectral embedding ˆX = [ ˆx1, . . . , ˆxn](cid:62) of A in Rd
is

and ˆΓ
⊥

×

×

−

⊥

ˆΛ
ˆX = ˆΓ
|
|

1/2

∈

Rn

d,

×

applied to a matrix returns the absolute

where the operator
value of its entries.

|·|

If the graph is directed, and the adjacency matrix is not
symmetric, it could be implicitly assumed that the generat-
ing model is P(Aij = 1) = x(cid:62)i yj, xi, yj
X, where each
node is given two different latent positions, representing the
behaviour of the node as source or destination of the link. In
this case, the embeddings can be estimated using the singular
value decomposition (SVD).

∈

Deﬁnition 3 (Adjacency embedding of the directed graph –
DASE). Given a directed graph with adjacency matrix A
0, 1
{
singular value decomposition

n, and a positive integer d, 1

∈
n, consider the

n
}

≤

≤

d

×

A = (cid:2) ˆU ˆU

(cid:3)

⊥

(cid:20) ˆD 0
ˆD
0
⊥

(cid:21) (cid:20) ˆV(cid:62)
ˆV(cid:62)
⊥

(cid:21)

= ˆU ˆD ˆV(cid:62) + ˆU

ˆD

ˆV(cid:62)
⊥

,

⊥

⊥

d

∈

Rd

where ˆD
+ is diagonal matrix containing the top d sin-
×
gular values in decreasing order, ˆU
d
×
contain the corresponding left and right singular vectors, and
the matrices ˆD
d
⊥
⊥
singular values and vectors. The d-dimensional directed ad-
jacency embedding of A in Rd, is deﬁned as the pair

contain the remaining n

d and ˆV

, and ˆV

, ˆU

Rn

Rn

−

∈

∈

×

⊥

ˆX = ˆU ˆD1/2,

ˆY = ˆV ˆD1/2.

Deﬁnition 1 (Generalised random dot product graph –

The DASE can be also naturally extended to bipartite graphs.

3

Link prediction in dynamic networks using random dot product graphs

4 Dynamic link prediction in random

dot product graphs

align the embeddings is deferred to Appendix A. Assuming
that an averaged embedding ¯X is obtained, the matrix of IPA
scores for prediction of AT +1 is:

Given a time series of network adjacency matrices
A1, A2, . . . , AT , the objective is to correctly predict AT +1.
The most common approach in the literature (Sharan and
Neville, 2008; Scheinerman and Tucker, 2010; Dunlavy et al.,
2011) is to analyse a collapsed version ˜A of the adjacency
matrices:

˜A =

T
(cid:88)

t=1

ψT

−

t+1At,

(4.1)

∀

∈

R is a sequence of weights. Scheiner-
where ψ1, . . . , ψT
man and Tucker (2010) propose to consider an average ad-
jacency matrix, setting ψt = 1/T
t = 1, . . . , T , which
corresponds to the maximum likelihood estimate of E(At)
if A1, . . . , AT are sampled independently from the same
Bernoulli(XX(cid:62)) distribution. The main limitation of such
a model is that it is assumed that the graphs do not dis-
play any temporal evolution. Furthermore, if (4.1) is used, it
is assumed that all the possible edges of the adjacency ma-
trix follow the same dynamics. Obtaining the ASE ˆX =
[ ˆx1, . . . , ˆxn] of ˜A leads to an estimate the scores:

S = ˆX ˆX(cid:62).

(4.2)

−

), implicitly assuming d+ = d and d

For simplicity, the inner product (4.2) is not weighted by the
matrix I(d+, d
= 0.
The estimation approaches in (4.1) and (4.2) will be used as
baselines for comparison with alternative methods for tem-
poral link prediction techniques using RDPGs, which will be
proposed and discussed in the remainder of this section. The
proposed methods will be classiﬁed in the following two cat-
egories:

−

• averages of inner products of embeddings (AIP),
• inner products of an average of embeddings (IPA).
First, it is possible to consider the individual ASE for each

adjacency matrix At, and calculate an AIP score:

SAIP =

1
T

T
(cid:88)

t=1

ˆXt ˆX(cid:62)t .

(4.3)

A second option is to obtain an averaged embedding
¯X from ˆX1, ˆX2, . . . , ˆXT , and use this for predicting the
link probabilities. This procedure is slightly more complex
than (4.3), since the embeddings are invariant to orthogonal
d,
transformations: given an orthogonal matrix Ωt
E(At) = XtX(cid:62)t = (XtΩt)(XtΩt)(cid:62). Therefore, the embed-
dings ˆX1, . . . , ˆXT only provide estimates of the correspond-
ing latent positions up to an orthogonal transformation, which
could vary for different values of t. Consequently, the embed-
dings must be suitably aligned or registered, before a direct
comparison can be carried out. Discussion of a technique to

Rd

∈

×

SIPA = ¯X ¯X(cid:62).

(4.4)

Similar scoring mechanisms can be derived for the tech-
niques of multiple graph inference described in Section 1,
such as the omnibus embedding (Levin et al., 2017), based
on the the omnibus matrix:

˜A =













A1

A2 + A1
2
...
AT + A1
2

A1 + A2
2

A2
...
AT + A2
2

· · ·

· · ·
. . .

· · ·

A1 + AT
2
A2 + AT
2
...
AT













.

(4.5)

The ASE ˆX of ˜A gives T latent positions for each node.
The individual estimates ˆXt = [ ˆx1t, . . . , ˆxnt] of the latent
positions for the t-th adjacency matrix are represented by
the submatrix formed by the estimates between the ((t
−
1)n + 1)-th and tn-th row of ˆX. Then, from the time series
ˆX1, ˆX2, . . . , ˆXT of omnibus embeddings, a matrix of scores
can be obtained using either AIP (4.3) or IPA (4.4). In this
case, the individual embeddings are directly comparable and
an alignment step is not required. On the other hand, the om-
nibus embedding cannot easily be updated when new graphs
AT +1, AT +2, . . . become available, since ˜A and the embed-
ding must be recomputed for each new snapshot. The idea of
an omnibus embedding can be also easily extended to directed
and bipartite graphs, constructing the matrix ˜A analogously
and then calculating the DASE.

Embeddings generated using the more parsimonious
COSIE model (Arroyo-Relión et al., 2020) are also consid-
ered. In COSIE networks, the latent positions are assumed to
be common across the T snapshots of the graph, but the link
d:
probabilities are scaled by a time-varying matrix Rt
E(At) = XRtX(cid:62). The common latent positions X and the
time series of weighting matrices R1, . . . , RT can be esti-
mated via multiple adjacency spectral embedding (MASE,
Arroyo-Relión et al., 2020).

Rd

∈

×

1, . . . , n

∈ {
∈
T d matrix ˜Γ = [ˆΓ1, . . . , ˆΓT ]

Deﬁnition 4 (Multiple adjacency spectral embedding –
MASE). Given a sequence of network adjacency matrices
, obtain the in-
A1, . . . , AT , and an integer d
}
dividual ASEs ˆXt = ˆΓt
ˆΛt
d. Then, construct the
1/2
|
|
Rn
T d, and consider
n
its singular value decomposition ˜Γ = ˆU ˆD ˆV(cid:62) + ˆU
ˆV(cid:62)
ˆD
,
⊥
where ˆD
+ is a diagonal matrix containing the top d
×
singular values in decreasing order, ˆU
RT d
tors, and the matrices ˆD

∈
d contain the corresponding left and right singular vec-
contain the remain-

d and ˆV

, and ˆV

, ˆU

Rn

Rn

Rd

×

∈

∈

∈

×

×

×

⊥

⊥

×

d

⊥

⊥

⊥

4

Link prediction in dynamic networks using random dot product graphs

ing singular values and vectors. The d-dimensional multi-
ple adjacency embedding of A1, . . . , AT in Rd is given by
ˆX = ˆU, which provides an estimate of X, and the sequence
ˆR1, . . . , ˆRT , where

ˆRt = ˆX(cid:62)At ˆX.

For prediction,

the matrix of AIP scores could be ob-
tained from the time series of estimated link probabilities
ˆX ˆR1 ˆX(cid:62), . . . , ˆX ˆRT ˆX(cid:62):

SAIP =

1
T

T
(cid:88)

t=1

ˆX ˆRt ˆX(cid:62).

(4.6)

Alternatively, an averaged ¯R could be equivalently ob-
tained from the time series of estimates ˆR1, . . . , ˆRT . Com-
bining ¯R with the estimate of the latent positions ˆX yields the
IPA scores:

SIPA = ˆX ¯R ˆX(cid:62).

(4.7)

The COSIE model can also be extended to directed and bi-
partite graphs assuming E(At) = XRtY(cid:62). This construc-
tion leads to estimates ˆRt = ˆU(cid:62)At ˆV, where ˆU and ˆV are
estimates of X and Y obtained from MASE on the DASE
embeddings ˆX1, . . . , ˆXT and ˆY1, . . . , ˆYT , based on two ma-
trices ˜Γ constructed from the left and right singular vectors
(cf. Deﬁnition 4).

In summary, several link prediction schemes based on ran-
dom dot product graph models have been proposed, corre-
sponding to three different types of spectral embedding:

• scores based on individual embeddings, cf.

(4.3) and

(4.4),

• omnibus scores, cf. (4.3) and (4.4), based on the matrix

representation in (4.5),

• COSIE scores, cf. (4.6) and (4.7).

Two scores, denoted AIP and IPA, are calculated for each em-
bedding type. All methods will be compared to the popular
collapsed adjacency matrix method in (4.2).

×

The methods described in this section are all based on
truncated eigendecompositions of some form of the adja-
cency matrix. The full eigendecomposition of a n
n
dense matrix requires a cubic computational cost (cid:79)(n3), but
only d eigenvectors and eigenvalues, where d is in general
(cid:79)(1), are required in the algorithms presented in this section.
This reduces the computational effort to (cid:79)(n2) (Yang et al.,
2021). Also, graph adjacency matrices are binary and nor-
mally highly sparse. In this setting, efﬁcient algorithms based
on the power method calculate the required decomposition of
a matrix A in (cid:79)
(Ghashami et al., 2016),
) denotes the number of non-zero entries of the
where nnz(
·
matrix, (cid:80)(
(0, 1) is an ap-
) is a polynomial function and ε
·
proximation error parameter. This allows the methodologies
in this section to be scalable to large networks with the sup-
port of modern computer libraries. For example, calculating

nnz(A)(cid:80)(1/ε)
}
{

∈

t=1 nnz(At)

(cid:80)(1/ε) (cid:80)T
{

the individual embeddings ˆX1, . . . , ˆXT only has complexity
(cid:79)
. COSIE adds a further SVD de-
}
composition in the MASE algorithm, which requires further
(cid:79)(nd2) operations. On the other hand, calculating the om-
nibus embedding for large graphs might quickly become cum-
bersome, especially if T is large, since up to (cid:79)(n2T 2) opera-
tions are required.

5

Improving prediction using
time series models

The collapsed matrix used in (4.1) assumes that the under-
lying dynamics of each link are the same across the entire
graph. This assumption is particularly limiting in real world
applications, where different behaviours might be associated
Instead, edge speciﬁc matrix
with different nodes or links.
Rn
n might be able to more re-
parameters Ψ1, . . . , ΨT
∈
liably capture the behaviour of each edge. A modiﬁcation of
the collapsed matrix ˜A in (4.1) is therefore proposed:

×

˜A =

T
(cid:88)

t=1

(ΨT

t+1 (cid:12)

−

At) ,

(5.1)

Rn

×

∈

(cid:12)

n is a sequence of weighting ma-
where Ψ1, . . . , ΨT
is the Hadamard element-wise product. The ma-
trices, and
trix in (5.1) is denoted predicted adjacency matrix. Note that
in (5.1), the weights can only be estimated for those entries
such that Aijt = 1 for at least one t
, but the
ASE of ˜A still allows to estimate non-zero link probabilities
even for those edges such that Aijt = 0

1, . . . , T

∈ {

t.

}

The idea could be easily extended to all the other predic-
tion settings proposed in Section 4, replacing the average
link probability or average embedding with an autoregressive
combination. For example, from the sequence of standard em-
beddings ˆX1, ˆX2, . . . , ˆXT , it could be possible to obtain the
scores as:

∀

SPIP =

T
(cid:88)

(cid:16)

t=1

ΨT

t+1 (cid:12)

−

ˆXt ˆX(cid:62)t

(cid:17)

.

(5.2)

Alternatively, it could be possible to use a similar technique
ˆXt) of the
d. The scores

to obtain an estimate ˜XT +1 = (cid:80)T
embedding XT +1, where in this case Ψt
are then obtained as:

t+1 (cid:12)
−
Rn
×

t=1(ΨT

∈

SIPP = ˜XT +1 ˜X(cid:62)T +1.

(5.3)

Similarly, for COSIE, the scores could be based on a linear
combination of ˆR1, . . . , ˆRT to estimate RT +1.

The equations (5.2) and (5.3) deﬁne two different method-
ologies to extend multiple RDPG inference models to a dy-
namic setting. Following the same nomenclature used in Sec-
tion 4, the scores based on time series models have been

5

Link prediction in dynamic networks using random dot product graphs

respectively denoted as PIP for the predicted inner prod-
uct (5.2), and IPP for the inner product of the prediction
(5.3). The PIP scores have a particularly interesting property:
the node-speciﬁc embeddings are combined with time series
models at the edge levels, fusing information at two different
network resolutions.

Note that, for COSIE scores, SAIP = SIPA from (4.6) and
= SIPP. This is because for SPIP, the scores
(4.7), but SPIP (cid:54)
are obtained directly from a prediction based on the estimated
link probabilities, whereas for SIPA, the prediction is based on
an estimate of RT +1 from ˆR1, . . . , ˆRT .

For estimation of the weighting matrices Ψ1, . . . , ΨT , the
time series of link probabilities or node embeddings will
be modelled independently. Seasonal autoregressive inte-
grated (SARI) processes represent a ﬂexible modelling as-
R, is a
sumption. A univariate time series Z1, . . . , ZT
SARI(p, b)(P, B)s with period s if the series is a causal au-
toregressive process deﬁned by the equation

∈

iid
∼
φpvp, Φ(v) = 1

φ(L)Φ(Ls)(1

L)b(1

−

−

Ls)BZt = εt, εt

N(0, σ2), (5.4)

−

−

−

−

−

. . .

φ1v

1 + εt with ˜Zt = Zt

Zt
−
= 0 and Φ(v)

Φ1v
−
ΦP vP , and L is the lag operator LkZt = Zt

where φ(v) = 1
−
. . .
k
−
(Brockwell and Davis, 1987). For example, consider a pro-
cess SARI(1, 0)(0, 1)s. The model equation (5.4) becomes
˜Zt = φ1 ˜Zt
s. The process is
−
causal if and only if φ(v)
1.
= 0 for
The parameters of the process p, b, P, B and s are all integer-
valued, and can be interpreted as follows: s is the seasonal pe-
riodicity; b corresponds to the differencing required to make
the process stationary in mean, variance, and autocorrelations,
and B refers to the seasonal differencing; p is to the number
of autoregressive terms appearing in the equation, and simi-
larly P refers to the number of seasonal autoregressive terms.
More details about SARI models and their interpretation are
given in Brockwell and Davis (1987).

| ≤

v
|

The value of s usually depends on the application domain.
For example, in computer networks with daily network snap-
shots, it is reasonable to assume s = 7, which represents a
periodicity of one week. The remaining parameters, p, b, P
and B, could be estimated using information criteria. For
small values of T , the corrected Akaike information criterion
(AICc) is preferred. The corresponding coefﬁcients of the
polynomials φ(v) and Φ(v), and the variance σ2, can be esti-
mated via maximum likelihood (Brockwell and Davis, 1987).
For a discussion on automatic selection of the parameters in
SARI models, see Hyndman and Khandakar (2008).

For prediction of

future values Zt+1 conditional on
Z1, . . . , Zt, the general forecasting equation is obtained from
(5.4), setting εt+1 to its expected value E(εt+1) = 0, and ob-
taining an estimate ˆZt+1 solving from the known terms of the
equation. Analogously, k-steps ahead forecasts for Zt+k can
also be obtained.

In this article, the univariate time series Z1, . . . , ZT mod-

elled using SARI are of four different types:

• Time

series of

estimated link probabilities ob-
tained from any embedding method:
for example
ˆx(cid:62)i1 ˆxj1, . . . , ˆx(cid:62)iT ˆxjT for the standard ASE, representing
the sequence of estimated scores for the edge (i, j). This
type of time series is used to obtain PIP scores, see (5.2);
• Time series of node embeddings on a given embedding
dimension: for example ˆxir1, . . . , ˆxirT , obtained consid-
ering only the i-th node embedding on the r-th dimen-
sion from ˆX1, . . . , ˆXT . Such values are used for the IPP
scores, see (5.3);

• Time series of entries of the COSIE matrix, used
to obtain IPP scores,
For example:
ˆRkh1, . . . , ˆRkhT , corresponding to the (k, h)-th entry in
ˆR1, . . . , ˆRT ;

see (5.3).

• Times series of binary entries of the network adjacency
matrices: for example Aij1, . . . , AijT for the edge (i, j),
used for (5.1).

The coefﬁcients for each entry of the weighting matrices
Ψ1, . . . , ΨT are obtained by matching (5.1), (5.2) and (5.3)
with the model equation (5.4).

In this work, the binary time series A1, A2, . . . , AT is also
modelled using indipendent SARI models for estimation of
(5.1). Such a modelling approach might not be entirely tech-
nically suited for binary-valued time series, but this choice has
relevant practical advantages: most programming languages
have packages for automatic estimation of the parameters in
SARI models, whereas the choice of initial values and esti-
mation of the parameters in most generalised process for bi-
nary time series (MacDonald and Zucchini, 1997; Kauppi and
Saikkonen, 2008; Benjamin et al., 2003) is notoriously difﬁ-
cult, which is not desirable when the estimation task should
be performed automatically and in parallel over a large set of
time series.

The time series modelling extensions presented in this sec-
tion are computationally expensive, since up to n2 or nd time
series model are ﬁtted, each with complexity (cid:79)(T k), where
k is the number of models compared for the purpose of model
selection using AICc. This results in a computational cost of
(cid:79)(n2T k) for PIP scores or (cid:79)(ndT k) for IPP scores, difﬁcult
to manage for large networks. Therefore, with the exception
of the IPP COSIE scores, the methodologies proposed in this
section do not scale well to large networks, unlike the tech-
niques proposed in Section 4. In the case of the IPP COSIE
score (4.7), the cost for prediction of future values of Rt is
only (cid:79)(d2T k), independent of n.

The methodologies for constructing link prediction scores
discussed in this work are summarised in Figure 1 in a
ﬂowchart. In summary, three choices must be made:

• embedding method (collapsed adjacency matrix, stan-

dard ASE, omnibus ASE, COSIE embedding);

• combination method (average, cf. Section 4, or predic-

6

(cid:54)
(cid:54)
Link prediction in dynamic networks using random dot product graphs

tion, cf. Section 5);

• AIP and IPA scores calculated from the omnibus embed-

• inner product (combination of inner products or inner

ding, cf. (4.5),

product of a combination).

• AIP and IPA scores calculated from COSIE, cf. (4.6) and

Clearly, the same methodology could be applied to any em-
bedding method, not necessarily based on the RDPG. Some
examples will be given in Section 6.2.2.

6 Results

The proposed methods were tested on synthetic data and
on real world dynamic networks from different application
transportation systems, cyber-security, and co-
domains:
authorship networks. For all examples, the parameter d was
selected using the proﬁle likelihood elbow criterion of Zhu
and Ghodsi (2006), unless otherwise speciﬁed.

(4.7).

The link prediction problem can be framed as a binary
classiﬁcation task. Hence, the performances of the methods
presented in this article are evaluated using the area under
the receiver operating characteristic (ROC) curve, commonly
known as AUC scores. The results are plotted in Figure 2. The
best performance is achieved by the AIP score based on the
standard ASE, which outperforms the commonly used method
of the collapsed adjacency matrix (4.1).

It is anticipated that the predictions should be improved
upon by the PIP and IPP extensions presented in Section 5,
since the simulated network has clear dynamics which are not
explicitly taken into account using the techniques from Sec-
tion 4. In particular, four methods are discussed:

6.1 Simulated data

6.1.1 Seasonal stochastic blockmodel

1, . . . , K

The performance of the rival link prediction techniques dis-
cussed in this article is initially compared on simulated data
from stochastic blockmodels. The stochastic blockmodel
(Holland et al., 1983) can be interpreted as a special case
of a GRDPG (Rubin-Delanchy et al., 2017): each node i
is assigned a latent community zi
, with cor-
∈ {
}
Rd; the probability of a
responding latent position µzi ∈
link (i, j) only depends on the community allocation of the
two nodes: P(Aij = 1) = µ(cid:62)ziI(d+, d
)µzj . To simu-
late a stochastic blockmodel, a within-community probabil-
K was generated, where
[0, 1]K
ity matrix B =
×
Bij
Beta(1.2, 1.2) is the probability of a link between
two nodes in communities i and j, and K is the number of
communities. The matrix has full rank with probability 1,
hence K = d. In the simulation, T = 100 graph snapshots
with n = 100 and K = 5 were generated. The commu-
nity allocations were chosen to be time dependent, assuming
a seasonality of one week. For each node, community alloca-
tions zi,u, u = 0, . . . , s
1, with s = 7, were sampled uni-
−
1, . . . , K
formly from
. Then, the adjacency matrices were
{
obtained as:

} ∈

Bij

∼

}

{

−

P(Aijt = 1) = Bzi,t mod s,zj,t mod s , t = 1, . . . , T.

Therefore, the link probabilities change over time, with a pe-
riodicity of 7 days. The models presented in Section 4 were
ﬁtted using the ﬁrst T (cid:48) = 80 snapshots of the graph, with
the objective of predicting the remaining T
T (cid:48) adjacency
matrices. The methods that are initially compared are:
• ASE of the averaged adjacency matrix, cf.

(4.1) and

−

(4.2),

• AIP and IPA scores calculated from the standard ASE,

cf. (4.3) and (4.4),

• ASE of the predicted adjacency matrix, cf.
(5.1),
with weights obtained from independent
seasonal
SARI(p, b)(P, B)7 processes ﬁtted on each binary se-
quence Aij1, Aij2, . . . , AijT (cid:48) such that at
least one
Aijt = 1;
• PIP scores

calculated from the
on

the

(5.2),

based

cf.
ˆx(cid:62)i1 ˆxj1, ˆx(cid:62)i2 ˆxj2, . . . , ˆx(cid:62)iT (cid:48) ˆxjT (cid:48)
individual ASEs on each A1, A2, . . . , AT (cid:48);

edge
obtained

standard ASE,
series
from the

time

• IPP scores calculated from the standard ASE, cf. (5.3),
based on prediction of the subsequent embeddings
˜XT (cid:48)+1, ˜XT (cid:48)+2, . . . from the time series of aligned1 in-
dividual ASEs ˆX1, . . . , ˆXT (cid:48);

• IPP scores calculated from COSIE, based on prediction
of correction matrices ˜RT (cid:48)+1, ˜RT (cid:48)+2, . . . from the time
series ˆR1, . . . , ˆRT (cid:48), where independent models are ﬁtted
to the d

d time series corresponding to each entry.

×

The time series models were ﬁt using the function auto_arima
in the statistical python library pmdarima, using the corrected
AIC criterion to estimate the number of parameters. The re-
sults are presented in Figure 3.

The AIP method (4.3) which had the best performance in
Figure 2, is signiﬁcantly improved by the PIP score (5.2) us-
ing time series modelling, and it is overall the only method
that reaches values of the AUC well above 0.8. Remarkably,
the performance of the predicted adjacency matrix method in
(5.1) outperforms the results based on most of the other meth-
ods, despite the issues related to the modelling of binary time
series pointed out in Section 5. On the other hand, the im-
provements obtained using the COSIE-based scores and the
IPP score (5.3) seem to be less signiﬁcant compared to the

1The

indeﬁnite Procrustes

in Ap-
pendix A, has been implemented in python using rpy2 and the R
codebase developed by Joshua Agterberg, available online at https:
//github.com/jagterberg/indefinite_procrustes and https:
//jagterberg.github.io/assets/procrustes_simulation.html.

alignment

described

step,

7

Link prediction in dynamic networks using random dot product graphs

Figure 1: Flowchart summarising the construction of a link prediction method using the techniques in Sections 4 and 5.

(a) Collapsed adjacency matrix scores
AIP and PIP scores, standard ASE

Figure 2: Results of the link prediction procedure on the simulated

seasonal SBM.

(b) IPA and IPP scores, standard ASE and COSIE

two other methods. This aspect will also be conﬁrmed on real
data examples in the next section. In general, it is clear from
the plots in Figure 3 that adding temporal dynamics to the net-
work via time series modelling is beneﬁcial for link prediction
purposes. In particular, including edge speciﬁc information
from the time series of estimated link probabilities, or from
the binary time series of links, has signiﬁcantly improved link
prediction.

6.1.2 Logistic dynamic network model

Next, the effect of the dynamic component on the prediction
is evaluated. A directed dynamic graph with n = 100 and
T = 100 is simulated, assuming Aijt
Bernoulli(vijt), t =
1, . . . , T , where

∼

logit(vijt) = bij + cijθ(t

1),

−

(6.1)

∈

∼

6.9, 0) in-
where bij is a baseline, such that bij
Uniform(
−
(0.001, 0.5).
dependently for all pairs (i, j), implying vij1 ∈
R is a trend parameter common to all the
Furthermore, θ
possible edges, and cij
is the sign of the trend on
each edge, such that P(cij = 1) = P(cij =
1) = 1/2. Note
that if θ = 0, the graph does not have any dynamics, whereas
increases, the graph dynamics also increases. Note that,
if
asymptotically for t
0 if cijθ
, and
vijt
. Dynamic graphs are simulated for

1 if cijθ

1, 1
}

→ −∞

→ ∞

∈ {−

, vijt

θ
|

→

−

|

→

→ ∞

Figure 3: Comparison between four of the link prediction models in
Figure 2, and their extensions using the methods in Sec-
tion 5, on the synthetic SBM data.

−

∈ {

0, 0.025, 0.05, 0.075

, and the AIP and PIP scores ob-
θ
}
tained from standard ASE trained on the ﬁrst T (cid:48) adjacency
matrices are calculated for prediction of the last T
T (cid:48) net-
work snapshots. The results are then compared with the AIP
scores with standard ASE, sequentially updated when new
network snapshots become available, used for a 1-step ahead
prediction of the next snapshot.
If the network has a rele-
vant dynamic component, the difference between the AUC
obtained from the sequential and non-sequential AIP scores
increases over time, because the network structure changes
and the non-sequential scores cannot capture such evolution.
On the other hand, the difference between the sequential AIP

8

Embeddingmethod-ASEofthecollapsedadjacencymatrix-standardASE-omnibusASE-COSIEembeddingCombinationmethod-average(A)-prediction(P)Innerproduct-innerproductofthecombination(IP-)-combinationoftheinnerproducts(-IP)Linkpredictionmethode.g.AIPscores,omnibusASE(averageofinnerproductsobtainedfromtheomnibusASEembedding)808284868890929496981000.550.60.65tAUCAIPscores,standardASEIPAscores,standardASEAIPscores,omnibusASEIPAscores,omnibusASEIPAscores,COSIEaveragedadjacencymatrix808284868890929496981000.60.70.8tAUCaveragedadjacencymatrixpredictedadjacencymatrixAIPscores,standardASEPIPscores,standardASE808284868890929496981000.60.7tAUCIPAscores,standardASEIPAscores,COSIEIPPscores,standardASEIPPscores,COSIELink prediction in dynamic networks using random dot product graphs

scores and the PIP scores should not show an increasing trend
over time, since the time dynamics is taken into account via
time series modelling.

Figure 4 plots the time series of differences between the
sequential AIP scores and the corresponding non-sequential
scores (Figure 4a), and the difference between the sequential
AIP scores and the PIP scores (Figure 4b), for four differ-
ent values of θ. The plot demonstrates that in presence of
a strong dynamic component, the sequential scores outper-
form non-sequential scores over time, as expected. On the
other hand, the PIP scores perform similarly to the sequen-
tial scores, and the trend in the differences seem to disappear,
up to ﬂuctuations: this is overall remarkable, since the PIP
scores are used for up to (T
T (cid:48))-steps ahead predictions of
−
matrices of scores based only on the initial T (cid:48) adjacency ma-
trices, whereas the sequential scores also use the last T
T (cid:48)
adjacency matrices sequentially for 1-step ahead predictions.

−

6.2 Santander bikes

Santander Cycles is a self-service cycle hire scheme operated
in central London. Data about usage of the bikes are periodi-
cally released by Transport for London2. In this example, data
from 7 March, 2018 to 19 March, 2019 were used, for a total
of T = 378 days. Each bike sharing station is considered as
a node, and an undirected edge (i, j, t) is drawn if at least one
journey between the stations i and j is completed on day t.
The total number of docking stations in London is n = 840.
The daily graphs are fairly dense, with an average edge den-
sity of approximately 10% across the T networks. The ﬁrst
T (cid:48) = 250 graphs are used as training set.

6.2.1 Averaged scores

Initially, the methods compared are four of the techniques
used to produce Figure 2:

• ASE of the averaged adjacency matrix,
• AIP and IPA scores calculated from the standard ASE,
• IPA scores calculated from COSIE.
For the Santander Cycles network, the results are reported
in Figure 5 for d = 10.
In Figure 5, the performance of
the classiﬁcation procedure drops around day 294. This cor-
responds to Christmas day, which has a different behaviour
compared to non-festive days. It is also interesting to point
out that COSIE methods tends to perform better on weekdays
than weekends, whereas the other methods more accurately
predict the links on weekends compared to weekdays. The re-
sults of the link prediction procedure in Figure 5 suggest that
the data might not have a long term trend, but only a seasonal
component, since the performance does not signiﬁcantly de-
crease over time, and the parameters obtained using a training

2The data are freely available at https://cycling.data.tfl.gov.

uk/, powered by TfL Open Data.

(a) Difference between sequential and non-sequential AIP scores,

standard ASE

(b) Difference between sequential AIP and non-sequential PIP

scores, standard ASE

Figure 4: Difference between sequential AIP scores and (a)
(b) non-sequential PIP
non-sequential AIP scores,
scores,
∈
{0, 0.025, 0.05, 0.075} in the logistic dynamic network
model (6.1).

calculated from standard ASE,

for θ

set of size T (cid:48) = 250 seem to reliably predict the structure of
the adjacency matrix even at T = 378. Overall, this example
seems to conﬁrm that the method of AIP scores (4.3) based
on standard ASE has the best performance for link prediction
purposes when time dynamics are not included.

6.2.2 Comparison with alternative methods

To provide further comparison, the methods proposed in Sec-
tion 4 are also compared in Figure 6 to other methods used
for link prediction in the literature. In order to demonstrate
that the proposed methodology could be readily extended to
any embedding technique, the embeddings were calculated
from each of the adjacency matrices A1, . . . , AT , and predic-
tion scores were obtained using the AIP methodology, akin to
(4.3). The alternative methods considered in this section are:

9

808284868890929496981000123·10−2tDifferenceofAUCsθ=0θ=0.025θ=0.05θ=0.07580828486889092949698100−1−0.500.511.5·10−2tDifferenceofAUCsθ=0θ=0.025θ=0.05θ=0.075Link prediction in dynamic networks using random dot product graphs

Figure 6: Results of the link prediction procedure on the Santander

Cycles network for different link prediction methods.

Figure 5: Results of the link prediction procedure on the Santander
Cycles network for different RDPG-based link prediction
methods.

• AIP scores calculated from the Adamic-Adar (AA) and
Jaccard coefﬁcients (used, for example, in Güne¸s et al.,
2016),

• AIP scores calculated from non-negative matrix factori-
sation (NMF; see, for example, Chen et al., 2017; Yu
et al., 2017a) with d = 10,

∈

• AIP scores calculated from unsupervised GraphSAGE
(Hamilton et al., 2017), GCN (Kipf and Welling, 2017)
with Deep Graph Infomax (DGI, Velickovic et al., 2019),
and Watch Your Step with Graph Attention (WYS-GA,
Abu-El-Haija et al., 2018)3. Unsupervised network em-
Rd are obtained independently for each
beddings ˆxit
of the T (cid:48) graphs in the training set, using one of the
aforementioned methods with one-hot indicator vectors
as node features (when required). For the unsuper-
vised GraphSAGE, a two-layer model with sizes 50 and
d = 10 is ﬁtted, with 10 walks of length 10 per node,
batch size 512 and 10 iterations in each encoder; Adam
(Kingma and Ba, 2015) is used for learning the embed-
2. Note that the embed-
dings, with learning rate 10−
ding dimension has been chosen to match the dimension
of the RDGP-based embeddings. For the GCN, a one-
layer network is trained, with layer size d = 10 and
ReLU activation, optimised by Adam with learning rate
2. For WYS-GS, 100 walks per node are used, with
10−
β = 0.1 and C = 10 (for the deﬁnition of such pa-
rameters, see Abu-El-Haija et al., 2018), with embed-
ding dimension d = 10; the model is then trained with
3. For each of the meth-
Adam with learning rate 10−
ods, edge features are obtained from the Hadamard prod-
uct ˆxit
ˆxjt between the estimated node embeddings
(see, for example, Grover and Leskovec, 2016). The
link probabilities for each time window are then esti-

(cid:12)

−

mated from T (cid:48) independent logistic regression models
ˆxjt.
with response Aijt and d predictors of the form ˆxit
The link probabilities are then combined using the AIP
method (4.3), and used to predict connections in the last
T

T (cid:48) observed graphs.

(cid:12)

• Predictive scores calculated from three methods specif-
ically developed for representation learning of dynamic
graphs: the Deep Embedding Auto-Encoder Method for
Dynamic Graphs (DynGEM, Goyal et al., 2017), the dy-
namic graph2vec autoencoder recurrent neural network
model (DyG2V-AERNN, Goyal et al., 2020)4, and the
Dynamic Self-Attention Network (DySAT, Sankar et al.,
2020)5. The methods were run using the default imple-
mentation of the software packages, setting the output
embedding dimension to d = 10 and the batch size to
100. Link probabilities for the T
T (cid:48) graphs in the test
set were calculated using the same procedure described
for GraphSAGE, GCN-DGI and WYS-GA.

−

The best performance among the alternative methods is
achieved by the NMF scores, which achieve an almost equiv-
alent performance to the AIP scores obtained from standard
ASE. Slightly inferior performance is achieved by DyG2V-
AERNN and DySAT, despite consistently exceeding 0.85
in AUC. GCN, Jaccard, WYS-GA and GraphSAGE have
a slightly worse performance, but still consistently achieve
AUC scores exceeding 0.8. All of the proposed method-
ologies perform better than the Adamic-Adar and DynGEM,
which seem to be largely outperformed by spectral embedding
methods. Note that representation learning methods shine in
particular when applied to large graphs with rich node features
(for example, Hamilton et al., 2017), which is clearly not the
case for the Santander cycles network. Furthermore, hyper-
parameter tuning is necessary to obtain a good link prediction
performance, whereas RDGP-based methods only require the

4The models were ﬁtted using the implementation in the python library

DynamicGEM (Goyal et al., 2018).

3The models were ﬁtted using the implementation in the python library

5The model was ﬁtted using the code in the GitHub repository https:

stellargraph (CSIRO’s Data61, 2018).

//github.com/aravindsankar28/DySAT.

10

2602803003203403603800.840.860.880.9tAUCAIPscores,standardASEIPAscores,standardASEaveragedadjacencymatrixIPAscores,COSIE2602803003203403603800.70.750.80.850.9tAUCstandardASEAAJaccardNMFGraphSAGEGCNWYS-GADynGEMDyG2V-AERNNDySAT2602803003203403603800.70.750.80.850.9tAUCstandardASEAAJaccardNMFGraphSAGEGCNWYS-GADynGEMDyG2V-AERNNDySAT2602803003203403603800.70.750.80.850.9tAUCstandardASEAAJaccardNMFGraphSAGEGCNWYS-GADynGEMDyG2V-AERNNDySAT2602803003203403603800.70.750.80.850.9tAUCstandardASEAAJaccardNMFGraphSAGEGCNWYS-GADynGEMDyG2V-AERNNDySAT2602803003203403603800.70.750.80.850.9tAUCstandardASEAAJaccardNMFGraphSAGEGCNWYS-GADynGEMDyG2V-AERNNDySAT2602803003203403603800.70.750.80.850.9tAUCstandardASEAAJaccardNMFGraphSAGEGCNWYS-GADynGEMDyG2V-AERNNDySATLink prediction in dynamic networks using random dot product graphs

embedding dimension as input, and no further tuning is re-
quired.

As discussed in Section 1, it should be noted that the
methodologies of AIP and IPA scores proposed in Section 4,
and the corresponding PIP and IPP extensions in Section 5,
could be applied to any sequence of individual embeddings,
not necessarily obtained using ASE, but also with other em-
bedding methods for static networks, for example NMF, as
demonstrated in this section. Since one of the main objec-
tives of this paper is comparing different embedding methods
based on RDPGs, the focus in subsequent examples will be
only on RDPG-based techniques.

6.2.3 Sequential scores

−

So far, the embeddings learned using the initial T (cid:48) snapshots
have been used to predict all the remaining T
T (cid:48) adjacency
matrices. In practical applications, it would be necessary to
sequentially update the scores when new snapshots become
available over time, improving the predictive performance.
This is demonstrated in Figure 7, where the AIP scores for
standard ASE and the average adjacency matrix scores from
Figure 5 are compared with their sequential counterparts, ob-
tained when the model is updated using each new observation
At in the test set. Clearly, updating the scores sequentially is
beneﬁcial, especially towards the end of the test set, whereas
the difference between the methodologies is negligible in the
initial snapshots of the test set. Both methods seem to reliably
predict even k-steps ahead network snapshots, since the non-
sequential curves in Figure 7 are fairly close to their sequen-
tial counterparts. The method of AIP scores based on stan-
dard ASE outperforms the scores based on the averaged adja-
cency matrix, commonly used in the literature, including se-
quential settings. Furthermore, the non-sequential AIP scores
(4.3) also outperform the sequential averaged adjacency ma-
trix. This result is quite remarkable, since the former only use
the initial T (cid:48) snapshots of the network for training, whereas
the latter is sequentially updated with the snapshots in the test
set.

6.2.4 Predicted scores

The performance of the classiﬁers can be improved using
some of the time series model in Section 5. Figure 8a show
the results obtained from the prediction of subsequent COSIE
correction matrices. The predictive performance is slightly
improved by the extended time series models. Again, it is
empirically conﬁrmed that adding temporal dynamics is ben-
eﬁcial for the performance of random dot product graph based
classiﬁers.

On the other hand, predicting the subsequent adjacency
spectral embeddings from the time series of aligned embed-
dings ˆX1, ˆX2, . . . , ˆXT (cid:48) does not seem to improve the predic-

Figure 7: Results for the AIP scores (4.3) and averaged adjacency
matrix scores for the Santander Cycles network, with and
without sequential updates.

tive performance. The results are presented in Figure 8b, and
conﬁrms the ﬁndings in Figure 3b, where the improvements
on the simulated network were less signiﬁcant compared to
other methods. In this case, the time series models are not
able to capture the dynamics of the aligned embeddings, and
the predictive performance does not improve in AUC.

The limited improvements in the results seem to suggest
that the network does not have a strong dynamic component.
The tradeoff between performance and the computational ef-
fort required to ﬁt multiple independent time series simulta-
neously, would suggest use of the AIP scores (4.3) based on
standard ASE in practical applications.

6.3 Los Alamos National Laboratory dataset

The uniﬁed host and network dataset (Turcotte et al., 2018)
released by the Los Alamos National Laboratory (LANL)
consists of a collection of network ﬂow and host event logs
generated from their machines running Microsoft Windows.
From the host event logs, 90 daily user-authentication bipar-
tite graphs have been constructed, writing Aijt = 1 if the user
i initiates a connection authenticating to computer j, on day t.
This graph is known as the user – destination IP graph. A to-
tal of n1 = 12,222 users, n2 = 5,047 hosts, and 85,020 pairs
(i, j) are observed, corresponding to approximately 0.137%
of all possible links.

6.3.1 Averaged scores and subsampling

The ﬁrst T (cid:48) = 56 matrices are used as training set. Note that
n2 scores for
it is computationally difﬁcult to calculate n1 ×
each adjacency matrix, and storing such large dense matri-
ces in memory is also not efﬁcient. Therefore, an estimate of
the AUC can be obtained by subsampling the negative class
at random from the zeroes in the test set adjacency matrices.
Two subsampling techniques are used to construct the nega-
tive class for prediction of At:

11

2602803003203403603800.860.880.9tAUCaveragedadjacencymatrix,non-sequentialaveragedadjacencymatrix,sequentialAIPscores,standardASE,non-sequentialAIPscores,standardASE,sequentialLink prediction in dynamic networks using random dot product graphs

(a) IPA and IPP scores, COSIE

(a) Subsampling (1).

(b) IPA and IPP scores, standard ASE

(b) Subsampling (2).

Figure 8: Comparison between two of the link prediction models in
Figure 5, and their extensions using the methods in Sec-
tion 5, on the Santander Cycles network.

(1) the negative class is constructed by sampling pairs (i, j)

such that Aijt = 0,

(2) the negative class contains randomly selected pairs (i, j)
such that Aijt = 0, and all pairs (i, j) such that Aijt = 0
and Aijt(cid:48) = 1 for at least 1 value of t(cid:48)

1, . . . , T

∈ {

.
}

For simplicity, the two techniques are denoted with the
numbers (1) and (2) in Figure 9, which reports the results for
the 6 methods considered in Figure 2 in Section 6.1. The for-
mer subsampling technique provides an estimate of the ROC
curve for the entire matrix, since the scores are sampled at
random from the distribution of all scores. On the other hand,
the latter method includes in the negative class more elements
that tend to have associated high scores, represented by the
pairs (i, j, t) such that Aijt = 0 and Aijt(cid:48) = 1 for at least
1 value of t(cid:48)
, giving an unbalanced sampling
}
procedure and therefore a biased estimate of the ROC curve.
Clearly, higher AUC scores are obtained using the ﬁrst sub-
sampling procedure.

1, . . . , T

∈ {

Interestingly, in Figure 9a, the COSIE-based AIP scores
seem to have the best predictive performance across the dif-
ferent methods. In particular, COSIE scores tend to largely
outperform the other methods during weekdays, whereas the
performance during weekends seems almost equivalent, and
sometimes inferior, to the AIP scores (4.3) based on the stan-
dard ASE. On the other hand, in Figure 9b, COSIE scores

Figure 9: Results of the link prediction procedure on the LANL net-
work. AUCs are calculated from ≈ 150,000 links per
graph.

have the worst performance among the methods, except a
spike on day 62.
In Figure 9b, AIP scores (4.3) based on
the standard ASE once again give the best predictive perfor-
mance. The results of Figure 9b are of particular interest since
these allow for a comparison of the classiﬁers on a more chal-
lenging negative class compared to Figure 9a. Therefore, it is
reasonable to conclude that the AIP scores (4.3) emerge again
as the most suitable method for link prediction based on ran-
dom dot product graphs.

6.3.2 Signiﬁcance of the difference between methods

It could be argued that the differences between the method-
ologies do not appear to be signiﬁcant, and might be due to
the subsampling scheme. In order to assess signiﬁcance of
the differences, the subsampling procedure was repeated for
M = 100 times, and the corresponding AUCs were calcu-
lated. Figure 10 plots the estimated 95% conﬁdence intervals
for the difference between the AUCs obtained using differ-
ent methods. Figure 10a uses the IPA scores calculated with
COSIE as reference, and the AUCs are obtained with sub-
sampling (1). Similarly, Figure 10b uses subsampling (2),
and the AIP scores calculated with standard ASE are used

12

2602803003203403603800.840.860.88tAUCIPAscores,COSIEIPPscores,COSIE2602803003203403603800.860.880.9tAUCIPAscores,standardASEIPPscores,standardASE606570758085900.980.991tAUC606570758085900.90.920.94tAUCAIPscores,standardASEIPAscores,standardASEAIPscores,omnibusASEIPAscores,omnibusASEaveragedadjacencymatrixIPAscores,COSIELink prediction in dynamic networks using random dot product graphs

(a) IPA scores, COSIE vs.
alternative methods – Subsampling (1)

(b) AIP scores, standard ASE vs.
alternative methods – Subsampling (2)

Figure 11: Results for the AIP scores (4.3) on the LANL network
with streaming updates. AUCs are calculated from ≈
150,000 links, using subsampling (2).

A demonstration using the method of ﬁxed forgetting factors
(Gama et al., 2013) is given here. The matrix of scores St for
prediction of At+1 is updated in streaming as follows:

wt = λwt

(cid:18)

St =

1

1 + 1,
(cid:19)
1
wt

St

−

1 +

1
wt

ˆXt ˆX(cid:62)t ,

(6.2)

−

−

Figure 10: 95% conﬁdence intervals of the difference between AUCs
obtained alternative methods, obtained using subsam-
pling (1) in (a) and (2) in (b). Reference method: (a)
IPA scores, COSIE, (b) AIP scores, standard ASE.

as reference. Note that the width of the conﬁdence intervals
in Figure 10 is barely visible, since the standard deviations
4. This is because the num-
of the AUC scores are < 10−
ber of subsamples is large enough to obtain extremely pre-
cise estimates of the AUC. Since the conﬁdence intervals do
not contain zero at any of the time points, the pairwise dif-
ferences between the performance of different methodologies
appear to be statistically signiﬁcant. Similar conﬁdence inter-
6 were observed for
vals, and corresponding p-values < 10−
all the comparisons in the current and next sections, suggest-
ing that the subsampling procedure for estimation of the AUC
is robust.

6.3.3 Streaming link prediction and sequential scores

For this example, it is also demonstrated how the proposed
methods can be extended for streaming applications. For ex-
ample, the method of combining inner products of individual
embeddings is particularly suitable for implementation in a
streaming fashion, since the inner products are easily updated
on the run when new snapshots of the graph are observed.

∈

starting from w1 = 1 and S1 = ˆX1 ˆX(cid:62)1 . The forgetting fac-
[0, 1] is usually chosen to be close to 1 (Gama et al.,
tor λ
2013). Note that λ = 1 corresponds to the sequential AIP
scores in (4.3), calculated as in Figure 7, whereas smaller val-
ues of λ give more weight to recent observations. In partic-
ular, λ = 0 only gives weight to the most recent snapshot.
Schemes similar to (6.2) could be also implemented to up-
date the collapsed adjacency matrix (4.1), obtaining the scores
from its ASE at each point in time, or to update the matrix Rt
in (4) for the COSIE embeddings, or the rotated embeddings
ˆXt. The forgetting factor approach might be interpreted as a
simpliﬁcation of the time series scheme proposed in Section 5,
where the same weight is given to each edge.

∈

The results for the entire observation period for a range of
different values of λ are plotted in Figure 11. The best per-
formance is achieved with the forgetting factor approach with
λ
[0.4, 0.8]. The performance for λ = 0 clearly drops
around the weekends, since the network has a seasonal com-
ponent which is not accounted for in the prediction. The dif-
ference between the curves for λ = 1 and λ < 1 suggests
that the graph has temporal dynamics which is captured by the
forgetting factor approach, which down-weights past observa-
tions in favour of more recent snapshots of the graph. This im-
pression is conﬁrmed by Figure 12, which shows the sequen-
tial and non-sequential AIP scores based on the standard ASE,
akin to Figure 7. The predictive performance slightly deteri-
orates for snapshots that are further away in time, whereas
1-step ahead predictions based on the sequential scores con-
sistently give better results.

13

60657075808590−505·10−3tDifferenceofAUCsIPAscores,COSIEvs.averagedadjacencymatrixIPAscores,COSIEvs.IPAscores,standardASEIPAscores,COSIEvs.AIPscores,standardASE60657075808590−101·10−2tDifferenceofAUCsAIPscores,standardASEvs.averagedadjacencymatrixAIPscores,standardASEvs.IPAscores,standardASEAIPscores,standardASEvs.IPAscores,COSIE01020304050607080900.850.90.951tAUCλ=0.0λ=0.2λ=0.4λ=0.6λ=0.8λ=1.001020304050607080900.850.90.951tAUCλ=0.0λ=0.2λ=0.4λ=0.6λ=0.8λ=1.0Link prediction in dynamic networks using random dot product graphs

ting the time series models on the sequence ˆR1, . . . , ˆRT (cid:48) of
COSIE weighting matrices is inexpensive, and it is therefore
possible to scale the time series extension of the IPA scores
to a fairly large network. The results of this procedure are
plotted in Figure 15, which shows again that the time series
extension is beneﬁcial for link prediction purposes.

6.5 DBLP dataset

Figure 12: Results for the AIP scores (4.3) for the LANL network,
with and without sequential updates. AUCs are calcu-
lated from ≈ 150,000 links per graph, using subsam-
pling (1).

6.3.4 Predicted scores

The performance can be again improved using the time series
models in Section 5. Figure 13 shows the results obtained us-
ing the two different subsampling schemes for three methods:
• ASE of the averaged and predicted adjacency matrix,
• AIP and PIP scores calculated from standard ASE,
• IPA and IPP scores calculated from COSIE.

From Figures 13a, 13c and 13e, it is evident that the exten-
sions do not improve the performance of the classiﬁer when
the subsampling scheme (1) is used. On the other hand,
Figures 13b, 13d and 13f show that relevant improvements
(especially on day 62) are obtained when the subsampling
method (2) is used, which represents a more difﬁcult classi-
ﬁcation task. Again, the results conﬁrm that the performance
of RDPGs for link prediction can be enhanced by time series
models.

6.4

Imperial College network ﬂow data

The methodologies proposed in Section 4 are also tested on a
large computer network, demonstrating that the spectral em-
bedding techniques are scalable to graphs of large size. A
directed graph with n = 95,220 has been constructed using
network ﬂow data collected at Imperial College London, lim-
iting the connections to internal hosts only. The data have
been collected over T = 47 days, between 1st January and
16th February 2020. An edge between a client i and a server j
is drawn on day t if the two hosts have connected at least once
during the corresponding day. The number of edges ranges
from a minimum of 344,565, observed on 1st January, to a
maximum of 912,984 on 6th February.

The results are plotted in Figure 14. In this case, the best
performance is achieved by the COSIE scores, similarly to
the LANL network in Figure 9a. The traditional methodol-
ogy of the averaged adjacency matrix is also outperformed by
the AIP scores, which supports the results obtained in all the
previous real data examples. As pointed out in Section 5, ﬁt-

Finally, the methodology is evaluated on a version of the
DBLP co-authorship dataset6, extensively used in the com-
puter science literature. The DBLP network is undirected,
with n = 1,258,753 nodes, corresponding to authors of pa-
pers in computer science, for a total of 7,654,336 undirected
co-authorship edges over T = 15 years, starting in 2000. An
edge between two authors i and j is drawn if they co-authored
a paper in year t. The network is extremely sparse, with edge
7 to
densities ranging from 1.90
10−
2015. The number of co-authorships consistently increases
over the years, corresponding to a steady increase in the num-
ber of publications in computer science journals and confer-
ences.

7 in 2000 to 7.41

10−

·

·

−

The initial T (cid:48) = 10 graphs, from 2000 to 2009, are used
as training set, whereas the last T
T (cid:48) graphs, from 2010 to
2014, correspond to the test set. The results are presented in
Table 1, for the same models examined in Section 6.4 on the
Imperial College network, for the two different subsampling
schemes. Unsurprisingly, the AIP scores with standard ASE
achieve the best performance. Limited improvement is ob-
tained considering the time series extension on the IPA scores
with COSIE.

The performance of the RDPG on the DBLP network is
signiﬁcantly worse than the other examples considered in this
section, suggesting that RDPG-based methods might not be
the most appropriate technique for this graph. This is be-
cause the graph is extremely sparse, and a large number of
new nodes appears in the network over time. Such authors,
before their ﬁrst published paper, are represented by rows and
columns ﬁlled with zeros in the adjacency matrix, acting as
disconnected components in the graph. Therefore, learning
the embedding for such nodes is particularly difﬁcult for the
RDPG, since a limited (or null) history of co-authorships is
available.

6.6 Discussion and summary of results

The main methodological contribution of this article is an
adaptation for temporal link prediction of existing RDPG-
based methods for joint inference on multiple graphs. Also,
this article proposes techniques to capture the temporal dy-
namics of the observed graphs, combining the link proba-

6The data are freely available at https://projects.csail.mit.edu/

dnd/DBLP/.

14

606570758085900.980.991tAUCAIPscores,standardASE,non-sequentialAIPscores,standardASE,sequentialLink prediction in dynamic networks using random dot product graphs

(a) Collapsed adjacency matrix
Subsampling (1)

(b) Collapsed adjacency matrix
Subsampling (2)

(c) AIP and PIP, standard ASE
Subsampling (1)

(d) AIP and PIP, standard ASE
Subsampling (2)

(e) IPA and IPP, COSIE scores
Subsampling (1)

(f) IPA and IPP, COSIE scores
Subsampling (2)

Figure 13: Comparison between three of the link prediction models in Figure 9, and their extensions using the methods in Section 5, on the

LANL network. AUCs are calculated from ≈ 150,000 links per graph.

bilities and embeddings obtained via spectral methods with
time series models. As demonstrated in Section 6.2.2, the
proposed methods for combination of individual embeddings,
and the extension based on time series modes, can be applied
on any embedding method for static graphs, not necessarily
restricted to RDPG models. The proposed methods have been
applied on different synthetic and real-world datasets of dif-
ferent complexity, which highlighted the strengths and weak-
In general, in most
nesses of the proposed methodologies.
simulated and real-world networks analysed in this work, the
AIP scores (4.3) based on standard ASE appear to consistently
achieve a very good link prediction performance in terms of
AUC scores.

Both simulations and applications on real data demon-
strated that adding temporal dynamics to the estimated link
probabilities via time series modelling is beneﬁcial for link

prediction purposes (cf. Sections 6.1, 6.2.4 and 6.3.4). On the
other hand, the time series extension is computationally ex-
pensive for most RDPG-based models, except the IPP scores
based on COSIE scores. The extensions provide signiﬁcant
beneﬁts only if the network presents a strong dynamic com-
ponent, as demonstrated in the simulation on the logistic dy-
namic network model in Section 6.1.2.

The application to the Santander bikes data (cf. Section 6.2)
highlighted that the random dot product graphs are an excel-
lent option for link prediction for fairly small graphs with-
out node or edge features.
In such cases, the simplicity of
RDPG-based models appears to overcome the advantages of
deep learning methods (cf. Section 6.2.2), which instead shine
when applied to large graphs with rich node and edge features
(for example, Hamilton et al., 2017). Furthermore, it must
be remarked that RDPG-based methods require minimal tun-

15

606570758085900.980.991tAUCaveragedadjacencymatrixpredictedadjacencymatrix606570758085900.920.940.96tAUCaveragedadjacencymatrixpredictedadjacencymatrix606570758085900.9850.990.9951tAUCAIPscores,standardASEPIPscores,standardASE606570758085900.920.940.96tAUCAIPscores,standardASEPIPscores,standardASE606570758085900.990.995tAUCIPAscores,COSIEIPPscores,COSIE606570758085900.90.920.94tAUCIPAscores,COSIEIPPscores,COSIELink prediction in dynamic networks using random dot product graphs

(a) Subsampling (1).

(a) Subsampling (1).

(b) Subsampling (2).

(b) Subsampling (2).

Figure 14: Results of the link prediction procedure on the Imperial
College NetFlow network. AUCs are calculated from 6.7
million links per graph.

Table 1: Results of the link prediction procedure on the DBLP co-
authorship network. AUCs are calculated from approxi-
mately 17 million links per graph.

(a) Subsampling (1).

Methodology

averaged adjacency matrix
AIP scores, standard ASE
IPA scores, standard ASE
IPA scores, COSIE
IPP scores, COSIE

2010

0.6912
0.7063
0.6637
0.6744
0.6893

Predicted graph
2012

2013

2011

0.6431
0.6685
0.6291
0.6378
0.6511

0.6095
0.6413
0.6066
0.6123
0.6252

0.5847
0.6235
0.5906
0.5955
0.6072

(b) Subsampling (2).

Methodology

averaged adjacency matrix
AIP scores, standard ASE
IPA scores, standard ASE
IPA scores, COSIE
IPP scores, COSIE

2010

0.6690
0.6765
0.6416
0.6502
0.6629

Predicted graph
2012

2013

2011

0.6202
0.6369
0.6058
0.6124
0.6234

0.5857
0.6083
0.5822
0.5862
0.5964

0.5598
0.5892
0.5653
0.5687
0.5773

2014

0.5777
0.6184
0.5856
0.5903
0.6020

2014

0.5508
0.5807
0.5577
0.5612
0.5690

ing (essentially, only the choice of the latent dimension d),
whereas alternative state-of-the-art models require computa-
tionally expensive hyperparameter tuning procedures.

Figure 15: IPA and IPP scores using COSIE embeddings on the Im-
perial College NetFlow network. AUCs are calculated
from 6.7 million links per graph.

The applications on the LANL, ICL and DBLP networks
(cf. Sections 6.3, 6.4 and 6.5) demonstrated that the method-
ologies of AIP and IPA scores are scalable to fairly large
graphs, and a good performance is achieved when the set of
nodes is stable over time. It has also been shown that the pro-
posed methodologies, in particular the AIP scores, are well
suited to streaming applications (cf. Section 6.3.3). The main
limitation of the proposed link prediction framework is its in-
ability to easily deal with new nodes appearing in the net-
work, as exempliﬁed by the application on the DBLP network
in Section 6.5.

7 Conclusion

In this paper, link prediction techniques based on random dot
product graphs have been presented, discussed and compared.
In particular, link prediction methods based on sequences of
embeddings, COSIE models, and omnibus embeddings have
been considered. Applications on simulated and real world
data have shown that one of the most common approaches
used in the literature, the decomposition of a collapsed adja-
cency matrix ˜A, is usually outperformed by other methods for
multiple graph inference in random dot product graphs.

Estimating link probabilities with the average of the inner

16

32343638404244460.940.960.98tAUC32343638404244460.880.90.92tAUCAIPscores,standardASEIPAscores,standardASEaveragedadjacencymatrixIPAscores,COSIE32343638404244460.960.970.980.99tAUCIPAscores,COSIEIPPscores,COSIE32343638404244460.880.90.92tAUCIPAscores,COSIEIPPscores,COSIELink prediction in dynamic networks using random dot product graphs

products from sequences of individual embeddings of differ-
ent snapshots of the graph has given the best performance in
terms of AUC scores across multiple datasets. This result
is particularly appealing for practical applications: calculat-
ing the individual ASEs is computationally inexpensive using
algorithms for large sparse matrices, and the method seems
particularly suitable for implementation in a streaming fash-
ion, since the average inner product could be easily updated
on the run when new snapshots of the graph are observed, as
demonstrated in Section 6.3.

The methods discussed in the article have then been fur-
ther extended to include temporal dynamics, using time se-
ries models. The extensions have shown improvements over
standard random dot product graph based link prediction tech-
niques, especially when the graph exhibits a strong dynamic
component. The techniques presented in this article could
also be readily extended to any embedding method for static
graphs, following the framework for calculating AIP and IPA
scores presented in Section 4, and the PIP and IPP extensions
in Section 5. Therefore, our methodology is not only appli-
cable to RDPG embeddings, particularly attractive for their
theoretical properties and ease of implementation, but also to
modern static embedding methods for graph adjacency matri-
ces, for example graph neural network techniques like GCN
or GraphSAGE. Overall, this article provides valuable guide-
lines for practitioners for using random dot product graphs as
tools for link prediction in networks, providing insights into
the predictive capability of such statistical network models.

References

Abu-El-Haija, S., Perozzi, B., Al-Rfou, R. and Alemi, A. A. (2018)
Watch your step: Learning node embeddings via graph attention.
In Advances in Neural Information Processing Systems, vol. 31.
Curran Associates, Inc.

Arroyo-Relión, J. D., Athreya, A., Cape, J., Chen, G., Priebe, C. E.
and Vogelstein, J. T. (2020) Inference for multiple heterogeneous
networks with a common invariant subspace. Journal of Machine
Learning Research.

Arroyo-Relión, J. D., Kessler, D., Levina, E. and Taylor, S. F. (2019)
Network classiﬁcation with applications to brain connectomics.
Annals of Applied Statistics, 13, 1648–1677.

Athreya, A., Fishkind, D. E., Tang, M., Priebe, C. E., Park, Y., Vo-
gelstein, J. T., Levin, K., Lyzinski, V., Qin, Y. and Sussman, D. L.
(2018) Statistical inference on random dot product graphs: a sur-
vey. Journal of Machine Learning Research, 18, 1–92.

Benjamin, M. A., Rigby, R. A. and Stasinopoulos, D. M. (2003)
Generalized autoregressive moving average models. Journal of
the American Statistical Association, 98, 214–223.

Brockwell, P. J. and Davis, R. A. (1987) Time Series: Theory and

Methods. Springer Series in Statistics. Springer-Verlag.

Cai, H., Zheng, V. W. and Chang, K. (2018) A comprehensive sur-
vey of graph embedding: Problems, techniques, and applications.
IEEE Transactions on Knowledge & Data Engineering, 30, 1616–
1637.

Charlin, L., Ranganath, R., McInerney, J. and Blei, D. M. (2015)
Dynamic Poisson factorization. In Proceedings of the 9th ACM
Conference on Recommender Systems, 155–162.

Chen, B., Li, F., Chen, S., Hu, R. and Chen, L. (2017) Link predic-
tion based on non-negative matrix factorization. PLOS ONE, 12,
1–18.

Chen, H. and Li, J. (2018) Exploiting structural and temporal evolu-
tion in dynamic link prediction. In Proceedings of the 27th ACM
International Conference on Information and Knowledge Man-
agement, 427–436.

CSIRO’s Data61 (2018) Stellargraph machine learning library.

https://github.com/stellargraph/stellargraph.

Deng, D., Shahabi, C., Demiryurek, U., Zhu, L., Yu, R. and Liu,
Y. (2016) Latent space model for road networks to predict time-
varying trafﬁc. In Proceedings of the 22nd ACM SIGKDD Inter-
national Conference on Knowledge Discovery and Data Mining,
1525–1534.

Dong, X., Frossard, P., Vandergheynst, P. and Nefedov, N. (2014)
Clustering on multi-layer graphs via subspace analysis on Grass-
IEEE Transactions on Signal Processing, 62,
mann manifolds.
905–918.

Dryden, I. L. and Mardia, K. V. (2016) Statistical Shape Analysis,

with Applications in R. John Wiley and Sons.

Dunlavy, D. M., Kolda, T. G. and Acar, E. (2011) Temporal link pre-
diction using matrix and tensor factorizations. ACM Transactions
on Knowledge Discovery from Data, 5.

Durante, D. and Dunson, D. B. (2014) Nonparametric Bayes dy-
namic modelling of relational data. Biometrika, 101, 883–898.

— (2018) Bayesian inference and testing of group differences in

brain networks. Bayesian Analysis, 13, 29–58.

Gama, J., Sebastião, R. and Rodrigues, P. P. (2013) On evaluating
stream learning algorithms. Machine Learning, 90, 317–346.

Gao, S., Denoyer, L. and Gallinari, P. (2011) Temporal link predic-
tion by integrating content and structure information. In Proceed-
ings of the 20th ACM International Conference on Information
and Knowledge Management, 1169–1174.

Ghashami, M., Liberty, E. and Phillips, J. M. (2016) Efﬁcient fre-
quent directions algorithm for sparse matrices. In Proceedings of
the 22nd ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining, 845–854.

Ginestet, C. E., Li, J., Balachandran, P., Rosenberg, S. and Kolaczyk,
E. D. (2017) Hypothesis testing for network data in functional
neuroimaging. Annals of Applied Statistics, 11, 725–750.

17

Link prediction in dynamic networks using random dot product graphs

Gower, J. C. (1975) Generalized Procrustes analysis. Psychometrika,

40, 33–51.

Goyal, P., Kamra, N., He, X. and Liu, Y. (2017) DynGEM: Deep
Embedding Method for Dynamic Graphs. In IJCAI International
Workshop on Representation Learning for Graphs.

Goyal, P., Rokka Chhetri, S. and Canedo, A. (2020) dyngraph2vec:
Capturing network dynamics using dynamic graph representation
learning. Knowledge-Based Systems, 187, 104816.

Goyal, P., Rokka Chhetri, S., Mehrabi, N., Ferrara, E. and Canedo,
A. (2018) DynamicGEM: A Library for Dynamic Graph Embed-
ding Methods. arXiv e-prints.

Grover, A. and Leskovec, J. (2016) node2vec: Scalable feature learn-
ing for networks. In Proceedings of the 22nd ACM SIGKDD Inter-
national Conference on Knowledge Discovery and Data Mining,
855–864.

Güne¸s, ˙I., Gündüz-Ö˘güdücü, ¸S. and Çataltepe, Z. (2016) Link pre-
diction using time series of neighborhood-based node similarity
scores. Data Mining and Knowledge Discovery, 30, 147–180.

Hamilton, W. L., Ying, R. and Leskovec, J. (2017) Inductive rep-
resentation learning on large graphs. In Proceedings of the 31st
International Conference on Neural Information Processing Sys-
tems, 1025–1035.

Hoff, P. D., Raftery, A. E. and Handcock, M. S. (2002) Latent space
approaches to social network analysis. Journal of the American
Statistical Association, 97, 1090–1098.

Holland, P. W., Laskey, K. B. and Leinhardt, S. (1983) Stochastic

blockmodels: First steps. Social Networks, 5, 109 – 137.

Hosseini, S. A., Khodadadi, A., Alizadeh, K., Arabzadeh, A., Fara-
jtabar, M., Zha, H. and Rabiee, H. R. (2020) Recurrent Poisson
IEEE Transactions
factorization for temporal recommendation.
on Knowledge and Data Engineering, 32, 121–134.

Hyndman, R. and Khandakar, Y. (2008) Automatic time series fore-
casting: The forecast package for R. Journal of Statistical Soft-
ware, Articles, 27, 1–22.

Ishiguro, K., Iwata, T., Ueda, N. and Tenenbaum, J. B. (2010) Dy-
namic inﬁnite relational model for time-varying relational data
analysis. In Advances in Neural Information Processing Systems
23, 919–927.

Jeske, D. R., Stevens, N. T., Tartakovsky, A. G. and Wilson, J. D.
(2018) Statistical methods for network surveillance. Applied
Stochastic Models in Business and Industry, 34, 425–445.

Jones, A. and Rubin-Delanchy, P. (2021) The multilayer random dot

product graph.

Kauppi, H. and Saikkonen, P. (2008) Predicting U.S. recessions with
dynamic binary response models. The Review of Economics and
Statistics, 90, 777–791.

Kazemi, S. M., Goel, R., Jain, K., Kobyzev, I., Sethi, A., Forsyth,
P. and Poupart, P. (2020) Representation learning for dynamic
graphs: A survey. Journal of Machine Learning Research, 21,
1–73.

Khosla, M., Setty, V. and Anand, A. (2021) A comparative study for
unsupervised network representation learning. IEEE Transactions
on Knowledge and Data Engineering, 33, 1807–1818.

Kim, Y. and Levina, E. (2019) Graph-aware modeling of brain con-

nectivity networks. arXiv e-prints.

Kingma, D. P. and Ba, J. (2015) Adam: a method for stochastic op-
timization. In 3rd International Conference on Learning Repre-
sentations, ICLR (eds. Y. Bengio and Y. LeCun). San Diego, CA,
USA.

Kintzel, U. (2005) Procrustes problems in ﬁnite dimensional indef-
inite scalar product spaces. Linear Algebra and its Applications,
402, 1–28.

Kipf, T. N. and Welling, M. (2017) Semi-supervised classiﬁcation
with graph convolutional networks. In 5th International Confer-
ence on Learning Representations, ICLR 2017, Conference Track
Proceedings.

Krivitsky, P. N. and Handcock, M. S. (2014) A separable model for
dynamic networks. Journal of the Royal Statistical Society: Series
B (Statistical Methodology), 76, 29–46.

Kumar, S., Zhang, X. and Leskovec, J. (2019) Predicting dynamic
embedding trajectory in temporal interaction networks. In Pro-
ceedings of the 25th ACM SIGKDD International Conference on
Knowledge Discovery & Data Mining, KDD ’19, 1269–1278.

Levin, K., Athreya, A., Tang, M., Lyzinski, V., Park, Y. and Priebe,
C. E. (2017) A central limit theorem for an omnibus embedding of
multiple random graphs and implications for multiscale network
inference. arXiv e-prints.

Li, X., Du, N., Li, H., Li, K., Gao, J. and Zhang, A. (2014) A deep
learning approach to link prediction in dynamic networks.
In
Proceedings of the 2014 SIAM International Conference on Data
Mining, 289–297.

Liben-Nowell, D. and Kleinberg, J. (2007) The link-prediction prob-
lem for social networks. Journal of the American Society for In-
formation Science and Technology, 58, 1019–1031.

Liu, Z., Zhou, D. and He, J. (2019) Towards explainable representa-
tion of time-evolving graphs via spatial-temporal graph attention
In Proceedings of the 28th ACM International Con-
networks.
ference on Information and Knowledge Management, CIKM ’19,
2137–2140.

Lü, L. and Zhou, T. (2011) Link prediction in complex networks:
A survey. Physica A: Statistical Mechanics and its Applications,
390, 1150 – 1170.

MacDonald, I. L. and Zucchini, W. (1997) Hidden Markov and Other

Models for Discrete-valued Time Series. Taylor & Francis.

18

Link prediction in dynamic networks using random dot product graphs

Menon, A. K. and Elkan, C. (2011) Link prediction via matrix fac-
In Machine Learning and Knowledge Discovery in

torization.
Databases: European Conference, 437–452. Springer.

Metelli, S. and Heard, N. A. (2019) On Bayesian new edge predic-
tion and anomaly detection in computer networks. Annals of Ap-
plied Statistics, 13, 2586–2610.

Neil, J., Hash, C., Brugh, A., Fisk, M. and Storlie, C. B. (2013) Scan
statistics for the online detection of locally anomalous subgraphs.
Technometrics, 55, 403–414.

Nguyen, G. H., Lee, J. B., Rossi, R. A., Ahmed, N. K., Koh, E.
and Kim, S. (2018) Continuous-time dynamic network embed-
In Companion Proceedings of the The Web Conference
dings.
2018, WWW ’18, 969–976.

Nielsen, A. M. and Witten, D. (2018) The multiple random dot prod-

uct graph model. arXiv e-prints.

Perozzi, B., Al-Rfou, R. and Skiena, S. (2014) Deepwalk: Online
In Proceedings of the 20th
learning of social representations.
ACM SIGKDD International Conference on Knowledge Discov-
ery and Data Mining, KDD ’14, 701–710.

Priebe, C. E., Park, Y., Tang, M., Athreya, A., Lyzinski, V., Vo-
gelstein, J. T., Qin, Y., Cocanougher, B., Eichler, K., Zlatic, M.
and Cardona, A. (2017) Semiparametric spectral modeling of the
drosophila connectome.

Qiu, J., Dong, Y., Ma, H., Li, J., Wang, K. and Tang, J. (2018)
Network embedding as matrix factorization: Unifying Deep-
Walk, LINE, PTE, and node2vec. In Proceedings of the Eleventh
ACM International Conference on Web Search and Data Mining,
WSDM ’18, 459–467. Association for Computing Machinery.

Qu, L., Zhu, H., Duan, Q. and Shi, Y. (2020) Continuous-time link
prediction via temporal dependent graph neural network. In Pro-
ceedings of The Web Conference 2020, WWW ’20, 3026–3032.

Rubin-Delanchy, P., Priebe, C. E., Tang, M. and Cape, J. (2017) A
the generalised

statistical interpretation of spectral embedding:
random dot product graph. arXiv e-prints.

Sankar, A., Wu, Y., Gou, L., Zhang, W. and Yang, H. (2020) DySAT:
Deep Neural Representation Learning on Dynamic Graphs via
Self-Attention Networks. In Proceedings of the 13th International
Conference on Web Search and Data Mining, 519–527.

Sarkar, P., Chakrabarti, D. and Jordan, M. (2014) Nonparametric link
prediction in large scale dynamic networks. Electronic Journal of
Statistics, 8, 2022–2065.

Sarkar, P. and Moore, A. W. (2006) Dynamic social network analysis
In Advances in Neural Information

using latent space models.
Processing Systems 18, 1145–1152.

Schein, A., Paisley, J., Blei, D. M. and Wallach, H. (2015) Bayesian
Poisson tensor factorization for inferring multilateral relations
from sparse dyadic event counts. In Proceedings of the 21th ACM
SIGKDD International Conference on Knowledge Discovery and
Data Mining, 1045–1054.

Scheinerman, E. R. and Tucker, K. (2010) Modeling graphs using
dot product representations. Computational Statistics, 25, 1–16.

Schönemann, P. H. (1966) A generalized solution of the orthogonal

Procrustes problem. Psychometrika, 31, 1–10.

Sewell, D. K. and Chen, Y. (2015) Latent space models for dynamic
networks. Journal of the American Statistical Association, 110,
1646–1657.

Sharan, U. and Neville, J. (2008) Temporal-relational classiﬁers for
prediction in evolving domains. In Proceedings of the 2008 Eighth
IEEE International Conference on Data Mining, 540–549.

Shiga, M. and Mamitsuka, H. (2012) A variational Bayesian frame-
work for clustering with multiple graphs. IEEE Transactions on
Knowledge and Data Engineering, 24, 577–590.

Tang, W., Lu, Z. and Dhillon, I. S. (2009) Clustering with multi-
ple graphs. In Proceedings of the 2009 Ninth IEEE International
Conference on Data Mining, ICDM ’09, 1016–1021. Washington,
DC, USA: IEEE Computer Society.

Turcotte, M. J. M., Kent, A. D. and Hash, C. (2018) Uniﬁed Host

and Network Data Set, chap. 1, 1–22. World Scientiﬁc.

Velickovic, P., Fedus, W., Hamilton, W. L., Liò, P., Bengio, Y. and
In 7th International
Hjelm, R. D. (2019) Deep graph infomax.
Conference on Learning Representations, ICLR 2019, New Or-
leans, LA, USA, May 6-9, 2019.

Wang, D., Cui, P. and Zhu, W. (2016) Structural deep network em-
bedding. In Proceedings of the 22nd ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining, KDD ’16,
1225–1234.

Wang, S., Arroyo, J., Vogelstein, J. T. and Priebe, C. E. (2021) Joint
embedding of graphs. IEEE Transactions on Pattern Analysis and
Machine Intelligence, 43, 1324–1336.

Xing, E. P., Fu, W. and Song, L. (2010) A state-space mixed mem-
bership blockmodel for dynamic network tomography. Annals of
Applied Statistics, 4, 535–566.

Xu, K. S. and Hero III, A. O. (2014) Dynamic stochastic blockmod-
els for time-evolving social networks. IEEE Journal of Selected
Topics in Signal Processing, 8, 552–562.

Yang, C., Priebe, C. E., Park, Y. and Marchette, D. J. (2021) Simulta-
neous Dimensionality and Complexity Model Selection for Spec-
tral Graph Clustering. Journal of Computational and Graphical
Statistics.

Young, S. J. and Scheinerman, E. R. (2007) Random dot product
graph models for social networks. In Algorithms and Models for
the Web-Graph, 138–149.

Yu, W., Aggarwal, C. C. and Wang, W. (2017a) Temporally fac-
torized network modeling for evolutionary network analysis. In
Proceedings of the Tenth ACM International Conference on Web
Search and Data Mining, 455–464.

19

Link prediction in dynamic networks using random dot product graphs

1. update the embeddings ˆXt, performing a standard Procrustes

superimposition of each ˆXj on ˜X:

ˆXj ← ˆXj ˜Uj ˜V(cid:62)
j ,

j

where ˆX(cid:62)

˜X = ˜Uj ˜Dj ˜V(cid:62)
j ;
2. update the reference embedding: ˜X = (cid:80)T
3. repeat steps 1 and 2 until the difference between two consecu-

ˆXt;

t=1

tive values of (A.2) is within a tolerance η.

The ﬁnal value of the reference embedding ˜X can be interpreted as
the average of rotations of the initial embeddings. The alignment
step increases the computational cost of the operations described in
Section 4 by a factor of (cid:79)(nd2), caused by the repeated SVD de-
compositions and matrix multiplications in the GPA algorithm.

When d− (cid:54)= 0 in the GRDPG setting, the problem is known as in-
deﬁnite Procrustes problem, and does not have closed form solution
(Kintzel, 2005). In this setting, the criterion (A.1) must be optimised
numerically for Ω ∈ O(d+, d−), the indeﬁnite orthogonal group
with signature (d+, d−). The optimisation routine could be applied
iteratively in the GPA algorithm to obtain an indeﬁnite GPA.

On the other hand, for directed and bipartite graphs, the criteria
(A.1) and (A.2) must be optimised jointly for the two embeddings
obtained using DASE in Deﬁnition 3. For two embeddings ( ˆX1, ˆY1)
and ( ˆX2, ˆY2) obtained from a directed graph, the solution is simply
given by aligning the stacked matrices [ ˆX(cid:62)
1 ](cid:62) ∈ R2n×r and
[ ˆX(cid:62)
2 ](cid:62) ∈ R2n×r using (A.1). The procedure could be also
iterated for more than two embeddings to obtain a joint generalised
Procrustes algorithm.

1 , ˆY(cid:62)

2 , ˆY(cid:62)

Yu, W., Cheng, W., Aggarwal, C. C., Chen, H. and Wang, W. (2017b)
Link prediction with spatial and temporal consistency in dynamic
networks. In Proceedings of the Twenty-Sixth International Joint
Conference on Artiﬁcial Intelligence, 3343–3349.

Zhang, Z., Cui, P. and Zhu, W. (2020) Deep learning on graphs: A
survey. IEEE Transactions on Knowledge and Data Engineering.

Zhou, D., Zheng, L., Han, J. and He, J. (2020) A data-driven graph
In Pro-
generative model for temporal interaction networks.
ceedings of the 26th ACM SIGKDD International Conference on
Knowledge Discovery & Data Mining, KDD ’20, 401–411.

Zhu, L., Guo, D., Yin, J., Steeg, G. V. and Galstyan, A. (2016) Scal-
able temporal latent space inference for link prediction in dynamic
social networks. IEEE Transactions on Knowledge and Data En-
gineering, 28, 2765–2777.

Zhu, M. and Ghodsi, A. (2006) Automatic dimensionality selection
from the scree plot via the use of proﬁle likelihood. Computa-
tional Statistics & Data Analysis, 51, 918 – 930.

A Generalised Procrustes alignment

of individual embeddings

As discussed in Section 4, for prediction of the future latent posi-
tions based on individual embeddings ˆX1, . . . , ˆXT , it is ﬁrst nec-
essary to align the embeddings. This section discusses a popular
method for aligning two matrices: Procrustes analysis (Dryden and
Mardia, 2016) and its generalisation to T matrices (Gower, 1975).
The alignment step is required because the latent positions Xt of a
single graph are not identiﬁable up to orthogonal transformations,
which leave the inner product unchanged: for an orthogonal ma-
t . Therefore ˆX1, . . . , ˆXT only
trix Ωt, (XtΩt)(XtΩt)(cid:62) = XtX(cid:62)
represent estimates of a rotation of the embeddings. Given two em-
beddings ˆX1, ˆX2 ∈ Rn×d, Procrustes analysis aims to ﬁnd the op-
timal rotation of ˆX2 on ˆX1. The following minimisation criterion is
utilised:

min
Ω

(cid:13)
ˆX1 − ˆX2Ω
(cid:13)
(cid:13)

(cid:13)
(cid:13)
(cid:13)F

,

(A.1)

where Ω is an orthogonal matrix, and (cid:107) · (cid:107)F denotes the Frobenius
norm. The solution of the minimisation problem has been derived
in Schönemann (1966), and is based on the SVD decomposition
ˆX(cid:62)
ˆX1 = ˜U ˜D ˜V(cid:62). The solution is Ω(cid:63) = ˜U ˜V(cid:62), and it follows
2
that the optimal rotation of ˆX2 onto ˆX1 is ˆX2 ˜U ˜V(cid:62).

Similarly, a set of T embeddings ˆXt ∈ Rn×r, t = 1, . . . , T
can be superimposed using generalised Procrustes analysis (GPA,
Gower, 1975), which uses the minimisation criterion:

min
Ωj

T
(cid:88)

j=1

(cid:13)
(cid:13)
(cid:13)

(cid:13)
2
ˆXjΩj − ˜X
(cid:13)
(cid:13)
F

s.t.

T
(cid:88)

j=1

S2( ˆXj) =

T
(cid:88)

j=1

S2( ˆXjΩj),

(A.2)
where, similarly to (A.1), Ωj are orthogonal matrices. Addition-
ally, ˜X ∈ Rn×r is a reference matrix, shared across the T matrices,
and S(·) is the centroid size S(M) = (cid:107)(In − 1
n )M(cid:107)F. The
GPA algorithm solves (A.2) by iterating standard Procrustes analy-
sis (Dryden and Mardia, 2016), after a suitable initialisation of the
reference matrix:

n 1n1(cid:62)

20

