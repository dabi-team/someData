IBRAHEM et al.: PRIVACY-PRESERVING ELECTRICITY THEFT DETECTION WITH DYNAMIC BILLING AND LOAD MONITORING FOR AMI NETWORKS

1

Efﬁcient Privacy-Preserving Electricity Theft
Detection with Dynamic Billing and
Load Monitoring for AMI Networks

Mohamed I. Ibrahem, Mahmoud Nabil, Mostafa M. Fouda, Senior Member, IEEE,
Mohamed Mahmoud, Member, IEEE, Waleed Alasmary, Senior Member, IEEE, and

Fawaz Alsolami, Member, IEEE

0
2
0
2

y
a
M
8
2

]

R
C
.
s
c
[

1
v
3
9
7
3
1
.
5
0
0
2
:
v
i
X
r
a

Abstract—In advanced metering infrastructure (AMI), smart
meters (SMs) are installed at the consumer side to send ﬁne-
grained power consumption readings periodically to the system
operator (SO) for load monitoring, energy management, billing,
etc. However, fraudulent consumers launch electricity theft cyber-
attacks by reporting false readings to reduce their bills illegally.
These attacks do not only cause ﬁnancial losses but may also
degrade the grid performance because the readings are used
for grid management. To identify these attackers, the existing
schemes employ machine-learning models using the consumers
ﬁne-grained readings, which violates the consumers privacy by
revealing their lifestyle. In this paper, we propose an efﬁcient
scheme that enables the SO to detect electricity theft, compute
bills, and monitor load while preserving the consumers privacy.
The idea is that SMs encrypt their readings using functional
encryption, and the SO uses the ciphertexts to (i) compute
the bills following dynamic pricing approach, (ii) monitor the
grid load, and (iii) evaluate a machine-learning model to detect
fraudulent consumers, without being able to learn the individual
readings to preserve consumers privacy. We adapted a functional
encryption scheme so that the encrypted readings are aggregated
for billing and load monitoring and only the aggregated value
is revealed to the SO. Also, we exploited the inner-product
operations on encrypted readings to evaluate a machine-learning
model to detect fraudulent consumers. Real dataset is used
to evaluate our scheme, and our evaluations indicate that our
scheme is secure and can detect fraudulent consumers accurately
with low communication and computation overhead.

Index Terms—Electricity theft detection, privacy preservation,

machine learning, functional encryption, dynamic billing.

I. INTRODUCTION

S MART grid (SG) is an advanced upgrade to the traditional

power grid that aims to facilitate reliable delivery of
electricity, optimize grid operation, and engage consumers [1].
Fig. 1 illustrates the model structure of the SG, which com-
prises of advanced metering infrastructure (AMI) network,

Corresponding author: Mohamed I. Ibrahem.
M. I. Ibrahem, and M. Mahmoud are with the Department of Electrical and
Computer Engineering, Tennessee Tech. University, Cookeville, TN 38505
USA (e-mail: miibrahem42@students.tntech.edu; mmahmoud@tntech.edu).

M. Nabil is with the Department of Electrical and Computer Engineering,
North Carolina A and T University, USA (e-mail: mnmahmoud@ncat.edu).
M. M. Fouda is with the Department of Electrical and Computer Engi-
neering, Tennessee Tech. University, Cookeville, TN 38505 USA, and the
Department of Electrical Engineering, Faculty of Engineering at Shoubra,
Benha University, Egypt (e-mail: mfouda@ieee.org).

W. Alasmary is with the Department of Computer Engineering, Umm Al-

Qura University, Saudi Arabia (e-mail: wsasmary@uqu.edu.sa).

F. Alsolami is with the Department of Computer Science, King Abdulaziz

University, Saudi Arabia (e-mail: falsolami1@kau.edu.sa).

electricity generation sources, transmission and distribution
systems, and a system operator (SO). AMI enables the bi-
directional communication between the smart meters (SMs),
which are deployed at consumer premises, and SO for regular
load monitoring, energy managment, and billing [2]. Unlike
the traditional power grid that collects the power consumption
readings monthly, AMI network collects ﬁne-grained power
consumption readings (every few minutes) measured/sent by
SMs. Then, these readings are forwarded to the SO for mon-
itoring the load, controlling the energy supply efﬁciently, and
calculating the consumers’ bills. These bills follow dynamic
pricing approach in which the tarrif of electricity consumption
changes through the day to stimulate consumers to reduce
consumption during peak hours [3].

In SG, electricity theft attacks can be launched by fraudulent
consumers who tamper with their SMs so that they report
lower consumption readings to reduce energy bill illegally.
This deceptive behaviour does not only cause ﬁnancial losses,
but also the false readings used for load monitoring may affect
the decisions made by the SO regarding grid management,
which may cause the instability of the grid or blackout in
severe cases [4]. Electricity theft is a serious problem in the
existing power grid that causes hefty ﬁnancial losses. For
instance, the United States loses about $6 billion annually due
to electricity thefts [5]. The losses in developing countries also
have extremely bad consequences. For example, India suffers
from about $17 billion losses every year because of electricity
theft [6].

In order to identify the fraudulent consumers, machine
learning-based models, which are trained on ﬁne-grained
power consumption readings, have been proposed [6]–[8].
However, revealing the consumers’ ﬁne-grained power con-
sumption readings to the SO for electricity theft detection, load
monitoring, and billing creates a serious privacy problem. This
is because the ﬁne-grained readings expose the consumers’ life
habits, whether they are at home or on-leave, number of people
at home, the appliances they are using, etc [9]. This may result
in criminal activities, e.g., thieves can break into homes when
consumers are absent [8]. On the other side, these private data
may be sold to insurance companies to adapt their plans based
on the consumers’ activities. In summary, the research problem
we address in this paper is how to enable the SO to monitor
load, compute bills, and detect fraudulent consumers without
learning the ﬁne-grained power consumption readings of the
consumers to preserve their privacy.

 
 
 
 
 
 
IBRAHEM et al.: PRIVACY-PRESERVING ELECTRICITY THEFT DETECTION WITH DYNAMIC BILLING AND LOAD MONITORING FOR AMI NETWORKS

2

Fig. 1: Smart grid conceptual architecture.

In the literature, the proposed scheme in [10] “PPETD”
tried to address this research problem. It uses secret sharing
technique to allow sending the ﬁne-grained power consump-
tion readings in a masked manner in such a way that the
SO can obtain the aggregated readings for billing and load
monitoring without being able to learn the individual readings
to preserve consumer privacy. It also employs a convolutional
neural network (CNN) machine learning model based on
secure multi-party computation protocols using arithmetic and
binary circuits. These protocols are executed interactively by
the SO and each SM to evaluate the CNN model on the
reported masked ﬁne-grained power consumption readings
learning the readings to preserve the consumers’
without
privacy. However,
this scheme suffers from the following
issues.

1) The computation and communication overheads are im-
time needed for the CNN
practically high. The total
model evaluation using masked readings is around 48
minutes and the amount of exchanged data is 1900 MB.
This may be impractical for SMs because cost-effective
devices tend to have limited computation capability and
low bandwidth communication. Moreover, this evalua-
tion is done in an online and interactive communication
session between each SM and the SO. Obviously, the
requirement of a long session between each SM and the
SO and exchanging much amount of data is not practical,
scalable, or even cost-effective given that cellular com-
munication may be used to enable the communications
between the SMs and SO.

2) There is a trade-off between the accuracy of the model
and overhead due to the approximation done for a non-
linear function (sigmoid function).

3) The classiﬁcation of the model is known to both SM and
SO, which is supposed to be known only to the SO. By
knowing the classiﬁcation of the model, the fraudulent

consumer can return the original software to the SM
before the SO sends technicians to inspect it to avoid
liability.

Therefore, in this paper, we address these limitations by
proposing a privacy-preserving and efﬁcient electricity theft
detection scheme enabling dynamic billing and load mon-
itoring using functional encryption (FE), named “ETDFE”.
The idea is that the SMs encrypt their ﬁne-grained readings
using functional encryption scheme and send the ciphertexts to
the SO. We adapted the functional encryption scheme [11] to
enable aggregating the SMs’ encrypted readings, and revealing
only the aggregated readings to the SO for billing and load
monitoring without being able to learn the individual readings
to preserve consumers’ privacy. Furthermore, we train a deep
learning-based electricity theft detection model and leverage
the inner product operations on encrypted data supported by
the FE to evaluate the model using the encrypted ﬁne-grained
readings without revealing the readings to the SO to preserve
privacy.

Using real dataset, we evaluated the performance of our
electricity theft detection model. We also analyzed the security
of our scheme and measured the communication and compu-
tation overhead. Our evaluations conﬁrm that our scheme is
secure and can detect electricity thefts accurately with much
less communication and computation overhead comparing
to the scheme proposed in [10]. Speciﬁcally, our scheme
can signiﬁcantly reduce the computation and communication
overheads. Moreover, unlike [10], our proposed scheme does
not need both SMs and the SO to involve in online/interactive
session to evaluate the electricity theft detection model.

The remainder of this paper is organized as follows. Sec-
tion II discusses the related works. Then, our system models
and design objectives are discussed in section III. Section IV
illustrates the preliminaries used in our work. Our envisioned
ETDFE scheme is presented in section V. Next, The perfor-

Power Generation  Renewable  Energy    Non-Renewable Energy  AMI Network       System Operator Transmission Distribution IAN HAN BAN HAN: Home Area Network BAN: Building Area Network IAN: Industrial Area Network SM: Smart Meter SM SM SM Power Flow                     Information Flow IBRAHEM et al.: PRIVACY-PRESERVING ELECTRICITY THEFT DETECTION WITH DYNAMIC BILLING AND LOAD MONITORING FOR AMI NETWORKS

3

mance evaluation and security analysis of our scheme are
discussed in sections VI and VII, respectively. Finally, the
paper is concluded in section VIII.

II. RELATED WORK

A few works in the literature have tried to address privacy-
preserving electricity theft detection in SG [10], [12]–[15].
Some schemes are based on machine learning techniques [10],
[13], while others use different techniques [12], [14], [15].

The work done by Salinas et. al. [12], [14] have attempted
to investigate the privacy issue in detecting electricity theft.
They proposed three distributed peer-to-peer (P2P) comput-
ing algorithms based on lowerupper decomposition (LUD)
to preserve privacy. Such algorithms solve linear system of
equations (LSE) for the consumers’ “honesty coefﬁcients” to
detect fraudulent consumers who commit energy theft. After
a mutual communication between the SMs to solve LSE, the
SO receives the honesty coefﬁcient from each SM. If the
honesty coefﬁcient is equal to one, this consumer is honest,
otherwise, the consumer reported less power consumption.
Although this scheme can successfully identify all the energy
thieves in a small size network, it may be unstable in large
networks due to the rounding errors in LU decomposition. In
addition, the scheme fails if the SMs tamper with the messages
sent to other parties. Furthermore, the power line losses are
assumed to be known, which are difﬁcult to acquire practically.
Besides, this scheme takes into consideration only one type of
attack in which the fraudulent consumers reduce their power
consumption reading with constant reduction rates, where the
real consumption readings are multiplied by a constant number
that is less than one. However, there are many other energy
theft scenarios, such as by-pass ﬁlters [6]. Finally, the scheme
does not consider load monitoring and dynamic billing.

The electricity theft detection scheme presented in [15]
considers consumers’ privacy by using Kalman ﬁlter-based
P2P state estimation protocol to ﬁnd the line currents and
biases of the consumers. The main idea of this scheme is to use
state estimation techniques by the SO to identify the fraudulent
consumers after receiving estimations of line segment currents
and biases from all SMs. The SMs with biases larger than a
predeﬁned threshold are considered fraudulent. The privacy of
this scheme is guaranteed by employing a distributed kalman
ﬁlter, where the SO does not need to access the consumers’
power consumption readings. However, this work signiﬁcantly
varies from ours in three perspectives. First, we use a machine
learning model to determine electricity thefts, which usually
performs better than state estimation approaches [6]. Second,
the proposed state estimator is based on a set of distributed
algorithms executed by SMs, and hence, the scheme may fail
if SMs tamper with the messages sent to other peers. Last, our
scheme enables dynamic billing and load monitoring, which
are not considered in [15].

Machine learning-based models have been proposed in [10],
[13] to identify electricity thefts. A CNN model is used in
[13] to detect fraudulent consumers. In this scheme, SMs send
their encrypted electricity consumption readings to two system
entities. One entity, which is assumed to be fully trusted,

is responsible for running a CNN model (i.e., electricity
theft detector) after decrypting the consumer’s ﬁne-grained
readings, and then reports the output of the model to the
SO. Another entity, which is assumed distrusted, aggregates
the consumers’ encrypted power consumption readings in a
certain residential area to obtain the aggregated reading for
load monitoring without being able to learn the individual
readings to preserve privacy. Practically, it is difﬁcult to ensure
that an entity would not abuse consumers’ information; in
addition, this scheme cannot support dynamic billing.

Nabil et. al. [10] have proposed a privacy-preserving scheme
that enables the SO to detect fraudulent consumers, who steal
electricity, by developing a CNN machine learning model
based on secure multi-party computation protocols using arith-
metic and binary circuits. These protocols are executed by the
SO and each SM in an online/interactive session to evaluate
the CNN model using the reported masked ﬁne-grained power
consumption readings. The proposed scheme uses also secret
sharing technique to share secrets allowing SMs to send
masked readings to the SO such that these readings can be
aggregated for the purpose of monitoring and billing. The
scheme also enables billing using dynamic pricing rates in
which the tariff of the electricity changes during the day to
stimulate consumers to not use electricity in peak hours to
reduce the demand. However, the scheme suffers from the
following drawbacks.

1) The proposed scheme requires high computation and
communication overhead. The SMs and SO should run
a machine learning model in an interactive way (i.e.,
online) to maintain the consumers’ privacy while allowing
the SO to detect whether a consumer is honest or fraud-
ulent. Furthermore, to evaluate the model for a single
SM, the total time needed is around 48 minutes and
the amount of exchanged data is 1900 MB. The scheme
also requires another overhead for running a technique
to share the secrets needed to mask the readings. This
large computation and communication overheads are im-
practical for SMs because cost-effective devices tend to
have limited computation capability and low bandwidth
communications.

2) A non-linear function (sigmoid) is used in the model and
in order to evaluate the function on masked readings, it
is approximated as a linear function. This creates a trade-
off between the accuracy of the model and overhead, i.e.,
the better the approximation, the better the accuracy but
with more overhead.

3) The classiﬁcation of the model is known to both SM and
SO, which is supposed to be known only to the SO. By
knowing the classiﬁcation of the model, the fraudulent
consumer can return the original software to the SM
before the SO sends technicians to inspect it to avoid
liability.

III. SYSTEM MODELS AND DESIGN OBJECTIVES

This section discusses the considered network and threat

models as well as the design objectives of our scheme.

IBRAHEM et al.: PRIVACY-PRESERVING ELECTRICITY THEFT DETECTION WITH DYNAMIC BILLING AND LOAD MONITORING FOR AMI NETWORKS

4

Fig. 2: Network Model.

A. Network Model

As shown in Fig. 2, our considered network model includes
the consumer-side (smart meters), system operator-side, and an
ofﬂine key distribution center (KDC). The role of each entity
is described below.

• Smart Meter (SM): The consumer has smart appliances
at his/her home which are connected to the SM. Each
SM sends its ﬁne-grained power consumption readings
periodically (e.g., every 30 minutes) to the SO. A set
of SMs, SM = {SMi, 1 ≤ i ≤ |SM|}, form an AMI
network. The SMs can communicate directly with the SO
or they can communicate with the SO via a gateway. In
the latter case, the SMs may communicate directly with
the gateway, or multi-hop data transmission is used to
connect the SMs to the gateway, where some SMs may
act as routers to relay other SMs’ data.

• System Operator (SO): The SO uses the ﬁne-grained
power consumption readings sent by SMs for load mon-
itoring and energy management. Moreover, the SO uses
these readings to evaluate a neural network model to
detect electricity thefts and compute the bill for each
consumer following dynamic pricing approach in which
the electricity price increases at peak hours to stimulate
consumers to reduce demand in these hours.

• Key Distribution Center (KDC): It distributes the pub-
lic parameters in addition to the private keys, i.e., the
encryption and functional decryption keys for both SMs
and SO, respectively. KDC can be operated by a national
authority such as the Department of Energy.

B. Threat Model

The SO may attempt to use the consumers’ ﬁne-grained
power consumption readings to learn sensitive information
including the consumers’ activities, e.g., learning whether a

consumer is at home or on-leave, and so forth. For consumers,
they may conduct the following misbehaviour. First, they may
send to the SO false (low) power consumption readings to
reduce their bills illegally, which does not only cause ﬁnancial
losses but it may also result in wrong decisions regarding
energy management. Second, the consumers may be inter-
ested in learning the ﬁne-grained power consumption of other
consumers to infer sensitive information about the lifestyle
of the consumers. Regarding collusion, the SO may collude
with consumer(s) to infer the readings of other consumers,
but the number of colluding consumers should be fewer than
or equal (n − 1), where n is the number of SMs. Moreover,
some consumers may collude with others to infer sensitive
information.

Basically, the objective of this paper is to preserve the
consumers’ privacy while using their ﬁne-grained power con-
sumption readings for load management, billing, and theft
detection, i.e., no one including the SO should be able to learn
the ﬁne-grained readings of individual consumers.

C. Design Objectives

Our scheme should achieve the following functionality and

security requirements:

1) Functionality Requirements:
(F1) In an AMI network, ETDFE should enable the SO
to obtain the total electricity consumption of the con-
sumers at each reporting period for load monitoring
and energy management.

(F2) Regarding billing, ETDFE should allow the SO to
compute each consumer’s electricity bill efﬁciently
following dynamic pricing.

(F3) ETDFE should allow the SO to run an electricity theft
detector for each consumer using his/her ﬁne-grained
power consumption readings to detect whether this
consumer is fraudulent or not.

2 Billing (dynamic pricing) Power consumption readings Encrypted readings Consumer side System operator Smart meter Load monitoring Electricity theft detector Key Distribution Center (KDC) One-time transmission Frequent transmissions Secret keys y dky : Functional decryption key y: A vector used in inner product operation dky IBRAHEM et al.: PRIVACY-PRESERVING ELECTRICITY THEFT DETECTION WITH DYNAMIC BILLING AND LOAD MONITORING FOR AMI NETWORKS

5

2) Security and Privacy Requirements:
(S1) Our electricity theft detector should be secure against
any misbehaviour from fraudulent consumers who
aim at stealing energy without being detected.
(S2) Preserving consumers’ privacy: No entity (including
the SO) should learn the ﬁne-grained power consump-
tion readings of individual consumers at any reporting
period.

(S3) Conﬁdentiality of AMI’s total power consumption
and consumers’ bills: SO should be the only entity
that learns the total power consumption of all con-
sumers in an AMI for load monitoring and the billing
amount of each consumer as well.

IV. PRELIMINARIES

A. Functional Encryption

Functional encryption (FE) is a new cryptosystem that al-
lows the encryptor to encrypt a message x using an encryption
key, and enables the decryptor to perform computations on the
encrypted message to learn the output of a predeﬁned function
f (x) using a functional decryption key without being able to
learn the message x itself [16]. Recently, the focus on FE has
been increasing, especially how to design efﬁcient schemes for
limited classes of functions or polynomials, such as linear [17],
[18] or quadratic [19]. In this paper, we focus on the inner
product functional encryption (IPFE) that allows to perform
inner product operation over encrypted vector. In an IPFE
scheme, given the encryption of a vector x, and a functional
decryption key associated with a vector y, one can obtain only
the dot product result (x · y) by decrypting the encryption of
x and without being able to learn x. IPFE consists of three
parties as follows.

• Key Distribution Center (KDC): This generates the en-
cryption and functional decryption keys for both the
encryptor and decryptor, respectively.

• Encryptor: It encrypts the plaintext vector x using the
encryption key and sends the ciphertext to the decryptor.
• Decryptor: It receives a functional decryption key dky
from the KDC, which is associated with a vector y, and
evaluates the dot product on the encrypted vector received
from the encryptor. It has access only to the result of that
dot product evaluation (x · y), and of course, it must not
collude with KDC.

B. Feed-Forward Neural Networks (FFNs)

FFNs are widely used in solving many challenging ma-
chine learning problems such as system identiﬁcation of a
biochemical process [20], face recognition system [21], and
age identiﬁcation from voice [22]. This wide adoption of FNNs
is due to their high accuracy. FFNs are called feed-forward
because the information only travels forward in the neural
network, from the input nodes and through the hidden layer(s)
(single or many layers) and ﬁnally through the output nodes.
They are also called deep networks, multi-layer perceptron
(MLP), or simply neural networks [23].

Fig. 3 shows a typical architecture of an FFN that consists

of:

Fig. 3: Typical architecture of a feed forward neural network
(FFN).

• Input Layer: This is the ﬁrst layer of a neural network.
It consists of nodes, called neurons, that receive input
data and pass them to the following layers. The number
of neurons in the input layer is equal to the number of
attributes or features of the input data.

• Output Layer: This is the last

layer which gives the
prediction (or classiﬁcation) of the model. The activation
function used in this layer depends on the problem. For
example, in a binary classiﬁer, the output is either 0
or 1, and thus, a sigmoid activation function is usually
used, while for a multi-class classiﬁer, a softmax function
is commonly used. On the other hand, for a regression
problem, where the output is not a predeﬁned category,
we can simply use a linear activation function.

• Hidden Layers: Between the input and output layers, there
are hidden layer(s) that depend on the type of the model,
e.g., the hidden layers of a CNN model typically consist
of convolutional layers, pooling layers, etc. Hidden layers
contain a vast number of neurons which apply transfor-
mations to the inputs before passing them. Every neuron
in a layer is connected to all the neurons in the previous
layer, and each connection may have a different strength
or weight. When the network is trained, the weights are
computed and updated in the direction of improving the
model accuracy. By having multiple hidden layers, we
can compute complex functions by cascading simpler
functions. The number of hidden layers is termed as the
depth of the neural network.

For a given neuron, the inputs are multiplied by the weights
and summed together. This value is referred to as the summed
activation of the neuron. The summed activation is then
transformed via an activation function and deﬁnes the speciﬁc
output or activation of that neuron.

In this paper, we use the FFN to solve a binary classiﬁcation
problem, i.e., to detect whether the consumer is honest or
fraudulent. In machine learning, classiﬁcation is a type of
supervised learning method, where the task is to divide the
data samples into predeﬁned groups by a decision function. In
the following, we discuss the training process of an FFN and
the widely used activation functions.

1) FFN Training: The features/input data is fed into the
ﬁrst layer of a neural network (i.e., input layer). Then, these
features are gradually mapped to higher-level abstractions via
the iterative update (a.k.a, feed-forward and back-propagation)

Input layerOutput layerHidden layersIBRAHEM et al.: PRIVACY-PRESERVING ELECTRICITY THEFT DETECTION WITH DYNAMIC BILLING AND LOAD MONITORING FOR AMI NETWORKS

6

in the hidden layers of the neural network for a predeﬁned
number of iterations. These mapping abstractions, known as
learned neural network model, can be used to predict the label
in the output layer.

The training of such a network is quite complicated, when
there exists an output error because it is hard to know how
much error comes from the neurons and how to adjust the
weights and biases [24]. Thus, the FNN training involves
adjusting the weight and the bias parameters Θ by deﬁning
a cost function and selecting an optimizer. The problem can
only be solved by ﬁnding the effect of all the weights in the
network. This is done by the back-propagation algorithm [24]
in which the FNN weights are updated using the gradients of
the cost function with respect to the neural network’s weights.
In an FFN, the output values are compared with the correct
prediction for optimizing the cost function. Then, the error
is fed back through the network to adjust the weights of each
connection in order to reduce the cost (loss) function [24]. For
the cost function, categorical cross-entropy C(y, ˆy) is deﬁned
to measure the loss due to the difference of two distributions,
true distribution y and learned distribution ˆy, for M classes
as follows:

C(y, ˆy) = min

(−

Θ

M
(cid:88)

c=1

y(c) log(ˆy(c))).

During training, an optimization method, e.g., ADAM [25],
is used for optimizing the cost function. Supervised labeled
data are used to train the neural network. In addition, hyper-
parameters of the neural network such as the number of
neurons in each layer,
type of the
optimizer, etc., can be determined using hyperopt python
library [26], k-fold cross validation, or any other validation
method [27].

the number of layers,

2) Activation Functions: In a neural network, the activation
function is responsible for transforming the summed weighted
input from the neuron into the activation of that neuron. In the
following, we explain some common activation functions and
their usage.

• Rectiﬁed Linear Unit (ReLU): It allows positive values
to pass through it, and maps negative values to zero. The
main advantage of ReLU is the computational simplicity
because it only requires a simple max() function as
follows [28].

ReLU (x) = max(0, x).

Unlike the tanh and sigmoid activation functions that use
exponential operations, ReLU mostly acts like a linear
activation function, and it is usually easier to optimize
the neural network when its behavior is linear or close to
linear.

• Softmax: It is often used in the output layer for multi-class
classiﬁcation problems. Softmax outputs a probability
vector for a given input vector, i.e., for an input vector
z = [z[1], . . . , z[M ]] ∈ RM of length M , where M is
the number of classes, the softmax function is deﬁned as
follows [28].

(cid:80)M

Sof tmax(z[i]) =

f or i = {1, . . . , M }.

ez[i]
j=1 ez[j]
V. PROPOSED SCHEME
In this section, we ﬁrst give an overview for the proposed
ETDFE and then discuss system initialization, how SMs report
their power consumption readings, and how the SO computes
the aggregated readings for load monitoring. Next, we explain
how the electricity bills are computed following dynamic
pricing approach. Finally, we explain the way we train a
machine learning model for electricity theft detection and
discuss how the SO can use the SMs’ encrypted readings to
evaluate the model to detect electricity theft without learning
the readings to preserve the consumers’ privacy.

A. Overview

The main phases of our scheme can be summarized as

follows.

• Using an FE scheme, each SMi ∈ SM sends its en-
crypted readings periodically to the SO using the secret
key si every time slot Tt as shown in Fig. 4.

• At every time slot Tt, the SO receives all encrypted
readings from all SMs and uses the monitoring functional
decryption key dkm to obtain the aggregated reading of
SMs in an AMI network for load monitoring without
being able to learn the individual readings to preserve
consumers’ privacy.

• Regarding billing, as shown in Fig. 4, after receiv-
ing b encrypted readings from each SM (which repre-
the readings per billing period TB , where TB =
sent
{T1 , T2 , . . . , Tb}), the SO applies dynamic pricing on
these readings to compute the bill for each consumer i
using the billing functional decryption key DKbi without
learning the individual readings to preserve privacy.
• After receiving d encrypted readings from the SMs, the
SO uses the functional decryption key DKdi of each SMi
to evaluate an electricity theft machine learning model
to detect whether this consumer is honest or fraudulent
without learning the readings to preserve privacy.
For better readability, we deﬁne the main notations used in
this section in Table I.

B. System Initialization

In system initialization1, the KDC2 should compute and
distribute the following: (1) Public parameters; (2) SMs’
encryption keys; and (3) SO’s functional decryption keys.

1) Public Parameters: To generate the public parameters,

the KDC should:

• generate { G, q, P } where G is a cyclic additive group

of prime order q and generator P .

• choose H, where H is a full-domain hash function onto

G2, i.e., H : {0, 1}∗ → G2.

Then, the public parameters { G, q, P, H} are published.

1We use the standard lowercase notation for elements in Zq and uppercase

notation for elements in G.

2KDC is needed only to bootstrap the system by distributing the necessary

keys. After that, the system is run without involving it

IBRAHEM et al.: PRIVACY-PRESERVING ELECTRICITY THEFT DETECTION WITH DYNAMIC BILLING AND LOAD MONITORING FOR AMI NETWORKS

7

i) Generating dkm: A vector of ones, y1, with a length
that equals to the number of SMs in an AMI network, is
used by the KDC to compute the monitoring functional
decryption key dkm. This key is sent to the SO such that
it can aggregate all the power consumption readings from
all SMs at each time slot Tt. This vector of ones is used so
that when inner product is done with the SMs’ readings,
the aggregated reading is obtained. The generation of
dkm key is as follows.
• The KDC performs the following operation to compute
the monitoring functional decryption key using the
SMs’ secret keys and y1:

dkm =

|SM|
(cid:88)

i=1

siy1[i] =

|SM|
(cid:88)

i=1

si ∈ Z2
q,

where y1[i] is the ith element in y1. Then the KDC
sends the dkm to the SO.

ii) Generating DKb: The SO sends a vector y2, with a
length b, to the KDC, where b is the number of readings
per billing period TB as shown in Fig. 4. This vector
represents the pricing rates the SO sets and it is used
for billing following dynamic pricing approach, i.e., each
element in y2 is the electricity rate for one consumption
time slot. This allows the SO to compute the inner product
operation between y2 and the power consumption of each
consumer at different time slots. Using y2, the KDC
generates a billing functional decryption key for each
SMi for each billing period as follows.
• The KDC calculates the following operations for each
SMi using the SMi’s secret key, y2, and a set of time
slot identiﬁers {(cid:96)1, (cid:96)2, . . . , (cid:96)b}, as follows:

U(cid:96)t = H((cid:96)t) ∈ G2, 1 ≤ t ≤ b.

DKbi =

b
(cid:88)

t=1

y2[t](s(cid:62)
i

· U(cid:96)t) ∈ G,

where (·) is the inner/dot product operation between
two vectors, and s(cid:62)
i

is the transpose of si.

• Next, the KDC sends the |SM| billing functional de-
cryption keys DKbi to the SO, where {1 ≤ i ≤ |SM|}
and |SM| is the number of SMs.

iii) Generating DKd: Regarding the evaluation of electricity
theft detection model at the SO-side, the SO sends the
layer’s weights of the model (W ) to the KDC.
ﬁrst
Supposing that W ’s dimension is d rows × n columns,
where d is the number of readings per electricity theft
detection period TD ={T1 , T2 , . . . , Td }, while n is the
number of neurons in the ﬁrst hidden layer in the model.
Then, W can be represented as:

W =









w1[1] w2[1]
w1[2] w2[2]

.
.

.
.

w1[d] w2[d]

. . . wn[1]
. . . wn[2]
. . .
. . .
. . . wn[d]

.
.









,

(1)

Fig. 4: Monitoring, billing, and electricity theft detection
intervals.

TABLE I: Main notations.

Notation

Description

SMi
TB

TD

ri[t]

ri

Ci[t]

ct

si
(cid:96)t
b

d

cB
i

cD
i

n

v

hi
G, q, P
H : {0, 1}∗ → G2

dkm, DKb, DKd

y1, y2

W

i-th smart meter

Reporting period used for billing

Reporting period used for electricity
theft detection
Consumption reading of SMi at time slot Tt
Input (power consumption readings) of the
SMi over TD
encrypted reading of SMi at time slot Tt
Encrypted consumption report vector from
all SMs, ct = [C1[t], C2[t], . . . , C|SM|[t]]
Secret key of SMi
Time slot identiﬁer

Number of readings per billing period

Number of readings per electricity
theft detection period
Encrypted consumption report vector of SMi
over billing period TB
Encrypted consumption report vector of SMi
over electricity theft detection period TD
Number of neurons in the ﬁrst hidden layer

Bias vector of size n for the ﬁrst hidden layer
v = [v[1], v[2], . . . , v[n]]

i-th hidden layer

Public parameters for the functional encryption
Full-domain hash function onto G2
Functional decryption keys for monitoring,
billing, and electricity theft detection

Vectors corresponding to monitoring and billing

Weights of the ﬁrst hidden layer
corresponding to electricity theft detection

(x · y)

Inner/dot product between vectors x and y

2) Smart Meters’ Encryption Keys: KDC generates SMs’
encryption keys: si ∈ Z2
q, where si is the secret key of SMi,
for 1 ≤ i ≤ |SM|, and |SM| denotes the number of SMs in
an AMI network.

3) SO’s Functional Decryption Keys: dkm, DKb, and
DKd are the functional decryption keys set used for monitor-
ing, billing, and electricity theft detection, respectively. The
KDC generates these functional decryption keys as follows.

Billing Monitoring Electricity theft detection |𝕊𝕄|  TB        Time SMi T1 T2 …  Tb … Td SM1 SM2 . . SM|𝕊𝕄| TD IBRAHEM et al.: PRIVACY-PRESERVING ELECTRICITY THEFT DETECTION WITH DYNAMIC BILLING AND LOAD MONITORING FOR AMI NETWORKS

8

1 , w(cid:62)

2 , . . . , w(cid:62)

where W is a 2-dimensional array and can be represented
as W = [w(cid:62)
n ], wi is the ith column of
W , wi = [wi[1], wi[2], . . . , wi[d]](cid:62) and wi ∈ Zd
q.
Therefore, the KDC generates n functional decryption
keys corresponding to each column of W . In our solution,
W is the same for all SMs, i.e., the SO applies a general
model to all SMs. Next, the KDC calculates the electricity
theft detection functional decryption keys for each SM for
each electricity theft detection period as follows.
• For each SMi, the KDC performs the following op-
eration using the SMi’s secret key, a set of time slot
identiﬁers {(cid:96)1, (cid:96)2, . . . , (cid:96)d}, and each column j of W ,
where j = {1, . . . , n}:

• Next, the SO computes:

|SM|
(cid:88)

i=1

Ci[t] − U (cid:62)

(cid:96)t dkm

|SM|
(cid:88)

((s(cid:62)
i

=

· U(cid:96)t) + ri[t]P ) − (

|SM|
(cid:88)

si)(cid:62)U(cid:96)t

i=1

|SM|
(cid:88)

ri[t]P − (

si)(cid:62)U(cid:96)t

(3)

i=1

i=1
|SM|
(cid:88)

= (

i=1
|SM|
(cid:88)

= (

i=1

si)(cid:62)U(cid:96)t +

|SM|
(cid:88)

i=1

ri[t])P ∈ G.

U(cid:96)t = H((cid:96)t) ∈ G2, 1 ≤ t ≤ d.

• Finally, the SO uses an approach to compute a discrete

logarithm to obtain:

Ddji =

d
(cid:88)

t=1

wj[t](s(cid:62)
i

· U(cid:96)t) ∈ G.

• Next, the KDC sends the n electricity theft detection
functional decryption keys to the SO for each SMi:

DKdi = {Ddji}∀j.

C. Reporting Fine-grained Power Consumption Readings

The consumers’ ﬁne-grained electricity consumption read-
ings are encrypted by using secret keys sent by the KDC. The
SMs transmit the encrypted readings periodically to the SO
for load monitoring, billing, and electricity theft detection. For
each reporting period Tt, each SMi ∈ SM generates a power
consumption report by executing the following operations.

• Each SMi uses its encryption key si and the time slot
identiﬁer (cid:96)t to encrypt its reading ri[t] in time slot Tt as
follows:

Ci[t] = (s(cid:62)
i

· U(cid:96)t) + ri[t]P ∈ G,

(2)

where: U(cid:96)t = H((cid:96)t) ∈ G2.

D. Aggregating Fine-grained Power Consumption Readings
for Monitoring

After collecting all the SMs’ encrypted readings (ct) at
reporting period Tt, where ct = [C1[t], C2[t], . . . , C|SM|[t]],
the SO uses the monitoring functional decryption key dkm
to obtain the total aggregated reading for load monitoring by
performing the following steps.

• Given the functional decryption key dkm and ciphertexts

ct, the SO can compute:

U(cid:96)t = H((cid:96)t) ∈ G2.

|SM|
(cid:88)

i=1

ri[t].

In this case, the discrete logarithm is not a difﬁcult problem be-
cause ((cid:80)|SM|
i=1 ri[t]) is not a large value. While many methods
have been introduced to compute the discrete logarithm such
as Shank’s baby-step giant-step algorithm [29], we resorted to
using a lookup table to compute it efﬁciently in a light-weight
manner.

the result ((cid:80)|SM|

By performing the above steps,

i=1 ri[t])
is the summation of the power consumption readings of all
SMs at each time slot Tt. Therefore, ETDFE can achieve
the functional requirement (F1) of reporting aggregated power
consumption reading for load monitoring by the SO without
being able to learn the individual readings to preserve con-
sumers’ privacy.

Beside the aforementioned steps, the SO should store the
ciphertexts of each SMi in vector cB
for calculating bills over
i
each billing interval TB as will be explained in section V-E,
where cB
i

is:

i = [Ci[1], . . . , Ci[b]](cid:62).
cB

Also, the SO should store the reports of each SMi over
electricity theft detection interval TD in vector cD
to be
i
applied to the electricity theft detector, at the end of each
electricity theft detection interval, as will be explained in
section V-F3, where cD
i

is deﬁned as follows:

i = [Ci[1], . . . , Ci[d]](cid:62).
cD

E. Bill Computation Using Dynamic Pricing

In addition to using the ﬁne-grained power consumption
readings in load monitoring and energy management, they
are also used to compute bills following dynamic pricing in
which the electricity tarrifs are higher in the peak-load periods
to stimulate consumers to shift their consumption to off-peak
hours to balance electricity supply and demand. In this section,
we explain how the SO uses the encrypted power consumption
readings to compute bills following dynamic pricing approach.
i vector) from each
SMi, {1 ≤ i ≤ |SM|}, the SO computes the bill at the end of

After collecting b encrypted readings (cB

IBRAHEM et al.: PRIVACY-PRESERVING ELECTRICITY THEFT DETECTION WITH DYNAMIC BILLING AND LOAD MONITORING FOR AMI NETWORKS

9

each billing interval by using the billing functional decryption
key DKbi by calculating

b
(cid:88)

t=1

y2[t]Ci[t] − DKbi

y2[t]((s(cid:62)
i

· U(cid:96)t) + ri[t]P ) −

b
(cid:88)

t=1

y2[t](s(cid:62)
i

· U(cid:96)t)

b
(cid:88)

t=1

y2[t]ri[t]P −

b
(cid:88)

t=1

y2[t](s(cid:62)
i

· U(cid:96)t)

b
(cid:88)

t=1
b
(cid:88)

=

=

y2[t](s(cid:62)
i

· U(cid:96)t) +

t=1
b
(cid:88)

= (

y2[t]ri[t])P.

t=1

(4)
Hence, the SO uses an approach to compute a discrete

logarithm to obtain:

b
(cid:88)

t=1

y2[t]ri[t].

This is the inner product of the SMi’s power consumption
readings and the pricing rates’ vector (y2), which is equiv-
alent to the weighted summation of the power consumption
readings. Therefore, ETDFE can achieve the functionality
requirement (F2) of computing each consumer’s bill following
dynamic prices.

F. Electricity Theft Detection

In this section, the dataset used for training the electricity
theft detection model
then we explain how
is presented,
we train the model as well as its architecture, and ﬁnally,
we discuss how the SO can detect electricity thefts without
violating the consumers’ privacy, i.e., without learning the
ﬁne-grained power consumption readings.

1) Dataset: A real smart meter dataset from the Irish Smart
Energy Trials [30] is used for training and evaluating our
electricity theft detector. This dataset was produced in January
2012 by the Electric Ireland and Sustainable Energy Authority
of Ireland. It contains electricity consumption readings for
more than 1000 consumers over 536 days from 2009 to 2010,
in which an electricity consumption reading is reported by
each SM every 30 minutes. In our experiment, we used the
electricity consumption readings for |SM| = 200 SMs from
the dataset. By pre-processing this data, we build 107, 200
records, where each record corresponds to readings of one
SM in a single day (i.e., 48 readings). We deﬁne a set ri
of electricity consumption readings (i.e., a record) that are
reported by SMi in each day. We assume that each electricity
theft detection interval is one day, SO the input size of our
FFN (d) is 48.

Electricity Theft Attacks: All the readings in the dataset
are for honest consumers. Although we need to train our
model using both honest and malicious data, it is difﬁcult
to collect false readings sent by fraudulent consumers. To
solve this problem, we created malicious dataset by using
a set of electricity theft attacks which are presented in [6].
We considered three types of attacks: by-pass ﬁlters, partial

TABLE II: Cyber attacks in Jokar et al. 2016 [6].

Attack Type

Cyber attacks in Jokar et al. 2016 [6]

f1(ri[j]) = αri[j]

Partial Reduction

By-pass

f2(ri[j]) = β[j]ri[j]
f3(ri[j]) = E[ri]
∀t ∈ [ts, tf]
0
ri[j] ∀t /∈ [ts, tf]

(cid:40)

f4(ri[j]) =

By-pass/Partial Reduction

Price-based Load Control

f5(ri[j]) = β[j]E[ri]
f6(ri[j]) = ri[d − j + 1]

reduction, and price-based load control, as summarized in
Table II. For each day, ri[j] denotes the jth electricity reading
of SMi. As can be seen in Table II, each function f (·) aims
at reducing the power consumption reading ri[j] by applying
different attack scenarios. The ﬁrst attack’s objective,
i.e.,
f1(·), is to reduce ri[j] by a ﬂat reduction ratio α, where
0 < α < 1, while the attack f2(·) dynamically reduces the
reading ri[j] by a value controlled by the time β[j], where
0 < β[j] < 1. The third attack f3(·) reports the predicted
value (mean value) E[ri] of a fraudulent consumer’s power
consumption readings for a given day. On the other hand, the
fourth attack f4(·) is a By-pass attack, in which the fraudulent
consumer sends zero readings during a certain interval (i.e.,
[ts, tf]), otherwise, it reports the actual consumption reading
ri[j], where ts and tf are the start and end of the electricity
theft interval, respectively. Similar to the attack f3(·), the
attack f5(·) also uses the predicted value (mean value) E[ri]
of a fraudulent consumer’s power consumption readings for a
given day. But the difference between them is that the readings
are reduced dynamically from time to time using β[j] in f5(·),
where 0 < β[j] < 1, while the fraudulent consumer who
launch f3(·) reports a ﬁxed value during the day. Finally, the
attack f6(·) is comparatively smart in reducing the electricity
bill as it does not change the actual readings during the day
but it reports the higher energy consumption readings during
low tariff periods.

Data Pre-processing: To apply the aforementioned attacks
to produce malicious readings, we ﬁrst set the parameters of
each function. For functions f1(·), f2(·), and f5(·), α and
β[j] are random variables that are uniformly distributed over
the interval [0.1, 0.6] [6], while ts, in f4(·), is a uniform
random variable in [0, 42], and the period of the attack, i.e.,
tf − ts, is a uniform random variable in [6, 48], and hence, the
maximum value of tf = 48. Hence, by applying these attacks
on the readings of each SM, the corresponding records for each
SM now contains 536 honest records (for daily readings) and
3, 216 malicious records (i.e., 6 attacks × 536). As a result,
the dataset is imbalanced because the malicious data is more
than the honest data.

We tackle the problem of imbalanced data by using adaptive
synthetic sampling approach (ADASYN) [31] for each SM’s
records to balance the size of honest and malicious classes.
Thus, each SM has 6, 432 honest and malicious records, where
each record contains 48 electricity consumption readings.
Consequently, the total number of records for 200 SMs in our
dataset is around 1.2 million. Each SM’s records are divided

IBRAHEM et al.: PRIVACY-PRESERVING ELECTRICITY THEFT DETECTION WITH DYNAMIC BILLING AND LOAD MONITORING FOR AMI NETWORKS

10

Fig. 5: Illustration of the encrypted and non-encrypted parts of the proposed theft detection model.

into two datasets for training and testing with the ratio of 4:1.
The training datasets are combined together from all SMs to
form ˆXTR of size about 1 million records. Similarly, the test
datasets are combined together from all SMs to form a test
dataset of size 257, 241 records. Training a model on variety
of synthetic attacks’ records along with a real dataset [30]
helps in improving the model detection rate.

2) Electricity Theft Detection Model: We train a fully
connected multi-layer FFN network, i.e., electricity theft de-
tector, with a softmax output layer on ˆXTR. While training
the model, (cid:96)2−regularization is used to limit over-ﬁtting,
and we adjust the hyper-parmaters of our FFN model using
hyperopt tool [26] on a validation dataset (which is 33% of
ˆXTR) to tune the number of neurons in each hidden layer,
and select activation function for each layer, batch size, and
learning rate. Then, our model is evaluated on the test dataset.
In the training phase, Adam optimizer is used to train the
model for 60 epochs, 250 batch size, 0.0001 learning rate,
and categorical cross entropy as the loss function. To train our
model, we used Python3 libraries such as Scikit-learn [32],
Numpy, TensorFlow [33] and Keras [34]. Table III gives
the detailed structure of our electricity theft detection model
including number of layers, number of neurons, and activation
functions.

3) Privacy-Preserving Evaluation of Theft Detection
Model: To enable the SO to evaluate the model we trained
without learning the readings to preserve the conumers’ pri-
vacy, we leverage the inner product operation of FE. As shown
in Fig. 5, only the operations of the ﬁrst layer of our model
architecture are executed using the encrypted data. The result
is known to the SO to use in the operations of the next layer.
Generally, the main operation needed by a neural network’s
feed-forward layers can be expressed by z = rW + v where
r is the previous layer input vector, W is the weight matrix,
and v is the bias vector. In our FFN model, the weight matrix

TABLE III: FFN model used in ETDFE, where AF stands for
activation function, and hi is the ith hidden layer.

Layer

Input

h1
h2
h3
h4
h5
h6
h7
h8
h9
h10
h11
h12
h13

Output

No. of neurons

48

40

500

350

110

350

110

1536

500

1536

500

1536

500

700

2

AF

Linear

Linear

ReLU

ReLU

ReLU

ReLU

ReLU

ReLU

ReLU

ReLU

ReLU

ReLU

ReLU

ReLU

Softmax

of the ﬁrst layer W has dimension (d × n) as shown in Eq. 1,
where d is the number of input neurons (features), and n is
the number of neurons in the ﬁrst hidden layer. In our model,
the operation (rW + v) is performed by multiplying the input
vector with W , and then the result is added to the bias vector
v. This results in n components that are the output of the ﬁrst
hidden layer, which is equivalent to n inner product operations
between the input and each column in the weight matrix W .
Therefore, to preserve the consumers’ privacy, we leverage
IPFE to do inner product operation on encrypted vectors to
obtain the output of the ﬁrst hidden layer which is:

riW + v,

Encrypted readings from SMi (ciD ) Encrypted network Feed forward network Malicious Honest …  …  …  … W IBRAHEM et al.: PRIVACY-PRESERVING ELECTRICITY THEFT DETECTION WITH DYNAMIC BILLING AND LOAD MONITORING FOR AMI NETWORKS

11

is

the

consumption readings)
(power
the SMi over TD, and it can be represented as

where ri
of
[ri[1], ri[2], . . . , ri[d]], while v is the bias vector of size n.

input

After collecting d encrypted readings (cD
i

vector) from
each {SMi, 1 ≤ i ≤ |SM|}, the SO runs the electricity
theft detector by using the functional decryption key DKdi
corresponding to SMi to detect whether consumer i is honest
or fraudulent. The n columns of W can be represented as
[w(cid:62)
n ], where wi is the ith column of W , and
wi = [wi[1], wi[2], . . . , wi[d]](cid:62) ∈ Zd
q. The evaluation of the
electricity theft detection model is done as follows.

2 , . . . , w(cid:62)

1 , w(cid:62)

• Given the functional decryption key DKdi and cipher-
texts cD
from each SMi at the end of each electricity
i
theft detection period TD , the SO can compute the inner
product between SMi’s ciphertexts cD
i and each column
of W by performing the following steps.

d
(cid:88)

t=1

wj[t]Ci[t] − Ddji

wj[t]((s(cid:62)
i

· U(cid:96)t) + ri[t]P ) −

d
(cid:88)

t=1

wj[t](s(cid:62)
i

· U(cid:96)t)

wj[t](s(cid:62)
i

· U(cid:96)t) +

d
(cid:88)

wj[t]ri[t]P −

=

=

d
(cid:88)

t=1
d
(cid:88)

t=1

d
(cid:88)

wj[t](s(cid:62)
i

t=1

t=1
d
(cid:88)

· U(cid:96)t) = (

wj[t]ri[t])P

t=1

(5)
• These equations are computed for j = 1, 2, . . . , n. The
SO uses an approach to compute a discrete logarithm to
obtain:

d
(cid:88)

t=1

wj[t]ri[t]

• The results are in clear form. Then the SO adds them to
the bias v of the ﬁrst hidden layer to obtain the output
of the ﬁrst hidden layer of the electricity theft detector
as follows:

[(ri · w(cid:62)

1 ) + v[1], (ri · w(cid:62)

2 ) + v[2], . . . ,
n ) + v[n]]

(ri · w(cid:62)

Then, the output of the ﬁrst hidden layer is the input to
the next layer of the model and the operations of next
layers are completed until the calculations are done in
the last layer and the classiﬁcation result is obtained.

Note that, the number of neurons in the ﬁrst hidden layer
should be fewer than the number of inputs (i.e., n < d) because
if n ≥ d, the SO may obtain the ﬁne-grained readings, since d
unknowns in d equations may be solved to obtain the readings.
Therefore, FFN model is evaluated securely by the SO at the
end of each electricity theft detection interval without learning
the consumption readings to preserve the consumers’ privacy.
Therefore, ETDFE can achieve the functionality requirement
(F3) of privacy-preserving electricity theft detection.

VI. PERFORMANCE EVALUATION

In this section, we ﬁrst evaluate the performance of the
electricity theft detection model, and then assess our scheme
in terms of communication and computation overhead.

A. Electricity Theft Detection

Performance Metrics: In order to evaluate our scheme’s
performance, we considered the following metrics. The de-
tection rate (DR) measures the percentage of fraudulent con-
sumers that are detected correctly. The false acceptance rate
(F A) measures the percentage of the honest consumers that
are falsely recognized as fraudulent. The highest difference
(HD) is the difference between DR and F A. The accuracy
measures the percentage of honest/fraudulent consumers that
are correctly detected as honest/fraudulent. The model perfor-
mance is better when DR, HD, and accuracy are high, and
F A is low.

DR =

T P
T P + F P

, F A =

F P
T N + F P

,

HD = DR − F A, Accuracy =

T P + T N
T N + T P + F P + F N

,

where, T P , T N , F N , and F P stand for true positive, true
negative, false negative, and false positive, respectively.

Results and Discussion: We have evaluated our model
using the confusion matrix which is imported from Scikit-learn
python library [32]. Our baseline is the plaintext FFN model
(without privacy preservation) and we also compare it with
our privacy-preserving model. We compare our results with
the proposed scheme in [6] and the three models proposed in
PPETD [10], which are MD1 with “28 CNN ﬁlters, 1 stride
size, 6 units ﬁlter size, and 2,048 hidden units”; MD2 with
“256 CNN ﬁlters, 1 stride size, 5 units ﬁlter size, 1,536 hidden
units”; and MD3 with “64 CNN ﬁlters, 1 stride size, 5 units
ﬁlter size, 1,536 hidden units”.

Table IV provides the evaluation results for our proposed
model and the existing models in the literature with and
without privacy preservation. Considering privacy-preserving
electricity theft detection, our scheme ETDFE offers higher ac-
curacy and DR, 93.36% and 92.56%, respectively, compared
to PPETD MD1 [10] which has 91.8% accuracy and 91.5%
DR. PPETD MD3 [10] has the lowest F A which equals to
3.9%, while ETDFE has 5.84%, which is slightly higher but
it is still acceptable. Furthermore, unlike [6] that creates one
model for each consumer, our detector is a general model that
does not rely on speciﬁc consumer’s data, and can be applied
to new consumers who have no history of power consumption.
Moreover, our scheme has higher HD than [6] and [10].

In addition, Fig. 6 shows the Receiver Operating Character-
istics (ROC) curves for our model with and without privacy
preservation. ROC curve is often used to evaluate the clas-
siﬁcation accuracy, which is measured by the area under the
ROC curve (AUC). This area indicates how much the model
can distinguish between the classes, where a higher AUC
represents a better performance. The given results indicate that
the overall accuracy of our model does not degrade when
using our privacy-preserving evaluation technique because

IBRAHEM et al.: PRIVACY-PRESERVING ELECTRICITY THEFT DETECTION WITH DYNAMIC BILLING AND LOAD MONITORING FOR AMI NETWORKS

12

TABLE IV: The results of our FFN model and other models in literature.

Model

Method

DR(%)

FA(%)

HD(%)

Accuracy(%)

ETDFE

PPETD MD1 [10]

PPETD MD2 [10]

PPETD MD3 [10]

Jokar et al. 2016 [6]

Without privacy
preservation

With privacy
preservation

Without privacy
preservation

With privacy
preservation

Without privacy
preservation

With privacy
preservation

without privacy
preservation

With privacy
preservation

without privacy
preservation

92.56

92.56

93.6

91.5

92.9

90.0

91.5

88.6

94.0

5.84

5.84

8.00

7.40

8.80

8.79

4.80

3.90

11.0

86.72

86.72

85.6

84.1

84.0

81.2

86.7

84.6

83.0

93.36

93.36

93.2

91.8

92.4

90.2

92.4

90.3

–

detection. For power consumption reporting, the SMs’ com-
putation overhead needed to encrypt the power consumption
reading by using Eq. 2 is 0.009 ms, compared to 0.35 ms in
PPETD [10], as can be seen in Table V. The results conﬁrm
that the computation overhead on the SMs is low which is
important because the SMs are resource-constrained devices.
On the other hand, the overhead of aggregating 200 readings
by the SO is 47.2 µs using our scheme, while it is 0.071 µs in
PPETD. Although our scheme need more time for aggregating
the SMs’ readings, it is still low. Therefore, the comparison
with PPETD demonstrates that our ETDFE scheme can reduce
the computation overhead of reporting a power consumption
reading on SMs by 97.4%.

For our privacy-preserving FFN model evaluation, the total
time needed to evaluate 8,318 hidden units over 15 layers FFN
model is around 0.82 seconds for each consumer at the end of
the electricity theft interval, while PPETD requires 48 minutes
to evaluate the model. Therefore, our scheme provides 99.9%
improvement in evaluating the electricity theft detection model
by the SO. It is worth nothing that this 0.82 seconds includes
the decryption of the ﬁrst layer and obtaining the result of
the classiﬁer. Moreover, unlike PPETD, our scheme does not
need each SM and the SO to be engaged in online/interactive
session for evaluating the electricity theft detection model.

2) Communication Overhead: We used elliptic curve, in
the cryptography operations needed for our scheme, which
provides 160 bits security level. As can be seen from Eq. 2,
each SM sends an encrypted ﬁne-grained reading of total size
of 40 bytes. For privacy-preserving evaluation of electricity
theft detection model,
the SO uses the stored ciphertexts
sent by each SM;
therefore, no additional communication
overhead is needed between the SO and the SMs. On the
other hand, PPETD uses masked readings to preserve con-
sumers’ privacy, and also uses secure multiplication, secure
evaluation of sigmoid(.), and garbled circuit for privacy-
preserving evaluation of a CNN model. This leads to a high
communication overhead of around 1900 MB per SM. As a

Fig. 6: ROC of our model, for the plaintext model (without
privacy preservation) and our privacy-preserving model.

the results of the inner product of the encrypted vectors
using FE is similar to the result of the inner product of the
plaintext vectors. This is different from the proposed scheme
in [10] that suffers from accuracy reduction when considering
privacy preservation. This reduction occurs because a non-
linear function (sigmoid) is approximated as a linear function
in order to be able to evaluate the model on masked readings.

B. Computation and Communication Overhead

Our scheme is implemented using Python “Charm” crypto-
graphic library [35] running on a standard desktop computer
with an Intel Core i7 Central Processing Unit (CPU) operating
at 2GHz and 8GB of Random Access Memory (RAM). We
used elliptic curve of size 160 bits (MNT159 curve).

1) Computation Overhead: To evaluate ETDFE, we com-
pare our scheme’s computation overhead with the one pre-
sented in [10] for load monitoring, billing, and electricity theft

0.00.20.40.60.81.0False positive rate0.00.20.40.60.81.0True positive ratePlaintext (area = 0.9523)Privacy (area = 0.9523)IBRAHEM et al.: PRIVACY-PRESERVING ELECTRICITY THEFT DETECTION WITH DYNAMIC BILLING AND LOAD MONITORING FOR AMI NETWORKS

13

TABLE V: Computation overhead of our
PPETD [10].

scheme and

Methodology

Encryption

Aggregation

Model evaluation

ETDFE

0.009 ms

PPETD [10]

0.35 ms

47.2 µs

0.071 µs

0.82 s

2880 s

result, Our scheme offers a signiﬁcantly lower communication
overhead in comparison with PPETD.

VII. SECURITY AND PRIVACY ANALYSIS

Our scheme can achieve the following desirable security/pri-
vacy requirements that can counter the attacks mentioned in
section III-B.

Theft detection: To ensure the secure evaluation of our
electricity theft detector, each SM ﬁrst encrypts its ﬁne-grained
power consumption readings using FE, and then, the SO uses
the functional decryption keys to get the output of the ﬁrst
layer without being able to learn the individual readings of the
SM. Then, this output can be used to obtain the classiﬁcation
of the model. In addition, our scheme ensures that only the
SO knows the result of the electricity theft detector, unlike
PPETD [10] in which the result is revealed to both the SO and
SM. This may give the consumer enough time to change the
malicious software of the SM before the SO sends technicians
to inspect it to avoid liability.

On the other hand, the SO uses the same encrypted readings
for monitoring, billing, and evaluation of the electricity theft
detector. Thus, our scheme ensures that a consumer will not
be able to fool the detector by sending two readings; one false
reading for billing/monitoring and another true reading for
theft detection. Therefore, our scheme is secured against this
misbehaviour, and hence, it can satisfy the security require-
ment of privacy-preserving theft detection (S1).

Consumers’ privacy preservation: The consumers’ ﬁne-
grained power consumption readings are encrypted and no
entity (including SO) is able to learn the individual readings to
preserve consumers’ privacy. In addition, if the same reading
is repeated at different times, the ciphertext looks different
because each time the encryption is done using different time
identiﬁer and thus U(cid:96)t cannot be repeated. If U(cid:96)t
is
slot
reused, the ciphertexts of two readings of the SMi (ri[1]
and ri[2]) are: ci[1] = (s(cid:62)
· U(cid:96)) + ri[1]P and ci[2] =
i
(s(cid:62)
· U(cid:96)) + ri[2]P , respectively. Hence, by subtracting the
i
two ciphertexts: ci[1] − ci[2] = (ri[1] − ri[2])P , by knowing
one reading, the other can be obtained. To learn a certain
consumer’s power consumption reading, the SO must collude
with (|SM|-1) consumers. This can be done by subtracting
the total power consumption of the colluding SMs from the
total power consumption known to the SO. This attack is not
feasible when the number of SMs in an AMI network is large.
In addition, although the SO has (cid:80)b
· U(cid:96)t), U(cid:96)t,
and y2 for the billing process, it is difﬁcult to obtain the
SMi’s secret key si and using it to compute the SMi’s future
readings, because U(cid:96)t changes, and thus it is infeasible to solve

t=1 y2[t](s(cid:62)
i

the discrete logarithmic problem. Therefore, ETDFE satisﬁes
the security requirement of privacy preservation (S2).

Conﬁdentiality of AMI’s total power consumption and
consumers’ bills: After receiving the encrypted ﬁne-grained
power consumption readings from SMs, the SO can aggregate
the readings to obtain the total power consumption for load
the
monitoring. Attackers, who may be able to intercept
encrypted readings, learn nothing about the total consumption
of an AMI because a private key known only to the SO
is needed to calculate the aggregated power consumption
readings. Also, the SO is the only entity which is capable
of computing the bill of each consumer since a secret key
known only to the SO is needed. Thus, ETDFE satisﬁes the
security requirement of the aggregated power conﬁdentiality
(S3).

VIII. CONCLUSION

In this paper, we have proposed ETDFE, a novel scheme
that uses encrypted ﬁne-grained power consumption readings
reported by the SMs for electricity theft detection, load moni-
toring, and computation of electricity bills following dynamic
pricing while preserving consumers’ privacy. To preserve
privacy, no entity is able to learn the ﬁne-grained power
consumption readings of individual consumers. Functional
encryption is used by each consumer to encrypt the power
consumption readings and the SO uses a functional decryption
key to compute bills and total power consumption for load
management, and evaluate a machine learning model using a
set of encrypted power consumption readings to detect electric-
ity theft. Moreover, extensive simulations have been conducted
using real dataset to evaluate our scheme. The given results
indicate that our scheme can detect fraudulent consumers
accurately and preserve consumers’ privacy with acceptable
communication and computation overhead. Unlike [10], our
scheme does not suffer from accuracy degradation due to the
privacy-preserving evaluation of the model. Furthermore, the
comparison with [10] demonstrates that our scheme can reduce
the computation overhead of reporting a power consumption
reading on SMs by 97.4%, while offering a signiﬁcantly lower
communication overhead. Unlike [10], the SO and SMs do
not need to establish an online/interactive session to evaluate
the electricity theft detection model, and we also reduce the
computation and communication overhead from 48 minutes
to only 0.82 seconds, and from 1900 MB per SM to only 40
bytes, respectively.

ACKNOWLEDGEMENT

This project was funded by the Deanship of Scientiﬁc
Research (DSR) at King Abdulaziz University, Jeddah, under
grant no. DF-745-611-1441. The authors, therefore, acknowl-
edge with thanks DSR for technical and ﬁnancial support.

REFERENCES

[1] V. C. Gungor, D. Sahin, T. Kocak, S. Ergut, C. Buccella, C. Cecati,
and G. P. Hancke, “A survey on smart grid potential applications
and communication requirements,” IEEE Transactions on Industrial
Informatics, vol. 9, no. 1, pp. 28–42, Feb. 2013.

IBRAHEM et al.: PRIVACY-PRESERVING ELECTRICITY THEFT DETECTION WITH DYNAMIC BILLING AND LOAD MONITORING FOR AMI NETWORKS

14

[24] S. Chaturvedi, R. N. Titre, and N. Sondhiya, “Review of handwritten
pattern recognition of digits and special characters using feed for-
ward neural network and izhikevich neural model,” in International
Conference on Electronic Systems, Signal Processing and Computing
Technologies, pp. 425–428, Jan. 2014.

[25] D. P. Kingma and J. Ba, “ADAM: A method for stochastic optimization,”

arXiv preprint arXiv:1412.6980, 2014.

[26] J. Bergstra, B. Komer, C. Eliasmith, D. Yamins, and D. D. Cox,
“Hyperopt: a Python library for model selection and hyperparameter
optimization,” Computational Science & Discovery, vol. 8, no. 1, p.
014008, Jul. 2015.

[27] M. Nabil, M. Ismail, M. Mahmoud, M. Shahin, K. Qaraqe, and E. Ser-
pedin, “Deep recurrent electricity theft detection in AMI networks with
random tuning of hyper-parameters,” in 24th International Conference
on Pattern Recognition (ICPR), pp. 740–745, Aug. 2018.

[28] C. Nwankpa, W. Ijomah, A. Gachagan, and S. Marshall, “Activation
functions: Comparison of trends in practice and research for deep
learning,” arXiv preprint arXiv:1811.03378, 2018.

[29] V. Shoup, “Lower bounds for discrete logarithms and related problems,”
in Advances in Cryptology — EUROCRYPT ’97: Springer Berlin Hei-
delberg, pp. 256–266, Jul. 1997.

Social

[30] “Irish
Mar.
commissionforenergyregulationcer/

Science

[Online]. Available:

2020.

Data

Archive,”

accessed:
last
http://www.ucd.ie/issda/data/

[31] H. He, Y. Bai, E. A. Garcia, and S. Li, “ADASYN: adaptive synthetic
sampling approach for imbalanced learning,” In Proc. of IEEE Interna-
tional Joint Conference on Computational Intelligence, pp. 1322–1328,
Jun. 2008.

[32] F. Pedregosa et al., “Scikit-learn: Machine learning in Python,” Journal
of Machine Learning Research, vol. 12, pp. 2825–2830, Oct. 2011.
[33] A. Mart´ın et al., “TensorFlow: Large-scale machine learning on
heterogeneous systems,” 2015, software available from tensorﬂow.org.
[Online]. Available: https://www.tensorﬂow.org/

[34] F. Chollet et al., “Keras,” https://github.com/fchollet/keras, 2015.
[35] J. A. Akinyele, C. Garman, I. Miers, M. W. Pagano, M. Rushanan,
M. Green, and A. D. Rubin, “Charm: a framework for rapidly proto-
typing cryptosystems,” Journal of Cryptographic Engineering, vol. 3,
no. 2, pp. 111–128, Jun. 2013.

[2] Z. M. Fadlullah, M. M. Fouda, N. Kato, A. Takeuchi, N. Iwasaki, and
Y. Nozaki, “Toward intelligent machine-to-machine communications in
smart grid,” IEEE Communications Magazine, vol. 49, no. 4, pp. 60–65,
Apr. 2011.

[3] A. Alsharif, M. Nabil, S. Tonyali, H. Mohammed, M. Mahmoud, and
K. Akkaya, “EPIC: efﬁcient privacy-preserving scheme with EtoE data
integrity and authenticity for AMI networks,” IEEE Internet of Things
Journal, vol. 6, no. 2, pp. 3309–3321, Apr. 2019.

[4] P. Gope and B. Sikdar, “Privacy-aware authenticated key agreement
scheme for secure smart grid communication,” IEEE Transactions on
Smart Grid, vol. 10, no. 4, pp. 3953–3962, Jul. 2019.
accessed: Mar.
last
https://www.usatoday30.usatoday.com/

2020.
money/industries/energy/2009-03-16-electricity-thefts N.htm

[5] “Electricity Thefts Surge

[Online]. Available:

in Bad Times,”

[6] P. Jokar, N. Arianpoo, and V. C. M. Leung, “Electricity theft detection
in AMI using customers consumption patterns,” IEEE Transactions on
Smart Grid, vol. 7, no. 1, pp. 216–226, Jan. 2016.

[7] Z. Zheng, Y. Yang, X. Niu, H. Dai, and Y. Zhou, “Wide and deep
convolutional neural networks for electricity-theft detection to secure
smart grids,” IEEE Transactions on Industrial Informatics, vol. 14, no. 4,
pp. 1606–1615, Apr. 2018.

[8] K. Gajowniczek, T. Zabkowski, and M. Sodenkamp, “Revealing house-
hold characteristics from electricity meter data with grade analysis and
machine learning algorithms,” Applied Sciences, vol. 8, no. 9, p. 1654,
Sep. 2018.

[9] G. W. Hart, “Nonintrusive appliance load monitoring,” Proceedings of

the IEEE, vol. 80, no. 12, pp. 1870–1891, 1992.

[10] M. Nabil, M. Ismail, M. M. E. A. Mahmoud, W. Alasmary, and E. Ser-
pedin, “PPETD: privacy-preserving electricity theft detection scheme
with load monitoring and billing for AMI networks,” IEEE Access,
vol. 7, pp. 96 334–96 348, Jun. 2019.

[11] M. Abdalla, D. Catalano, D. Fiore, R. Gay, and B. Ursu, “Multi-input
functional encryption for inner products: Function-hiding realizations
and constructions without pairings,” Advances in Cryptology – CRYPTO,
Cham: Springer International Publishing, pp. 597–627, 2018.

[12] S. Salinas, M. Li, and P. Li, “Privacy-preserving energy theft detection
in smart grids,” In Proc. of 9th Annual IEEE Communications Society
Conference on Sensor, Mesh and Ad Hoc Communications and Networks
(SECON), pp. 605–613, Jun. 2012.

[13] D. Yao, M. Wen, X. Liang, Z. Fu, K. Zhang, and B. Yang, “Energy
theft detection with energy privacy preservation in the smart grid,” IEEE
Internet of Things Journal, vol. 6, no. 5, pp. 7659–7669, Oct. 2019.

[14] S. Salinas, M. Li, and P. Li, “Privacy-preserving energy theft detection
in smart grids: A P2P computing approach,” IEEE Journal on Selected
Areas in Communications, vol. 31, no. 9, pp. 257–267, Sep. 2013.
[15] S. Salinas and P. Li, “Privacy-preserving energy theft detection in
microgrids: A state estimation approach,” IEEE Transactions on Power
Systems, vol. 31, no. 2, pp. 883–894, Mar. 2016.

[16] D. Boneh, A. Sahai, and B. Waters, “Functional encryption: Deﬁnitions
and challenges,” in Theory of Cryptography: Springer Berlin Heidelberg,
pp. 253–273, Mar. 2011.

[17] S. Agrawal, B. Libert, and D. Stehl´e, “Fully secure functional encryption
for inner products, from standard assumptions,” in Advances in Cryp-
tology – CRYPTO 2016: Springer Berlin Heidelberg, pp. 333–362, Jul.
2016.

[18] M. Abdalla, F. Bourse, A. De Caro, and D. Pointcheval, “Simple
functional encryption schemes for inner products,” in Public-Key Cryp-
tography – PKC 2015: Springer Berlin Heidelberg, pp. 733–751, Mar.
2015.

[19] C. Baltico, D. Catalano, D. Fiore, and R. Gay, “Practical functional
encryption for quadratic functions with applications to predicate en-
cryption,” in Advances in Cryptology – CRYPTO 2017, Cham: Springer
International Publishing, pp. 67–98, Jul. 2017.

[20] A. Bulsari and H. Saxen, “Application of feed-forward neural networks
for system identiﬁcation of a biochemical process,” in [Proceedings]
1991 IEEE International Joint Conference on Neural Networks, pp.
1224–1229 vol.2, Nov. 1991.

[21] A. J. Dhanaseely, S. Himavathi, and E. Srinivasan, “Performance com-
parison of cascade and feed forward neural network for face recognition
system,” in International Conference on Software Engineering and
Mobile Application Modelling and Development (ICSEMA 2012), pp.
1–6, Dec. 2012.

[22] O. Byk and L. M. Arslan, “Age identiﬁcation from voice using feed-
forward deep neural networks,” in 26th Signal Processing and Commu-
nications Applications Conference (SIU), pp. 1–4, May. 2018.

[23] S. Haykin, Neural Networks and Learning Machines: A Comprehensive
Foundation (3rd Edition). USA: Prentice-Hall, Inc., Nov. 2008.

