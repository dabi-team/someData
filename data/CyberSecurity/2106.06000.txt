1
2
0
2

n
u
J

0
1

]

R
C
.
s
c
[

1
v
0
0
0
6
0
.
6
0
1
2
:
v
i
X
r
a

Use of a non-peer reviewed sources in cyber-security scientific
research

Dalibor Gernhardt
dalibor.gernhardt@gmail.com
Centre for Defence and Strategic Studies "Janko Bobetko"
Croatian Defense Academy
Zagreb, Croatia

Stjepan Groš
stjepan.gros@fer.hr
Laboratory for Information Security and Privacy
University of Zagreb Faculty of Electrical Engineering
and Computing
Zagreb, Croatia

ABSTRACT
Most publicly available data on cyber incidents comes from pri-
vate companies and non-academic sources. Common sources of
information include various security bulletins, white papers, re-
ports, court cases, and blog posts describing speciﬁc events, of-
ten from a single point of view, followed by occasional academic
sources, usually conference proceedings. The main characteristics
of the available data sources are: lack of peer review and unavail-
ability of conﬁdential data. In this paper, we use an indirect ap-
proach to identify trusted sources used in scientiﬁc work. We an-
alyze how top-rated peer reviewed literature relies on the use of
non-peer reviewed sources on cybersecurity incidents. To identify
current non-peer reviewed sources on cybersecurity we analyze
references in top rated peer reviewed computer security confer-
ences. We also analyze how non-peer reviewed sources are used,
to motivate or support research. We examined 808 articles from
top conferences in ﬁeld of computer security. The result of this
work are list of the most commonly used non-peer reviewed data
sources and information about the context in which this data is
used. Since these sources are accepted in top conferences, other re-
searchers can consider them in their future research. To the best
of our knowledge, analysis on how non-peer reviewed sources are
used in cyber-security scientiﬁc research has not been done before.

KEYWORDS
non-peer reviewed sources, cyber security, cyber incidents

1 INTRODUCTION
It is well known that the ﬁrst information about incidents in cy-
berspace is usually published in non-peer reviewed sources, such
as various news portals, blog posts, or even Twitter feeds, as shown
by the recent example of the Solarwinds hack, where users used
the hashtag #sunburst to follow the latest news [19]. Only after a
certain, possibly long, period of time does the information spread
to scientiﬁc, i.e. peer-reviewed, sources.

The reason for this state of aﬀairs is that when an incident oc-
curs, various industrial incident managers and handlers are the
ﬁrst on the scene to help the company manage and recover from
the incident. In doing so, they will have full access to the com-
promised systems and all activities taking place at that time. They
are also provided with all the necessary resources to assist them in
their work, as well as any ﬁndings coming from external systems or

, 2021
2021. ACM ISBN 978-x-xxxx-xxxx-x/YY/MM. . . $15.00
https://doi.org/10.1145/nnnnnnn.nnnnnnn

entities like law enforcement. During this time, some of the infor-
mation leaks out through the victim themselves. For example, the
company may publish some information on company websites for
reputation management and control of damage, as seen in exam-
ple [14]. Information also leaks by investigators themselves. They
want to show themselves as capable of handling the situation, thus
enhancing their reputation among prospective customers. In both
cases, the information released is heavily redacted so that nothing
considered sensitive is leaked. The more informative leaks come in-
directly from people who are familiar with the situation and share
less redacted information with journalists or bloggers, or publish it
themselves under various nicknames. This is a very dynamic phase,
and in addition to these sources, there are many more who simply
copy, extract and edit original sources in many other ways and
publish them on various portals and social networks. So there is a
lot of noise created in a due course.

Only after the investigation is concluded we get a clearer picture
of what happened, though not everything is known even after the
investigation concludes and things get again to normal operations.
These forensic investigations usually last from 4 to 18 months [7, 8].
Once the results of the investigations are made public, they are
often purged of much of the sensitive but important information.
For these reports to ﬁnd their way into the academic literature,
there is at least several months of additional delay in case of confer-
ences, and for journals the average duration of peer review process
could be up to 17 weeks [9]. Clearly, the ﬂow of information from
industrial sources to academic ones can be slow.

This situation raises two issues for researchers wishing to study
incidents or the threat actors behind them in order to help make de-
fenses better. First, data sources are scattered all over the Internet,
as discussed in [11], making it diﬃcult to ﬁnd them. And second,
there is a question about the quality of the sources found. In other
words, is it an original source, or was it taken from somewhere?
Also, is it all of the information that is out there, or is it only part of
it? Was it written by an expert or an expert journalist who knows
what the key elements of the incident are and thus gets everything
is properly conveyed to the reader, or it was written by someone
who doesn’t know security so important details were potentially
left out?

In this work, we aim to help researchers by identifying relevant
and trustworthy non-peer reviewed sources that address computer
security issues, such as reports, blogs, and news sites. Researchers
can then focus on these sources knowing that the content pub-
lished in them is more likely to be relevant and can be reliably
used to support their research.

 
 
 
 
 
 
, 2021

Dalibor Gernhardt and Stjepan Groš

Since it is very diﬃcult for a single person to review all the
possible sources for its quality, we decided to tackle this problem
by studying references in papers published in top security confer-
ences. The idea behind this is that non-peer reviewed sources used
by authors that publish in top security conferences are well scru-
tinized for the quality of its content. In addition to this analysis,
we also wanted to know how exactly information from non-peer
reviewed sources was used, i.e., whether it was used to support ar-
guments in the main research or it was used only as the motivation
for the paper in the introduction section of an article.

Since it is very diﬃcult for a single person to review all the
possible sources for its quality, we decided to tackle this problem
by studying references in papers published in top security confer-
ences. The idea behind this is that non-peer reviewed sources used
by authors that publish in top security conferences are well scru-
tinized for the quality of its content. In addition to this analysis,
we also wanted to know how exactly information from non-peer
reviewed sources was used, i.e., whether it was used to support ar-
guments in the main research or it was used only as the motivation
for the paper in the introduction section of an article.

To the best of our knowledge this has not been done before.
This work makes the following contributions: ﬁrst, we have de-
veloped an indirect methodology for identiﬁcation of high-quality
non-peer sources, and second, we provide researchers with a list
of high-quality, non-peer reviewed sources used in the scientiﬁc
literature.

This paper is organized as follows. Section 2. describes what
kind of information is publicly available to researchers. Section 3
presents our methodology for identiﬁcation of non-peer reviewed
sources in scientiﬁc research. Section 4 provides technical insight
into our data collection eﬀorts. In Section 5 we present the results
of our study, followed by a discussion of the results in Section 6. In
Section 7 we provide recommendations for researchers regarding
usage of non-peer reviewed sources. Section 8 concludes this paper
and gives an overview of the future work.

2 BACKGROUND
The potential sources for information regarding computer secu-
rity incidents are various reports, newspaper articles, blogs, tweets,
threat intelligence (TI), and occasional conference proceedings [11].
Freely available reports and white papers are often condensed
versions of reports available in paid TI [3]. Motives behind releas-
ing free reports can be seen in the marketing and selling compa-
nies’ security products, services, or TI. The data in free reports and
whitepapers is presented in a way that protects the identity of the
attack victim and removes any sensitive or conﬁdential informa-
tion that could be used to link to the victim or the victim’s systems.
After sanitation, the reports still hold key data, but with limited sur-
rounding context, which makes them diﬃcult to use because not
much information is given except for some technical details [3]. It
is important to note that these documents have little in common,
and they are not standardized or scientiﬁcally reviewed in any way.
The authors of these documents often do not distinguish between
the meaning of the terms report [4] and white paper [5], and the
content of these documents varies depending on the author. Even

when researchers have access to paid TI that contain original ver-
sions of reports, the use of such documents in scientiﬁc research
is often not permitted, as discussed in [3].

Apart from reports, various newspapers and news web portals
often cover computer security topics. Some of them are special-
ized and others cover only the most notable incidents, and thus
emphasizing some event. Due to the large number of news web-
sites and portals that often quote each other, it is diﬃcult to as-
sess the true origin of the information. Blogs can be an additional
source of information. Blogs can be private, maintained by some
well-informed industry insiders, such as [10, 16], or, as is often the
case, maintained by companies. Cybersecurity companies usually
have their own dedicated blogs where they publish ﬁrst-hand in-
formation before they are made into specialized reports or white
papers.

There are cases where exchange of incident data is mandated
at the national level. This data is not publicly available. For exam-
ple, the European directive on security of network and information
systems (NIS directive) aims to share cybersecurity incident data
among critical infrastructure companies [17, 18]. The problem with
the NIS directive is that only large companies are covered, and even
then, only signiﬁcant incident data is shared, where deﬁnition of
a signiﬁcant incident depends from case to case on many factors
[6].

Other data sources can be seen in the form of free Open sources
of Threat Intelligence (OTI) such as [1]. The general characteristic
of OTIs is that they are highly technical and rely on references to
other data sources, sources such as those we seek to identify in this
work. As such, OTIs are not data sources in their own right; from
the perspective of this work, they can be seen as repositories of
pointers to other data sources.

If this is the case, one may wonder where do peer-reviewed ar-
ticles get their input information from. It is known that there are
numerous reliable and fast sources dealing with this type of news:
both personal and security companies blogs, various reports, etc.,
but since they are dispersed there is little knowledge about the
quality of the data provided. In the following sections, we aim to
identify publicly available and non-peer reviewed data sources ex-
ists and assess how this data is used in scientiﬁc work.

3 METHODOLOGY
Since we do not have the resources to analyze all available data
sources: reports, various news and blog sites, to ﬁnd out which of
them publish high quality original content, our goal was to derive
a methodology for identifying those sources in a diﬀerent manner.
We decided to take an indirect approach: We selected a set of trust-
worthy data sources and analyzed which sources are used in these
documents.

Typically, as the prestige of a journal or conference increases, so
does the quality control of its content. This implies that these pa-
pers must have used high quality references as sources. Top rated
journals and conferences have stricter rules regarding the quality
of sources compared to lower rated ones. In other words: We leave
it to the reviewers to ﬁlter out trustworthy sources of information
about computer security incidents.

Use of a non-peer reviewed sources in cyber-security scientific research

, 2021

Since the peer review time of journals tends to be longer com-
pared to conferences, we have chosen to analyze top computer se-
curity conferences. The second argument for using conferences
rather than journals is the assumption that the nature of these
sources is changing. From our experience, we have found that non-
peer reviewed sources change over time, one day they are active
with lots of new content and the next day they are gone. This
change over time means that there is no guarantee that a source
used in the past will still provide quality content today. Our goal
is to ﬁnd out which are the best sources at the present time. Our
methodology can be broken down into the following steps:

Step 1: Identify top peer-reviewed conferences. The ﬁrst step in the
process is to identify the relevant rankings that show the
top conferences in a ﬁeld of computer security.

Step 2: Identify commonly used non-peer reviewed sources. Our ini-
tial assumption is that most, if not all, non-peer reviewed
sources are referenced by a URL. This information can be
used to isolate all URLs in reference sections of conference
proceedings. We are aware that this method will not cover
all cases of non-peer reviewed sources, as some of them are
not available online. To mitigate this, we will perform a man-
ual search of the dataset using a set of keywords that might
contain such sources.

Step 3: Reference usage analysis.

After identifying the most commonly used non-peer reviewed
sources, we analyzed how these references were used in the
articles. The goal was to determine if the references were
used to support motivation or if they contained information
that was relevant to the research itself. For the purpose of
this research, we divided the articles into the following dis-
tinguishable sections:

(a) introduction and related work,
(b) background,
(c) research,
(d) discussion.

After we have done all the three steps, the result is a list of non-
peer reviewed sources of the highest quality. These sources are
trusted enough to be used as sources in papers at top conferences,
which means they contain trustworthy data. An additional con-
tribution is the analysis that shows how these sources were used.
Sources used in the main research indicate that the information
provided is relevant to the research itself, and data used in other
parts may indicate that this information was a trigger for some
research.

4 DATA COLLECTION
The ﬁrst step in data collection is to determine the ranking of rele-
vant conferences. Once the relevant conferences are identiﬁed, we
need to decide how many conferences with the highest ranking
should be analyzed and set a time frame for the analysis, as de-
scribed in Section 4.1. The next step is to identify all non-peer re-
viewed data sources used in the reference sections of the confer-
ence papers (Section 4.2). Section 4.3 describes the technical diﬃ-
culties encountered in identifying the non-peer reviewed sources
used in the papers. We conclude this section by presenting obser-
vations on trends in the computer industry in Section 4.4: various

Table 1: Top conferences in computer security in 2020 ac-
cording to Microsoft Academic Research [12]

Rank Conference

1

2

3
4

5

6

7

8

9

IEEE Symposium on Security and Pri-
vacy (S&P) 2020
CCS’20 ACM SIGSAC Conference on
Computer and Communications Secu-
rity
USENIX Security Symposium ’20
SIGCOMM ’20: Annual conference of
the ACM – Special Interest Group on
Data Communication on the applica-
tions, technologies, architectures, and
protocols for computer communication
40th Annual International Cryptology
Conference – CRYPTO 2020
Network and Distributed System Secu-
rity Symposium 2020 (NDSS)
Financial Cryptography and Data Secu-
rity (FC) 2020
Annual Computer Security Applica-
tions Conference (ACSAC) 2020
IEEE International Conference on Com-
puter Communications (ICC) 2020

security companies acquisitions and name changes, and the ten-
dency of security companies to publish data using multiple brands.
These events have inﬂuenced our analysis and can be expected in
the future.

4.1 Top computer security conferences
To identify the most relevant computer security conferences, we
used Microsoft Academic’s saliency ranking [12] . We decided to
analyze the top 9 computer security conferences in the period of
one year - 2020, as shown in Table 1. Originally, we intended to
analyze the top 10 conferences, but we were not able to obtain all
the proceedings of the tenth conference on the list, so we removed
it from our research.

Once we identiﬁed the conferences and the desired time period
for analysis, we created a local dataset containing 570 PDF ﬁles
with a total of 808 articles. Here we can see that some confer-
ences oﬀer the option for downloading individual papers, while
others tend to publish conference proceedings as books containing
hundreds of papers. This inconsistency regarding how conference
proceedings are made available complicates automation in future
steps of our research, as it is diﬃcult to automate the analysis of
diﬀerently structured data.

4.2 Identiﬁcation of relevant non-peer

reviewed data sources.

Our initial assumption was that most, if not all, non-peer reviewed
sources should be cited with associated URLs. With this assump-
tion in mind, we have searched our entire dataset for the strings

, 2021

Dalibor Gernhardt and Stjepan Groš

"http://" and "https://" and extracted the surrounding text to obtain
the full URL and some context.

While preparing for this phase, we evaluated several approaches
on how to analyze this data. One idea was to search the URL strings
for keywords. This approach was discarded because we could not
predict all possible keywords and, ﬁnally, there is a possibility that
the content of the URL string does not correlate with the content
of the web page. Finally, we decided to perform an analysis of how
frequently each URL appears. Once frequent URLs are identiﬁed,
then we will proceed to evaluation of webpages. During the analy-
sis, we did not rely on existing lists of web page classiﬁcations such
as those used to ﬁlter internet content, e.g., [20] , and opted for a
manual analysis of the content referenced by each URL that ap-
pears above a certain threshold. In our initial search of the dataset,
we identiﬁed 12560 URLs. To identify commonly used sources, we
have grouped the URLs by their associated domain names, e.g.,
we found 8 diﬀerent URLs pointing to the domain "krebsonsecu-
rity.com". This process of grouping URLs to domain names resulted
in the identiﬁcation of 237 domain names that were cited more
than ﬁve times.

Closer examination of the frequently occurring domain names
revealed that most of the cited URLs were actually links to diﬀer-
ent Digital Object Identiﬁers (DOIs), various article, or source code
repositories, rather than non-peer reviewed sources. To identify
relevant non-peer reviewed sources, we excluded domains asso-
ciated with the following topics: DOIs, articles and proceedings
repositories, source code repositories, vulnerability databases, ex-
ploit databases, news about various products and corresponding
updates, Wikipedia articles, technical speciﬁcations, manuals, cryp-
tocurrency news, various statistics and metrics, protocol documen-
tation, processor documentation, anonymity browsing, bug databases,
as these types of sources are not relevant to our research.

Through this search, we only identiﬁed sources that are cited
using URLs. If some source is cited without a URL, it would not
be identiﬁed automatically. For example, non-peer reviewed con-
ferences (such as Black Hat) often provide ﬁrst-hand information
on hacking and cybersecurity. From our experience, we have found
that authors of articles cite these sources in inconsistent ways, with
some authors citing with the URL and others citing with the name
of the conference and authors. Since our primary search is focused
on URLs, these types of results would not show up unless they were
cited with URL. To include these types of results, we used several
lists of hacking conferences and searched our dataset for mentions
of conference names in reference sections and included them in our
list. In addition to conferences, we manually searched the dataset
for keywords such as "SANS Institute", reputable sources that could
be used as sources but are not cited using URL.

To narrow down the list to relevant sources, we decided to ana-
lyze only sources that were cited ﬁve or more times. If some source
has a frequency less than ﬁve, then we consider it rarely used and
dismiss it. This process resulted in the elimination of about 5 500
rarely cited domains or keywords. After examining the content
referenced by the URLs, we obtained a list of domains related to
various computer security topics: specialized news sites, blogs, in-
dustrial sources publishing various reports and white papers.

4.3 Identifying the reference context
After reducing the list of sources to the most relevant domain names,
we searched the dataset again, this time using each relevant key-
word identiﬁed in a previous step. We evaluated where in the paper
a reference to a particular source was used. This was mostly man-
ual and time-consuming step for several reasons:

i. Number of queries

After the process of grouping URL to frequent domain names
and adding additional keywords for the search as described
in the previous section, we performed 150 queries over 808
papers.

ii. Inconsistency of article structure

Each conference uses a diﬀerent template, each author has
a diﬀerent number of sections in the paper. Also, as men-
tioned in IV.A, some conferences allow access to individual
papers, and some publish papers in the form of a book.

iii. Diﬀerent citation rules

Some citation rules state that sources are sorted alphabeti-
cally, while others state that sources are sorted in the order
in which they appear in the paper. When authors cite mul-
tiple sources at once, the references are often grouped, e.g.,
"[1-5]", with the reference number hidden in range of val-
ues.

In all the cases, our process was as follows: ﬁrst, we searched the
paper for the keywords, if the certain keyword was found, then we
identiﬁed the reference number in the reference section of the pa-
per, e.g., " [19]", third, we evaluated where in the paper a reference
to a particular source was used.

Distinction of sections in papers is diﬃcult to standardize ob-
jectively and is therefore susceptible to subjective interpretation
and questioning. The primary goal of this paper was to determine
what currently used non-peer reviewed sources exist, and the sec-
ondary goal was to evaluate the context in which they were used.
The authors made every eﬀort to be as objective as possible and
the results provide at least some indication of how these sources
are used.

4.4 Observations
During our research, we came across several cases where cited
source originated from a security company that was acquired by
another company at some point, resulting in both brand names
being cited depending on when the author accessed the content
or when post was originally published. For example, since Syman-
tec was acquired by Broadcom in 2019 [15], publications are pub-
lished under the diﬀerent brand - Broadcom, resulting in citations
of both names. To further complicate the analysis, Broadcom pub-
lishes diﬀerent types of documents from diﬀerent domain names,
such as: blogs, white papers, reports. Similarly, Palo Alto Networks
acquired PureSec in 2019 [13], AT&T acquired AlienVault [2].

Another observation is that large security companies post docu-
ments under diﬀerent brand names. Sophos frequently posts news
under the brand name NakedSecurity, Eset posts under the brand
name WeLiveSecurity, Kaspersky uses the brand name SecureList,
Cisco uses both Cisco and Talos names, and Microsoft uses Tech-
net, MSDN, and Azure names.

Use of a non-peer reviewed sources in cyber-security scientific research

, 2021

Table 2: Distribution of non-peer reviewed citations among
top nine conferences

Table 3: Specialized non-peer reviewed sources used in 5 an-
alyzed conferences held in 2020

Conference

SP 2020
CCS ’20
Security ’20
SIGCOMM ’20
CRYPTO 2020
NDSS 2020
FC 2020
ACSAC 2020
ICC 2020
Total:

Number of
non-peer
reviewed
citations
103
96
101
10
1
77
1
57
2
448

Percentage of total
number

23 %
21 %
23 %
2 %
0 %
17 %
0 %
13 %
0 %

Because the citations from these sources are spread across mul-
tiple brands with the same origin, in some cases with only a few
citations from individual sources, we grouped the results from the
sources and presented them as one data source, grouping both the
names and the types of reports. The only exception to this rule
were sources originating from Google. Both "security.googleblog.com"
and "googleprojectzero.blogspot.com" were cited more than 5 times,
so we decided to treat them as separate sources.

5 RESULTS
The results are presented as follows: In Section 5.1 we present how
often diﬀerent conferences rely on non-peer reviewed sources. Full
results of our study showing which sources are most frequently
used are presented in Section 5.2, and in Section 5.3 we present
our ﬁndings on usage of non-peer reviewed sources regarding to
a paper context.

5.1 Distribution of non-peer reviewed sources

across conferences.

After analysis of top nine conferences in the ﬁeld of computer se-
curity during 2020 (Table 1), we have noticed uneven distribution
in usage of non-peer reviewed sources from conference to confer-
ence. Possible reason for this is the fact that all conferences are in
the ﬁeld of computer security, but focus on diﬀerent topics. Table 2.
summarizes the use of non-peer reviewed sources at each confer-
ence. It is noticeable that the conferences SIGCOMM, CRYPTO, FC,
and ICC have a total of 14 references to non-peer reviewed review
sources that meet our criteria.

The small sample size of the four conferences is not suﬃcient
to draw ﬁrm conclusions. For this reason, we excluded these four
conferences from further analysis. This left us with data from ﬁve
conferences that are relevant to the ﬁeld and that use non-peer
reviewed sources: S&P, CCS, Security, NDSS, and ACSAC.

5.2 Identifying non-peer reviewed data sources
Through our analysis of references used in the top 2020 cyberse-
curity conferences, we identiﬁed 37 data sources that were cited

Source
No
Blackhat series
1.
googlepro...blogspot.com*
2.
zdnet.com
3.
wired.com
4.
Broadcom (Symantec)
5.
arstechnica.com
6.
techcrunch.com
7.
theguardian.com
8.
theverge.com
9.
forbes.com
10.
security.googleblog.com
11.
grsecurity.net
12.
Kaspersky (Securelist)
13.
Fireeye
14.
bbc.com
15.
BleepingComputer.com
16.
17.
bits-please.blogspot.com
18. Microsoft (Azure, MSDN)
19.
20.
21.
22.
23.
24.
25.
26.
27.
28.
29.
30.
31.
32.
33.
34.
35.
36.
37.

reuters.com
SANS Institute
KrebsOnSecurity.com
Palo Alto Networks
Sophos (Naked security)
Cisco (Talos)
DEF CON
washingtonpost.com
theregister.co.uk
citizenlab.ca
thehackernews.com
dyn.com/blog
telegraph.co.uk
bloomberg.com
McAfee report
blog.cloudﬂare.com
TrendMicro Blog
signal.org/blog/
blog.apnic.net**

Total count

Type
Conference
Sec. comp. blog
Specialized news
Specialized news
Security company
Specialized news
Specialized news
General news
General news
General news
Sec. comp. blog
Security company
Security company
Security company
General news
Specialized news
Private blog
Security company
General news
Institute
Private news
Security company
Security company
Sec. comp. blog
Conference
General news
General news
Laboratory
Specialized news
Sec. comp. blog
General news
General news
Security company
Sec. comp. blog
Sec. comp. blog
Sec. comp. blog
Sec. comp. blog

s
n
o
i
t
a
t
i
c

f
o

.

o
N

54
27
25
24
20
19
18
14
13
13
13
12
12
11
10
10
9
9
8
8
8
8
8
8
7
7
7
6
6
6
5
5
5
5
5
5
4
434

*google.projectzero.com
**blog.apnic.net falls under source 5 because it was once cited
in SIGCOMM ’20 which was not analyzed regarding
position of citation in article

more than 5 times, for a total of 434 times in 540 articles from ﬁve
conferences, as shown in Table 3.

, 2021

Dalibor Gernhardt and Stjepan Groš

As described in Section IV.B, we identiﬁed data sources using
two methods: analysis of URL string analysis and searching refer-
ences against a list of possible sources which are not cited by URL.
Our study shows that out of 37 frequent sources, 34 were cited by
URL (92%), with only three sources that were not cited by URL:
Blackhat and DEFCON conferences, and the SANS Institute. If we
focus on the quantity of citations, the results are as follows: Out of
434 citations, 365 were cited by URLs (84%).

If we focus on the type of sources rather than the number of ci-
tations when interpreting the results in Table 3. the results are as
follows: The most frequently cited sources are unspecialized but
highly reputable news websites (24%), followed by security com-
panies publications (21%) and security companies blog posts (21%).
In fourth place are specialized news sites (16%), with all other types:
conferences, laboratories, private blogs and news, institutes falling
into the remaining 18%.

If we focus instead on the number of references originating from
diﬀerent types of sources, the results are as follows: Specialized
news websites are the most cited with 102 citations or 24%, fol-
lowed by security companies publications with 85 (20%) citations.
Non-specialized news websites are third with 82 (19%) citations,
security company blogs are fourth with 73 (17%) citations, and
hacking conferences are ﬁfth with 61 citations (14%), with all other
sources falling within the remaining 6%.

5.3 Analysis of reference context
The ﬁnal goal of this work was to ﬁnd out in which contexts au-
thors used non-peer reviewed sources and whether the use of these
sources was consistent from conference to conference. We wanted
to know if these sources were used only to motivate the work, to
show that a particular behavior was found in practice, or if these
data were used in the main body of the research. As described in
Section 3, we manually analyzed 434 citations with the goal of de-
termining how these sources were used.

The results of this analysis are presented in Table 4. showing
which non-peer reviewed sources are used, their type, how they
are used in papers regarding context, both at the level of individ-
ual conference observed conference and on average. The results
shown in 5. show distribution of non-peer reviewed references in
all conferences: Non-peer reviewed sources were most frequently
cited in the introductory sections of articles or in the review of re-
lated work at 61% of the time. In the development section, these
sources are used in 17% of citations and in the main body of the
research in 16%. As shown in Table 5 the use of references in dis-
cussions is not consistent between the observed conferences.

6 DISCUSSION
This section is organized as follows: In Section 6.1 we analyze inde-
pendent researchers used as sources in papers. In a subsequent Sec-
tion 6.2, we examine which sources are not cited with URL. How
non-peer reviewed sources are used in papers is discussed in 6.3.
In Section 6.4 we analyze which references tend to be cited in dif-
ferent parts of papers.

6.1 Independent researchers as data sources
One of the goals of this research was to identify the use of pri-
vate blogs likely to be associated with well-informed individuals
or academics, with the aim of determining whether there are dom-
inant authors there. However, our results did not identify any such
sources, apart from "kerbsonsecurity.com". Although our method-
ology and data collection eﬀort should have identiﬁed these sources,
as authors we wanted to re-examine why private blogs were miss-
ing from our ﬁnal list.

To identify private blogs, we took a list of all URLs in our dataset
and searched them again, this time looking for the keyword "blog"
within the string of each URL. This time we did not check whether
the blog was about computer security, and decided to analyze all
12560 URLs found in conference papers. We identiﬁed 240 domains
that contained the string "blog", but we could not identify recurring
sources. To be more precise, 173 URLs containing the string "blog"
were cited only once, and 37 were cited twice, implying that private
blogs do not provide consistent information on computer security,
at least in 2020.

Our second guess was that there might be authors posting via
online social networks such as Twitter or Medium. Searching for
the keyword "twitter.com" in the URL strings, we obtained only 11
articles with links to diﬀerent authors. Searching for the keyword
"medium.com" yielded 28 citations in articles, but again with no
dominant authors. Similarly, "youtube.com" is cited in 15 papers,
also without dominant authors.

6.2 Sources without URL in citation
Sources such as Blackhat conferences are often not cited with a
URL, as described in Section 4.2. For identiﬁcation of this type of
sources we searched URL strings against a set keywords of poten-
tial sources. After using a few sources for top hacking conferences
and searching, we identiﬁed only two cited conferences: the Black-
hat series with 54 citations and the DEF CON with 7 citations. At
ﬁrst glance, the Blackhat conference series is the best positioned
source, but when analyzing the content of these citations, it be-
comes clear that these citations mostly focus on speciﬁc exploits
and techniques, rarely on incidents as such. Since this conference
is not peer-reviewed, we decided to include it in our list because it
is relevant to our research topic. We could not identify any other
references to conferences that were non-peer reviewed.

A similar observation regarding citation by URL can be applied
to the case of the "SANS Institute". Publications originating from
this institution are sometimes cited by URL, but sometimes by doc-
ument name or authors, making automatic identiﬁcation diﬃcult.
We could not identify any other relevant data source which is used
in the papers but without mentioning the URL in the citation.

6.3 On the use of non-peer reviewed sources
In this paper, we analyzed the top conferences that took place in
2020, so we cannot provide information about the longevity of
these sources. We hypothesize that these non-peer reviewed sources
change over time, and yesterday’s sources do not have to provide
the same quality of information. For example, we observed that
the cited source "bits-please.blogspot.com" was only active from
2014 to 2016 and is still cited in 2020, but with no new information

Table 4: Summarized results of relevant non-peer reviewed sources in computer security conferences of 2020

S&P 2020

C D A

CCS ’20
B

C D A

Í 𝐴 Í 𝐵 Í 𝐶 Í 𝐷

Cites Source

Type

Fireeye
BleepingComputer.com
bbc.com

Broadcom (Symantec)
arstechnica.com
techcrunch.com
theguardian.com
forbes.com
security.googleblog.com
theverge.com
grsecurity.net

Blackhat series
1.
googleprojectzero
2.
3.
zdnet.com
4. wired.com
5.
6.
7.
8.
9.
10.
11.
12.
13. Kaspersky (Securelist)
14.
15.
16.
17. Microsoft (Azure, MSDN)
bits-please.blogspot.com
18.
Palo Alto Networks
19.
SANS Institute
20.
21.
reuters.com
22. Cisco (Talos)
23.
24. KrebsonSecurity.com
25.
theregister.co.uk
26. DEF CON
27. washingtonpost.com
citizenlab.ca
28.
dyn.com/blog
29.
thehackernews.com
30.
signal.org/blog/
31.
blog.cloudﬂare.com
32.
TrendMicro Blog
33.
34.
telegraph.co.uk
35. McAfee report
bloomberg.com
36.
blog.apnic.net*
37.

Sophos (Naked security)

Conference
Sec. comp. blog
Secialized news
Secialized news
Security comp.
Secialized news
Secialized news
General news
General news
Sec. comp. blog
General news
Security comp.
Security comp.
Security comp.
Secialized news
General news
Security comp.
Private blog
Security comp.
Institute
General news
Sec. comp. blog
Security comp.
Private news
General news
Conference
General news
Laboratory
Sec. comp. blog
Secialized news
Sec. comp. blog
Sec. comp. blog
Sec. comp. blog
General news
Security comp.
General news
Sec. comp. blog

A

5
2
1
7
5
5
3

1
1
2

1
1
3
2
7

1

2
3
1

1
1
1

1

1
1

B

1

1
1

2

2
3

1

1
2

4
1

1

1
1
1
1
1

2
1
1

1

1

1
1

1

1

1

3

13
9
4
4
4

3
3

3
2
4
2
2
2

1
1
1
3

2

1
3

Security ’20

NDSS 2020

ACSAC 2020

B

3
1

1

1
1

3

1

2

1

B

2

1
1

1

1
1
1

1
1

2

2
1

1
1

C D A

3

1
1

1

3

2
1

1

1

2
1

1
2

7
2
1
2
3
3
1
2

3

2
1

1

1
2
1
2

1
2

1

2

1
1

C D A B C D

1

2

1
1

1

1

1
1

1

1

1

1

1
1

1
1

1

2

3

1

2

1

1

1

1

1

1

1

1

1

3

4
3
4

1
1

2

1
2
1
2

1
2
1
2
1

1

2
1

3

1

1

33
18
15
21
18
11
8
7
3
7
6
7
10
6
4
5
3
7
2
3
4
4
7
7
6
2
4
4
4
4
2
3
3
4
4
5
3

9
3
2
1
2
3
3
2
5
1
3
5
2
4
0
1
3
2
4
2
1
3
0
1
0
2
2
0
1
2
1
0
2
1
1
0
0

1
2

1

1
2

1

1

3
1
1
1

1
1
1
1

1

2

1

1

1
1

5
5
5
5
2
3
1
1
2

1
1
5

1

1

2
1
2
1

2
1
1

2

2

2
2

4
1
1
1

1
1
2

2
2

1

1

1

1

19

Í

54
27
25
24
20
19
18
14
13
13
13
12
12
11
10
10
9
9
8
8
8
8
8
8
7
7
7
6
6
6
5
5
5
5
5
5
4

0
4
3
0
0
1
1
2
3
2
1
0
0
1
1
1
2
0
2
1
0
0
0
0
1
0
0
1
0
0
0
0
0
0
0
0
0

12
2
5
2
0
4
6
3
2
3
3
0
0
0
5
3
1
0
0
2
3
1
1
0
0
3
1
1
1
0
2
2
0
0
0
0
1

69

TOTAL

59

17

18

9

56

17

4

67

14

14

6

42

17

10

8

40

9

8

0

264

74

27

434

*A - Introduction or Related Work, B - Development, C - Main reaseach, D - Dicussion
Numbers show how many times source was cited in certain part of article

U
s
e

o
f

a
n
o
n
-
p
e
e
r

r
e
v
i
e
w
e
d
s
o
u
r
c
e
s

i

n
c
y
b
e
r
-
s
e
c
u
r
i
t
y
s
c
i
e
n
t
i
f
i
c

r
e
s
e
a
r
c
h

,

2
0
2
1

, 2021

Dalibor Gernhardt and Stjepan Groš

Table 5: Distribution of reference usage regarding a position
within articles

k
r
o
w
d
e
t
a
l
e
R
r
o
n
o
i
t
c
u
d
o
r
t
n
I

57%
58%
66%
55%
70%
61%
6.6

e
c
n
e
r
e
f
n
o
C

S&P 2020
CCS ’20
Security ’20
NDSS 2020
ACSAC 2020
Average
Standard dev.

t
n
e
m
p
o
l
e
v
e
D

17%
18%
14%
22%
16%
17%
3.1

h
c
r
a
e
s
e
r
n
i
a
M

17%
20%
14%
13%
14%
16%
2.9

n
o
i
s
s
u
c
s
i
D

9%
4%
6%
10%
0%
6%
4.1

s
e
c
n
e
r
e
f
e
R

103
96
101
77
57
86.8
19.6

since then. In addition, all citations are concentrated on a single
blog post, so this source is not a constant source of new informa-
tion, but rather a one-time source.

Newspapers with general content were found to be relevant
sources of information with a total of 82 citations. These newspa-
pers are reputable sources of trustworthy news, they are more fre-
quently cited by authors compared to specialized news sites. These
unspecialized news sources do not necessarily cover all computer
security topics. However, they do cover important events and can
therefore be considered as a source of valid arguments about a par-
ticular problem or incident. In this paper, we did not focus on the
journalists themselves as a source of data, but only the news sites
as such were analyzed.

6.4 Positional citation of non-peer reviewed

references.

Analyzing the references used, we can see that the Blackhat con-
ference series is the main source in all article parts, except the dis-
cussion part, as shown in Table 6. The introduction part of the arti-
cles is mainly composed of specialized or industrial sources, with
56% of all citations coming from the top 10 sources. In the develop-
ment section of the articles, the percentage is similar, with 56.7% of
citations coming from the top 10 sources, again mainly from spe-
cialized news sites and industrial sources. In the main research, we
observed similar numbers, with 68% of the citations coming from
the top 10 sources. Interestingly, the list of sources for the main re-
search consists mainly of specialized and general news sites with
only one industry source in the top 10. The original hypothesis
of the authors was that industry sources are mostly used in this
part of the articles as they provide technical details, but our data
shows otherwise. Since the discussion section of the articles has
the fewest citations overall, the results of this part of the study are
less reliable and we were only able to identify the top 7 sources,

since all other sources are cited only once in this section. These
top 7 sources cover 66.7% of all citations and the list consists of
both news and security company sources.

One of the limiting factors in future exploration of older con-
tent is the sole access to conference proceedings. We observed that
some conference websites are no longer maintained. Access to old
proceedings is limited due to inactive URLs and searching for indi-
vidual articles is time consuming.

7 RECOMMENDATIONS FOR RESEARCHERS
Our research analyzed a period of one year and has analyzed top
nine computer security conferences. During our research, we found
that non-peer reviewed sources are not evenly present among the
conferences. When we look at the distribution of usage among
conferences shown in 2., it is clear that some conferences do not
use non-peer reviewed sources: SIGCOMM, CRYPTO, FC, and ICC.
This could be due to editorial practices or due to content of these
conferences. The use of non-peer reviewed sources is most com-
mon in the following conferences: S&P, Security, CCS, NDSS, and
ACSAC.

The cumulative results presented in Table 6. show that confer-
ence papers authors rely on a relatively small number of non-peer
reviewed sources. In the top ten list we have:

• one conference covering technical topics (Blackhat),
• two security companies publications (Google Project Zero

and Broadcom),

• four specialized news sites (ZDnet, Wired, Ars Technica, TechCrunch),
• three news websites (The Guardian, The Verge, Forbes).
In addition, we provide researchers with information on how
these references were used. Not all sources contain data relevant to
the research itself. Overall, non-peer reviewed sources are most of-
ten, 61% of the time, used by researchers as motivation for the work
(see Table 5 for full results). Some sources are more frequently used
for motivation, but others contain data that is more frequently used
in the main part of the research, as shown in the overview in Ta-
ble 6. These sources are accepted by reviewers in top computer
security conferences and as such should be followed by computer
security researchers as they publish trustworthy information. We
recommend researchers to follow these sources as they can provide
important information for future research.

8 CONCLUSION AND FUTURE WORK
In this paper, we have developed a methodology for identifying and
analyzing the use of non-peer reviewed sources in computer secu-
rity. To the best of our knowledge, this has not been done before.
We analyzed the top computer security conferences of 2020, as con-
ferences tend to have a shorter review time compared to journals.
Our results show that diﬀerent conferences tend to show diﬀerent
levels of reliance on non-peer reviewed sources. Of the nine con-
ferences analyzed, ﬁve conferences contained references to 97% of
analyzed citations, while we did not identify signiﬁcant use of non-
peer reviewed sources in four conferences. We identiﬁed a total of
37 diﬀerent non-peer reviewed sources with more than 5 citations
in the observed conferences. Non-peer reviewed sources are used
to motivate the work in 61% of the cases, followed by the develop-
ment section with 17% and the main research with 16%, with the

Use of a non-peer reviewed sources in cyber-security scientific research

, 2021

Table 6: Top 10 sources in regard of positional citing in papers

No.

1.
2.
3.
4.
5.
6.
7.
8.
9.
10.

Introduction or
Related Work
Blackhat series
wired.com
googleprojectzero
Broadcom (Symantec)
zdnet.com
arstechnica.com
Kaspersky (Securelist)
techcrunch.com
theguardian.com
security.googleblog.com

Cit.

Development

Cit.

Main research

Cit.

Discussion

Cit.

33
21
18
18
15
11
10
8
7
7

Blackhat series
grsecurity.net
forbes.com
Fireeye
Palo Alto Networks
googleprojectzero
arstechnica.com
techcrunch.com
theverge.com
Cisco (Talos)

9
5
5
4
4
3
3
3
3
3

Blackhat series
techcrunch.com
zdnet.com
BleepingComputer.com
arstechnica.com
theverge.com
theguardian.com
DEF CON
security.googleblog.com
bbc.com

12
6
5
5
4
3
3
3
3
3

googleprojectzero
zdnet.com
forbes.com
theguardian.com
security.googleblog.com
Microsoft (Azure, MSDN)
Palo Alto Networks

4
3
3
2
2
2
2

[11] Antoine Lemay, Joan Calvet, François Menet, and José M. Fernandez. 2018. Sur-
vey of publicly available reports on advanced persistent threat actors. Computers
and Security 72 (2018), 26–59. https://doi.org/10.1016/j.cose.2017.08.005
[12] Microsoft. 2021. Microsoft Academic, Conferences Analytics: Computer security.

https://academic.microsoft.com/conferences/41008148,38652104

[13] Palo Alto Networks. 2019. Palo Alto Networks Completes Acquisition of PureSec.

https://www.paloaltonetworks.com/company/press/2019/palo-alto-networks-completes-acquisition-of-puresec

[14] Sudhakar

Ramakrishna.

Our
Customer
a
https://orangematter.solarwinds.com/2021/01/07/our-plan-for-a-safer-solarwinds-and-customer-community/

Plan
for
Community.

SolarWinds

2021.

Safer

and

[15] Duncan Riley and SiliconANGLE Media. 2019.
tonLifeLock as Broadcom closes purchase of
https://siliconangle.com/2019/11/05/symantec-now-nortonlifelock-broadcom-completes-acquisition-enterprise-business/

Symantec is now Nor-
its enterprise business.

[16] Bruce Schneier. 2021. Schneier on Security. https://www.schneier.com
[17] Giuseppe Settanni, Florian Skopik, Yegor Shovgenya, Roman Fiedler, Mark Car-
olan, Damien Conroy, Konstantin Boettinger, Mark Gall, Gerd Brost, Christophe
Ponchel, Mirko Haustein, Helmut Kaufmann, Klaus Theuerkauf, and Pia Olli.
2017. A collaborative cyber incident management system for European intercon-
nected critical infrastructures. Journal of Information Security and Applications
34 (jun 2017), 166–182. https://doi.org/10.1016/j.jisa.2016.05.005

[18] THE EUROPEAN PARLIAMENT AND THE COUNCIL OF THE EUROPEAN
UNION. 2016. DIRECTIVE (EU) 2016/1148 OF THE EUROPEAN PARLIAMENT
AND OF THE COUNCIL (NIS dierctive). https://doi.org/10.2307/j.ctt1xhr7hq.20
hashtag.

[19] Twitter.com.

#sunburst

Twitter

[n.d.].

https://twitter.com/hashtag/sunburst?src=hashtag_click

[20] Virtual Graﬃti

Inc. 2021.

Blue Coat WebFilter: URL categories.

https://www.edgeblue.com/WebFilter.asp

remaining 6% falling into the discussion section. Research suggests
that diﬀerent sources tend to be dominant in diﬀerent sections of
articles, presumably because they do not provide the same type of
information.

Most of the non-peer reviewed sources are specialized websites,
security company publications, and organizational blogs. These
sources are trusted enough to be allowed in top conferences and
as such can be seen as sources of trustworthy information on com-
puter security and should therefore be considered by researchers.
During our research, we identiﬁed only one relevant "well in-
formed" individual or small organization who publishes security
news. Both private and organizational blogs were cited a total of
421 times, but they are scattered across 240 diﬀerent sources.

In this paper we did not conduct a longitudinal study, and it
would be interesting to determine both: how these data correlate
over time and whether there is a correlation between non-peer re-
viewed data sources used in journals and conferences. In addition,
at this point we do not know how this data compares with diﬀer-
ently rated conferences and journal articles. It could be that lower
rated conferences are later cited in higher rated conferences, thus
used as information ﬁlters.

REFERENCES
[1] AT&T Buisiness.

[n.d.].

AT&T Alien Labs Open Threat Exchange.

https://cybersecurity.att.com/open-threat-exchange
to
2018.

Buisiness.

AT&T

[2] AT&T

Acquire

AlienVault.

https://cybersecurity.att.com/who-we-are/press-releases/at-t-to-acquire-alienvault

[3] Xander Bouwman, Harm Griﬃoen, Jelle Egbers, Christian Doerr, Bram Klievink,
and Michel van Eeten. 2020. A diﬀerent cup of TI? The added value of com-
mercial threat intelligence. Proceedings of the 29th USENIX Security Symposium
(2020), 433–450.

[4] Cambridge University Press.

[n.d.].

Meaning of Report

in English.

https://dictionary.cambridge.org/dictionary/english/report

[5] Cambridge University Press. [n.d.]. Meaning of White Paper in English.

https://dictionary.cambridge.org/dictionary/english/white-paper

[6] European Union Agency for Cybersecurity (ENISA). 2021. Technical Guideline

on Incident Reporting. https://doi.org/10.2824/633879

[7] Tim Grant. 2018. Speeding up Planning of Cyber Attacks Using AI Techniques:
State of the art. In Proceedings, 13th International Conference on Cyber Warfare
& Security (ICCWS 2018),. Washington DC, 235–244.

[8] Tim Grant, E. Van Eijk, and H.S. Venter. 2016. Assessing the feasibility of con-
ducting the digital forensic process in real time. In Proceedings of the 11th Interna-
tional Conference on Cyber Warfare and Security, ICCWS 2016. Boston, 146–155.
[9] Janine Huisman and Jeroen Smits. 2017. Duration and quality of the peer re-
view process: the author’s perspective. Scientometrics 113, 1 (2017), 633–650.
https://doi.org/10.1007/s11192-017-2310-5

[10] Brian Krebs. 2021. KerbsonSecurity. https://krebsonsecurity.com

