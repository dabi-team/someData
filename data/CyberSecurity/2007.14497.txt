Cyber Deception for Computer and Network
Security: Survey and Challenges

Zhuo Lu, Member, IEEE, Cliff Wang, Fellow, IEEE, and Shangqing Zhao Student Member, IEEE,

1

0
2
0
2

l
u
J

8
2

]

R
C
.
s
c
[

1
v
7
9
4
4
1
.
7
0
0
2
:
v
i
X
r
a

Abstract—Cyber deception has recently received increasing
attentions as a promising mechanism for proactive cyber defense.
Cyber deception strategies aim at injecting intentionally falsiﬁed
information to sabotage the early stage of attack reconnaissance
and planning in order to render the ﬁnal attack action harmless
or ineffective.

Motivated by recent advances in cyber deception research, we
in this paper provide a formal view of cyber deception, and review
high-level deception schemes and actions. We also summarize
and classify recent research results of cyber defense techniques
including game-
built upon the concept of cyber deception,
theoretic modeling at the strategic level, network-level deception,
in-host-system deception and cryptography based deception.
Finally, we lay out and discuss in detail the research challenges
towards developing full-ﬂedged cyber deception frameworks and
mechanisms.

I. INTRODUCTION

As the convergence of our physical and digital worlds grows
quickly, more and more information becomes available and it
is a critical task to protect today’s information technology (IT)
systems and the information they carry. Recent high-proﬁle
hacking events (e.g., 2014 Sony Pictures hack [1] and 2016
Democratic National Committee email hack [2]) and steadily
increasing statistics of cyber attackers [3] have shown that our
current cyber defense is inadequate to combat more prevalent
and sophisticated cyber attacks.

From an attacker’s perspective, a cyber kill chain [4], [5]
consists of a number of attack stages, from the reconnais-
sance stage to understand a computer network system towards
the ﬁnal stage to launch effective attacks. Traditional cyber
defense mechanisms for computer and network systems have
been largely reactive in nature, and have extensively addressed
attack detection and mitigation after the attack action, but
offers ineffective countermeasures at early stages in the cyber
kill chain.

Recently, proactive strategies have been proposed to counter
cyber attacks in their early stages. Such strategies can be
mainly categorized into two types: 1) moving target defense
(MTD, e.g., [5]–[9] and 2) cyber deception (e.g., [10]–[13]).
With the same objective to defeat attacks, MTD and cyber
deception entail different defense procedures:MTD focuses on
dynamically changing the attack surface (e.g., system setups
or conﬁgurations) such that an attacker cannot observe and

identify accurate information during the attack reconnaissance
stage, which can make any attack action hardly effective.
Cyber deception aims at injecting intentionally falsiﬁed infor-
mation to mislead the attackers during their attack planning
stage. For example, the early honeypot systems [11], [12]
intend to attract potential attackers to waste their time while
in the meantime trying to learn attackers’ strategies.

Compared to MTD, cyber deception has several advantages
and can be more effective when used appropriately [14]. There
are a number of cyber deception based strategies created in the
literature to protect computing or network systems, showing
the promising potential of cyber deception to be adopted as a
mainstream proactive cyber defense technique. Motivated by
the recent research progress, we aim to take a formal look at
cyber deception, and review common deception schemes and
actions. In particular, the following issues are discussed in this
paper.

• Top-level model of cyber deception: we ﬁrst describe the
stages of one-round deception model, and then review the
common deception schemes and actions.

• State-of-the-art: we summarize recent research results
of cyber defense techniques built upon the concept of
cyber deception in the literature, including game-theoretic
modeling at the strategic level, network deception ap-
proaches, in-host-system deception schemes and ﬁnally
cryptography based deception methods.

• Major research issues and challenges: we identify major
research issues associated with cyber deception, and
discuss each issue in detail.

The rest of the paper is as follows. In Section II, we review
the top-level models of cyber deception. In Section III, we
categorize recent research results leveraging cyber deception
in the literature. In Section IV, we outline and discuss the
major research issues going forward. Finally, we conclude this
paper in Section V.

II. HIGH-LEVEL MODELS OF CYBER DECEPTION

In this section, we review the high-level models of cyber
deception. We ﬁrst discuss the three phases of one round of
deception, and summarize common deception schemes and
actions.

Zhuo Lu and Shangqing Zhao are with the Department of Electrical
Engineering, University of South Florida, Tampa FL 33620, USA. E-mails:
{zhuolu@, shangqing@}usf.edu.

Cliff Wang is with the Department of Electrical and Computer Engi-
neering, North Carolina State University, Raleigh NC 27695, USA. Email:
cliffwang@ncsu.edu.

A. Model of One-Round Deception

Cyber deception strategies are “planned actions taken to
mislead and/or confuse attackers and to thereby cause them to
take (or not take) speciﬁc actions that aid computer security
defenses.” [15]. In practice, an attacker may keep probing

 
 
 
 
 
 
to a target system to ﬁnd potential vulnerability to exploit,
while a defender may choose to update its system regularly
to defeat reconnaissance and potential exploits. The defense
framework based on cyber deception can be modeled as a two-
party interactive process. Attacker and defender engagement
consistently evolves over time. Defense using cyber deception
may never be a single action but quite often involve multiple
rounds of engagement to be effective.

For each round of cyber deception, it may include three-

phase actions [16], [17], as shown in Figure 1.

                          Phase I: Planning Deception
- Determine the goal of deception under the context of 
cyber defense and define deception strategy
- Plan deception interactions with attackers in order to 
engage and identify the attackers' biases

Preplanning
/Redesign 
based on 
feedbacks
for the 
next-round

       Phase II: Implementing & Deploying Deception
- Implement all essential components to deploy a 
deception scheme and to engage with adversaries 

            Phase III: Monitor the feedback channels 
- The defender monitors feedbacks to understand and 
profile the behavior of attackers, to identify biases of 
adversaries, to assess deception scheme success and 
based on all above to plan for potential next round of 
deception

Believed

Suspected

Disbelieved

Fig. 1. One-round model of deception defense.

• Phase I (planning deception). During the planning phase
of deception, based on the initial knowledge of adver-
saries such as their intents, interests and capabilities, de-
fenders would ﬁrst specify the goal of the deception that
could reasonably be expected as achievable. A deception
plan would include the design on how to engage with
the attackers and the deception information that could be
used to create cognitive biases [14], which is the key to
the success of the overall deception-based defense.
The defender would carefully balance the details of
the deception plan (e.g., the amount and type of truth
disclosure, combined with biased information in order to
deceive, potential risks to confuse regular users, and the
overhead involved) to maximize the success rate of the
deception strategy while trying to minimize the impact to
normal operations.

• Phase II (implementing and deploying deception). In this
phase, the deception scheme is implemented. Depend-
ing on the deception plan, deception components could
contain both devices (hosts or servers), information on
devices, and communications among devices. For more
advanced adversaries, defenders may also need to pay
attention to side channels so that the deployed deception
scheme will be as foolproof as possible.

2

• Phase III (monitoring and evaluating deception outcome)
is the ﬁnal phase of one round of deception. Since
deception based defense focuses on manipulating the
adversary, it is essential to keep tracking of the attacker’s
behavior and observing the reaction of the attacker after
deception is applied.
Deception by nature is a mental game between attackers
and defenders. While defenders try to guide attackers into
the wrong way, an intelligent attacker could potentially
suspect or even detect part of the deception scheme
and make adjustment to their actions accordingly. By
carefully monitoring feedbacks such as behavior changes
of attackers, defenders can assess the cognitive state of
the adversary and estimate the outcome of the current
deception action.

By carefully evaluating feedbacks, the defenders will deter-
mine the outcome of deploying the current round of deception:
(i) believed, when the deception scheme has successfully
introduced biases to the attacker; (ii) suspected, when the
attacker detects some abnormal signals and may not fully
believe the intended fake information; and (iii) disbelieved,
when the attacker identiﬁes that the deception strategy is being
used. This represents a total failure of the defender. The third
scenario creates a challenging situation for the defender: the
hard decision is whether to exit the deception scheme com-
pletely, or to start a brand new deception game. On the other
hand, the defender’s assessment on the deception outcome
depends on the quantity and quality of feedbacks. When the
feedbacks are lacking or have a high level of uncertainties,
defenders can only make the best educated guess.

B. Deception Schemes and Common Actions

Deception-based cyber defense relies on two main types of
actions: information simulation and dissimulation. Information
dissimulation is commonly used to hide information. Common
methods include masking, repackaging, and dazzling [18].

• Masking: Masking attempts to hide or erase crucial
information from the target in order to escape detection.
Data masking techniques, such as shufﬂing, substitution
and encryption, are commonly used to protect critical
information such as personal identiﬁable data.

• Repackaging: Repackaging refers to the transformation
of key characteristics of the target so that they look
irrelevant or different from the original, hoping that the
attack’s attention may be distracted away from the target.
IP address hopping [19] is a recent repackaging technique
such that hosts on a network will constantly have different
IP addresses and that network ﬂows cannot be easily
tracked by adversaries.

• Dazzling: Dazzling blurs or obscures key elements of
the target without removing them in order to confuse
the target with other objects. For example, software
obfuscation obscures critical sections of either source or
running code and has been used as a common practice in
defending against reverse engineering [20], [21].

Information simulation involves mimicking, inventing, and
decoying techniques [22]. The objective of simulation is to

create and use false information to distract and to mislead
adversaries.

• Mimicking: Creation of a fake entity through imitation
by duplicating key characteristics or identity of another
real entity. It is one of the most widely used simulation
methods. For example, a honeypot [12] can mimic a real
web site.

• Inventing: Creation of non-existent entities with key
elements and key characteristics that look real. There
are subtle differences between mimicking and inventing.
While the primary requirement of mimicking is to create
a fake entity that should look like the original entity,
invention creates a new entity that looks realistic.

• Decoying: Decoying has been a widely-used method
among all simulation techniques. A decoy is normally an
object that just looks or behaves like a genuine object. It
is used to distract attention to something different from
the real target. For example, a decoy web server can
be used to attract attackers. Decoying, mimicking and
inventing are often used together. A decoy server could be
mimicking the function of a real server of an organization
(i.e., a honey pot), or it could be invented just for the
purpose of distraction.

Both information simulation and dissimulation techniques

are often combined in a real world deception scheme.

III. CURRENT RESEARCH AND APPLICATIONS BASED ON
CYBER DECEPTION

Cyber attack and defense are an endless arms race. In a
cyber deception game, both the defender and the attacker
are trying to outsmart each other. In this section, we review
recent techniques that leverage the idea of cyber deception
to defend against potential intrusions. As shown in Fig. 2,
current research can be summarized into four categories: game
theoretic based modeling at the strategic level, network-level
deception, host or device level deception, and cryptography-
based deception. In the following, we review and summarize
these four categories individually.

Cyber-deception based strategies in computer/network system

3

a multistage Stackelberg game has been adopted for creating
deceptive routing strategies in order to defeat jamming in
multi-hop wireless networks. The deception framework models
the scenario where the defender ﬁrst deploys a proactive
defense strategy, and then the adversary follows the protocol.
Since the adversary is always resource limited, if the adversary
wastes its limited resources, such as jamming power on the
fake ﬂow, the real data packets will have a much higher chance
of arriving at the destination uninterrupted. Adopting a game
model between the sending source node and the jammer helps
the trade-off study between the deception cost and the impact,
and allowed the defender to devise the most effective strategy
against jamming.
More recently,

idea has been applied to
Internet of Things (IoT) systems. A Bayesian game model is
proposed in [26] to represent the interactive deception process
involving the attacker and the defender. Because both players
are willing to change their strategies upon learning from
previous assessments, a repeated game model that enables the
update of players’ decisions has shown to be efﬁcient under
the Bayes setting.

the honeypot

B. Network-Level Deception

Under a typical network attack scenario, an adversary wants
to gain control (or to disable) a valuable target in the network
by ﬁrst scanning the network, then hacking into a vulnerable
system to gain access to more devices in the network from
the initially compromised device. To prevent the adversary
from successfully penetrating the network, the defender using
cyber deception needs to engage with the attacker through
the inspection of the incoming packets and try to identify the
attacker’s intent and capability, and then respond through a
combined action of denying access to critical systems and
staging misleading information to confuse attackers.

Network-level 
deception

Topology info

Host info

Traffic info

Game theoretic 
based modeling

In-host-system 
deception

Network-level 
deception

Cryptography 
based deception

Fig. 3. Network-level information can be potentially manipulated or fabricated
to serve the deceptive purpose.

Fig. 2. Categories of recent research results based on cyber deception.

A. Game-theoretic Modeling at the Strategic Level

Game theory has been widely adopted at the strategy level
to model the interactions between the defender and the attacker
under varying security settings [23]–[25]. For example, [24]
modeled the defender-attacker interaction as a signaling game
with non-cooperative two players. The research focused on
establishing a dynamic game with incomplete information,
and employed deceptive equilibrium strategies for network
defense. In [25],

Several types of network-level information can be poten-
tially manipulated or fabricated to serve the deceptive purpose,
as shown in Fig. 3.

• Network topology information. The work in [27] pro-
posed using modiﬁed network topology response to de-
ceive an adversary’s traceroute probe, which has been
used often by the adversary as the ﬁrst step to discover
the forward path of data packets.
Through the investigation of two strategies (random and
intelligent deceptions), [27] showed that
the random
deception scheme can add noise to distort the adver-
sary’s topology discovery; while the intelligent deception

approach produces a believable, but incorrect network
topology to mislead the adversary.

• Network host information. In [28], a mobile honeypot
system for industrial control systems was introduced.
This system can be placed in many network locations
to provide an additional layer of defense to disrupt at-
tacker’s reconnaissance activities. In addition the system
can provide the defender with an early notiﬁcation of
incoming attacks.
Network tarpits [29] have been used as a form of defen-
sive cyber deception to masquerade as many fake hosts
as possible to deceive or to confuse network scanner. It
is worth noting that in [30], an active probing detector
Degreaser was developed to detect tarpits based on packet
ﬁngerprinting. Degreaser could be potentially used by an
attacker as a detection tool. It is critical to revise current
generation of tarpits to continue using the technique as a
network security mechanism.

• Network trafﬁc information. The work in [31] proposed
an adaptive approach to deceive an attacker that actively
collects trafﬁc data in an attempt to obtain system ﬁn-
gerprints and to ﬁnd a potential target. The proposed de-
ceptive defense approach manipulates outgoing trafﬁc so
that it resembles trafﬁc generated by a host with different
system proﬁles (e.g., operating system and service).
The work in [32] presented a new approach for self-
conﬁguring honeypots that can carry out passively check
on network trafﬁc of cyber-physical systems (CPS) and
adjust to the sensing environment to create deceptive
network entities that can be used to attract malicious
players.

C. In-host-system Deception

In-host-system deception quite often lets the attacker enter a
target system in a controlled manner. The deception setting in
the target system can be used not only to mislead the attacker,
but also help defenders to gather essential information about
the attacker who has entered the system.

A typical example of in-host-system deception is honey
patching proposed in [33], which reformulates traditional
security patches into honey-patches that can confuse attackers
by making it difﬁcult for them to determine if a potential
compromise has been made successfully or not. When a
system detects an attempt to exploit, the honey patch redirects
the attacker to an un-patched decoy where the attack is
allowed to proceed. In the meantime, the decoy setting allows
the defender to gather information about the attack and to
potentially identify previously unseen malware. In addition,
using decoy, misinformation can be presented to the attacker
through falsiﬁed data or system settings.

Another recent work of in-host-system deception called
honeywords [13] generates extra hashed fake passwords for
each user’s account in a system. Even when a ﬁle containing
hashed passwords was compromised and the hash value could
potentially be reversed, an adversary still cannot tell a real
password from a similar-looking honeyword. This approach
effectively adds another layer of defense to password ﬁle

4

protection. In addition, when the adversary tries to use the
cracked, but wrong password, the system will instantly recog-
nize the password hacking attempt.

D. Cryptography based Approach

Recently, a new cryptographic primitive known as honey
encryption is introduced to help enhance system resilience
against brute force attacks [34], [35]. A honey-encrypted
ciphertext has a unique property that an attacker could use
a wrong key to yield a valid-looking output message, but the
attacker cannot distinguish whether it is the correct plaintext
or not. By adopting the honey encryption scheme, the defender
can defeat brute-force attackers when they try to guess keys
randomly. A recent application called Honey Chatting has been
proposed in [36] to combat eavesdropping attacks by applying
honey encryption to chatting applications. Honey encryption
ensures that an attacker will not be able to verify if a right key
is used to decrypt a chatting message thus cannot determine
the exact content of the message.

The application of honey encryption relies on a highly
accurate distribution transforming encoder (DTE) over the
message space. Unfortunately, the use of DTE severely im-
pacts the practicality of honey encryption, mainly due to its
inapplicability to more complicated structured data. Building
an efﬁcient and precise DTE is the main challenge when
extending honey encryption into a varieties of practical ap-
plications. The work in [37] constructed an efﬁcient DTE
for genomic data that offers an information-theoretic security
guarantee against message-recovery attacks.

IV. MAJOR RESEARCH ISSUES GOING FORWARD

Although the use of deception to enhance cyber defense
has shown a number of interesting and promising results, it
is still an under-explored area. There are many interesting
research topics that await further investigation. In this section,
we discuss key research issues that need to be addressed and
identify steps going forward towards the goal of establishing
the scientiﬁc foundation of a full-ﬂedged cyber deception
framework for practical applications.

A. Precise Adversarial Model

Understanding adversaries is essential for a cyber deception
scheme to succeed. However, obtaining a good understanding
of adversaries has proven to be a huge challenge. A clear
deﬁnition of the adversary model has long been desired. It
will serve as a key basis for creating, analyzing and assessing
a cyber defense technique [38]. We need a precise adversarial
model for both creating a deception scheme and evaluating its
effectiveness.

Current deception techniques often exploit cognitive biases
of adversaries [14]. To be able to do that, defenders need
to learn as much as possible about the cognitive state of an
adversary which may include relevant information on knowl-
edge, capability, intent, and decision process, and any biases
from social/cultural factors and other surrounding issues. The
cognitive state model is usually individualized, making it hard

to generalize. However, a good human model for adversary
cognitive state estimation is essential for deception design and
deployment, because key elements of any successful deception
scheme is to exploit biases of adversaries’ cognitive state and
leverage the weaknesses of their decision making process to
our advantage.

Unlike MTD schemes which depend on creating compu-
tational complexity to increase attack difﬁculty and cost to
defeat adversaries, deception relies on a better understanding
of our opponents, especially their weaknesses and biases in
knowledge and decision making process so that they could be
exploited accordingly.

B. Continuous, Multi-round Engagement

As noted in Section II, cyber deception can be considered
as a two-party interactive game over time, where the defender
must keep engaged with the attacker. However, it could be
very challenging or sometimes even impossible to collect
information about a potential attacker whom we have not
been interacted with [14] before. As a result, people tend to
think that cyber deception may not provide a good defense
against zero-day attacks. However, this line of thinking may
be faulty since to exploit zero-day attacks, adversaries still
need to go through probing, learning and planning stages of
their cyber kill chain. A key reason for having zero-day attacks
is because the defender is unaware of the early actions taken
by the attackers. Proactive strategies, such as cyber deception,
aim to change that by emphasizing early engagement with
adversaries. From that perspective, cyber deception schemes
are extremely valuable for defending against future zero-day
attacks because the ﬁrst phase of cyber deception is to engage
and gain the knowledge of an adversary as much as possible,
and as early as possible.

To engage with adversaries during their reconnaissance
phase, defenders can proactively craft honeypot- or honeynet-
like systems that may attract adversaries’ probing and lever-
age the interactions to learn more of their intent and their
techniques.

Based on initial information learned, defenders can update
their “honey” schemes to gain more knowledge. This suggests
that the defender-attacker engagement can and should involve
multiple rounds of interactions where defenders would adapt
their system dynamically. The honey system can be adjusted
based on initial knowledge on the adversaries. In the mean-
time, the system can start staging false information while being
probed. This ﬁts the thinking behind early work on game
theoretic approaches to establish trade-off principles between
truth disclosure and fake information projection [17], [24]
that may help guide honey system interactions and adversary
engagement.

C. Manipulation of Adversarial Mind

5

challenging process which has not been studied extensively. In
prior psychology research, human mind manipulations through
persuasion and inﬂuences have been studied [41]. However,
these approaches are mostly through direct human interactions,
including both verbal and non-verbal communications. In the
cyber deception domain,
the manipulation or inﬂuence is
mostly through carefully planned cyber artifacts such as fake
ﬁles, fake devices, and fake information.

In modern control theory [39], [40], controllability and
observability are two key concepts that have been used to
determine whether a physical system can be measured and
controlled, and how successful the control attempt will be.
Observability refers to the ability to see and measure system
attributes and to determine internal states, while controllability
refers to the capability to change the target system to the
desired state. The same two concepts may also apply to
cyber deception and be used to quantify the ability to observe
adversaries and the degree of manipulation that can be reached.
It is highly desirable to get as much observability of the de-
ception target as possible, in order to apply deception schemes
effectively to drive an adversary’s mindset into the “desired”
wrong state. The key research question still remains on how
to formally deﬁne “observability” with regards to a human
adversary’s understanding and “controllability” that can be
used to quantify the effectiveness of deception schemes. Initial
research has touched upon integrating human factors in cyber
security [42], [43] as well as using control theory to interpret
human behavior [44], but substantial new research needs to be
carried out from the security and deception perspective with
human factors in the loop, and with a possibility of leveraging
insights gained from the rich set of modern control theory [39],
[40] to interpret and measure cyber deception.

D. Usability Analysis and Quantiﬁcation

Usability of an information system refers to the degree of
ease, effectiveness, and efﬁciency that users can learn and use
the intended functions provided by such a system [45]. It is
one of the most important metrics that any information system
designer needs to pay attention to, including proactive cyber
systems. Initial study has shown that any security process
needs to incorporate user experience into consideration in
order for it to be successful [46]. When creating and deploying
proactive techniques such as deception to thwart potential
attacks, it is important to include usability in metrics to quan-
tify the success of a deception scheme. Deception is meant
to disrupt, distract and mislead adversaries through selected
true and fake information setup and disclosure. However,
a deception scheme needs to ensure that it will make the
minimum impact to normal users. Key questions such as on
how to prevent average users from being confused or even
disrupted by deception information are largely untouched.

The ultimate goal of cyber deception is to manipulate
adversaries’ decision process and to mislead them into wrong
actions. Although manipulating or controlling a physical sys-
tem has been studied extensively in the ﬁeld of control theory
[39], [40], manipulation of human decision process is a much

Attack surface quantiﬁcation [47] provides us with a good
measurement of MTD effectiveness. However, metrics for
deception are yet to be deﬁned. It is our belief that any
deception effectiveness measurement should also incorporate
usability impact.

6

E. Combining Deception and MTD Approaches

[10] C. P. Stoll, The cuckoo’s egg: Tracking a spy through the maze of

Cyber deception and MTD schemes have received lots of
research interests recently. There were over 40 MTD schemes
based on a 2013 survey report [48], and the number of scheme
is much higher today. In the meantime, deception schemes
are gaining popularity and often combined with MTD as a
complementary method. When MTD is adopted to increase
diversity and complexity of a target system, deception can
augment MTD by adding fake setups for better defense. While
MTD makes it harder and more expensive for adversaries to
observe and attack, deception will distract and mislead in the
meantime.

To disrupt the adversaries’ cyber kill chain, both schemes
can be used at the same time or at different stages. For
example, recent works on network anti-inference [49], [50]
suggest combining both MTD technique (i.e., dynamic change
of network routing) and deception technique (i.e., adding fake
network trafﬁc) to effectively disrupt adversaries’ capability
to identify network ﬂows and to determine critical nodes
of the network. In addition, both techniques can be applied
at different stages: while both MTD deception can mislead
adversaries’ reconnaissance efforts, MTD can further increase
the complexity and difﬁculty for them to penetrate a system.
More research is needed on how to combine both methods
seamlessly and to maximize protection.

V. CONCLUSION

In this paper, we reviewed emerging cyber deception re-
search from high-level concepts to detailed techniques devel-
oped recently for protecting computer and network systems.
Cyber deception has shown its promising use but is still in its
infancy with many challenging issues to be addressed. More
research efforts will be needed to lay a solid scientiﬁc foun-
dation that spans multiple disciplines including computer and
network security, cryptography, control theory, and cognitive
science.

REFERENCES

[1] Wikipedia, “Sony Pictures hack,” https://en.wikipedia.org/wiki/Sony

Pictures hack.

[2] ——, “2016 Democratic National Committee email leak,” https://en.
wikipedia.org/wiki/2016 Democratic National Committee email leak.
[3] Verizon, “Threats on the horizon - the rise of the advanced persistent

threat,” http://goo.gl/ZnuJ9g.

[4] C. Croom, “The cyber kill-chain: A foundation for a new cyber-security

strategy,” High Frontier, vol. 6, no. 4, pp. 52–56, 2010.

[5] K. Zaffarano, J. Taylor, and S. Hamilton, “A quantitative framework
for moving target defense effectiveness evaluation,” in Proc. of ACM
Workshop on Moving Target Defense, 2015, pp. 3–10.

[6] J. H. Jafarian, E. Al-Shaer, and Q. Duan, “Openﬂow random host
mutation:
transparent moving target defense using software deﬁned
networking,” in Proc. of Workshop on Hot Topics in Software Deﬁned
Networks, 2012, pp. 127–132.

[7] M. Crouse, B. Prosser, and E. W. Fulp, “Probabilistic performance
analysis of moving target and deception reconnaissance defenses,” in
Proc. of ACM MTD, 2015.

[8] T. E. Carroll, M. Crouse, E. W. Fulp, and K. S. Berenhaut, “Analysis
of network address shufﬂing as a moving target defense,” in Proc. of
IEEE ICC, 2014.

[9] S. Jajodia, A. K. Ghosh, V. Swarup, C. Wang, and X. S. Wang, Moving
target defense: Creating asymmetric uncertainty for cyber threats.
Springer Science & Business Media, 2011, vol. 54.

computer espionage. Doubleday, 1989.

[11] N. C. Paxton, D. I. Jang, S. Russell, G. J. Ahn, I. S. Moskowitz, and
P. Hyden, “Utilizing network science and honeynets for software induced
cyber incident analysis,” in Proc. of HICSS, 2015.

[12] L. Spitzner, “Honeypots: Sticking it to hackers,” Network Magazine,

vol. 18, no. 4, 2003.

[13] A. Juels and R. L. Rivest, “Honeywords: Making password-cracking

detectable,” in Proc. of ACM CCS, 2013.

[14] C. Wang and Z. Lu, “Cyber deception: Overview and the road ahead,”

IEEE Security and Privacy, vol. 16, pp. 80–85, 2018.

[15] J. J. Yuill, Defensive computer-security deception operations: Processes,

principles and techniques. ProQuest, 2006.

[16] M. H. Almeshekah and E. H. Spafford, “Planning and integrating

deception into computer security defenses,” in Proc. of NSPW, 2014.

[17] K. E. Heckman, F. J. Stech, B. S. Schmoker, and R. K. Thomas, “Denial
and deception in cyber defense,” Computer, vol. 48, no. 4, 2015.
[18] S. Grazioli and S. L. Jarvenpaa, “Deceived: under target online,”
Communications of the ACM, vol. 46, no. 12, pp. 196–205, 2003.
[19] E. Al-Shaer, “Toward network conﬁguration randomization for moving
Springer, 2011, pp. 153–

target defense,” in Moving Target Defense.
159.

[20] N. Kuzurin, A. Shokurov, N. Varnovsky, and V. Zakharov, “On the
concept of software obfuscation in computer security,” in Proc. of
International Conference on Information Security, 2007, pp. 281–298.
[21] B. Barak, O. Goldreich, R. Impagliazzo, S. Rudich, A. Sahai, S. Vadhan,
and K. Yang, “On the (im)possibility of software obfuscation,” Crypto,
pp. 1–18, 2001.

[22] J. B. Bell and B. Whaley, Cheating and deception.

Transaction

Publishers, 1991.

[23] M. H. Manshaei, Q. Zhu, T. Alpcan, T. Bacs¸ar, and J.-P. Hubaux, “Game
theory meets network security and privacy,” ACM Computing Surveys,
vol. 45, no. 3, p. 25, 2013.

[24] T. E. Carroll and D. Grosu, “A game theoretic investigation of deception
in network security,” Security and Communication Networks, vol. 4,
no. 10, 2011.

[25] Q. Zhu, A. Clark, R. Poovendran, and T. Basar, “Deceptive routing

games,” in Proc. of IEEE CDC, 2012.

[26] Q. D. La, T. Quek, J. Lee, S. Jin, and H. Zhu, “Deceptive attack and
defense game in honeypot-enabled networks for the Internet of Things,”
IEEE Internet Things J., 2016.

[27] S. T. Trassare, R. Beverly, and D. Alderson, “A technique for network

topology deception,” in Proc. of IEEE MILCOM, 2013.

[28] E. Vasilomanolakis, S. Srinivasa, and M. Muhlhauser, “Did you really
hack a nuclear power plant? an industrial control mobile honeypot,” in
Proc. of IEEE CNS, 2015.

[29] Wikipedia, “Tarpit (networking),” https://en.wikipedia.org/wiki/Tarpit

%28networking%29.

[30] L. Alt, R. Beverly, and A. Dainotti, “Uncovering network tarpits with

degreaser,” in Proc. of ACSAC, 2014.

[31] M. Albanese, E. Battista, and S. Jajodia, “A deception based approach
for defeating OS and service ﬁngerprinting,” in Proc. of IEEE CNS,
2015.

[32] T. Vollmer and M. Manic, “Cyber-physical system security with de-
ceptive virtual hosts for industrial control networks,” IEEE Trans. Ind.
Informat., vol. 10, no. 2, May 2014.

[33] F. Araujo, K. W. Hamlen, S. Biedermann, and S. Katzenbeisser, “From
patches to honey-patches: Lightweight attacker misdirection, deception,
and disinformation,” in Proc. of ACM CCS, 2014.

[34] A. Juels and T. Ristenpart, “Honey encryption: Encryption beyond the
brute-force barrier,” IEEE Security Privacy, vol. 12, no. 4, 2014.
[35] ——, “Honey encryption: Security beyond the brute-force bound,” in

Proc. of Crypto, 2014, pp. 293–310.

[36] J. I. Kim and J. W. Yoon, “Honey chatting: A novel instant messaging
system robust to eavesdropping over communication,” in Proc. of IEEE
ICASSP, 2016.

[37] Z. Huang, E. Ayday, J. Fellay, J.-P. Hubaux, and A. Juels, “Genoguard:
Protecting genomic data against brute-force attacks,” in Proc. of IEEE
S&P, 2015.

[38] G. Cybenko, S. Jajodia, M. P. Wellman, and P. Liu, “Adversarial and
uncertain reasoning for adaptive cyber defense: Building the scientiﬁc
foundation,” in Proc. of International Conference on Information Sys-
tems Security, 2014, pp. 1–8.

[39] D. P. Bertsekas, D. P. Bertsekas, D. P. Bertsekas, and D. P. Bertsekas,
Dynamic programming and optimal control. Athena Scientiﬁc Belmont,
MA, 1995, vol. 1, no. 2.

7

[40] Z. Bubnicki, Modern control theory.

Springer Science & Business

Media, 2005.

[41] K. Hogan, The psychology of persuasion: how to persuade others to

your way of thinking. Pelican Publishing, 2010.

[42] E. Schultz, “The human factor in security,” Computers & Security,

vol. 24, no. 6, pp. 425–426, 2005.

[43] B. M. Bowen, R. Devarajan, and S. Stolfo, “Measuring the human factor

of cyber security,” in Proc. of IEEE HST, 2011, pp. 230–235.

[44] C. S. Carver and M. F. Scheier, Attention and self-regulation: A control-
Springer Science & Business

theory approach to human behavior.
Media, 2012.

[45] J. Nielsen, “Usability 101: Introduction to usability,” 2003.
[46] L. F. Cranor and N. Buchler, “Better together: Usability and security
go hand in hand,” IEEE Security & Privacy, vol. 12, no. 6, pp. 89–93,
2014.

[47] P. K. Manadhata and J. M. Wing, “An attack surface metric,” IEEE
Trans. Software Engineering, vol. 37, no. 3, pp. 371–386, 2011.
[48] H. Okhravi, M. Rabe, T. Mayberry, W. Leonard, T. Hobson, D. Bigelow,
and W. Streilein, “Survey of cyber moving target techniques,” DTIC
Document, Tech. Rep., 2013.

[49] Z. Lu and C. Wang, “Network anti-inference: A fundamental perspective
on proactive strategies to counter ﬂow inference,” in Proc. of IEEE
INFOCOM, Apr. 2015.

[50] Z. Lu, C. Wang, and M. Wei, “On detection and concealment of critical
roles in tactical wireless networks,” in Proc. of IEEE MILCOM, Oct.
2015.

