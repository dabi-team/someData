2
2
0
2

n
u
J

5

]

R
C
.
s
c
[

1
v
6
5
1
2
0
.
6
0
2
2
:
v
i
X
r
a

Perspectives of Non-Expert Users on Cyber Security and Privacy:
An Analysis of Online Discussions on Twitter

Nandita Pattnaik∗, Shujun Li and Jason R.C. Nurse

aInstitute of Cyber Security for Society (iCSS), University of Kent, Canterbury, CT2 7NP, UK

A R T I C L E I N F O

A B S T R A C T

Keywords:
Security
Privacy
Home user
Social media
User behavior
Smart home
Machine learning
Data mining
Topic modeling
Sentiment analysis

Current research on users‘ perspectives of cyber security and privacy related to traditional and
smart devices at home is very active, but the focus is often more on speciﬁc modern devices such
as mobile and smart IoT devices in a home context. In addition, most were based on smaller-scale
empirical studies such as online surveys and interviews. We endeavour to ﬁll these research gaps
by conducting a larger-scale study based on a real-world dataset of 413,985 tweets posted by
non-expert users on Twitter in six months of three consecutive years (January and February in
2019, 2020 and 2021). Two machine learning-based classiﬁers were developed to identify the
413,985 tweets. We analysed this dataset to understand non-expert users‘ cyber security and
privacy perspectives, including the yearly trend and the impact of the COVID-19 pandemic. We
applied topic modelling, sentiment analysis and qualitative analysis of selected tweets in the
dataset, leading to various interesting ﬁndings. For instance, we observed a 54% increase in non-
expert users‘ tweets on cyber security and/or privacy related topics in 2021, compared to before
the start of global COVID-19 lockdowns (January 2019 to February 2020). We also observed an
increased level of help-seeking tweets during the COVID-19 pandemic. Our analysis revealed
a diverse range of topics discussed by non-expert users across the three years, including VPNs,
Wi-Fi, smartphones, laptops, smart home devices, ﬁnancial security, and security and privacy
issues involving diﬀerent stakeholders. Overall negative sentiment was observed across almost
all topics non-expert users discussed on Twitter in all the three years. Our results conﬁrm the
multi-faceted nature of non-expert users‘ perspectives on cyber security and privacy and call for
more holistic, comprehensive and nuanced research on diﬀerent facets of such perspectives.

1. Introduction

Peoples’ use of the internet has been increasing at a very fast pace in the past decades. A recent report from
Statista (Johnson, 2022b) informed that roughly 62% of the world population and 94% in Western Europe were using
the internet as of January 2022. In terms of computing devices they use to access the internet, another 2021 report from
Statista (Johnson, 2022a) found that almost 91% of global users used smartphones, followed by 71% using laptops
and/or desktop PCs, 30% from smart TVs and 14% from other smart home devices. The same report also showed
that most (65%) of global users accessed the internet from their own computing devices, while a signiﬁcant portion
(30%) used work devices. With the wide use of the internet and diﬀerent types of computing devices, cyber security
and privacy issues have also been increasing, and many internet users have developed some awareness of such issues,
especially on phishing and malware (Johnson, 2021a).

With the increasing use of the internet and computing devices by global users, and the consequent cyber security
and privacy issues, it is important to understand the perspectives of users regarding such topics. User perspective in
this context includes the levels of awareness, perception, concerns, decisions, behaviors, and day-to-day practice of
the users in relation to cyber security and privacy. Many researchers have conducted studies to better understand
users’ perspectives on cyber security and privacy. Related studies have mainly focused on two diﬀerent types of
users – ‘experts’ with a good level of cyber security knowledge and ‘non-expert users’ who normally lack cyber
security awareness (Rahman, Rohan, Pal and Kanthamanon, 2021). Diﬀerent aspects of non-expert users’ cyber
security behaviors have been studied by researchers, e.g., conscious/unconscious decisions of non-expert users to
recognize diﬀerent cyber threats (Kang, Dabbish, Fruchter and Kiesler, 2015; Wu and Zappala, 2018), ignoring
necessary updates of important software (Ion, Reeder and Consolvo, 2015), preferring not to use encryption (Wu

∗Corresponding author

np407@kent.ac.uk (N. Pattnaik); S.J.Li@kent.ac.uk (S. Li); J.R.C.Nurse@kent.ac.uk (Jason R.C. Nurse)
www.hooklee.com (S. Li)

ORCID(s): 0000-0003-1272-077X (N. Pattnaik); 0000-0001-5628-7328 (S. Li); 0000-0003-4118-1680 (Jason R.C. Nurse)

N. Pattnaik et al.: Preprint submitted to Elsevier

Page 1 of 18

 
 
 
 
 
 
Perspectives of Non-Expert Users on Cyber Security and Privacy: An Analysis of Twitter Discussions

and Zappala, 2018), hesitance about the use of MFA (multi-factor authentication) (Das, Wang, Kim and Camp, 2020)
and password managers (Alodhyani, Theodorakopoulos and Reinecke, 2020). Such insecure behaviors often lead to
security vulnerabilities (Jones, Lodinger, Widlus, Namin and Hewett, 2021). Most past studies primarily relied on
data self-reported by a relatively small number of recruited human participants, and often qualitative methods were
used due to the small scale of the empirical studies (Rahman et al., 2021). Results obtained from such smaller-scale
self-reported data normally cover only a narrow range of topics, and key ﬁndings can be diﬃcult to generalize to a
larger population of users. Therefore, working with larger-scale data collected from the wild, e.g., real-world data
collected from online social network (OSN) platforms, can help provide more evidence and insights supplementary
evidence to past studies (Andreotta, Nugroho, Hurlstone, Boschetti, Farrell, Walker and Paris, 2019). However, for
users’ perspectives of cyber security and privacy, such research is still relatively rare.

Furthermore, there has been a general trend of the focus on the computing devices covered, from more traditional
ones such as PCs and smartphones (Camp, 2009; Wash, 2010; Kang et al., 2015) to smart and IoT (Internet of Things)
devices more recently (Zheng, Apthorpe, Chetty and Feamster, 2018; Sturgess, Nurse and Zhao, 2018; Zimmermann,
Gerber, Marky, Böck and Kirchbuchner, 2019; Barbosa, Zhang and Wang, 2020; Chalhoub and Flechais, 2020;
Cannizzaro, Procter, Ma and Maple, 2020). Most related research in the literature arguably focused more on one type of
computing devices (e.g., smartphones or smart speakers), therefore do not cover the wider range of computing devices
modern users are using in diﬀerent contexts of cyber security and privacy.

This paper reports our analysis of nearly half a million tweets about non-expert users’ discussions on Twitter, one
of the largest OSN platforms, to provide a more holistic view of their perspectives on cyber security and privacy. We
chose to focus on non-expert users in our study, since the rich knowledge and diﬀerent mental models of cyber security
experts make them a less representative user group to study normal users’ perspectives (Camp, Asgharpour and Liu,
2008; Busse, Schäfer and Smith, 2019). The dataset covers three 2-month periods in three years (January and February
in 2019, 2020 and 2021), allowing us to look at yearly trends as well as changes before the ﬁrst global COVID-19
lockdowns and during the COVID-19 pandemic. More speciﬁcally, our research questions (RQs) are deﬁned as follows:

RQ1 How can we identify privacy and security related tweets posted by non-expert users?

RQ2 What do non-expert users normally discuss online, regarding their personal perspectives on cyber security and

privacy?

RQ3 How did such discussions on Twitter evolve in the past three years, including before and during the COVID-19

pandemic?

RQ4 What was the general sentiment of non-expert users when talking about cyber security and privacy on Twitter?

RQ5 To what extent did the general sentiment of non-expert users change in the past three years, including before and

during the COVID-19 pandemic?

Based on the above RQs, our main contributions can be summarized below:

1. We designed a machine learning based classiﬁer to detect speciﬁc tweets related to cyber security and privacy
with a good performance. To the best of our knowledge, past studies have focused on topics such as classiﬁcation
of cyber security related accounts (Mahaini, Li and Saglam, 2019) or cyber threats (Dionísio, Alves, Ferreira
and Bessani, 2019).

2. We also developed a second machine learning based classiﬁer to detect non-expert user accounts with a good

performance. We were unaware of any work on such classiﬁers.

3. By applying topical modeling to our dataset, we identiﬁed a wide range of topics non-expert users discussed
on cyber security and privacy, such as on VPNs, Wi-Fi, smartphones, laptops, smart home devices, ﬁnancial
security, and diﬀerent stakeholders.

4. A trend analysis of non-expert users’ discussions on cyber security and privacy across the three years showed
some noticeable changes of topics, e.g., a substantial increase of VPN use during the COVID-19 pandemic
compared with before it.

5. By applying sentiment analysis to the datasets and tweets belonging to diﬀerent topics, we revealed a general

negative sentiment of non-expert users when discussing cyber security and privacy on Twitter.

N. Pattnaik et al.: Preprint submitted to Elsevier

Page 2 of 18

Perspectives of Non-Expert Users on Cyber Security and Privacy: An Analysis of Twitter Discussions

6. A trend analysis of non-expert users’ sentiment across the three years revealed some previously unknown
patterns, e.g., the sentiment seemed to have become more polarized over years, with the percentage of more
neutral posts decreasing year on year.

The rest of the paper is organized as follows. After brieﬂy introducing some related work in Section 2, the methods
we used for this study are explained in detail in Section 3. Section 4 reports results and ﬁndings of the research, followed
by Section 5 in which further discussions, limitations of the research and our future work are presented. The last section
concludes the paper.

2. Related Work

With the growing level of social media activities, online users have been generating massive textual content (An-
dreotta et al., 2019), and researchers have been increasingly utilizing such user-generated content (UGC) to study
diﬀerent online phenomena (Yin and Kaynak, 2015). However, to the best of our knowledge, such studies have not
attracted suﬃcient attention from researchers working on users’ perspectives on cyber security and privacy. In this
section, we introduce some selected work we consider closely related.

Some researchers leveraged public data such as those on Twitter to study diﬀerent aspects of user perspectives in
cyber security and privacy. For instance, Saura, Palacios-Marqués and Ribeiro-Soriano (2021) explored the Twitter-
verse for cyber security issues commonly discussed by home users in the context of smart living environments.
Kowalczuk (2018) used a mixed method to analyze tweets and Amazon reviews of smart speakers users, and found
enjoyment as the primary reason of using smart speakers. Sriram, Li and Hadaegh (2021) conducted a cross-sectional
analysis on both Twitter and Reddit data to identify cyber security and privacy concerns of end users of IoT devices.
Zubiaga, Procter and Maple (2018) conducted a longitudinal study of tweets between 2009 and 2016 with topic and
sentiment analysis to understand the general public’s perception of IoT devices. Such research often focused speciﬁcally
on IoT and smart home devices, so did not cover the wide range of topics including devices that often feature in user
discussions.

Some other researchers used public data to monitor and analyze citizens’ feeling about security, which covers more
physical aspects such as crime in a neighborhood or a city. For instance, Chaparro, Pulido, Rudas, Reyes, Victorino,
Narvaez, Gomez and Martinez (2020) and Camargo, Torres, Martínez and Gómez (2016) explored Twitter data to
understand behaviors of online users from speciﬁc geo-locations. Greco and Polli (2021) proposed some methods for
calculating real-time public perception of cyber security measurement. Such work does not have a smart home focus.
Some researchers focused on privacy-related behaviors of online users, especially about unintentionally leaking
personal information on OSN platforms such as Twitter. For instance, privacy features were explored by Caliskan Islam,
Walsh and Greenstadt (2014) to detect users’ online behaviors and Aghasian, Garg and Montgomery (2020) to develop
a privacy scoring model for measuring such behaviors. Khazaei, Xiao, Mercer and Khan reported how online users
who would like to remain private online can be detected, so businesses can respect their privacy preferences. In
addition, some researchers also studied leakage of personal information via online users’ discussions, e.g., Sharma,
Karunanayake, Masood and Ikram (2022) (Sharma et al., 2022) reported that Twitter users often unintentionally
disclosed personal information online while discussing about the COVID-19 pandemic, as observed in four countries
(Australia, India, the UK and the US) and in three diﬀerent periods of the pandemic (before, during and after the
lockdown) in each country.

Another related research topic is machine learning based automatic detection of cyber security related discussions
on OSN platforms such as Twitter Alves, Bettini, Ferreira and Bessani (2021), Dionísio et al. (2019), Mittal, Das,
Mulwad, Joshi and Finin (2016). Most of these types of work are often OSINT (open source intelligence) related and
have normally a strong technical focus, instead of users’ perspectives.

As reviewed above, although some researchers have leveraged data collected from OSN platforms to study cyber
security and privacy related behaviors of online users, their focus is relatively narrow and did not look at a wide range
of topics online users discussed over time. This paper aims to ﬁll such a gap.

3. Methodology

As mentioned in Section 1, we decided to focus on online discussions of non-expert users to better capture their
perspectives on cyber security and privacy. This required us to develop two classiﬁers for detecting tweets related to
the topic (cyber security and privacy) and the user group (tweets posted by non-expert users), in order to address RQ1.

N. Pattnaik et al.: Preprint submitted to Elsevier

Page 3 of 18

Perspectives of Non-Expert Users on Cyber Security and Privacy: An Analysis of Twitter Discussions

We developed such two classiﬁers, tested their performance, and applied them to a large set of tweets collected using
the Twitter API to produce the dataset we worked with. Topical modeling, sentiment analysis and additional trend
analysis were then conducted on the dataset to answer RQs 2-5.

For each of the two classiﬁcation tasks, we trained and tested ﬁve candidate classiﬁers using a labeled dataset
in order to identify the best classiﬁer: 1) four traditional machine learning algorithms, including logistic regression,
support vector machines (SVM) with a radial basis function (RBF) kernel, random forest and XGBoost, working with
n-gram features, and 2) a BERT-based classiﬁer that can extract features via a more automated process.

The four traditional classiﬁers based on n-gram features were trained, 5-fold cross-validated and tested using Scikit-
learn (sckit learn), a popular open-source machine learning package. For the BERT-based classiﬁer, we chose the
‘BERT-base’ model with 110 million parameters, 12 transformer layers and 12 self-attention heads (Devlin, Chang,
Lee and Toutanova, 2018), implemented as part of the widely used library Huggingface (Hugging Face). We used
Google Colab’s NVIDIA Tesla P100-PCIE-16 GB GPU’s to run all classiﬁers.

3.1. Data Collection

We collected tweets using Twitter’s Academic API v21. Due to the rate limits of the API2, collecting tweets in all
the 36 months in 2019-2021 could take a long time, likely 36 weeks (more than 8 months) according to our experiments.
We therefore decided to collect tweets in a two-month period for each year. In order to decide which two representative
months to select, we considered two factors. Firstly, according to some recent statistics (Salesforce, 2021; Ward, 2022;
Sabanoglu, 2021), the level of product sales is often the highest in November and December, i.e., at the end of the year
just before the Christmas holiday period. If we assume that users would spend some time to use new devices during
the holiday period, they would more likely to share their experiences and to ask questions on social media in January
and February. Secondly, since we would like to collect data that can support comparison of online discussions of
English-speaking users before and during the COVID-19 pandemic, we looked at the time when the global lockdown
started worldwide. This seems to be in March 2020 for most countries where English-speaking users lived (BBC,
2020). Based on the two factors, we decided to choose January and February as the two-month period, which allowed
us to have two years before the ﬁrst wave of global COVID-19 lockdowns (2019 and 2020) and one year during the
pandemic (2021).

In order to retrieve relevant historical tweets in the past, we needed to use Twitter’s Search API, which required us
to use some keywords as search terms. Determining the most appropriate search keywords was not trivial, as non-expert
users do not use technical terms expert users would use for discussing cyber security and privacy related topics. Hence,
we decided to use some general computing keywords and names of diﬀerent computing devices non-expert users often
use at home. Rather than deﬁning such keywords ourselves, we used the following sources as the basis to derive such
keywords, in order to avoid any biases we may have.

1. Some keywords selected from an empirical study: We conducted an online anonymous survey with 50 participants
using the Proliﬁc survey platform3, on frequently used keywords by non-expert users while searching for cyber
security and privacy-related queries online. This survey was approved by the University of Kent’s Central
Research Ethics Advisory Group. Out of 144 keywords reported by the participants, we selected 23 ones based
on their nature (computing/security related term), and the frequency of use (used by more than one participant).
We avoided using too broad keywords such as ‘Google’, ‘Internet’ and ‘Windows’.

2. A number of lists of most used computing devices at homes reported in the research literature, including:

• a list of diﬀerent types of smart home devices shown in Table 3 of (Huang, Apthorpe, Li, Acar and Feamster,

2020a),

• a list of commonly used smart devices shown in Table I of (Gai, Azam, Shanmugam, Jonkman and De Boer,

2018),

• a list of smart devices used at home in multi-user scenarios, as shown in Table I of (Huang, Obada-Obieh

and Beznosov, 2020b),

• a list of smart devices shown in Figure 3 of (Cannizzaro et al., 2020), and

1https://developer.twitter.com/en/products/twitter-api/academic-research
2There were multiple limits for our approved Twitter Academic API account: 1 app per account, 10 million tweets / month per account, 300

requests / 15 minutes per app, 1 request / second per app, and 500 results per response.

3https://www.prolific.co/

N. Pattnaik et al.: Preprint submitted to Elsevier

Page 4 of 18

Perspectives of Non-Expert Users on Cyber Security and Privacy: An Analysis of Twitter Discussions

• a list of common devices owned by smart home users shown in Table 1 of (Zheng et al., 2018).

3. Commonly used computing devices included in the following reports from Statista:

• a 2020 report on market shares of electronic devices used by internet users in the UK to go online (O’Dea,

2021),

• a 2020 report on the average number of devices residents have access to in UK households (Laricchia,

2022),

• a 2020 report on devices used to access Wi-Fi in UK homes (Alsop, 2021), and

• a 2021 report on devices used by global users to access internet (Johnson, 2022a).

Based on the above sources and our general knowledge on relevant keywords and computing devices used by non-
expert home users, we derived 37 unique keywords: ‘account’, ‘Amazon Alexa’, ‘Amazon Echo’, ‘app’, ‘breach’, ‘e-
reader’, ‘Google Home’, ‘iPad’, ‘iPhone’, ‘android’, ‘laptop’, ‘smart mobile’, ‘password’, ‘smart TV’, ‘tablet’, ‘WiFi’,
‘Bluetooth’, ‘smart camera’, ‘smart watch’, ‘smart doorbell’, ‘smart switch’, ‘Chromecast’, ‘smart speaker’, ‘smart hub’,
‘smart light’, ‘printer’, ‘smart thermostat’, ‘VPN’, ‘smart kettle’, ‘smart refrigerator’, ‘smart washing machine’, ‘smart
meter’, ‘smart toy’, ‘smart door lock’, ‘smart baby monitor’,‘smart plug’, and ‘games console’.

Using the 37 keywords with Twitter’s Academic Search API, we obtained 13.7 million tweets for further processing.
We decided not to collect retweets as they include only repeated discussions. In other words, our collected data consists
of original tweets, replies and quoted tweets (without the quoted original tweet), and other meta-data such as ‘authorId’,
‘userName’, ‘createdAt’, ‘location’, ‘publicMetrics’.

3.2. Data Cleaning, Tokenization and Vectorization

To facilitate feature extraction for the candidate classiﬁers, we needed to conduct some pre-processing steps,
including data cleaning, tokenization and vectorization. Special characters, hyperlinks, references to audio and video
ﬁles and tweets without any text but only hashtags and/or mentions were taken out as a ﬁrst step of data cleaning.
Emojis were transferred to their equivalent words or phrases in English using the ‘emot’ library (Shah, 2022).

For the n-gram based classiﬁers, we also applied stop-word removal and lemmatization to prepare them for
tokenization. The processed data was then tokenized using the BOW (bag of word) method (Sethy and Ramabhadran,
2008) and vectorized using the TF-IDF (Term Frequency and Inverse Document Frequency) vectorizer of the Scikit-
learn library4 to prepare a matrix of TF-IDF features. This TF-IDF matrix is then fed into the four n-gram based
classiﬁers as input features.

The pre-processing of data diﬀered for the BERT-based classiﬁer since it works in a very diﬀerent way from the
traditional machine learning algorithms we used. BERT, a neural network-based encoder technique reported in Devlin
et al. (2018), works with a bidirectional contextual word embedding modeling method. The model essentially stacks a
series of encoder structures based on the transformer architecture (Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
Kaiser and Polosukhin, 2017) and pre-trains the model by masking out a certain percentage of the words, which forces
the model to learn the words. A deliberate retention of special characters such as question marks, exclamation marks and
commas were implemented and no stop-word removal techniques were used to maintain the BERT model’s original
eﬀectiveness (Hofstätter, Lipani, Zlabinger and Hanbury, 2020) as the model inherently calculates its algorithm by
using context-based attentions. Once the pre-trained model was loaded, it was ﬁne-tuned with the help of our context-
speciﬁc pre-processed tweets. This was then fed to the Hugging Face transformer library to implement TensorFlow’s
BERT-based sequence classiﬁcation module (Google, 2022) to classify our data.

After completion of the pre-processing steps, we noticed many duplicate tweets in our data, which were possibly
bot-generated. We decided to remove the duplicate tweets before any further processing. Finally, after the pre-
processing and deduplication procedure, we obtained 13.7 million tweets as the raw data for labeling and classiﬁcation
to produce the dataset of cyber security and privacy related tweets.

3.3. Developing Classiﬁers
3.3.1. Cyber Security and Privacy (‘CySecPriv’) Classiﬁer

To develop a classiﬁer, we ﬁrst need a labeled dataset. Based on our expert knowledge, we decided to use a number
of criteria to manually label a tweet as ‘CySecPriv’ or ‘NonCySecPriv’, depending on, if the tweet fulﬁls any of the
following point:

4https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html

N. Pattnaik et al.: Preprint submitted to Elsevier

Page 5 of 18

Perspectives of Non-Expert Users on Cyber Security and Privacy: An Analysis of Twitter Discussions

1. at least one term from the following established lists of cyber security and privacy related terms:

• https://www.ncsc.gov.uk/information/ncsc-glossary
• https://www.bsigroup.com/en-GB/Cyber-Security/Glossary-of-cyber-security-terms/
• https://www.getsafeonline.org/glossary/
• https://niccs.cisa.gov/about-niccs/cybersecurity-glossary

2. at least one keyword included in the list of terms of the cyber security taxonomy reported in (Mahaini et al.,

2019)5,

3. at least one hashtag related to any of the above terms, and
4. at least one phrase or sentence that clearly describes a cyber security or privacy related topic, i.e., a tweet like

‘my computer must have been infected after I downloaded a movie’6.

The labeling process was completed in two diﬀerent stages. First, 9,000 tweets (1,500 from each of the six months
in our dataset) were randomly selected and labeled by the ﬁrst author according to the above-mentioned criteria. This
led to an imbalanced dataset with only 5% of tweets being labeled CySecPriv. To produce a more balanced dataset for
training and testing purposes, we collected a set of 18,000 (3,000 from each month) tweets based on a diﬀerent set of
cyber security related keywords (within the scope of the ﬁrst two items of the list 3.3.1) and labeled them separately.
Some tweets (676) in this set were discarded because either they were duplicate tweets or they did not contain any real
original content excepting ‘@mentions’ and/or hashtags. Labeled data from both stages were combined to produce
our ﬁnal labeled dataset with 26,324 tweets, including 14,041 CySecPriv tweets and 12,282 NonCySecPriv tweets.
The database is still unbalanced, but not signiﬁcantly so. Our experiments showed that such a dataset already worked
relatively well, so we did not apply any over- or under-sampling to make the dataset perfectly balanced.

3.3.2. Non-Expert User Classiﬁer

For this classiﬁer, we followed a multi-class approach to label a Twitter account into four diﬀerent classes based

on its meta-data (username, display name, user proﬁle and location), as shown below.

1. Non-expert user: a user account satisfying both of the following criteria:

(a) the proﬁle is a personal account, indicated by the use of a ﬁrst-person pronoun (i.e., ‘I’, ‘me’) at least once,
or a noun or a phase representing a person, e.g., a name like ‘Bob’ or a relation such as ‘wife’ or ‘son’.
(b) the proﬁle clearly suggest that the account owner is not an expert on cyber security or privacy, e.g., if
the profession is declared to be ‘actor’, ‘painter’, ‘musician’ or ‘trader’. (There might of course be some
cases where the candidate does not declare themselves to be a security expert, but actually are in the oﬄine
world.)

2. Expert: a personal account (following the above criterion 1(a) for non-expert users) that used at least one
recognized cyber security or privacy related term (as described in the keyword list 3.3.1 of the CySecPriv
classiﬁer) to describe their work, education or expertise, e.g., ‘security expert’, ‘cryptographer’, ‘hacker’ or a
‘student studying a cyber security course’.

3. Non-Person: a user account that belongs to an organization, a group of people or a community.
4. Unknown: when the information in the user proﬁle is insuﬃcient to draw any conclusion about the type of

account.

To help facilitate the manual labeling process, we leveraged the widely used NER (named entity recognition) module
in the Spacy library (ExplosionAI GmbH) to automatically detect entities related to persons and organizations.

To support training and testing of the non-expert user classiﬁer, we sampled 10,200 accounts randomly from the raw
dataset and collected their meta-data. The meta-data was pre-processed to exclude non-ASCII characters and special
characters that are not exclamation marks, question marks, full stop signs, double and single quotation marks, and to
convert emojis into equivalent English phrases using the ‘emot’ library. The pre-processed meta-data was then input to
the NER module of SpaCy to detect any named entities. Taking the NER tags as useful references, the sample accounts
were then manually labeled by the ﬁrst author into the above-mentioned four classes, leading to 7,860 labeled as non-
expert users, 825 as experts, 1,143 as non-person, and 394 as unknown. The labeled dataset was highly imbalanced,

5https://cyber.kent.ac.uk/research/cyber_taxonomy/
6Note that this quoted tweet is an artiﬁcially created illustrative example to avoid exposing any real tweet in our dataset for data protection

reasons.

N. Pattnaik et al.: Preprint submitted to Elsevier

Page 6 of 18

Perspectives of Non-Expert Users on Cyber Security and Privacy: An Analysis of Twitter Discussions

Model

Precision

Recall

F1-Score

Model

Precision

Recall

F1-Score

BERT-based
Logistic Regression
SVM (RBF kernel)
Random Forest
XGBoost

0.92
0.90
0.92
0.94
0.90

0.92
0.84
0.76
0.61
0.86

0.91
0.87
0.83
0.74
0.88

BERT-based
Logistic Regression
SVM (RBF kernel)
Random Forest
XGBoost

0.94
0.83
0.68
0.70
0.73

0.95
0.90
1.0
1.0
0.98

0.94
0.86
0.81
0.83
0.84

(a) CySecPriv classiﬁer

(b) Non-expert user classiﬁer

Table 1
Performance comparison of diﬀerent machine learning models for the two classiﬁcation tasks of our work

Raw tweets collected (𝑛 = 17.4 millions)

Tweets after pre-process and de-
duplication (𝑛 = 13.7 millions)

CySecPriv tweets after applying the
CySecPriv classiﬁer (𝑛 = 1, 225, 406)

Total CySecPriv authors (expert + non-
expert users) (𝑛 = 662, 291)

Tweets posted by non-expert users
after applying the CySecPriv and Non-
Expert user classiﬁers (𝑛 = 413, 985)

Non-expert users posted CySecPriv tweets
(𝑛 = 319, 060)

Figure 1: The number of tweets after each step of the data curation process and the number of corresponding authors for
the last two steps

but we decided not to modify (over- or under-sample) it as current research has shown evidence (D’Sa, Illina and Fohr,
2020; Madabushi, Kochkina and Castelle, 2020; Oak, Du, Yan, Takawale and Amit, 2019; Aduragba, Yu, Senthilnathan
and Crsitea, 2020) that some machine learning models such as BERT-based ones can still work well with imbalanced
data. In addition, although being a multi-class classiﬁer, for our purpose it was used more like a binary classiﬁer
for detecting one class (non-expert users). For such a binary classiﬁer, the dataset imbalance is less serious: 7,860
vs. 825 + 1, 143 + 394 = 2, 362.

The labeled data was then fed as input to diﬀerent candidate classiﬁers to identify the best performing algorithm.
All ﬁve classiﬁers did reasonably well on the imbalanced dataset, although we found that the BERT-based classiﬁer
performed much better than the four traditional classiﬁers, as shown in Table 1. More detailed explanation on the
performance metrics of the classiﬁers are given in Section 4.

3.4. Applying Classiﬁers

After obtaining the trained and tested ‘CySecPriv’ and ‘Non-Expert User’ classiﬁers, we applied them sequentially
to the pre-processed dataset of 13.7 million tweets to produce the actual dataset for further analysis. The ﬁnal dataset
consists of 413,985 (3.01%) ‘CySecPriv’-related tweets written by 319,060 non-expert users. Figure 1 demonstrates
the number of tweets after each step of the data curation and the number of authors after applying the classiﬁers.

Due to the non-perfect accuracy of the classiﬁers, the dataset must also include a small portion of false positive
samples and have missed some false negative samples. Taking this into consideration, later we will avoid results that
can be aﬀected by such false positives, e.g., for topical modeling results, any topics with a small number of tweets may
be more aﬀected by false positives so become less reliable.

N. Pattnaik et al.: Preprint submitted to Elsevier

Page 7 of 18

Perspectives of Non-Expert Users on Cyber Security and Privacy: An Analysis of Twitter Discussions

3.5. Topic Modeling

Once we had the ﬁnal dataset, we investigated important topical areas that attracted non-expert users’ attention
(RQ2 and RQ3). We tried two popular topic modeling algorithms for this purpose: latent Dirilect allocation
(LDA) (Blei, Ng and Jordan, 2003) and non-negative matrix factorization (NMF) (Kuang, Choo and Park, 2015), both
having been widely used and NMF being reported to perform better in some tasks especially for processing shorter
texts like tweets (Chen, Zhang, Liu, Ye and Lin, 2019). We found that LDA provided semantically more interpretable
results compare to NMF, while NMF was generally faster in processing the outputs. As the interpretability of the results
is more important than speed for our purposes, we decided to use LDA as the topical modeling method. LDA requires
the number of topics as an input parameter, so we needed a way to determine the best value of the number. We used
Gensim7, a popular topic coherence model tool, to determine a relevant 𝑘 while processing all topic modeling cases. In
addition, an R package pyLDAvis (Sievert and Shirley, 2014) was used to visualize and interpret the results of LDA.
The LDA algorithm was used to analyze topics in our ﬁnal datasets in three diﬀerent ways: (1) tweets in all three
years together to get the overall picture, (2) tweets in each of the three diﬀerent years separately to allow yearly trend
analysis, and (3) 2019 and 2020 tweets combined vs the 2021 data to study any changes of topics before the global
COVID-19 lockdowns and during the pandemic.

3.6. Sentiment Analysis

To address RQ4 and RQ5, we conducted sentiment analysis on the ﬁnal dataset. We experimented with two
sentiment analysis algorithms, VADER (Valence Aware Dictionary for Sentiment Reasoning) analysis (Hutto and
Gilbert, 2014) that is a popular lexicon-based sentiment analysis library for Twitter-like datasets and ‘bert-base-
multilingual-uncased-sentiment’ (NLP Town), a BERT-based sentiment analysis algorithm implemented by the NLP
Town8 for the Hugging Face library. VADER classiﬁes an input text into three diﬀerent classes, i.e., ‘positive’,
‘negative’ and ‘neutral’, whereas the BERT-based algorithm produces a ﬁve-leveled sentiment score (between -2 and
2), with -2 being totally negative and 2 totally positive9. Results produced by the two algorithms are very diﬀerent, so
we decided to evaluate their performance against a manually constructed benchmark.

To decide which sentiment analysis algorithm to use, we conducted a comparison between them using some ground
truth labels for tweets with ‘positive’, ‘negative’ and ‘neutral’ sentiment. Such labels were produced by the ﬁrst author
of the paper by manually inspecting 500 randomly selected samples, which were classiﬁed as totally positive (2),
totally negative (-2) or neutral (0) by the BERT-based algorithm. The ground truth labels were compared with the
outputs from both sentiment analysis algorithms to calculate an agreement rate, i.e., the percentage of the ground truth
labels match the outputs of a given algorithm, as an accuracy metric. The results revealed that the BERT-based model
achieved an agreement rate of 71%, 10% higher than VADER that achieved an agreement score of 61%. The results
are aligned with results from past studies conducted by other researchers (Crocamo, Viviani, Famiglini, Bartoli, Pasi
and Carrà, 2021; Nemes and Kiss, 2021). Therefore, we decided to use the BERT-based algorithm for our sentiment
analysis experiments.

3.7. Qualitative Analysis

In order to gather more insights about some of the important topics we observed from our earlier quantitative
analysis we decided to conduct a qualitative analysis. Our methodology follows the four-phased approach proposed
in (Andreotta et al., 2019). We decided to qualitatively inspect randomly selected tweets belongings to six LDA
topics, including 1) four cyber security related topics that were frequently discussed in all three years – ‘VPNuse’,
‘DeviceAccSec’ and ‘WiﬁPass’, ’HomePrivSec’ and 2) two topics that appeared only in pre-Covid period (2019-
20) or during pandemic period in 2021 – ‘External Stakeholders’ 2019/2020 for 2019-20 and ‘HelpRelated’ for
2021, as presented in Figure 4. We randomly extracted 500 tweets from each of the 5 selected topics. This led to
in total 500 × 3 × 4 + 500 × 2 = 7, 000 tweets for qualitative analysis. For the analysis itself, we followed the
thematic analysis method proposed in (Braun, Clarke, Hayﬁeld and Terry). Important keywords from each topic
were highlighted and assigned to diﬀerent codes ﬁrst. For example, a tweet on forgetting password was assigned to
a code ‘password’ and a tweet on sharing a password with a family member to ‘sharing behavior’. Eventually, these
codes were compared and grouped into a number of coherent themes. For example, all Wi-Fi related codes such as

7https://radimrehurek.com/gensim/
8https://www.nlp.town/
9The algorithm originally returns a score between 1 and 5. We decided to shift the range by -3, so the range become [-2,2] and a negative/positive

value means negative/positive sentiment, which we consider more interpretable.

N. Pattnaik et al.: Preprint submitted to Elsevier

Page 8 of 18

Perspectives of Non-Expert Users on Cyber Security and Privacy: An Analysis of Twitter Discussions

Year #(Tweets) #(Non-expert CySecPriv tweets)(%)

Year #(CySecPriv Authors) #(Non-expert authors)

2019
2020
2021

4,690,397
4,439,719
4,589,582

85,495 (1.8%)
94,169 (2.1%)
234,321 (5.1%)

2019
2020
2021

171,883
215,857
274,551

64,747 (38%)
73,653 (34%)
180,660 (66%)

(a) CySecPriv tweets by non-expert users in 2019-21

(b) Non-expert authors in 2019-21

Table 2
The yearly trend of ‘CySecPriv’ tweets and non-expert (NE) authors of such tweets (2019-2021), showing a substantially
increased level in 2021 (during the COVID-19 pandemic) compared with 2019 and 2020 (before the ﬁrst wave of global
COVID-19 lockdowns), in both relevant tweets and non-expert authors involved.

‘WiFi neighbour/family/friends’, ‘Wi-Fi awareness’, ‘Wi-Fi password’, ‘Wi-Fi Device’, ‘Wi-Fi Issue/solution/help’
were grouped in the theme ‘Wi-Fi related security’.

4. Results
4.1. Performance of ‘CySecPriv’ and ‘Non-Expert User’ Classiﬁers (RQ1)

Identifying privacy and security related tweets posted by non-expert users was our ﬁrst research question. To that
extent, we developed a classiﬁer to ﬁrst determine the cyber security nature of a tweet, and then a second classiﬁer to
identify the author as non-expert user. The following paragraph explains the performance success of our classiﬁers.
According to the results in Table 1a, we can see that the BERT-based classiﬁer performed the best, so we decided
to use it for our analysis. This classiﬁer achieved a precision score of 0.90, a recall score of 0.93 and an F1-score of
0.92, a reasonably high score to classify and label our tweets. We compared our results to other similar studies using
BERT-based classiﬁers to evaluate our model. We noticed that, in general, BERT-based models achieved an F1-score
between 0.83 and 0.95 (Sriram et al., 2021; Mozafari, Farahbakhsh and Crespi, 2020; Ghourabi, 2021; Husain and
Uzuner, 2021; Kalepalli, Tasneem, Phani Teja and Manne, 2020; Dionísio et al., 2019). Similarly good performance
results were observed for the ‘Non-Expert User’ classiﬁer. As shown in Table 1b, the best-performing classiﬁer is also
the BERT-based one, which achieved an F1-score of 0.94 when it is used to predict non-expert users (versus the other
three classes).

As mentioned in the previous section, after applying the two classiﬁers to the 13.7 million raw tweets, we obtained
413,985 tweets written by non-expert users. Among all the CySecPriv tweets authored by non-expert users, we noticed
a very sharp (nearly 3 times) increase both in the absolute number and the relative percentage of CySecPriv tweets from
2019-20 (85,495, 1.8%) to 2021 (over 230,000, 5.1%), as shown in Table 2. If we look at the proportion of non-expert
users in the total CySecPriv authorship, who posted at least one CySecPriv tweet, we can also see a much sharper
increase from 2019-20 (64000-74000 users, 34-38% of all CySecPriv authors) to 2021 (over 180,000 users, 66% of
all), more than doubled in the absolute number and almost 54-64% relatively. The increase during the COVID-19
pandemic (2021) may be attributed to the increased use of digital technologies at home due to the global lockdowns
that led to more cyber security and privacy challenges and concerns for non-expert users.

4.2. Non-expert users’ cyber security and privacy related discussions and trend analysis (RQ2 and

RQ3)

Having identiﬁed the relevant tweets, we explored the results using topic modeling to understand the types of
discussions non-expert users were engaged in on Twitter. As mentioned in Section 3, we analyzed the data in three
diﬀerent ways, (1) tweets in all the three years together as one dataset, (2) tweets from each individual year, and (3)
tweets in 2019-20 and those in 2021. Results of these two diﬀerent analyses are shown in Figures 2, 3 and 4, respectively.
In the following two sub-subsections, we discuss results of the quantitative analysis and the qualitative analysis, with
greater details.

4.2.1. Quantitative Analysis

We ﬁrst applied LDA analysis to the entire subset of data. The results depicted in Figure 2 demonstrate common
discussion areas of non-expert Twitter users pertaining to cyber security and privacy. Interestingly and unexpectedly,
the top topic turned out to be the use of VPNs (‘VPNuse’, 21%), which is followed by device account security

N. Pattnaik et al.: Preprint submitted to Elsevier

Page 9 of 18

Perspectives of Non-Expert Users on Cyber Security and Privacy: An Analysis of Twitter Discussions

(‘AcctPrivSec’, 13%), laptop security (‘LaptopSec’, 10%), Wi-Fi and password security (9.2%), and cyber security and
privacy matters at home (‘HomePrivSec’, 8.6%). In addition, cyber security and privacy matters related to diﬀerent
computing devices is also an important cluster of topics: iPhone (‘iPhoneSec’, 8%), general devices (‘DevicePrivSec’,
7.3%), Android (‘AndroidPrivSec’, 6.3%) and mobile apps (‘AppPrivSec’, 6%). Considering the second most used topic
‘AcctPrivSec’ is also device-related, it may be the case that device-related discussions are even more common than
those related to the top-most topic ‘VPNuse’. Note that the boundary between diﬀerent topics is not a clear-cut, so
there are often overlaps between diﬀerent discussions, e.g., a tweet in our dataset about how to use an IP camera and
access details through VPN could come either under ‘DevicePrivSec’ or ‘VPNUse’.

We then applied LDA to relevant tweets in each individual year. Figure 3 gives a compact view of the top topics
calculated for each year along with the percentage of tweets in each topic. As in the case of the overall results, the
top-most topic for all the three years remains ‘VPNuse’. Inspecting the overlaps between diﬀerent topics quantitatively
and qualitatively (see Section 4.2.2 for the latter), we observed that the ‘VPNuse’ topic overlaps heavily with other
topics, indicating VPNs were used in many diﬀerent contexts. For example, ‘VPN’ as a keyword was mentioned in
35% of tweets on the ‘HelpRelated’ topic in 2021 and 16% of the total tweets of the ‘WiﬁPass’ topic in 2020. While the
topic distributions across the three individual years look similar, there are some noticeable diﬀerences. For instance, the
percentage of the ‘WiﬁPass’ topic decreased from 10.4% in 2019 to 9.5% in 2021, substituted with broader discussions
on new topics such as ‘HomePrivSec’ (3.6%), ‘InternetSec’ (2.2%) and ‘HelpRelated’ (2.7%).

The topic modeling results presented in Figure 4 show statistics of topics before the ﬁrst wave of global COVID-19
lockdowns (2019-20) and during the pandemic (2021). It is evident from the ﬁgure that, several topics appeared to
be common in both periods, e.g., ‘VPNuse‘, ‘LaptopSec’, ‘AccPrivSec’, ‘iPhoneSec’, and ‘WiﬁPass’, indicating that
the nature of the frequently discussed topics before and during COVID period have not changed much. However, we
can also notice that, there are topics which are diﬀerent, e.g., a number of new topic emerged during the pandemic
period, including ‘HelpRelated’ (2.7%) containing tweets about peoples’ query, help or advice related tweets, and
‘ScamProtectThreat’ (8.8%) relating to diﬀerent types of scams and security threat people encountered and ways to
protect themselves. These may be attributed to more cyber security and privacy issues encountered by non-expert
users due to an increased level of digital activities during the COVID-19 pandemic. There is a notable increase in the
topic area of ‘VPNuse’ during the 2021 pandemic period, which suggests that non-expert users’ use of VPN may have
increased during this period. Another major trend emerged is that non-expert users were concerned by and engaged with
discussions of a wide range of topics, such as cyber security and privacy issues of both traditional computing devices
and ‘smarter’ devices, networking behaviors and authentication techniques such as passwords, privacy enhancing
techniques and tools such as VPNs, seeking help and support on diﬀerent privacy and cyber security related topics,
Wi-Fi-related topics, ﬁnancial security involving external stakeholders, cyber security speciﬁc to home, mobile device
security and web browser security. Evidences of these discussions could be found in topics across the years.

13%

20.8%

VPNuse
AcctPrivSec
LaptopSec

WiﬁPass
HomePrivSec
iPhoneSec
DevicePrivSec
AndroidPrivSec
AppPrivSec

WorkIssue
WebSec
CryptoHacking

iPadHackScam
JobElection

3.4%

2.2%
2.1%
1.8%
1.4%

10%
9.2%

8.6%

8%
7.3%

6.3%
6%

(a) Main topics of discussion

(b) Topic distribution

0

5

10

15

20

25

Figure 2: Topics derived from the full dataset (2019-21)

4.2.2. Qualitative Analysis

As mentioned in Section 3, we used thematic analysis to code the selected six topics for our qualitative analysis,
which resulted in seven diﬀerent themes and provided further insights into the topic categories. These details are

N. Pattnaik et al.: Preprint submitted to Elsevier

Page 10 of 18

Perspectives of Non-Expert Users on Cyber Security and Privacy: An Analysis of Twitter Discussions

LaptopSec

VPNUse

AcctPrivSec
DataPrivacy

WiﬁPass

AndroidPrivSec

iPhoneSec
HomePrivSec

HackingMedia

DevicePrivSec

14.9%

13.9%

12.1%

10.6%
10.4%
10.1%
9.6%
9.2%

4.8%
4.4%

VPNuse
DevicePrivSec
LaptopSec
AcctPrivSec
WiﬁPass
AndroidPrivSec
iPhoneSec
AppSec
HomePrivSec
InternetSec
FinBitScam

16.7%

12.4%
12%
11.4%

10.2%

8.4%
8.3%
7.7%

5.2%
4.4%

3.3%

VPNuse
iPhAndroidSec
AcctPrivSec
LaptopSec

WiﬁPass
ScamProtectThreat
DevicePrivSec
CryptoBitHack
HomePrivSec
HelpRelated
InternetSec

21.1%

15.9%

13.3%

12.1%

9.5%
8.8%

6.2%

4.5%
3.6%
2.7%
2.2%

0

5

10

15

20

25

0

5

10

15

20

25

0

5

10

15

20

25

(a) 2019

(b) 2020

(c) 2021

Figure 3: Topic distribution for each of the three individual years (2019-2021)

Figure 4: Topic distributions in 2019-20 (before the ﬁrst wave of global COVID-19 lockdowns) and in 2021 (during the
COVID-19 pandemic)

discussed below. Although we collected topics generated by LDA, after manually going through the data we observed
several overlaps in the topics. For example, we had 500 records on help-related topics but after the thematic analysis
we found 1,852 tweets that could be assigned to the theme of ‘Help and support needed’ and otherwise were in either
‘AcctPrivSec’, ‘VPNuse’, ‘ExtStakeHolder’ or ’WiﬁPass’ in the LDA results. Such overlap were envisaged due to the
automatic nature of analysis done in LDA topic modeling.

(I) Help and Support Needed: A number of queries and discussions (222 tweets, 12% of 1,852 help-related ones) on
laptops, desktops, tablets and routers involved cyber security problems about passwords and user authentication, where
non-expert users expressed their inability to cope with the requirements of multiple password changes and the use of
OTPs (one-time passwords). Users sought help on virus-related problems, and their inability to distinguish between
scams and genuine requests from legitimate parties sometime indicating people’s general awareness of scam messages,
but also their lack of technical skills to recognize scams and consequently help themselves. There were a number of
discussion (333 tweets, 18% of 1,852) involving questions and advice related to Wi-Fi security especially about secure
Wi-Fi in public places from a user perspective, and also seeking help on forgotten passwords, broken Wi-Fi security,
how to stop neighbors from breaking into Wi-Fi, handling security notiﬁcations, etc. Cyber security related questions
regarding web browsers on PCs were another major area of discussions, often about seeking advice on how to clear
caches and cookies, how to deal with adware and how to use private browsing. VPN-related questions covered a big
portion (482 tweets, 26% of 1,852) involving questions on downloading and setting up VPNs, diﬀerent operational
problems, seeking help on what type of VPNs to install, etc.

(II) Awareness on Password Protection: User authentication, and passwords particularly, have been prominent
topics of cyber security related discussion for a long time (Zimmermann and Gerber, 2020). 11% of the total data we
analyzed (826 of 7,000) were password-related discussions. For the tweets we analyzed in this study, we noticed that
only a very small number of tweets (32, 3.9% of 826) referred to modern authentication schemes based on biometrics
or multi-factor authentication (MFA). Wi-Fi security is a major topic (490 tweets, 60% of 826), where non-expert

N. Pattnaik et al.: Preprint submitted to Elsevier

Page 11 of 18

15.7%13.1%12.5%11.5%9.9%9.5%4.9%2.2%8.8%8.0%3.9%VPNuseLaptopSecAcctPrivSecWiFiPassiPhoneSecDevicePrivSecHomePrivSecInternetSecAppSecExtStakeHolderFinanceSec(a)Topicdistribution:2019-2021.1%12.1%13.3%9.5%15.9%6.2%3.6%2.2%8.8%4.5%2.7%VPNuseLaptopSecAcctPrivSecWifiPassiPhAndroidSecDevicePrivSecHomePrivSecInternetSecScamProtectThreatCryptoBitHackHelpRelated(b)Topicdistribution:2021Perspectives of Non-Expert Users on Cyber Security and Privacy: An Analysis of Twitter Discussions

users expressed the risks associated with leaked Wi-Fi passwords and their worry or fear of such passwords being
compromised. Password managers (PMs) appeared to be a popular sub-topic as well. Tweets on PMs covered both
positive and negative aspects, covering areas such as browser-based PMs or dedicated software tools, advice on the
best PMs, open-source and commercial PMs, selective use of PMs, and how to use PMs. A very small number of
tweets (16, 1.9% of 826) advised using PMs as a good cyber security habit or voiced doubts on their usefulness. Tweets
involving general passwords were mainly about how users were frustrated to remember diﬃcult passwords, unable to
cope with managing passwords for multiple devices or expressed distrust of stakeholders who manage PMs. In line
with the discussions in some recent studies (Zimmermann and Gerber, 2020), we noticed that, non-expert users in
general were not enthusiastic about more modern authentication methods such as MFA, which may be attributed to the
substantial eﬀorts needed for setting things up, compared to the simplicity of using more traditional knowledge-based
methods such as textual passwords.

(III) Wi-Fi related security: 1,852 (26% of 7,000) tweets asked for help and advice on locating Wi-Fi access points,
(re)conﬁguring Wi-Fi settings, connecting and disconnecting diﬀerent devices to and from Wi-Fi access points, and
cyber security issues of Wi-Fi routers (e.g., compromised routers). Some tweets under this theme discussed ways of
hacking into neighbors’ Wi-Fi (e.g., for using neighbors’ Wi-Fi illegally to watch paid TV programs) and how to protect
themselves from this kind of attacks. Another aspect discussed under this topic is the behavior of some non-expert
users in sharing their Wi-Fi passwords with trusted people such as guests, friends and roommates, without any heed to
potential security problems. Granting important user credentials to trusted people may seem harmless, and it is one of
the usual way of sharing Wi-Fi access points at home, but it can potentially open up possibilities of insecure storage,
extension of admin privileges (unless a separate guest account is used). Some interesting tweets in our set talked about
how people took photographs of wi-Fi credentials wherever they visited and their phone was full of these details from
friends and families. Overall, it seemed that while some non-expert users had some understanding of cyber security
issues involving the use of Wi-Fi, many of them had either a low level of awareness or were unsure of how to protect
themselves from potential cyber security problems. Setting up an auto-connect, time-limited guest account could solve
this problem but unfortunately not all Wi-Fi provider oﬀers this choice and if on oﬀer, they are quite complicated to
follow up.

(IV) Privacy: Privacy as a topic was discussed by a number of (2,206, 32% of 7,000) non-expert users. Privacy
concerns around smart home devices, such as Amazon Echo, Google Nest, smart locks, smartwatches, smartphones
and smart TVs, are one of the main reasons behind privacy-related discussions, with a majority of (1,876, 85% of
2,206) all tweets were attributed to discussions related to these areas. Users expressed their mistrust, frustration and
awareness or unawareness about data collection, storage and transfer to third parties from these devices. Keywords
such as ‘scared’, ‘panic’, ‘trust’ and ‘annoy’ made a regular appearance within these tweets. On a positive side, users
also discussed or advised others on how to improve privacy of these devices. A number of (318, 14% of 2,206) tweets
were related to possible data breaches, trust in data collectors, data leaking, data theft, secure data storage and transfer.
Webcams and laptop privacy also caught many users’ attention, with some of them discussing about privacy ﬁlters for
laptops and webcam privacy covers. Several tweets mentioned or asked about how VPNs could help enhance privacy
and whether it is worth using it for that purpose.

(V) External stakeholders: This was an interesting topic covering a wide range of discussions. Such tweets referred
to diﬀerent stakeholders who are in some way responsible for cyber security and privacy of users. The stakeholders
mentioned include governments, companies and other third parties who were not part of the non-expert users’
operational environments but impacted the way their cyber security and privacy related issues were generated and
handled. The activities and impacts of governmental bodies are one of the frequently discussed sub-topics. These
include governmental apps snooping on phones and devices, diminishing trust of users on governments handling
of their personal data, outdated security certiﬁcates on governmental websites, and also low-quality information
on governmental websites such as mis-spelling ‘Smart meters’ as ‘Spy meters’. Many users were very vocal about
companies not caring about their privacy and data security, tracking user devices to collect personal data covertly, and
even pre-installing spyware on user devices.

(VI) Smartphones and other smart devices: A lot of discussions (1,876, 26% of 7,000) in our samples were related
to iPhone and Android smartphones and other smart devices. Many discussions focused on Android’s lack of security

N. Pattnaik et al.: Preprint submitted to Elsevier

Page 12 of 18

Perspectives of Non-Expert Users on Cyber Security and Privacy: An Analysis of Twitter Discussions

(e.g., such devices being vulnerable to malware or spyware), and ways to protect against such security problems.
Although many posts were positive about iPhone security, others placed their mistrust in a growing level of security
mishaps and vulnerabilities in iPhone. Location tracking using the phone was also discussed sometimes as a good
feature for locating lost phones but was also labeled as a harmful feature. Smart speakers such as Amazon Alexa
are one of the frequently mentioned smart devices under this topic, and tweets were on discussions of data privacy,
security updates, third party involvement in data sharing, and following appropriate security behaviors while using
smart speakers.

(VII) VPN related discussion: As mentioned in Section 4.2.1, VPN was the most discussed topic as shown in the
quantitative analysis, so it was not surprising that we encountered many tweets (2,006, 29% of 7,000) under this topic
in our qualitative analysis. Most discussions on VPNs revolved around people trying to get help to download, install,
or conﬁgure VPNs at home. Various operational issues and general advice on type of VPNs to use or purchase, need
of VPNs in diﬀerent scenarios and the use of VPNs for watching and streaming diﬀerent programs to avoid privacy
issues were also quite popular. The use of VPNs to avoid or override local restrictions on speciﬁc data or resource use
was a popular topic, too. Many of these tweets (489, 24% of 2,006) advised on the what, how and why’s of VPNs,
responded to work-related queries, and some also expressed distrust of VPNs.

4.3. Sentiment analysis of non-expert users’ discussions on cyber security and privacy and trend

analysis (RQ4 and RQ5)

Having identiﬁed the topical areas non-expert users were interested, we investigated their sentiment with relation
to these topics. As mentioned in Section 3, we used an oﬀ-the-shelf BERT-based sentiment analysis classiﬁer for this
purpose. We examined each of the topics individually to understand the underlying sentiment tones of users, which
turned out to be overwhelmingly negative for all topics, as depicted in Figure 5 (data normalized to be presented
as percentage) and negative in general across the three years. Some topics have a relatively higher percentage of
tweets with a ‘strongly positive’ score, e.g., tweets belonging to the topics ‘VPNuse’ and ‘HomePrivSec’. By manually
inspecting some tweets under these topics, we noticed that many tweets are about suggesting devices or apps that
users felt happy about, and some are about users expressing appreciation on being able to understand the workings of
a technology or to remember their forgotten passwords. Two example topics tweets with a negative sentiment talked
about are Wi-Fi access points being hacked by neighbors and vulnerabilities of PMs. Two topics, ‘InternetSec’ and
‘LaptopSec’, have the higher percentage (over 70% across all three years) of tweets with a ‘strongly negative’ score. Our
results showed a sharp contrast to the results reported in (Sriram et al., 2021), which studied Twitter data to determine
users’ sentiment towards IoT in general and found the users sentiments to be more positive towards cyber security and
privacy.

LaptopSec
AcctPrivSec
VPNuse
iPhoneSec
DataPrivacy
AndroidSec
WiﬁPass
HomePrivSec
HackingMedia
DevicePrivSec

-2

-1

0

1

2

VPNuse
AcctPrivSec
LaptopSec
DeviceSecPriv
WiﬁPass
AndroidSec
iPhoneSec
AppSec
HomeSecPriv
FinBitCScam
InternetSec

VPNuse
iPhAndroidSec
AcctPrivSec
LaptopSec
WiﬁPass
ScamProtThret
DevicePrivSec
CryptoBitHack
HomePrivSec
InternetSec
HelpRelated

0

0.2

0.4

0.6

0.8

1

0

0.2

0.4

0.6

0.8

1

0

0.2

0.4

0.6

0.8

1

(a) 2019

(b) 2020

(c) 2021

Figure 5: Sentiment analysis results for each of the three years (2019-21)

5. Further Discussions, Limitations and Future Work

To summarize the results reported in the previous section, the good performance of the two classiﬁers enabled us
to extract a large number of cyber security and privacy related tweets posted by non-expert users in three consecutive

N. Pattnaik et al.: Preprint submitted to Elsevier

Page 13 of 18

Perspectives of Non-Expert Users on Cyber Security and Privacy: An Analysis of Twitter Discussions

years (January and February of 2019-21). Topical modeling analysis of the extracted tweets led to insights about a wide
range of topics non-expert users were discussing before the global COVID-19 lockdowns and during the pandemic. The
biggest topic is about the use of VPNs, which was unexpected because the topic has not been extensively studied in the
research literature (more details given below). Comparing topics in 2019-20 and 2021, we noticed a substantial increase
in non-expert users’ discussions on many topics including VPN, laptops, mobile phones, device accounts. Sentiment
analysis of the extracted tweets led to the discovery of an overall and consistent negative sentiment for all topics across
all three years. However, we found that non-expert users’ opinions seemed to have become more polarized during
the COVID-19 pandemic (2021), i.e., the neutral sentiment became much thinner compared with before the global
lockdowns (2019-20). Another noticeable pattern we observed is that most discussions of non-expert users were about
traditional computing devices such as laptops, tablets and smart phones rather than smart home devices, suggesting that
over-focusing on cyber security and privacy of smart home devices may miss the likely fact that traditional computing
devices remain the center of home networking at most households.

The fact that VPN-related discussions form the biggest topic in our data can be related to the reported increase
usage of VPNs especially during the COVID-19 pandemic (Johnson, 2021b). Among all such discussions about VPNs,
typical sub-topics include privacy, malware, the legality of use, bypassing geolocation control (based on IP addresses),
hardware- and software-based VPNs and work-based tweets. The extensive discussions on VPNs are aligned with the
results reported in (Busse et al., 2019), which reported that VPNs are often mentioned in cyber security and privacy
advice and among general practices of non-expert users. Despite the importance of VPNs, current research on VPNs
is more about technical aspects, and human factors are much less studied. Studies that did venture into human factors
of VPNs focused on limited areas such as the information disclosed while using VPNs (Molina, Gambino and Sundar,
2019), user awareness of VPN (Jayatilleke and Pathirana, 2018; Karaymeh, Ababneh, Qasaimeh and Al-Fayoumi,
2019), and user attitudes towards adopting VPNs (Namara, Wilkinson, Caine and Knijnenburg, 2020; Sombatruang,
Omiya, Miyamoto, Sasse, Kadobayashi and Baddeley, 2020) (note that (Namara et al., 2020) focused mainly on expert
users). We believe more research is needed to study a wide range of aspects regarding the use of VPNs by non-expert
users, especially in complicated contexts such as working from home, bringing own devices to work, and other hybrid
(e.g., work-life, multi-user and multi-device) environments.

Another noticeable phenomenon we observed is that many discussions of non-expert users, either about traditional
computing devices, smart devices or other digital platforms and tools, were often about seeking help and advice and
expressing frustration about cyber security and privacy. Such discussions formed one of the topics in 2021 (during
the COVID-19 pandemic), indicating that working and studying from home led to an increase level of cyber security
and privacy concerns and problems. Many from among these tweets, have a negative sentiment, suggesting that non-
expert users largely struggled with getting their problems solved without help. According to our analysis, non-expert
users often referred to Google for support on cyber security and privacy problems, however, as reported in a recent
study (Turner, Nurse and Li, 2021), googling often did not work appropriately for getting such advice. We call for more
research on understanding diﬃculties non-expert users are facing with getting help they need and on better methods
for providing such help.

A third informative ﬁnding of our study is about non-expert users’ discussions on their usage of multiple devices
and their interactions with multiple other users in the home context. Some discussions on multiple devices are less
surprising, e.g., interactions between mobile phones and smart devices, but some others were less expected, e.g.,
security issues of Bluetooth pairing between diﬀerent computing devices. Regarding multi-user aspects, we noticed
discussions that pointed to scenarios where cyber security and privacy issues were caused by or related to the presence
of multiple users at home. Example scenarios include non-expert users sharing their Wi-Fi access points and password
details with secondary and temporary users such as house guest and friends, and some users discussing how to illegally
break into neighbors’ Wi-Fi access points. Past studies on such multi-user aspects we are aware of (Marky, Voit, Stöver,
Kunze, Schröder and Mühlhäuser, 2020; Bernd, Abu-Salma and Frik, 2020; Huang et al., 2020b; Ahmad, Farzan,
Kapadia and Lee, 2020) were all smaller-scale empirical studies. One possible future research direction on multi-user
and multi-device scenarios is to investigate how personal and sensitive data ﬂow between diﬀerent computing devices
and possible users. The subject of personal and/or sensitive data is an important topic not only because it is an element
in understanding and maintaining the privacy of data, but also the sensitivity of the personal data alters depending on
the context it is used, the source it is derived from and the stakeholder which uses it and evolve with time (Saglam, Nurse
and Hodges, 2022). A detail study of these areas, can help understand user behaviors and identify new interventions.
Our study demonstrated that using real-world data from OSN platforms can oﬀer a much richer dataset and cover a
wider range of topics discussed by people in the wild than empirical studies based on a smaller number of participants

N. Pattnaik et al.: Preprint submitted to Elsevier

Page 14 of 18

Perspectives of Non-Expert Users on Cyber Security and Privacy: An Analysis of Twitter Discussions

in settings such as surveys, interviews and focus groups. However, using online social media analysis along also has
its own limitations, e.g., it is more passive and depends on what people discussed online. There could be more issues
at play in the real world which would not be captured through the online postings. It is also diﬃcult to study more
speciﬁed topics or speciﬁc interventions when studying the sheer volume of data.. The diversity of the data also means
there can be too many factors aﬀecting the results, so it can be diﬃcult to conduct causal analysis. As a result, we
believe that mixed methods, which combine both larger-scale OSN analysis and smaller-scale empirical studies, will
be more appropriate for studying user perspectives on cyber security and privacy. For instance, as suggested in (Joseph,
Shugars, Gallagher, Green, Mathé, An and Lazer, 2021), the larger set of macro results obtained via an OSN analysis
study could be followed by complementary empirical studies that focus on more speciﬁc aspects revealed by the OSN
analysis.

Secondly, we have used the months of January and February of each year to conduct this study, which might not
be representative enough of the whole year. In future studies, we would endeavour to include a more representative set
of data to give us more informative result and coverage.

Last but not the least, we would like to point out that our study is heavily based on the two machine learning
classiﬁers and the automated analysis tools for topical modeling and sentiment analysis. Such tools are not perfect
and can produce both false positives and false negatives, and the high volume data made manual inspection of results
infeasible, so we relied on a limited level of qualitative analysis. The manual labeling process we did could also suﬀer
from subjectivity since we had to rely on some subjective judgments when applying pre-deﬁned criteria to label the
data. The keywords we used to extract the original 13.7 million tweets may not be representative enough so we may
have missed some relevant tweets. All such problems are common for all online social media analysis studies, which
further justify the need to have some follow-up smaller-scale empirical studies to validate and extend the ﬁndings
reported in our study.

6. Conclusion

Using a large-scale Twitter dataset in January and February in three consecutive years (2019-21) and two BERT-
based classiﬁers to automatically detect cyber security and privacy related tweets posted by non-expert users, this paper
reports interesting results about non-expert users’ discussions on cyber security and privacy, via topic modeling and
sentiment analysis. We observed that non-expert users discussed a wide range of topics, covering many diﬀerent types
of computing devices, with more discussions on more traditional computing devices than smart ones. The results also
showed noticeable changes of non-expert users’ discussions on cyber security and privacy before the global COVID-19
lockdowns (2019-20) and during the pandemic (2021), e.g., an increased level of more polarized sentiment in 2021.
Many results of our study can help researchers identify new directions for future research, based on both data-driven
and empirical studies.

CRediT authorship contribution statement

Nandita Pattnaik: Conceptualization of this study, Methodology, Software, Data curation, Experiments, Data
analysis, Writing - Original draft preparation. Shujun Li: Conceptualization of this study, Methodology, Data analysis,
Writing - revision. Jason R.C. Nurse: Conceptualization of this study, Methodology, Writing - revision.

References
Aduragba, O.T., Yu, J., Senthilnathan, G., Crsitea, A., 2020. Sentence contextual encoder with BERT and BiLSTM for automatic classiﬁcation with
imbalanced medication tweets, in: Proceedings of the Fifth Social Media Mining for Health Applications Workshop & Shared Task, Association
for Computational Linguistics. pp. 165–167. URL: https://aclanthology.org/2020.smm4h-1.31.

Aghasian, E., Garg, S., Montgomery, J., 2020. An automated model to score the privacy of unstructured information–social media case. Computers

& Security 92, 101778:1–101778:10. doi:10.1016/j.cose.2020.101778.

Ahmad, I., Farzan, R., Kapadia, A., Lee, A.J., 2020. Tangible privacy: Towards user-centric sensor designs for bystander privacy. Proceedings of

the ACM on Human-Computer Interaction 4, 116:1–116:28. doi:10.1145/3415187.

Alodhyani, F., Theodorakopoulos, G., Reinecke, P., 2020. Password managers—it’s all about trust and transparency. Future Internet 12, 189:1–

189:50. doi:10.3390/fi12110189.

Alsop, T., 2021. Connected devices used to access Wi-Fi at home 2020. URL: https://www.statista.com/statistics/387709/

connected-devices-used-to-access-wireless-internet-at-home-uk/.

Alves, F., Bettini, A., Ferreira, P.M., Bessani, A., 2021. Processing tweets for cybersecurity threat awareness. Information Systems 95, 101586:1–

101586:18. doi:10.1016/j.is.2020.101586.

N. Pattnaik et al.: Preprint submitted to Elsevier

Page 15 of 18

Perspectives of Non-Expert Users on Cyber Security and Privacy: An Analysis of Twitter Discussions

Andreotta, M., Nugroho, R., Hurlstone, M.J., Boschetti, F., Farrell, S., Walker, I., Paris, C., 2019. Analyzing social media data: A mixed-
methods framework combining computational and qualitative text analysis. Behavior Research Methods 51, 1766–1781. doi:10.3758/
s13428-019-01202-8.

Barbosa, N.M., Zhang, Z., Wang, Y., 2020. Do privacy and security matter to everyone? quantifying and clustering user-centric considerations
about smart home device adoption, in: Proceedings of 16th Symposium on Usable Privacy and Security, USENIX Association. pp. 417–435.
URL: https://www.usenix.org/conference/soups2020/presentation/barbosa.

BBC, 2020. Coronavirus: The world in lockdown in maps and charts. News. URL: https://www.bbc.com/news/world-52103747.
Bernd, J., Abu-Salma, R., Frik, A., 2020. Bystanders’ privacy: The perspectives of nannies on smart home surveillance, in: Proceedings of the 10th
USENIX Workshop on Free and Open Communications on the Internet, USENIX Association. pp. 1–14. URL: https://www.usenix.org/
conference/foci20/presentation/bernd.

Blei, D.M., Ng, A.Y., Jordan, M.I., 2003. Latent Dirichlet allocation.

Journal of Machine Learning Research 3, 993–1022. URL: https:

//jmlr.org/papers/volume3/blei03a/blei03a.pdf.

Braun, V., Clarke, V., Hayﬁeld, N., Terry, G., . Thematic analysis, in: Handbook of Research Methods in Health Social Sciences. Springer, pp.

843–860. doi:10.1007/978-981-10-5251-4_103.

Busse, K., Schäfer, J., Smith, M., 2019. Replication: No one can hack my mind revisiting a study on expert and non-expert security practices
and advice, in: Proceedings of the 15th Symposium on Usable Privacy and Security, USENIX Association. pp. 117–136. URL: https:
//www.usenix.org/conference/soups2019/presentation/busse.

Caliskan Islam, A., Walsh, J., Greenstadt, R., 2014. Privacy detective: Detecting private information and collective privacy behavior in a large social
network, in: Proceedings of the 13th Workshop on Privacy in the Electronic Society, ACM. pp. 35–46. doi:10.1145/2665943.2665958.
Camargo, J.E., Torres, C.A., Martínez, O.H., Gómez, F.A., 2016. A big data analytics system to analyze citizens’ perception of security, in:

Proceedings of the 2016 IEEE International Smart Cities Conference, IEEE. pp. 1–5. doi:10.1109/ISC2.2016.7580846.

Camp, L.J., 2009. Mental models of privacy and security. IEEE Technology and Society Magazine 28, 37–46. doi:10.1109/MTS.2009.934142.
Camp, L.J., Asgharpour, F., Liu, D., 2008. Experimental evaluations of expert and non-expert computer users’ mental models of security risks.
Project document. URL: https://www.researchgate.net/publication/228671400_Experimental_Evaluations_of_Expert_
and_Non-expert_Computer_Users%27_Mental_Models_of_Security_Risks.

Cannizzaro, S., Procter, R., Ma, S., Maple, C., 2020. Trust in the smart home: Findings from a nationally representative survey in the UK. PLoS

ONE 15, e0231615:1–e0231615:30. doi:10.1371/journal.pone.0231615.

Chalhoub, G., Flechais, I., 2020. “Alexa, are you spying on me?”: Exploring the eﬀect of user experience on the security and privacy of smart speaker
users, in: HCI for Cybersecurity, Privacy and Trust: Second International Conference, HCI-CPT 2020, Held as Part of the 22nd HCI International
Conference, HCII 2020, Copenhagen, Denmark, July 19–24, 2020, Proceedings, Springer. pp. 305–325. doi:10.1007/978-3-030-50309-3_
21.

Chaparro, L., Pulido, C., Rudas, J., Reyes, A., Victorino, J., Narvaez, L., Gomez, F., Martinez, D., 2020. Sentiment analysis of social network content
to characterize the perception of security, in: Proceedings of the 2020 IEEE/ACM International Conference on Advances in Social Networks
Analysis and Mining, ACM. pp. 685–691. doi:10.1109/ASONAM49781.2020.9381434.

Chen, Y., Zhang, H., Liu, R., Ye, Z., Lin, J., 2019. Experimental explorations on short text topic mining between LDA and NMF based schemes.

Knowledge-Based Systems 163, 1–13. doi:10.1016/j.knosys.2018.08.011.

Crocamo, C., Viviani, M., Famiglini, L., Bartoli, F., Pasi, G., Carrà, G., 2021. Surveilling COVID-19 emotional contagion on Twitter by sentiment

analysis. European Psychiatry 64, e17:1–e17:6. doi:10.1192/j.eurpsy.2021.3.

Das, S., Wang, B., Kim, A., Camp, L.J., 2020. MFA is a necessary chore!: Exploring user mental models of multi-factor authentication technologies,
in: Proceedings of the 53rd Annual Hawaii International Conference on System Sciences, University of Hawai’i at Manoa. pp. 5441–5450.
doi:10.24251/HICSS.2020.669.

Devlin, J., Chang, M.W., Lee, K., Toutanova, K., 2018. BERT: Pre-training of deep bidirectional transformers for language understanding.

arXiv:1810.04805 [cs.CL]. doi:10.48550/arXiv.1810.04805.

Dionísio, N., Alves, F., Ferreira, P.M., Bessani, A., 2019. Cyberthreat detection from Twitter using deep neural networks. arXiv:1904.01127 [cs.LG].

doi:10.48550/arXiv.1904.01127.

D’Sa, A.G., Illina, I., Fohr, D., 2020. BERT and fastText embeddings for automatic detection of toxic speech, in: Proceedings of the 2020
International Multi-Conference on Organization of Knowledge and Advanced Technologies, IEEE. pp. 1–5. doi:10.1109/OCTA49274.2020.
9151853.

ExplosionAI GmbH, . spaCy 101: Everything you need to know · spaCy usage documentation. URL: https://spacy.io/usage/spacy-101.
Gai, A., Azam, S., Shanmugam, B., Jonkman, M., De Boer, F., 2018. Categorisation of security threats for smart home appliances, in: Proceedings
of the 2018 International Conference on Computer Communication and Informatics, IEEE. pp. 1–5. doi:10.1109/ICCCI.2018.8441213.
Ghourabi, A., 2021. SM-Detector: A security model based on BERT to detect SMiShing messages in mobile environments. Concurrency and

Computation: Practice and Experience 33, e6452:1–e6452:15. doi:10.1002/cpe.6452.

Google, 2022. Classify text with BERT. URL: https://www.tensorflow.org/text/tutorials/classify_text_with_bert.
Greco, F., Polli, A., 2021.
s11205-020-02341-8.

Security perception and people well-being.

Social Indicators Research 153, 741–758.

doi:10.1007/

Hofstätter, S., Lipani, A., Zlabinger, M., Hanbury, A., 2020. Learning to re-rank with contextualized stopwords, in: Proceedings of the 29th ACM

International Conference on Information & Knowledge Management, ACM. pp. 2057–2060. doi:10.1145/3340531.3412079.

Huang, D.Y., Apthorpe, N., Li, F., Acar, G., Feamster, N., 2020a. IoT Inspector: Crowdsourcing labeled network traﬃc from smart home devices
at scale. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 4, 46:1–46:21. doi:10.1145/3397333.
Huang, Y., Obada-Obieh, B., Beznosov, K.K., 2020b. Amazon vs. my brother: How users of shared smart speakers perceive and cope with privacy
risks, in: Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, ACM. pp. 1–13. doi:10.1145/3313831.3376529.

Hugging Face, . Hugging Face – the AI community building the future. URL: https://huggingface.co/.

N. Pattnaik et al.: Preprint submitted to Elsevier

Page 16 of 18

Perspectives of Non-Expert Users on Cyber Security and Privacy: An Analysis of Twitter Discussions

in: FTI
URL: https:

Husain, F., Uzuner, O., 2021.

Fine-tuning approach for Arabic oﬀensive language detection system: BERT-based model,

Proceedings: 4th International Conference on Computer Applications and Information Security, FTI. pp. 1–5.
//storage.googleapis.com/production-ipage-v1-0-1/981/556981/qPjjjfVx/2052bf7b80e84ceabd4db4f47be1cf0a?
fileName=Paper-no-02-Fatemah%20Husain.pdf.

Hutto, C., Gilbert, E., 2014. VADER: A parsimonious rule-based model for sentiment analysis of social media text. Proceedings of the International
AAAI Conference on Web and Social Media 8, 216–225. URL: https://ojs.aaai.org/index.php/ICWSM/article/view/14550.
Ion, I., Reeder, R., Consolvo, S., 2015. “...no one can hack my mind”: Comparing expert and non-expert security practices, in: Proceedings of
the 11th Symposium On Usable Privacy and Security, USENIX Association. pp. 327–346. URL: https://www.usenix.org/conference/
soups2015/proceedings/presentation/ion.

Jayatilleke, A., Pathirana, P., 2018. Smartphone VPN app usage and user awareness among Facebook users, in: Proceedings of the 2018 National

Information Technology Conference, IEEE. pp. 1–6. doi:10.1109/NITC.2018.8550081.

Johnson, J., 2021a. Share of online adults worldwide who can identify key cybersecurity terms as of 2020. URL: https://www-statista-com.

chain.kent.ac.uk/statistics/1147391/online-adults-identify-cybersecurity-terms/.

Johnson, J., 2021b. VPN usage surge during coronavirus crisis 2020. URL: https://www.statista.com/statistics/1106137/

vpn-usage-coronavirus/.

Johnson, J., 2022a.

Devices used to access the internet 2021.

URL: https://www.statista.com/statistics/1289755/

internet-access-by-device-worldwide/.

Johnson, J., 2022b. Global internet penetration rate as of January 2022, by region. URL: https://www.statista.com/statistics/269329/

penetration-rate-of-the-internet-by-region/.

Jones, K.S., Lodinger, N.R., Widlus, B.P., Namin, A.S., Hewett, R., 2021. Do warning message design recommendations address why non-
experts do not protect themselves from cybersecurity threats? a review. International Journal of Human-Computer Interaction 37, 1709–1719.
doi:10.1080/10447318.2021.1908691.

Joseph, K., Shugars, S., Gallagher, R., Green, J., Mathé, A.Q., An, Z., Lazer, D., 2021. (mis)alignment between stance expressed in social media data
and public opinion surveys, in: Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, ACL. pp. 312–324.
doi:10.18653/v1/2021.emnlp-main.27.

Kalepalli, Y., Tasneem, S., Phani Teja, P.D., Manne, S., 2020. Eﬀective comparison of LDA with LSA for topic modelling, in: Proceedings of the
2020 4th International Conference on Intelligent Computing and Control Systems, IEEE. pp. 1245–1250. doi:10.1109/ICICCS48265.2020.
9120888.

Kang, R., Dabbish, L., Fruchter, N., Kiesler, S., 2015. “my data just goes everywhere:” user mental models of the internet and implications for
privacy and security, in: Proceedings of the 2015 USENIX Symposium on Usable Privacy and Security, USENIX Association. pp. 39–52. URL:
https://www.usenix.org/conference/soups2015/proceedings/presentation/kang.

Karaymeh, A., Ababneh, M., Qasaimeh, M., Al-Fayoumi, M., 2019. Enhancing data protection provided by VPN connections over open WiFi
networks, in: Proceedings of the 2019 2nd International Conference on New Trends in Computing Sciences, IEEE. doi:10.1109/ICTCS.2019.
8923104.

Khazaei, T., Xiao, L., Mercer, R.E., Khan, A., . Understanding privacy dichotomy in Twitter, in: Proceedings of the 29th on Hypertext and Social

Media, ACM. pp. 156–164. doi:10.1145/3209542.3209564.

Kowalczuk, P., 2018. Consumer acceptance of smart speakers: a mixed methods approach. Journal of Research in Interactive Marketing 12, 418–431.

doi:10.1108/JRIM-01-2018-0022.

Kuang, D., Choo, J., Park, H., 2015. Nonnegative matrix factorization for interactive topic modeling and document clustering, in: Partitional

Clustering Algorithms. Springer, pp. 215–243. doi:10.1007/978-3-319-09259-1_7.

Laricchia, F., 2022. Average number of connected devices in UK households 2020. URL: https://www.statista.com/statistics/1107269/

average-number-connected-devices-uk-house/.

sckit learn, . 1. supervised learning. URL: https://scikit-learn.org/stable/supervised_learning.html.
Madabushi, H.T., Kochkina, E., Castelle, M., 2020. Cost-sensitive BERT for generalisable sentence classiﬁcation with imbalanced data. URL:

http://arxiv.org/abs/2003.11563, arXiv:2003.11563.

Mahaini, M.I., Li, S., Saglam, R.B., 2019. Building taxonomies based on human-machine teaming: Cyber security as an example, in: Proceedings

of the 14th International Conference on Availability, Reliability and Security, ACM. pp. 30:1–30:9. doi:10.1145/3339252.3339282.

Marky, K., Voit, A., Stöver, A., Kunze, K., Schröder, S., Mühlhäuser, M., 2020. “i don’t know how to protect myself”: Understanding privacy
perceptions resulting from the presence of bystanders in smart environments, in: Proceedings of the 11th Nordic Conference on Human-Computer
Interaction: Shaping Experiences, Shaping Society, ACM. pp. 1–11. doi:10.1145/3419249.3420164.

Mittal, S., Das, P.K., Mulwad, V., Joshi, A., Finin, T., 2016. CyberTwitter: Using Twitter to generate alerts for cybersecurity threats and
vulnerabilities, in: Proceedings of the 2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, IEEE.
pp. 860–867. doi:10.1109/ASONAM.2016.7752338.

Molina, M.D., Gambino, A., Sundar, S.S., 2019. Online privacy in public places: How do location, terms and conditions and VPN inﬂuence
disclosure?, in: Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems, ACM. pp. 1–6. doi:10.1145/
3290607.3312932.

Mozafari, M., Farahbakhsh, R., Crespi, N., 2020. A BERT-based transfer learning approach for hate speech detection in online social media, in:
Complex Networks and Their Applications VIII: Volume 1 Proceedings of the Eighth International Conference on Complex Networks and Their
Applications COMPLEX NETWORKS 2019, Springer. pp. 928–940. doi:10.1007/978-3-030-36687-2_77.

Namara, M., Wilkinson, D., Caine, K., Knijnenburg, B.P., 2020. Emotional and practical considerations towards the adoption and abandonment of
VPNs as a privacy-enhancing technology. Proceedings on Privacy Enhancing Technologies 2020, 83–102. doi:10.2478/popets-2020-0006.
Journal of Information and

Nemes, L., Kiss, A., 2021. Prediction of stock values changes using sentiment analysis of stock news headlines.

Telecommunication 5, 375–394. doi:10.1080/24751839.2021.1874252.

N. Pattnaik et al.: Preprint submitted to Elsevier

Page 17 of 18

Perspectives of Non-Expert Users on Cyber Security and Privacy: An Analysis of Twitter Discussions

NLP Town,

.

nlptown/bert-base-multilingual-uncased-sentiment

· Hugging Face.

URL: https://huggingface.co/nlptown/

bert-base-multilingual-uncased-sentiment.

Oak, R., Du, M., Yan, D., Takawale, H., Amit, I., 2019. Malware detection on highly imbalanced data through sequence modeling, in: Proceedings

of the 12th ACM Workshop on Artiﬁcial Intelligence and Security, ACM. pp. 37–48. doi:10.1145/3338501.3357374.

O’Dea, S., 2021.

Home devices used to online UK 2020.

URL: https://www.statista.com/statistics/612951/

home-devices-used-to-go-online-uk/.

Rahman, T., Rohan, R., Pal, D., Kanthamanon, P., 2021. Human factors in cybersecurity: A scoping review, in: Proceedings of the 12th International

Conference on Advances in Information Technology, ACM. pp. 1–11. doi:10.1145/3468784.3468789.

Sabanoglu, T., 2021. Total monthly sales value of all retailing including automotive fuel in Great Britain from January 2017 to December 2021.

URL: https://www.statista.com/statistics/287867/retail-sales-total-value-monthly-great-britain-gb/.

Saglam, R.B., Nurse, J.R.C., Hodges, D., 2022. Personal information: Perceptions, types and evolution.

Journal of Information Security and

Applications 66, 103163. doi:https://doi.org/10.1016/j.jisa.2022.103163.

Salesforce, 2021. 2021 ecommerce stats and trends report. URL: https://www1.salecycle.com/l/22702/2021-04-01/77jbfv.
Saura, J.R., Palacios-Marqués, D., Ribeiro-Soriano, D., 2021. Using data mining techniques to explore security issues in smart living environments

in Twitter. Computer Communications 179, 285–295. doi:10.1016/j.comcom.2021.08.021.

Sethy, A., Ramabhadran, B., 2008. Bag-of-word normalized n-gram models, in: Proceedings of the 9th Annual Conference of the International
Speech Communication Association, ISCA. pp. 1594–1597. URL: https://www.isca-speech.org/archive_v0/archive_papers/
interspeech_2008/i08_1594.pdf.

Shah, N., 2022. Description of the emot:3.1 library. URL: https://github.com/NeelShah18/emot.
Sharma, B., Karunanayake, I., Masood, R., Ikram, M., 2022. Analysing security and privacy threats in the lockdown periods of COVID-19 pandemic:

Twitter dataset case study. arXiv:2202.10543 [cs]. URL: http://arxiv.org/abs/2202.10543, arXiv:2202.10543.

Sievert, C., Shirley, K., 2014. LDAvis: A method for visualizing and interpreting topics, in: Proceedings of the 2014 Workshop on Interactive

Language Learning, Visualization, and Interfaces, ACL. pp. 63–70. doi:10.3115/v1/W14-3110.

Sombatruang, N., Omiya, T., Miyamoto, D., Sasse, M.A., Kadobayashi, Y., Baddeley, M., 2020. Attributes aﬀecting user decision to adopt a virtual
private network (VPN) app, in: Information and Communications Security: 22nd International Conference, ICICS 2020, Copenhagen, Denmark,
August 24–26, 2020, Proceedings, Springer. pp. 223–242. doi:10.1007/978-3-030-61078-4_13.

Sriram, A., Li, Y., Hadaegh, A., 2021. Mining social media to understand user opinions on IoT security and privacy, in: Proceedings of the 2021

IEEE International Conference on Smart Computing, IEEE. pp. 252–257. doi:10.1109/SMARTCOMP52413.2021.00056.

Sturgess, J., Nurse, J.R.C., Zhao, J., 2018. A capability-oriented approach to assessing privacy risk in smart home ecosystems, in: Living in the

Internet of Things: Cybersecurity of the IoT-2018, IET. doi:10.1049/cp.2018.0037.

Turner, S., Nurse, J.R.C., Li, S., 2021. When googling it doesn’t work: The challenge of ﬁnding security advice for smart home devices, in: Human
Aspects of Information Security and Assurance: 15th IFIP WG 11.12 International Symposium, HAISA 2021, Virtual Event, July 7–9, 2021,
Proceedings, Springer. pp. 115–126. doi:10.1007/978-3-030-81111-2_10.

Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, L., Polosukhin, I., 2017. Attention is all you need, in: Advances
in Neural Information Processing Systems 30 (NIPS 2017), Curran Associates, Inc.. pp. 5998–6008. URL: https://proceedings.neurips.
cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html.

Ward, B., 2022.

When are people most

likely to buy online?

URL: https://www.salecycle.com/blog/stats/

when-are-people-most-likely-to-buy-online/.

Wash, R., 2010. Folk models of home computer security, in: Proceedings of the 6th Symposium on Usable Privacy and Security, ACM. pp. 1–16.

doi:10.1145/1837110.1837125.

Wu, J., Zappala, D., 2018. When is a tree really a truck? exploring mental models of encryption, in: Proceedings of the 14th Symposium on Usable
Privacy and Security, USENIX Association. pp. 395–409. URL: https://www.usenix.org/conference/soups2018/presentation/wu.
Yin, S., Kaynak, O., 2015. Big data for modern industry: Challenges and trends [point of view]. Proceedings of the IEEE 103, 143–146.

doi:10.1109/JPROC.2015.2388958.

Zheng, S., Apthorpe, N., Chetty, M., Feamster, N., 2018. User perceptions of smart home IoT privacy. Proceedings of the ACM on Human-Computer

Interaction 2, 200:1–200:20. doi:10.1145/3274469.

Zimmermann, V., Gerber, N., 2020. The password is dead, long live the password – a laboratory study on user perceptions of authentication schemes.

International Journal of Human-Computer Studies 133, 26–44. doi:10.1016/j.ijhcs.2019.08.006.

Zimmermann, V., Gerber, P., Marky, K., Böck, L., Kirchbuchner, F., 2019. Assessing users’ privacy and security concerns of smart home

technologies. i-com 18, 197–216. doi:10.1515/icom-2019-0015.

Zubiaga, A., Procter, R., Maple, C., 2018. A longitudinal analysis of the public perception of the opportunities and challenges of the Internet of

Things. PLoS ONE 13, e0209472:1–e0209472:18. doi:10.1371/journal.pone.0209472.

N. Pattnaik et al.: Preprint submitted to Elsevier

Page 18 of 18

