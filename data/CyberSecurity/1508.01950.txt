Defending Against Stealthy Attacks on Multiple
Nodes with Limited Resources: A Game-Theoretic
Analysis

Ming Zhang, Student Member, IEEE, Zizhan Zheng, Member, IEEE, and Ness B. Shroff, Life Fellow, IEEE

1

9
1
0
2

t
c
O
0
2

]
T
G
.
s
c
[

4
v
0
5
9
1
0
.
8
0
5
1
:
v
i
X
r
a

Abstract—Stealthy attacks have become a major threat for
cyber security. Previous works in this direction fail to capture
the practical resource constraints and mainly focus on one-
node settings. In this paper, we propose a two-player game-
including a system of multiple independent
theoretic model
nodes, a stealthy attacker and an observable defender. In our
model, the attacker can fully observe the defender’s behavior
and the system state, while the defender has zero feedback
information. Further, a strict resource constraint is introduced to
limit the frequency of the attacks/defenses for both players. We
characterize the best responses for both attacker and defender
under both non-adaptive and adaptive strategies. We then study
the sequential game where the defender ﬁrst announces its
strategy and the attacker then responds accordingly. We have
designed an algorithm that ﬁnds a nearly optimal strategy for
the defender and provided a full analysis of its complexity and
performance guarantee.

Index Terms—Stealthy Attacks, Resource Constraints, Game

Theory

I. INTRODUCTION

Increasingly sophisticated cyber attacks constantly push
the evolution of cyber security. In recent years, worldwide
organizations and IT companies, e.g., United Nation, Google
and Amazon, are facing a signiﬁcantly increasing number of
Advanced Persistent Threats (APT) [8]. The APT attack has
several distinguishing properties that render traditional defense
mechanisms less effective. First, they are often launched by
incentive driven entities, including government and competi-
tive companies with speciﬁc targets. Second, the APT attack is
persistent, which usually involves multiple stages and frequent
compromises of the system. Based on [1], half of the entities
suffering APT attacks experienced another successful com-
promise within one year. Third, they are highly adaptive and
stealthy, often operating in a “low-and-slow” fashion [15] in
order to maintain a small footprint and avoid of being detected.
In fact, some of the past APT attacks have been so effective
because they have gone undetected for months or longer [9],
[14]. Hence, conventional security measures against one-shot
attack and known attack types are not sufﬁcient in the face
of long-lasting and stealthy attacks. Meanwhile, the objective
of APT attacks usually includes the key information theft and
complete control over the system, resulting in a much bigger
loss than traditional cyber attacks.

This work has been funded by QNRF fund NPRP 5-559-2-227, ARO-
W911NF-15-1-0277, NSF grant CNS-1816495, and a grant from the Board
of Regents of the State of Louisiana LEQSF(2017-19)-RD-A-15.

M. Zhang (zhang.2562@osu.edu) is with the Department of Computer
Science and Engineering, Ohio State University, Columbus, OH, 43202 USA.
is with the Department of Computer

Z. Zheng (zzheng3@tulane.edu)

Science, Tulane University, New Orleans, LA, 70118, USA.

N. Shroff (shroff.11@osu.edu) is with the Departments of ECE and CSE,

Ohio State University, Columbus, OH, 43202, USA.

In this paper, we study a two-player non-zero-sum game that
explicitly models stealthy attacks with resource constraints, as
an extension of the asymmetric version of the FlipIt game
considered in [22] . We consider a system with N independent
nodes (or components), an attacker, and a defender. Both
players compete for the control of the system by attacking or
defending each node, subject to an instantaneous move cost
per node and a long-term average resource constraint across
the entire system. The attacker tries to maximize its beneﬁts
by successfully compromising nodes, and the defender aims
at minimizing the total defense cost and value loss incurred
by losing control of a node.

To model the stealthy attacks, we assume that the defender
has no feedback about
the node state and the attacker’s
behavior across the entire game, which is reasonable in many
security setups. On the other hand, the attacker is capable of
observing the defender’s each move as well as the node state,
and makes decisions accordingly. In this work, we consider
two commonly adopted solution concepts, Nash Equilibrium
and Sequential Equilibrium, both of which have been applied
to cybersecurity. In the former, the defender and the attacker
determine their strategies at the beginning of the game simul-
taneously, while in the latter, the defender acts as the leader
of the game and commits to a strategy ﬁrst, and the attacker
as the follower then responds accordingly.

For tractability and simplifying the analysis, we assume
that the set of nodes are independent in the sense that the
proper functioning of one node does not depend on other
nodes, which serves as a ﬁrst-order approximation of the more
general setting of interdependent nodes to be considered in
our future work. Despite of the assumption that each node is
independent, the multi-node setting together with the resource
constraints impose signiﬁcant challenges in characterizing the
best responses, Nash Equilibria and Sequential Equilibria of
the games.

One example where our game model can be applied is key
rotation. For a system with multiple communication links or
servers that are protected by different keys, an APT attacker
may compromise some of the keys from time to time. A
common practice is to periodically generate fresh keys by a
trusted key-management service, without knowing when they
are compromised. On the other hand, the attacker can easily
detect when the key expires with a negligible cost and there
is a constraint on the frequency of moves at both sides. There
are also other examples where our model can be useful such
as password reset and virtual machine refreshing [16], [22],
[32].

To help reader better understand our main results, we brieﬂy
explain the key concepts below. Formal deﬁnitions can be
found in Sections III and IV.

 
 
 
 
 
 
2

TABLE I: Main Results

Attacker
Defender
i.i.d. attack ⇆ periodic defense
Markovian attack → periodic defense
i.i.d. attack 8 Markovian defense

Best Response

Nash Equilibrium A complete characterization of NEs (6 types)

Sequential Game

Optimal attack
under a given
defense strategy (24)

A polynomial time
algorithm for optimal
defense (Algorithm 1)

• In a periodic defense strategy: the defender protects each
node periodically. That is, the time interval between two
consecutive defenses is ﬁxed for a given node.

• In an i.i.d. attack strategy : the attacker’s waiting time
before each attack (modeled as a random variable) is i.i.d.
across time.

• In a Markovian defense (resp. attack) strategy: the time
interval between two defenses (resp. the waiting time of
each attack) follows a Markov process.

• Nearly Optimal strategy: For arbitrary small positive
number ǫ, we can always ﬁnd a strategy that the perfor-
mance difference between this strategy and the theoretical
optimal strategy is less than ǫ.

We have made following contributions in this paper with

the main results summarized in Table I 1.

• We propose a two-player game model with multiple inde-
pendent nodes, an overt defender, and a stealthy attacker
where both players have strict resource constraints.

• We prove that periodic defense is a best response against
i.i.d. attack among all defense strategies, and i.i.d. attack
is a best response against periodic defense among all at-
tack strategies. We further consider Markovian strategies
and prove that periodic defense is still a best response
against a Markovian attacking strategy, but i.i.d. attack
is not necessarily a best response against a Markovian
defending strategy.

• For the pair of periodic defense and i.i.d. attack strategies,
we fully characterize the set of Nash Equilibria of our
game, and show that there is always one (and maybe
more) equilibrium, for the case when the attack times are
deterministic.

• We further consider the sequential game with the de-
fender as the leader and the attacker as the follower.
We design a dynamic programming based algorithm
that identiﬁes a nearly optimal strategy (in the sense
of subgame perfect equilibrium) for the defender. We
also fully characterize the trade-off between algorithm
performance and its complexity.

This paper is the extended version of [35]. In addition to
improving the presentation and organization of the paper, we
have provided in this journal submission version (i) an exten-
sion of the defender’s and attacker’s best response strategies
from the non-adaptive setting to the general adaptive setting,
(ii) we provide some preliminary analysis about Markovian
strategies for both attacker and defender, and (iii) a better
understanding of the performance vs. complexity trade-off of
our algorithm for the sequential game, reducing its complexity
by a factor of O(N 3) with the same performance guarantee.

1In Table I, A → B means that B is a best response against A; A 9 B

means that B is NOT a best response against A

The remainder of this paper is organized as follows. A
summary of related work is provided in Section II. We
present our game-theoretic model in Section III, and study
best-response strategies of both players in Section IV. The
sequential game is studied in Section VI. In Section VII,
we present numerical result, and we conclude the paper in
Section VIII.

II. RELATED WORK

Game theory has been extensively applied to cyber-security
and network security [11], [20], [25], [31]. However, tradi-
tional models mainly focus on known attacks and largely
ignore the budget constraints of both the defender and the
attacker.

As mentioned in the introduction, our model is inspired
by the FlipIt game [16], [32] proposed in response to an
APT attack towards RSA Data Security [10], a non-zero-sum
dynamic game that explicitly models the stealthy takeover of
a single node. In the original model, a player obtains control
over a component instantaneously by “ﬂipping” it, and obtains
feedback only when it moves. Dominant strategies or strongly
dominant strategies are characterized for several classes of
periodic and renewable strategies and some simple adaptive
strategies. But the full analysis of Nash Equilibrium is only
provided when both the defender and the attacker employ a
periodic strategy with a random starting phase. Several variants
of the basic model have been studied [21], [22]. In particular, a
multi-node extension is considered in [21] where the attacker
needs to compromise either all the nodes (AND model) or a
single node (OR model) to take over a system. The authors
name such a model as “FlipThem”. However, only prelim-
inary analytic results are provided. Leslie et al. extend the
“FlipThem” model in [23], [24] where the attacker can obtain
partial beneﬁts by compromising a certain number (larger than
a threshold) of nodes. An asymmetric model similar to ours
where the attacker is stealthy while the defender is observable
is considered in [22], where full Nash Equilibrium analysis
is provided but only for the single node setting. In [28],
Nochenson et al ﬁrst initiate the effort of adding player’s
characterization information including gender and age in the
FlipIt game model. Basak et al [13] further extend the concept
by adding different type of rationale of human agents. In [36],
Zheng et al. use multi-armed bandit model to investigate the
optimal timing of security updates against stealthy attacks.
There are also some behaviorial studies of the FlipIt game [27].
However, none of the previous works considered an explicit
resource constraint on the players.

A different type of security game has also been studied
in the literature mainly for protecting physical
infrastruc-
tures [12], [19], [30], [31]. Essentially a mixed strategy Stack-
elberg game is considered, where the defender is the leader
and the attacker is the follower. The key assumption is that
the defender ﬁrst decides upon a randomized defense policy,
and the attacker then observes the randomized policy of the
defender but not its realization before taking an action. While
this is a useful assumption under certain scenarios, it may not
hold when the attacker is highly adaptive. In particular, since
the attacker may be able to observe the defender’s previous
actions, it could take an action before the defender changes
its policy to get more beneﬁt. Moreover, the two-stage game
is insufﬁcient to capture the persistent and stealthy behaviors
of advanced attacks. In spite of the fundamental differences of

the two models, recent work that extend this model to multiple
defenders and bounded rationality [18], [26] provide useful
insights to our model as well, which will be studied in our
future work.

III. GAME MODEL

In this section, we discuss our two-player game model
including its information structure, the action spaces of both
attacker and defender, and their payoffs. Our game model
extends the single node model in [22] to multiple nodes and
includes a resource constraint on each player.

A. Basic Model

In our game-theoretic model, there are two players (the
defender and the attacker) and a network of N independent
nodes2. Each node has a value of ri representing the payoff
the attacker can receive per unit time by successfully com-
promising node i. We consider ﬁnite time horizon where the
game starts at time t = 0 and goes to any time t = T . We
assume that time is continuous. Every time when the attacker
starts an attack for node i, it incurs a cost of CA
i and takes
a random period of time αi,k to succeed. On the other hand,
if the defender makes a move to protect node i, the node is
immediately recovered and incurring a cost of CD
i . Further,
this information is immediately learned by the attacker. The
attacker’s strategy is to determine Wi,k, the waiting time from
the defender’s k-th move to its next attack on node i, for each i
and k. On the contrary, the defender’s strategy is to determine
the time intervals between its (k − 1)-th move and k-th move
for each node i and k, denoted as Xi,k. Both the attacker’s
and the defender’s strategies can be randomized and adaptive
in general.

In this paper, an attack strategy is considered adaptive when
the attacker’s decision on Wi,k for any i and k can depend
on the realized value of Xi′,k′ for any i′ and k′ ≤ k. An
adaptive defense strategy is deﬁned similarly. On the other
hand, a strategy is deﬁned as non-adaptive if the values of
Wi,k’s and Xi,k’s are either pre-computed or follow ﬁxed
probability distributions. The attacker (defender) can attack
(defend) multiple nodes at the same time and maintain their
possession until the other player’s next move, which may or
may not change the node state.

In addition to the move cost, we introduce a strict resource
constraint for each player, which is a practical assumption but
has been ignored in most prior works on security games. In
particular, we place an upper bound on the average amount
of resource that is available to each player at any time (to
be formally deﬁned below). As in typical security games,
we assume that ri, CA
i , the distribution of αi,k, and the
budget constraints are all common knowledge of the game, that
is, they are known to both players. Without loss of generality,
all nodes are assumed to be protected at time t = 0. Table II
summarizes the notations used in the paper.

i , CD

As in [22], we consider an asymmetric feedback model
where the attacker’s moves are stealthy, while the defenders’
moves are observable. More speciﬁcally, at any time,
the
attacker knows the full history of moves by the defender, as
well as the state of each node, while the defender does not
know whether a node is compromised or not. This asymmetric

3

Fig. 1: Game Model

information structure is crucial in modeling stealthy attacks in
cyber security.

In this paper, we consider both non-adaptive and adaptive
strategies. We deﬁne the strategy space for the attacker as all
possible Wi,k ∀i, k that follows a joint distribution. Similarly,
the defender’s strategy space refers to all possible Xi,k ∀i, k
following a joint distribution. Since the defender cannot ob-
serve the attacker’s behavior and node states, we only need
to consider non-adaptive strategies for the defender. That is,
the defender’s decisions on Xi,k’s can be independent of the
realization of Wi,k’s. On the other hand, the attacker can
observe the defender’s moves. Thus in general, Wi,k may
depend on the realization of both Xj,τ and Wj,τ for any j
and τ such that Tj(τ ) < Ti(k) where Tj(τ ) refers to the time
instance of node j’s τ -th defense.

B. Defender’s Problem

We model the total cost to the defender as the summation
of the total time when nodes are compromised and the total
move cost. The defender aims at maximizing its payoff, which
is deﬁned as the negation of its total loss. Given the attacker’s
strategy {Wi,k}, the defender faces the following optimization
problem:

max
{Xi,k},Li

E

(cid:20)

N

−

T −

(cid:16)

P

i=1 (cid:18)
X

−

LiCD
i
T

Li
k=1 min(Wi,k + αi,k, Xi,k)
(cid:17)

T

· ri

(cid:19)(cid:21)

(1)
and the optimization variable Xi,k and Li satisfy the following
two constraints.
N

Li
T

i=1
X
Li

≤ B with probability 1

(2)

Xi,k ≤ T with probability 1 ∀i

k=1
X

where Li (a random variable) is the total number of defense
Li
applied to node i during time T . In (1), T −
k=1 min(Wi,k +
αi,k, Xi,k) refers to the total time when node i is compromised
and LiCD
is the overall move cost. The ﬁrst constraint deﬁnes
i
an upper bound B of the average number of nodes that can
be protected at any time. The second constraint in (2) deﬁnes
the feasible set of Xi,k.

P

C. Attacker’s Problem

Given the defender’s strategy {Xi,k},

Li
k=1 φ(Wi,k, Xi,k)) · CA

the total cost of
i , where

2The terms “components” and “nodes” are interchangeable in this paper.

attacking node i is then (

P

4

TABLE II: List of Notations

Meaning

time horizon
number of nodes
value per unit of time of compromising node i
attacking time for node i in the k-th move
attacker’s move cost for node i
defender’s move cost for node i
attacker’s waiting time in its k-th move for node i
time between the (k − 1)-th and the k-th defenses
for node i
budget to the defender, greater than 0
budget to the attacker, greater than 0
frequency of defenses for node i
probability of immediate attack on node i
after it recovers
the number of defense moves for node i

Symbol
T
N
ri
αi,k
C A
i
C D
i
Wi,k

Xi,k

B
M
mi

pi

Li

IV. BEST RESPONSES

In this section, we analyze the best-response strategies for
both players. Our main result is that when the attacker employs
an i.i.d. strategy, a periodic strategy is a best response for
the defender, and vice versa. To prove this result, however,
we have provided characterization of best responses in more
general settings.

A. Defender’s Best Response

We ﬁrst show that an optimal deterministic defense strategy
is always optimal in general for (1). We then prove that the
periodic defense is optimal against i.i.d. attacks.

Lemma IV.1. Suppose x⋆
i,k and l⋆
i are the optimal solutions
of (1) among all deterministic strategies, then they are also
optimal among all the strategies (including both adaptive and
non-adaptive strategies).

φ(Wi,k, Xi,k) = 1 if Wi,k < Xi,k and φ(Wi,k, Xi,k) = 0
otherwise. It is important to note that when Wi,k ≥ Xi,k, the
attacker actually gives up its k-th attack against node i (this is
possible as the attacker can observe when the defender moves).
The attacker’s problem can be formulated as follows, where
M is an upper bound on the average number of nodes that the
attacker can attack at any time instance.

max
Wi,k

E

N

(T −

Li
k=1 min(Wi,k + αi,k, Xi,k)) · ri

(cid:20)

i=1
X

(

−

T

P
Li
k=1 φ(Wi,k, Xi,k)) · CA
i

T

(cid:21)

and the attacker needs to satisfy the following constraint

P

N

E

"

i=1
X

T

1
T

0
Z

vi(t)dt

≤ M

#

(3)

(4)

where vi(t) = 1 if the attacker is attacking node i at time t
and vi(t) = 0 otherwise. Note that we make the assumption
that the attacker has to keep consuming resources when the
attack is in progress. We further have the following equation:

T

0
Z

Li

vi(t)dt =

(min(Wi,k + αi,k, Xi,k) − min(Wi,k, Xi,k))

k=1
X

(5)

Putting (5) into (3), (4) and moving the expectation inside,

the attacker’s problem becomes

max
Wi,k

N

T · ri − E[

Li
k=1 min(Wi,k + αi,k, Xi,k)] · ri

i=1 (cid:20)
X

T

Li
k=1 P (Wi,k < Xi,k)] · CA
i

T

P

E[

−

P

Proof. Consider a general defense strategy Xi,k, we deﬁne
xi,k and li as the realizations of Xi,k and Li respectively and
li
let C = {(xi,k, li)|
k=1 xi,k ≤ T }. Let
U D(Xi,k, Li) denote the target function of (1) and denote
ˆU D(xi,k, li)

li
T ≤ B and

N
i=1

P

P

N

−

T −

=

i=1
X

(cid:16)

li
k=1 E[min(Wi,k + αi,k, xi,k)]
T

P

(cid:17)

· ri − liCD
i

(8)
Since the defender cannot observe the attacker’s behavior,
any realization of Xi,k can be pre-determined. Thus, we can
compute the total expected payoff for defender as follows:
U D(Xi,k, Li)
= P (Xi,k = x⋆

i , ∀i, k) · ˆU D(x⋆

i,k Li = l⋆

i,k, l⋆
i )

+

P (Xi,k = xi,k Li = li, ∀i, k) · ˆU D(xi,k, li)

xi,k 6=X⋆
≤ ˆU D(x⋆

(xi,k , li)∈C
X
i,k, l⋆
i )

i,k

li6=L⋆
i

The equality holds only when Xi,k = x⋆
Therefore, x⋆
fender’s strategies.

i,k and l⋆

(9)
i ∀i, k w.p.1.
i are also optimal among all the de-

i,k Li = l⋆

According to the lemma, it sufﬁces to consider defender’s
strategies where both Xi,k and Li,k are deterministic. It is also
worth mentioning that the order in which nodes are defended
makes no difference since the nodes are independent of each
other. We then deﬁne the set of i.i.d. attack strategies and show
that periodic defense is a best response against i.i.d. attacks.

Deﬁnition IV.1. An attack strategy is called i.i.d. if it is non-
adaptive, and Wi,k is independent across i and is i.i.d. across
k.

(cid:21)

(6)

Theorem IV.1. Periodic defense is a best response among all
defense strategies if the attacker employs an i.i.d. strategy.

with resource constraints

N

E[

Li
k=1(min(Wi,k + αi,k, Xi,k) − min(Wi,k, Xi,k))]

i=1 (cid:20)
X

P
≤ M

T

(cid:21)

(7)

To prove this result, we need the following deﬁnition.

Deﬁnition IV.2. For a given Li, we deﬁne a set Xi
that
includes all deterministic defense strategies for node i with
the following properties:

1)

Li
k=1 Xi,k = T ;

P

2) FWi,k+αi,k (Xi,k) = FWi,j +αi,j (Xi,j) ∀k, j,

where FWi,k+αi,k (·) is the marginal CDF of Wi,k + αi,k. Let
X denote the set of defense strategies where for each node i,
a strategy in Xi is adopted.

Note that (1) Xi can be an empty set in general due to the
randomness of Wi,k + αi,k; (2) for deterministic Xi,k, Wi,k
is independent of any Xj,τ s.t. Tj(τ ) ≥ Ti(k). The following
lemma shows that when Xi is non-empty for all i, any strategy
that belongs to X is a defender’s best deterministic strategy
against a non-adaptive attacker.

Lemma IV.2. Consider a non-adaptiv attack strategy. For any
Li
T ≤ B, if Xi 6= ∅ for any i,
given set of {Li} with
then any strategy in X is a best deterministic strategy for the
defender.

N
i=1

P

Proof. We ﬁrst deﬁne the defender’s payoff for node i as

U D

i (Xi,k, Li) =

−

T −

Li
k=1 E[min(Wi,k + αi,k, Xi,k)]

· ri

(cid:18)

−

P
LiCD
i
T

T

(cid:19)

.

(10)
Since {Li} are ﬁxed, Problem (1) can be divided into N
independent sub-problems as follows:

U D

i (Xi,k)

max
Xi,k

Li

s.t.

Xi,k ≤ T

(11)

k=1
X

We ﬁrst assume that FWi,k+αi,k (Xi,k) is continuous for any
i and k. Since the attacking strategy is non-adaptive, Xi,k is
independent of Wi,k. We can then prove that the objective
function is concave by showing that the Hessian matrix of
U D
i ({Xi,k}) with respect to Xi,k, (1 ≤ k ≤ Li) is negative
sem-deﬁnite. We note that even when FWi,k+αi,k (Xi,k) is
not continuous, the concavity can still be proved using the
subgradient concept. The details are omitted to save space.

Since U D

i (Xi,k) is concave and continuously differentiable,
the KKT conditions are both sufﬁcient and necessary. From
Li
the KKT conditions, we have ν⋆(
k=1 Xi,k − T ) = 0 and
FWi,k+αi,k (Xi,k) = FWi,j +αi,k (Xi,j ), ∀k, j, where ν⋆ is the
Lagrangian multiplier. It is clear that U D
i (Xi,k) is maximized
Li
when the constraint is tight, that is,
k=1 Xi,k = T . Note that
Li
there may exists a set of Xi,k with
k=1 Xi,k < T that is also
optimal for (11). Thus, the two conditions in Deﬁnition IV.2
are sufﬁcient but not necessary.

P
P

P

We now prove Theorem IV.1.

Proof. For any ﬁxed {Li}, let Xi , [ T
]. It is easy
Li
to check that {Xi} satisﬁes the ﬁst property in Deﬁnition IV.2
and will satisfy the second property if αi,k is i.i.d. with
respect to k. According to Lemma IV.2, {Xi} is an optimal
(deterministic) solution given {Li}. It follows that if we let
{L⋆

i } denote the optimal solution of

· · · T
Li

T
Li

N

−

T −

Li
k=1 E[min(Wi,k + αi,k, T
Li

)]

· ri − LiCD
i

(cid:16)

P

T

(cid:17)

max
Li

i=1
X

5

T
L⋆
i

with resource constraint
[ T
L⋆
i
Hence, a periodic strategy with periods of X ⋆
best-response strategy for the defender.

,
] is an optimal solution to the defender’s problem.
i for all i is a

Li
T ≤ B. Then X ⋆

· · · T
L⋆
i

P

N
i=1

i

According to Theorem IV.1, the defender use periodic strat-
egy to keep the system stable, in the sense of the same total
loss between two defenses. Since the distribution of attacker’s
waiting time Wi,k does not change with time, a ﬁxed defense
interval provides the same expected payoff between every two
consecutive moves. Moreover, the convexity of the defender’s
optimization problem guarantees an optimal solution under a
given attack strategy.

B. Attacker’s Best Response

We ﬁrst analyze the attacker’s best response against any
deterministic defense strategy, then show that the i.i.d. strategy
is the best response against periodic defense.

Deﬁnition IV.3. An attack strategy is called independent non-
adaptive if it is non-adaptive, and Wi,k is independent across
i and k.

Lemma IV.3. When the defense strategy is deterministic,
for any attacking strategy (adaptive or non-adaptive), there
always exists an independent non-adaptive strategy that gives
the attacker the same payoff.

Proof. When the defense strategies are deterministic, we can
move the expectation in (6) after the summation over k and
the expectation is with respect to αi,k. The same for constraint
(7). Then, the proof is done as long as we can construct an
independent non-adaptive strategy W ′
i,k such that for all i and
k, we have

1) E[min(Wi,k +αi,k, Xi,k)] = E[min(W ′
2) E[min(Wi,k, Xi,k)] = E[min(W ′
3) P (Wi,k < Xi,k) = P (W ′

i,k < Xi,k).

i,k, Xi,k)];

i,k +αi,k, Xi,k)];

Since Xi,k is deterministic and αi,k is independent across i
and k, the expectation above is with respect to the marginal
distribution of Wi,k only. Thus, we can construct W ′
i,k whose
distribution is the same as Wi,k’s marginal distribution which
does not depend on any realization of Xj,τ and Wj,τ s.t.
Tj(τ ) < Ti(k). Meanwhile, W ′
i,k is independent across i and
k.

According to Lemma IV.3, it sufﬁces to consider indepen-
dent non-adaptive strategies when the defender uses determin-
istic strategies.

Lemma IV.4. When the defense strategy is deterministic, the
attacker’s best response (among non-adaptive strategies) must
satisfy the following condition

W ⋆

i,k =

0
≥ Xi,k

(

w.p. pi,k
w.p. 1 − pi,k

(12)

Please ﬁnd the proof in Section IX-A. Lemma IV.4 implies
that for each node i, the attacker’s best strategy is to either
attack node i immediately after it realizes the node’s recovery,
or gives up the attack until the defender’s next move. There
is no incentive for the attacker to wait a small amount of
time to attack a node before the defender’s next move. The
the
constraint M actually determines the probability that
attacker will attack immediately. If M is large enough, the

6

attacker will never wait after defender’s each move. We then
ﬁnd the attacker’s best response when the defender employs
the periodic strategy.

Theorem IV.2. Assume that for any i, the attacking times
αi,k’s are i.i.d. across k. When the defender employs a peri-
odic strategy, the i.i.d. strategy is the attacker’s best response
among all strategies.

Proof. Suppose that
the defender uses a periodic strategy
where for any i, Xi,k = 1/mi for any k. With (12), the
attacker’s problem (6) can be simplied to a fractional knapsack
problem with decision variables {pi,k}. For any given node i,
pi,k’s unit reward (payoff in the target function divided by
weight in the constraint) across k are all equal when αi,k’s
are i.i.d. across k. Thus, setting all the pi,k in (12) equal is
one of the optimal solution. Therefore, the i.i.d. strategy is a
best solution for attacker when the defender uses a periodic
strategy.

C. Simpliﬁed Optimization Problems

We put particular emphasis on the case where the defender
employs a periodic strategy and the attacker uses an i.i.d.
strategy. According to Theorem IV.1 and Theorem IV.2, peri-
odic defense and i.i.d. attack can form a pair of best-response
strategies with respect to each other. Consider such pairs of
strategies. Let mi , Li
T = 1
, and let pi denote the
Xi,k
probability that Wi,k = 0 for all k. We assume that all the
attacking times αi,k are i.i.d. across k and omit the subscript
k in αi,k. The optimization problems to the defender and the
attacker can then be simpliﬁed as follows.
Defender’s problem:

max
mi

N

E[min (αi,

i=1 (cid:20)(cid:18)
X
N

1
mi

s.t.

mi ≤ B

i=1
X

Attacker’s problem:

)]piri − CD
i

· mi − piri

(cid:19)

max
pi

N

i=1
X
N

i=1
X

pi ·

ri(1 − E[min(αi,

(cid:18)

1
mi

)] · mi) − CA

i mi

(cid:19)

s.t.

E[min(αi,

1
mi

)] · mi · pi ≤ M

(14)
We observe that the defender’s problem is a continuous
convex optimization problem, while the attacker’s problem is
a fractional knapsack problem. Therefore, the best response
strategy of each side can be easily determined. Also, the time
period T disappears in both problems. It is worth mentioning
that ﬁnding the Nash Equilibrium of (13) - (14) is very
challenging since the constraint of (14) is non-convex with
respect to mi, thus the strategy space of this generalized Nash
Equilibrium problem (GNEP) is not jointly convex.

D. Markovian Strategies

Based on Theorems IV.1 and IV.2, the defender’s periodic
strategy and attacker’s i.i.d. strategy form a Nash equilibrium
among all adaptive and non-adaptive strategies. However, it
remains unclear what is the best response if one of the players

uses an adaptive strategy. To the best of our knowledge,
there has been virtually no discussion about adaptive strate-
gies in the ﬁeld of stealthy attacks. Further, even though
a deterministic strategy is always optimal for the defender
based on Lemma IV.1, there may still exist non-deterministic
strategies that are also optimal. Meanwhile, Nash equilibria
under more general strategies from both players may exist.
In this section, we provide some preliminary results in this
direction by considering Markovian strategies from both the
defender’s and the attacker’s perspectives. We assume that
the attacker’s waiting times Wi,k follow (12) and deﬁne a
Markovian attacking strategy as follows:

Deﬁnition IV.4. An attacking strategy is a Markovian strat-
egy if the attack probabilities {pi,k} for node i follow a
discrete Markov chain over K states v1, v2, · · · , vK with
transition matrix M A
i . That is, Pr(pi,k+1 = vs|pi,k = vt) =
M A

i (s, t) for any s and t.
A Markovian defense strategy is deﬁned similarly by con-
sidering {Xi,k} instead of {pi,k}. For tractability, we only
consider the expected payoffs for the defender in a steady
state. We show our main results about Markovian strategies in
the following.

Theorem IV.3. If the attacker employs an ergodic Markovian
strategy, the periodic strategy is defender’s best response.

The proof can be found in Section IX-B. Theorem IV.3 tells
us that the defender still prefers using a periodic strategy when
the attacker’s strategy space includes Markovian strategies.
Consequently, the pair of periodic strategy and i.i.d. strategy
naturally forms the Nash equilibrium in this case. However, the
i.i.d. attack strategy may not be optimal against a Markovian
defending strategy as shown in the following theorem.

The detailed proof can be found in Section IX-C. Theo-
rem IV.4 tells us that the attacker may use an adaptive strategy
against the Markovian defending strategy. Compared to the
defender, since the attacker is able to observe the defending
periods and the node states, the attacking strategy may become
state-dependent. Therefore, Nash equilibria beyond periodic
defense and i.i.d. attack can exist in the space of both adaptive
and non-adaptive strategies.

E. Discussion on Security Games in Networks

In this work, we focus on protecting a set of independent
nodes where the payoff functions are additive, that is, the total
payoff to a player is a weighted summation of the payoffs
from each node. Even in this case, ﬁnding the equilibrium
solutions of the game (13) - (14) is already very challenging
as we mentioned in Section IV-C. Solving a security game in a
general network setting that yields non-additive utility is even
harder. Because of that, existing security game work typically
assume additive utility as we did.

To extend our solutions discussed in Sections V and VI to
a network setting, a promising direction is to introduce non-
additive payoff functions to the defender and the attacker to
capture the dependencies of node values. There are several
recent work [17], [33], [34] that consider security games in
network settings. In particular, Wang et al. [34] developed

(cid:21)

(13)

Theorem IV.4. If the defender employs a Markovian strategy,
the i.i.d. attack strategy is not optimal in general.

a general framework to convert a security game with non-
additive utility to a combinatorial optimization problem over
a set system, and characterized the complexity of ﬁnding
the Nash Equilibrium. However, efﬁcient algorithms are only
known for some special cases and none of them apply to our
setting directly. Further, most previous work on security games
including [34] consider a static setting (or the stead state in a
repeated setting) where the game is played only once, which
cannot faithfully model the joint spatial and temporal decisions
in dynamic stealthy games as we consider in this paper.

V. NASH EQUILIBRIA

In this section, we study the set of Nash Equilibria of the
game where the defender employs a periodic strategy, and the
attacker employs an i.i.d. strategy. For tractability, we further
assume that the attacking time αi,k is deterministic for all i
and we omit the subscript k. We show that this game always
has a Nash equilibrium and may have multiple equilibria of
different values.

We ﬁrst observe that for deterministic αi, when mi ≥ 1
,
αi
the defender’s payoff becomes −miCD
i , which is maximized
when mi = 1
. Therefore, it sufﬁces to consider mi ≤ 1
.
αi
αi
Thus, the optimization problems to the defender (13) and the
attacker (14) can be simpliﬁed as follows.

For a given p, the defender aims at maximizing its payoff:

max
mi

N

i=1
X
N

[mi(riαipi − CD

i ) − piri]

s.t.

mi ≤ B

i=1
X
0 ≤ mi ≤

1
αi

, ∀i

(15)

7

defender tends to protect more a component with higher µi(p),
while for a given m, the attacker will attack a component more
frequently with higher ρi(m). When m and p are clear from
the context, we simply let µi and ρi denote µi(p) and ρi(m),
respectively.

To ﬁnd the set of NEs of our game, a key observation is that
if there is a full allocation of defense budget B to m such that
ρi(m) is a constant for all i, any full allocation of the attack
budget M gives the attacker the same payoff. Among these
allocations, if there is further an assignment of p such that
µi(p) is a constant for all i, then the defender also has no
incentive to deviate from m; hence (m, p) forms an NE. The
main challenge, however, is that such an assignment of p does
not always exist for the whole set of nodes. Moreover, there
are NEs that do not fully utilize the defense or attack budget
as we show below. To characterize the set of NEs, we ﬁrst
prove the following properties satisﬁed by any NE of the game.
For a given strategy (m, p), we deﬁne µ∗(p) , maxi µi(p),
ρ∗(m) , mini ρi(m), F (p) , {i : µi(p) = µ∗(p)}, and
D(m, p) , {i ∈ F : ρi(m) = ρ∗(m)}. We omit m and p
when they are clear from the context.

Lemma V.1. In any NE, (1) mi ≤

ri
riwi+C A
i

and (2) pi ≥ CD

i
riwi

.

ri
Proof. To prove the ﬁrst property, suppose mi >
.
riwi+C A
i
Then pi must be 0; otherwise the beneﬁt for attacking i
becomes negative. This in turn implies that mi = 0 by the
assumption that CD
i > 0, a contradiction. To prove the second
property, suppose pi < CD
. Then we have µi < 0, which
implies mi = 0 and therefore pi = 1 since ri > 0, a
contradiction.

i
riwi

Lemma V.2. If (m, p) is an NE, we have (see Table III):

1) ∀i 6∈ F, mi = 0, pi = 1, ρi = ∞;
2) ∀i ∈ F \D, mi ∈ [0,

ri
wiri+C A
i
ri
wiri+C A
i

], pi = 1;
], pi ∈ [ CD

i
riwi

, 1].

On the other hand, for a given m, the attacker aims at

maximizing its payoff:

3) ∀i ∈ D, mi ∈ [0,

max
pi

N

i=1
X
N

pi[ri − mi(riαi + CA

i )]

s.t.

miαipi ≤ M

i=1
X
0 ≤ pi ≤ 1, ∀i

(16)

For a pair of strategies (m, p), the payoff to the defender is
N
i=1[mi(piriwi − CD
i ) − piri], while the payoff
Ud(m, p) =
N
i=1 pi[ri − mi(riwi + CA
to the attacker is Ua(m, p) =
i )].
P
A pair of strategies (m∗, p∗) is called a (pure strategy) Nash
P
Equilibrium (NE) if for any pair of strategies (m, p), we have
Ud(m∗, p∗) ≥ Ud(m, p∗) and Ua(m∗, p∗) ≥ Ua(m∗, p). In the
following, we assume that CA
i > 0. The cases
i = 0 or CD
where CA
i = 0 or both exhibit slightly different
structures, but can be analyzed using the same approach.
Without loss of generality, we assume ri > 0 and CD
≤ 1 for
all i. Note that if ri = 0, then node i can be safely excluded
from the game, while if CD
> 1, the coefﬁcient of mi in
i
riwi
Ud (deﬁned below) is always negative and there is no need to
protect node i.

i > 0 and CD

Let µi(p) , piriwi − CD
Ud, and ρi(m) , ri−mi(riwi+C A
i )

i denote the coefﬁcient of mi in
. Note that for a given p, the

i
riwi

miwi

by the assumption that CA

Proof. We ﬁrst show that if mi > 0 and mj > 0, then
µi = µj. Suppose µi < µj. Then it is better to protect i
than protecting j. Since mi > 0, we must have mj = 1
>
wj
ri
i > 0, a contradiction. It
riwi+C A
i
ri
follows that mi = 0 ∀i 6∈ F and mi ∈ [0,
] ∀i ∈ F .
riwi+C A
i
Since when mi = 0, we must have ρi = ∞, and pi = 1,
pi = 1, ρi = ∞ ∀i 6∈ F . It remains to show that pi = 1 for
all i ∈ F \D. Assuming F \D 6= ∅, then we have ρj < ∞
for j ∈ D, which implies that mj > 0 for j ∈ D. Since
ρi < ρ∗ for i ∈ F \D, it is more beneﬁcial to attack i that any
j ∈ D. Since pj > 0 and mj > 0 for j ∈ D, we must have
pi = 1.

i ≥ rj wj − CD

Lemma V.3. If (m, p) forms an NE, then for i ∈ D, j ∈ F \D
j > rkwk − CD
and k 6∈ F , we have riwi − CD
k .
Proof. Since µi = µj for i ∈ D and j ∈ F \D by the
deﬁnitions of F and D, and pi ≤ pj = 1 by Lemma V.2,
we have riwi − CD
j . On the
other hand, since µj > µk by the deﬁnition of F , and
pj = pk = 1 by Lemma V.2, we have rjwj − CD
j = µj >
µk = rkwk − CD
k .

i ≥ µi = µj ≥ rj wj − CD

According to the above lemma, to ﬁnd all the equilibria of
the game, it sufﬁces to sort all the nodes by a non-increasing

8

TABLE III: Necessary Conditions for NEs

]

[0,

i ∈
mi

pi
µi
ρi

[0,

D
ri
wiri+CA
i
[ CD
, 1]
i
riwi
µ∗
ρ∗

]

F \D
ri
wiri+CA
i
1
µ∗
> ρ∗

F
0

1
< µ∗
+∞

i
riwi

i∈F mi < B (cases 4-
We next consider the cases when
6). We ﬁrst observe that pi = CD
, ∀i ∈ F , or equivalently,
P
µ∗ = 0. Otherwise, if µi > 0, mi can be further increased
< 1
to reduce the cost due to the fact that mi ≤
wi
in any NE (by Lemma V.1 and the assumption that CA
i >
0), a contradiction. We then have F = FN by its deﬁnition.
Cases 4-6 then follow from a similar argument for cases 1-3
by distinguishing different values of ρ∗.

ri
riwi+C A
i

order of riwi − CD
i , and consider each Fh consisting of the
ﬁrst h nodes such that rhwh − CD
h+1, and
each subset Dk ⊆ Fh consisting of the ﬁrst k ≤ h nodes
in the list. In the following, we assume such an ordering of
nodes. Consider a given pair of F and D ⊆ F . By Lemma V.2
and the deﬁnitions of F and D, the following conditions are
satisﬁed by any NE with F (p) = F and D(m, p) = D.

h > rh+1wh+1 − CD

In the following, NEs that fall into each of the six cases
considered above are named as Type 1 - Type 6 NEs, respec-
tively. The next theorem shows that our game has at least one
equilibrium and may have more than one NE.

Theorem V.2. The attacker-defender game always has a pure
strategy Nash Equilibrium, and may have more than one NE
of different payoffs to the defender.

mi = 0, pi = 1, ∀i 6∈ F ;

mi ∈ [0,

], pi = 1, ∀i ∈ F \D;

(17)

(18)

mi ∈ [0,

ri
wiri + CA
i
ri
wiri + CA
i
mi ≤ B,

], pi ∈ [

CD
i
riwi

, 1], ∀i ∈ D;

(19)

miwipi ≤ M ;

(20)

i∈F
X
µi = µ∗, ∀i ∈ F ;
ρi = ρ∗, ∀i ∈ D;

i∈F
X
µi < µ∗, ∀i 6∈ F ;
ρi > ρ∗, ∀i 6∈ D.

(21)
(22)

The following theorem provides a full characterization of

the set of NEs of the game.

Theorem V.1. Any pair of strategies (m, p) with F (p) = F
and D(m, p) = D is an NE iff it is a solution to one of the
following sets of constraints in addition to (17) to (22).

i∈F miwipi = M ;

i∈F mi = B; ρ∗ = 0;
i∈F mi = B; ρ∗ > 0;
i∈F mi = B; ρ∗ > 0; pi = 1, ∀i ∈ F ;
i∈F mi < B; µ∗ = 0; F = FN ; ρ∗ = 0;
i∈F mi < B; µ∗ = 0; F = FN ; ρ∗ > 0;
i∈F miwipi = M ;
i∈F mi < B; µ∗ = 0; F = FN ; ρ∗ > 0; pi = 1, ∀i ∈

P

1)
2)
3)
4)
5)

6)

P
P
P
P
P
P
F .
P

i∈F

i∈F

P

P

i∈F
P

ri
wiri+C A
i

ri
wiri+C A
i

ri
wiri+C A
i
ri
wiri+C A
i
ri
wiri+C A
i
. It follows that

Proof. We ﬁrst consider the cases when the budget constraint
of the defender is tight, i.e.,
i∈F mi = B (cases 1-3). Since
in any NE by Lemma V.1 and mi = 0 for i
mi ≤
ri
not in F by Lemma V.2, we must have B ≤
i∈F
wiri+C A
i
, we have ρ∗ = 0 (case
in any NE. If B =
P
1). Assume B <
. First consider the case D =
, i ∈ F . Hence, ρ∗ > 0
F . We then have mi ≤
since B <
i∈F miwipi =
M (case 2) unless pi = 1, ∀i ∈ F (case 3); otherwise, some
pi, i ∈ F can be increased to get more beneﬁt. Note that
case 3 can happen only if riwi − CD
is the same for all i ∈
i
ri
,
F . Next consider the case D ( F . If B ∈ [
wiri+C A
i
), we again have ρ∗ = 0 and get case 1, but
with extra constraints regarding i ∈ F \D as required by (18)
P
and (??). Otherwise, if B <
, by applying a
similar argument as above, we again have ρ∗ > 0 and get
P
case 2 or case 3 depending on whether the attacker’s budget
constraint is tight or not.

ri
wiri+C A
i

ri
wiri+C A
i

i∈D

P

P

P

i∈E

i∈F

i

h

if

P

riwi

i
riwi

i≤h mh

i < M and

i = 0 otherwise.

Proof. To show the ﬁrst part, for any given index h ≤ N ,
we deﬁne a pair of strategies (mh, ph) as follows. Let mh
i =
0, ∀i > h and let {mh
i , i ≤ h} be the solution to the constraints
i≤h mh
i = B and (2) ρi is a constant for all i ≤ h;
(1)
i = 1, ∀i > h (hence µh+1 = rh+1wh+1 − CD
ph
h ), and ∀i ≤
h, ph
if h < N , ph

P
i = µh+1+CD
We ﬁrst prove the following claim. For a given h, let h′ ≤ h
denote the smallest index such that rh′ wh′ −CD
h′ = rhwh−CD
h .
, ph′
Consider two pairs of strategies (mh, ph) and (mh′
). We
i wiph′
i≤h mh′
i wiph
claim that if
i ≥
M , then there is a Type 2 NE respecting Fh. Note that by
P
deﬁnition,
i < M is always true when h = N .
To prove the claim, we consider another pair of strategies
i wiph′
i≤h mh
then since
i < M , there must exist p with pi = 1, ∀i > h,
, ∀i ≤ h such that
rhwh
i wipi = M . Hence, (mh, p) is a Type 2 NE.
i wiph′
then since
i ≥ M , there must exist m with mi = 0, ∀i >
P
i ], ∀h′ ≤ i ≤ h, and {mh
i , i ≤ h} be the solution
i≤h mh
i = B and (2) ρi is a constant
i = M . We again get a

i wiph′
i≤h mh′
h, mi ∈ [0, mh
P
to the constraints (1)
for all i < h′, such that
P
Type 2 NE.

P
). If we have
i wiph

, 1], and pi = µh+CD

On the other hand,
P

ph ∈ [ µh+1+CD
P

(mh, ph′
i≤h mh

i≤h miwiph′

i < M ,

i ≥ M ,

P
i≤h mh

i≤h mh

i≤h mh

i wiph

i≤h mh

ri
wiri+C A
i

ri
wiri+C A
P
i

P
i wiph

i < M by the claim. If

P
We then prove the theorem. First note that

if B ≥
, then there is a Type 1 or Type 4 NE in
ri
FN . Assume B <
. There is h < N such
wiri+C A
P
i
ri
, where
and B ≥
that B <
wiri+C A
i
h′
is deﬁned as above. If there is an NE with respect to
some F (h′′), h′′ > h, we are done. Otherwise, we have
i ≥ M ,
there is a Type 2 NE as proved above. Otherwise, consider
P
the pair of strategies (m′, ph′
i = 0, ∀i > h,
ri
i , i ≤ h} is the solution
mi =
wiri+C A
i
i = B and (2) ρi is a constant
to the constraints (1)
for all i < h′. If
i ≥ M , there is Type 2 NE.
Otherwise, there must be a Type 1 NE.
P

, ∀i < h′, and {mh
i≤h mh
iwiph′

To show the second part, consider the following example
with two nodes where r1 = r2 = 1, w1 = 2, w2 = 1, CD
1 =
1/5, CD
2 = 7/2, B = 1/3, and M = 1/5.
It is easy to check that m = (1/6, 1/6) and p = (3/20, 9/10)
is a Type 2 NE, and m = (1/3, 0) and p = (p1, 1) with

2 = 4/5, CA

1 = 1, CA

) where m′

i≤h m′
P

i≤h mh

i wiph′

i<h′

i≤N

i≤N

P

P

i≤h

p1 ∈ [1/5, 3/10] are all Type 1 NEs, and all these NEs have
different payoffs to the defender.

VI. SEQUENTIAL GAME

In this section, we study the subgame perfect equilib-
rium [29] of the Stackelberg game when the defender em-
ploys a periodic strategy and the attacker employs an i.i.d.
strategy. In the sequential game, the defender ﬁrst commits
to a strategy and makes it public, the attacker then responds
accordingly. We assume that at t = 0, the leader (defender) has
determined its strategy and the follower (attacker) has learned
the defender’s strategy and determined its own strategy in
response. In addition, the players do not change their strategies
thereafter. Our objective is to identify the best sequential
strategy for the defender. We adopt the same assumption in
Section V and then deﬁne the subgame perfect equilibrium as
follows:

Deﬁnition VI.1. A pair of strategies (m⋆, p⋆) is a subgame
perfect equilibrium of the sequential game if m⋆ is the optimal
solution of

max
mi

N

i=1
X
N

[mi(riαip⋆

i − CD

i ) − p⋆

i ri]

s.t.

mi ≤ B

i=1
X
0 ≤ mi ≤

1
αi

, ∀i

where p⋆

i is the optimal solution of
N

pi[ri − mi(riαi + CA

i )]

max
pi

i=1
X
N

s.t.

miαipi ≤ M

i=1
X
0 ≤ pi ≤ 1, ∀i

(23)

(24)

Note that in a subgame perfect equilibrium, p⋆

i is the optimal
solution of (24), but the defender’s best strategy m⋆
is not
i
necessarily optimal with respect to (23). Due to the multi-node
setting and the resource constraints, it is very challenging to
identify an exact subgame perfect equilibrium strategy for the
defender. We ﬁrst establish several properties about the optimal
defense strategy and then propose a dynamic programming
based algorithm that ﬁnds a nearly optimal defense strategy.
To clearly state the properties, we partion all the nodes into

four disjoint sets deﬁned below:
1) F = {i|mi > 0, pi = 1}
2) D = {i|mi > 0, 0 < pi < 1};
3) E = {i|mi > 0, pi = 0};
4) G = {i|mi = 0, pi = 1}.
We observe that

the set D has at most one element
since (24) is a fractional knapsack problem. Let ρi(mi) ,
ri−mi(riαi+C A
i )
. We use md to represent mi, i ∈ D for
miαi
simplicity and denote ρd = ρd(md). If D is empty, we pick
any node i in F with minimum ρi and treat it as a node in D.

Lemma VI.1. For all optimal solutions of
always have ρd ≥ 0

(23)-(24), we

9

Proof. If ρd < 0, the defender can give a smaller budget to
the corresponding node to bring ρd down to 0. In any case, the
payoffs from nodes in sets D and E are 0 since the attacker
will give up attacking the nodes in sets D and E. Thus, the
defender has more budget to defend the nodes in sets F and
G which brings more payoff. Therefore ρd is always greater
than or equal to 0.

Based on Lemma VI.1, we only consider non-negative ρd

in the our analysis and algorithm.

Lemma VI.2. For any given nonnegative ρd, an optimal
solution for (23)-(24) satisﬁes the following properties:
i > 0 ∀i ∈ F ∪ E ∪ D

1) riαi − CD
2) mi ≤ mi ∀i ∈ F
3) mj = mj ∀j ∈ E
4) mi ≤ 1
αi
i∈E mi − md > 0.
5) B −

∀i

i

P

where mi = ρ−1
(ρd)
Proof. If riαi − CD
i ≤ 0 ∀i ∈ F ∪ E ∪ D. there is no point
for the defender to defend such node which will only make
the payoff even worse due to high defending cost. Thus, all
the nodes whose riαi − CD
i ≤ 0 are only in set G. For ∀i ∈
F , ρi(mi) = ρd and ρi(mi) ≥ ρd. According to the reverse
relationship between ρ and mi, we have mi ≤ mi. For ∀j ∈
E, since ρj(mj) = ρd and ρj(mj) ≤ ρd, mj is actually a
lower bound for mj. Setting mj = mj makes the cost from
node i, which is miCD
i gets its minimum and so does the
whole problem since it also uses the minimum budget from
B. Therefore, more budget can be allocated for mi i ∈ F to
minimize the cost from the nodes in set F . Further, it’s easy to
check mi is always less than 1
for any given nonnegative ρd.
αi
As to the 5th property, if B −
i∈E mi − md ≤ 0, there is no
budget for nodes in set F and D, which means F and D are
P
both empty. According to the greedy method, it only happens
when M = 0 which violates our assumption. Therefore, B −

i∈E mi − md > 0.

Lemma VI.3. For any nonnegative ρd, there exists an optimal
P
solution for (23)-(24) such that ∀i ∈ F , there is at most ONE
mi < mi and all the other mi = mi.

The proof of Lemma VI.3 is in Section IX-D. Lemmas VI.1
- VI.3 establish the foundation for the following key result
about the optimal defense strategy of (23)-(24).

Proposition VI.1. For any nonnegative ρd, there exists an
optimal solution {mi}n

i=1 such that

1) ∀i ∈ F , there is at most one mi < mi and all the other

mi = mi;
2) md = md
3) ∀i ∈ E, mi = mi;
4) ∀i ∈ G, mi = 0.

We denote the node whose mi < mi in the ﬁrst property
of Proposition VI.1 as node f and its defending frequency
as mf . Based on Proposition VI.1, we can easily compute
the value of mi for each node (except mf ) after the set
allocation is ﬁxed. Also, we can explicitly list the defender’s
payoff, defender’s budget usage and attacker’s budget usage
by putting each node into different sets as shown in Table IV.
For the fractional node, its mi can be computed using linear
programming when all the other mi have been determined.

10

TABLE IV: Nodes in Different Sets with Given ρd

nodes d and f ):

Defender’s
payoff
Defender’s
budget usage
Attacker’s
budget usage

F

E

mi(riαi − C D

i ) − ri −miC D
i

mi

miαi

mi

0

G

−ri

0

0

We use dynamic programming to determine the optimal set
allocation.

From the discussion above, we propose the following al-
gorithm to the defender’s problem (see Algorithm 1). The
algorithm iterates over all possible node d in set D and all
possible node f with fractional assignment in set F . We ﬁrst
compute a special case when set G is empty (line 2). In
this case, the defender’s optimal strategy can be obtained by
solving (25) based on Proposition VI.1.

max
mf

mf (rf αf − CD

f ) − rf + md(prdαd − CD

d ) − prd

s.t. mf + md ≤ b

m − mdαd ≤ mf αf ≤ m
mf ≤ mf

p =

m − mf αf
αdmd

(27)
3) Similarly, SEQ(0, b, m, d, f, F alse) returns the solution

to the following problem:

max
mf

mf (rf αf − CD

f ) − rf + md(rdαd − CD

d ) − rd

s.t. mf + md ≤ b

mf αf ≤ m − αdmd
mf ≤ mf

(28)
Note that if the constraints in (27) or (28) deﬁne an
empty set for mf , SEQ simply returns −∞.

V al(d, f ) = max

ρd,pi,mf

mi(piriαi − CD
i )

Algorithm 1 Sequential Strategy for Defender

i6=f
X

− piri + mf (rf αf − CD

f ) − rf

s.t.

mi + mf ≤ B,

pimiαi + mf αf ≤ M

ρd =

i6=f
X
ri − mi(riαi + CA
i )
miαi

i6=f
X
≥ 0, 0 ≤ pi ≤ 1, mf ≥ 0
(25)
The algorithm then iterates over nonnegative ρd with a step
size ρstep (line 4). Given ρd, d, f ,
the best set allocation
(together with mi for all i) are determined using dynamic
programming as explained below.

For any given ρd, d and f , we compute mi for all i (line
5). Let SEQ(i, b, m, d, f, ind) denote the maximum payoff
of the defender considering only node 1 to node i (excluding
nodes d and f ), for a given defender’s budget b ∈ [0, B] and
an attacker’s budget m ∈ [0, M ] . The parameter ind is a
boolean variable that indicates whether we can put nodes in
set E arbitrarily. If ind is T rue, any node (except nodes d
and f ) can be in set E. Otherwise, a node i can be allocated
to set E only if ri − mi(riαi + CA
i ) ≤ 0. The value of
SEQ(i, b, m, d, f, ind) is determined recursively. If node i
is either d or f , we simply set SEQ(i, b, m, d, f, ind) =
SEQ(i − 1, b, m, d, f, ind). Otherwise, we have the following
recurrence equation, where the three cases refer to putting node
i in sets F , E and G, respectively.

SEQ(i, b, m, d, f, ind) =

SEQ(i − 1, b − mi, m − αimi, d, f, ind)

+mi(riαi − CD

i ) − ri

max 
SEQ(i − 1, b − mi, m, d, f, ind) − miCD

i
SEQ(i − 1, b, m, d, f, ind) − ri


We have the following boundary conditions:

(26)

1) The recursion SEQ will return −∞ when i > 0 and (i)
m < 0, or (ii) b < 0, or (iii) m = 0 and ind = F alse;
2) SEQ(0, b, m, d, f, T rue) returns the solution to the
following problem (i.e., the total payoffs contributed by

1: for d, f ← 1 to n do
2:

3:

4:
5:

6:

7:
8:

Solve (25) to obtain V al(d, f )
n
ρmax ← ρ :
i=1 αimi(ρ) = M
for ρd ← 0 to ρmax with step size ρstep do

P

mi ← mi(ρd) for all i
val′
val′′
end for
Pdp(d, f ) ← maxρ{val′

← SEQ(n, B, M, d, f, T rue)
d,f,ρd
d,f,ρd ← SEQ(n, B, M, d, f, F alse)

9:
10: end for
11: Palg ← maxd,f {Pdp(d, f ), V al(d, f )}

d,f,ρd, val′′

d,f,ρd }

Algorithm 1 computes the optimal solution by searching
over all combinations of d, f and ρd. For any given combi-
nation, the dynamic program actually ﬁnds all the solutions
that satisfy Proposition VI.1, meaning that Pdp(d, f ) returns
the optimal defense strategy under given d, f and ρd (line
9). Therefore, Palg is the maximum payoff that the defender
can achieve (line 11). For the dynamic program, we round
the input before running SEQ(n, B, M, d, f, ind), since the
recursion may never stop without rounding. Denote δ as the
rounding parameter, we have mi ←
, αi ←
M
for all i and B ←
. By setting δ small
, M ←
δ
(cid:5)
(cid:4)
enough, Algorithm 1 can ﬁnd a strategy that is arbitrarily close
to the subgame perfect equilibrium strategy of the defender.
Formally, we can establish the following result.

mi
δ

αi
δ

B
δ

(cid:4)

(cid:5)

(cid:5)

(cid:4)

(cid:4)

(cid:5)

Theorem VI.1. Let |Palg| denote the defender’s cost obtained
by Algorithm 1 and |P ⋆| the optimal cost. Given ρstep and the
rounding parameter δ, We have |Palg |
|P ⋆| ≤ 1 + (ρstep + δ)O(N ).
Please ﬁnd the detailed proof in Section Theorem VI.1
provides the performance guarantee of Algorithm 1 showing
the trade-off between performance and the time complexity.
Based on Theorem VI.1, we have the following corollary.
Corollary VI.1. By setting both ρstep and δ with O( 1
N ),
Algorithm 1 can achieve a near-optimal solution and its
complexity is O(N 5BM )

s
f
f
o
y
a
P

2

1

0

-1

-2

0

s
f
f
o
y
a
P

3

2

1

0

-1

-2

-3

0

Type 1 NE - Defender
Type 1 NE - Attacker
Type 5 NE - Defender
Type 5 NE - Attacker
SPE - Defender
SPE - Attacker

0.1

0.2
M

0.3

0.4

Type 1 NE - Defender
Type 1 NE - Attacker
Type 5 NE - Defender
Type 5 NE - Attacker
SPE - Defender
SPE - Attacker

0.2

0.4

0.6

0.8

1

B

(a) Payoffs with varying M

(b) Payoffs with varying B

Fig. 2: The effects of varying resource constraints on payoffs.
In both ﬁgures, r1 = 2, r2 = 1, w1 = 1.7, w2 = 1.6, CD
1 =
0.5, CD
2 = 1.5, B = 0.3 in (a), and
M = 0.1 in (b)

2 = 0.6, CA

1 = 1, CA

VII. NUMERICAL RESULTS

In this section, we present numerical results for our game
models. For the illustrations, we assume that all the attacking
times αi are deterministic as in Sections VI. We study the pay-
offs of both the attacker and the defender and their strategies in
both Nash Equilibrium (two-node setting) and subgame perfect
equilibrium (both two-node and ﬁve-node settings), and study
the impact of various parameters including resource constraints
B, M , and the unit value ri.

A. Simulations with Selected Parameters

We ﬁrst study the impact of the resource constraints M and
B on the player’s payoffs in a two-node setting. The results are
given in Figure 2, where we have plotted both Type 1 and Type
5 NEs 3 and subgame perfect equilibria. A Type 5 NE only
occurs when M is small as shown in Figure 2a, while Type
1 NE appears when B is small as shown in Figure 2b, which
is expected since B is fully utilized in a Type 1 NE while
M is fully utilized in a Type 5 NE. When the defense budget
B becomes large, the summation of mi does not necessarily
equal to B and thus Type 1 NEs disappear. Similarly, Type 5
NEs disappear for large attack budget M . In both ﬁgures, the
subgame perfect equilibria always bring the defender higher
payoffs compared with Nash Equilibria, which is expected.

B. Simulations with Real-World data

To have a better understanding of the performance of
Algorithm 1, we consider a ﬁve-node setting and use real-word
data from the National Vulnerability Database (NVD) [2]. We
pick ﬁve vulnerability incidents about IoT devices revealed
by the database. For each incident, we use their Impact Score
(the potential impact of the vulnerability), Exploitability Score
(how vulnerable the thing itself is to attack), Vulnerability
Base Score (how critical
the vulnerability is) and Attack
Complexity (Low or High) [3]–[7] as an approximation of
the node value, attacking time, defending cost and attacking
cost respectively. Speciﬁcally, we set node values as r =
[5.9 3.6 5.9 5.2 3.6]. For the attacking times, since higher
Exploitability Score means easier attack, we take the reciprocal
and set α = [10/3.9 10/2.8 10/2.8 10/2.8 10/3.9] where the
constant 10 is used for normalization. The Vulnerability Base

3There are also Type 2 NEs, which are omitted for the sake of clarify.

11

SPE - Defender
SPE - Attacker

5
Noise Level

10

m

m

m

m

m

1

2

3

4

5

s
f
f
o
y
a
P

4

2

0

-2

-4

-6

0

0.16

0.14

0.12

0.1

0.08

y
g
e
t
a
r
t
S
s
'
r
e
d
n
e
f
e
D

1

0.06

0

5
Noise Level

10

SPE - Defender
SPE - Attacker

1

m

m

m

m

m

1

2

3

4

5

0.5
M

0.5
M

s
f
f
o
y
a
P

20

10

0

-10

-20

-30

0

0.2

0.15

0.1

0.05

y
g
e
t
a
r
t
S
s
'
r
e
d
n
e
f
e
D

0

0

(a) Payoffs and strategies with
varying M

(b) Payoffs and strategies with
varying noise level

Fig. 3: The effects of varying resource constraint M and unit
value ri, where B = 0.2 in (a), B = 0.5 and M = 0.3 in (b).
In (b), a random noise level is added to r1 and r2.

Score is utilized to approximate the defending cost by setting
CD = [9.8 6.5 8.8 8.1 7.5]/3, while the attacking cost is set
to 2 if the Attack Complexity is High and 1 otherwise. We
study the effects of varing M and r in Figure 3a.

In Figure 3a, the attacker’s budget M varies from 0 to 1 and
the defending budget B = 0.2. When M = 0, the defender
can set mi for all i to arbitrary small (but positive) values, so
that the attacker is unable to attack any node, leading to a zero
payoff for both players. As M becomes larger, the attacker’s
payoff increases, while the defender’s payoff decreases, and
the defender tends to defend the nodes with higher values
more frequently, as shown in Figure 3a(lower). The defender
gradually stop protecting low value nodes and move all the
resources to defend node 3. Note that the defending frequency
for node 3 is smaller than that for node 1 at the beginning. This
is because when M is small, the attacker attacks each node
with a very small probability, thus the defender can protect all
the nodes at the same time to prevent big loss. Since node 1
and 3 have the same unit value while α1 < α3, the defender
protects node 1 more frequently. However, when the attacker
has enough resources to attack each node with a much higher
probability, it is not beneﬁcial for the defender to protect other
nodes except node 3 since it has the highest node value and
attacking time.

In Figure 3b, we ﬁxed r3 through r5 and increase r1 and
r2 by adding a random noise uniformly distributed between
[noise level − 1, noise level] ∗ 0.1. We vary the noise level
from 1 to 10. As shown in the ﬁgure, m1 and m2 keep
increasing when the noise level becomes larger, while the
defending frequencies for all other three nodes decrease due to
limited defending resources, which indicates that the defender
should protect the nodes with higher values more frequently
in the subgame perfect equilibrium.

 
 
12

TABLE V: Running Time Improvement

No. of nodes Algorithm 1 Algorithm 1 in [35]

2
3
4
5
6

12.1 sec
131.5 sec
1036.3 sec
2117.9 sec
3.45 hours

31.4 sec
410.8 sec
3710.8 sec
9261.3 sec
24 - 26 hours

Table V compares the running time of Algorithm 1 and that
of the corresponding algorithm in our conference paper [35].
All experiments are conducted on a desktop with 4-Core
Intel i5-4670K CPU @ 3.40GHz and Matlab R2019a. The
same simulation setting as in Figure 3a is applied with ﬁxed
M = 0.2. We observe that Algorithm 1 is much faster
than the original algorithm in our conference paper and the
improvement is more signiﬁcant in a larger setting.

VIII. CONCLUSION

In this paper, we propose a two-player non-zero-sum game
for protecting a system of multiple components against a
stealthy attacker where the defender’s behavior is fully ob-
servable and both players have strict resource constraints. We
prove that periodic defense and non-adaptive i.i.d. attack are
a pair of best-response strategies with respect to each other in
the space of both adaptive and non-adaptive strategies. For this
pair of strategies, we characterize the set of Nash Equilibria
of the game, and show that there is always one (and maybe
more) equilibrium, for the case when the attack times are
deterministic. We further study the sequential game where the
defender ﬁrst publicly announces its strategy and design an
algorithm that can identify a strategy that is arbitrarily close
to the subgame perfect equilibrium strategy for the defender.
We also provide a full analysis of the algorithm performance
and its complexity guarantee.

REFERENCES

[17] A. Gueye, V. Marbukh, and J. C. Walrand. Towards a metric for
communication network vulnerability to attacks: A game theoretic
approach. In International Conference on Game Theory for Networks,
pages 259–274. Springer, 2012.

[18] A. X. Jiang, A. D. Procaccia, Y. Qian, N. Shah, and M. Tambe. Defender
(Mis)coordination in Security Games. In International Joint Conference
on Artiﬁcial Intelligence (IJCAI), 2013.

[19] D. Korzhyk, Z. Yin, C. Kiekintveld, V. Conitzer, and M. Tambe.
Stackelberg vs. Nash in Security Games: An Extended Investigation of
Interchangeability, Equivalence, and Uniqueness. Journal of Artiﬁcial
Intelligence Research, 2011.
[20] H. Kunreuther and G. Heal.

Interdependent security. Journal of Risk

and Uncertainty, 26(2-3), 2003.

[21] A. Laszka, G. Horvath, M. Felegyhazi, and L. Butty´an. Flipthem: Mod-
eling targeted attacks with ﬂipit for multiple resources. In Conference
on Decision and Game Theory for Security (GameSec), 2014.

[22] A. Laszka, B. Johnson, and J. Grossklags. Mitigating Covert Compro-
mises: A Game-Theoretic Model of Targeted and Non-Targeted Covert
Attacks. In Conference on Web and Internet Economics (WINE), 2013.
[23] D. Leslie, C. Sherﬁeld, and N. P. Smart. Threshold ﬂipthem: When the
winner does not need to take all. In Conference on Decision and Game
Theory for Security (GameSec), pages 74–92. Springer, 2015.

[24] D. Leslie, C. Sherﬁeld, and N. P. Smart. Multi-rate threshold ﬂipthem.
In European Symposium on Research in Computer Security (ESORICS),
pages 174–190. Springer, 2017.

[25] M. H. Manshaei, Q. Zhu, T. Alpcan, and T. Bas¸ar. Game Theory Meets
Network Security and Privacy. ACM Computing Surveys, 2012.
[26] T. H. Nguyen, R. Yang, A. Azaria, S. Kraus, and M. Tambe. Analyzing
the Effectiveness of Adversary Modeling in Security Games. In AAAI
Conference on Artiﬁcial Intelligence (AAAI), 2013.

[27] A. Nochenson and J. Grossklags. A Behavioral Investigation of the
In Workshop on the Economics of Information Security

FlipIt Game.
(WEIS), 2013.

[28] A. Nochenson, J. Grossklags, et al. A behavioral investigation of the
ﬂipit game. In Proceedings of the 12th Workshop on the Economics of
Information Security (WEIS), page 93, 2013.

[29] M. J. Osborne and A. Rubinstein. A Course in Game Theory. The MIT

Press, 1994.

[30] P. Paruchuri, J. P. Pearce, J. Marecki, M. Tambe, F. O. nez, and
S. Kraus. Playing games for security: an efﬁcient exact algorithm for
In International Conference on
solving Bayesian Stackelberg games.
Autonomous Agents and Multiagent Systems (AAMAS), 2008.

[31] M. Tambe. Security and Game Theory: Algorithms, Deployed Systems,

Lessons Learned. Cambridge University Press, 2011.

[32] M. van Dijk, A. Juels, A. Oprea, and R. L. Rivest. FlipIt: The Game

of “Stealthy Takeover”. Journal of Cryptology, 26(4):655–713, 2013.

[33] S. Wang, F. Liu, and N. Shroff. Non-additive security games. In Thirty-

First AAAI Conference on Artiﬁcial Intelligence, 2017.

[1] https://www.ﬁreeye.com/content/dam/collateral/en/mtrends-2018.pdf.
[2] https://nvd.nist.gov.
[3] https://nvd.nist.gov/vuln/detail/CVE-2019-10891.
[4] https://nvd.nist.gov/vuln/detail/CVE-2019-9461 .
[5] https://nvd.nist.gov/vuln/detail/CVE-2019-13267.
[6] https://nvd.nist.gov/vuln/detail/CVE-2019-11061.
[7] https://nvd.nist.gov/vuln/detail/CVE-2019-16159.
[8] Advanced persistent threat. http://en.wikipedia.org/wiki/Advanced persistent threat.
[9] ESET
The
http://www.eset.com/int/about/press/articles/article/eset-and-sucuri-uncover-linuxcdorkeda-apache-webserver-backdoor-the-
most-sophisticated-ever-affecting-thousands-of-web-sites/, 2013.

Linux/Cdorked.A:
Backdoor.

Sucuri
Sophisticated

and
Most

Uncover

Apache

[34] S. Wang and N. Shroff. Security game with non-additive utilities and
multiple attacker resources. Proceedings of the ACM on Measurement
and Analysis of Computing Systems, 1(1):13, 2017.

[35] M. Zhang, Z. Zheng, and N. B. Shroff. A game theoretic model for de-
fending against stealthy attacks with limited resources. In International
Conference on Decision and Game Theory for Security, pages 93–112.
Springer, 2015.

[36] Z. Zheng, N. B. Shroff, and P. Mohapatra. When to reset your keys:
In AAAI Conference

Optimal timing of security updates via learning.
on Artiﬁcial Intelligence (AAAI), pages 3679–3685, 2017.

IX. APPENDIX

[10] A. Coviello.

Open letter

to RSA customers, March 17, 2011.

http://www.rsa.com/node.aspx?id=3872.

[11] T. Alpcan and T. Bas¸ar. Network Security: A Decision and Game-

Theoretic Approach. Cambridge University Press, 2010.

[12] B. An, M. Brown, Y. Vorobeychik, and M. Tambe. Security Games
with Surveillance Cost and Optimal Timing of Attack Execution.
In
International Conference on Autonomous Agents and Multiagent Systems
(AAMAS), 2013.

[13] A. Basak, J. ˇCern`y, M. Gutierrez, S. Curtis, C. Kamhoua, D. Jones,
B. Boˇsansk`y, and C. Kiekintveld. An initial study of targeted personality
models in the ﬂipit game. In International Conference on Decision and
Game Theory for Security, pages 623–636. Springer, 2018.

[14] B. Bencs´ath, G. P´ek, L. Butty´an, and M. F´elegyh´azi. The Cousins of
Stuxnet: Duqu, Flame, and Gauss. Future Internet, 4:971–1003, 2012.
[15] K. D. Bowers, M. E. V. Dijk, A. Juels, A. M. Oprea, R. L. Rivest, and
N. Triandopoulos. Graph-based approach to deterring persistent security
threats. US Patent 8813234, 2014.

[16] K. D. Bowers, M. van Dijk, R. Grifn, A. Juels, A. Oprea, R. L.
Rivest, and N. Triandopoulos. Defending Against the Unknown Enemy:
Applying FLIPIT to System Security. In Conference on Decision and
Game Theory for Security (GameSec), 2012.

A. Proof of Lemma IV.4

Proof. In order to get the attacker’s best responses against
any defender’s deterministic strategies, we can divide (6) into
N ∗ L sub-optimization problems

s.t.

min
Wi,k

E[min(Wi,k + αi,k, Xi,k)]ri + P (Wi,k < Xi,k)CA
i
T
E[min(Wi,k + αi,k, Xi,k)] − E[min(Wi,k, Xi,k)]
T

≤ Mi,k
(29)
Li
k=1 Mi,k = M and Mi,k can be arbitrary
where
positive number. Note that we consider the equivalent mini-
mization problem by taking the negative of the target function
of (3) and omitting the constant part. We claim that, the

N
i=1

P

P

optimal solution to (29) is to allocate as much budget as
possible to P (Wi,k = 0), that is

W ∗

i,k =

w.p. p∗
i,k

0
≥ Xi,k w.p. 1 − p∗
i,k

(

(30)

p∗
i,k

where
min(1,
ri(E[min(αi,k, Xi,k)] − Xi,k) + CA
otherwise.

=

Mi,kT
E[min(αi,k,Xi,k)] )

i < 0, and p∗

if
i,k = 0

Since Mi,k is any number such that

Li
k=1 Mi,k =
M , the optimal solution of (6) also satisﬁes the same structure
of (30). We then prove our claim. For simplicity, we assume
that Wi,k is a discrete r.v., and without loss of generality, it
has the following p.m.f

N
i=1

P

P

Wi,k = 


w.p. p0
w.p. pi, i = 1 · · · n

0
vi
≥ Xi,k w.p. 1 −

n
j=0 pj

(31)

where n ∈ N such that 0 < v1 < v2 < . . . < vn < Xi,k. The
following proof can be adapted to the continuous Wi,k as well
by replacing sums with integrals and p.m.f with p.d.f.



P

Putting (31) into (29), attacker’s problem can then be

converted to the following form

n

min

pj(ri[E[min(vj + αi,k, Xi,k)] − Xi,k] + CA

i ) + Xi,kri

j=0
X

(32)
n
j=0 pjE[min(αi,k, Xi,k − vi)] ≤

with two constraints:

Mi,kT and

n
j=0 pj ≤ 1. where v0 = 0.

P

is recovered,

Let J({p0, ..., pn}) denote the objective function in (32).
P
Since ri(E[min(αi,k, Xi,k)] − Xi,k) + CA
i < ri(E[min(vj +
αi,k, Xi,k)] − Xi,k) + CA
i , if ri(E[min(αi,k, Xi,k)] − Xi,k) +
CA
i ≥ 0, J({p0, ..., pn}) is minimized by setting pj =
0, ∀j = 0, ..., n, which implies Wi,k ≥ Xi,k w.p.1. Such
condition describes the case that even if the attacker attacks
the node immediately after it
its reward is
the attacker never attacks. If
still
less than 0. Therefore,
ri(E[min(αi,k, Xi,k)] − Xi,k) + CA
i < 0, we claim that the
optimal solution is to allocate as much budget Mi,kT as
possible to p0, that is, we set all pj = 0, 1 ≤ j ≤ n,
E[min(αi,k,Xi,k)] ). This is clearly true if
and p0 = min(1,
ri(E[min(vj + αi,k, Xi,k)] − Xi,k) + CA
i ≥ 0. Therefore, it
sufﬁces to consider the case when ri(E[min(αi,k, Xi,k)] −
Xi,k) + CA
i < 0.
optimal
if
then we can ﬁnd another
0 > p0. We

To
solution
p0 < min(1,
optimal solution {p′
distinguish the following two cases:

i < ri(E[min(vj + αi,k, Xi,k)] − Xi,k) + CA
prove

{p0, p1, ..., pn}
Mi,kT
E[min(αi,k,Xi,k)] ),
1, ..., p′
0, p′

consider
(32). We

n} such that p′

claim,
to

show that

Mi,kT

the

an

P

n
Case 1: p0E[min(αi,k, Xi,k)] +
j=1 pjE[min(αi,k, Xi,k −
vi)] < Mi,kT . Then by the optimality of {p0, p1, ..., pn} and
the assumption that ri(E[min(vj +αi,k, Xi,k)]−Xi,k)+CA
i <
n
j=0 pj = 1. Let j ≥ 1 denote an index such
0, we must have
that pj > 0. Then there must exist a small amount △p > 0
j = p′
such that p′
k = pk, ∀k 6= 0 and
k 6= j is again a feasible solution to (32). We further have
0, ..., p′

J({p0, ..., pn}) − J({p′
= △p(ri[E[min(vj + αi,k, Xi,k)] − Xi,k] + CA
i )

P
0 = p0 + △p, p′

j − △p, p′

n})

13

− △p(ri[E[min(αi, Xi,k)] − Xi,k] + CA
i )

= △pri(E[min(vj + αi,k, Xi,k)] − E[min(αi,k, Xi,k)])
≥ 0

n
Case 2: p0E[min(αi,k, Xi,k)] +
j=1 pjE[min(αi,k, Xi,k −
vi)] = Mi,kT . Again let j ≥ 1 denote an index such
that pj > 0. Then there must exist a small amount
△M > 0 such that p′
j =
0 = p0 +
k = pk, ∀k 6= 0 and k 6= j is a
pj −
feasible solution to (32). We further have

△M
E[min(αi,k,Xi,k−vj )] , p′

△M
E[min(αi,k,Xi,k)] , p′

P

=

=

n})

J({p0, ..., pn}) − J({p′

0, ..., p′
△M (ri[E[min(vj + αi,k, Xi,k)] − Xi,k] + CA
i )
E[min(αi,k, Xi,k − vj)]
△M (ri[E[min(αi,k, Xi,k)] − Xi,k] + CA
i )
E[min(αi,k, Xi,k)]

−

△M
E[min(αi,k, Xi,k − vj)]
△M
E[min(αi,k, Xi,k)]

−

(rivj − riXi,k + CA
i )

(−riXi,k + CA
i )

≥ 0

B. Proof of Theorem IV.3
Proof. When the attacker’s strategy is an ergodic Markov
chain, the pi,k’s time-average distribution is the same as its
steady state distribution. Therefore the defender’s problem (1)
can be transferred to the following

max
{Xi,k},Li

lim
T →∞

E

N

(cid:20)

i=1 (cid:18)
X

−

LiCD
i + T ri
T

(

+

P

Li
k=1 E[pi,k] min(αi,k, Xi,k) + (1 − E[pi,k])Xi,k) · ri

T

(33)
with the same resource constraint in (2) where the expectation
in the numerator is with respect to the steady-state distribution
of pi,k. We ﬁnd that (33) is the same as (1) if we set

(cid:19)(cid:21)

W ⋆

i,k =

0
∞

(

w.p. E[pi,k]
w.p. 1 − E[pi,k]

(34)

Here, E[pi,k]
is the expected value of pi,k’s steady state
distribution. Therefore, based on Lemma IV.1 and Theo-
rem IV.1, we know that the periodic strategy is defender’s
best response.

C. Proof of Theorem IV.4
Proof. For simplicity, we assume there is only one node and
the attacking time αi,k ∀i, k is deterministic. (We omit all the
subscript i in this proof since there is only one node and use
α to represent αi,k ∀k). The defender’s Markovian strategy
has two states x1 and x2 referring the two defending periods
whose transition probabilities are as follows: P (Xk+1 =
x2|Xk = x1) = u and P (Xk+1 = x1|Xk = x2) = v. Let π1
and π2 represent the probability that Xk = x1 and Xk = x2 in
steady state, respectively. We have π1 = v
u+v .
Since the attacker can observe the defender’ defending period,
the attacking strategy may depend on the defender’s state
(the previous defending period). Let p1 denote the attacking

u+v and π2 = u

14

probability when the attacker observes the defender using
X1 in the previous defense move, and p2 as the attacking
probability for X2.

We compute the average payoff for the attacker per defense
move. Given the defender uses x1 in the previous defense
move, the expected payoff for the attacker is SXk−1=x1 =
[(1 − u) · (x1 − α)p1 + u · (x2 − α)p1] · r − p1CA. If the
defender uses x2 in the previous defense move, the attacker’s
expected payoff is SXk−1=x2 = [vp2(x1 − α)+ (1 − v)p2(x2 −
α)] · r + p2CA. Here, we assume x1 ≥ α and x2 ≥ α. (The
defender has no incentive to set x1 or x2 smaller than α).
Further, since the Markov chain is time reversible, we also
have P (Xk−1 = x2|Xk = x1) = u and P (Xk−1 = x1|Xk =
x2) = v. For attacker’s budget constraint, we have

E[

Li
k=1 min(Wk + α, Xk) − min(Wk, Xk)]

T

P

=π1 · E[min(Wk + α, x1) − min(Wk, x1)|Xk = x1]
+π2 · E[min(Wk + α, x2) − min(Wk, x2)|Xk = x2]
=π1[(1 − u)p1α + up2α] + π2[(1 − v)p2α + vp1α]
=(π1p1 + π2p2)α

Then, the attacker’s optimization problem becomes

max
p1,p2

π1SXk−1=x1 + π2SXk−1=x2

s.t. π1p1 + π2p2 ≤ M/α
0 ≤ p1, p2 ≤ 1

(35)

Since (35) is a fractional knapsack problem, it’s easy to show
that setting p1 = p2 is not optimal in general, meaning that the
i.i.d. strategy is NOT the attacker’s optimal response against
Markovian defending strategy.

D. Proof of Lemma VI.3
Proof. Suppose the set allocation and ρd are ﬁxed, which
means md and mi ∀i are also ﬁxed. According to Lemma VI.2,
we can now convert (23)-(24) to the following problem:

max
mi,i∈F

[mi(riαi − CD

i ) − ri] −

ri −

miCD
i

i∈F
X
+ md(prdαd − CD

i ) − prd

i∈G
X

i∈E
X

with constraints:

(36)
i∈E mi − md,
i∈F mi ≤ B −
i∈F αimi + pαdmd ≤ M and 0 ≤ mi ≤ mi ∀i ∈ F . where

p = min{1,
P

P
M−Pi∈F αimi
αdmd

}.

P

Case 1: If

M−Pi∈F αimi
αdmd

≤ 1, we put p =

M−Pi∈F αimi
αdmd

back into the target function of (36) and convert it to

max
mi,i∈F

[mi(riαi − CD

i ) − ri] −

ri −

miCD
i

i∈F
X
+

M −

i∈G
X

i∈E
X

rd(αdmd − 1) − mdCD
d

i∈F αimi

αdmd
P
i∈F mi ≤ B −

(37)
i∈E mi − md and 0 ≤

with constraints:
mi ≤ mi ∀i ∈ F .

P

It is easy to see that (37) is a fractional knapsack problem.
Thus, there is at most one fractional variable which means at
most one mi < mi.

P

Case 2: If

j ≥ rkαk − CD

M−Pi∈F αimi
> 1, the attacker’s budget is not
αdmd
fully utilized and all p⋆
i in (23) equal to 1. Thus, the sets D and
E are empty. Now suppose there exist two nodes j and k in F
with mj < mj and mk < mk. Without loss of generality, by
assuming rjαj − CD
k , we can always increase
the defender’s payoff by decreasing mk and increasing mj
until either mj = mj or mk = 0. If mk = 0, node k is in set
G. Here, if the attacker’s budget is fully utilized (as in Case
1), we can not guarantee the new payoff by decreasing mk
and increasing mj is always bigger, since αk may be much
smaller than αj, making the increase of mj is very small due
to limited attacker’s budget.

Above all, we can claim that there exists an optimal solution

with at most one node in set F with mi < mi.

E. Proof of Theorem VI.1

Proof. If the set G is empty in the optimal solution P ⋆,
Algorithm 1 computes the optimal payoffs for the defender
by solving (25). Then, we have maxd,f V al(d, f ) = P ⋆.
Therefore, |Palg |

|P ⋆| = 1.

If the set G is not empty in the optimal solution P ⋆, we
ﬁrst consider the loss of performance due to ρstep. Denote
ρ⋆ as the optimal ρd for computing P ⋆ and ρ′ the ﬁrst ρd
that is greater than ρ⋆ in Algorithm 1. Let m⋆
i = mi(ρ⋆)
i = mi(ρ′). Let |Pρ′ | refer to the total cost when ρ⋆
and m′
increases to ρ′ for the optimal solution P ⋆. By increasing ρ⋆
to ρ′, each m⋆
i and the total cost increases in
two parts. The ﬁrst part is due to the decrease of m⋆
i for all i
in F . The second part comes from sets E and D. Since m⋆
i
decreases, the attacker has extra budget to attack the nodes in
sets E and D, moving these nodes to sets F and D. For all
sets F , D, E and G above, we refer to the set allocation in
optimal solution P ⋆. Let HF and HE denote the increase of
total cost from the two parts, respectively. We have

i decreases to m′

HF =

=

ri(1 − m′

iαi) + m′

iCD

i − ri(1 − m⋆

i αi) − m⋆

i CD
i

i∈F (cid:20)
X

△mi(riαi − CD
i )

(cid:21)

i∈F
X
where △mi = m⋆

i − m′
i.

Let p′

d and p⋆

node in set D under ρ′ and ρ⋆, respectively. Denote p′
attacking probability for node i under ρ′. We have

d be the attacker’s attacking probability for the
i as the

HE =

p′
iri(1 − m′

iαi) + m′

iCD

i − m⋆

i CD
i

i∈E (cid:20)
X
drd(1 − m′
iri(1 − m′
p′

dαd) + m′
iαi)

+ p′

≤

dCD

d − p⋆

(cid:21)
dαd) − m⋆
drd(1 − m⋆

dCD
d

i∈E∪D
X
Also note that p′
constraint such that

(38)
i, i ∈ E ∪ D must satisfy the resource

N

im′
p′

iαi ≤

△miαi

(39)

i∈E∪D
X

i=1
X

where the right-hand side represents an upper bound on the
extra budget for nodes in sets E and D. From (38) and (39),

we have

N

HE ≤

We further have

i=1
X

△miαi · max
{

i

ri(1 − αim′
i)
αim′
i

}

△mi =

≤

ri
(ρ⋆ + ri)αi + CA
i

−

ri
(ρ′ + ri)αi + CA
i

ρstepriαi

[(ρ⋆ + ri)αi + CA

i ][(ρ′ + ri)αi + CA
i ]

15

(40)

Since ρ′ is one of the ρd that Algorithm 1 iterates through, we
have |Palg| ≤ |Pρ′ |. Then, we can compute the approximation
ratio as follows:

≤

|Pρ′ | − |P ⋆|
|P ⋆|

|Palg| − |P ⋆|
|P ⋆|
i∈F ∪D △mi(riαi − CD
i )
|P ⋆|

≤

=

HF + HE
|P ⋆|

P
(

P

N

i=1 △miαi) · maxi{ ri(1−αim′
|P ⋆|
riαi(riαi−CD
i )
[(ρ⋆+ri)αi+C A
i ]2

i∈F ∪D ρstep

αim′
i

i)

}

|P ⋆|

+

≤

+

N
i=1

P
(

P

ρstepriα2
i

[(ρ⋆+ri)αi+C A

i ] ) · maxi{ρ′ + C A

i
αi

}

i ][(ρ′+ri)αi+C A
|P ⋆|
2(riαi − CD

≤ ρstep ·

N
i=1

+

P

≤ ρstep

(cid:18)
N maxi

+

i∈F ∪D m⋆
i∈F ∪D[ri(1 − m⋆

i

(cid:18) P
riα2
i
P
i ·C A
i

C A

· maxi

N
i=1

+

C A
i
αi
i∈G ri

P
i αi(riαi − CD
i )
P
riCD
i
αi
C A
i
mini ri

maxi

C A
i
αi

m⋆

{
max
i

riαi
C A
i

maxi

i αi) + m⋆

i )αi/ri
i CD
i ]
riαi
(ρ⋆+ri)αi+C A
i

(cid:19)

}

+ N maxi

riαi
C A
i

αi
CD
i

} + N

maxi

riαi
C A
i

(1 + maxi

mini ri

≤ ρstep

max
i



{

≤ ρstep · O(N )



(cid:19)
maxi

αi
C A
i

C A
i
αi

)





(41)

A similar argument can be used to bound the loss of perfor-
mance due to rounding parameter δ. The only difference is the
decrease of m⋆
i ]2 + δ.
|Palg |
|P ⋆| ≤

The rest is very similar to (41). It follows that
1 + (ρstep + δ)O(N ) as desired.

i which satisﬁes △mi ≤

ρstepriαi
[(ρ⋆+ri)αi+C A

