TrustGNN: Graph Neural Network based Trust
Evaluation via Learnable Propagative and
Composable Nature

Cuiying Huo, Di Jin, Chundong Liang, Dongxiao He, Tie Qiu and Lingfei Wu

1

2
2
0
2

y
a
M
5
2

]

G
L
.
s
c
[

1
v
4
8
7
2
1
.
5
0
2
2
:
v
i
X
r
a

Abstract—Trust evaluation is critical for many applications
such as cyber security, social communication and recommender
systems. Users and trust relationships among them can be seen
as a graph. Graph neural networks (GNNs) show their powerful
ability for analyzing graph-structural data. Very recently, existing
work attempted to introduce the attributes and asymmetry of
edges into GNNs for trust evaluation, while failed to capture some
essential properties (e.g., the propagative and composable nature)
of trust graphs. In this work, we propose a new GNN based
trust evaluation method named TrustGNN, which integrates
smartly the propagative and composable nature of trust graphs
into a GNN framework for better trust evaluation. Speciﬁcally,
TrustGNN designs speciﬁc propagative patterns for different
propagative processes of trust, and distinguishes the contribution
of different propagative processes to create new trust. Thus,
TrustGNN can learn comprehensive node embeddings and pre-
dict trust relationships based on these embeddings. Experiments
on some widely-used real-world datasets indicate that TrustGNN
signiﬁcantly outperforms the state-of-the-art methods. We further
perform analytical experiments to demonstrate the effectiveness
of the key designs in TrustGNN.

Index Terms—Social trust evaluation, social networks, graph

neural networks, trust chains.

I. INTRODUCTION

With the evolution of communication technology and the
widespread popularity of the Internet, the number of social
network users is growing rapidly. Online social networks
such as Facebook, LinkedIn and Twitter have become an
integral part of their user’s daily life. However, due to the
inherent openness of online social networks, anyone can join
these networks, which inevitably provides an opportunity for
malicious users to spread incorrect or illegal information [1],
[2]. Therefore, evaluating social trust, which plays a crucial
role in the functionality and operation of social networks, has
become an important topic in online social network analysis.
Trust is the extent by which one user (trustor) expects
that another user (trustee) performs a given action [3]. Trust
evaluation is to evaluate the pairwise trust relationship between
two users who are directly or indirectly connected within
online social networks. As shown in Fig. 1, trust-based online
social networks usually contain multiple types of social trust
relationships. The trust relationship is usually asymmetric, that

Cuiying Huo, Di Jin, Chundong Liang, Dongxiao He and Tie Qiu are
with the College of Intelligence and Computing, Tianjin University, Tianjin
300350, China. E-mail: huocuiying@tju.edu.cn; jindi@tju.edu.cn; liangchun-
dong@tju.edu.cn; hedongxiao@tju.edu.cn; qiutie@ieee.org.

Lingfei Wu is with the JD.COM Silicon Valley Research Center, 675 E
Middleﬁeld Rd, Mountain View, CA 94043 USA. E-mail:lwu@email.wm.edu.

Fig. 1. The social network schema based on social trust relationships. The
arrow points from the trustor to the trustee. Different colored arrows represent
different types of social trust relationships.

is, there may be two trust relationships in opposite directions
between two users. There are many different attempts proposed
to evaluate the social trust in online social networks [4]–
[6]. E.g., the subjective logic-based methods [7]–[9], which
follow the assumptions of cognitive recognition and introduce
the uncertainty inference process for the subjective nature
of trust. The probability statistics-based methods [10]–[12],
rely on statistical distributions to represent and model so-
cial trust relationship in a computational way. The machine
learning-based methods [3], [13], use some machine learning
techniques such as matrix factorization to model the trust
evaluation task as a learnable problem. However, these existing
approaches usually have high computational complexity, or
have poor performance because they do not consider the user’s
attribute information.

In recent years, with the great success of deep learning,
Graph Neural Networks (GNNs) [14]–[16], as powerful tools
for processing graph data, have shown superior performance
on various network analysis tasks, such as node classiﬁca-
tion [17], [18], link prediction [19], [20] and recommenda-
tion [21], [22]. The essence of GNNs is the process of infor-
mation propagation and aggregation guided by graph structure.
These GNN-based methods obtain meaningful representation
of nodes/edges in a network by integrating the neighborhood
information of nodes/edges. On the other hand, an online
social network based on social trust can be thought of as a
trust graph where the nodes are social users and the edges are
the trust relations between them. The edge in the graph can
represent the trust relationship between two nodes. Therefore,
it is signiﬁcant to utilize the powerful representation learning
capabilities of GNN for trust evaluation tasks.

To our best knowledge, there has been only one attempt
to apply GNNs to trust evaluation in online social networks,
i.e., Guardian [23], presented very recently. Guardian divides

 
 
 
 
 
 
2

the neighbor nodes into the set of in-degree neighbor nodes
and the set of out-degree neighbor nodes, and uses a graph
convolutional network [24] (GCN) layer for information ag-
gregation respectively. It uses an mean aggregator to aggregate
the information of different ﬁrst-order neighbors, and aggre-
gates high-order neighbor information by stacking multiple
GCN layers. But the design of Guardian does not take full
account of the nature of social trust in social networks, e.g.,
the propagative and composable nature, which are however
essentially important for trust evaluation. To sum up, in order
to better apply GNNs to trust evaluation, there are three main
challenges:

1) The propagative nature indicates that trust can be passed
between users along a chain, so we can obtain the
trust value between any two users who are indirectly
connected through the chain. Guardian fails to explicitly
consider the role of the social trust chain, which will
result in redundancy or lack of effective information. In
this context, the ﬁrst challenge is how we can explicitly
integrate the trust chain into GNN frameworks in order
to better model the propagative nature.

2) Due to the asymmetry of the trust relationship, the direc-
tionality of trust propagation also needs to be considered.
Simply grouping neighbor nodes based on in-degree and
out-degree is not suitable for trust chains. Therefore,
the second challenge is how to deﬁne a directional
propagation pattern for trust chains.

3) The composable nature indicates us that when there are
multiple trust chains between two users, the trust value
needs to be aggregated by considering the interaction
between these chains. The mean aggregator of Guardian
cannot distinguish the information from differnet chains.
Thus,
the third challenge is how to assign different
weights according to the importance coefﬁcients of
neighbor nodes to consider the composable nature more
comprehensively.

Facing the above challenges, we propose a GNN-based trust
evaluation method that comprehensively utilizes the nature
of social trust, namely TrustGNN. Since there are usually
multiple types of trust relationships in online social networks,
we ﬁrst deﬁne multiple speciﬁc trust chains according to the
trust types. The trust chain is composed of multiple users and
trust relationships. Inspired by knowledge graph embedding
methods, we deﬁne the propagative pattern of information
on chains by considering the interaction between users and
trust relationships in a chain, as well as the directionality
of social trust. By doing so, the propagative nature and the
asymmetry of social trust can be obtained. Moreover, in online
social networks, a target node usually needs to aggregate
information from multiple trust chains, i.e., the composable
nature of social trust. Considering that different types of trust
chains have different impact on the target node, we adopt
a learnable attention [25], [26] to learn their contributions
for better capturing the composable nature of online social
networks.

necessary for GNN to deal with trust evaluation. And then,
we introduce that GNN, as an effective tool for processing
graph-structured data, can be used for trust evaluation in a
more natural way. Second, we propose a GNN-based online
social network trust evaluation method (TrustGNN), which
more comprehensively and essentially integrates the prop-
agative, composable, and asymmetric nature of social trust
into the same GNN framework. Third, extensive experiments
and analyses on two online social networks demonstrate the
superiority of the proposed method over the state-of-the-art
methods.

The rest of the paper is organized as follows. Section II gives
the problem deﬁnitions and analysis. Section III proposes the
new approach TrustGNN. We conduct extensive experiments
in Section IV. Finally, we discuss related work in Section V
and conclude in Section VI.

II. PROBLEM DEFINITION AND ANALYSIS

Trust Graph. In this paper, we deﬁne trust relationships
in the online social network as a directed trust graph G =
(V, E, R, φ), where node set V represents users and edge set
E represents trust relationships among users. The trust type set
R enumerates all trust relationship types in the graph G. The
mapping function φ : E → R maps observed edges to trust re-
lationship types, so each edge strictly corresponds to a speciﬁc
trust relationship. Moreover, the trustworthiness is different in
different application domain. For example, trustworthiness can
be simply classiﬁed into two types, i.e., R = {Trust, Distrust}.
But in some more complicated situations such as in Advogato1
and Pretty-Good-Privacy2 (PGP), the trust relations have four
types, i.e., R = {Observer, Apprentice, Journeyer, Master}.

Trust Evaluation. The trust evaluation task is to predict the
unobserved trust relationships in a trust graph G. Speciﬁcally,
given a trust graph G = (V, E, R, φ), the goal is to train a
model f (·). For nodes u ∈ V, v ∈ V, and edge hu, vi /∈ E,
the model f (·) can predict the trust relationship for the two
nodes, i.e., f (hu, vi) → R. Note that trust relationships are
directed, and the trust relationship from node u to node v does
not equal to the relationship from node v to node u. Therefore,
f (hu, vi) 6= f (hv, ui).

Properties in Trust Graph. Before discussing the proposed
method, we ﬁrst show some insights about trust graphs and
analyze some properties which are used in our method. For any
two nodes u and v, there will be a kind of trust relationship
from node u to node v if hu, vi ∈ E. We deﬁne u as the
trustor and v the trustee. The two common-used properties
in trust evaluation are the propagative nature and composable
nature of social trust [23]. Speciﬁcally, the propagative nature
of social trust means that trust can be passed among nodes,
creating trust chains that connects two nodes who are indi-
rectly connected in the graph. For example, in Fig. 2(a), node
u trusts node a with a trust value of 2 and node a trusts
node v with a trust value of 1. There is a trust chain between
node u and node v, which can be taken as evidence to create
trust relationship from node u to node v. The composable

To summarize, the main contributions of this paper are
as follows. First, we discuss and clarify what is essentially

1http://trustlet.org/datasets/advogato/
2http://networkrepository.com/arenas

TABLE I
NOTATIONS AND EXPLANATIONS

Notations

Explanations

xnode
xedge
p
Pj
hv, H
ri
zv, Z
q
wPj
αPj
W , b
Y
˜Y

The attributes of a node.
The attributes of an edge.
A trust chain.
The j-th type of trust chains.
The latent representation of node v / all nodes.
The latent representation of the i-th edge type.
The ﬁnal node embedding vector of node v / all nodes.
The attention vector.
The importance of chain type Pj.
The normalized weight of chain type Pj.
The parameters of neural networks.
The predicted trust relationships.
The ground truth.

nature of social trust means that there may be several trust
chains between two nodes, and these chains interact to provide
evidence for us to create a new trust relationship between these
two nodes (Fig. 2(b)).

In this paper, we deﬁne two nodes connected by a trust
chain as neighbor nodes. In particular, the head node u is the
trust chain based trustor neighbor of the tail node v, while
the tail node v is the trust chain based trustee neighbor of the
head node u.

Graph Neural Networks (GNNs). GNNs [14], [15] are
powerful tools for analyzing graph-structural data. A GNN
can be interpreted as smoothing local information through
propagation and aggregation operations in a graph, and ﬁnally
learning node representations that can be applied to various
downstream tasks. After k iterations of propagation and ag-
gregation, a node’s representation can capture topology and
attribute information within its k-hop neighborhood in the
graph. Formally, in the k-th layer, the representation h(k)
of
u
node u is

v = Prop(k)
a(k)

(cid:16)h(k−1)

v

(cid:17) ,

v ∈ N (u)

u = Agg(k)
h(k)

(cid:16)h(k−1)

u

, {a(k)
v

: v ∈ N (u)}(cid:17)

(1)

(2)

where N (u) is the set of the direct neighbors of node u,
Prop(k) (·) and Agg(k) (·) are two functions implemented by
neural networks in the k-th GNN layer. Prop(k) (·) corresponds
to the node representation transformation in the propagation
process and Agg(k) (·) aggregates the transformed neighbor
node representations and its own representation.

In this work, we use GNN framework to learn node em-
beddings and evaluate trust relationships between two nodes
based on their embeddings. The key novelty here is that
we design a new GNN to simultaneously model propagative
and composable nature of trust graphs. Intuitively, different
trust chains should have different effects for creating trust.
there should be different propagation rules on
Therefore,
different trust chains in GNNs. In this way, the propagative
nature in trust graphs can be well learned. Moreover, when
GNNs aggregate neighbor information from different trust
chains, it should distinguish the contribution of information
from different chains and generate node representations based

3

(cid:28649)
(cid:28649)

(cid:28582)

(cid:28582)

(cid:28581)

(cid:28581)

(cid:28629)
(cid:28629)

(cid:28650)

(cid:28650)

(cid:28649)

(cid:28649)

(cid:28650)

(cid:28650)

(cid:28582)

(cid:28582)

(cid:28629)

(cid:28629)

(cid:28581)

(cid:28581)

(cid:28581)

(cid:28581)

(cid:28630)

(cid:28630)

(cid:28583)

(cid:28583)

(a) The propagative nature

(b) The composable nature

Fig. 2. The illustrations of properties in trust graphs focused in this work. (a)
The propagative nature. Trust is passed from node u to node v along a chain,
providing the evidence to create trust relationships between nodes u and v.
(b) The composable nature. Trust is passed from node u to node v along two
chains with different types. The two trust chains that need to be combined to
create a new trust relationship between nodes u and v .

on their contributions. This is because a trust chain composed
of relationships with high value is more helpful to create a new
trust relationship. Thus, GNNs can capture the composable na-
ture in trust graphs and learn comprehensive node embeddings
for trust evaluation.

In the following we will show the proposed model based
on the ideas discussed above. All notations that we used in
the paper and their explanations are provided in Table I.

A. Overview

III. METHOD

In this section, we present our graph neural network (GNN)
based trust evaluation method (TrustGNN). Since the propaga-
tive and composable nature is the basis for creating new trust,
we integrate these two properties into the GNN framework,
and capture them in a learnable manner. The overview of
TrustGNN is illustrated in Fig. 3, which consists of four
components. i) TrustGNN ﬁrst
initializes the attributes of
nodes and edges and projects them into a latent space, i.e.,
attribute transformation. ii) The information is propagated
along trust chains. Here TrustGNN extends knowledge graph
embedding methods to GNN to better model the propagative
pattern of trust, and further considers the asymmetry of trust,
i.e., trust chain based propagation. iii) TrustGNN identiﬁes the
information propagated from different chains and aggregates
the information in a discriminable way, and ﬁnally generates
node embeddings,
iv)
TrustGNN uses a multilayer perceptron layer to predict trust
relationships based on node pair embeddings, i.e., the predictor
layer.

trust chain based aggregation.

i.e.,

B. Attribute Transformation

In a complete trust graph G = (V, E, R, φ),

there are
homogeneous nodes and heterogeneous edges, and nodes and
edges both have their attributes. These nodes and edges may
have different attribute vector dimensions. Even though they
happen to have same dimension, they may still be in different
vector spaces. Therefore, we need to transform these attributes
into a common vector space to feed to the GNN framework.
TrustGNN uses a linear transformation to transform all node

attributes. For each node v ∈ V, there is

hv = Wnode · xv

(3)

4

4

3

2

6

1

5

6

1

as Trustee

3

4

1

5

2

1

as Trustor

4

6

4

6

4

5

4

1

1

1

1

1

1

1

3

5

2

P
r
o
p
a
g
a
t
i
o
n

+

+

+
+

A
A

t
t
t
t
e
e
e
e
n
n
n
n
t
t
i
i
o
o
n
n

A

t
t
t
t
e
e
e
n
n
n
t
t
t
t
i
i
o
o
n
n

 !

" !

 !

" !
" " 

 !

" !

…
…

P
r
e
d
i
c
t
o
r

R
e
l
a
t
i
o
n
s
h
i
p

P
r
e
d
i
c
t
e
d

Attribute Transformation

Propagation

Aggregation

Prediction Layer

Fig. 3. The ﬂow chart of TrustGNN (take maximum length of the trust chain as 2 as an example). TrustGNN ﬁrst transforms attributes of nodes and edges into
a common vector space, and then propagate and aggregate transformed attributes based on trust chains to generate node embeddings. Due to the asymmetry
of trust, TrustGNN generates two kinds of embeddings from the perspective of trustee and trustor, and concatenates them as a ﬁnal embedding. TrustGNN
ﬁnally predicts the trust relationships based on embeddings of trustor-trustor node pairs.

where xv is the attribute vector of node v, hv the transformed
representation of node v and Wnode a learnable parameter
matrix. TrustGNN has different linear transformations corre-
sponding to different types of edges. For the i-th type of edge,
there is

ri = Wedge−i · xedge−i

(4)

where xedge−i is the attribute vector of the i-th edge type,
Wedge−i a learnable parameter matrix speciﬁc to the i-th edge
type, and ri the transformed representation of the i-th edge
type.

Note that not all datasets have completed attributes for nodes
and edges. For the datasets missing node or edge attributes,
we initialize these missing attributes as random vectors and
treat these vectors as a part of learnable parameters in neural
networks.

C. Trust Chain Based Propagation

In trust graphs, trust may be passed from one node to
another along a trust chain so that two nodes at head and tail
of a trust chain can create a new trust relationship, in which
the head node is a trustor and the tail node is a trustee. The
message passing in GNNs is a similar propagative pattern with
trust propagation in a trust graph. Therefore, we can integrate
trust chains into GNNs and make GNNs propagate information
along trust chains. However, the length of a trust chain can be
inﬁnite and there can be inﬁnite types of trust chains in a trust
graph. In TrustGNN, we limit the maximum length of the trust
chain to the preset hyper-parameter K, which is reasonable
because trust will decrease in the propagation process and a
too long trust chain is not beneﬁcial to creating new trust.

Consider a trustee node v and a trust chain p of length
rk−→ v, the node v should receive
k (k ≤ K) : u
the information from node u as well as edges {r1, ..., rk} in
the chain. Here, TrustGNN uses a RotatE-like method [27] to

r1−→ ...

compose the attributes of node u and edges {r1, ..., rk} in the
complex plane3

(5)

hp
v = hu ◦ r1 ◦ ... ◦ rk
where hu, r1, ...rk ∈ Cd, Cd denotes the complex plane, the
modulus |ri| = 1 and ◦ is Hadamard (element-wise) product.
Due to the propagation property of RotatE, the Hadamard
product among edges (r1 ◦ ... ◦ rk) can be seen as the new
type of composed relationship speciﬁc to the trust chain p,
and hp
v is the information that node v receives on the chain p.
Trust is asymmetric. It is worth noting that node v also
serves as a trustor node in a trust graph, and a comprehensive
node embedding should contain information from its trustee
role and trustor role. Thus, for the same trust chain p with node
v being the head (p : v

rk−→ u), TrustGNN computes

r1−→ ...

¯hp
v = hu ◦ ¯rk ◦ ... ◦ ¯r1

(6)

in Formula 5. Due to the
where ¯ri
is conjugate with ri
inversion property of RotatE,
the conjugate vector ¯ri can
present the inverse relationship of ri (trust and trusted), and
¯hp
v is the information that node v receives when node v serves
as a trustor node in trust chain p.

Discussions: 1) For the nodes in a trust chain, TrustGNN
only considers the attributes of the head/tail node but ignores
the nodes in between. This is because we just want to capture
the trust relationship between head and tail nodes through a
trust chain. Other nodes in the chain may be the head/tail
node in other chains and thus can be computed to create trust
relationships in other propagation processes. 2) RotatE [27]
is a knowledge graph (KG) embedding method. It maps each
entity and relation in a KG to the complex vector space and
deﬁnes each relation as a rotation of source entity to target

3We truncate a vector (h or r) into two as the real and imaginary parts

respectively.

 
entity. The propagation property of RotatE means that two
relations can be composed (Hadamard product) to generate a
new type of relations, which can be thought of as a new rota-
tion in complex plane. TrustGNN extends RotatE to compose
multiple relations (edges) to generate more complex relations.
The inversion property of RotatE means that two relations with
opposite semantics can be represented by conjugate vectors in
the complex plane. TrustGNN uses the inversion property to
compute propagative information from views of both trustor
and trustee of a node. Moreover, when TrustGNN computes
Formula 5 and Formula 6 from left to right, the intermediate
results exactly correspond to the representation of intermediate
nodes of a chain. This is another reason why we can ignore
the nodes inner a chain.

D. Trust Chain Based Aggregation

There are often multiple different types of trust chains in a
trust graph and these chains interact to provide evidence for us
to create a new trust relationship between the two nodes. Ac-
cordingly, a node aggregates information from several chains
with different types in our TrustGNN framework. TrustGNN
uses a learnable attention score [25], [26] to distinguish the
contribution of different types of chains. Before computing the
attention score, TrustGNN ﬁrst summarizes the information on
the chains sharing the same type. Consider a node v and a set
chains in the j-th type, TrustGNN aggregates the information
via a sum operation

v = WPj · 
hPj


hv +

X
ψ(p)=Pj

hp
v





(7)

where ψ(·) is a mapping function to indicate which type a trust
chain is, Pj the j-th type of trust chain, and WPj a learnable
parameter matrix speciﬁc to Pj. hPj
is the representation of
v
node v for the j-th chain type. Correspondingly, we use H Pj
to represent all nodes. Here, a sum operation means TrustGNN
treats chains with the same type equally, because chains with
the same type have the same propagative process (Formula 5)
and thus should have equal contribution for node embeddings.
Then, for the summarized information H P1 , H P2, ..., H Pj ,
TrustGNN aggregates them with different weights as chains
with different types have different impact on creating trust
and, moreover, there is usually a complex interaction between
different types of chains. TrustGNN learns weights through
an discriminative attention mechanism [25], [26] to model the
composable nature in trust graphs. Speciﬁcally, TrustGNN ﬁrst
transforms chain-type-speciﬁc representation (hPj ) through a
nonlinear transformation, and then measures the score of the
chain-type-speciﬁc representation as the similarity of trans-
formed representation with a chain-type-level attention vector
q. Furthermore, TrustGNN averages the score of all the chain-
type-speciﬁc node representations, which can be explained as
the importance of each chain type
1
|V| X
v∈V

Wattn · hPj
(cid:0)

qT · tanh

wPj =

v + b

(8)

(cid:1)

where Wattn is a learnable parameter matrix, b a bias vector, q
the chain-type-level vector of attention. The parameter Wattn

and b are shared for all chain types. Then, the softmax function
is adopted to normalize the score

5

αPj =

exp(wPj )
k
c=1 exp(wPc )
P

(9)

which can be interpreted as the contribution of the chain type
Pj. The higher the weight of Pj, the more contribution Pj
provides in the composable nature. TrustGNN aggregates these
chain-type-speciﬁc representations to obtain the embeddings

Z =

k

X

j=1

αPj · H Pj

(10)

Note that in Section III-C, TrustGNN computes node rep-
resentations from two aspects: the trustee role and the trustor
role. The embedding Z only aggregates the information about
the trustee role. Therefore, TrustGNN needs to compute an
embedding ¯Z for the trustor role and combines the two to get
a more comprehensive node embedding

(11)

¯Z =

k

X

¯αPj · ¯H Pj

j=1
where ¯H Pj is the node representations about the trustee role
on the Pj chain type, and ¯αPj is the corresponding weight
computed by Formula 9. Note that ¯αPj and αPj are irrelevant
because TrustGNN uses another parameters to compute ¯αPj ,
i.e., ¯Wattn and ¯b. This means that a chain will have different
contributions when it serves for embeddings about different
roles (trustee or trustor). TrustGNN ﬁnally combines Z and ¯Z
to obtain the ﬁnal embedding

Zf inal = W ·

Z
(cid:0)

(cid:1)

(12)

¯Z
(cid:13)
(cid:13)

where || is the concatenation operation and W a learnable
parameter matrix to transform the embeddings into a low-
dimensional space.

E. The Predictor Layer

TrustGNN is a trust evaluation model based on node embed-
dings. Speciﬁcally, given two nodes u and v as a trustor-trustee
pair, TrustGNN predicts their trust relationships based on their
embeddings

˜yu−v = σ (MLP(zu||zv))

(13)

where zu and zv are node embeddings (two vectors in Zf inal),
is the concatenation operation, MLP(·) is a multi-layer
||
perceptron (MLP), and σ(·) is an activation function. Note
that because of asymmetric property of trust relationships in
trust graphs, ˜yu−v 6= ˜yv−u. As the number of trust types in
trust graphs is limited, the trust evaluation task is equivalent
to the classiﬁcation task based on embedding pairs. TrustGNN
is a semi-supervised model and it minimizes cross-entropy
between the predicted values and ground-truth values as the
loss function

L = cross entropy(Y, ˜Y )

(14)

where Y is the observed categorical values in the trust graph
and ˜Y the predicted result by TrustGNN. TrustGNN is an end-
to-end model, as the parameters in predictor layer and that in
embedding module are updated together via back propagation,
under the guidance of this uniﬁed objective function.

6

TABLE II
STATISTICS OF DATASETS.

Datasets

Nodes

Edges

Diameter

Avg. Degree

Advogato
PGP

6,541
38,546

51,127
317,979

4.82
7.7

19.2
16.5

IV. EXPERIMENTS

In this section, we ﬁrst provide the experimental setup,
including dataset description, baselines for comparison, and
parameters and model settings. Then we show the comparison
results with baseline methods and ﬁnally give the ablation
experiments and parameter analysis.

A. Experiment Setup

1) Datasets: We adopt two widely-used, real-world datasets
for model evaluation (as done in most related works such as
Guardian [23], NeuralWalk [13] and OpinionWalk [9]). The
statistics of the two datasets are shown in Table II.

1) Advogato is a dataset collected from the online software
development community, in which a trust edge from
user P to user Q represents P’s trust in Q, representing
the ability of user Q in software development. The
trust relationships can be divided into four types, i.e.,
{Observer, Apprentice, Journeyer, Master}. Nodes and
edges in Advogato have no attributes so that we initialize
node attributes as random vectors and treat these vectors
as a part of learnable parameters of the neural networks.
2) Pretty-Good-Privacy (PGP) is a dataset obtained from
the public key certiﬁcation network, in which the trust
edge from user P to Q represents that user P attests to
user Q’s trust. Similarly, trust in the this dataset contains
four different levels of trust and attributes are initialized
by neural networks.

2) Baselines: We compare the proposed TrustGNN with
four state-of-the-art methods, corresponding to four popular
types of trust evaluation methods, i.e., a matrix factorization-
based method, a walk-based method, a deep neural network-
based method, and a GNN-based method.

1) Matri [3] uses matrix factorization to infer trust relation-
ships between users. It utilizes locally generated trust
relationships to characterize multiple complex latent
factors between each trustor and trustee, and further
introduces prior knowledge and trust propagation to
improve prediction accuracy. The trust relationship be-
tween each node pair is captured by computing the
similarity between the trustor’s latent vector and the
trustee’s latent vector in a learnable latent space.

2) OpinionWalk [9] uses random walk to model the trust re-
lationship between users. The method uses the breadth-
ﬁrst search method to create the trust relationship for ev-
ery two users who do not have a direct trust relationship,
uses Dirichlet distribution to model the data distribution,
and expresses the direct trust value between users in the
form of a matrix.

3) NeuralWalk [13] is a deep neural network based method.
It ﬁrst models the propagation and fusion of direct trust
among users in the trust social network by designing
a neural network module named WalkNet. Then, with
WalkNet as the neural subunit, the multi-hop social trust
among users in the network is captured in the form
of iterative neural subunits. This approach is the state-
of-the-art modelling scheme for trust evaluation, but it
typically requires greater computational and memory
complexity than other approaches.

4) Guardian [23] applies GNN to the trust evaluation
task for the ﬁrst time. It designs a trust convolutional
layer to model trust
interactions in social networks.
The method is also designed to incorporate the two
trust relationships of popularity and engagement into the
model learning process, respectively. It ﬁnally predicts
the trust relationship of each trustor-trustee pair based on
the representations. Note that our proposed TrustGNN
is also a graph neural network-based method, while
TrustGNN better models the propagative nature and
composable nature of trust among users to achieve better
performance.

3) Evaluation metrics: Follow the metrics used in
Guardian [23], we adopt two popular metrics to evaluate the
effectiveness of the new proposed method, including F1-score
and Mean Absolute Error (MAE). In the experiments, we run
each method 20 times and take the average of these results as
the ﬁnal result. Note that larger F1-score values indicate better
prediction performance, whereas smaller MAE values indicate
better prediction performance. For the split of the datasets,
since OpinionWalk is deductive, we conduct experiments with
randomly selected 1,000 trustor-trustee pairs for both datasets.
As for other baselines as well as our TrustGNN, we randomize
the two datasets into 80% trustor-trustee pairs to form the
training set and the rest for the test set. When computing
F1-score, we map the predicted relationship into categorical
values, i.e., {Observer: 0, Apprentice:1, Journeyer: 2, Master:
3}. When computing MAE, we follow the Matri [3] and
Opinion [9] to map the relationship into scalar values, i.e.,
{Observer: 0.1, Apprentice:0.4, Journeyer: 0.7, Master: 0.9}.
4) Parameter settings: For the baselines, we adopt their
default parameter settings as they often lead to the best
results. For our TrustGNN, we set learning rate to 0.005,
the dimensions of nodes and edge attributes to 1024, and the
dimension of attention vector (q) and representation vector (h,
r, z) to 128. We set the maximum length of trust chains K to
2 since it is typically sufﬁcient to model trust relationships in
online social networks. And when K is too large, there will
be additional computational cost and more noise may be intro-
duced. We implemented our proposed method using Python-
3.74 and Pytorch-1.65. All the experiments were conducted on
the same machine with Linux system (Ubuntu 5.4.0), Intel(R)
Xeon(R) CPU E5-2680, 128GB RAM and 2 NVIDIA 1080Ti
GPUs.

4https://www.python.org/
5https://pytorch.org/

7

TABLE III
PERFORMANCE COMPARISION WITH BASELINES. LARGER VALUES OF
F1-SCORE (AND SMALLER VALUES OF MAE) INDICATE BETTER RESULTS.
THE BEST RESULTS ARE IN BOLD.

TABLE IV
PERFORMANCE EVALUATION WITH DIFFERENT TRAINING SIZES ON
ADVOGATO. THE BEST RESULTS ARE IN BOLD.

Methods

Advogato

PGP

F1-Score MAE

F1-Score MAE

TrustGNN

74.4% 0.081

87.2% 0.083

Guardian

NeuralWalk

OpinionWalk

Matri

73.0%

74.0%

63.3%

65.0%

0.087

0.082

0.232

0.141

86.7%

0.086

–

66.8%

67.3%

–

0.251

0.136

B. Performance Comparisons

We ﬁrst evaluate the performance of TrustGNN on Ad-
vogato dataset. The experimental results are provided in
Table III where the best results are in bold. The proposed
TrustGNN outperformed all baselines. Compare to the second
best method, i.e., NeuralWalk, TrustGNN improves 0.4% in
terms of F1-Score. Correspondingly, the error rate reduces
by 1.9%. In terms of MAE, TrustGNN also achieves the
best performance, equivalent to the best baseline NeuralWalk.
We also evaluate TrustGNN on the larger PGP dataset and
the results are provided in Table III. Compared to Guardian,
TrustGNN improves 0.5% and reduces errors by 3.8% in terms
of micor-F1, and also achieves the best MAE score. Also of
note is that, because of the huge computational and memory
complexity of NeuralWalk, it fails to get the results on PGP
dataset (as the number of nodes/edges in PGP is ∼ 6 times
in Advogato). In contrast, TrustGNN is lightweight and can
meanwhile achieve the best performance.

Besides, as shown in Table III, there is a great gap be-
tween neural network-based methods (TrustGNN, Guardian,
NeuralWalk) and the others (Opinion, Matri). This means that
the powerful learning ability of neural networks allows it to
better solve the trust evaluation task. In the above three neural
networks-based methods, the newly proposed TrustGNN has
more elaborate designs. TrustGNN follows the principle of
knowledge graph embedding to propagate information on
chains, which can better model the propagative nature of social
trust. It also applies attention mechanism between different
types of chains, which is better to capture the composable
nature to distinguish the contributions of different type of
chains when creating new trust relationships.

We also evaluate TrustGNN on these two datasets with
different training and testing splits. Speciﬁcally, we set the
portions of training set as 40%, 60%, 80% and report the
performance in terms of F1-Score and MAE. We select
Guardian and Matri as comparision algorithms. The results
are shown in Table IV and Table V. Obviously, TrustGNN
achieves best result across all splits, on both Advogato and
PGP datasets. This further demonstrated the robustness and
stability of TrustGNN model.

Methods

Training Set
(%)

F1-Score

MAE

TrustGNN

Guardian

Matri

80%
60%
40%

80%
60%
40%

80%
60%
40%

74.4%±0.1% 0.081±0.001
72.6%±0.1% 0.088±0.001
70.1%±0.1% 0.096±0.001

73.0%±0.1%
71.7%±0.2%
69.7%±0.0%
65.0%±0.4%
63.9%±0.3%
61.7%±0.3%

0.087±0.001
0.091±0.001
0.098±0.000
0.141±0.001
0.145±0.001
0.153±0.001

TABLE V
PERFORMANCE EVALUATION WITH DIFFERENT TRAINING SIZES ON PGP.
THE BEST RESULTS ARE IN BOLD.

Methods

Training Set
(%)

F1-Score

MAE

TrustGNN

Guardian

Matri

80%
60%
40%

80%
60%
40%

80%
60%
40%

87.2%±0.1% 0.083±0.001
86.3%±0.1% 0.090±0.001
85.4%±0.1% 0.097±0.001

86.7%±0.1%
85.9%±0.1%
84.6%±0.1%
67.3%±0.7%
64.7%±0.1%
60.5%±0.1%

0.086±0.001
0.091±0.001
0.100±0.001
0.136±0.0003
0.141±0.0004
0.164±0.0001

C. Visualization and Interpretation

We visualize the weight of each type of trust chains in
TrustGNN, i.e., α in Formula 9. TrustGNN uses attention
mechanism to compute contribution of each type of chains.
In the experiments, we limit
the length of chains to 2.
Both Advogato and PGP datasets have 4 different types of
relationships. Therefore, the number of chain types is 42 = 16.
Here we use Advogato dataset as an example and visualize
the top 5 chain types in Fig. 4. We use scalars to represent
different types of relationships {Observer: 1, Apprentice:2,
Journeyer: 3, Master: 4} so that large values indicate strong
trust relationships. From Fig. 4 we can see that the top 5
types of chains contain relationships with large values. This
is reasonable because strong trust relationships are often more
helpful to creating new trust relationships. Moreover, Trust-
GNN accurately assigns the highest weight for the chain type
with two strongest relationships (4 → 4). This demonstrates
that TrustGNN is consistent with the laws of reality and has
good interpretation. Note that there are also some relationships
with small values in the top 5 types of chains. This may
be because trustworthiness is imbalanced in trust graphs. The
number of relationships with values of 1 and 2 is much larger
than relationships with values of 3 and 4. The model may be
biased due to imbalanced data, but in general, TrustGNN can
learn high weight for chains with strong trust relationships.

8

0.1379

0.14

0.12

0.1146

t
h
g
e
W

i

0.10

0.08

0.06

0.1041

0.1018

0.0904

0.04

0.02

0.00

4→4

3→3

1→4
Type of chain

3→1

3→4

Fig. 4. Visualization of top 5 types of chains. We limit the length of chains
to 2. For example, “1→4” means the chain type that a trustor trusts an
intermediate node with a trust value of 1 and the intermediate node trusts
a trustee with a trust value of 4.

D. Analysis of Attribute Initialization Methods

As some datasets may not have raw attributes, we need
to deﬁne the attributes of nodes and edges in advance. In
Guardian [23], they use node2vec [28] embeddings and one-
hot vectors as node/edge attributes. We follow the Guardian’s
setting to study what types of attributes are more suitable for
our TrustGNN. In this experiment, node attributes are deﬁned
as embeddings pre-trained from node2vec or initialized as a set
of learnable parameters of the neural networks. Edge attributes
are deﬁned as one-hot vectors or initialized as a set of learnable
the cases
parameters of the neural networks. We test all
and report the F1-Score and MAE score in Table VI. From
Table VI we can ﬁnd that TrustGNN achieves the best results
when node and edge attributes are both initialized as learnable
parameters. This may be because the learning ability of neural
networks can learn good attributes for nodes and edges. We
also noticed that using node2vec embeddings will reduce the
performance while using one-hot vectors has little impact on
the performance. The one-hot vectors assign discriminative
attributes for different
it can still
distinguish the role of different types of trustworthiness. On
the other hand, because node2vec is proposed for graph with
homogeneous edges, it may be not so suitable for trust graphs
with multi-relations.

types of edges so that

TABLE VI
THE RESULTS OF TRUSTGNN WITH DIFFERENT TYPES OF ATTRIBUTES.

Node
Attributes

Edge
Attributes

Advogato

PGP

F1-Score MAE

F1-Score MAE

Parameter

Parameter

Parameter

One-hot

Node2vec

Parameter

Node2vec

One-hot

74.4%

74.2%

72.4%

72.4%

0.081

0.083

0.088

0.088

87.2%

87.1%

83.3%

82.0%

0.083

0.084

0.114

0.124

E. Ablation Study

Similar to most deep learning methods, TrustGNN consists
of several different components that may have important
impact on the model performance. To provide intuitive under-
standing to the model’s components, we perform experiments
comparing TrustGNN with its three variants. The variants are
deﬁned as follows: 1) In the trust chain based propagation
process (Section III-C), a node will receive two kinds of
information corresponding to its two roles. Here we ignore
the trustor role of nodes and make a node only receive the
information from its trustee role, named as TrustGNN-1; 2)
We also ignore the trustee role of nodes and make a node
only receive the information from its trustor role, named as
TrustGNN-2; 3) In trust chain based aggregation, we employ
a sum operation instead of discriminative aggregation, named
as TrustGNN-3. We report the average F1-Score at different
training ratios for comparison.

As shown in Fig. 5, we can draw three conclusions: (1)
TrustGNN consistently outperforms all its variants on both
datasets, illustrating the effectiveness of simultaneously con-
sidering two different roles of target nodes and discrimi-
native aggregation of different trust chains. (2) TrustGNN-
1 and TrustGNN-2 have different performance advantages
in different datasets, which further illustrates the necessity
of comprehensively considering two different roles of target
nodes. (3) TrustGNN-3 is consistently lower than the other
three baselines, which illustrates the rationality of aggregation
considering the importance of different trust chains, and can
more fully capture the composable nature of trust.

0.755

0.745

TrustGNN-1
TrustGNN-2

TrustGNN-3
TrustGNN

0.735

0.725

0.715

e
r
o
c
S
-
1
F

0.880

0.875

0.870

TrustGNN-1
TrustGNN-2

TrustGNN-3
TrustGNN

e
r
o
c
S
-
1
F

0.865

0.860

0.705

0.695

0.685

0.855

0.850

40%

60%

80%

The training ratio

40%

60%

80%

The training ratio

(a) Advogato

(b) PGP

Fig. 5. Comparisons of F1-Score of our TrustGNN and three variants at
different training ratios on two datasets.

F. Parameter Analysis

We further analyzed how model parameters affected Trust-
GNN performance. The most important hyperparameters of
TrustGNN are the maximum length of trust chain K and the
attribute dimension of edge/node. Here we report the average
F1-Score on Advogato and PGP datasets.

Maximum length of trust chain. In order to analyze the
inﬂuence of the maximum length of trust chain K on the
model performance, we test the performance when K = 1, 2,
and 3 on two datasets respectively. As shown in Fig. 6, the
model performance ﬁrst increases and then decreases with
increase of K on both datasets. This observation is reasonable
because trust chains that are too short cannot adequately

0.745

0.88

0.745

0.743

Node Dimension
Edge Dimension

0.873

0.872

Node Dimension
Edge Dimension

9

e
r
o
c
S
-
1
F

0.740

0.735

e
r
o
c
S
-
1
F

0.87

0.86

e
r
o
c
S
-
1
F

0.741

0.739

e
r
o
c
S
-
1
F

0.871

0.870

0.869

0.730

1

2
Maximum length k of the trust chain

3

0.85

1

2
Maximum length k of the trust chain

3

0.737

0.735

64

128

512 1024 2048

256
Dimension

0.868

0.867

64

128

512 1024 2048

256
Dimension

(a) Advogato

(b) PGP

(a) Advogato

(b) PGP

Fig. 6. Parameter analysis of maximum length of trust chain K on two
datasets.

Fig. 7. Parameter analysis of attribute dimensions of nodes and edges. The
default dimension is 1024 for both nodes and edges. We ﬁx the default setting
for nodes/edges and analyze another.

capture the propagative nature of trust, while trust chains that
are too long may introduce more noise as trust will decrease
in the propagation process.

Attribute dimension. We also analyze the impact of at-
tribute dimension when TrustGNN initializes node and edge
attributes as learnable parameters. We ﬁx the dimension of
node/edge to 1024 and test the performance with edge/node
dimension varying in {64, 128, 256, 512, 1024, 2048}. The
analysis result of node attribute dimension and that of edge
attribute dimension are both shown in Fig. 7. They show the
same trend. The curves ﬁrst rise and then fall and TrustGNN
achieves best performance when dimensions of nodes and
edges are both around 1024. This may because when the
dimension is too small, e.g., 64, the expressive ability of
the model will be weak due to the overly small number of
parameters. When the dimension is too large, it is difﬁcult for
the model to converge to a good state due to the overly large
number of parameters.

V. RELATED WORK

A. Trust Evaluation

Due to the signiﬁcance of trust in online social networks,
trust evaluation has been widely studied and reviewed [29],
[30]. Trust relationships can be formalized as subjective trust
measures. The subjective logic-based methods introduce the
uncertainty inference process for the subjective nature of trust.
For example, TNA-SL [7] simpliﬁes the complex trust graph
to a series-parallel graph by deleting the most uncertain path
to obtain a canonical graph. Trust measures are expressed
as beliefs, and subjective logic is used to calculate the trust
between any parties in the network. 3VSL [8] assumes social
trust among users is determined by the objective evidences,
and believes that cognitive features of social trust among users
are not what they care about. It distinguishes the posteriori and
priori uncertainties existing in trust, and the difference between
distorting and original opinions, thus be able to compute multi-
hop trust in arbitrary graphs. OpinionWalk [9] uses an opinion
matrix to model the topology of the trust graph. Each entry
in the matrix is a direct opinion of two corresponding users.
They then devised multiple matrix-like operations by using
discounting and combining operations instead of traditional
multiplication and summation. In this matrix-like operations,
the discounting and combining operations are adopted to
model trust propagation and fusion.

Another type of methods which is based on probability
statistics often uses mathematical distribution to model trust
evaluation. For example, Liu et al. [10] propose a context-
aware trust model to predict dynamic trust by modeling the
interactions of agents using Hidden Markov Model. They ﬁrst
apply information theory and multiple discriminant analysis
to select the most useful features and combine the same to
generate a compact and effective feature vector, which is
viewed as the observations associated with each interaction.
Then they propose a HMM based trust model considering
such contextual information to capture dynamic behavior of
the target agent. Li et al. [11] quantify interpersonal trust
by analyzing the frequency of social interactions between
users and their friends on Facebook. They adopt bidirectional
interaction relationships in online social networks to decon-
struct users’ social behaviors and apply principal component
analysis to estimate interpersonal trust. Liu et al. [12] propose
a framework to accurately model single values as parameters.
The model ﬁrst uses a probabilistic graph model to model
trustors’ opinions and biases to his rating on the trustee.

Very recently, many trust evaluation methods based on
machine learning technology are also constantly being pro-
posed. For example, Matri [3] is a multi-aspect trust inference
model using matrix factorization. It views the trust evaluation
problem as a recommendation task, then borrows the rich
methodologies from collaborative ﬁltering. NeuralWalk [13]
ﬁrst designs a neural subunit named WalkNet to model the
propagation and fusion of direct trust in trust social networks.
Then, the unknown multi-hop trust relationship between users
is calculated by iterating this subunit continuously. Espe-
cially, with the success of deep learning, GNN-based model
Guardian [23] has been proposed. Guardian divides the neigh-
bor nodes directly connected to the target node into in-degree
neighbor nodes and out-degree neighbor nodes, and uses the
convolutional layer for information aggregation respectively.
Then it obtains high-order neighbor information by stacking
multiple convolutional layers. Medley [31] leverages social
interactions that change dynamically over time to perform trust
evaluations on dynamic online social networks. The method
proposes a functional temporal encoding module to model
temporal features and employs an attention mechanism to as-
sign higher importance to recent temporal social relationships.

10

B. Graph Nerual Networks

Graph neural networks (GNNs) [14], [15] have been proved
to be an effective tool for analyzing graph-structural data. Most
GNNs learn node representations by aggregating message from
neighboring nodes based on the guidance of graph topology.
GNNs are ﬁrst applied to homogeneous graphs. For example,
GCN [24] simpliﬁes spectral graph convolutions [32] by using
a localized ﬁrst-order approximation. GAT [25] considers that
different neighbors of the target node may have different
importance, and integrates the importance coefﬁcients into the
aggregation function. GraphSAGE [33] aggregates the neigh-
bor information of the target node in a learnable manner, and
learns node representations in an inductive manner by using
node-level sampling methods. R-GCN [34] designs multiple
convolution operations in units of edge types to model the
impact of different types of edges on the target node. GIN [35]
aims to study the expressive power of GNNs by studying the
ability to distinguish any two graphs, and proposes a new
framework, which is shown to have the same expressive power
as Weisfeiler-Lehman. Beyond homogeneous graphs, there are
also some GNNs for heterogeneous graphs. Heterogeneous
graphs contain more than one type of nodes or edges, which
can better model real-world systems. In heterogeneous GNNs,
the most important design is using discriminate operations
to distinguish the role of different types of nodes/edges in
GNN framework. For example, HAN [36] and MAGNN [37]
use attention mechanism to learn the weights for information
with different semantic. HetSANN [38] and HGT [39] pro-
poses a type-aware attention layer to model the relationships
between different types of nodes without directly adopting
traditional convolutional layers. In addition, GNNs have also
been continuously extended to computer vision [40], [41],
natural language processing [42]–[44] and other ﬁelds [14],
and have achieved great success.

Despite the great success of previous work, there are seldom
GNN-based work for trust evaluation tasks. A trust graph can
be seen as a heterogeneous graph but it has more ﬁeld-related
properties. In this paper we show our insights about trust
graph and design a new GNN-based trust evaluation method
by integrating trust properties into GNN framework.

C. Knowledge Graph Embedding

Knowledge graph embedding (KGE) focus on learning low-
dimensional embeddings for entities and their relations in
knowledge graph (KG) [45], [46]. The learned embeddings
can be used for KG tasks such as KG alignment [47], [48]
and relation predictions [46], [49]. KGE methods can be
viewed as modeling (head entity, relation, tail entity) triples.
Concretely, a scoring function is deﬁned to measure the
plausibility of triplets given embeddings and help update the
representation of the training data. The scoring functions have
many designing criteria, such as translation relation [50],
rotational relation [27], inner product [51] and others [52],
[53]. For example, RotatE [27] is a recent proposed method.
It maps the entities and relations in a KG to complex vector
space, and deﬁnes the relations between entities as rotations
from source entities to target entities. The interaction between

entities and relations in score functions maintains the semantic
relationships between entities and relations, and also can be
applied to model trust relationships. In this paper we extend
design principles in KGE to model the propagative nature
of trust, not only for triplets but also for more complex
interaction, e.g., multiple user and relationships in a trust
chain.

VI. CONCLUSION

In this paper, we proposed TrustGNN, a new graph neural
network (GNN) based method for trust evaluation in on-
line social networks. In TrustGNN, we for the ﬁrst
time,
explicitly integrated the propagative and composable nature
into GNN framework to learn comprehensive embeddings for
better trust evaluation. We deﬁned trust chains to model the
propagative pattern of trust and extended knowledge graph
embedding methods to model the interaction among nodes and
relationships in each trust chain. We further used attention
mechanism to learn the importance coefﬁcients of different
types of chains, in order to distinguish the contributions of
different propagative process. Experimental results on widely-
used real-world datasets have demonstrated the superiority of
the new proposed TrustGNN. The ablation studies also showed
the effectiveness of key designs in TrustGNN. Our proposed
TrustGNN has achieved good performance, but deep learning
techniques still have great potential for trust evaluation tasks.
In the future, we would like to incorporate the dynamic
behavior of social networks into our model. We would also
like to explore self-supervised techniques and apply them
effectively to trust evaluation in social networks.

REFERENCES

[1] P. Gao, H. Miao, J. S. Baras, and J. Golbeck, “STAR: semiring trust
inference for trust-aware social recommenders,” in Proceedings of the
Tenth ACM Conference on Recommender Systems (RecSys 2016), 2016,
pp. 301–308.

[2] R. M. Bond, C. J. Fariss, J. J. Jones, A. D. I. Kramer, C. Marlow,
J. E. Settle, and J. H. Fowler, “A 61-million-person experiment in social
inﬂuence and political mobilization,” Nature, vol. 489, no. 7415, pp.
295–298, 2012.

[3] Y. Yao, H. Tong, X. Yan, F. Xu, and J. Lu, “MATRI: a multi-aspect
and transitive trust inference model,” in the Twenty-second International
World Wide Web Conference (WWW 2013), 2013, pp. 1467–1476.
[4] S. M. Ghafari, A. Beheshti, A. Joshi, C. Paris, A. Mahmood, S. Yakhchi,
and M. A. Orgun, “A survey on trust prediction in online social
networks,” IEEE Access, vol. 8, pp. 144 292–144 309, 2020.

[5] R. S. Almogbel and A. A. Alkhalifah, “User behavior in social networks
toward privacy and trust: Literature review,” Int. J. Interact. Mob.
Technol., vol. 16, no. 1, 2022.

[6] M. Alkhamees, S. Alsaleem, M. Al-Qurishi, M. A. AlRubaian, and
A. Hussain, “User trustworthiness in online social networks: A sys-
tematic review,” Appl. Soft Comput., vol. 103, p. 107159, 2021.

[7] A. Jøsang, R. Hayward, and S. Pope, “Trust network analysis with
subjective logic,” in the Twenty-Nineth Australasian Computer Science
Conference (ACSC 2006), vol. 48, 2006, pp. 85–94.

[8] G. Liu, Q. Yang, H. Wang, X. Lin, and M. P. Wittie, “Assessment
of multi-hop interpersonal
in social networks by three-valued
subjective logic,” in IEEE Conference on Computer Communications
(INFOCOM 2014), 2014, pp. 1698–1706.

trust

[9] G. Liu, Q. Chen, Q. Yang, B. Zhu, H. Wang, and W. Wang, “Opin-
ionwalk: An efﬁcient solution to massive trust assessment in online
social networks,” in IEEE Conference on Computer Communications
(INFOCOM 2017), 2017, pp. 1–9.

[10] X. Liu and A. Datta, “Modeling context aware dynamic trust using
hidden markov model,” in Proceedings of the Twenty-Sixth AAAI Con-
ference on Artiﬁcial Intelligence (AAAI 2012), 2012.

[11] X. Li, Q. Yang, X. Lin, S. Wu, and M. P. Wittie, “Itrust: interpersonal
trust measurements from social interactions,” IEEE Netw., vol. 30, no. 4,
pp. 54–58, 2016.

[12] L. Liu and Q. Yang, “A probabilistic graph model for trust opinion
estimation in online social networks,” arXiv preprint arXiv:1909.10055,
2019.

[13] G. Liu, C. Li, and Q. Yang, “Neuralwalk: Trust assessment in online
social networks with neural networks,” in IEEE Conference on Computer
Communications (INFOCOM 2019), 2019, pp. 1999–2007.

[14] Z. Wu, S. Pan, F. Chen, G. Long, C. Zhang, and P. S. Yu, “A
comprehensive survey on graph neural networks,” IEEE Trans. Neural
Netw. Learn. Syst., vol. 32, no. 1, pp. 4–24, 2021.

[15] F. Scarselli, M. Gori, A. C. Tsoi, M. Hagenbuchner, and G. Monfardini,
“the graph neural network model,” IEEE Trans. Neural Networks,
vol. 20, no. 1, pp. 61–80, 2009.

[16] L. Wu, P. Cui, J. Pei, and L. Zhao, Graph Neural Networks: Foundations,
Frontiers, and Applications. Singapore: Springer Singapore, 2022.
[17] Y. Rong, W. Huang, T. Xu, and J. Huang, “Dropedge: Towards deep
graph convolutional networks on node classiﬁcation,” in the Eighth
International Conference on Learning Representations (ICLR 2020),
2020.

[18] X. Wang, M. Zhu, D. Bo, P. Cui, C. Shi, and J. Pei, “AM-GCN: adaptive
multi-channel graph convolutional networks,” in the 26th ACM SIGKDD
Conference on Knowledge Discovery and Data Mining (SIGKDD 2020),
2020, pp. 1243–1253.

[19] J. You, R. Ying, and J. Leskovec, “Position-aware graph neural net-
works,” in Proceedings of the Thirty-sixth International Conference on
Machine Learning (ICML 2019), vol. 97, 2019, pp. 7134–7143.
[20] H. Chen, H. Yin, X. Sun, T. Chen, B. Gabrys, and K. Musial, “Multi-
level graph convolutional networks for cross-platform anchor link pre-
diction,” in the 26th ACM SIGKDD Conference on Knowledge Discovery
and Data Mining (SIGKDD 2020), 2020, pp. 1503–1511.

[21] F. Xu, J. Lian, Z. Han, Y. Li, Y. Xu, and X. Xie, “Relation-aware
graph convolutional networks for agent-initiated social e-commerce rec-
ommendation,” in Proceedings of the Twenty-eighth ACM International
Conference on Information and Knowledge Management (CIKM 2019),
2019, pp. 529–538.

[22] Z. Liu, M. Wan, S. Guo, K. Achan, and P. S. Yu, “Basconv: Ag-
gregating heterogeneous interactions for basket recommendation with
graph convolutional neural network,” in Proceedings of the 2020 SIAM
International Conference on Data Mining (SIAM 2020), 2020, pp. 64–
72.

[23] W. Lin, Z. Gao, and B. Li, “Guardian: Evaluating trust in online social
networks with graph convolutional networks,” in Thirty-ninth IEEE
Conference on Computer Communications (INFOCOM 2020), 2020, pp.
914–923.

[24] T. N. Kipf and M. Welling, “Semi-supervised classiﬁcation with graph
convolutional networks,” in the Fifth International Conference on Learn-
ing Representations (ICLR 2017), 2017.

[25] P. Velickovic, G. Cucurull, A. Casanova, A. Romero, P. Li`o, and Y. Ben-
gio, “Graph attention networks,” in the Sixth International Conference
on Learning Representations (ICLR 2018), 2018.

[26] C. Zhang, S. Dang, B. Shihada, and M.-S. Alouini, “Dual attention-
based federated learning for wireless trafﬁc prediction,” in Proceedings
of INFOCOM, 2021.

[27] Z. Sun, Z. Deng, J. Nie, and J. Tang, “Rotate: Knowledge graph
embedding by relational rotation in complex space,” in the Seventh
International Conference on Learning Representations (ICLR 2019),
2019.

[28] A. Grover and J. Leskovec, “node2vec: Scalable feature learning for
networks,” in Proceedings of the Twenty-second ACM SIGKDD Interna-
tional Conference on Knowledge Discovery and Data Mining (SIGKDD
2016), 2016, pp. 855–864.

[29] W. Sherchan, S. Nepal, and C. Paris, “A survey of trust

in social

networks,” ACM Comput. Surv., vol. 45, no. 4, pp. 47:1–47:33, 2013.

[30] W. Jiang, G. Wang, M. Z. A. Bhuiyan, and J. Wu, “Understanding
graph-based trust evaluation in online social networks: Methodologies
and challenges,” ACM Comput. Surv., vol. 49, no. 1, pp. 10:1–10:35,
2016.

[31] W. Lin and B. Li, “Medley: Predicting social trust in time-varying
online social networks,” in the Fortieth IEEE Conference on Computer
Communications (INFOCOM 2021), 2021.

[32] J. Bruna, W. Zaremba, A. Szlam, and Y. LeCun, “Spectral networks
and locally connected networks on graphs,” in the Second International
Conference on Learning Representations (ICLR 2014), 2014.

11

[33] W. L. Hamilton, Z. Ying, and J. Leskovec, “Inductive representation
learning on large graphs,” in Annual Conference on Neural Information
Processing Systems 2017 (NeurlPS 2017, 2017, pp. 1024–1034.
[34] M. Schlichtkrull, T. N. Kipf, P. Bloem, R. Van Den Berg, I. Titov,
and M. Welling, “Modeling relational data with graph convolutional
networks,” in the Semantic Web - 15th International Conference (ESWC
2018), 2018, pp. 593–607.

[35] K. Xu, W. Hu, J. Leskovec, and S. Jegelka, “How powerful are graph
neural networks?” in the Seventh International Conference on Learning
Representations (ICLR 2019), 2019, pp. 1–17.

[36] X. Wang, H. Ji, C. Shi, B. Wang, Y. Ye, P. Cui, and P. S. Yu, “Hetero-
geneous graph attention network,” in the World Wide Web Conference
(WWW), 2019, pp. 2022–2032.

[37] X. Fu, J. Zhang, Z. Meng, and I. King, “Magnn: Metapath aggregated
graph neural network for heterogeneous graph embedding,” in the World
Wide Web Conference (WWW), 2020, pp. 2331–2341.

[38] H. Hong, H. Guo, Y. Lin, X. Yang, Z. Li, and J. Ye, “An attention-
based graph neural network for heterogeneous structural learning,” in the
Thirty-Fourth AAAI Conference on Artiﬁcial Intelligence (AAAI 2020),
2020, pp. 4132–4139.

[39] Z. Hu, Y. Dong, K. Wang, and Y. Sun, “Heterogeneous graph trans-
former,” in the World Wide Web Conference (WWW), 2020, pp. 2704–
2710.

[40] X. Lin, Q. Zou, and X. Xu, “Action-guided attention mining and
relation reasoning network for human-object interaction detection,” in
the Twenty-Ninth International Joint Conference on
Proceedings of
Artiﬁcial Intelligence (IJCAI 2020), 2020, pp. 1104–1110.

[41] Z. Chen, X. Wei, P. Wang, and Y. Guo, “Multi-label image recognition
with graph convolutional networks,” in Conference on Computer Vision
and Pattern Recognition (CVPR 2019), 2019, pp. 5177–5186.

[42] L. Wu, Y. Chen, K. Shen, X. Guo, H. Gao, S. Li, J. Pei, and B. Long,
“Graph neural networks for natural language processing: A survey,”
arXiv preprint arXiv:2106.06090, 2021.

[43] Y. Chen, L. Wu, and M. J. Zaki, “Reinforcement

learning based
graph-to-sequence model for natural question generation,” in the Eighth
International Conference on Learning Representations (ICLR 2020),
2020.

[44] K. Xu, L. Wu, Z. Wang, Y. Feng, M. Witbrock, and V. Sheinin,
“Graph2seq: Graph to sequence learning with attention-based neural
networks,” arXiv preprint arXiv:1804.00823, 2018.

[45] T. Dettmers, P. Minervini, P. Stenetorp, and S. Riedel, “Convolutional
2d knowledge graph embeddings,” in Proceedings of the Thirty-Second
AAAI Conference on Artiﬁcial Intelligence (AAAI 2018), 2018, pp. 1811–
1818.

[46] T. Trouillon, J. Welbl, S. Riedel,

´E. Gaussier, and G. Bouchard,
“Complex embeddings for simple link prediction,” in Proceedings of
the Thirty-third International Conference on Machine Learning (ICLR
2016), 2016, pp. 2071–2080.

[47] Y. Yan, L. Liu, Y. Ban, B. Jing, and H. Tong, “Dynamic knowledge graph
alignment,” in Thirty-Fifth AAAI Conference on Artiﬁcial Intelligence
(AAAI 2021), 2021, pp. 4564–4572.

[48] K. Xu, L. Wang, M. Yu, Y. Feng, Y. Song, Z. Wang, and D. Yu, “Cross-
lingual knowledge graph alignment via graph matching neural network,”
in Proceedings of the Fifty-seventh Conference of the Association for
Computational Linguistics ACL, 2019, pp. 3156–3161.

[49] Y. Lin, Z. Liu, H. Luan, M. Sun, S. Rao, and S. Liu, “Modeling relation
paths for representation learning of knowledge bases,” in Proceedings
of the 2015 Conference on Empirical Methods in Natural Language
Processing (EMNLP 2015), 2015, pp. 705–714.

[50] A. Bordes, N. Usunier, A. Garc´ıa-Dur´an, J. Weston, and O. Yakhnenko,
“Translating embeddings for modeling multi-relational data,” in the
Twenty-seventh Annual Conference on Neural Information Processing
Systems (NeurlPS 2013), 2013, pp. 2787–2795.

[51] B. Yang, W. Yih, X. He, J. Gao, and L. Deng, “Embedding entities and
relations for learning and inference in knowledge bases,” in the Third
International Conference on Learning Representations (ICLR 2015),
2015.

[52] X. Dong, E. Gabrilovich, G. Heitz, W. Horn, N. Lao, K. Murphy,
T. Strohmann, S. Sun, and W. Zhang, “Knowledge vault: a web-scale
approach to probabilistic knowledge fusion,” in the Twentieth ACM
SIGKDD International Conference on Knowledge Discovery and Data
Mining (SIGKDD 2014), 2014, pp. 601–610.

[53] R. Socher, D. Chen, C. D. Manning, and A. Y. Ng, “Reasoning with
neural tensor networks for knowledge base completion,” in the Twenty-
seventh Annual Conference on Neural Information Processing Systems
(NeurlPS 2013), 2013, pp. 926–934.

