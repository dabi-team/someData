PHYSICAL INTEGRITY ATTACK DETECTION OF SURVEILLANCE 
CAMERA WITH DEEP LEARNING BASED VIDEO FRAME 
INTERPOLATION 

JONATHAN PAN 

Nanyang Technological University, Singapore 
E-MAIL: JonathanPan@ntu.edu.sg 

Abstract: 

Surveillance  cameras,  which  is  a  form  of  Cyber  Physical 
System,  are  deployed  extensively  to  provide  visual  surveillance 
monitoring of activities of interest or anomalies. However, these 
cameras  are  at  risks  of  physical  security  attacks  against  their 
physical  attributes  or  configuration  like  tampering  of  their 
recording coverage, camera positions or recording configurations 
like  focus  and  zoom  factors.  Such  adversarial  alteration  of   
physical  configuration  could  also  be  invoked  through  cyber 
security attacks against the camera’s software vulnerabilities to 
administratively  change  the  camera’s  physical  configuration 
settings. When such Cyber Physical attacks occur, they affect the 
integrity of the targeted cameras that would in turn render these 
cameras ineffective  in fulfilling the intended  security  functions. 
There  is  a  significant  measure  of  research  work  in  detection 
mechanisms  of  cyber-attacks  against  these  Cyber  Physical 
devices,  however  it is  understudied  area  with such mechanisms 
against integrity attacks on physical configuration. This research 
proposes the use of the novel use of deep learning algorithms to 
detect  such  physical  attacks  originating  from cyber or  physical 
spaces. Additionally, we proposed the novel use of deep learning-
based  video  frame  interpolation  for  such  detection  that  has 
comparatively better performance to other anomaly detectors in 
spatiotemporal environments.     

Keywords: 

Cyber  Physical  Security;  Surveillance  Camera  Physical 

Tampering; Anomaly Detection; Interpolation; Deep Learning 

1. 

Introduction 

Surveillance  cameras  are  an  integral  part  of  the  smart 
infrastructure to provide security video surveillance to monitor 
and record areas of interest. Surveillance cameras are typically 
deployed  in  public  areas  like  shopping  malls,  roadways, 
transportation  hubs  and  also  transportation  platforms  like 
trains. These surveillance cameras are operated by their human 
operators, processed by video analytics tools to detect activity 
or  object of  interest  and  videos  are  stored into  video  storage 
medium  for  later  retrieval  for  post  incident  analysis  like 

incident  investigation  or  digital  forensics.  For  such  video 
surveillance to support their intended usages, the integrity of 
physical configuration of these surveillance cameras needs to 
be  upkept  and  prevent  any  unauthorized  changes. 
Configurations like the camera’s position or placement, Pan-
Tilt-Zoom (PTZ) configuration and their ability to maintain the 
line-of-sight of the area of surveillance.     

There  are  however  threats  and  vulnerabilities  to  these 
surveillance camera’s physical configuration. Such malicious 
attack may occur in cyber or physical realms. Cyber induced 
form of attacks would first exploit the software vulnerability 
of the targeted camera and  consequentially  cause adversarial 
digitally-enabled  alteration  of  the  physical  configuration. 
Physical  tampering  of  cameras  could  be  the  simpler  or  less 
technically  complex  forms  of  attack  that  only  requires  the 
attacker to have physical reach to the camera to effect change 
to  the  configuration  [17].  The  effects  of  such  physical 
tampering  could  result  in  the  disruption  of  video  stream  or 
corrupt  surveillance  coverage.  Conventional 
forms  of 
detection  mechanism  of  physical  alteration  would  require 
human  operators  to  manually  study  or  observe  video  feeds. 
When  there  are  large  numbers  of  surveillance  cameras 
involved,  such  monitoring  efforts  are 
inefficient  and 
ineffective. Site inspections of camera deployments would be 
labour  intensive  and  have  long  lead-time  to  detect  such 
occurrences. 

This  research  proposes  two  novelties.  The  first  is  the 
application  of  Artificial  Intelligence  based  Deep  Learning 
algorithms  to  detect  anomalous  tampering  of  the  physical 
configuration  of  surveillance  cameras.  The  second  is  the 
proposition  of  a  novel  approach  to  video  anomaly  detection 
using  video  frame  interpolation  applied  to  spatiotemporal 
video  feeds.  Unlike  most  video  anomaly  detector, this  is  not 
based  on  visual  optics  flow.  With  this  technique,  it  would 
provide an out-of-band visual layer approach to detect physical 
tampering of surveillance camera as a human operator could 
on  video  stream  that  is  susceptible  to  varying  degree  of 
environmental changes within the surveillance area.   

ã 2019 IEEE. Personal use of this material is permitted. Permission from 
IEEE must be obtained for all other users for all other uses, in any current 
or  future  media,  including  reprinting/republishing  this  material  for 
advertising  or  promotional  purposes,  creating  new  collective  works,  for 
resale  or  redistribution  to  servers  or  lists,  or  reuse  of  any  copyrighted 
component of this work in other works. 

 
 
The  next  section  of  this  paper  provides  background 
information about the forms of Cyber Physical attacks against 
surveillance and video frame interpolation. This is followed by 
related research work in detecting such form of attack and the 
popular types of deep learning video anomaly detectors. The 
description of the model is covered, followed by description of 
experiments  and  analysis  done.  The  paper  concludes  with  a 
conclusion and discussion about future research directions.         

operator  manually  study  the  video  feeds  and  identify  any 
observable unintended changes to the video feeds. Hence this 
preliminary  research  work  attempts  to  automate  human’s 
abilities to analyze video feeds for any observable unintended 
changes induced by physical alterations while ignoring normal 
contextual environmental changes.   

2.2.  Video Frame Interpolation   

2.  Background Information 

2.1.  Cyber Physical Attacks Against Surveillance Cameras   

include 

tampering  of 

The  physical  dimension  of  surveillance  cameras  is  a 
prime  candidate  for  an  attack  vector.  Such  physical  attacks 
would 
the  cameras’  physical 
configuration like changing of the cameras’ position, adjusting 
the PTZ, blocking the cameras’ line of sight or fiddling with 
the cameras’ lens focal or zoom settings. These cameras could 
easily  be  physically  damaged  that  would  totally  disrupt  the 
video feeds. They could also be at risks of environmental based 
disruption 
supply, 
communication  links  or  physical  mountings  used  with  these 
cameras  [11].  While  there  are  physical  tamper  protection 
solutions  available,  there  are  limits  to  such  physics-based 
protection and less so for detection capabilities. However, such 
tampering  could  easily  be  detected  by  an  observant  human 
operator.   

the  dependent  power 

attack 

to 

to  cyber-attacks 

Surveillance  cameras,  like  all  Internet  of  Things  (IoT) 
devices,  are  also at  risk  to a  wide  range  of cyber  threats. As 
these IoT devices connect digitally to provide video feeds and 
receive  administrative  control  commands,  they  are  also 
vulnerable 
that  could  have  physical 
consequences. Unauthorized privileged remote access to these 
surveillance  cameras  could  alter  the  configuration  of  the 
vulnerable  cameras  preventing  them  from  performing  their 
intended surveillance functions or coverage [10]. Such forms 
of Cyber Physical attacks [15] originating primarily in cyber 
dimensions  with  physical  consequence  is  likened  to  the 
Stuxnet malware attack that altered the physical operations of 
the targeted uranium enrichment facility. 

With  the  varied  forms  of  cyber,  physical  or  combined 
forms of attacks that could affect the configuration integrity of 
these IoT cameras, there are limits to detect such occurrence to 
prevent  or  recover  from  such  attacks.  The  cyber  detection 
mechanisms like Intrusion Detection System (IDS) would be 
effective against cyber-attacks; however, they are less capable 
of  detecting  physical  attacks.  Conversely  physical  attacks 
could  cause  significant  cyber  consequential  impact  to  the 
intended digital operations of these IoT cameras. An approach 
to  detect cyber  physical  attack  variants  would  be  to  have  an 

Interpolation, within the mathematical field of numerical 
analysis,  involves  the  approximated  proposition  of  missing 
data points from a range of known data points. It has been used 
generate  high  resolution  images  from  low  resolution  images 
[12].  Video  frame  interpolation  involves  the  synthesis  of 
nonexistent frames in-between the frames. It is typically used 
in rendering, compression and increasing video quality as part 
image  processing.  A 
of  computer  vision  and  digital 
conventional approach for frame generation is to use motion 
estimation-based  methods  that  entails  the  computation  of 
missing frames through the estimation of optical flows [14] or 
moving  gradient  techniques  [13].  There  are  significant 
interests  in  applying  deep  convolutional  neural  networks  to 
video  frame  interpolation.  Mathieu  et  al.  [7]  used  Mean 
Squared  Error  (MSE)  as  its  loss  function  and  multi-scale 
architecture  to  sharpen  video  frames.  Liu  et  al  [21]  adopted 
optical  flow-based  networks  to  synthesis  new  video  frames. 
However,  there  is  none  applied  in  the  context  of  anomaly 
detection.  Hence  our  research  novelty  is  the  application  of 
Deep  Learning  based  Video  Frame  Interpolation  as  an 
anomaly detector. 

3.  Related Work 

3.1.  Physical Integrity Tampering Detection 

Giraldo  et  al.  [1]  surveyed  the  research  trends  in 
developing  detection  solutions  to  detect  varied  forms  of 
‘physics-based’ attacks against Cyber Physical Systems. They 
observed  many  forms  of  attacks  against  the  ‘Trust’  factor  or 
the  integrity  of  physical  components  of  Cyber  Physical 
Systems would likely have observable attack effects. However, 
the problem is that such attack induced deviation effects may 
not be monitored hence detection alarms would not be raised.   
Valente  and  Cardenas  [4]  proposed  the  use  visual 
challenges  like  QR  codes  to  verify  the  freshness  of  camera 
video footage. The intent is to detect forms of adversarial video 
attacks that included moving cameras to point to different area. 
However,  this  detection  solution  would  detect  anomalies  as 
long  as  the  visual  challenge  remain  visible  to  the  camera. 
Zhang et al. [3] also observed that the physical environmental 
conditions are typically unique to the IoT’s deployment hence 

 
 
they are diverse. Hence any detection solution would need to 
be  contextually  tuned  to  the  environment  to  minimize  false 
alarms  yet  optimally  sensitive  to  detect  environmental 
integrity attacks. They also concluded that the study of dealing 
with 
is 
understudied. This research work addresses the need to have a 
contextually 
this 
understudied area.   

threats  originating  from  physical  environment 

tuned  detector  and  contributed 

to 

3.2.  Deep Learning based Anomaly Detectors 

Deep Learning algorithms have been very popular lately 
in their application to anomaly or fault detection. This is due 
to their ability to learn features (including video feeds) from 
raw data with their deep architectures compromising of layers 
of  non-linear  data  processing  units  called  neural  networks. 
There are a variety of Deep Learning based methods used for 
such detection [9]. According to Ravi et al., they are broadly 
classed into the following three. 

•  Autoencoder 

for 

reconstruction 

uses 
representational  learning  approach  that  models  normal 
behavior  of  surveillance  videos  through  linear  and  non-
linear transformations of image flows from video footages.   

that 

•  Predictive  modeling 

like  Convolutional  Recurrent 
Neural  Network  models  attempts to  predict future  video 
frames from current temporal spatial video frames based 
on conditional distribution  𝑃(𝑥$	|(𝑥$’(	, 𝑥$’*	, … 𝑥$’,	)). 
•  Generative models like Variational Autoencoders (VAE) 
attempts  to  model  the  likelihood  of  normal  video  feeds 
through the inclusion of stochastic variations. 

Anomaly  detection  with  these  unsupervised  algorithms 
are done through the measure of variation of the reconstructed 
and actual video frame pairs against defined threshold. 

4.  Models 

4.1.  Base Deep Learning Algorithm 

In our research, we applied the Convolutional Long-Short 
Term Memory (ConvLSTM) [16] as the base architecture for 
our  anomaly  detector  for  physical  attacks  against  the  Cyber 
Physical  surveillance  camera.  The  ConvLSTM  extends  the 
fully connected Long-Short Term Memory (LSTM) to include 
convolutional structures in both the input-to-state and state-to-
state transitions. With convolutional kernels, the ConvLSTM 
ingests  the  video  frame  images  with  higher  dimensions  of 
spatial temporal associations as inputs. The following are the 
mathematical expressions for the ConvLSTM. 

𝐼$ = 	 𝜎(𝑊23 ∗ 𝑋$ + 𝑊73 ∗ 𝐻$’( + 𝑊93 ∘ 𝐶$’( + 𝑏3) 

𝐹$ = 	 𝜎(𝑊2> ∗ 𝑋$ + 𝑊7> ∗ 𝐻$’( + 𝑊9> ∘ 𝐶$’( + 𝑏>) 

𝐶$ = 	 𝑓$ ∘ 𝐶$’( + 𝑖3 ∘ tanh(𝑊29 + 𝑋$ + 𝑊79 ∗ 𝐻$’( + 𝑏9) 

𝑂$ = 	 𝜎(𝑊2F ∗ 𝑋$ + 𝑊7F ∗ 𝐻$’( + 𝑊9F ∘ 𝐶$’( + 𝑏F) 

𝐻$ = 	 𝑜$ ∘ tanh(𝑉$) 

(1) 

(2) 

(3) 

(4) 

(5) 

In  comparison  to  LSTM,  the  ConvLSTM  has  ‘∗’ 
operators that performs convolution operation while ‘◦’ is the 
Hadamard  product  for  the  element-wise  product  of  matrices. 
The  rest  of  network  structure  performs,  like  the  LSTM 
network,  processes  the  input,  forget,  cell,  output  and  hidden 
state computations for each timestep denoted by  𝐼,𝐹,𝐶,𝑂  and 
𝐻  respectively with activation by  𝜎  and convolutional filter 
computation  with  the  sets  of  weights,  𝑊 .  Each  state  is 
represented  as  a  matrix  representing  a  video  frame. 
ConvLSTM has been used extensively as the base architecture 
for video anomaly detection. 

4.2.  Anomaly Detector Algorithms 

With the base ConvLSTM, we applied the popular three 
forms  of  anomaly  detectors  [9]  namely  Autoencoder  [18], 
Predictive [19] and VAE [20] used as comparative models to 
our model. 

FIGURE 1. ConvLSTM Predictor     

Our  model  is  similarly  structured  to  the  Predictive 
ConvLSTM [9] shown in Figure 1. The Predictive model takes 
in  a  sequence  of  video  frames  ( 𝑥$’J, 𝑥$’J’(	, … , 𝑥$’(	,	𝑥$	 ), 
where  𝐽   is  the  length  of  the  LSTM’s  timestep,  performs 
unsupervised feature extraction through an encoder which then 
feeds to a decoder that is trained to deconvolute and predict the 
next video frame (𝑥$L(	) through reconstructive approximation 
as illustrated mathematically below. 

𝑥M$L( = 	 𝑝(𝑥$L(|𝑥$’J, 𝑥$’J’(, … 𝑥$’(, 𝑥$) 
≈ 	 𝑝(𝑥$L(|𝑓PQ9FR3QS(𝑥$’J, 𝑥$’J’(, … 𝑥$’(, 𝑥$)) 
≈ 𝑔3Q$PU,FVW$P(𝑓PQ9FR3QSX𝑥$’J, 𝑥$’J’(, … 𝑥$’(, 𝑥$Y) 

(6) 

 
 
 
 
     
 
 
 
 
 
 
 
 
Our  model,  based  on  deep  learning  convolutional 
interpolation [8], involves approximating the interpolation of 
[(𝑥, 𝑦)  from the pair of adjacent 
the missing video frame  𝜃$’(
video frames available  𝜃$’*(𝑥, 𝑦)  and  𝜃$(𝑥, 𝑦). 

𝜃   is  the  actual  value  and  𝑝   is  the  total  number  of  pixels 
contained in that frame.   

𝑒 =

1
𝑝

,
‘ (𝜃]
3c(

a3 − 𝜃a3)*

(8) 

A high MSE that exceeds a defined threshold between the 
two frames (computed interpolated reconstruct and the actual) 
indicates  the  notable  change  noted  by  the  model  hence 
indicating an anomalous occurrence. 

5.  Methodology and Analysis 

5.1.  Dataset 

For  our  video  training  data,  we  used  two  sets  of  video 
surveillance  camera  footages.  Both  sets  are  stationary  train 
surveillance  cameras  with  people  moving  through  the  train 
carriages  with  segments  of  video  footage  with  passengers 
performing some atypical activities like hugging and fighting 
in  a  moving  train  with  constantly  changing  environmental 
background observed through the window screens of the train 
carriages. Both surveillance camera datasets were captured as 
part  of  Eureka  Celtic  Initiative  supported  by  four  European 
countries  [5]  focused  on  improving  train  passenger  security 
video  analytics.  Two  cameras  datasets  are  cameras  from 
different locations as shown below.   

FIGURE 2. Video Frame Interpolation   

The  encoding  ConvLSTM  network  ingests  the  input 
sequence  of  video  frames  (𝑥$’J, 𝑥$’JL(, … , 𝑥$’*, 𝑥$ )  into  its 
hidden layers of ConvLSTM with one video frame excluded 
(𝑥$’(	). The Interpolation ConvLSTM network will unfold the 
hidden  state  to  reconstruct  the  missing  video  frame  through 
interpolation. 

FIGURE 3. ConvLSTM Interpolator 

𝑥M$’( = 	 𝑝(𝑥$’(|𝑥$’J, 𝑥$’J’(, … 𝑥$’*, 𝑥$) 
≈ 	 𝑝(𝑥$’(|𝑓PQ9FR3QS(𝑥$’J, 𝑥$’J’(, … 𝑥$’*, 𝑥$)) 
≈ 𝑔3Q$PU,FVW$P(𝑓PQ9FR3QSX𝑥$’J, 𝑥$’J’(, … 𝑥$’*, 𝑥$Y) 

(7) 

We  adopted  the  same  Mean  Square  Error  (MSE)  loss 
function used by Mathieu et al. [7], in applying deep learning 
on video interpolation to solve blurriness in frame prediction, 
to  train  the  interpolation  model  to  reconstruct  the  missing 
frame. During inference, the model computes the interpolated 
missing  video  frame  against  the actual  video  frame that  it is 
given using MSE where  𝜃]	is the inferred interpolated output, 

FIGURE 4. Surveillance Cameras on Moving Train   

We  trained  all  models  to  tune  them  to  learn  the 
spatiotemporal features of both environments. We also created 
a sets of test videos from both cameras that simulated physical 
attacks. The training dataset accounted about 90% of the video 
footage  and  10%  for  testing  dataset.  The  simulated  attacks 
took the following forms of attacks with ten randomly selected 
time  instances  for  each  attack  hence  having  imbalance  class 
distribution of normal video footages and video segments with 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
attack effects. 

to closely monitor.   

•  Blocking camera’s  view  that  simulated  by  masking  out 
the video footage with a black image. This attack mimics 
a  physical  attack  of  covering  the  camera  or  perhaps 
physically  making  the  camera’s  capture  lens  opaque 
through application of water based paint.   

FIGURE 5. Rightmost video frame simulates blocked view   

•  Adjusting  the  zoom  configuration  of  the  camera  that 
was  simulated  by  cropping  specific  video  frames.  This 
simulation simulates the attack of physically adjusting the 
zoom factor of the camera configuration hence causing the 
camera to limit its viewing angle and obscuring parts of 
the intended surveillance coverage. 

FIGURE 6. Rightmost video frame simulates zoom-in   

•  Altering the focus of the camera that was simulated by 
applying image filters (blurring) to specific video frames. 
The  simulation  seeks  to  mimic  the  physical  manual 
adjustments of focal lens of the camera hence affecting the 
clarity of the captured video feed. 

FIGURE 7. Rightmost video frame simulates blurring effect   

•  Adjusting  the  camera’s  viewing  angle 

that  was 
simulated  by  shifting  the  viewing  area  of  the  recorded 
video footage. This attack simulates a physical left tilt of 
the camera position. The effects of the change of viewing 
area could obscure area of the view that may be important 

FIGURE 8. Rightmost video frame simulates small left-shift   

5.2.  Results and Analysis 

All models were trained and tested with the four sets of 
test scenarios. An evaluation criterion based on True Positive, 
True Negative, False Positive, False Negatives were collected. 
Additionally,  the  F1,  Precision  and  Recall  values  were 
computed.  Hence  a  total  of  32  test  evaluation  results  were 
collected  with  the  four  test  scenarios  with  two  sets  of 
previously unseen camera videos across four models including 
our interpolation anomaly detector model. The following are 
the results summarized and organized by the four test scenarios. 

TABLE 1. Blocking Camera’s View 

Evaluation 

TP/TN/FP/FN 

F1 

Precision 

Recall 

Model 

Predictor 

20/7828/5/0 

Interpolator 

20/7832/1/0 

VAE 

AE 

20/7822/11/0 

0/7833/0/20 

0.89 

0.98 

0.78 

N/A 

0.80 

0.95 

0.65 

N/A 

1.00 

1.00 

1.00 

0.00 

TABLE 2. Adjust Camera’s Zoom 

Evaluation 

TP/TN/FP/FN 

F1 

Precision 

Recall 

Model 

Predictor 

20/7828/5/0 

Interpolator 

20/7832/1/0 

VAE 

AE 

20/7821/12/0 

4/7833/0/16 

0.89 

0.98 

0.77 

0.33 

0.80 

0.95 

0.63 

1.00 

1.00 

1.00 

1.00 

0.20 

TABLE 3. Alter Camera’s Focus 

Evaluation 

TP/TN/FP/FN 

F1 

Precision 

Recall 

Model 

Predictor 

18/7828/5/2 

Interpolator 

10/7826/7/10 

VAE 

3/7821/12/17 

0.84 

0.54 

0.17 

0.78 

0.59 

0.20 

0.90 

0.50 

0.15 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
Model 

Evaluation 

TP/TN/FP/FN 

F1 

Precision 

Recall 

AE 

0/7833/0/20 

N/A 

N/A 

0.00 

TABLE 4. Shift Camera – Camera 1 

Evaluation 

TP/TN/FP/FN 

F1 

Precision 

Recall 

Model 

Predictor 

19/7826/7/1 

Interpolator 

19/7831/2/1 

VAE 

AE 

10/7822/11/10 

0/7831/2/20 

0.83 

0.93 

0.49 

N/A 

0.73 

0.90 

0.48 

0.00 

0.95 

0.95 

0.50 

0.00 

The  test  results  indicate  that  the  anomaly  detector  with 
video frame interpolation performed the best compared to the 
other models for physical attacks for three out of the four test 
scenarios.  It  was  second  best  for  the  simulated  tests  of 
adjusting the camera’s focus. 

As  part  of  testing,  we  rendered  the  interpolated  video 
frame of our our ConvLSTM Interpolator model to study the 
reconstructed  video  frame.  We  compared  the  interpolated 
video  frames  when  there  were  nobody  present  in  the  train 
carriage and where there was.   

FIGURE 9. Reconstructed video frame by our ConvLSTM Interpolator 
when the train carriage is empty (left) and has passengers (right) 

Notably the left images of the reconstructed video frames 
has  a  definitive  image  representation  of  the  environmental 

settings of the train carriage. Where there are image segments 
in  the  video  frame  that  may  contain  transient  objects  like 
moving  or  seated  passengers  present  in  the  surveillance 
footage, the model would generate a silhouette form of those 
objects. It is apparent that our model ConvLSTM Interpolator 
has tuned itself to  environmental  settings  of  the  surveillance 
coverage. 

6.  Conclusion and Future Directions 

Surveillance  cameras  are  at  risks  of  physical  integrity 
attacks  and  it  is  an  understudied  area.  There  is  serious 
functional  surveillance  impact  from  attacks  on  the  physical 
configurations  of  these  surveillance  cameras  that  could 
originate  from  cyber  or  physical  spaces.  When  such  attack 
occurs  and  remains  undetected,  the  video  recordings  of  the 
attacked  cameras  could  be  rendered  useless  when  they  are 
analyzed for investigative purposes or digital video forensics.   
This research work demonstrates the application of deep 
learning  algorithms  to  perform  visual  layer  inspection  or 
monitoring of surveillance video feeds to spot any observable 
forms of surveillance coverage integrity attacks. Additionally, 
this work further extends the typical classes of deep learning 
based anomaly detection algorithms to  include  a  novel form 
using video frame interpolation.   

Future research work will involve applying the detection 
approach  to  actual  surveillance  camera  feeds  to  detect  real   
attacks. Also, to apply it on archived video recordings to detect 
any past physical tampering or attack occurrences. Finally, to 
the  application  of  interpolation  based  anomaly 
extend 
detection to other domains beyond visual anomalies.     

References 

[1]  B. Ravi, D. M. Thomas, R. Parakkal, “An Overview of 
Deep  Learning  Based  Methods  for  Unsupervised  and 
Semi-Supervised Anomaly Detection in Videos”, Journal 
of Imaging, vol. 4, pp. 36, 2018. 

[2]  J. Giraldo, D. Urbina, A. Cardenas, J. Valente, M. Faisal, 
J. Ruths, N. O. Tippen-hauer, H. Sandberg, R. Candell, 
“A Survey of Physics-Based Attack Detection in Cyber- 
Physical  Systems.  ACM  Computing  Surveys,  Vol.  51, 
Issue. 4, Article 76, 36 pages, July 2018. 

[3]  N.  Zhang,  S.  Demetriou,  X.  Mi,  W.  Diao,  K.  Yuan,  P. 
Zong,  F.  Qian,  X.  F.  Wang,  K.  Chen,  Y.  Tian,  C.  A. 
Gunter, K. Zhang, P. Tague, Y. H. Lin, “Understanding 
IoT Security Through the Data Crystal Ball: Where We 
Are Now and Where We Are Going to Be”, CoRR, vol. 
abs/1703.09809, 2017.   

 
 
 
 
 
 
 
 
[4]  J. Valente, A. A. Cardenas, “Using visual challenges to 
verify the integrity of security cameras”, Proceedings of 
the  31st  Annual  Computer  Security  Applications 
Conference (ACSAC), 2015.   

[5]  S. A. Velastin, D. A. Gomez-Lira, “People Detection and 
Pose  Classification  Inside  a  Moving  Train  Using 
Computer  Vision”,  International  Visual  Informatics 
Conference, Springer, Pp. 319-330, 2017.   

[6]  X. Shi, Z. Chen, H. Wang, D. Yeung, W. Wong, W. Woo, 
“Convolutional  LSTM  network:  A  machine  learning 
approach for precipitation nowcasting.”, NIPS, Pp. 802-
810, 2015.     

[7]  M.  Mathieu,  C.  Couprie,  Y.  LeCun,  “Deep  multi-scale 
video  prediction  beyond  mean  sequare  error”,  arXiv 
preprint arXiv:1511.05440, 2015.     

[8]  S.  Niklaus,  L.  Mai,  F. Liu,  “Video  Frame  Interpolation 
via  Adaptive  Separable  Convolution”,  The  IEEE 
International  Conference  on  Computer  Vision  (ICCV), 
pp. 261-270, 2017.   

[9]  Y. Nagouthu, Y. Chen, E. Blasch et al, “A study on smart 
online  frame  forging  attacks  against  video  surveillance 
system”,  Proceedings  of  the  2019  SPIE  Defense  + 
Commercial Sensing, pp. 1-12, SPIE, 2019.   

[10]  A.  Costin,  “Security  of  CCTV  and  Video  Surveillance 
Systems:  Threats,  Vulnerabilities,  Attacks 
and 
the  6th 
Mitigation”,  TrustED’16  Proceedings  of 
International  Workshop  on  Trustworthy  Embedded 
Devices, New York, 2016.   

[11]  N. Zhang, X. Demetriou, X. Mi, W. Diao, K. Yuan, P.. 
Zong, F. Qian, X. Wang, K. Chen, Y. Tian, C. A. Gunter, 
K. Zhang, P. Tague, Y. Lin, “Understanding IoT Security 
Through the Data Crystal Ball: Where We Are Now and 
Where  We  Are  Going  To  Be”,  CoRR,  vol. 
abs/1703.09809, 2017.   

[12]  W. C. Siu, K. W. Hung, “Review of image interpolation 
and super-resolution”, Signal & Information Processing 
Association  Annual  Summit  and  Conference,  Asia-
Pacific, 2012.   

[13]  D. Mahajan, F. Huang, W. Matusik, R. Ramamoorthi, P. 
N. Belhumeur, “Moving gradients: A path-based method 
for plausible image interpolation”, ACM Trans. Graph., 
Vol. 28, Issue 3, pp. 1-42, 2009.   

[14]  S. Baker, D. Scharstein, J. P. Lewis, S. Roth, M. J. Black, 
R. Szeliski, “A database and evaluation methodology for 
optical flow”, International Journal of Computer Vision, 
Vol. 92, Issue 1, pp. 1-31, 2011.   

[15]  H. Sandberg, S. Amin, K. H. Johansson, “Cyberphysical 
Security in Networked Control Systems: An Introduction 
to the Issue”, Vol. 35, Issue 1, pp. 20-23, 2015.   

[16]  S. Xingjian, Z. Chen, H. Wang, D. Yeung, W. Wong, W. 
Woo,  “Convolutional  LSTM  network:  A  machine 
learning approach for precipitation nowcasting”, Neural 
Information Processing Systems, 2015.   

[17]  M.  Murphy,  “Man  arrested  for  tampering  with  traffic 
Facebook”, 

cameras, 
http://pix11.com/2015/08/25/man-arrested-after-
posting-videos-on-facebook-of-him-tampering-with-
traffic-cameras, Aug., 2015.   

‘how-to’ 

posting 

on 

[18]  Y.  S.  Chong,  Y.  H. Tay, “Abnormal event  detection in 
videos  using  spatiotemporal  autoencoder”,  Proceedings 
of the 14th International Symposium ISNN 2017, Sapporo, 
Hakodate  and  Muroran,  Hokkaido, Japan,  pp.  189-196, 
21-26 Jun 2017.   

[19]  N.  Srivastava,  E.  Mansimov,  R.  Salakhudinov, 
“Unsupervised  learning  of  video  representation  using 
lstms”, Proceedings of the 32rd International Conference 
on Machine Learning”, Lille, France, pp. 843-852, 6-11 
Jul 2015.   

[20]  J. An, S. Cho, “Variational Autoencoder Based Anomaly 
Detection Using Reconstruction Probability”, Technical 
Report SNU Data Mining Centre, South Korea, 2015.   

[21]  Z.  Liu,  R.  Yeh,  X.  Tang,  Y. Liu,  A.  Agarwala, “Video 
frame synthesis using deep voxel flow”, arXiv, preprint 
arXiv:1702.02463, 2017.   

 
 
 
 
