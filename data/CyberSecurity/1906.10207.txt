Date of publication xxxx 00, 0000, date of current version xxxx 00, 0000.

Digital Object Identiﬁer 10.1109/ACCESS.2021.DOI

Joint State Estimation Under Attack of
Discrete Event Systems

QI ZHANG1,2, CARLA SEATZU2, (Senior Member, IEEE), ZHIWU LI1,3, (Fellow, IEEE), AND
ALESSANDRO GIUA2, (Fellow, IEEE)
1School of Electro-Mechanical Engineering, Xidian University, Xi’an 710071, China
2Department of Electrical and Electronic Engineering, University of Cagliari, 09123 Cagliari, Italy
3Institute of Systems Engineering, Macau University of Science and Technology, Taipa 999078, Macau

Corresponding author: Zhiwu Li (e-mail: zhwli@xidian.edu.cn).

This work was partially supported by the National Key R&D Program of China under Grant 2018YFB1700104, the Natural Science
Foundation of China under Grand Nos. 61472295, 61673309, 61873342, the ShaanXi Huashan Scholars, the Science and Technology
Development Fund, MSAR, under Grant No. 122/2017/A3, and the Project RASSR05871 MOSIMA ﬁnanced by Region Sardinia, FSC
2014-2020, annuity 2017, Subject area 3, Action Line 3.1.

ABSTRACT The problem of state estimation in the setting of partially-observed discrete event systems
subject to cyber attacks is considered. An operator observes a plant through a natural projection that hides
the occurrence of certain events. The objective of the operator is that of estimating the current state of
the system. The observation is corrupted by an attacker which can tamper with the readings of a set of
sensors thus inserting some fake events or erasing some observations. The aim of the attacker is that of
altering the state estimation of the operator. An automaton, called joint estimator, is deﬁned to describe
the set of all possible attacks. In more details, an unbounded joint estimator is obtained by concurrent
composition of two state observers, the attacker observer and the operator observer. The joint estimator
shows, for each possible corrupted observation, the joint state estimation, i.e., the set of states consistent
with the uncorrupted observation and the set of states consistent with the corrupted observation. Such a
structure can be used to establish if an attack function is harmful w.r.t. a misleading relation. Our approach
is also extended to the case in which the attacker may insert at most n events between two consecutive
observations.

INDEX TERMS Discrete event systems, state estimation, cyber attacks.

1
2
0
2

c
e
D
4
1

]

R
C
.
s
c
[

7
v
7
0
2
0
1
.
6
0
9
1
:
v
i
X
r
a

I. INTRODUCTION
Cyber-physical systems are intelligent interconnected sys-
tems which are particularly exposed to network-based ma-
licious attacks. Their security is a topic which during the last
years has received much attention in different information
and communications technology (ICT) communities such as
automatic control [1], [2], computer science and engineering
[3], [4], and telecommunications [5].

In the domain of automatic control, the security of dynam-
ical systems has been addressed with two main formalisms.
The ﬁrst one is that of time-driven systems, either in contin-
uous time [6], [7] or in discrete time [8], [9]. In [6], the issue
of reliable control in cyber-physical system under attack has
been investigated. Rabehi et al. [7] design a secure interval
observer for solving the problem of state estimation. In [8],
the issue of reachability analysis in discrete-time systems
under attack has been studied. Finally, Zhang et al. [9]
propose the problem of data-driven resilient control against

cyber attacks.

The second formalism is that of discrete-event systems,
where time driven dynamics are abstracted and a logical (non
numerical) approach based on formal languages is adopted.
The problem of attack detection in the framework of discrete
event systems is addressed in [10]–[12]. In [13] the focus is
on fault diagnosis of discrete event systems under attack. The
problem of opacity enforcement by insertion functions under
energy constraints has been investigated in [14]. The problem
of supervisory control of discrete event systems under attack
has been considered in [15]–[24].

Mainly inspired by some recent works [25]–[28], we
address the problem of state estimation in the setting of
partially-observed discrete event systems subject to cyber
attacks. In this paper, which is an extended version of [29]1,

1In [29] we only provided preliminary ideas by considering a less gen-
eral problem statement. Furthermore, no algorithm was formally presented
therein.

VOLUME 4, 2016

1

 
 
 
 
 
 
we consider a plant modeled as a discrete event system with
state set X, whose evolution is observed by an operator. The
occurrence of a subset of events Eo, called observable events,
can be detected by sensors while all other events, called silent
events, produce no observation. An evolution of the plant
produces an observed word s ∈ E∗
o which the operator uses
to determine the set of consistent states C(s) ⊆ X, i.e., the
set of states in which the system may be when s has been
produced.

We assume that an attacker, which has a full knowledge
of the plant, may corrupt the sensor readings. This could
happen because either the attacker can gain direct control
of a sensor or it can corrupt messages between the plant
and the operator assuming they are connected through a
network. The particular attack model we adopt, among those
that have been presented in the literature, is based on the
one considered by Meira-Góes et al. [26]. In particular, the
attacker may insert in the word observed by the operator
fake occurrences of compromised events or, on the contrary,
may erase the occurrence of such events. In addition, we
consider the possibility that the length of a word inserted by
the attacker between the occurrence of two observable events
may be n-bounded.

The attacker aims to mislead an operator. Under attack,
an observation s ∈ E∗
o produced by a plant can be changed
into a corrupted observation s(cid:48) ∈ E∗
o and as a result the
operator computes a state estimate C(s(cid:48)) ⊆ X, which is in
general incorrect. The attacker may have arbitrary goals. As
an example, it may want to hide the fact that the plant has
reached a critical state such that the operator does not activate
appropriate protections that are fundamental for the system
safeness. In all generality, we formalize a malicious goal by
introducing a misleading relation R ⊆ 2X × 2X and we say
that an attack is harmful if there exists some observation s
that can be changed into a corrupted observation s(cid:48) such that
(C(s), C(s(cid:48))) ∈ R.

In this paper, we ﬁrst show how to construct two particular
automata, called attacker observer and operator observer,
which are deﬁned on an augmented attack alphabet which
includes the observable events of the plant and the events
describing the action of the attacker. Based on concurrent
composition of these two observers, we design a joint es-
timator, which describes all possible attacks. Finally, by
inspection of such a structure one can determine if the attack
function is harmful w.r.t. a misleading relation.

A. LITERATURE REVIEW
The problem of estimation under attack has been considered
by relatively few authors in the automatic control literature.
In [30]–[32] the state estimation problem for time-driven

models is studied.

Ding et al. [30] propose the problem of remote state
estimation under denial-of-service attacks. A sensor needs
to choose a channel to transmit the data packets, while an
attacker needs to choose a channel to attack. They formalize
such a problem as a two player stochastic game between

Q. Zhang et al.: Joint State Estimation Under Attack of Discrete Event Systems

the sensor and the attacker, and present optimal strategies
in terms of computational complexity for both sides, respec-
tively.

Peng et al. [31] consider the issue of optimal attack energy
allocation against remote state estimation. An optimal attack
strategy that can result in maximal estimation error covari-
ances is derived. Finally, they prove that the optimal strategy
has a threshold structure.

Cheng et al. [32] develop an attack strategy that can
degrade the estimation performance by tampering with the
sensors, eavesdropping the measurements, and injecting false
feedback information. They conclude that, with the presence
of an attacker, the mean-squared stability condition of the
state estimation is weakened.

In this work we consider discrete-event models, and the
approaches developed in the above mentioned literature can-
not be adopted. The state estimation problem for discrete
event systems so far has not been studied in all generality,
but has been partially addressed in the context of supervisory
control. Here we mention a few recent publications which
have inspired our work.

Tong et al. [25] present a new ﬁnite structure called par-
allel observer, which allows to simultaneously describe the
observations of the supervisor and of the attacker. Based on
the parallel observer, a maximally permissive supervisor is
developed to enforce current-state opacity.

Meira-Góes et al. [26] propose a novel bipartite transition
structure in the framework of discrete event systems, namely,
Insertion-Deletion Attack structure, and present a game-like
relationship between the supervisor and the environment (the
plant and the attacker) to determine if the attacker can lead
the plant to a forbidden state without being detected by the
supervisor.

Lima et al. [27] propose a defense policy that prevents
cyber attacks at sensor and actuator layer in supervisory
control systems. It is assumed that the attacker can alter the
observation of events in a set of events Σvs, and modify the
enabling of events in a set of events Σva. The detectable net-
work attack security and undetectable network attack security
are introduced to prevent the plant from reaching forbidden
states.

Su [28] addresses the problem of attack-with-bounded-
sensor-reading-alteration (ABSRA), where the attacker can
intercept the sensor readings from the plant and arbitrarily
alter them but with an upper bound on the length of the
altered observation word. In this way the attacker can cheat
the supervisor, which will lead the plant to the undesirable
states. The author also develops a supervisor that is robust to
ABSRA.

We point out that signiﬁcant differences exist between the
problem setting considered in this paper and the problem set-
ting dealt in most of the papers in the literature, including the
above mentioned ones. What we propose is a methodology
for studying how the possible choices of the attacker can
affect the estimate of the operator. On the contrary, previous
works on cyber attacks in the DES literature, including [15],

2

VOLUME 4, 2016

Q. Zhang et al.: Joint State Estimation Under Attack of Discrete Event Systems

[26]–[28], consider the case of an operator/supervisor: in
such a case the goal of the attacker is to beguile the supervisor
so that a speciﬁcation is violated, i.e., the plant reaches a
forbidden state or generates a forbidden evolution.

The proposed approach can be applied not only to the
case in which an operator-supervisor controls a plant in
closed-loop — as in the above mentioned papers — but in
more general settings, where the operator may have goals of
different nature. As an example, in our framework one may
study how cyber attacks disturb an operator-monitor which
takes decisions based on its estimation of the plant state or
an operator-diagnoser which aims to detect the occurrence of
faults. Mutatis mutandis, our approach can also be used for
addressing a problem of opacity enforcing: in such a case the
operator is an intruder that wants to infer a secret and the
attacker is the agent that corrupts the observation to thwart
the intruder.

B. CONTRIBUTIONS AND STRUCTURE OF THE PAPER
This paper contains several original contributions.

• The problem of joint state estimation under attack is
formalized; harmful attacks are characterized in general
terms by means of a misleading relation.

• Based on the notion of attack alphabet and attack words,
which describe how observations can be corrupted by
the attacker we show how to construct two different
observers: they describe the state estimates computed
by the attacker and by the operator for each corrupted
observation.

• A formal methodology to design a joint estimator is pre-
sented. This automaton, constructed as the concurrent
composition of the two observers, describes all possible
attacks.

• The joint estimator shows, for each possible corrupted
observation, the joint state estimation, i.e., the set of
states consistent with the uncorrupted observation and
the set of states consistent with the corrupted observa-
tion. Such a structure also indicates if a harmful attack
exists.

The rest of the paper is organized as follows. In Sec-
tion II, we recall the basic notions of ﬁnite-state automata
and of state estimation via observers. In Section III, we ﬁrst
describe the adopted attack model, and then formalize the
problem considered in this paper. In Section IV, we develop
two observers: attacker observer and operator observer. In
Section V, we deﬁne the unbounded joint estimator as the
concurrent composition of such observers. Then, we deﬁne
an automaton that allows us, again via concurrent composi-
tion, to deﬁne a bounded joint estimator, starting from the
unbounded one. Conclusions are ﬁnally drawn in Section VI
where we also discuss our future lines of research in this
framework.

II. PRELIMINARIES
Given an alphabet E, let E∗ denote the set of all words
on the alphabet. Given two words w1, w2 ∈ E∗, let w1w2

denote their concatenation. Similarly, given two languages
L1, L2 ⊆ E∗, we denote their concatenation L1L2 and when
L1 = {w} we also write L1L2 = wL2.

A deterministic ﬁnite-state automaton (DFA) is a four-
tuple G = (X, E, δ, x0), where X is the set of states, E
is the set of events (alphabet), δ : X × E → X is the
transition function, and x0 is the initial state. The transition
function can be extended to δ∗ : X × E∗ → X such that
δ∗(x, ε) = x, and δ∗(x, σe) = δ(δ∗(x, σ), e) for all x ∈ X,
e ∈ E and σ ∈ E∗. The generated language of G is deﬁned
as L(G) = {σ ∈ E∗ | δ∗(x0, σ) is deﬁned}.

Given two alphabets E(cid:48) and E with E(cid:48) ⊆ E, the natural

projection on E(cid:48), PE(cid:48) : E∗ → (E(cid:48))∗ is deﬁned as [33]:

PE(cid:48)(ε) := ε , PE(cid:48)(σe) :=

(cid:26) PE(cid:48)(σ)e
PE(cid:48)(σ)

if
if

e ∈ E(cid:48),
e ∈ E \ E(cid:48).

(1)
Therefore, given a word σ ∈ E∗, its natural projection on E(cid:48)
is obtained by erasing events that do not belong to E(cid:48).

The concurrent composition of two languages is deﬁned
as L1 (cid:107) L2 = {σ ∈ E∗ | PE1(σ) ∈ L1, PE2(σ) ∈ L2},
where E1 and E2 are alphabets of L1 and L2, respectively,
and E = E1 ∪ E2. The concurrent composition operator can
also be deﬁned for DFA. In particular, given two DFA G(cid:48) and
G(cid:48)(cid:48), their concurrent composition, denoted as G = G(cid:48) (cid:107) G(cid:48)(cid:48),
generates language L(G) = L(G(cid:48)) (cid:107) L(G(cid:48)(cid:48)).

A partially-observed deterministic ﬁnite-state automaton
is denoted as G = (X, E, δ, x0), where E = Eo ∪ Euo,
Eo is the set of observable events, and Euo is the set of
unobservable events. In the following, to keep the notation
simple, we denote as P : E∗ → E∗
o the natural projection
on Eo. The inverse projection P −1 : E∗
is deﬁned
as P −1(s) = {σ ∈ E∗ : P (σ) = s}, where σ ∈ E∗, and
s ∈ E∗
o .

o → 2E∗

When a partially-observed DFA generates a word σ ∈
L(G) it produces the observation s = P (σ) ∈ E∗
o . However,
in general a given observation may be produced by more
than one generated word. The set of words consistent with
observation s is deﬁned by

S(s) = P −1(s) ∩ L(G) = {σ ∈ L(G) | P (σ) = s}

and denotes the set of words generated by the DFA that
produce observation s.

Correspondingly, the set of states consistent with observa-

tion s is deﬁned by

C(s) = {x ∈ X | (∃σ ∈ S(s)) δ∗(x0, σ) = x}

and denotes the set of states in which the DFA can be when
observation s had been produced.

The set C(s) ⊆ X is also called the state estimate
corresponding to observation s ∈ E∗
o . The problem of state
estimation of a partially-observed DFA G can be solved, in
all generality, constructing a new structure called its observer
(see [34] for details).

Let us ﬁrst deﬁne, for a partially-observed DFA G, the
unobservable reach of a state x ∈ X. This set is denoted

VOLUME 4, 2016

3

by U R(x) and is deﬁned as a set of states x(cid:48) ∈ X reached
from state x generating an unobservable word σ ∈ E∗
uo, i.e.,
U R(x) = {x(cid:48) | ∃σ ∈ E∗
uo, δ∗(x, σ) = x(cid:48)}. This deﬁnition
can be extended to a set of states B ⊆ 2X as follows:

U R(B) =

(cid:91)

x∈B

U R(x).

The observer Obs(G) of a partially-observed DFA G =

(X, E, δ, x0), is a DFA:

Obs(G) = (B, Eo, δobs, b0),

where the set of states is B ⊆ 2X , the alphabet Eo is the
set of observable events of G, the transition function δobs :
B × Eo → B is deﬁned as:

δobs(b, eo) :=

(cid:91)

x∈b

U R({x(cid:48) | δ(x, eo) = x(cid:48)}),

and the initial state is b0 := U R(x0).

As shown in [34], given a partially-observed DFA G with
observer Obs(G) = (B, Eo, δobs, b0), for any observation
s ∈ E∗

o produced by G it holds that C(s) = δ∗

obs(b0, s).

III. THE JOINT STATE ESTIMATION PROBLEM
In this section, ﬁrst, we introduce an attack model and an
original formalism to represent it. Then, we formalize the
problem considered in this paper.

A. ATTACK MODEL
In this paper we consider a plant modeled by a partially
observable DFA with set of observable events Eo and set
of unobservable events Euo. Referring to Fig. 1, if σ is a
word generated by the plant, the observed word is s = P (σ).
An attacker may corrupt the output signals produced by the
plant with the effect of inserting in the observation some
events that did not occur, or erasing some events that have
occurred. Such a corrupted observation is denoted as s(cid:48) (a
sequence of events in Eo), and the operator constructs its
state estimation based on s(cid:48). In our framework, we assume
the operator monitors the plant to estimate its current state:
the objective of the attacker is to corrupt the observation in
such a way that a correct estimation is not possible.

FIGURE 1. A plant G under attack.

Deﬁnition 1: [26] The set of compromised events is denoted
as Ecom ⊆ Eo. It includes all the observable events that
can be corrupted by the attacker, either inserting them in the
operator observation, even if they have not actually occurred,
(cid:5)
or erasing them in the operator observation.
The deﬁnition of compromised events was ﬁrst proposed
in [26]. However, while in [26] the authors assume that all
the compromised events can be inserted and erased by the
attacker, here we slightly generalize the deﬁnition as follows.

Q. Zhang et al.: Joint State Estimation Under Attack of Discrete Event Systems

The set of compromised events that can be inserted in
the observer evolution is denoted as Eins, and the set of
events that can be erased is denoted as Eera. To keep the
presentation general, we assume that Eins and Eera are not
necessarily disjoint.

The relationship among the different subsets of observable

events Eo is clariﬁed in Fig. 2.

FIGURE 2. The relationship among the subsets of Eo.

We now formally describe the action of the attacker in
terms of two new types of events that it can generate. More
precisely, even if it is possible to directly deﬁne the attacker
as a ﬁnite-state transducer that “translates" an observed word
s into a corrupted observation s(cid:48) (see Fig. 1), for a reason that
will appear clear in the following, we prefer to characterize
the attacker’s action in terms of a new word deﬁned on a so-
called attack alphabet Ea.
Deﬁnition 2: The attack alphabet is deﬁned as Ea = Eo ∪
E+ ∪ E−, and we assume that Eo, E+, and E− are disjoint
sets.

The set of inserted events [26] is denoted as E+, namely
E+ = {e+ | e ∈ Eins}. The occurrence of an event e+ ∈
E+ denotes the fact that the attacker inserts in the operator
observation an event e ∈ Eins that has not occurred in reality.
The set of erased events [26] is denoted as E−, namely
E− = {e− | e ∈ Eera}. The occurrence of an event
e− ∈ E− denotes the fact that the attacker erases from the
operator’s observation event e ∈ Eera generated by plant. (cid:5)
+ |
|w+| ≤ n} denote the set of words on alphabet E+ whose
length does not exceed n. Note that if n = ∞ then E≤n
+ =
E∗
+.
Deﬁnition 3: Given a plant G with a set of compromised
events Ecom = Eins ∪ Eera, let n ∈ N ∪ {∞} be a bound.
An n-bounded attacker can be deﬁned by an attack function
fn : P (L(G)) → E∗
a, where Ea is the attack alphabet
(Deﬁnition 2), satisfying the following conditions:

Given a bound n ∈ N ∪ {∞}, let E≤n

+ = {w+ ∈ E∗

+

(a) fn(ε) ∈ E≤n
+ ,
(b) ∀se ∈ P (L(G)) with s ∈ E∗
o :
(cid:26) fn(se) ∈ fn(s){e−, e}E≤n
fn(se) ∈ fn(s){e}E≤n
+

e ∈ Eera,
e ∈ Eo \ Eera.
(2)
(cid:5)
In Deﬁnition 3, condition (a) means that the attacker can
insert a bounded word w+ ∈ E≤n
+ at the initial state, before
any event generated by the plant is observed. Condition (b)
implies that if an event e ∈ Eera occurs, the attacker can
either erase event e or not erase it, and then insert any word

if
if

4

VOLUME 4, 2016

Q. Zhang et al.: Joint State Estimation Under Attack of Discrete Event Systems

w+ ∈ E≤n
attacker can insert any word w+ ∈ E≤n

+ . If an event e ∈ Eo\Eera occurs, then the

+ after e.

We notice that imposing that the attacker may insert at
most n consecutive events between any two observed events,
makes sense in practice. Indeed, even if our model is purely
logical, a real system can produce in a ﬁnite time just a
ﬁnite number of events. If the attacker could introduce an
arbitrarily large number of events between two consecutive
observed events, this would lead to an anomalous behavior
as observed by the operator.

We denote as Fn the set of attack functions for a given

n ∈ N ∪ {∞}.
Deﬁnition 4: The language modiﬁed by an attack function
fn is called attack language. It is denoted as L(fn, G) and is
deﬁned as L(fn, G) = fn(P (L(G))). A word w ∈ L(fn, G)
is called an attack word.

The set of all the attack languages relative to a given n ∈

N ∪ {∞}, denoted as L(Fn, G), is deﬁned as

L(Fn, G) =

(cid:91)

fn∈Fn

L(fn, G) =

(cid:91)

fn∈Fn

fn(P (L(G))).

(3)

(cid:5)
Given two integer numbers n and n(cid:48), Fn ⊆ Fn(cid:48) if n ≤ n(cid:48).

Furthermore, Fn ⊆ F∞ for all n < ∞.
Deﬁnition 5: The operator mask (cid:98)P : E∗

a → E∗

o is deﬁned as:

(cid:98)P (ε) = ε, (cid:98)P (we(cid:48)) =






(cid:98)P (w)e if e(cid:48) = e ∈ Eo ∨
e(cid:48) = e+ ∈ E+,
(cid:98)P (w) if e(cid:48) = e− ∈ E−.

(4)

(cid:5)
The internal structure of the attacker is visualized in Fig. 1
as a black box taking an observation s as an input and
producing a corrupted observation s(cid:48) as an output. Such an
internal structure is sketched in more detail in Fig. 3.

FIGURE 3. Internal structure of the attacker with observed word s ∈ E∗
o ,
attack word w ∈ E∗

a, and corrupted observation s(cid:48) ∈ E∗
o .

Here the observed word is s = P (σ) (a sequence of events
in Eo). The attacker corrupts the observation according to the
attack function fn, producing w ∈ L(fn, G) ⊆ E∗
a. Such a
sequence is projected via (cid:98)P on Eo, generating a word s(cid:48). The
plant operator constructs its state estimation based on s(cid:48).

B. PROBLEM STATEMENT
In this subsection we ﬁrst describe the possible goals of the
attacker on which we are focusing in this paper. Then we
formalize the problem statement. To this aim we introduce a
relation R ⊆ 2X × 2X , called a misleading relation. If s and
s(cid:48) in E∗
o denote, respectively, the generic uncorrupted and

corrupted observation of the operator, the goal of the attacker
is achieved whenever

(C(s), C(s(cid:48))) ∈ R,

obs(b0, s(cid:48)), and (C(s), C(s(cid:48))) ∈ R.

i.e., whenever the pair (set of states consistent with the
uncorrupted observation, set of states consistent with the cor-
rupted observation) belongs to R. The following deﬁnition
formalizes this.
Deﬁnition 6: Let G = (X, E, δ, x0) be a plant with
set of observable events Eo and its observer Obs(G) =
(B, Eo, δobs, b0). An attack function fn is harmful w.r.t.
a relation R ⊆ 2X × 2X if there exists an observation
s ∈ P (L(G)) generated by the plant, whose set of consistent
states is C(s) = δ∗
obs(b0, s), such that s can be corrupted into
a word s(cid:48) = (cid:98)P (fn(s)) whose corresponding set of consistent
states is C(s(cid:48)) = δ∗
(cid:5)
Different physical problems can be described in this setting
by suitably deﬁning relation R. A signiﬁcant example is the
following one.
Example 1: Assume that a subset of states of a system,
Xcr ⊆ X, is labeled as critical in the sense that when the
system is in one of such states, a protective action must be
taken to avoid possible damages. The operator is monitoring
the system evolution in order to establish when one of such
states is reached. Obviously, if the operator does not realize
that a critical state has been reached, no action is taken and
the system behaviour can be seriously compromised. The
effectiveness of an attacker that aims to affect the system
observation in order to prevent the operator to realize when a
critical state is reached, can be evaluated via the misleading
relation deﬁned as R = {(X (cid:48), X (cid:48)(cid:48)) | X (cid:48) ∩Xcr (cid:54)= ∅ and X (cid:48)(cid:48) ∩
Xcr = ∅}. Indeed, the attack is harmful if there exists at least
one observation s such that C(s) ∩ Xcr (cid:54)= ∅ (meaning that
the system may be in a critical state) which can be corrupted
to an observation s(cid:48) with C(s(cid:48)) ∩ Xcr = ∅ (meaning that
the operator excludes the possibility that the system is in a
(cid:5)
critical state).
Given a plant G = (X, E, δ, x0) with set of observable
events Eo, and a misleading relation R ⊆ 2X × 2X , the main
contribution of this paper consists in providing a tool, called
a joint estimator that contains all the possible actions (insert
and/or erase observations) that an attacker may implement
during the system evolution. On the basis of such a structure,
the attacker can establish if the attacks are harmful to the
plant.

IV. ATTACKER OBSERVER AND OPERATOR OBSERVER
In this section we introduce two special structures, called
Attacker Observer and Operator Observer, which are funda-
mental to derive the solution to the joint estimation problem
we are considering.

A. ATTACKER OBSERVER
The attacker observer Obsatt(G) describes all possible attack
words that can be generated by functions in F∞ and the
corresponding sets of consistent states of the system. Since

VOLUME 4, 2016

5

Q. Zhang et al.: Joint State Estimation Under Attack of Discrete Event Systems

attacks are performed by the attacker, it knows which obser-
vations originate from events that have really occurred in the
plant (Eo), which observations have been erased (E−), and
which observations have been inserted (E+). The attacker
observer Obsatt(G) can be constructed using Algorithm 1.

Algorithm 1 Construction of
Obsatt(G)
Input: An observer Obs(G) = (B, Eo, δobs, b0), Eins, and

attacker observer

the

Eera.
Output: An

attacker

observer Obsatt(G)

=

(B, Ea, δatt, b0).

if δatt(b, e) = b(cid:48), then
δatt(b, e−) = b(cid:48);

1: Let Ea := Eo ∪ E+ ∪ E−;
2: Let δatt := δobs;
3: for all e ∈ Eera, do
for all b ∈ B, do
4:
5:
6:
7:
8:
9: end for
10: for all e ∈ Eins, do
for all b ∈ B, do
11:
12:
13:
14: end for

δatt(b, e+) = b;

end for

end for

end if

According to Algorithm 1, the set Ea is initially com-
puted and the transition function of Obsatt(G) is initialized
at δatt = δobs. Indeed, events in Eo are events actually
occurring in the plant, thus when such events occur the at-
tacker updates its state estimation according to the transition
function of Obs(G).

Then, for all e ∈ Eera and for all b ∈ B, whenever
δatt(b, e) is deﬁned, the algorithm imposes δatt(b, e−) =
δatt(b, e). Indeed, the attacker knows that e− corresponds to
event e that has been canceled, thus the way it updates its
estimation is the same in the case of e and e−.

Finally, for all events e ∈ Eins, and for all states b ∈ B,
we add self-loops δatt(b, e+) = b. Indeed, the attacker knows
that events in E+ are fake events that have not really occurred
in the plant, thus it does not update its estimation based on
them. In particular, self-loops correspond to the possibility
of inserting an arbitrarily large number of such events, which
is consistent with the fact that we are dealing with attack
functions in F∞.
Example 2: Consider a partially-observed plant G =
(X, E, δ, x0) in Fig. 4(a), where E = Eo ∪ Euo, Eo =
{a, c, d, g}, and Euo = {b}. The corresponding observer of
G is shown in Fig. 4(b). Let Eins = {c, d}, and Eera =
{c, g}. The attacker observer constructed using Algorithm 1
is shown in Fig. 5(a).

Since events c, g ∈ Eera, and there is a transition labeled
c from state {1, 2} to state {3} in the observer of the plant
Obs(G), we add transitions labeled c and c− from state
{1, 2} to state {3} in the attacker observer. Similar arguments

(a) G

(b) Obs(G)

FIGURE 4. (a) A partially-observed plant G; (b) its observer Obs(G), where
Eo = {a, c, d, g}.

(a) Obsatt(G)

(b) Obsopr(G)

FIGURE 5. (a) Attacker observer in Example 2 and (b) operator observer in
Example 3 for the plant in Fig. 4.

6

VOLUME 4, 2016

Q. Zhang et al.: Joint State Estimation Under Attack of Discrete Event Systems

can be used to explain transitions labeled c and c− from state
{5} to state {6}, self-loops labeled g and g− at state {4}.
Then, since c, d ∈ Eins, we add self-loops labeled c+ and
(cid:5)
d+ at all the states.
The following proposition provides a characterization of

the attacker observer.
Proposition 1: Consider a plant G with set of observable
events Eo and observer Obs(G) = (B, Eo, δobs, b0). Let f∞
be an attack function, F∞ be the set of attack functions, and
Ea = Eo ∪E+ ∪E− be an attack alphabet. Let Obsatt(G) be
the attacker observer constructed using Algorithm 1. It holds
that:

(a) L(Obsatt(G)) = L(F∞, G);
(b) ∀s ∈ P (L(G)), ∀f∞ ∈ F∞ with w = f∞(s) ∈ E∗
a:
att(b0, w) = δ∗
δ∗

obs(b0, s).

Proof: (a) According to Algorithm 1, Step 2 implies that
L(Obsatt(G)) contains all words that can be observed if no
attack occurs. Correspondingly, according to the deﬁnition
of attack function (Deﬁnition 3), the set of attack languages
L(F∞, G) also contains these words since the attacker does
not reduce the language of the plant.

Steps 3–9 guarantee that all attacks resulting from the can-
cellation of events in Eera are considered. Correspondingly,
according to the deﬁnition of attack function, each time the
plant generates an event e ∈ Eera, then the attacker can erase
it.

Finally, Steps 10–14 guarantee that all attacks resulting
from the insertion of an arbitrarily large number of events
in Eins are taken into account. Again, according to the
deﬁnition of attack function, the attacker can insert any word
w+ ∈ E≤n

+ whenever possible.

Thus, we can conclude that L(Obsatt(G)) = L(F∞, G).
(b) We prove this by induction on the length of s. If s = ε,
the result follows from the fact that, by deﬁnition of attack
function, it is f∞(ε) ∈ E≤n
+ , and by Steps 10–14, events in
E+ lead to self-loops in Obsatt(G).

Let us now consider a generic word s ∈ P (L(G)) with
length greater than one, written as s = se, where s ∈
P (L(G)) and e ∈ Eo. Assume the result holds for s. We
prove that it also holds for s = se considering the following
two possible cases.

f∞(s){e−, e}E≤n

If e ∈ Eera, by the deﬁnition of attack function, w ∈
(cid:83)
+ is true. According to Steps 3–9,
f∞∈F∞
events e and e− are dealt with in the same manner when
deﬁning the transition function δatt. Finally, as just pointed
out, according to Steps 10–14, events in E+ lead to self-loops
in Obsatt(G).

Finally, if e ∈ Eo \ Eera, by the deﬁnition of attack
f∞(s)eE≤n
+ is true. Thus the result

function, w ∈ (cid:83)

f∞∈F∞

follows from the fact that, according to Steps 10–14, events
in E+ lead to self-loops in Obsatt(G) and events in Eo are
dealt with in the same manner in Obsatt(G) and Obs(G). (cid:3)
Now we discuss the computational complexity of con-
structing the attacker observer Obsatt(G). Given a plant G

with set of states X, the observer of the plant Obs(G) can
be constructed in 2|X| steps. According to Algorithm 1,
Obsatt(G) has the same number of states as Obs(G); thus
the complexity of building Obsatt(G) is O(2|X|).

B. OPERATOR OBSERVER
The attack model we are considering may change an obser-
vation s into a corrupted observation s(cid:48) which cannot be
produced by the nominal plant. In this case the operator
understands that the system is under attack. This can be
formalized as follows.
Deﬁnition 7: Consider a plant G. An attack function fn is
said to be stealthy if (cid:98)P (L(fn, G)) ⊆ P (L(G)), where (cid:98)P is
(cid:5)
the operator mask.
In words, stealthiness requires that the set of words that
an operator observes when the system is under attack is
contained in the set of words the operator may observe when
no attack occurs.

The operator observer Obsopr(G) generates two different
sets of words. The ﬁrst set includes all words on E∗
a that may
either result from an uncorrupted observation of the plant
or from a corrupted observation which keeps the attacker
stealthy. The second set of words includes all the previous
words continued with a symbol in Ea so that the resulting
word is not consistent with an uncorrupted observation.
While the words in the ﬁrst set lead to a set of states that
according to the operator are consistent with the perceived
observation, those in the second set lead to a dummy state
denoted as b∅. The operator observer Obsopr(G) can be
constructed using Algorithm 2, as shown below.

According to Algorithm 2, the set of states Bopr = B ∪
{b∅} and the set of events Ea are initially computed. Then,
the transition function of Obsopr(G) is initialized at δopr =
δobs. Indeed, events in Eo are events actually occurring on the
plant; when such events occur, the operator updates its state
estimation according to the transition function of Obs(G).

Furthermore, for all e ∈ Eins and for all b ∈ B, we
impose δopr(b, e+) = δopr(b, e). Indeed, the operator does
not distinguish between events in E+ and the corresponding
events in Eins. For all e ∈ Eera and for all b ∈ B, we add
self-loops δopr(b, e−) = b. Indeed, events in E− correspond
to no observation by the operator.

Finally, for all the events ea ∈ Ea that are not enabled at
the generic state b ∈ B, let δopr(b, ea) = b∅. As a result, for
all b ∈ B and for all ea ∈ Ea, function δopr(b, ea) is deﬁned.
On the contrary, δopr(b∅, ea) is undeﬁned for all ea ∈ Ea.
Example 3: Consider again the plant G in Fig. 4. Let Eins =
{c, d} and Eera = {c, g}. The operator observer constructed
using Algorithm 2 is visualized in Fig. 5(b).

Since c, d ∈ Eins and there is a transition labeled c
from state {1, 2} to state {3} in Obs(G), we add transitions
labeled c and c+ from state {1, 2} to state {3} in the oper-
ator observer. Similar arguments can be used to explain the
transitions labeled c and c+ from state {5} to state {6}, the
transitions labeled d and d+ from state {7, 8} to state {8},
and the self-loops labeled d and d+ at state {8}. Then, since

VOLUME 4, 2016

7

Algorithm 2 Construction of
Obsopr(G)
Input: An observer Obs(G) = (B, Eo, δobs, b0), Eins, and

the operator observer

observer Obsopr(G)

=

Eera.
Output: An

operator
(Bopr, Ea, δopr, b0).
1: Let Bopr := B ∪ {b∅};
2: Let Ea := Eo ∪ E+ ∪ E−;
3: Let δopr := δobs;
4: for all e ∈ Eins, do
for all b ∈ B, do
5:
6:
7:

if δopr(b, e) = b(cid:48), then
δopr(b, e+) = b(cid:48);

end if

end for

8:
9:
10: end for
11: for all e ∈ Eera, do
for all b ∈ B, do
12:
13:

δopr(b, e−) = b;

end for

14:
15: end for
16: for all ea ∈ Ea, do
17:
18:
19:

for all b ∈ B, do

if δopr(b, ea) is not deﬁned, then

δopr(b, ea) = b∅;

end if

20:
21:
22: end for

end for

c, g ∈ Eera, we add self-loops labeled c− and g− at all the
states. Finally, we add all the missing transitions to the new
(cid:5)
state b∅, which has no output arc.
To better characterize the properties of the operator ob-
server, let us deﬁne two sets of words associated to an attack
model as described in Subsection III-A.
Deﬁnition 8: The set of stealthy words on attack alphabet Ea
is

Ws = {w ∈ E∗

a | (cid:98)P (w) ∈ P (L(G))},

while the set of exposing words on Ea is

We = {wea ∈ E∗

a | w ∈ Ws, ea ∈ Ea, wea (cid:54)∈ Ws}.

(cid:5)
In plain words, a stealthy word w produces an observed
word s(cid:48) = (cid:98)P (w) which does not reveal the presence of
the attacker because such an observation may have been
produced by the plant. An exposing word is a non-stealthy
word on Ea whose strict preﬁxes are all stealthy: hence it
reveals the presence of the attacker but only at the last step.

The following proposition provides a characterization of

the operator observer.
Proposition 2: Let G be a plant with set of observable events
Eo and observer Obs(G) = (B, Eo, δobs, b0). Given an
attack alphabet Ea = Eo ∪ E+ ∪ E− with set of stealthy
words Ws and set of exposing words We, let Obsopr(G) be

Q. Zhang et al.: Joint State Estimation Under Attack of Discrete Event Systems

the operator observer constructed by Algorithm 2. It holds
that:

(a) L(Obsopr(G)) = Ws ∪ We;
(b) ∀w ∈ L(Obsopr(G)): if w ∈ Ws, then δ∗
obs(b0, (cid:98)P (w)); if w ∈ We, then δ∗
δ∗

opr(b0, w) = b∅.

opr(b0, w) =

Proof: (a) Follows from Algorithm 2, and from the deﬁni-
tions of stealthy words, exposing words, and operator mask.
In more detail, Step 3 guarantees that all uncorrupted
words belong to L(Obsopr(G)). Steps 4–10 guarantee that,
in Obsopr(G), events in E+ lead to the same states of the
corresponding events in Eins. Steps 11–15 guarantee that,
in Obsopr(G), events in E− lead to self-loops. The above
steps guarantee that all the stealthy words w ∈ Ws belong to
L(Obsopr(G)).

Finally, Steps 16–22 impose that,

if after executing
Steps 1–15, a certain event in Ea is not already enabled at
a certain state of Obsopr(G), then such an event is enabled at
such a state and leads to state b∅, where no other event may
be executed. These steps ensure that all the exposing words
w ∈ We belong to L(Obsopr(G)).

(b) We prove this by induction on the length of w. If w = ε,

the result holds being ˆP (w) = ε.

Consider now a word w ∈ L(Obsopr(G)) with length
greater than one. Assume w ∈ Ws, and let w = w(cid:48)ea.
Assume that the result holds for a generic w(cid:48) ∈ Ws. By
deﬁnition of operator mask, if ea ∈ Eo ∪ E+, then (cid:98)P (w) =
(cid:98)P (w(cid:48))e ∈ (cid:98)P (w(cid:48)){e, ε}; otherwise (cid:98)P (w) = (cid:98)P (w(cid:48)) ∈
opr(b0, w(cid:48)), ea).
(cid:98)P (w(cid:48)){e, ε}. Thus δ∗
obs(b0, (cid:98)P (w(cid:48))), e) if ea ∈
Then, δ∗
obs(b0, (cid:98)P (w(cid:48))), ε) if
Eo ∪ E+, and δ∗
ea ∈ E−.

obs(b0, (cid:98)P (w)) = δobs(δ∗

obs(b0, (cid:98)P (w)) = δobs(δ∗

opr(b0, w) = δopr(δ∗

According to Algorithm 2 the transition function of
Obsopr(G) starting for a generic state b ∈ B is deﬁned in the
same way in case of e and e+ (Steps 6 and 7), while it corre-
sponds to a self-loop in the case of e− ∈ E− (Step 13). As a
result, we can conclude that δ∗

opr(b0, w) = δ∗

obs(b0, (cid:98)P (w)).

Finally, the last claim in (b) follows from the fact that, if
w ∈ We, according to Algorithm 2, all the missing transitions
(cid:3)
end up in the new state b∅, thus δ∗
Given a plant G with set of states X, the observer of the
plant Obs(G) can be constructed in 2|X| steps. According
to Algorithm 2, the operator observer Obsopr(G) has at
most 2|X| + 1 states; thus the complexity of constructing
Obsatt(G) is O(2|X|).

opr(b0, w) = b∅.

V. UNBOUNDED AND N -BOUNDED JOINT ESTIMATORS
In this section we deﬁne a particular DFA, called joint
estimator, which is deﬁned on alphabet Ea and contains all
attack words that can be generated by the plant.

Here we distinguish two different cases. In the ﬁrst case,
the attack function belongs to F∞. We call unbounded joint
estimator the corresponding DFA, denoted as A∞. In the
second case, the attack function belongs to Fn for a given
n ∈ N. We call n-bounded joint estimator the corresponding
DFA and denote it as An.

8

VOLUME 4, 2016

Q. Zhang et al.: Joint State Estimation Under Attack of Discrete Event Systems

A. UNBOUNDED JOINT ESTIMATOR
Let us ﬁrst formalize the deﬁnition of A∞.
Deﬁnition 9: The unbounded joint estimator A∞ =
(R, Ea, δa, r0) w.r.t. G and Ecom is deﬁned as A∞ =
(cid:5)
Obsatt(G) (cid:107) Obsopr(G).
Example 4: Consider again the plant G in Fig. 4 whose
attacker observer and operator observer are visualized in
Figs. 5(a) and (b), respectively. The unbounded joint estima-
tor A∞ built according to Deﬁnition 9 is shown in Fig. 6.

Theorem 1: Let G be a plant with set of observable events Eo
and observer Obs(G) = (B, Eo, δobs, b0). Given attack al-
phabet Ea, with set of stealthy words Ws and set of exposing
words We, let A∞ = (R, Ea, δa, r0) be its unbounded joint
estimator. It holds that:

(a) L(A∞) = L(F∞, G) ∩ (Ws ∪ We);
(b) ∀s ∈ P (L(G)), ∀f∞ ∈ F∞ with w = f∞(s) ∈ E∗
a:

a(r0, w) = (ba, ba) ⇐⇒
obs(b0, (cid:98)P (w)) = ba;
a(r0, w) = (ba, b∅) ⇐⇒
obs(b0, (cid:98)P (w)) is not deﬁned.

(i) if w ∈ Ws then δ∗
obs(b0, s) = ba, δ∗
δ∗
(ii) if w ∈ We then δ∗
obs(b0, s) = ba, δ∗
δ∗
Proof:
(a) Follows from Propositions 1 and 2 and
it holds that
Indeed, by Proposition 1,
Deﬁnition 9.
L(Obsatt(G)) = L(F∞, G) and by Proposition 2, it holds
that L(Obsopr(G)) = Ws ∪ We. Since A∞ is deﬁned as the
concurrent composition of Obsatt(G) and Obsopr(G), hav-
ing the same alphabet, its language is equal to the intersection
of the languages of the two DFA.

(b) We ﬁrst consider the case: w ∈ Ws.
(If) Assume that δ∗

obs(b0, s) = ba, δ∗

obs(b0, (cid:98)P (w)) =
ba. By Propositions 1 and 2, it holds that δ∗
obs(b0, s) =
att(b0, w) and δ∗
δ∗
opr(b0, w), namely,
att(b0, w) = ba and δ∗
δ∗
opr(b0, w) = ba. Since A∞ =
Obsatt(G) (cid:107) Obsopr(G), by deﬁnition of concurrent com-
position, it is δ∗

obs(b0, (cid:98)P (w)) = δ∗

a(r0, w) = (ba, ba).

FIGURE 6. Unbounded joint estimator A∞ in Example 4.

By inspecting the unbounded joint estimator A∞ in Fig. 6,
once event a occurs on the plant, the attacker executes event
a on A∞ starting from the initial state ({0}, {0}). Thus state
({1, 2}, {1, 2}) is reached. Now, the attacker may wait for
a new event occurring on the plant, a or c in this case.
Alternatively, the attacker may insert an event c or d in the
operator observation, which correspond to execute c+ or d+,
respectively, in A∞. Then, the attacker may erase event c in
the operator observation, which corresponds to execute c− in
A∞, and so on.

We notice that, any word w ∈ E∗

a generated by the un-
bounded joint estimator allows us to argue the following three
information: (1) which is the observation s ∈ E∗
o actually
produced by the system; (2) how the attacker corrupted it
(which events it has inserted and/or erased); (3) which is
the word s(cid:48) ∈ E∗
o observed by the operator. Consider as an
example, the word w = ac−ac+ ∈ E∗
a that leads to state
({4}, {6}). This corresponds to the observation s = aca
produced by the system. The attacker erases the observation c
after the ﬁrst a and inserts the dummy observation c after the
second a, resulting in the word s(cid:48) = (cid:98)P (w) = aac observed
(cid:5)
by the operator.
The following theorem provides a characterization of the

unbounded joint estimator.

VOLUME 4, 2016

obs(b0, s) = δ∗

(Only if) Assume that δ∗

att(b0, w) = ba and δ∗

a(r0, w) = (ba, ba). Since A∞ =
Obsatt(G) (cid:107) Obsopr(G), by deﬁnition of concurrent compo-
sition, it holds that δ∗
opr(b0, w) = ba.
By Propositions 1 and 2, it is δ∗
att(b0, w) and
δ∗
obs(b0, (cid:98)P (w)) = δ∗
obs(b0, s) = ba and
δ∗
obs(b0, (cid:98)P (w)) = ba.
Let us ﬁnally consider the case w ∈ We. The proof follows
from the deﬁnition of concurrent composition and the fact
that a word w in the operator observer yields state b∅ if
and only if (cid:98)P (w) (cid:54)∈ P (L(G)), i.e., δ∗
obs(b0, (cid:98)P (w)) is not
(cid:3)
deﬁned.

opr(b0, w), namely, δ∗

In plain words, Theorem 1 implies that the language of
the joint estimator contains all words on alphabet Ea that
can be generated under attack and that are either stealthy or
exposing. In addition the state (ba, ba) reached in the joint
estimator by a stealthy word w = f∞(s) describes the joint
estimation composed by the correct observation ba = C(s)
that would have been computed by the operator without
attack, and the corrupted observation ba = C(s(cid:48)) = C( (cid:98)P (w))
due to the attack. An exposing word w = f∞(s) reaches a
state (ba, b∅) where ba = C(s) is the correct observation that
would have been computed by the operator without attack.

Let us show how to select a harmful attack function on the

basis of the unbounded joint estimator A∞.
Proposition 3: Given a plant G = (X, E, δ, x0) with set
of compromised events Ecom, let R ⊆ 2X × 2X be the
misleading relation, and A∞ = (R, Ea, δa, r0) be the un-
bounded joint estimator. An attack function fn is harmful iff
R ∩ R (cid:54)= ∅.

9

Proof: (If) Assume that there exists a state r = (ba, ba) of the
joint estimator A such that r ∈ R ∩ R. Since r ∈ R, then
there exists an attack word w with δa(r0, w) = r. According
to the deﬁnition of attack function (Deﬁnition 3), there exists
an observation s ∈ P (L(G)) such that w = fn(s), where P
is the natural projection.

According to Theorem 1, if w ∈ Ws (Ws is the set of
stealthy words), we have r = (ba, ba) such that δ∗
obs(b0, s) =
ba, and δ∗
obs(b0, (cid:98)P (w)) = ba, where (cid:98)P is the operator mask.
Note that, if w ∈ We (We is the set of exposing words),
then δa(r0, w) = r = (ba, b∅) /∈ R, which leads to a
contradiction. For this reason, we exclude such a case.

Since r = (ba, ba) ∈ R, then the observation s can be
corrupted into a word s(cid:48) = (cid:98)P (w) such that (C(s), C(s(cid:48))) ∈
R, where C(s) = δ∗
obs(b0, s(cid:48)) (C(s)
(resp., C(s(cid:48))) is the set of states consistent with observation s
(resp., s(cid:48))). According to Deﬁnition 6, we can conclude that
fn is harmful.

obs(b0, s), and C(s(cid:48)) = δ∗

(Only if) Assume that an attack function fn is harmful.
According to Deﬁnition 6, there exists an observation s
that can be corrupted into an observation s(cid:48) = (cid:98)P (w) such
that (C(s), C( (cid:98)P (w))) ∈ R, where C(s) = δ∗
obs(b0, s),
C( (cid:98)P (w)) = δ∗
obs(b0, (cid:98)P (w)), and w = fn(s) ∈ Ws (we
exclude the case that w ∈ We for the same reason that
discussed in the above proof).

Since the joint estimator A contains all the possible at-
tacks, and according to Theorem 1, then there must exist a
state r = δa(r0, w) = (ba, ba) such that δ∗
obs(b0, s) = ba,
(cid:3)
and δ∗
Example 5: Recall the plant G in Fig. 4 with the unbounded
joint estimator A∞ depicted in Fig. 6. Assume that the
misleading relation is R = {({5}, X) | X ⊆ {6, 7, 8}}.

obs(b0, (cid:98)P (w)) = ba. Namely, R ∩ R (cid:54)= ∅.

Looking at A∞, if the plant generates the word aa, A∞ is
in state ({5}, {5}), then the attacker can insert a fake event
c+ such that state ({5}, {6}) ∈ R is reached. If such a
state is reached, the plant is in the critical state {5}, while
the operator thinks that the plant is in the non-critical state
{6}. Thus no protective actions are activated, and damages
(cid:5)
are caused.
We conclude this subsection discussing the complexity of

computing the unbounded joint estimator A∞.

Given a plant G with set of states X, both the attack
observer and the operator observer are computed in 2|X|
steps. The unbounded joint estimator is deﬁned as A∞ =
Obsatt(G) (cid:107) Obsopr(G); thus the complexity of construct-
ing A∞ is O(2|X| · 2|X|).

B. BOUNDED JOINT ESTIMATOR
The n-bounded joint estimator An that describes attack func-
tions in Fn, can be easily obtained starting from A∞. To this
aim, a particular DFA, called n-bounded attack automaton,
denoted as Gn, is introduced. Then An is obtained as the
concurrent composition of A∞ and Gn.
Deﬁnition 10: The n-bounded attack automaton is a DFA:
Gn = (X, Ea, δ, 0), where X = {0, 1, . . . , n} (n ∈ N), and
the transition function is deﬁned as follows:

Q. Zhang et al.: Joint State Estimation Under Attack of Discrete Event Systems

(cid:26) ∀i ∈ X, δ(i, ea) := 0 if ea ∈ Ea \ E+,

∀i ∈ (X\{n}), δ(i, ea) := i + 1 if ea ∈ E+.

(5)

(cid:5)
Fig. 7 shows the n-bounded attack automaton Gn. As it
can be seen, events in Ea \ E+ are enabled at any state. On
the contrary, events in E+ are enabled provided that they have
not been already executed n times consecutively.

FIGURE 7. n-bounded attack automaton Gn

Theorem 2: Let G be a plant with attack alphabet Ea and
unbounded joint estimator A∞ = (R, Ea, δa, r0). Let An =
A∞ (cid:107) Gn, where Gn is the n-bounded attack automaton. It
holds that L(An) = L(A∞) \ {w ∈ L(A∞) | consE+(w) >
n}, where consE+(w) denotes the maximum number of
consecutive events in E+ contained in the word w.

Proof: Follows from the fact that An is deﬁned as An =
A∞ (cid:107) Gn and Gn limits to n the maximum number of
consecutive events that the attacker can add to the operator
(cid:3)
observation.
Example 6: Consider the unbounded joint estimator A∞ in
Example 4. The 1-bounded attack automaton G1 and the 1-
bounded joint estimator A1 = A∞ (cid:107) G1 are depicted in
Figs. 8 and 9, respectively.

FIGURE 8. 1-bounded attack automaton G1 in Example 6.

The 1-bounded joint estimator forces the attacker to insert
at most one fake event between the occurrence of two observ-
(cid:5)
able events of the system.
A result equivalent to Theorem 1 holds for an n-bounded

joint estimator.

Now we discuss the computational complexity of building
the n-bounded joint estimator An. Given an integer value
n, the n-bounded joint estimator is obtained by computing
An = A∞ (cid:107) Gn where Gn is the n-bounded attack
automaton. Therefore, the complexity of computing An is
O(2|X| · 2|X| · n).

VI. CONCLUSIONS AND FUTURE WORK
In this paper we investigate the problem of state estimation
under attack, for partially-observed discrete event systems. In

10

VOLUME 4, 2016

Q. Zhang et al.: Joint State Estimation Under Attack of Discrete Event Systems

FIGURE 9. 1-bounded joint estimator A1 in Example 6.

more detail, an operator observes the system evolution with
a natural projection, which depends on the sensors available
on the system. The operator observation may be corrupted
by an attacker. The corruption may be done by erasing some
events that have occurred and/or inserting some events that
have not actually occurred. It is possible to impose an upper
bound on the number n of consecutive observations that
can be added by the attacker within the occurrence of two
observable events in the plant. We show how to construct a
joint estimator that contains all the possible attacks that can
be implemented during the system evolution and that allows
to establish if an attack function is harmful w.r.t. a given
misleading relation.

Our future lines of research in this framework will follow
several directions. On the one hand, we will look for a way
to select stealthy and harmful attacks on the basis of the joint
estimator or establish if such attacks can be thwarted. On the
other hand, we will try to characterize and solve the same
problem using Petri nets to understand if some advantages
in terms of computational complexity can be obtained and
if efﬁcient solutions can also be computed for unbounded
systems.

REFERENCES
[1] D. Zhang, G. Feng, Y. Shi, and D. Srinivasan, “Physical safety and cyber
security analysis of multi-agent systems: A survey of recent advances,”
IEEE/CAA J. of Autom. Sinica, vol. 8, no. 2, pp. 319–333, Feb. 2021.
[2] A. Rashidinejad, B. Wetzels, M. Reniers, L. Lin, Y. Zhu, and R. Su,
“Supervisory control of discrete-event systems under attacks: An overview
and outlook,” in Proc. 18th European Control Conference, Napoli, Italy,
2019, pp. 1732–1739.

[3] M. Uma and G. Padmavathi, “A survey on various cyber attacks and their
classiﬁcation,” Int. J. of Network Security, vol. 15, no. 5, pp. 390–396, Sep.
2013.

[4] F. Salahdine and N. Kaabouch, “Social engineering attacks: A survey,”

Future Internet, vol. 11, no. 4, 2019.

[5] A. Basit, M. Zafar, X. Liu, A. R. Javed, Z. Jalil, and K. Kifayat, “A com-
prehensive survey of AI-enabled phishing attacks detection techniques,”
Telecommunication Syst., vol. 76, pp. 139–154, Jan. 2021.

[6] X. Huang and J. Dong, “Reliable control policy of cyber-physical systems
against a class of frequency-constrained sensor and actuator attacks,” IEEE
Trans. Cybern., vol. 48, no. 12, pp. 3432–3439, Dec. 2018.

[7] D. Rabehi, N. Meslem, and N. Ramdani, “Secure interval observer for
linear continuous-time systems with discrete measurements subject to
cyber-attacks,” in Proc. 4th Conference on Control and Fault Tolerant
Systems, Casablanca, Morocco, 2019, pp. 336–341.

[8] H. Liu, B. Niu, and J. Qin, “Reachability analysis for linear discrete-
time systems under stealthy cyber attacks,” IEEE Trans. Autom. Control,
vol. 66, no. 9, pp. 4444–4451, Sep. 2021.

[9] W. Zhang, S. Mao, J. Huang, L. Kocarev, and Y. Tang, “Data-driven
resilient control for linear discrete-time multi-agent networks under un-
conﬁned cyber-attacks,” IEEE Trans. Circuits Syst. I, vol. 68, no. 2, pp.
776–785, Feb. 2021.

[10] D. Thorsley and D. Teneketzis, “Intrusion detection in controlled discrete
event systems,” in Proc. IEEE 45th Annu. Conf. on Decision and Control,
San Diego, USA, 2006, pp. 6047–6054.

[11] F. A. Barbhuiya, M. Agarwal, S. Purwar, S. Biswas, and S. Nandi,
“Application of stochastic discrete event system framework for detection
of induced low rate TCP attack,” ISA Trans., vol. 58, pp. 474–492, Sep.
2015.

[12] R. Fritz and P. Zhang, “Modeling and detection of cyber attacks on discrete
event systems,” in Proc. of 14th Int. Workshop on Discrete Event Systems,
Sorrento, Italy, 2018, pp. 285–290.

[13] M. Agarwal, S. Biswas, and S. Nandi, “Discrete event system framework
for fault diagnosis with measurement inconsistency: case study of rogue
DHCP attack,” IEEE/CAA J. of Autom. Sinica, vol. 6, no. 3, pp. 789–806,
May 2019.

[14] Y. Ji, X. Yin, and S. Lafortune, “Enforcing opacity by insertion functions
under multiple energy constraints,” Automatica, vol. 108, p. 108476, Oct.
2019.

[15] L. K. Carvalho, Y.-C. Wu, R. Kwong, and S. Lafortune, “Detection and
mitigation of classes of attacks in supervisory control systems,” Automat-
ica, vol. 97, pp. 121–133, Nov. 2018.

[16] P. M. Lima, M. V. S. Alves, L. K. Carvalho, and M. V. Moreira, “Security
against network attacks in supervisory control systems,” in Proc. of the
20th IFAC World Congress, vol. 50, Toulouse, France, 2017, pp. 12 333–
12 338.

[17] M. Wakaiki, P. Tabuada, and J. P. Hespanha, “Supervisory control of
discrete-event systems under attacks,” Dyn. Games and Appl., vol. 9, no. 4,
pp. 965–983, Dec. 2019.

[18] L. Lin and R. Su, “Synthesis of covert actuator and sensor attackers,”

Automatica, vol. 130, p. 109714, Aug. 2021.

[19] R. Meira-Góes, H. Marchand, and S. Lafortune, “Synthesis of supervisors
robust against sensor deception attacks,” IEEE Trans. Autom. Control,
DOI: 10.1109/TAC.2021.3051459.

[20] Z. Jakovljevic, V. Lesi, and M. Pajic, “Attacks on distributed sequential
control in manufacturing automation,” IEEE Trans. Ind. Informat., vol. 17,
no. 2, pp. 775–786, Feb. 2021.

[21] J. Yao, X. Yin, and S. Li, “On attack mitigation in supervisory control
systems: a tolerant control approach,” in Proc. IEEE 59th Annu. Conf. on
Decision and Control, Jeju Island, Republic of Korea, 2020, pp. 4504–
4510.

[22] Y. Wang and M. Pajic, “Supervisory control of discrete event systems in
the presence of sensor and actuator attacks,” in Proc. IEEE 58th Annu.
Conf. on Decision and Control, Nice, France, 2019, pp. 5350–5355.
[23] D. You, S. Wang, M. Zhou, and C. Seatzu, “Supervisory control of Petri
nets in the presence of replacement attacks,” IEEE Trans. Autom. Control,
DOI: 10.1109/TAC.2021.3063699.

[24] S. Zheng, S. Shu, and F. Lin, “Modeling and control of discrete event sys-
tems under joint sensor-actuator cyber attacks,” in Proc. 6th International
Conference on Autom., Control and Robotics Engineering, Dalian, China,
2021, pp. 216–220.

[25] Y. Tong, Z. Ma, Z. Li, C. Seatzu, and A. Giua, “Supervisory enforcement
of current-state opacity with incomparable observations,” in Proc. of 13th
Int. Workshop on Discrete Event Systems, Xi’an, China, 2016, pp. 313–
318.

[26] R. Meira-Góes, E. Kang, R. H. Kwong, and S. Lafortune, “Synthesis
of sensor deception attacks at the supervisory layer of Cyber-Physical
Systems,” Automatica, vol. 121, p. 109172, Nov. 2020.

[27] P. M. Lima, L. K. Carvalho, and M. V. Moreira, “Detectable and unde-
tectable network attack security of cyber-physical systems,” in Proc. of
14th Int. Workshop on Discrete Event Systems, Sorrento, Italy, 2018, pp.
179–185.

VOLUME 4, 2016

11

Q. Zhang et al.: Joint State Estimation Under Attack of Discrete Event Systems

[28] R. Su, “Supervisor synthesis to thwart cyber attack with bounded sensor

reading alterations,” Automatica, vol. 94, pp. 35–44, Aug. 2018.

[29] Q. Zhang, Z. Li, C. Seatzu, and A. Giua, “Stealthy attacks for partially-
observed discrete event systems,” in Proc. of the 23th Int. Conf. on
Emerging Technologies and Factory Autom., Turin, Italy, 2018, pp. 1161–
1164.

[30] K. Ding, Y. Li, D. E. Quevedo, S. Dey, and L. Shi, “A multi-channel
transmission schedule for remote state estimation under Dos attacks,”
Automatica, vol. 78, pp. 194–201, Apr. 2017.

[31] L. Peng, L. Shi, X. Cao, and C. Sun, “Optimal attack energy allocation
against remote state estimation,” IEEE Trans. Autom. Control, vol. 63,
no. 7, pp. 2199–2205, Jul. 2018.

[32] P. Cheng, Z. Yang, J. Chen, Y. Qi, and L. Shi, “An event-based stealthy
attack on remote state estimation,” IEEE Trans. Autom. Control, vol. 65,
no. 10, pp. 4348–4355, Oct. 2020.

[33] P. J. G. Ramadge and W. M. Wonham, “The control of discrete event

systems,” Proceedings of the IEEE, vol. 77, no. 1, pp. 81–98, Jan. 1989.

[34] C. G. Cassandras and S. Lafortune, Introduction to discrete event systems.

Springer, 2008.

12

VOLUME 4, 2016

