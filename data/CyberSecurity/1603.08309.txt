6
1
0
2

r
a

M
8
2

]

R
C
.
s
c
[

1
v
9
0
3
8
0
.
3
0
6
1
:
v
i
X
r
a

A Stochastic Model of Active Cyber Defense Dynamics

Shouhuai Xu†, Wenlian Lu‡⋆, and Hualun Li⋆
† Department of Computer Science, University of Texas at San Antonio
San Antonio, Texas 78249, USA
‡ Department of Computer Science, University of Warwick
Coventry CV4 7AL, UK
⋆ School of Mathematical Sciences, Fudan University
Shanghai, P. R. China, 200433
Email: shxu@cs.utsa.edu, wenlian@fudan.edu.cn, 09210180042@fudan.edu.cn

August 5, 2013

Abstract

The concept of active cyber defense has been proposed for years. However, there are no mathematical models
for characterizing the effectiveness of active cyber defense. In this paper, we ﬁll the void by proposing a novel
Markov process model that is native to the interaction between cyber attack and active cyber defense. Unfor-
tunately, the native Markov process model cannot be tackled by the techniques we are aware of. We therefore
simplify, via mean-ﬁeld approximation, the Markov process model as a Dynamic System model that is amenable
to analysis. This allows us to derive a set of valuable analytical results that characterize the effectiveness of four
types of active cyber defense dynamics. Simulations show that the analytical results are inherent to the native
Markov process model, and therefore justify the validity of the Dynamic System model. We also discuss the
side-effect of the mean-ﬁeld approximation and its implications.
Keywords: Active cyber defense, reactive cyber defense, cyber attack-defense dynamics, cyber security dynamics

1 Introduction

The concept of active cyber defense (e.g., using the so-called “white” or “good” worms to identify and ﬁght/kill the
malicious ones) has been proposed for years. However, the exploration has primarily focused on legal and policy
issues [1, 2, 3, 4, 5, 6, 7, 8]. On the other hand, active cyber defense has already happened in some sense (e.g.,
the Welchia worm attempted to “kick out” the Blaster worm from the infected computers [4, 9]), and full-ﬂedged
active cyber defense is seemingly inevitable in the near future [6, 10, 11]. It is therefore more imperative than ever to
systematically characterize the effectiveness of active cyber defense. In this paper, we initiate the theoretical study
on this perspective of cyber security, with emphasis on addressing the following basic question: How effective is
active cyber defense? Such characterization studies not only will deepen our understanding of active cyber defense,
but also will help real-life decision-making (e.g., when to launch active cyber defense?) and even policy-making
(e.g., whether or not to launch active cyber defense?).

1.1 Our Contributions

We formulate, to the best of our knowledge, the ﬁrst mathematical model for characterizing the effectiveness of
active cyber defense. The interaction between cyber attack and active cyber defense can be naturally modeled as a

1

 
 
 
 
 
 
Markov process (Section 2). Unfortunately, we do not know how to tackle the native Markov process analytically
because all the techniques we are aware of do not appear to be applicable (see Section 1.2 for discussions). We
therefore simplify, via the mean-ﬁeld approximation, the native Markov process model as a Dynamic System model
that is amenable to analysis. In the Dynamic System model, we obtain a set of analytical results (Sections 4-6). We
then use simulations to validate the accuracy of the Dynamic System model (Section 8). Simulations show that the
analytical results derived from the Dynamic System model are inherent to the native Markov process model, and
that the accuracy of the Dynamic System model, in terms of dynamics accuracy and threshold accuracy (which will
be speciﬁed in Section 8), increases with the average node degree. Moreover, the analytical results lead to various
insights, with some highlighted (informally) as follows:

•

•

•

If neither the defender nor the attacker is superior to, or more advanced than, its opponent in terms of cyber
combat power (Types I-II dynamics with a certain threshold), the effectiveness of active cyber defense will
depend on (in some quantitative fashion we derive): (i) the attack-defense network structure, (ii) the initial
security state of the attack-defense network, (iii) the attacker’s and defender’s combat-power, and (iv) the
attacker/defender strategy. We also characterize the beneﬁt to strategic attacker/defender that initially “oc-
cupies” the large-degree nodes. Speciﬁcally, we show: (i) when the attack-defense network structures are
Erd¨os-R´enyi (ER) random graphs, a strategic defender/attacker does not gain signiﬁcant beneﬁt; (ii) when the
attack-defense network structures are power-law graphs, a strategic defender/attacker gains signiﬁcant bene-
ﬁt.1 Moreover, we obtain the following quantitative result: The beneﬁt to strategic defender is maximized for
the sub-class of power-law graphs with exponent γ = 2. These are described in Sections 4-5.

If the defender is superior to (or more advanced than) the attacker in terms of cyber combat power (Type III
dynamics), the defender can always use active cyber defense to automatically “clean up” (i.e., cure) the entire
network, regardless of the attack-defense network structure and no matter whether the attacker is strategic
or not. This suggests that cyber superiority could serve as an effective deterrence, and can be seen as a
consequence due to the lack of a certain threshold in the combat power function. The explorations of Type III
dynamics and its dual (i.e., Type IV dynamics) are described in Section 6.

As discussed in Section 7, active cyber defense can eliminate the asymmetry that is an inherent weakness of
reactive cyber defense, where the defender runs “anti-virus software”-like tools on each computer to detect
and cure infections (which are caused by that the attacks/malwares penetrated the perimeter defense such as
Firewalls). The cause of the asymmetry is that when the defense is reactive, the attack effect is automatically
ampliﬁed by the network (a kind of “network effect”).

We stress that the focus of the present paper is to characterize how effective active cyber defense is. This
means that we should not make any signiﬁcant restrictions on the parameter regimes and network structures. One
important research problem, which is orthogonal to our focus and is not addressed in the present paper, is how to
extract the model parameters and the attack-defense network structure for a given cyber system. In principle, the
model parameters can be obtained by analyzing the strength and weakness of the attack and defense tools (“what
if” analysis can be used in the absence of sufﬁcient data), and/or by conducting experiments (in lieu of physical
experiments) to observe the outcome of experimental cyber combats. The network structure can be derived from the
cyber system conﬁgurations and security policies, which may restrict which computers can directly communicate
with which other computers. The characterization results presented in this paper accommodate a large class of
parameter and structure scenarios.

1These results are reminiscent of, and in parallel to, the connectivity-based robustness characterizations of ER and power-law graphs [12],
which is however a different perspective from ours because the attacker in our model aims to compromise as many nodes as possible but does
not delete any (of the compromised) nodes.

2

1.2 Related Work

We classify the related prior work based on two perspectives: one is centered on the problem that is under investiga-
tion, and the other is centered on the technique that is exploited to tackle the problem under investigation.

From the perspective of the problem under investigation, we note that all existing studies in both the mathematics
literature and the physics literature are geared toward, in the terms of the present paper, characterizing the outcome of
reactive defense under various parameter conditions (see for example [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23] and
the references there in). These studies substantially generalize the pioneering work of Kephart and White [24, 25],
which was based on homogeneous epidemic models in biological systems [26, 27, 28]. For example, even for the
very recent work [21], which studies the attack-defense dynamics between one defender and multiple attackers
that ﬁght against each other as well, the defense is still reactive. In contrast, the present paper introduces a new
research problem, namely characterizing the outcome of active defense under various model parameter conditions
(include the graph/network structure). To the best of our knowledge, we are the ﬁrst to study the active cyber
defense problem mathematically, despite that the technical practice of active cyber defense has been discussed for
years [1, 2, 3, 4, 5, 6, 7, 8]. This is so even though our active cyber defense model is reminiscent of the voter model
(see, for example, [29, 30, 31, 32, 33]), where each node can adopt the state of one of its random neighbors at each
time step. However, the voter model corresponds to the special case of our active cyber defense model with linear
combat-power functions (the concept of combat-power functions will be introduced later). In contrast, we study
general nonlinear combat-power functions, which explain why the techniques for analyzing the voter model cannot
tackle our active cyber defense model (see Section 2.2 for further discussions). Finally, it is worth mentioning that
active cyber defense is different from automatic patching [34] because the attacker may have already compromised
many computers, and that our active cyber defense model is different from the Moran process [35, 36], which
considers the mutation dynamics of homogeneous nodes.

From the perspective of the techniques that are exploited to tackle the epidemic problem with network structures
[13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], there are mainly two approaches. The ﬁrst approach is to use the
mean-ﬁeld approximation (e.g., [37]). Our Dynamic System model is also based on mean-ﬁeld approximation of a
native stochastic process model. Mean-ﬁeld approximation is a plausible ﬁrst step in studying problems such as the
stochastic active cyber defense process we introduce in the present paper. Nevertheless, we empirically characterize
the accuracy of the mean-ﬁeld approximations.

The second approach is to directly tackle the native processes that take place on network structures. This ap-
proach is more rigorous than the mean-ﬁeld approximation approach, but is often pursued after establishing some
understandings based on the mean-ﬁeld approach. This approach is valuable not only because it can derive rigorous
results, but also because it can (in)validate some results obtained via the mean-ﬁeld models. For example, Ball et al.
[19, 20] study the threshold behavior and the ﬁnal outcome of the SIR (susceptible-infectious-removed) epidemic
process on random networks with clusters (communities). They consider the SIR epidemic process in two steps: the
SIR epidemic spreading within the clusters (local spreading) and then the SIR epidemic spreading cross the clusters.
For their studies, it is reasonable to use the Branching process approximation because they only need to consider the
case of small initial infections (i.e., early stage of epidemic spreading) and because the notion of offspring genera-
tion is well-deﬁned in SIR models. They derive a rigorous central limit theorem under certain conditions. In another
line of investigations, Berger et al. [15] investigate the SIS (susceptible-infectious-susceptible) Contact process [38]
on random graphs that are generated via preferential attachment [39]. Their rigorous study conﬁrms the threshold
result of Pastor-Satorras and Vespignani [37] obtained via the mean-ﬁeld approximation, namely that the epidemic
threshold of scale-free networks is 0. Chatterjee and Durrett [18] further study both SIR and SIS models on random
graphs with the power-law degree distributions. Improving upon some results in [18], Mountford et al. [22] show
that the epidemic extinction time for the Contact process on power-law random graphs grows exponentially in the

3

number of nodes, and Mountford et al. [23] obtain bounds for the density of infected nodes.

The rest of the paper is organized as follows. In Section 2, we present the native Markov process model and
then show how to simplify it as a Dynamic System model that is amenable to analysis. In Section 3, we brieﬂy
review some background knowledge. In Sections 4-6, we characterize four types of active cyber defense dynamics.
In Section 7, we explain why active cyber defense can eliminate an inherent weakness of reactive cyber defense.
In Section 8, we use simulations to show that the analytical results derived from the Dynamic System model are
inherent to the native Markov process model. In Section 9, we conclude the paper with future research directions.
Lengthy proofs are deferred to the Appendix.

2 Active Cyber Defense Model

A cyber system consists of networked computers/nodes of ﬁnite populations. A computer has two states: compro-
mised or secure (i.e., vulnerable but not compromised). We may say that a compromised computer is “occupied”
by the adversary/attacker, and a secure computer is “occupied” by the defender. The adversary can compromise a
computer by exploiting its (e.g., zero-day or unpatched) vulnerabilities. Attacks are malware-like, meaning that the
compromised computers can attack the vulnerable computers in an epidemic-spreading fashion. With active cyber
defense, the defender can use “good worm”-like mechanisms to spread in networks (as the malicious worms do) to
identify and “clean up” the compromised computers.

time
(cid:857)

Initial security state of an 
example cyber system

Three example equilibrium security 
states of the cyber system

Figure 1: Illustration of cyber security state evolution under active cyber defense, where the same initial state may
evolve, under different conditions, toward one of the three example equilibrium states — all nodes are secure (blue
dots); all nodes are compromised (red dots); some nodes are secure. The core research issue is to characterize how
the initial state, network topology, parameters and attacker/defender strategies would govern the evolution.

The interaction between cyber attack and active cyber defense formulates an attack-defense interaction structure,
a graph topology that represents how the compromised nodes attack the secure nodes and how the secure nodes use
active cyber defense to clean up the compromised nodes. We say a defender (attacker) is strategic if it initially
occupies the large-degree nodes in the graph with higher probabilities. The attack-defense interaction leads to the
evolution of cyber security state of the entire cyber system. We illustrate the state evolution in Figure 1, where a

4

blue dot means “secure” and a red dot means “compromised.” As shown in Figure 1, the state evolution can exhibit
rich phenomena (e.g., the existence of multiple kinds of equilibria). At a high level, the research objective is to
characterize how the evolution is governed by the initial state, graph topology, parameters and attacker/defender
strategies. The characterization will allow us to answer some basic questions such as: under what conditions the
cyber security state evolves toward the all-blue equilibrium?

2.1 The Native Markov Process Model

Formally, cyber attack-defense takes place over a ﬁnite network/graph structure G = (V, E), where V =
1, 2, . . . , n
{
E (i.e., there are no self-loops in the setting
is the set of nodes/computers and E is the set of edges/arcs with (u, u) /
∈
V is in one of two states: blue, meaning that it is secure (i.e.,
of the problem). At any point in time, a node v
vulnerable but not compromised by the attacker); red, meaning that it is compromised by the attacker. Node v’s
state changes because of some u, where (u, v)
E because a secure node will not clean
up itself and a compromised node will not attack itself. Since our study applies to both undirected and directed
graphs, we focus on undirected graphs while mentioning the difference when the need arises. We do not make any
signiﬁcant restrictions on G because in real-life G can have any topology. This has become a standard practice in
characterization studies of cyber security (see, for example, [13, 14, 16, 17, 21]).

E. Note that (u, u) /
∈

∈

∈

}

The state of node v

∈

V at time t is a random variable ξv(t)

ξv(t) =

1 v

(

0 v

∈

∈

Correspondingly, we deﬁne

∈ {

:
0, 1
}
V is blue at time t
V is red at time t.

Bv(t) = P(ξv(t) = 1) and Rv(t) = P(ξv(t) = 0).

Denote by ˜θv,BR(t) the rate at which v’s state changes from blue to red at time t, which is a random variable
because it depends on the states of v’s neighbors. Similarly, denote by ˜θv,RB(t) the random rate at which v’s state
changes from red to blue at time t. The state evolution of v
V is naturally described as a Markov process (dubbed
“Markov process model” or “Markov model” for reference purpose) with the following transition probabilities:

∈

and

P(ξv(t + ∆t) = 1

ξv(t)) =

(cid:12)
(cid:12)

P(ξv(t + ∆t) = 0

ξv(t)) =

(cid:12)
(cid:12)

∆t

·

1
(

−

∆t

·

1
(

−

˜θv,RB(t) + o(∆t)
∆t

˜θv,BR(t) + o(∆t)

·

˜θv,BR(t) + o(∆t)
∆t

˜θv,RB(t) + o(∆t)

·

ξv(t) = 0

ξv(t) = 1

ξv(t) = 1

ξv(t) = 0

(1)

(2)

→

0. Denote by Nv =

V . Since the random rates
as ∆t
˜θv,RB(t) and ˜θv,BR(t) are naturally determined by the random states of node v’s neighbors, we use deterministic but
) : R
possibly nonlinear functions fRB(
[0, 1] to deﬁne respectively the random rates
·
˜θv,RB(t) and ˜θv,BR(t), as follows:

) : R
[0, 1] and fBR(
·

the set of neighbors of node v

V : (u, v)

u
{

→

→

E

∈

∈

∈

}

˜θv,RB(t) = fRB

1
deg(v)

ξu(t)

!

Xu∈Nv

and ˜θv,BR(t) = fBR

1
deg(v)

(1

−

ξu(t))

!

.

Xu∈Nv

5

 
 
) the combat-power functions because they abstract the attacker’s and defender’s combat
) and fBR(
We call fRB(
·
·
capabilities.

At this point, we do not know how to tackle the above native Markov process model. One may note that the
above combat-power functions are reminiscent of the so-called Voter model [29], where a node changes its opinion
(or state) to the opinion of one random neighbor according to a ﬁxed-rate Poisson process. This allows the model to
be transformed into a dual process that works backward in time and becomes a random walk [29], which makes it
tractable. In contrast, in our model a node changes its state according to a rate that is not ﬁxed but instead nonlinearly
dependent up on the states of its neighbors. The nonlinearity prevents us from transforming our native Markov
process model into a Random Walk model, meaning that the technique used in [29] cannot solve the problem we
encounter. This nonlinearity-caused difﬁculty suggests us to simplify/approximate the native Markov process model
as a tractable Dynamic System model.

2.2 Simplifying the Markov Process Model as Dynamic System Model

Now we show how to simplify the native Markov process model into a tractable Dynamic System model via the
mean-ﬁeld approximation. From Eq. (1), we have, for v

V ,

∈

Bv(t + ∆t) = ∆t

˜θv,RB(t)

·

·

Rv(t) + (1

∆t

·

−

˜θv,BR(t))Bv(t) + o(∆t),

which can be rewritten as:

Bv(t + ∆t)
∆t

−

Bv(t)

= ˜θv,RB(t)

Similarly, from Eq. (2) we can derive for all v

V :

∈

Rv(t + ∆t)
∆t

−

Rv(t)

= ˜θv,BR(t)

By letting ∆t

→

0, we have for all v

V :

∈

Rv(t)

−

˜θv,BR(t)

Bv(t)

−

˜θv,RB(t)

·

·

·

·

Bv(t) + o(∆t).

Rv(t) + o(∆t).

(

Note that

d

dt Bv(t) = ˜θv,RB(t)
dt Rv(t) = ˜θv,BR(t)

d

Rv(t)

Bv(t)

·

·

−

−

˜θv,BR(t)
˜θv,RB(t)

Bv(t)

Rv(t).

·

·

(3)

E

˜θv,RB(t)
(cid:16)
(cid:17)

= E

fRB

1
deg(v)

ξu(t)

!!

.

Xu∈Nv

By the idea of mean-ﬁeld approximation, we can move the expectation inside the combat-power function, and replace
the mean of random rate ˜θv,RB(t), denoted by θv,RB(t), with the following term:

fRB

1
deg(v)

Xu∈Nv

E [ξu(t)]

= fRB

!

1
deg(v)

Bu(t)

!

.

Xu∈Nv

We can treat ˜θv,BR(t) analogously. As a result, we obtain the mean state-transition probability θv,RB(t) and θv,BR(t)
as:

θv,RB(t) = fRB

1
deg(v)

Bu(t)

!

Xu∈Nv

and θv,BR(t) = fBR

1
deg(v)

Ru(t)

!

.

Xu∈Nv

6

 
 
 
 
 
 
Therefore, Eq. (3) becomes the following Dynamic System model for all v

V :

∈

d
dt Bv(t) = θv,RB(t)

Rv(t)

·

−

θv,BR(t)

Bv(t)

·




d
dt Rv(t) = θv,BR(t)

Bv(t)

θv,RB(t)

Rv(t).

·
Note that the Dynamic System model for all v
V encodes the graph topology via parameters θv,BR(t) and
θv,RB(t), which encode the information about node v’s neighborhood (including the states of node v’s neighbors).
The corresponding state-transition diagram for any node v

V is depicted in Figure 2.



−

∈

·

(4)

∈

B

v, BR(t)

v, RB(t)

R

Figure 2: State-transition diagram of a single node v

V (B: blue; R: red)

∈

2.3 Instantiating the Dynamic System Model via Speciﬁc Combat-Power Functions

) abstracts the defender’s power against the attacker. It should satisfy the
Recall that combat-power function fRB(
·
following properties: (i) fRB(0) = 0; (ii) fRB(1) = 1; (iii) fRB(
) increases monotonically. This is intuitive because
·
the more blue nodes surrounding a red node, the greater the chance the red node will become blue (because of the
active defense launched by the blue nodes). In this paper, we consider four types of fRB(
) with examples depicted
·
) have an inherent threshold while the others don’t.
in Figure 3, where the ﬁrst two types of fRB(
·

•

•

•

•

Type I: For a given threshold σ

(0, 1), we deﬁne

∈

θv,RB(t) = fRB

1
deg(v)

Bu(t)

!

Xu∈Nv

1

0

1/2

u∈Nv Bu(t) > σ
u∈Nv Bu(t) < σ

1
deg(v)
1
deg(v)
otherwise.

P

P

(5)

= 



Intuitively, the defender is more powerful than the attacker when σ < 1/2, less powerful than the attacker
when σ > 1/2, and equally powerful as the attacker when σ = 1/2.

(0, 1), we deﬁne: fRB(x) is convex and fRB(x) < x for x

Type II: For a given threshold τ
[0, τ );
fRB(x) is concave and fRB(x) > x for x
(τ, 1]; fRB(x) = x for x = τ , fRB(0) = 0, and fRB(1) = 1.
Moreover, fRB(
) is increasing and continuous in intervals [0, τ ) and (τ, 1]. This type of functions is known as
·
“sigmoid” functions. Intuitively, the defender is more powerful than the attacker when τ < 1/2, less powerful
than the attacker when τ > 1/2, and equally powerful as the attacker when τ = 1/2.

∈

∈

∈

Type III: fRB(
(0, 1) and fRB(0) = 0,
) is concave, continuous and increasing in [0, 1], fRB(x) > x for s
·
fRB(1) = 1. Intuitively, the defender is more advanced than the attacker (i.e., the defender has cyber combat
superiority).

∈

(0, 1) and fRB(0) = 0,
Type IV: fRB(
) is convex, continuous and increasing in [0, 1], fRB(x) < x for x
·
fRB(1) = 1. Intuitively, the defender is less advanced than the attacker. Note that Type IV fRB(
) is dual to
·
).
Type III fRB(
·

∈

7

q
q
 
 1

)
x
(
B
R

f

 0.5

 0

 0

 1

)
x
(
B
R

f

 0.5

 0.5

 1

(a) Type I (σ = 1/2)

 1

)
x
(
B
R

f

 0.5

 0

 0

 1

)
x
(
B
R

f

 0.5

 0.2

 0.4

 0.6

 0.8

 1

(b) Type II: τ = 1/2

 0

 0

 0.2

 0.4

 0.6

 0.8

 1

 0

 0

 0.2

 0.4

 0.6

 0.8

 1

(c) Type III: fRB (x) = x1/2

(d) Type IV: fRB(x) = x2

) examples (Type II: fRB(x) = 2x2 for x
Figure 3: fRB(
·

∈

[0, 0.5], fRB(x) =

2x2 + 4x

−

1 for x

−

∈

[0.5, 1])

Based on the above 4 types of combat-power functions, we focus on the 4 types of combat-function combinations

that satisfy

By combining Eqs. (4) and (6), we obtain the following master equation for a single node v

V :

∈

θv,BR(t) = 1

θv,RB(t).

−

d
dt

Bv(t) = θv,RB(t)(1

= θv,RB(t)

−

θv,BR(t)Bv(t)

Bv(t))

−
Bv(t).

−

(6)

(7)

The research task is to characterize Types I-IV dynamics, namely the dynamics of master equation (7) with Types
I-IV combat-power functions, respectively. For example, for Type I combat-power function, we have

θv,BR(t) = fBR

1
deg(v)

1

[1

−

Bu(t)]

!

= 
0


1/2

Xu∈Nv

u∈Nv [1
u∈Nv [1

1
deg(v)
1
deg(v)
otherwise.

P

P

Bu(t)] > 1

Bu(t)] < 1

σ

σ

−

−

−

−

(8)


We want to characterize, among other things, the roles of the thresholds speciﬁed in Types I-II dynamics, and the
consequences due to the lack of such thresholds in Types III-IV dynamics.

Summary of notations

Let R be the set of real numbers, P(
), Var(
), E(
) be the probability, expectation, and variance functions, respec-
·
·
·
tively. Other major notations are summarized in the following table.

8

 
G = (V, E)

graph/network that abstracts a cyber system from a cyber security perspective, where

= n

V
|

|

E
}
Nv|
|

Nv Nv =

V : (u, v)

u
{

deg(v)
γ
σ, τ
ξv(t)
Bv(t)
Rv(t)

∈

∈
v’s (in-)degree, deg(v) =
power-law exponent, P(deg(v) = k)
k−γ
indicator of defender’s relative combat-power in Types I and II dynamics, respectively
state of node v at time t: blue (i.e., 1 or “secure”) and red (i.e., 0 or “compromised”)
probability v
probability v

V is blue at time t
V is red at time t

∝

α α = 1
n
S random set of blue nodes at time t = 0

v∈V Bv(0), namely the average fraction of blue nodes at time t = 0

∈
∈

P

θv,BR(t)
θv,RB(t)

probability that node v’s state changes from blue to red at time t
probability that node v’s state changes from red to blue at time t

3 Preliminaries

Arbitrary Networks

By “arbitrary network” we mean a given network G = (V, E) that may or may not have a special structure/topology
of interest. Most analytical results in this paper are derived from dynamic systems that take place on arbitrary
networks. In general, such results are often independent of the statistical properties of the networks (e.g., the degree
distribution).

In order to show the existence of the third kind of equilibrium illustrated in Figure 1 (i.e., some nodes in blue
color and the other nodes in red color), we also consider a given network that has a cluster (or community) structure.
A network G = (V, E) has a clustered structure of V1, V2, . . . , NK if
= j, and the
Vj =
= j. More speciﬁcally, the
nodes belonging to Vi are better connected than the nodes crossing Vi and Vj for any i
T
K, which is deﬁned as
special phenomenon is related to the minimum node expansion in cluster Vk for 1
k

i Vi = V , Vi

for all i

S

∅

≤

≤

βk = inf
v∈Vk

Nv
Vk|
|
deg(v)
T

, where Nv =

u : (u, v)
{

E

.
}

∈

(9)

Generalized Random Graphs

In order to characterize the beneﬁt to the strategic defender who initially occupies the large-degree nodes with greater
probabilities (a scenario that is often difﬁcult to analyze), we propose to use the generalized random graph model
[40]. This means that the result is applicable to a class of random networks (which however include the Erd¨os-R´enyi
(ER) random graphs and power-law random graphs [40]), rather than arbitrary networks; this slight restriction is
compensated with some valuable analytical results. (Characterizing the beneﬁt to strategic defender in arbitrary
networks is left as an open problem.)

In the generalized random graph model, we are given an expected (in-)degree sequence (d1(n), . . . , dn(n)) that
deﬁnes a family of graphs. Let dmin(n) = min
. A
}
random graph instance G(n) = (V (n), E(n)) can be obtained by linking each pair of nodes (u, v) with probability

and dmax(n) = max

dj(n) : 1
{

dj(n) : 1
{

≤

≤

≤

≤

n

n

}

j

j

pvu(n) =

du(n)dv(n)
n
k=1 dk(n)

independent of the others [40], where 0

pvu(n)

≤

≤

P
1 under the assumption (dmax(n))2

(10)

n
k=1 dk(n).

≤

P

9

6
6
For simplifying the analysis, we allow self-links while noting that our result can be adapted to accommodate
that there are no self-links. In order to attain deeper insights, we will consider two instantiations of the generalized
random graph model, namely the classic Erd¨os-R´enyi (ER) random graphs with d1(n) = . . . = dn(n) or edge
probability p = d1(n)/n, and the ubiquitous power-law random graphs with #{v∈V :deg(v)=k}
k−γ for some
γ > 0. Note that γ does not need to be greater than 1 because dmax(n) is ﬁnite.

#V

∝

Note that complete graphs are a special case of arbitrary networks and of generalized random graphs. Since the
theorems we present below hold either for arbitrary networks or for generalized random graphs, they automatically
apply to complete graphs.

4 Characterizing Type I Active Cyber Defense Dynamics

In this section, we ﬁrst characterize Type I active cyber defense dynamics with non-strategic defender in arbitrary
networks, where the initial occupation probability Bv(0) is identical to all nodes. We then investigate the more
deg(v) in the generalized random graph model,
difﬁcult case of strategic defender with degree-dependent Bv(0)
where the defender initially occupies the large-degree nodes with higher probabilities (i.e., the large-degree nodes
are appropriately better protected).

∝

4.1 Characterizing Type I Dynamics with Non-Strategic Defender

Type I dynamics with non-strategic defender is characterized through Theorems 1-3. The characterizations include
the conditions under which the defender can or cannot use active cyber defense to automatically clean up the entire
network, and a method for deciding whether an equilibrium is stable. Theorem 1 requires the following Lemma 1,
whose proof is omitted because it is similar to (and simpler than) the proof of Lemma 2 that is given in Appendix C.

Lemma 1 Consider Type I dynamics with threshold σ and system (7) in arbitrary network G = (V, E).

(i) If

1
deg(v)

u∈Nv Bu(0) > σ holds for all v

∈
and minv∈V Bv(t) increases monotonically.

P

(ii) If

1
deg(v)

u∈Nv Bu(0) < σ holds for all v

∈
and maxv∈V Bv(t) decreases monotonically.

P

V , then

1
deg(v)

u∈Nv Bu(t) > σ holds for all v

V , then

1
deg(v)

P

P

u∈Nv Bu(t) < σ holds for all v

V and t

0,

≥

V and t

0,

≥

∈

∈

Theorem 1 (a sufﬁcient condition under which the defender or the attacker will occupy the entire network) Consider
V ,
Type I dynamics with threshold σ and arbitrary network G = (V, E). If
limt→∞ Bv(t) = 1; if

u∈Nv Bu(0) > σ for all v

u∈Nv Bu(0) < σ for all v

V , limt→∞ Bv(t) = 0.
P

1
deg(v)

1
deg(v)

∈

∈

P

Proof We only prove the ﬁrst part because the second part can be proved analogously. According to Lemma 1, we
know 1
0 and
v

V . This and Eq. (5) imply that θv,RB(t) = 1 for all t

u∈Nv Bu(t) > σ for all t

V . Thus, system (7) becomes

0 and v

deg(v)

≥

≥

∈

∈

P

dBv(t)
dt

= θv,RB(t)

Bv(t) = 1

Bv(t).

−

−

This leads to Bv(t) = exp(

−

t)Bv(0) + 1

exp(

−

−

t) and thus limt→∞ Bv(t) = 1.

Theorem 1 holds for arbitrary networks, including the special case of complete graphs. Theorem 1 leads to the

following insight (informally stated):

10

Insight 1 There is a quantitative relationship between the initial network security state and the combat-power func-
tion as indicated by the threshold σ in Type I combat-power function. Speciﬁcally, when neither the defender nor the
attacker is superior to its opponent, active cyber defense can automatically clean up a compromised network only
when the defender has occupied more than a threshold σ portions of the network (or nodes). This means that the de-
fender may need to manually clean up some compromised nodes before using active cyber defense to automatically
clean up the entire network.

Theorem 2 (a sufﬁcient condition under which neither the defender nor the attacker will occupy the entire network)
Consider Type I dynamics with threshold σ and arbitrary clustered network G = (V, E). Let Bv(0) = αk for every
Vk and βk be the minimum node expansion as deﬁned in Eq. (9). If αkβk > σ, all nodes in Vk will become
v
blue; if (1

σ, all nodes in Vk will become red.

αk)βk > 1

∈

−

−

Proof

If αkβk > σ for all nodes in Vk, then

1
deg(v)

Xu∈Nv

Bu(0)

1
deg(v)

≥

αk · |

Nv ∩

Vk| ≥

αkβk > σ.

As in Theorem 1, we have limt→∞ Bv(t) = 1.

If (1

−

αk)βk > 1

−

σ for all nodes in Vk, then

1
deg(v)

1

−

Bu(0)

≥

Xu∈Nv

deg(v)
deg(v) −
Vk|
Nv ∩
deg(v)

Nv ∩
|

Vk| ·
deg(v)

αk

Vk|
Nv \
|
deg(v)

−

(1

αk)

(1

−

≥

−

αk)βk > 1

σ.

−

= |

As in Theorem 1, we have limt→∞ Bv(t) = 0.

Theorem 2, which applies to arbitrary networks with the cluster structure, leads to:

Insight 2 Suppose (i) neither the defender nor the attacker is superior to its opponent and (ii) the initial network
security state does not satisfy the conditions of Theorem 1. Then, the network structure plays an important role.
Speciﬁcally, in clustered networks, active cyber defense may only be able to automatically clean up some clusters,
but not the entire network.

Theorem 1 identiﬁes two stable equilibria B∗ = [1, . . . , 1] and B∗ = [0, . . . , 0], while Theorem 2 gives a
condition under which another kind of stable equilibria exist (i.e., different clusters in different color). Because
the stability of equilibria gives a high-level description of Type I dynamics (e.g., under what condition the global
network security state evolves toward a particular equilibrium), we need some general method/algorithm to evaluate
the stability of equilibria. This is addressed by the following Theorem 3, whose proof is deferred to Appendix A.
Before presenting the theorem, we recall that an equilibrium B∗ is stable if there exists a neighborhood of B∗ such
that every trajectory B(t) initially located in the neighborhood converges to B∗. We say B∗ is a stable equilibrium
with exponential convergence if for each B(t) in the neighborhood, there exist positive constants ̺ > 0 and M > 0
such that

M e−̺t for all t

B∗

0.

B(t)
k

−

k ≤

≥

Theorem 3 (method/algorithm for determining stability of equilibria and their emergence rates) Consider Type I
v ]v∈V be an equilibrium and ¯B∗ =
dynamics with threshold σ and arbitrary network G = (V, E). Let B∗ = [B∗
[1

B∗

v ]v∈V .

−

11

(i) If the following holds for all v

V

∈



both B∗ and ¯B∗ are asymptotically stable equilibria with exponential convergence.


P

P

0

1

B∗

v =

1
deg(v)
1
deg(v)

u∈Nv B∗
u∈Nv B∗

u > σ
u < σ,

(11)

(ii) If B∗

v = σ for some v

∈

V , B∗ and ¯B∗ are unstable.

Recall that Theorem 1 says that the system has two equilibria: [1, . . . , 1] and [0, . . . , 0]. Since both equilibria
satisfy condition (11), Theorem 3 says that the two equilibria are asymptotically stable with exponential convergence.

4.2 Characterizing Type I Dynamics with Strategic Defender

∝

Now we investigate Type I dynamics with strategic defender, where the initial probability that node v is secure is
proportional to its degree, namely Bv(0)
deg(v). We analyze it in the afore-reviewed generalized random graph
model [40]. This means that our analytical result (Theorem 4 below) is not necessarily true for arbitrary networks.
We compensate this slight restriction with valuable analytical results, including the quantiﬁcation of the beneﬁts
when the attack-defense network structures are ER graphs and power-law graphs. The basic idea behind the proof
of Theorem 4 is to show that under the given conditions, the event
u∈Nv Bu(0) > σ occurs almost surely.
We accomplish this by using an asymptotical normal distribution, and by showing that the Lyapunov condition in
the Central Limit Theorem and the Kolmogorov condition in the Strong Law of Large Numbers [41] are satisﬁed.
The proof details are given in Appendix B.

1
deg(v)

P

Theorem 4 (outcome of active cyber defense with strategic defender) Let G(n) = (V (n), E(n)) be an instance of
n-node random graph generated according to a given expected (in-)degree sequence (d1(n), . . . , dn(n)). Given the
degree-dependent probability Bv(0), we determine v’s state according to Bv(0) independent of anything else. Let
S =

be the set of blue nodes in G(n) at time t = 0, and

V (n)

v : v
{

∈

Bv(0) = 1
}

∧

where deg(v) is the (in-)degree of v

V (n) in G(n). Let

P

∈

φ(n) =

v∈S deg(v)
u∈V (n) deg(u)
P

,

s2
n,v =

Bu(0)2pvu(n)(1

qn,v =

w2

n,v =

Xu∈V (n)

Xu∈V (n)

Xu∈V (n)

Bu(0)3pvu(n)(1

pvu(n)(1

pvu(n)),

−

−

−

pvu(n)),

pvu(n))

(1

−

(cid:2)

pvu(n))2 + pvu(n)2

,

(cid:3)

(12)

(13)

(14)

(15)

gn,v =

pvu(n)(1

pvu(n))

(1

pvu(n))2 + pvu(n)2

.

−

−

Xu∈V (n)
Assume (i). limn→∞ supv∈V (n) qn,v/s3
(iii). limn→∞
(v). limn→∞(
almost surely, then limn→∞ limt→∞ Bv(t) = 1 holds for all v
P
limn→∞ P (limt→∞ Bv(t) = 1) = 1; if limn→∞φ(n) < σ holds almost surely, then limn→∞ limt→∞ Bv(t) = 0
holds for all v

(cid:3)
(cid:2)
n,v = 0; (ii). limn→∞ supv∈V (n) gn,v/w3
n,v = 0;
n,v)3/2 = 0;
v∈v(n) w2
1
d2
v
V (n) almost surely, namely

ln(n)/dmin(n) = 0; (iv). limn→∞(
v∈V (n) qn,v)/(

v∈V (n) gn,v)/(
n,v)3/2 = 0; (vi). limn→∞
P

V (n) almost surely, namely limn→∞ P (limt→∞ Rv(t) = 1) = 1.

= 0. If limn→∞φ(n) > σ holds

v∈v(n) s2

P
P

v∈V (n)

P

p

∈

∈

12

Xv∈V (n)
d2
v(n)
h

Note that Theorem 4 holds for generalized random graphs (rather than arbitrary networks), which however are
√n because

not necessarily dense. To see this, we observe that a sufﬁcient condition for assumption (v) is dmin ≫
1
d2
v(n) ≤

n
d2
min(n)

.

A necessary condition for assumption (v) is

n, where

d2
v(n)
i
h

= 1
n

v∈V (n) d2

v(n), because

i ≫

1
d2
v(n) ≥

1
n

n
v∈V (n) d2

v(n)

=

P
.

n
d2
v(n)
h
i

Xv∈V (n)

These conditions do not imply that the graphs are dense. For example, the two conditions are satisﬁed by dv(n) =
O(√n log(n)) for all v

V (n), which however implies that density of the graph converges to zero as n

.

P

Theorem 4 corresponds to the case of strategic defender with Bv(0)

strategic attacker with Rv(0)
separately, and then compare them to draw deeper/quantitative insights with respect to ER and power-law graphs.

deg(v), and can be adapted to the case of
∝
deg(v). In what follows we discuss the implications of Theorem 4 in these two cases

∝

→ ∞

∈

Characterizing the qualitative beneﬁt to strategic defender with Bv(0)

deg(v)

∝

Since Bv(0)
of initial blue nodes is

∝

deg(v), we have Bv(0) = C1

deg(v)

Pu∈V (n) deg(u) for some constant C1 > 0. Then, the expected number

Deﬁne

Bv(0) = C1

Xv∈V (n)

Xv∈V (n)

P

deg(v)
u∈V (n) deg(u)

= C1.

αthreshold =

σ
n

[

P

u∈V (n) deg(u)]2
v∈V (n) deg(v)2 ,

(16)

where deg(v) is the (in-)degree of node v
deﬁne random variable χv(S):

∈

V (n). With respect to random set S of blue nodes at time t = 0, we

P

Since

χv(S) =

1 v

∈
0 v /
∈

(

S

S.

φ(n) =

u∈S deg(u)
v∈V (n) deg(v)
P

P

u∈V (n) deg(u)χu(S)
v∈V (n) deg(v)
u∈V (n) deg(u)Bv(0)
P
v∈V (n) deg(v)

=

P

≈ P

> σ,

(17)

[

V (n). Since

Theorem 4 implies the following: if |S|

P
n < αthreshold,
Pu∈V (n) deg(u)]2
then limt→∞ Bv(t) = 0 for v
σ. This means that
Pv∈V (n) deg(v)2 ≤
a strategic defender can use active cyber defense to automatically clean up the entire network even if the defender
initially occupies less than σ, but more than αthreshold (

n > αthreshold, then limt→∞ Bv(t) = 1 for v

≤
Insight 3 If the large-degree nodes are appropriately better protected by the strategic defender, the strategic de-
fender can use active cyber defense to automatically clean up the network even if it only occupies αthreshold (
σ)
portions of the network.

n, we have αthreshold ≤

σ), portions of the network. This leads to:

V (n); if |S|

≤

∈

∈

13

Characterizing the qualitative beneﬁt to strategic attacker with Rv(0)

deg(v)

∝

In this case, we have Rv(0) = C2

deg(v)

σ. The red-node initial occupation threshold is 1−σ
n

) is dis-
Pu∈V deg(u) for some constant C2 > 0. According to Eq. (8), fBR(
·
Pu∈V deg(u)]2
Pv∈V deg(v)2 . Thus, the blue-node initial

[

continuous at 1
occupation threshold is

−

βthreshold = 1

1

−
n

−

σ

[

v∈V deg(v)]2
v∈V deg(v)2 .

P
P

If |S|

n > βthreshold, limt→∞ Bv(t) = 1; if |S|

n < βthreshold, limt→∞ Bv(t) = 0. Since βthreshold ≥

(18)

σ, this leads to:

Insight 4 If the large-degree nodes are compromised by the strategic attacker, the defender can use active defense
to clean up the network only after the defender occupies βthreshold (

σ) portions of the network.

≥

Characterizing the quantitative beneﬁt to strategic defender in ER graphs

For ER graphs with edge probability p, the degree distribution follows a binomial distribution B(n, p):

P(deg(v) = k) =

n
p !

pk(n

−

p)k, k = 0, 1, . . . .

In the above we showed

αthreshold = σ

p
p + p(1

−

p)/n

, βthreshold = 1

(1

−

−

σ)

p
p + p(1

−

.

p)/n

→ ∞

p/[p + p(1

, both αthreshold and βthreshold converge to the threshold σ. More speciﬁcally, βthreshold −

p)/n] converges to 0, while βthreshold
αthreshold

= 1 + 1−p

σn converges to 1. This leads to:

αthreshold =

As n
1

−

−

Insight 5 For large ER graphs, the beneﬁt to strategic defender/attacker is not signiﬁcant because the node degrees
are relatively homogeneous.
(This is reminiscent of, and in parallel to, the connectivity-based robustness of ER
networks, namely that ER networks are resilient against strategic deletion of large-degree nodes [12]. Note however
that in our model, the attacker aims to compromise nodes but does not delete any nodes.)

Characterizing the quantitative beneﬁt to strategic defender in power-law graphs

Consider power-law graphs with exponent γ. Let C =
sum with integral in Eq. (16), we can deﬁne

αthreshold = σ

n
C

dmax(n)

k1−γdk

dmin(n)

Z

2

!

, 

n
C

k2−γdk

!

dmin(n)

Z

R

dmax(n)

dmax(n)

dmin(n) k−γdk = dmax(n)1−γ −dmin(n)1−γ

1−γ

. By replacing the

=

σ
n

(cid:18)

n2(dmax(n)2−γ
(dmax(n)1−γ

dmin(n)2−γ)2/(2
−
dmin(n)1−γ)2/(1

γ)2
−
γ)2

n(dmax(n)3−γ
(dmax(n)1−γ

dmin(n)3−γ)/(3
dmin(n)1−γ)/(1

−
−

(cid:19) (cid:30)(cid:18)
−
, γ = 1, γ = 2, γ = 3. Let z = dmax(n)/dmin(n). For γ /
1, 2, 3
}

−

∈ {

γ)
γ)

.

−
−
, one can
1, 2, 3
}

(cid:19)

This leads to four cases: γ /
show

∈ {

(dmax(n)2−γ
(dmax(n)1−γ

dmin(n)2−γ)2/(2
dmin(n)1−γ)2/(1

γ)2
γ)2

−
−

(cid:30)

(dmax(n)3−γ
(dmax(n)1−γ

−
−

dmin(n)3−γ)/(3
dmin(n)1−γ)/(1

γ)
γ)

−
−

−
−
1)2
−
1)(z3−γ

=

(z2−γ

(z1−γ

−

(3

1)

−

γ)(1

−
(2

−
γ)2

−

γ)

.

14

 
 
For γ = 1, 2, 3, we can reason in a similar fashion. As a result, we can deﬁne

(z2−γ −1)2
(z1−γ −1)(z3−γ −1)
1
2 z−1
z+1
ln(z)
z(ln(z))2
(z−1)2
2 z−1
z+1

1
ln(z)

(3−γ)(1−γ)
(2−γ)2

γ

= 1, 2, 3

γ = 1

γ = 2

γ = 3.

h(z, γ) =






If the defender is strategic, a sufﬁcient condition for limt→∞ Bv(t) = 1 is |S|
attacker is strategic, a sufﬁcient condition for limt→∞ Bv(t) = 1 is |S|
we have

n > βthreshold = 1

(1

−

−

n > αthreshold = σ

h(z, γ); if the
σ)h(z, γ). Therefore,

·

βthreshold −

αthreshold = 1

h(z, γ),

−

βthreshold
αthreshold

1

−

=

(1
σ

σ)h(z, γ)

−
h(z, γ)
·

= 1 +

h(z, γ)
h(z, γ)

.

1
σ

−
·

(19)

(20)

Eqs. (19) and (20) reach maximum at γ = 2. This leads to:

Insight 6 For power-law graphs, the beneﬁt to strategic defender/attacker is signiﬁcant. (This is also reminiscent
of, and in parallel to, the connectivity-based robustness of power-law networks, namely that power-law networks
are easily disrupted by strategic deletion of large-degree nodes [12]. Again, in our model the attacker aims to
compromise nodes but does not delete any nodes.) Moreover, the beneﬁt to strategic defender is maximized for the
sub-class of power-law networks with exponent γ = 2.

5 Characterizing Type II Active Cyber Defense Dynamics

Type II dynamics is similar to Type I dynamics, except the following: Type-I combat-power function is discontinuous
near the threshold σ, whereas Type II combat-power function is continuous and differentiable near the threshold τ .
For the case of non-strategic defender with node-independent Bv(0), we obtain the following Theorems 5-7, which
are in parallel to Theorems 1-3, respectively. Theorem 5 requires the following Lemma 2, whose proof is given in
Appendix C.

Lemma 2 Consider Type II dynamics with threshold τ and system (7) in arbitrary network G = (V, E).

(i) If

1
deg(v)

u∈Nv Bu(0) > τ holds for all v

∈
and minv∈V Bv(t) increases monotonically.

P

(ii) If

1
deg(v)

u∈Nv Bu(0) < τ holds for all v

∈
and maxv∈V Bv(t) decreases monotonically.

P

V , then

1
deg(v)

u∈Nv Bu(t) > τ holds for all v

V , then

1
deg(v)

P

P

u∈Nv Bu(t) < τ holds for all v

V and t

0,

≥

V and t

0,

≥

∈

∈

Proof of the following Theorem 5, which holds for arbitrary networks, is given in Appendix D.

Theorem 5 (a sufﬁcient condition under which the defender or the attacker will occupy the entire network) Consider
V ,
Type II dynamics with threshold τ and arbitrary network G = (V, E). If
limt→∞ Bv(t) = 1 for all v

1
deg(v)
V , limt→∞ Bv(t) = 0 for all v

u∈Nv Bu(0) > τ for all v
V .

u∈Nv Bu(0) < τ for all v

1
deg(v)

V ; if

∈

∈

P

∈

∈

P

15

6
Theorem 6 (a sufﬁcient condition under which neither the defender nor the attacker will occupy the entire network)
Consider Type II dynamics with threshold τ and arbitrary network G = (V, E) with the cluster structure. Let
Bv(0) = αk for every v
Vk and βk be the minimum node expansion as deﬁned in Eq. (9). If αkβk > τ , all nodes
in Vk will become blue; if (1

τ , all nodes in Vk will become red.

αk)βk > 1

∈

−

−

Proof of Theorem 6 is similar to proof of Theorem 2. Proof of the following Theorem 7 is given in Appendix E.

Both theorems hold for arbitrary networks.

Theorem 7 (method/algorithm for determining stability of equilibria) Consider Type II dynamics with threshold τ
and arbitrary network G = (V, E). Let B∗ = [B∗

v ]v∈V be an equilibrium and ¯B∗ = [1

v ]v∈V .

B∗

−

(i) Equilibria B∗ = [1, . . . , 1] and B∗ = [0, . . . , 0] are asymptotically stable with exponential convergence.

(ii) If B∗

v = τ for some v

∈

V , B∗ and ¯B∗ are unstable.

For the case of strategic defender with Bv(0)

deg(v), we can obtain a result for generalized random graphs

in parallel to Theorem 4 via a similar proof. We omit the lengthy details. In summary, we have:

∝

Insight 7 The preceding Insights 1-6 are equally applicable to Type II dynamics.

6 Characterizing Types III-IV Active Cyber Defense Dynamics

Types III-IV combat-power functions represent that the defender (attacker) is superior to, or more advanced than, its
opponent. Due to the lack of threshold in the computer-power functions, an immediate consequence is that there is
no difference between the case of non-strategic defender and the case of strategic defender. Further consequences
due to the lack of threshold are characterized as follows.

Theorem 8 (characterizing Type III dynamics) Consider Type III dynamics in arbitrary network G = (V, E).

(i) If Bv(0) > 0 for all v

∈

V , then limt→∞ Bv(t) = 1 for all v

V .

∈

(ii) Equilibrium Bv(0) = [1, . . . , 1] is asymptotically stable with exponential convergence.

(iii) Equilibrium Bv(0) = [0, . . . , 0] is unstable.

Part (i) of Theorem 8 can be proved as in the ﬁrst half of Theorem 5. Parts (ii) can be proved in a fashion similar
to Part (i) of Theorem 7. Parts (iii) can be proved in a fashion similar to Part (ii) of Theorem 7. Since Type IV
dynamics is dual to Type III dynamics, from Theorem 8 we obtain:

Theorem 9 (characterizing Type IV dynamics) Consider Type IV dynamics in arbitrary network G = (V, E).

(i) If Bv(0) < 1 for all v

∈

V , then limt→∞ Bv(t) = 0 for all v

V .

∈

(ii) Equilibrium Bv(0) = [0, . . . , 0] is asymptotically stable with exponential convergence.

(iii) Equilibrium Bv(0) = [1, . . . , 1] is unstable.

Theorems 8-9, which hold for arbitrary networks, lead to:

Insight 8 If the defender is superior to the attacker in terms of cyber combat power, the defender can always
use active defense to automatically clean up the entire network as long as there are a few computers that are not
compromised. In the extreme case where the attacker compromised the entire network, the defender only needs to
manually clean up a few computers before launching active defense to automatically clean up the entire network.
These suggest that cyber combat superiority can serve as an effective deterrence.

16

7 Advantage of Active Cyber Defense over Reactive Cyber Defense

Current cyber defense is mainly reactive, where the defender runs “anti-virus software”-like tools on each com-
puter to scan and cure infections, which are caused by attacks/malwares that penetrated the perimeter defense (e.g.,
Firewalls). Reactive cyber defense inevitably causes an asymmetry that is advantageous to the attacker because the
attack effect is automatically ampliﬁed by the network (a kind of “network effect”). Speciﬁcally, reactive cyber de-
fense may be modeled using the well-known SIS (Susceptible-Infectious-Susceptible) model, while accommodating
arbitrary attack-defense network topologies. A sufﬁcient condition for the spreading to die out is [16]:

λ1,A <

cure capability
spreading capability

,

where λ1,A is the largest eigenvalue of the adjacency matrix corresponding to the attack-defense defense structure
and is in a sense the average node degree or connectivity [42], cure capability abstracts the defender’s reactive
defense power (i.e., the probability that a compromised node becomes a susceptible node at a single time step), and
spreading capability abstracts the attacker’s attack power (i.e., the probability that a compromised node success-
fully attacks a susceptible neighboring node at a single time step). This means that the attacker always beneﬁts from
rich connectivity because the attack effect is ampliﬁed by λ1,A, which explains why the asymmetry phenomenon is
advantageous to the attacker [43, 44, 45].

On the other hand, Sections 4-6 show that the asymmetry disappears with active cyber defense because λ1,A (or
its like) does not play a role in the analytical results. This justiﬁes one usefulness of the model-based characterization
studies. In summary, we have:

Insight 9 Active cyber defense eliminates the attack ampliﬁcation phenomenon, namely the asymmetry between
cyber attack and reactive cyber defense.

8 Validating the Dynamic System Model via Simulation

The above characterizations of active cyber defense dynamics are based on the Dynamic System model, which is
the mean-ﬁeld approximation of the native Markov process model. Therefore, we need to show whether or not the
analytical results derived from the Dynamic System model are inherent to the Markov process model.

8.1 Validation Methodology

Our validation methodology is centered on examining the dynamics accuracy and the threshold accuracy of the
Dynamic System model. For examining the dynamic accuracy, we compare the mean blue occupation probability
v∈V Bv(t), and the simulation-based mean fraction of blue
in the Dynamic System model, namely
= 1
nodes in the Markov process model, namely
exhibit a similar, if
and
P
|V |
not exactly the same, dynamic behavior, we conclude that the analytical results derived from the Dynamic System
model are inherent to the Markov process model. (i) Our simulation of the Markov process model is based on Eq.
(1), namely

= 1
Bv(t)
|V |
i
h
ξv(t)
i
h

v∈V ξv(t). If

Bv(t)
i
h

ξv(t)
i
h

P

P

ξv(t + ∆t) = 1
{

ξv(t), v

N

}

∈

=

(cid:12)
(cid:12)

∆t

1
(

·

˜θv,RB(t)
∆t

˜θv,BR(t)

−

·

ξv(t) = 0

ξv(t) = 1

where the random rate ˜θv,RB is replaced with its mean θv,RB as speciﬁed in Eq. (5). Simulation results are based on
the average of 50 simulation runs. (ii) Our numerical calculation in the Dynamic System model is based on Eq. (7),

17

namely

In both cases, we set ∆t = 0.01.

Bv(t + ∆t) = Bv(t) + [θv,RB(t)

Bv(t)]∆t.

−

For examining the threshold accuracy, we study whether or not the threshold σ in the Dynamic System model is
faithful to the threshold σmarkov in the Markov process model. In order to to compute σmarkov, we use the following
is probabilistic in a very small interval that contains σ, we
numerical method. Since the convergence of
deﬁne σmarkov as the median value in that interval. Speciﬁcally, let a1 be the smallest value such that an initial blue
occupation greater than a1 will cause all nodes to become blue in all 50 runs. Let b1 be the largest value so that an
initial blue occupation smaller than b1 will cause all nodes to become red in all 50 runs. We set σmarkov = a1+b1
.

ξv(t)
i
h

2

In our simulation, we use two kinds of graphs:

•

•

ER random graph: It has n = 2, 000 nodes and independent link probability p = 0.02.

Power-law random graph: It has n = 2, 000, exponent γ = 2.5, minimum node degree 2, and maximum node
degree 120.

8.2 Dynamics Accuracy of the Dynamic System Model

Overall dynamics accuracy

First, let us consider Type I dynamics and non-strategic defender with node-independent identical initial occupation
probability Bv(0). Figure 4 conﬁrms that Theorem 1, which was proven in the Dynamic System model, is indeed
inherent to the Markov process model. Speciﬁcally, in the Dynamic System model, the
’s corresponding to
Bv(t)
i
h
’s corresponding to Bv(0) = 0.2 < σ = 1/3 all converge
Bv(0) = 0.4 > σ = 1/3 all converge to 1, and the
Bv(t)
i
h
’s corresponding to P
= 0.4 all converge to 1, and the
to 0. In the Markov process model, the
ξv(t)
h
i
’s corresponding to P
= 0.2 all converge to 0. Therefore, the dynamic behavior indicated by
ξv(0) = 1
ξv(t)
h
}
{
i
Theorem 1 is also exhibited by the Markov process model.

ξv(0) = 1
}
{

)æ
t
(

v

 Æ

,

 æ
)
t
(

v

B

1

0.8

0.6

0.4

0.2

0
0

Markov model (<s )
Markov model (>s )
Dynamic System (>s )
Dynamic System (<s )

200

400

Time

600

800

1000

)æ
t
(

v

 Æ

,

 æ
)
t
(

v

B

1

0.8

0.6

0.4

0.2

0
0

Markov model (>s )
Dynamic System (<s )
Dynamic System (>s )
Markov model (<s )

200

400

Time

600

800

1000

(a) ER graph

(b) Power-law graph

Figure 4:

Bv(t)
i
h

vs.

ξv(t)
i
h

in Type I dynamics with σ = 1/3 and non-strategic defender.

Second, let us look at Type I dynamics and strategic defender with Bv(0)

deg(v). Deﬁne η = Pu∈S deg(u)
Pv∈V deg(v) ,
where S is the set of blue nodes at time t = 0. Inequality (17) indicates that if η > σ, all nodes will become
blue; if η < σ, all nodes will become red. In our simulation, we set σ = 0.5. Figure 5(a) shows that in the ER
in the Markov process model converge to 1 when
graph, both
ξv(t)
i
h
η = 0.52 > σ = 0.5, and converge to 0 when η = 0.45 < σ = 0.5. Figure 5(b) shows that in the power-law
network, both
converge to 1 when η = 0.45 (< σ = 0.5), and converge to 0 when η = 0.35
(far smaller than σ = 0.5). These conﬁrm the phenomenon that is implied by Theorem 4, namely that the effect of

in the Dynamic System model and

Bv(t)
i
h

Bv(t)
i
h

ξv(t)
i
h

and

∝

18

Æ
 
 
x
 
 
Æ
 
 
x
 
 
strategic defense is not signiﬁcant in ER networks but signiﬁcant in power-law networks. In any case, the simulation
results demonstrate that the phenomenon exhibited by the Dynamic System model is inherent to the Markov process
model.

)æ
t
(

v

 Æ
,

)æ
t
(

v
B

1

0.8

0.6

0.4

0.2

0
0

Markov Model (>s )
Dynamic System (>s )
Markov Model (<s )
Dynamic System (>s )

200

400

Time

600

800

1000

)æ
t
(

v

 Æ
,

)æ
t
(

v

B

1

0.8

0.6

0.4

0.2

0
0

Markov model (>s )
Markov model (<s )
Dynamic System (>s )
Dynamic System (<s )

200

400

Time

600

800

1000

(a) ER graph

(b) Power-law graph

Figure 5:

Bv(t)
i
h

vs.

ξv(t)
i
h

in Type I dynamics with σ = 1/2 and strategic defender.

Third, let us look at Types II-IV dynamics and non-strategic defender with node-independent identical initial

∈

−

−

1 for x

2x2 + 4x

ξv = 1
}
{

occupation probability Bv(0). Consider Type II combat-power function with τ = 0.5, fRB(x) = 2x2 for x
∈
[0, 0.5], and fRB(x) =
[0.5, 1]. For the Dynamic System model, Figures 6(a)-6(b) show
Bv(0) = 0.4 < τ = 0.5 implies that all nodes will become red, and Bv(0) = 0.6 > τ = 0.5 implies that all nodes
will become blue. In the Markov process model, the same phenomenon is exhibited with the same initial condition
P
= Bv(0). This validates Theorem 5. For Type III combat-power function with fRB(x) = x1/2, Figures
corresponding to Bv(0) = 0.02 converges to 1 in the Dynamic System model.
6(c)-6(d) demonstrate that
The same phenomenon is exhibited in the Markov process model. This validates Theorem 8. For Type IV combat-
power function fRB(x) = x2, Figures 6(e)-6(f) validate that
corresponding to Bv(0) = 0.98 converges to 0.
The same phenomenon is exhibited in the Markov process model. This conﬁrms that the dynamic behavior indicated
by Theorem 9 is also exhibited by the Markov process model.

Bv(t)
i
h

Bv(t)
i
h

1

0.8

0.6

0.4

0.2

)æ
t
(

v

 x

,Æ

)æ
t
(

v

B

0
0

1

)æ
t
(

v

 Æ
,

)æ
t
(

v
B

0.5

0
0

Markov Model (>s )
Markov Model (<s )
Dynamic System (<s )
Dynamic system (>s )

200

400

Time

600

800

1000

1

0.5

)æ
t
(

v

,Æ

 æ
)
t
(

v
B

0
0

Markov model (>s )
Dynamic System (>s )
Markov model (<s )
Dynamic System (<s )

200

400

Time

600

800

1000

(a) Type II dynamics (ER)

(b) Type II dynamics (Power-law)

Markov model
Dynamic System

200

400

Time

600

800

1000

1

0.5

)æ
t
(

v

,Æ

,æ
)
t
(

v
B

0
0

Markov Model
Dynamic System

200

400

Time

600

800

1000

1

0.8

0.6

0.4

0.2

)æ
t
(

v

,Æ

)æ
t
(

v

B

0
0

1

)æ
t
(

v

 Æ
,

)æ
t
(

v
B

0.5

0
0

Markov Model
Dynamic System

200

400

Time

600

800

1000

(c) Type III dynamics (ER)

Markov Model
Dynamic System

200

400

Time

600

800

1000

(d) Type III dynamics (Power-law)

(e) Type IV dynamics (ER)

(f) Type IV dynamics (Power-law)

Figure 6:

ξv(t)
i
h

vs.

Bv(t)
i
h

in Types II-IV dynamics with non-strategic defender.

Fourth, for power-law networks and strategic defender with Bv(0)

deg(d), we derived the sufﬁcient condition

∝

19

Æ
 
x
 
 
Æ
 
x
 
 
Æ
 
 
 
Æ
 
x
 
 
Æ
 
x
 
 
Æ
 
x
 
 
Æ
 
x
 
 
Æ
 
x
 
 
·

|S|
h(z, γ) for limt→∞ Bv(t) = 1, meaning that in order for the defender to use active cyber defense to
n > σ
automatically clean up the network, the defender needs to occupy more than σ
h(z, γ) fraction of the nodes, which
is minimum when h(z, γ) is minimum. As shown in Figure 7(a), for ﬁxed z, h(z, γ) is minimum at γ=2, which
corresponds to the sub-class of power-law networks that maximize the beneﬁt to the strategic defender. Figure 7(b)
plots the simulation results in the Markov process model. We observe that σmarkov is minimum at γ = 2 in the
Markov model as well. These further conﬁrm that the particular conclusion drawn in the Dynamic model — the
beneﬁt to the strategic defender is maximized for power-law graphs with exponent γ = 2 — is also inherent to the
Markov process model.

·

1

0.9

)

,g
z
(
h

0.8

0.7

0.5

0.45

v
o
k
r
a
m

0.4

z=3
z=6
z=10

1

2

3

4

5

0.35

1.5

2

2.5

3

3.5

z=3
z=5.5
z=8
z=10
4

4.5

(a) Numerical h(z, γ)

(b) Simulation-based σmarkov

Figure 7: Power-law networks with exponent γ = 2 maximizes the beneﬁt to strategic defenders

Dynamics inaccuracy: cause and characteristics

In the above, our simulation results show, from the perspective of system state dynamics, that the Dynamic System
model offers overall accurate approximation to the Markov process model. Still, Figures 4-6 visually exhibit the
following phenomenon: the Dynamic System model sometimes underestimates and sometimes overestimates the
dynamics simulated from the Markov process model. What is the cause of this phenomenon? To answer this
question, we observe that the master equation Eq. (3) can be rewritten as:

d
dt

˜Bv(t) = ˜θv,RB(t)

˜Bv(t)

−

(21)

where

˜θv,RB(t) = E

fRB

1
deg(v)

ξv(t)

!!

Xu∈Nv

and ˜θv,RB(t) = 1

˜θv,BR(t) so as to be consistent with Eq. (6). It can be seen that if fRB(
) is convex, then
·

−

˜θv,RB(t) = E

fRB

≥

fRB

E

(cid:18)

1
deg(v)

1
deg(v)

ξv(t)

!!

Xu∈Nv

ξv(t)

(cid:19)!

Xu∈Nv

= θv,RB(t).

) is concave, then ˜θv,RB(t)
θv,RB(t). As a result, the above phenomenon can be explained
Analogously, if fRB(
·
as follows: For Types I-II combat-power functions, the dynamics in the Dynamic System model underestimates
u∈Nv ξv(t) is below the threshold in the combat-
the dynamics in the native Markov process model when
1
u∈Nv ξv(t) is above
power function, and overestimates the dynamics in the Markov process model when
deg(v)

1
deg(v)

≤

P

20

P

g
 
 
g
s
 
 
 
 
 
 
 
the threshold (see Figures 4-5 and Figures 6(a)-6(b)). For Type III combat-power functions, which can be regarded
as concave over the region [0, 1], the dynamics in the Dynamic System model overestimates the dynamics in the
Markov process model (see Figures 6(c)-6(d)). Analogously, for Type IV combat-power functions, the dynamics of
the Dynamic System model underestimates the dynamics in the Markov process model (see Figures 6(e)-6(f)).

Having explained the cause of the slight dynamic inaccuracy, we want to establish some deeper understanding of
the inaccuracy. In particular, we want to know how the inaccuracy may be dependent upon the average node degree.
For this purpose, we consider the following notion of relative error between the Dynamic System model and the
Markov process model:

RE =

T

0 [ ˜Bv(t)

R

T
0

−
˜B2
v (t)dt

Bv(t)]2dt

,

where ˜Bv(t) is the probability that node v is blue in the Markov process model, and Bv(t) is the dynamic system
state. To investigate the impact of average node degree, we ﬁx the variance of the node degrees, denoted by dvar.
Consider in the generalized random graph model with a given expected degree sequence that follows the power-law
distribution. By ﬁxing the variance dvar and the ratio r between the minimum and maximum expected degrees as
dmax = r
dmin, we derive dmin with respect to the varying power-law exponent γ from 1 to 6, as follows:

R

∗

dmin =

dvar

1−γ
3−γ

s

r3−γ −1
r1−γ −1 −

1−γ
(2−γ)2

r2−γ −1
(r1−γ −1)2

.

With r = 20 and dvar = 400, we obtain a series of generalized random graphs of 2,000 nodes. Although we cannot
precisely ﬁx the variance, the actual standard deviation of degrees for different γ’s is quite stable: 20.47
0.48. We
run the Markov process model and the Dynamic System model on the random graphs to calculate the relative errors.
We ﬁnd, as shown in Figure 8, that the relative errors decrease with the average node degree.

±

0.1

0.05

r
o
r
r

E
e
v
i
t

l

a
e
R

0

20

30

40
50
Average Degree

60

70

80

Figure 8: Relative error vs. average node degree

8.3 Threshold Accuracy of the Dynamic System Model

Now we examine the accuracy of the Dynamic System model from a different perspective:
threshold accuracy.
That is, we examine the accuracy of the threshold σ derived from the Dynamic System model with respect to the
threshold σmarkov, which is numerically derived from the Markov process model. For the special case of Type III-IV
combat-power functions, which have no threshold, we observe the following: For Type III combat-power functions,
if ˜Bv(0) > 0 for some nodes that can reach all other nodes, then limt→∞ ˜Bv(t) = 1 for all v
V ; For Type IV
combat-power functions, if ˜Rv(0) > 0 for some nodes that can reach all other nodes, then limt→∞ ˜Bv(t) = 0 for all

∈

21

 
V . To see this, we note that in the case of Type III combat-power functions, the following holds:

v

∈

˜θv,RB(t) = E

1
deg(v)

f

"

ξu(t)

!#

Xu∈Nv

1
deg(v)

E

"

≥

ξu(t)

#

1
deg(v)

=

"

˜Bu(t)
#

.

Xu∈Nv

Xu∈Nv

The case of Type IV combat-power functions can be treated analogously. However, the situation for Types I-II
combat-power functions is very different as we elaborate below.

Threshold (in)accuracy for Types I-II combat-power functions: cause and characteristics

We illustrate the following threshold-drifting phenomenon with the speciﬁc fRB(
) in Type I dynamics for example.
·
Figures 9(a)-9(b) plot σmarkov and σ in the case of non-strategic defender with node-independent identical probabil-
deg(v). We observe
ity Bv(0). Figures 9(c)-9(d) plot σmarkov and σ in the case of strategic defender with Bv(0)
that Figure 9(d) exhibits a pattern that is different from the others, which we cannot explain at the moment but we
plan to investigate in the future. In all other cases, we observe the following: if σ < 0.5, then σmarkov < σ; if
σ > 0.5, then σmarkov > σ. We call this threshold-drifting phenomenon, which indicates that the threshold σ in the
Dynamic System model may deviate from the threshold σmarkov in the Markov process model.

∝

1

 s
,

v
o
k
r
a
m

0.5

1

 s
,

v
o
k
r
a
m

0.5

0
0

0.2

0.4

0.6

0.8

1

0
0

0.2

0.4

0.6

0.8

1

(a) Node-independent Bv(0): ER graph

(b) Node-independent Bv(0): Power-law graph

1

 s
,

v
o
k
r
a
m

0.5

1

 s
,

v
o
k
r
a
m

0.5

0
0

0.2

0.4

0.6

0.8

1

0
0

0.2

0.4

0.6

0.8

1

(c) Degree-dependent Bv(0): ER graph

(d) Degree-dependent Bv(0): Power-law graph

Figure 9: Threshold-drifting phenomenon:
σmarkov.

red diagonal line corresponds to σ and blue curves correspond to

What is the cause of the threshold-drifting phenomenon? In order to answer this question, let us deﬁne α =
v∈V Bv(0), namely the average fraction of blue nodes at time t = 0. The probability that k out of node v’s

1
n
deg(v) neighbors are initially blue is:

P

Q(deg(v), α, k) =

deg(v)
k

(cid:18)

αk(1

−

(cid:19)

α)deg(v)−k.

22

 
s
s
s
s
s
s
s
s
Suppose at each time step the occupation probability approximately follows the binomial distribution. For a random
node ¯v, its expected degree is
, with ν(0) = α.
Now we consider the Dynamic System model. The mean of θ¯v,RB(t) is the probability that the actual number of
blue neighbors is greater than σ

and the probability that ¯v is blue is ν(t) =

deg(v)
i
h

ξv = 1
{

P
h

}i

. Denote this probability by θσ(ν(t),
deg(v)
i

). Then,
deg(v)
i
h

· h

θσ(ν(t),

)
deg(v)
i
h

=

k>ν(t)·hdeg(v)i Q(
, ν(t), k)
deg(v)
i
h
, ν(t), k) + 1
deg(v)
k>ν(t)·hdeg(v)i Q(
i
h

( P

, ν(t), σ
deg(v)
2 Q(
i
h

if σ

if σ

deg(v))

·

deg(v)
i
deg(v)
i

· h

· h

Hence, we can use the following equation to approximate the Markov process model:

P

dν(t)
dt

= θσ(ν(t),

)
deg(v)
i
h

−

ν(t).

is no integer

is integer.

(22)

This one-dimension differential equation has two stable equilibria, ν = 0 (i.e., all nodes are red) and ν = 1 (i.e., all
nodes are blue). The critical value of the initial condition between the attracting basins ν = 0 and ν = 1 is the non-
trivial solution of θσ(ν,
ν = 0, namely the solution other than 0 and 1 (which are the trivial solutions).
= σ, which
The critical value in the Dynamic System model approximates σmarkov. As shown in Figure 9, σmarkov 6
explains the threshold-drifting phenomenon.

)
deg(v)
i
h

−

Having explained the cause of the threshold-drifting phenomenon, we suspect that the degree of threshold-
drifting also depends on the average node degree (more speciﬁcally, the threshold-drifting phenomenon disappears
with the average degree). To conﬁrm/disconﬁrm this, we compare in Figure 10 the threshold σmarkov in the Markov
process model and the threshold σ in the Dynamic System model, with respect to identical initial blue-occupation
probability Bv(0). In both ER and power-law graphs, we observe that σmarkov asymptotically converges to σ as the
average node degree

increases.

deg(v)
i
h

,s

v
o
k
r
a
m

0.3

0.28

0.26

0.24

0.22

10

0.32

 s
,

v
o
k
r
a
m

0.3

0

1000
100
Average Degree

10000

100

200
Average degree

300

400

(a) ER graph (σ = 0.3)

(b) Power-law graph (σ = 1/3)

Figure 10: The greater the average node degree, the better the approximation of σmarkov (blue curve) to σ (red line).

The implication of the threshold-drifting phenomenon is that the threshold σ may need to be adjusted in practice
when σ > 1/2 (i.e., for some small ∆σ using σmarkov = σ + ∆σ instead). For the case σ < 1/2, adjustment is
not necessary because σ (> σmarkov) is sufﬁcient for governing the dynamics toward the all-blue equilibrium (i.e.,
active cyber defense is effective for automatically cleaning up the network).

9 Conclusions

We presented the ﬁrst mathematical model and characterization of active cyber defense dynamics. The analytical
results give conditions under which (strategic) active cyber defense is effective, and lead to practical insights that

23

s
s
can be adopted for decision-making and policy-making in real life.

Our study brings a range of interesting research problems, such as: How should we accommodate more sophis-
ticated combat-power functions? How can we analyze strategic defender/attacker, including Bv(0)
deg(v) and
possibly other scenarios, in arbitrary networks (rather than in the generalized random graph model)? How can we
analyze the native Markov process model without using the Dynamic System approximation (while noting that the
difﬁculty mainly lies in the nonlinearity of the combat-power functions)?

∝

Acknowledgement

We thank the reviewers for their comments that helped us improve the paper. Shouhuai Xu was supported in part by
ARO Grant #W911NF-12-1-0286, AFOSR MURI Grant #FA9550-08-1-0265, and NSF Grant #1111925. Wenlian
Lu was jointly supported by the Marie Curie International Incoming Fellowship from the European Commission (no.
FP7-PEOPLE-2011-IIF-302421), the National Natural Sciences Foundation of China (no. 61273309), the Shanghai
Guidance of Science and Technology (SGST) (no. 09DZ2272900) and the Laboratory of Mathematics for Nonlinear
Science, Fudan University. Any opinions, ﬁndings, and conclusions or recommendations expressed in this material
are those of the author(s) and do not necessarily reﬂect the views of any of the funding agencies.

References

[1] F. Castaneda, E. Sezer, and J. Xu, “Worm vs. worm: preliminary study of an active counter-attack mechanism,”

in Proceedings of the 2004 ACM Workshop on Rapid Malcode (WORM’04), pp. 83–93, 2004.

[2] D. Aitel,

“Nematodes – beneﬁcial worms.” http://www.immunityinc.com/downloads/

nematodes.pdf, Sept. 2005.

[3] N. Weaver and D. Ellis, “White worms don’t work,” ;login: The USENIX Magazine, vol. 31, no. 6, pp. 33–38,

2006.

[4] B. Schneier,

“Benevolent worms.” http://www.schneier.com/blog/archives/2008/02/

benevolent_worm_1.html, February 19, 2008.

[5] H. Lin, “Lifting the veil on cyber offense,” IEEE Security & Privacy, vol. 7, no. 4, pp. 15–21, 2009.

[6] W. Matthews, “U.s. said to need stronger, active cyber defenses.” http://www.defensenews.com/

story.php?i=4824730, 1 Oct 2010.

[7] J. Kesan and C. Hayes, “Mitigative counterstriking: Self-defense and deterrence in cyberspace,” Harvard Jour-
nal of Law and Technology (forthcoming, available at SSRN: http://ssrn.com/abstract=1805163).

[8] H. S. N. Wire, “Active cyber-defense strategy best deterrent against cyber-attacks.” http://www.

homelandsecuritynewswire.com/active-cyber-defense-strategy-best-deterrent-against-
28 June 2011.

[9] R. Naraine,

“’friendly’ welchia worm wreaking havoc.” http://www.internetnews.com/

ent-news/article.php/3065761/Friendly-Welchia-Worm-Wreaking-Havoc.htm,
August 19, 2003.

[10] L. Shaughnessy, “The internet: Frontline of the next war?.” http://www.cnn.com/2011/11/07/us/

darpa/, November 7, 2011.

24

[11] J. Wolf, “Update 2-u.s. says will boost its cyber arsenal.” http://www.reuters.com/article/2011/

11/07/cyber-usa-offensive-idUSN1E7A61YQ20111107, November 7, 2011.

[12] R. Albert, H. Jeong, and A. Barabasi, “Error and attack tolerance of complex networks,” Nature, vol. 406,

pp. 378–482, 2000.

[13] Y. Wang, D. Chakrabarti, C. Wang, and C. Faloutsos, “Epidemic spreading in real networks: An eigenvalue
viewpoint,” in Proc. of the 22nd IEEE Symposium on Reliable Distributed Systems (SRDS’03), pp. 25–34,
2003.

[14] A. Ganesh, L. Massoulie, and D. Towsley, “The effect of network topology on the spread of epidemics,” in

Proceedings of IEEE Infocom 2005, 2005.

[15] N. Berger, C. Borgs, J. Chayes, and A. Saberi, “On the spread of viruses on the internet,” in Proceedings of the

sixteenth annual ACM-SIAM symposium on Discrete algorithms, SODA ’05, pp. 301–310, 2005.

[16] D. Chakrabarti, Y. Wang, C. Wang, J. Leskovec, and C. Faloutsos, “Epidemic thresholds in real networks,”

ACM Trans. Inf. Syst. Secur., vol. 10, no. 4, pp. 1–26, 2008.

[17] P. Van Mieghem, J. Omic, and R. Kooij, “Virus spread in networks,” IEEE/ACM Trans. Netw., vol. 17, pp. 1–14,

Feb. 2009.

[18] S. Chatterjee and R. Durrett, “Contact processes on random graphs with power law degree distributions have

critical value 0,” Ann. Probab., vol. 37, no. 6, pp. 2332–2356, 2009.

[19] F. Ball, D. Sirl, and P. Trapman, “Threshold behaviour and ﬁnal outcome of an epidemic on a random network

with household structure,” Adv. in Appl. Probab, vol. 41, no. 3, pp. 765–796, 2009.

[20] F. Ball, D. Sirl, and P. Trapman, “Analysis of a stochastic

epidemic on a random network incorporating

household structure,” Mathematical Biosciences, vol. 224, no. 2, pp. 53 – 73, 2010.

SIR
{

}

[21] S. Xu, W. Lu, and Z. Zhan, “A stochastic model of multivirus dynamics,” IEEE Trans. Dependable Sec. Com-

put., vol. 9, no. 1, pp. 30–45, 2012.

[22] T. Mountford, J.-C. Mourrat, D. Valesin, and Q. Yao, “Exponential extinction time of the contact process on

ﬁnite graphs,” ArXiv e-prints, Mar. 2012.

[23] T. Mountford, D. Valesin, and Q. Yao, “Metastable Densities for Contact Processes on Power Law Random

Graphs,” ArXiv e-prints, Dec. 2012.

[24] J. Kephart and S. White, “Directed-graph epidemiological models of computer viruses.,” in IEEE Symposium

on Security and Privacy, pp. 343–361, 1991.

[25] J. Kephart and S. White, “Measuring and modeling computer virus prevalence,” in IEEE Symposium on Secu-

rity and Privacy, pp. 2–15, 1993.

[26] A. McKendrick, “Applications of mathematics to medical problems,” Proc. of Edin. Math. Soceity, vol. 14,

pp. 98–130, 1926.

[27] W. Kermack and A. McKendrick, “A contribution to the mathematical theory of epidemics,” Proc. of Roy. Soc.

Lond. A, vol. 115, pp. 700–721, 1927.

25

[28] H. Hethcote, “The mathematics of infectious diseases,” SIAM Rev., vol. 42, no. 4, pp. 599–653, 2000.

[29] R. Durrett, Random graph dynamics. Cambridge University Press, 2007.

[30] N. Masuda, N. Gibert, and S. Redner, “Heterogeneous voter models,” Phys. Rev. E, vol. 82, p. 010103, Jul

2010.

[31] E. Pugliese and C. Castellano, “Heterogeneous pair approximation for voter models on networks,” Europhysics

Letters, vol. 88, no. 5, p. 58004, 2009.

[32] V. Sood, T. Antal, and S. Redner, “Voter models on heterogeneous networks,” Physical Review E, vol. 77, no. 4,

pp. 1–13, 2008.

[33] F. Schweitzer and L. Behera, “Nonlinear voter models: The transition from invasion to coexistence,” European

Physical Journak B, vol. 67, p. 301, 2009.

[34] M. Vojnovic and A. Ganesh, “On the race of worms, alerts, and patches,” IEEE/ACM Trans. Netw., vol. 16,

pp. 1066–1079, October 2008.

[35] P. A. P. Moran, The statistical processes of evolutionary theory. Clarendon Press, 1962.

[36] M. A. Nowak, Evolutionary Dynamics: Exploring the Equations of Life. Harvard University Press, 2006.

[37] R. Pastor-Satorras and A. Vespignani, “Epidemic spreading in scale-free networks,” Phys. Rev. Lett., vol. 86,

no. 14, pp. 3200–3203, 2001.

[38] T. Liggett, Stochastic Interacting Systems: Contact, Voter and Exclusion Processes. Springer-Verlag, 1999.

[39] A. Barabasi and R. Albert, “Emergence of scaling in random networks,” Science, vol. 286, pp. 509–512, 1999.

[40] F. Chung and L. Lu, Complex Graphs and Networks (Cbms Regional Conference Series in Mathematics).

Boston, MA, USA: American Mathematical Society, 2006.

[41] K. Chung, A Course in Probability Theory (Second Edition). Academic Press, 2000.

[42] L. Lovasz, “Eigenvalues of graphs.” http://www.cs.elte.hu/˜lovasz/eigenvals-x.pdf.

[43] S. Staniford, V. Paxson, and N. Weaver, “How to own the internet in your spare time,” in Proceedings of the

11th USENIX Security Symposium, pp. 149–167, 2002.

[44] D. Moore, C. Shannon, G. Voelker, and S. Savage, “Internet quarantine: Requirements for containing self-

propagating code,” in INFOCOM’03, 2003.

[45] S. Staniford, D. Moore, V. Paxson, and N. Weaver, “The top speed of ﬂash worms,” in Proceedings of the 2004

ACM workshop on Rapid malcode (WORM’04), pp. 33–42, ACM Press, 2004.

[46] P. Hill, Rates of convergence in the central limit theorem. London, UK: Pitman Advanced Publisher, 1982.

26

A Proof of Theorem 3

Proof For (i), note that equilibrium of Eq. (7) satisﬁes

fRB

1
deg(v)

Xu∈Nv
v + δB. If B∗

= B∗
v .

B∗
u

!

v = 0, then θv,RB(0) = 0 and Bv(t) decreases toward 0. In any case, the sign of

Consider a small perturbation B(0) = B∗
v = 1, then θv,RB(0) = 1 and Bv(t) increases toward 1;
if B∗
σ
in a small time interval [0, t0) for some t0 is unchanged. Let t1 be the maximum time at which all the signs of
1
σ. If t1 is ﬁnite, then all
deg(v)
signs in a small time interval starting at time t1 are respectively the same as the signs at time t1. This implies that
V ,
t1 = +
which implies that the system is asymptotically stable.

P
σ is the same as the sign of

σ are respectively the same as the signs of

. So, the sign of

u∈Nv Bu(0)

u∈Nv Bu(0)

u∈Nv Bu(t)

u∈Nv Bu(t)

u∈Nv Bu(t)

σ for all v

P
∞

1
deg(v)

1
deg(v)

1
deg(v)

1
deg(v)

P

−

−

−

−

−

∈

To see that ¯B∗ is also an equilibrium, consider the dynamic behavior of Rv(t) in Eq. (7), namely dRv (t)

dt =

P

P

θv,BR(t)

−

Rv(t), where

θv,BR(t) = fBR

1
deg(v)

Rv(t)

!

= 1

fRB

−

1
deg(v)

Xu∈Nv

Bv(t)

!

.

Xu∈Nv

Since Bv(t) + Rv(t) = 1 always holds for all v, ¯B∗ is an equilibrium of (11) and thus an equilibrium of (7).

To see the rates of convergence to the above equilibria, we note θv,BR(t) = 0 or 1 for all t and v

V . Thus, (7)

becomes either dBv (t)

dt = 1

Bv(t), or dBv (t)

dt =

∈
Bv(t). In any case, the convergence rate is O(exp(

t)).

−

−
For (ii), we ﬁrst note that the deﬁnition of Type I combat-power function implies θv,RB ∈ {
v1, . . . , vr}
{

−
. Suppose at
}
V1, we
∈
. For any ǫ > 0, it is always possible to ﬁnd a sufﬁciently small δB from a set of positive Lebesgue
0, 1
}

equilibrium B∗ that B∗
have B∗
measures and impose perturbation near B∗: B∗∗ = B∗ + δB such that

0, 1, σ
r. In other words, for any v

vk = σ for vk ∈

, where 1

< ǫ and

v ∈ {

V1 =

≤

≤

V

k

\

1
deg(v)
1
deg(v)




P

u∈Nv B∗∗
u∈Nv B∗∗

u > σ if v
∈
u < σ if B∗
v = 0.

δB
k

k
V1 or B∗
v = 1

By treating B∗∗ as the initial security state at time t = 0, there exists a time interval [0, t0) such that

P


v = σ, Bv(t) monotonically strictly increases toward 1 for t

for any node v with B∗

[0, t0);

∈

•

•

•

for any node v with B∗

v = 1, we have Bv(t) = 1 for t

[0, t0);

∈

for any node v with B∗

v = 0, Bv(t) does not decrease for t

[0, t0).

∈

Since for any v with B∗∗

v = σ, we have Bv(t)

1 as t

→

→ ∞

, B∗ with B∗

v = σ for some v is unstable.

B Proof of Theorem 4

Proof From condition limn→∞φ(n) > σ, for almost every sequence of φ(n) we can pick some µ > µ′ > 0 such
that φ(n) > σ + µ > σ + µ′ for sufﬁciently large n. Recall random variable χv(S):

χv(S) =

1 v

∈
0 v /
∈

(

S

S.

27

 
 
 
Note that P(χv(S) = 1) = Bv(0). Let ζvu be a random variable indicating the link between (from) node u and (to)
node v, namely

According to Eq. (10), we have

ζvu =

1 (u, v)

∈
0 (u, v) /
∈

(

E(n)

E(n).

P(ζvu = 1) = pvu(n) =

dv(n)du(n)
k∈V (n) dk(n)

.

Since we assumed that the Bv(0)’s are independent of each other and also independent of the linking of edges in
G(n), ζvu and χu(S) are independent with respect to u. Our goal is to estimate the probability of event Av as deﬁned
by

P

Av =

1
deg(v)

(

Bu(0) < σ

1
deg(v)

=

)




Bu(0)

·

ζvu < σ

,




Xu∈V (n)

namely P(Av) = P(

Xu∈Nv
Bu(0) < σ
Note that random variables ζvu for all u
P
pvu(n) and variance is Var(ζvu) = pvu(n)(1
variable has only two states, we have

u∈V (n) ζvu ·

·
∈
−



deg(v)).
V (n) are independent of each other. Its expectation is E(ζvu) =
pvu(n)). Because E(χu(S)
ζvu) = Bu(0)pvu(n) and the random



·

P (Av)

= P

= P







qP

1
Var(ζvu)B2

u(0)

u∈V (n)

[ζvuBu(0)

Xu∈V (n)

E(ζvu)Bu(0))] <

−

[ζvu ·

Bu(0)

Bu(0)

·

pvu(n)] <

−

u∈V (n)


qP
+σ

deg(v)
sn,v

−

1
Var(ζvu)B2

u(0)

dv

+

dv
sn,v " P

u∈V (n) deg(u)χu(S)

P
−
p∈V (n) dp
P

+

P

Xu∈V (n)
u∈V (n) χu(S) deg(u)

p∈V (n) deg(p) P
u∈V (n) duBu(0)

#!

v∈V (n) dv −

v∈V (n) deg(v)

P

v∈V (n) d(v)
P

P

deg(v)

σ

·

−

u∈V (n)

E(ζvu ·

χu(S))

P
u∈V (n)

qP
dv
σ
sn,v "

− P

χu(S))

Var(ζvu ·
u∈V (n) χu(S)

·

p∈V (n) deg(p)



deg(u)



#

n,v is deﬁned in Eq. (12). Since Var[ζv,uBu(0)] = Bu(0)2pvu(1

P

where s2
s2
n,v.

Note that assumption (i) implies

pvu), we have

u∈V (n)

Var[ζv,uBu(0)] =

−

P

lim
n→∞

1
s3
n,v

E
Xu∈V (n) (cid:26)

|

ζv,uBu(0)

E(ζv,uBu(0))
|

3

−

= lim
n→∞

qn,v
s3
n,v

= 0.

(cid:27)

with qn,v deﬁned in Eq. (13). This guarantees the Lyapunov condition in the Central Limit Theorem (with δ = 1)
[41]. So, as n

,

→ ∞

1

s2
n,v Xu∈V (n)

q

[ζv,uBu(0)

Bu(0)pvu]

N (0, 1)

→

−

(23)

28

in distribution uniformly, as n

. We call this asymptotic normal random variable φv.

In addition, we observe that

→ ∞

σ

deg(v)
sn,v

−

dv

= σ

dv
sn,v

deg(v)
dv

−

dv

= σ

dv
sn,v

deg(v)

−
wn,v

dv

wn,v
dv →

o(1)

dv
sn,v

(24)

with wn,v deﬁned in Eq. (14), with probability 1, because the term deg(v)−dv
converges to the standard Gaussian
random variable owing to the Lyapunov central limit theorem where the Lyapunov condition is guaranteed by as-
V (n), and
sumption (ii), noting gn,v, deﬁned in Eq. (15), denoting the third order moment of ζv,u for all u
because

wn,v

∈

as n

→ ∞

, owing to assumption (iii). Furthermore, we observe that

wn,v
dv ≤

1

√dv →

0

v∈V (n) dv −

v∈V (n) deg(v)

P

v∈V (n) d(v)
P

=

P

v∈V (n) dv −

v∈V (n) deg(v)

v∈V (n) w2
P
n,v

v∈V (n) w2
v∈V (n) d(v) →

n,v

qP

0

(25)

almost surely, because Pv∈V (n) dv−

Pv∈V (n) deg(v)

P

qP

P

converges to the standard Gaussian random variable, owing to the

Lyapunov central limit theorem where the Lyapunov condition is guaranteed by assumption (iv), and

qPv∈V (n) w2

n,v

v∈V (n) w2
v∈V (n) d(v) ≤

n,v

qP

1

v∈V (n) dv

0,

→

owing to assumption (iii). We further observe that

P

qP

u∈V (n) deg(u)χu(S)

−
p∈V (n) dp
P

u∈V (n) duBu(0)

u∈V (n) deg(u)χu(S)

P

u∈V (n) duBu(0)

−
v∈v(n) s2
P
n,v

n,v

v∈v(n) s2
p∈V (n) dp →

qP

0

(26)

P

P

=

almost surely, because

qP

P

u∈V (n) deg(u)χu(S)

u∈V (n) duBu(0)

−
v∈v(n) s2
P
n,v

P

converges to the standard Gaussian random variable, owing to the Lyapunov central limit theorem where the Lya-
punov condition is guaranteed by assumption (v), and

qP

n,v

v∈v(n) s2
p∈V (n) dp ≤

qP

1

p∈V (n) dp

owing to assumption (iii). Combining (23), (24), (25) and (26) with the fact

P

qP

u∈V (n) χu(S) deg(u)
p∈V (n) deg(p)

1,

≤

P

P

29

we conclude that there exists a random variable ǫn,v that converges to zero uniformly with probability 1 such that

P (Av) = P



u∈V (n)

1
Var(ζvu)B2

u(0)

qP
Finally, we observe that σ



φ(n)

−

≤ −

rate in the Central Limit Theorem [46], implies

[ζvuBu(0)

E(ζvu)Bu(0))] <

−

dv
sn,v (cid:18)

σ

−

φ(n) + ǫn,v

.



(cid:19)

Xu∈V (n)
µ holds with probability 1. This inequality, together with the convergence



η
(cid:12)
(cid:12)
(cid:12)
(cid:12)

P

Av

σ + µ

Φ (tn(v))

C

≥

−

≤

(1 +

qn,v/s3

n,v
3)
tn(v)
|
|

,

where tn(v) =
normal distribution, and C is a universal constant.

−

µ′ deg(v)
sn,v

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:18)

(cid:19)
, noting µ′ < µ, for sufﬁciently large n, Φ(
) is the probability function of the standard
·

(cid:12)
(cid:12)
(cid:12)
(cid:12)

Since

and

we have

Φ (tn(v)) =

2
√π

tn(v)

−∞

Z

exp(

−

y2
2

)dy,

x

−∞

Z

y2/2)dy

exp(

−

exp(

−

≤

x2/2)/(

−

x) for all x

0,

≤

Φ (tn(v)) <

exp

2n
√π

(cid:2)

Xv∈V (n)

−

(minv tn(v))2/2
minv tn(v)

(cid:3)

.

(27)

Under assumption (iii), the supra-limit of the logarithm of the right-hand side of Eq. (27) becomes:

limn→∞

ln

(cid:26)

(cid:18)
v∈V (n) Φ (tn(v))

2
√π

→

(cid:19)
0 as n

This implies

P

+ ln(n)

[min
v

−

tn(v)]2/2

ln[min

v

−

tn(v)]

=

(cid:27)

.

−∞

. In addition, we observe that

→ ∞

Cqn,v
tn,v|
|

1 +

3 ≤

qn,v
d3
v ≤

C

C

Xv∈V (n)

Xv∈V (n)

1
d2
v

Xv∈V (n)

converges to zero owing to assumption (vi).
Putting the above together, we have

P

lim
n→∞





[v∈V (n)

Av


≤

≤

limn→∞

P (Av)

Xv∈V (n)

limn→∞

Φ (tn(v)) + Climn→∞

Xv∈V (n)

= 0

Cqn,v

1 +

3
tn(v)
|
|

Xv∈V (n)

By applying Theorem 1, for each event not belonging to
proves the ﬁrst part of the theorem.

v Av, we have limt→∞ Bv(t) = 1 for all v

V (n). This

∈

Analogously, we can prove the second part. This completes the proof.

S

30

C Proof of Lemma 2

deg(v)

Proof We only prove part (i) because part (ii) can be proved analogously. In order to simplify the presentation, let
Yv(t) = 1

u∈Nv Bu(t) be the average portion of v’s blue neighbors at time t.

First, we need to show that Yv(t) > τ holds for all v

0. For this purpose, we let τ ∗ > τ such that
Yv(0) > τ ∗ holds for all v
0. We observe that Yv(t) > τ ∗ holds in
a small time interval starting at time t = 0 because of the continuity of the Bv(t)’s with respect to t. Let t1 be the
ﬁrst time at which minv∈V Yv(t) = τ ∗, namely

V , and show that Yv(t) > τ ∗ holds for all t

V and t

P

≥

≥

∈

∈

t1 = inf

t : min
v∈V

(cid:26)

Yv(t) > τ ∗ for all t

[0, t)

∈

∈

V

.
(cid:27)

as follows.

We show t1 = +

∞
Suppose t1 < +

d(minv∈V Yv(t))
dt

. We claim that minv∈V Yv(t) is non-increasing in an interval starting at time t1; otherwise,
> 0 in a small interval starting at time t1 and minv Yv(t) > τ ∗ in the small interval, which contradicts

∞

the deﬁnition of t1.

Let V ∗ = arg minv∈V Yv(t1). For each v′

V ∗, we have

∈

d
dt 

1
deg(v′)

Bu(t)

Xu∈Nv′
dBu(t)
dt





(cid:12)
(cid:12)
t=t1
(cid:12)
(cid:12)
(cid:12)
(cid:12)


1
deg(v′)

1
deg(v′)

1
deg(v′)

=

=

≥

fRB(τ ∗)

τ ∗

−

= fRB(τ ∗)

τ ∗ > 0

Xu∈Nv′
−

Xu∈Nv′

fRB

(cid:18)

Xu∈Nv′ "

t=t1
(cid:12)
(cid:12)
(cid:12)
1
(cid:12)
deg(u)

Bw(t1)

(cid:19)

Bu(t1)

#

−

Xw∈Nu

owing to τ ∗ > τ . Hence, minv Yv(t) is strictly increasing in an interval starting at time t1. This contradicts that
minv∈V Yv(t) is non-increasing in an interval starting at time t1. The contradiction was caused by the assumption
t1 < +

. Therefore, we have t1 = +

.

∞

∞

Second, we need to show that minv∈V Bv(t) increases monotonically. Let Vt =

which may not be a singlet. For t = 0, the given initial condition
that for each v∗ ∈

V0, we have

1
deg(v)

P

,
u : Bu(t) = arg minv Bv(t)
}
{
V implies

u∈Nv Bu(0) > τ for all v

∈

dBv∗ (t)
dt

t=0
(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
deg(v∗)

= fRB 

1
deg(v∗)

>

Bu(0)



−

Bv∗ (0)

Xu∈Nv∗
Bu(0)


Bv∗ (0)

−

0

≥

Xu∈Nv∗
because fRB(s) > s for s > τ . This means that minv Bv(t) strictly increases in a small time interval starting at
t = 0.

Let t2 be the maximum time that minv Bv(t) keeps strictly increasing, namely

t : min
t2 = sup
{

v

Bv(t) strictly increases in [0, t)
.
}

31

We now show that t2 = +
However, for each v2 ∈

∞

Vt2, we have

. Suppose t2 < +

, meaning that minv Bv(t) is not strictly increasing at t = t2.

∞

dBv2(t)
dt

t=t2
(cid:12)
(cid:12)
(cid:12)
(cid:12)

= fRB 

1
deg(v2)

>

1
deg(v2)

Xu∈Nv2

Bu(t2)

Bv2(t2)

−



Xu∈Nv2
Bu(t2)


Bv2(t2)

−

0

≥

1
deg(v2)

because
at t = t2, which contradicts the deﬁnition of t2. Therefore, t2 = +
t

Bu(t2) > τ and fRB(s) > s for all s > τ . This implies that minv Bv(t) strictly increases
, namely minv Bv(t) strictly increases for all

u∈Nv2

P

∞

0.

≥

D Proof of Theorem 5

Proof We prove the ﬁrst part as the second part can be proved analogously. Lemma 2 shows that minv Bv(t)
monotonically increases, meaning that limt→∞ minv Bv(t) exists.
In order to show limt→∞ Bv(t) = 1 for all
V , it sufﬁces to show limt→∞ minv Bv(t) = 1. Suppose limt→∞ minv Bv(t) < 1. There are two cases, but
v
both cause contradictions as we elaborate below. Therefore, we have limt→∞ minv Bv(t) = 1.

∈

Case 1: τ < limt→∞ minv Bv(t) < 1.
There exist τ < τ1 < τ2 < 1 and T > 0 such that τ1 ≤

for all x
be the index set of arg minv Bv(t). For each v∗ ∈

∈

Vt, we have

[τ1, τ2] and is continuous, we can ﬁnd some δ > 0 such that fRB(x)

x > δ for all x

minv Bv(t)

τ2 for all t

T . Since fRB(x)

≤

≥

x > 0
−
[τ1, τ2]. Let Vt

∈

−

dBv∗(t)
dt

for all t > T . This leads to

1
deg(v∗)

= fRB 

fRB(Bv∗ (t))

≥

−

Bu(t)

Bv∗ (t)

−



Xu∈Nv∗
Bv∗ (t) > δ



(28)

min
v

Bv(t) > min

v

Bv(T ) + δ(t

T ).

−

Since minv Bv(T ) + δ(t

T )

+

as t

→
Case 2: limt→∞ minv Bv(t)
Let Vt be the index set of arg minv Bv(t). Since

→ ∞

∞
τ .

−

≤

δ′ > 0 such that for each v∗ ∈

Vt,

, this contradicts Bv(t)

1.

≤

1
deg(v)

u∈Nv Bu(t) > τ for all v and t, there exist T ′ > 0 and

P

1
deg(v∗)

fRB

(cid:18)

Bu(t)

(cid:19)

−

Xu∈Nv∗

Bv∗(t) > δ′

holds for all t > T ′. By the same argument as in Case 1, we can show limt→∞ minv Bv(t) = +
Bv(t)

1.

≤

, which contradicts

∞

32

E Proof of Theorem 7

Proof Part (i) can be seen by considering any perturbation near each equilibrium B∗. For these equilibria, we can
use linearization to analyze the convergence rates. Let B(t) = ([Bv(t)]v∈V )⊤, A be the adjacency matrix of G,
v=1), 1 = [1, . . . , 1]⊤, 0 = [0, . . . , 0]⊤, δB be the variation of B(t) near 1 or 0, In denote the
D = diag ([deg(v)]n
n-dimension identity matrix, z = 1 indicate that we are considering the convergence rate of stable equilibrium 1,
and z = 0 indicate that we are considering the convergence rate of stable equilibrium 0. Then, linearization leads to

dδB(t)
dt

=

f

′

RB(z)D−1A

(cid:20)

−

In

δB.

(cid:21)

The convergence rate is estimated by the largest real part of all eigenvalues of matrix f
largest eigenvalue of D−1A equals 1, the convergence rate is estimated as O(exp[(f
z = 1.

′

RB(z)

−

′

RB(z)D−1A

In. Since the
1)t] for both z = 0 and

−

For proving part (ii), suppose at equilibrium B∗ that B∗
V

n.
In other words, for any v
. For any ǫ > 0, it is always possible to ﬁnd a sufﬁciently small
0, 1
}
δB from a set of positive Lebesgue measures and impose a perturbation near B∗ while satisfying the following:
B∗∗ = B∗ + δB such that

vk = τ for vk ∈

v1, . . . , vr}
{

, where 1

V1, B∗

< ǫ and

v ∈ {

V1 =

≤

≤

≤

∈

k

\

r

δB
k

k

1
deg(v)
1
deg(v)

u∈Nv B∗∗
u∈Nv B∗∗

u > τ
u < τ

P




τ

if B∗
if B∗

v ≥
v < τ.

Let us treat B∗∗ as the initial security state at time t = 0. For any node v with B∗



P

v ≥

(29)

τ , we have

dBv(t)
dt

= fRB

t=0
(cid:12)
(cid:12)
(cid:12)
(cid:12)

>

(cid:18)
1
deg(v)

1
deg(v)

Xu∈Nv

B∗∗
u

B∗
v

−

Xu∈Nv
B∗∗

u −

(cid:19)
B∗∗

v ≥

0.

This means that there is a time interval [0, t0) in which for any node v with B∗
increases. For any node v with B∗
v < τ , we have

v ≥

τ , Bv(t) monotonically strictly

dBv(t)
dt

= fRB

t=0
(cid:12)
(cid:12)
(cid:12)
(cid:12)

<

(cid:18)
1
deg(v)

1
deg(v)

Xu∈Nv

B∗∗
u

B∗
v

−

Xu∈Nv
B∗∗

u −

(cid:19)
B∗∗

v ≤

0,

which means that the corresponding Bv(t)’s strictly decrease for a small time interval t
[0, t0). In summary,
for any small perturbation with (29) as the initial security state, Bv(t) leaves the equilibrium. Therefore, B∗ with
B∗

v = τ for some v is unstable.

∈

33

