2
2
0
2

g
u
A
5
2

]

R
C
.
s
c
[

1
v
4
4
1
2
1
.
8
0
2
2
:
v
i
X
r
a

Automatic Mapping of Unstructured Cyber Threat
Intelligence: An Experimental Study

(Practical Experience Report)

Vittorio Orbinato∗, Mariarosaria Barbaraci†, Roberto Natella∗, Domenico Cotroneo∗
∗DIETI, Universit`a degli Studi di Napoli Federico II, Naples, Italy
{vittorio.orbinato, roberto.natella, cotroneo}@unina.it
†University of Bern, Bern, Switzerland
mariarosaria.barbaraci@unibe.ch

Abstract—Proactive approaches to security, such as adversary
emulation, leverage information about threat actors and their
techniques (Cyber Threat Intelligence, CTI). However, most
CTI still comes in unstructured forms (i.e., natural language),
such as incident reports and leaked documents. To support
proactive security efforts, we present an experimental study
on the automatic classiﬁcation of unstructured CTI into attack
techniques using machine learning (ML). We contribute with
two new datasets for CTI analysis, and we evaluate several ML
models, including both traditional and deep learning-based ones.
We present several lessons learned about how ML can perform
at this task, which classiﬁers perform best and under which
conditions, which are the main causes of classiﬁcation errors,
and the challenges ahead for CTI analysis.

Index Terms—Cybersecurity, Cyber Threat

Intelligence,
MITRE ATT&CK, TTPs, Adversary Emulation, Natural Lan-
guage Processing, Machine Learning

I. INTRODUCTION

Addressing security issues of IT systems has become of
paramount importance for all kinds of businesses. Traditional
penetration testing alone, consisting mostly in identifying and
exploiting vulnerabilities, is becoming increasingly ineffective
[5]. Its exclusive focus on the ﬁrst steps of the cyber kill chain
[24] prevents analysts from deepening into post-compromise
scenarios, by analyzing what might happen in the post-
exploitation phases of an attack. In order to strengthen security,
organizations are considering “offensive security” strategies
based on adversary emulation [5], i.e., a proactive approach
that emulates attackers within an IT system for training and
evaluation purposes. Unfortunately, this approach comes with
a high cost, in terms of specialized personnel (“red teams”)
needed to emulate attackers, which limits its adoption.

In recent years, adversary emulation tools have been emerg-
ing as a promising solution to make security exercises easier
[8]. These tools automate the execution of individual, low-
level malicious actions, such as for credential stealing, lateral
movement, data exﬁltration, and more [4]. Despite this sup-
port, these tools still need to be programmed to orchestrate
multiple actions and to emulate the behaviors of a real attacker.
Therefore, adversary emulation exercises need to be guided
by Cyber Threat Intelligence (CTI), i.e., information on the

capabilities and intents of attackers, and on the techniques
adopted in their campaigns.

To support adversary emulation and other security activities,
the industry is currently investing efforts in standardizing
CTI, such as the STIX representation format [37] and the
TAXII sharing protocol [39]. However, most Cyber Threat
Intelligence still comes in unstructured forms (i.e., text in
natural language), such as incident reports written by security
analysts [18], [20], [47], and documents leaked by insiders
from attacker groups [6], [49], [50]. Therefore, converting CTI
into a structured form is still a missing step towards supporting
adversary emulation with automated tools.

In this work, we present a study on automatically extracting
CTI from unstructured sources, using machine learning tech-
niques for Natural Language Processing (NLP). We contribute
with two new datasets for CTI analysis, with samples of
CTI in natural
language text, which we labeled with the
corresponding adversarial techniques described in the text.
We based the labeling on the well-known MITRE ATT&CK
framework [12], which provides an extensive knowledge base
and classiﬁcation scheme of techniques used by most cyber
criminal groups. We also present an extensive experimental
analysis on classifying unstructured CTI into the corre-
sponding attack techniques, by using both traditional machine
learning algorithms, and more recent ones based on deep
learning.

From the experimental analysis, we derived some lessons
learned about the automatic mapping of unstructured CTI.
CTI mapping is a difﬁcult multi-class classiﬁcation problem,
since, at the time of writing, the ATT&CK framework de-
scribes 188 different attack techniques. Moreover, there is an
imbalance among the techniques, since some of them occur
much more frequently in real attacks. We found that only
few algorithms can achieve an accurate classiﬁcation, and
that algorithms based on deep learning can only achieve a
competitive accuracy when trained with our new extended
dataset. We also qualitatively analyzed classiﬁcation mistakes,
in order to identify the reasons for inaccuracies. We found
that applying classiﬁers on short
texts is prone to errors,
since descriptions can be ambiguous and can be equally apply

 
 
 
 
 
 
to multiple techniques. Finally, we observe that evaluating
ML techniques on descriptions of individual techniques can
be misleading. Therefore, we analyzed CTI documents as a
whole, which span multiple techniques adopted in the same
campaign, and which contain more noise due to sentences not
strictly related to attack techniques. We found that indeed ML
models perform differently in the document-level evaluation
compared to the sentence-level evaluation, and that deep
learning techniques can achieve better results in this scenario.
The paper is structured as follows: Section II provides
background and a motivating example; Section III illustrates
the experimental process of this work; Section IV and V
present the experimental results, respectively on sentence-level
and document-level datasets; Section VI analyzes the lessons
learned; Section VII discusses related work; and Section IX
draws the conclusion and points out some directions for future
work.

II. BACKGROUND AND MOTIVATING EXAMPLE

The planning and execution of adversary emulation exer-
cises are expensive activities, in terms of skills and man-hours
to invest. They include teaming as well as other activities: sce-
nario deﬁnition, monitoring, and results evaluation. Adversary
emulation is composed by a set of activities which can be split
into two macro-phases: Attack modeling and Attack emulation.
Attack modeling. This phase concerns Cyber Threat Intelli-
gence and it gathers information on the threats and attacks
to emulate. A signiﬁcant effort is required to gather these
documents, because of their heterogeneous nature and sources.
It is then necessary to analyze and systematize this data, so
as to map an attack onto a set of operational steps, in order
to deﬁne an execution ﬂow for the emulation exercise. To this
goal, many cybersecurity frameworks provide taxonomies of
attack tactics, techniques, and procedures (TTPs), with MITRE
ATT&CK [12] rapidly becoming the de facto standard in the
cybersecurity landscape. All the activities required by this
phase are currently performed by human operators, hence the
need for highly specialized personnel.

As an example, we will refer to the FIN6 APT [13],
analyzed and documented by the Center for Threat-Informed
Defense (CTID) [19]. FIN6 is a ﬁnancially motivated cyber-
criminal group, whose activities can be traced back to 2015
[14]. To identify their activities and describe their modus
operandi, CTID collected and analyzed several threat reports
from different organizations, such as VISA [53], FireEye [20],
and Security Intelligence [46]. FIN6’s activities were mapped
to MITRE ATT&CK techniques, and divided into Enabling
[15] and Operational [16] objectives, whose operational steps
are shown in Figure 1. Their ﬁrst tactical objective is Initial
Access, which identiﬁes potential targets to be exploited, by
means of legitimate stolen user credentials (T10781 [41]) and
spearﬁshing (T1566 [34]) (step 1 in Figure 1). After a host
has been compromised, and command and control (C2) is
established, FIN6 conducts internal reconnaissance, so as to

1Txxxx indicates a technique from the MITRE ATT&CK framework

ﬁnd opportunities for privilege escalation, lateral movement
and exﬁltration in the second phase. This step relies on tech-
niques for Account Discovery (T1087 [27]), Remote System
Discovery (T1018 [36]), and System Network Conﬁguration
Discovery (T1016 [38]) (step 2 ). The next objective is Priv-
ilege Escalation: for this purpose, FIN6 leverages credential
dumping (T1003 [33]) and access token manipulation (T1134
[26]) (step 3 ), and copies the Active Directory database
ﬁle (T1003.003 [32]) in the Windows domain (step 4 ). The
last step of this phase is the exﬁltration of credentials in a
compressed format (T1560.001 [28]), over SSH as well as
other channels (T1048 [31]) (step 5 ). In particular, FIN6
targets operational payment servers to inject malicious code
(T1055 [35]) (step 6 ). Finally, the attack exﬁltrates stolen
data towards a remote server, using DNS tunneling (T1048
[31]) (step 7 ).
Attack emulation. The second macro-phase of adversary
emulation is the operational execution of the attack, leveraging
the information provided by the previous phase. The attack
techniques need to be associated with an implementation,
provided by speciﬁc threat emulator tools. Among these em-
ulators, MITRE CALDERA [5], [29] is the most prominent
one, as it is designed for orchestrating complex attacks that
consist of multiple techniques. A threat emulator needs to
be conﬁgured before running a simulation: we will refer to
CALDERA to describe the necessary steps. First of all, it is
necessary to setup the Command and Control server, which
will coordinate the simulations. The next step is to deploy the
remote agent on the target machine: an agent is a software
program which connects to the C2 server via a predeﬁned
contact method [30]. The C2 server will be responsible for
sending the instructions to the agents. Once the agent has been
deployed, it is possible to choose the adversary proﬁle for the
simulation. A proﬁle is a group of abilities that includes the
attack techniques typically used by a speciﬁc attacker [30].

In the case of FIN6, a new adversary proﬁle for CALDERA
needs to be conﬁgured, by combining multiple techniques from
CALDERA into an orchestrated attack. Therefore, the emula-
tion of an attack relies on accurate planning of adversarial
activities, which is currently performed by human operators.
To overcome this issue, it is useful to automate the analysis
of CTI, by extracting adversary techniques and mapping them
to a standard taxonomy (e.g., MITRE ATT&CK) to feed the
emulation tool.

III. METHODOLOGY

In this section, we present the workﬂow of our experimental
approach. Since our goal
is to ﬁt CTI into a ﬁnite set
of categories (i.e., ATT&CK techniques), we address this
problem as a classiﬁcation machine learning task. Therefore,
we build datasets to train and to evaluate machine learn-
ing algorithms, and perform several experiments on multiple
classiﬁcation techniques. Our experimental approach revolves
around three phases: Dataset Construction, Pre-processing,
and Classiﬁcation, shown in Figure 2. The outcome will be
a ML model ready to be used for the mapping of natural

campaigns, and other indicators of compromise (IOCs). These
elements are represented as nodes (Domain Objects) in a
graph, and are connected by links (Relationship Objects)
to represent related concepts (e.g., a malware campaign is
linked to its IOCs). These objects include attributes, such as
a unique ID, a name and a description in natural language,
and references to external documents with more information
(e.g., online incident reports, and other attack taxonomies such
as Common Attack Pattern Enumerations and Classiﬁcations
(CAPEC) [11]).

In the ﬁrst step of our process, we parsed the knowledge
base in STIX format. In particular, we extracted information
from the attack pattern objects, which represent attack tech-
niques from the MITRE ATT&CK framework, and which
include a general description of the technique in natural
language. Moreover, we extracted the links (i.e., Relationship
Objects) between the attack patterns and the threat actors
and campaigns that adopted them (e.g., Intrusion Set objects).
These Relationship Objects include an additional description
of the technique, in the context of a speciﬁc attack. Finally,
in the case of attack pattern objects that provide external
references to the CAPEC taxonomy, we used these references
to obtain more descriptions from CAPEC (also available in
STIX format) about the attack techniques.

The subsequent step in our approach was cleaning the
enriched data by removing all the unnecessary information,
such as empty lines, and links and references to external
sources. After cleaning the data, we proceeded with Text
Tokenization: the text was tokenized at sentence-level using
the Natural Language Toolkit (NLTK) [7] sentence tokenizer.
Finally, we tied all this information together to deﬁne the
dataset. Each entry contains the following data: ATT&CK
technique ID, name, and a description of the technique in
natural language, as shown in Table II.

We release the dataset as open data2. The extent of the
resulting dataset is reported in Table I. All 188 techniques in
the MITRE ATT&CK framework were covered. Each tech-
nique can appear in the dataset multiple times with different
descriptions, as a technique may have been adopted in multiple
attack campaigns, even if in different ways. Each sample
describes a technique with one or multiple sentences. In total,
12,945 samples were included.

TABLE I
DATASET OF CTI SAMPLES IN NUMBERS.

Categories
Samples
Unique words
Total # of words

188
12,945
7,881
193,453

Once the dataset has been built, it needs to be pre-processed.
The Pre-processing phase encompasses different steps de-
pending on the type of the machine learning model. For
traditional machine learning (ML) models, this phase starts

2https://github.com/dessertlab/cti-to-mitre-with-nlp

Fig. 1: FIN6 Operational Steps.

language documents into the corresponding techniques of the
MITRE ATT&CK framework.

Fig. 2: Experimental approach.

In the Dataset Construction, we built a new dataset,
which consists of (unstructured) descriptions of adversarial
techniques in natural language. Each sample in the dataset
describes one malicious technique, and has been annotated
with a label,
i.e., a technique from the taxonomy of the
MITRE ATT&CK framework. We built the dataset using the
public knowledge base of the MITRE ATT&CK framework.
This knowledge base provides detailed descriptions in natural
language of several threat actors and their malware campaigns.
These descriptions are also mapped to MITRE ATT&CK in a
structured way. Therefore, we built the dataset by extracting
both descriptions and their mappings to MITRE ATT&CK.
In particular, we analyzed the knowledge base as released by
MITRE using the Structured Threat Information eXpression
(STIX) language [17].

STIX is a representation of CTI as serializable JSON. It
describes cyber threats using an extensive set of elements,
including: cybercriminal groups, their campaigns and targeted
sectors and companies,
their
software tools, and any related artifacts, such as hash values
of malicious executables, IPs and domains involved in their

their targeted vulnerabilities,

Text Description

Technique

Sub-technique

Sub-technique name

TABLE II
EXAMPLE OF DATASET ENTRIES.

Hydraq creates a backdoor through which remote at-
tackers can adjust token privileges

XCSSET attempts to discover accounts from various
locations such as a user’s Evernote, AppleID, Telegram,
Skype, and WeChat data

PoisonIvy creates a Registry key in the Active Setup
pointing to a malicious executable

BADNEWS can use multiple C2 channels, including
RSS feeds, Github, forums, and blogs

Hildegard has searched for SSH keys, Docker creden-
tials, and Kubernetes service tokens

Kobalos can write captured SSH connection credentials
to a ﬁle under the /var/run directory with a .pid exten-
sion for exﬁltration

TEARDROP was decoded using a custom rolling XOR
algorithm to execute a customized Cobalt Strike payload

It has also disabled Windows Defender’s Real-Time
Monitoring feature and attempted to disable endpoint
protection services

APT29 has exﬁltrated collected data over a simple
HTTPS request to a password-protected archive staged
on a victim’s OWA servers

T1134

T1087

T1547

T1102

T1552

T1074

T1140

T1562

T1048

T1134

T1087

Access Token Manipulation

Account Discovery

T1547.014

Active Setup

T1102.002

Bidirectional Communication

T1552.001

Credentials In Files

T1074

T1140

Data Staged

Deobfuscate/Decode Files or
Information

T1562.001

Disable or Modify Tools

T1048.002

Exﬁltration Over Asymmetric
Encrypted Non-C2 Protocol

with Stopwords Removal. The following step is Stemming
and Lemmatization: stemming consists in removing all the
preﬁxes/sufﬁxes from the words, while lemmatization links all
the inﬂected words to the corresponding lemma (e.g., exploits
and exploiting are both linked to the lemma exploit). The
last step of this phase concerns the Text Representation: the
information contained in a sentence is converted to a bag of
words, with each sentence encoded as a one-hot vector. Using
bags of words results in large feature vectors: this may cause
loss of the word context and position inside the sentence. In
a large corpus, it is common to have more frequent words,
related to language patterns, that do not bring useful features
to the classiﬁer and less frequent yet informative words. To
balance the representation, we can apply Term-Frequency
Inverse Document-Frequency (TF–IDF) term weighting to
transform count features into ﬂoating point values, preserving
meaningful but rarer information present in the entire corpus.
On the contrary, for neural network models, the pre-processing
phase consists of representing text with word embeddings: this
type of representation encodes each word taking the context
into account. In this way, it is possible to deﬁne the similarity
between two words, by means of their distance.

After this step,

the data is ready for classiﬁcation. We

consider several classiﬁcation models, among two sets:

• Traditional ML models. This set includes well-studied
classiﬁers used for NLP tasks since decades, including:
Naive Bayes, Logistic Regression, Support Vector Ma-
chines (SVM), and Multi-Layer Perceptron (MLP);

• Deep Neural Networks. Following the latest develop-
ments in NLP research, we consider recent classiﬁers

based on complex neural network architectures, includ-
ing: Recurrent Neural Networks (RNN),
in particular
Long Short-Term Memory (LSTM), Convolutional Neu-
ral Networks (CNN), and Transformers [52].

In particular, among the deep learning-based classiﬁers, the
Transformer architecture represents the most recent advance-
ment in the ﬁeld of NLP research. It introduces the self-
attention mechanism, which weights the tokens of the input
data according to their importance. Therefore, we also build
a classiﬁer using SecureBERT, a Language Model (LM) pre-
trained on cybersecurity terms [2]. It is based on BERT, a
multi-layer bidirectional Transformer encoder, composed of
12 layers (transformer blocks), 12 attention heads, and 110
million parameters in its base version. Generally pre-trained
on Masked Language Modeling (MLM) and Next Sentence
Prediction (NSP) tasks, SecureBERT presents only a MLM
head layer.

Our attack classiﬁcation problem poses some challenges to
ML classiﬁers. Since we deal with a large number of different
classes (i.e., the 188 MITRE ATT&CK techniques), we are
addressing a multi-class classiﬁcation problem with a quite
large number of categories. It is worth mentioning that text
classiﬁcation problems are usually binary, or have a few cate-
gories (typically around 10). Moreover, we also observed that
the attack data is quite imbalanced: the majority class is the
Command and Scripting Interpreter (T1059) technique, which
is represented by 698 occurrences, while the minority class is
Cloud Service Dashboard (T1538), which occurs only 4 times.
The different frequencies of the techniques reﬂect their actual
adoption by threat actors, and their time of introduction in

the ATT&CK Framework, as recent techniques tend to be less
represented. These challenges motivate our experimental study
on ML classiﬁers for the problem of mapping CTI, in order
to identify their relative strengths and limitations.

IV. EXPERIMENTAL EVALUATION WITH
CROSS-VALIDATION

In this section, we perform a preliminary evaluation on
the dataset itself, by adopting a cross-validation approach. In
the following, we elaborate on the evaluation methods and
experimental results.

ATT&CK techniques from unstructured text, similarly to our
work. At the time of writing, the TRAM project only supports
three classiﬁers (Multinomial Naive Bayes, a basic Logistic
Regression model, and MLP), and no systematic experimental
evaluation has yet been reported in the scientiﬁc literature.
Moreover, the TRAM project only provides a limited dataset
of CTI-to-ATT&CK mappings, which only covers 80 attack
techniques with more than 1 sample, with a total of 1, 482
samples of attack descriptions. In this work, we consider a
wider set of ML algorithms, and we introduce a new, larger
dataset for the evaluation.

A. Evaluation metrics and baseline

B. Model Training

In order to compare the performance of the classiﬁcation
models, we considered four different metrics. Before introduc-
ing metrics, we brieﬂy recap some key concepts: True Positives
(TP) and True Negatives (TN) represent a correct prediction
made by the classiﬁer, respectively for positive and negative
classes, thus the predicted label matches the actual one. On
the other hand, False Positives (FP) and False Negatives (FN)
respectively represent an entry from a positive/negative class
that has been incorrectly classiﬁed. Based on these deﬁnitions,
we analyze the following metrics for multi-class classiﬁcation
[21]: precision is the number of correct positive predictions
(TP) divided by the total number of positive predictions (TP
+ FP) made by the model, while recall is the number of true
positives (TP) divided by the total number of positive instances
(TP + FN). Precision indicates how much the model can be
trusted when it predicts an instance as positive, and recall
shows the ability of the model to ﬁnd all the positive instances
in the dataset.

precision =

T P
T P + F P

recall =

T P
T P + F N

Given the imbalanced nature of our dataset and the skewed
distribution of classes, we considered the F-Measure statistic
instead of the accuracy. Also known as F1-Score, The F-
Measure is the armonic mean of precision and recall, and tells
us how well the model is able to classify all classes, including
minority ones.

F -M easure = 2 ·

precision · recall
precision + recall

In some use cases, the ML models could be used as a rec-
ommender, to suggest to the analyst a set of candidate attack
mappings (instead of providing only one “hard” prediction).
Therefore, as the last metric, we analyzed the top K accuracy
(AC@K), with K equal to 3: it indicates how likely the correct
class is ranked in the top 3 predictions. We considered the
weighted version of these metrics, so as to take into account
the frequency of each class.

As baseline for our evaluation, we consider the Threat
Report ATT&CK Mapping project (TRAM) [40], an open
source platform developed by the CTID. This platform maps

We developed the processing pipeline using the SKLearn
Library [9], [44], which provides several resources for ML.
The hyper-parameters of the models were tuned according to
the imbalance of our dataset. In a preliminary data analysis,
we noticed that the vocabulary included about 7,800 unique
words, resulting in very large features vectors. As explained in
Section III, we applied traditional NLP pre-processing steps:
stemming, lemmatization and stopwords removal. Then, we
used TFIDFVectorizer, based on TF-IDF statistic, to obtain a
numerical representation of the text, reﬂecting the importance
of each word in the corpus. Besides, we set the ngram range to
(1, 2), to extract both unigrams and bigrams, and max features
to 10, 000.

For the Naive Bayes and Logistic Regression models, we
presented two different versions: the LogisticRegression with
the class weight parameter set to balanced and the Com-
plementNaiveBayes, which take into account the imbalanced
representation of classes, and the basic library version of
LogisticRegression and MultinomialNaiveBayes. For SVM,
we consider both the case of One versus One (OvO), which
trains n(n − 1)/2 binary classiﬁers to split a multi-class
classiﬁcation into multiple binary classiﬁcation problems; and
One versus the Rest (OvR), which instantiates n classiﬁers
to classify a sample between a single category versus all of
the other choices united. We chose a linear kernel and set
the class weight parameter to balanced for both of them.
Finally, for MLP, we used the model provided by SKLearn,
by setting up the maximum number of iterations for the
learning algorithm and the early stopping parameter to prevent
overﬁtting.

the ﬁrst

For the deep learning models, we leveraged the Keras
library [10]. We focused on both RNN and CNN models,
using word embeddings as text representation. In these mod-
els,
layer transforms words into their equivalent
embedding vectors: each sentence has been previously split
into tokens and subsequently padded or truncated to meet
a maximum length constraint. We chose to implement the
LSTM architecture, a RNN model commonly used for text
processing tasks. The hyper-parameters setup for the LSTM
layer were: 150 for the number of units, deﬁning the output
dimension, and 0.2 for the dropout parameter, useful to prevent
overﬁtting. Furthermore, we added a slightly different version
initializes the embedding layer with a
of this model

that

pre-trained cybersecurity-speciﬁc Word2vec model [42]. This
model provides a word representation with a hundred size
vectors: we extended its vocabulary and retrained the model
with an incremental approach to add new words.

On the other hand, for the CNN, we set up a single layer
composed of 256 ﬁlters to extract features and a convolution
window of 5, followed by a Global Max Pooling layer. Both
models present a ﬁnal fully connected layer of 188 units for
the classiﬁcation task. To avoid overﬁtting, we took advantage
of Keras EarlyStopping callback to automatically deﬁne the
number of epochs during the training of the models. The batch
size was set to 64, while the validation-set percentage to 0.1.
Finally, we built a classiﬁer based on Transformers, by
means of the transfer learning technique and the pre-trained
SecureBERT model [2] [1]. Leveraging the Hugging Face [54]
Framework and the Pytorch [43] library, we ﬁne-tuned the
model on our dataset and re-trained it with a very low learning
rate, 1e − 05, so as to adapt pre-trained features to our data.
SecureBERT presents a BERT core followed by a MLM head
layer. We extracted the pre-trained BERT core and built a
classiﬁer on top of that adding two layers: a dropout layer,
with a fraction of 0.3, to prevent overﬁtting, and linear layer
for the classiﬁcation into 188 different categories. We set the
batch size to 16 and the number of epochs to 10.

To train each model, the data set was split into two parts:
80% for the training set and 20% for the test set. We used a
stratiﬁed split to preserve the same proportion of examples in
both the training and test sets.

C. Results

We ﬁrst consider the results obtained from our dataset,
presented in Table III. The best result is achieved by Se-
cureBERT, according to both F-Measure and AC@3, followed
respectively by MLP and the OVR version of the SVM model.
For both Naive Bayes and Logistic Regression models we
presented the results of multiple variants, as discussed in
Section IV-B. The aim of this choice was to demonstrate how
the models showed better results when taking the frequency of
each class into account. As far as SVM models are concerned,
we notice that there is no signiﬁcant difference between the
performance of the OvO and OvR strategies. This result
supports the choice of the OvR strategy instead of the OvO
one, since it constructs a linear number of classiﬁers rather
than a quadratic one. SVM show good results both in the case
of F-Measure and top K accuracy. These values are very close
to the top ranking model for both these metrics. The other DL-
based classiﬁers did not match the traditional ML algorithms’
performance, as we observed a 10% gap among them. It is
worth noting that the LSTM model performed slightly better
when the embedding layer was initialized with the pre-trained
cybersecurity Word2vec weights.

We then evaluated the ML algorithms using the dataset
from the TRAM project. The comparison with the TRAM
project serves as a baseline for the evaluation, and provides
evidence of the industry’s interest in the problem addressed by
this work. The TRAM dataset comes with a smaller absolute

TABLE III
EVALUATION OF THE RESULTS IN OUR DATASET.

Models

Complement
Naive Bayes

Multinomial
Naive Bayes

Logistic
Regression

Logistic
Regression
(balanced)

SVM (OvO)

SVM (OvR)

MLP

LSTM

LSTM
(Word2vec)

CNN

SecureBERT

Metrics

F-Measure

Precision

Recall

AC@3

63.9%

65.9%

66.3%

66.6%

36.8%

49.2%

41.5%

20.2%

55.6%

59.1%

60.5%

43.6%

64.6%

69.3%

64.5%

79.6%

69.9%

69.9%

70.4%

57.7%

71.8%

71.8%

71.9%

59.1%

70.2%

77.2%

70.2%

77.3%

71.6%

77.3%

58.5 % 54.7%

61.0%

62.2%

62.3%

64.4%

61.4%

72.5%

63.0%

72.5%

62.7%

59.5%

72.5%

86.9%

TABLE IV
EVALUATION OF THE RESULTS IN THE TRAM DATASET.

Models

Complement
Naive Bayes

Multinomial
Naive Bayes

Logistic
Regression

Logistic
Regression
(balanced)

SVM (OvO)

SVM (OvR)

MLP

LSTM

LSTM
(Word2vec)

CNN

SecureBERT

Metrics

F-Measure

Precision

Recall

AC@3

53.7%

59.1%

61.6% 57.0%

23.5%

29.6%

31.9% 16.7%

40.9%

50.6%

46.4% 31.0%

57.7%

66.8%

58.9% 65.2%

60.9%

60.9%

50.5%

34.3%

63.8%

63.8%

56.0%

36.0%

64.6% 44.0%

64.6% 42.6%

54.2% 42.0%

36.3% 32.4%

36.5%

37.2%

39.7% 40.2%

42.4%

52.5%

42.1%

52.5%

47.1% 38.5%

52.5% 68.6%

TABLE V
EVALUATION OF RESULTS IN MIXED DATASET, OURS COMBINED WITH
TRAM.

of memory occupancy.

D. Qualitative Error Analysis

Models

Complement
Naive Bayes

Multinomial
Naive Bayes

Logistic
Regression

Logistic
Regression
(balanced)

SVM (OvO)

SVM (OvR)

MLP

LSTM

LSTM
(Word2vec)

CNN

SecureBERT

Metrics

F-Measure

Precision

Recall

AC@3

62.3%

64.0%

64.8% 63.2%

36.5%

50.5%

41.3% 36.5%

56.8%

60.0%

61.2% 42.2%

64.2%

68.6%

63.9% 79.6%

68.5%

68.5%

68.9%

57.3%

70.3%

70.3%

69.8%

58.6%

69.0% 73.1%

69.0% 73.0%

70.0% 69.9%

58.2% 52.9%

59.8%

60.4%

61.0% 59.8%

62.4%

71.6%

62.7%

71.6%

64.1% 58.0%

71.6% 86.1%

number of samples compared to our proposed dataset. As
we can observe from the metrics in Table IV, the poorest
performance is achieved by the DL-based models, which adopt
word embeddings to represent text, and which beneﬁt from
large training datasets. These models are penalized when
evaluated on the smaller TRAM dataset, which contains a
lower number of sample sentences compared to our dataset.
Similarly, while maintaining the best ranking for AC@3,
SecureBERT is outperformed by the SVM classiﬁer in terms of
F-Measure. Traditional models, which use BoW, show better
results: the SVM model is the best model according to the
F-Measure, while Logistic Regression is the one with the best
trade-off between F-Measure and AC@3.

To complete our evaluation, we combined the TRAM
dataset with ours. Table V shows the results of the clas-
siﬁcation for the extended dataset. SecureBERT, as for the
evaluation on our dataset, remains the best model, providing
the best score in both F-Measure and AC@3. The majority
of the traditional models continue to provide good results: the
balanced Logistic Regression model outperforms all the other
ones scoring as the second best for the AC@3, while MLP has
the second higher F-Measure. The performance is comparable
with the ﬁrst analysis, with a small decrease of the metrics as
an artifact of the cross-validation process, and due to a higher
variety of data in the combined dataset.

Although the performance of the classiﬁer based on Se-
cureBERT is surely promising and provides good results, it
is worth mentioning that this ML model, based on the Trans-
former architecture, needs a longer training process, leveraging
GPU power to handle a greater number of parameters. In
the end, the resulting model is far more complex in terms

Considering the promising results obtained from the pre-
vious analysis, we qualitatively analyzed mispredictions, to
evaluate how far they were from the choices of a human ana-
lyst. Following the intuition that the DL-based classiﬁers could
be the ones worth deepening for further improvements, we
collected all of CNN predictions on the test set. We manually
analyzed several cases of misprediction: a representative subset
is reported in Table VI. In the ﬁrst sample, the actual technique
refers to an attacker’s intervention in the system conﬁguration
to start a certain malicious program at startup. The predicted
class is about the opponent’s intervention on the Windows
registry to hide a malicious conﬁguration. The predicted action
is implied by the correct one, because autostart execution
for persistence is achieved by means of a Registry Key
modiﬁcation. In the second sample in the table, the classiﬁer
was mistaken in reverse, making a wrong prediction due to
the Registry Key being mentioned in the description. We also
observed that about the 46% of mispredictions belong to the
same tactic of the correct technique, such as in the third sample
in Table VI, where both labels are related to the Exﬁltration
tactic of MITRE ATT&CK. In these cases, the ML model was
still able to extract relevant information about the goal of an
attack technique. In light of the difﬁculty of our classiﬁcation
task (i.e., identifying an attack technique among a very large
set of techniques), this is a relevant result. We also found
that several sentences are ambiguously worded and could be
correctly mapped to multiple ATT&CK techniques, even by a
human analyst. The fourth, ﬁfth, and sixth example in Table VI
could potentially be associated with both the predicted and the
actual label. In the last example, the description seems more
likely related to the predicted label rather than the actual one.
In conclusion, we saw how difﬁcult is to precisely evaluate the
effectiveness of the prediction made by the classiﬁer based on
a single phrase. From here, the necessity to conduct a more
thorough evaluation, based on real-world CTI documents.

V. EXPERIMENTAL EVALUATION ON CTI DOCUMENTS

In the previous evaluation, we used ML models to classify
short descriptions of the ATT&CK techniques in natural
language. The sample were short sentences about a technique
engaged by an attacker. Nevertheless, in a real-world sce-
nario, a human cybersecurity analysts deals with entire CTI
documents, instead of individual sentences and techniques. In
this case, the description in natural language spans all of the
multiple techniques adopted in an attack campaign. For these
reasons, we performed a document-level analysis, in which
we would like to observe how many ATT&CK techniques the
classiﬁers are able to identify from a document. In this case,
the output of the ML model is a set of techniques. In the
previous case, every sample described exactly one ATT&CK
technique. We do not focus on mapping individual sentences to
techniques; instead, we evaluate how many of the techniques

TABLE VI
EXAMPLES OF MISPREDICTIONS.

Text to Evaluate

SharpStage has the ability to create persistence for the
malware using the Registry autorun key and startup
folder.

Actual
Technique

T1547

Predicted
Technique

T1112

Actual Name

Predicted Name

Boot or Logon Autostart
Execution

Modify Registry

Stuxnet can create registry keys to load driver ﬁles.

T1112

T1547

Modify Registry

Boot or Logon Autostart
Execution

A Gamaredon Group ﬁle stealer can transfer collected
ﬁles to a hardcoded C2 server.

However, an adversary may hijack the syscall interface
code stubs mapped into a process from the vdso shared
object to execute syscalls to open and map a malicious
shared object.

FIN6 has used has used Metasploit’s named-pipe im-
personation technique to escalate privileges.

APT29 added their own devices as allowed IDs for
active sync using Set-CASMailbox, allowing it to obtain
copies of victim mailboxes.

Sowbug identiﬁed and extracted all Word documents
on a server by using a command containing *.doc and
*.docx.

T1041

T1055

T1134

T1098

T1020

Exﬁltration Over C2 Channel

Automated Exﬁltration

T1569

Process Injection

System Services

T1036

Access Token Manipulation

Masquerading

T1210

Account Manipulation

Exploitation of Remote
Services

T1083

T1119

File and Directory Discovery

Automated Collection

TABLE VII
DATASET OF WHOLE DOCUMENTS WITH CYBER THREAT INTELLIGENCE.

Threat

Reference

# Techniques

# Sentences

Follow The Money: Dissecting the Operations of
the Cyber Crime Group FIN6

Pick-Six-Intercepting a FIN6 Intrusion, an Actor
Recently Tied to Ryuk and LockerGoga Ran-
somware

MenuPass: Japan-Linked Organizations Targeted
in Long-Running and Sophisticated Attack Cam-
paign

MenuPass: United States v. Zhu Hua Indictment

WizardSpider: Ransomware Activity Targeting
the Healthcare and Public Health Sector

WizardSpider: Ryuk’s Return

[20]

[25]

[47]

[51]

[18]

[48]

17

50

32

23

99

72

81

101

73

46

275

76

presented in the document were correctly identiﬁed by the
model.

We built an additional new dataset for this evaluation.
For each document describing a threat actor or attack, we
identiﬁed a list of ATT&CK techniques engaged in it. The
documents were collected from the knowledge base of the
MITRE ATT&CK framework. ATT&CK documents notorious
malware campaigns and threat groups, by structuring infor-
mation from incident reports and from cybersecurity experts.
These sources typically provide a broad description of real
attacks, including a general introduction, a description of the
targeted industry sector, the general methodology of the threat
actors, the technical information about attack techniques, and
the suggested mitigations against the threat.

Differing from the ﬁrst dataset (in which we looked at
descriptions of individual techniques), in this case we fol-

lowed references from the MITRE ATT&CK to external
information sources, and collected these sources as documents.
Detailed information is provided in Table VII: threat-related
articles/reports, number of techniques described in them, and
total number of sentences within each source. From the
MITRE ATT&CK knowledge base, we also derived for each
document a “ground-truth” vector of techniques presented in
the document. Then, we evaluated how many techniques our
models are able to correctly predict, and the percentage of
correct prediction overall.

To leverage ML models to identify multiple techniques from
a document, we applied a threshold on the outputs of the
classiﬁer, i.e., a vector of probabilities, with one probability
value for each ATT&CK technique. If the probability exceeds
the threshold, we include the corresponding technique in the
set of ATT&CK techniques chosen for the document. This

(a) FIN6 [20]

(b) FIN6 [25]

(c) MenuPass [51]

(d) MenuPass [47]

(e) WizardSpider [18]

(f) WizardSpider [48]

Fig. 3: Document-level evaluation

approach also allows the ML model to distinguish between
pertinent and non-pertinent sentences in the document (i.e.,
sentences not related to any technique), since a document
typically includes sentences that are not strictly related to
attack patterns. Finally, we use the predictions to compute
metrics (precision, recall, and F-measure) in order to compare
the results of different ML models. For this type of analysis,
we deﬁned precision as:

NCU
NU
where NCU represents, given a classiﬁer and a document,
the number of unique techniques correctly predicted by the
classiﬁer (i.e., regardless of how many times the techniques
are detected across the sentences of the document), and NU
indicates the total number of unique techniques predicted.
Similarly, recall was deﬁned as:

NCU
NGT
where NCU is the same number used to compute the precision,
and NGT represents, for each document, the number of unique
techniques in the ground truth.

Figure 3 shows the results of our analysis. Given a docu-
ment, we reported the value of F-measure for each classiﬁer,
for values of the threshold from 0.1 to 0.8, with a 0.1 step.
As expected, the results tend to be worse for higher values
of the threshold, due to the fact that a smaller number of
predictions is accepted. Indeed, the highest accuracy is reached
with lower values of the threshold, with 0.2 emerging as
the best value for it. Intuitively, since the probability is split

among all of 188 techniques, a 0.2 probability for a given
technique would be much higher than the other 187 ones.
Overall, it is possible to notice that the DL models achieve
better performance than the traditional ML models. The results
of this analysis are lower than the sentence-level evaluation of
the previous section. This can be traced back to the nature of
the documents, which describe a large number of ATT&CK
techniques. Moreover, in a given document, the number of
sentences that actually describe the techniques is usually lower
than the number of non-pertinent ones. However, the average
of F-measure achieved by the models is around 50%: this is
a good starting point to help a human operator who needs to
analyze one or more documents, because the models will be
capable of identifying at least half the techniques described in
it.

VI. LESSONS LEARNED

In the experimental study, we investigated the use of
machine learning to automatically classify unstructured CTI
into the corresponding attack techniques from the MITRE
ATT&CK framework. The successes and open issues found
in this study provide us with several
lessons learned, as
summarized in the following.

Applicability of ML for mapping unstructured CTI to
attack techniques. NLP to analyze unstructured text is a
common procedure both in research and in the industry
sector. The range of applicability of NLP is widening to
different domains, including Cybersecurity in recent work. The
experimental results provided by the ﬁrst analysis with cross-
validation support the idea that ML is indeed applicable on

Cybersecurity documents. The classiﬁers achieved an accuracy
(in terms of F-Measure) up to 72%, even when challenged by
a large set of classes (188 MITRE ATT&CK techniques). This
is a relevant result, since multi-class classiﬁcation is a difﬁcult
task. Moreover, the ambiguity in natural language, as well as
the ambiguity between classes (as discussed in Section IV-D)
makes this problem even more challenging for ML algorithms,
and poses challenges for their experimental evaluation, also.
Even if the practical adoption of these techniques seems
feasible, further improvements are still required. In this work,
we aim to lay the groundwork for developing new solutions
for analyzing unstructured CTI, by providing new datasets, an
evaluation methodology, and baseline results for comparisons.

Selecting a ML algorithm. From the initial analysis, we
gained information on the performance of several different
classiﬁers, spanning from traditional to deep learning-based
ones. The best one has been SecureBERT, followed by MLP,
SVM, Logistic Regression, and CNN. In particular, the analy-
sis on several datasets of different sizes (i.e., TRAM and our
own new dataset) suggests that deep learning-based models,
such as CNN, have the potential to improve their accuracy
when trained with larger datasets. This ﬁnding is conﬁrmed in
the document-level analysis, where we found that traditional,
well-known ML models, such as Logistic Regression and
Naive Bayes, perform poorly compared to the others.

real-world

classiﬁcation

Applying
documents.
on
Document-level evaluation provides a different point of
view on the performance of ML algorithms. In this scenario,
we deal with large unstructured texts that describe campaigns
with several attack techniques, and that include additional
non-pertinent sentences. Due to these additional challenges,
the classiﬁcation accuracy was generally lower compared to
the previous sentence-level evaluation. Moreover, we found
traditional ML algorithms were less accurate
that several
than the deep learning-based ones:
this result points out
that sentence-level evaluation is not sufﬁcient for a thorough
evaluation, since it can lead to over-optimistic results. Finally,
our sensitivity analysis showed that
the best accuracy is
achieved when low values of the threshold are used to select
output classes. Indeed, the best value for the threshold turned
out to be 0.2. Calibrating this threshold is important, since the
classiﬁer needs to deal with sentences that describe multiple
attack techniques, and with other ones that do not include
any technique.

VII. RELATED WORK

The automated analysis of Cyber Threat Intelligence is
a recent and active research area in the cybersecurity ﬁeld.
TIM [55] is a framework that mines information about attack
techniques from unstructured CTI using the Threat Context
Enhanced Network (TCENet), a custom model developed for
this task. It performs a coarse-grained analysis, by categorizing
CTI into only 6 categories: Phishing, Scheduled Task/Job,
Obfuscated Files or Information, Deobfuscate/Decode Files or
Information, Collection, Application Layer Protocol. Ampel

et al. [3] developed a model to analyze Common Vulnera-
bilities and Exposures (CVEs) and to label them with one
of 10 MITRE ATT&CK tactics (Defense Evasion, Discovery,
Privilege Escalation, Collection, Lateral Movement, Impact,
Credential Access, Initial Access, Exﬁltration, Execution).
EXTRACTOR [45] is a tool for analyzing sentences to extract
information on attack behavior. In particular, EXTRACTOR
identiﬁes system entity names (e.g., ﬁle or process names,
IP, and registry keys) and actions (read, write send, receive,
connect, fork) described in the sentences. This approach per-
forms a low-level analysis, without abstracting the actions to
ATT&CK techniques. TTPDrill [22] is a system that extracts
threat actions from unstructured sources of CTI. It leverages
a dedicated ontology to ﬁt the mined malicious actions, by
combining NLP and Information Retrieval (IR) techniques.
The scope of this tool is limited to the identiﬁcation of a small
set of threat actions, such as data exﬁltration, add registry,
and DLL injection. ActionMiner [23] is another framework
for the extraction of threat actions from CTI documents. It
information to identify low-level
uses entropy and mutual
actions, which are represented as verb-object couples. These
threat actions are not mapped to the techniques in the MITRE
ATT&CK taxonomy. Our work differs from these previous
ones. Most importantly, our approach classiﬁes CTI by map-
ping it into all of the 188 ATT&CK techniques. This ﬁne-grain
analysis is particularly important in some scenarios, including
the planning of adversary emulation activities, which need
to match the speciﬁc actions of threat actors to be realistic.
Moreover, in this work, we performed a more extensive study
on the automatic classiﬁcation of CTI, considering several
datasets and ML models.

VIII. THREATS TO VALIDITY

Documents. To build the datasets, we selected threat and
incident reports publicly available online. As a consequence,
the choice of the CTI for the dataset could be affected by our
selection. To mitigate this issue, we focused on documents
gathered by MITRE for the ATT&CK framework.

Models. For the classiﬁcation of attack techniques, we ana-
lyzed several traditional ML and Deep Learning models. We
selected the most popular models for NLP tasks, choosing both
traditional and recent ones. We also considered a Transformer-
based model, SecureBERT, so as to include the most recent
advancements in NLP research. To the best of our knowledge,
our study covers the largest number of ML models in this
ﬁeld.

Metrics. To evaluate the performance of the classiﬁcation
models, we adopted the traditional metrics for multi-class
classiﬁcation tasks. In particular, we decide to consider the
F1-Score instead of the accuracy, to take into account the
imbalance of our datasets and the distribution of classes. We
also selected the top K accuracy, with K set to 3, which
indicates if the correct class is in the top 3 predictions.

IX. CONCLUSION AND FUTURE WORK
In this work, we presented an experimental study on the
automatic mapping of Cyber Threat Intelligence into attack
techniques. In particular, we focused on the well-known
MITRE ATT&CK taxonomy to deﬁne classes to be mapped
to CTI. Moreover, we adopted the knowledge base of MITRE
ATT&CK to build two datasets of CTI descriptions in natural
language: the ﬁrst one labeled at sentence-level, the other
at document-level, with the corresponding attack techniques.
We tested several state-of-the-art classiﬁcation models, which
achieved promising results at mapping attack techniques. The
lessons learned from this analysis point out
the strengths
and limitations of the aforementioned ML models, and set
directions for future work.

In addition to improving the mapping of CTI to ATT&CK
techniques, we foresee future work on integrating this ap-
proach into offensive security practices. In particular, adver-
sary emulation can beneﬁt from this work, in order to enable
organizations to emulate the actions of a given threat actor,
according to CTI collected from ﬁeld. The mapped CTI can
potentially be used to conﬁgure an automated tool, in order to
emulate the speciﬁc attack techniques used by a threat actor.
This, in turn, would signiﬁcantly reduce the cost and effort
needed to perform security assessments and training exercises.

ACKNOWLEDGMENTS
This work has been partially supported by the Programme
F.R.A. of Universit`a degli Studi di Napoli Federico II (project
OSTAGE), and by the Italian Ministry of University and
Research (MUR) under the programme “PON Ricerca e Inno-
vazione 2014-2020 – Dottorati innovativi con caratterizzazione
industriale”.

REFERENCES

[10] Franc¸ois Chollet et al. Keras. https://keras.io, 2015.
[11] MITRE Corporation. CAPEC. https://capec.mitre.org/.
[12] MITRE Corporation. MITRE ATT&CK. https://attack.mitre.org/.
[13] CTID.

FIN6 Adversary

Plan.

https://github.com/

center-for-threat-informed-defense/adversary emulation library/tree/
master/ﬁn6.

[14] CTID.

FIN6

Intelligence

Summary.

https://github.com/

center-for-threat-informed-defense/adversary emulation library/blob/
master/ﬁn6/Intelligence Summary.md.

[15] CTID.

FIN6

Phase

one.

https://github.com/

center-for-threat-informed-defense/adversary emulation library/blob/
master/ﬁn6/Emulation Plan/Phase1.md.
FIN6

https://github.com/

Phase

two.

[16] CTID.

center-for-threat-informed-defense/adversary emulation library/blob/
master/ﬁn6/Emulation Plan/Phase2.md.

[17] CTID. STIX Project. https://stixproject.github.io/.
[18] Cybersecurity & Infrastructure Security Agency. Ransomware Activity
Targeting the Healthcare and Public Health Sector. https://www.cisa.
gov/uscert/ncas/alerts/aa20-302a.

[19] MITRE Engenuity. Center for threat-informed defense. https://ctid.

mitre-engenuity.org/.

[20] FireEye. Follow The Money: Dissecting the Operations of the Cyber
Crime Group FIN6. https://www2.ﬁreeye.com/rs/848-DID-242/images/
rpt-ﬁn6.pdf.

[21] Margherita Grandini, Enrico Bagli, and Giorgio Visani. Metrics for

multi-class classiﬁcation: an overview. ArXiv, abs/2008.05756, 2020.

[22] Ghaith Husari, Ehab Al-Shaer, Mohiuddin Ahmed, Bill Chu, and Xi Niu.
TTPDrill: Automatic and Accurate Extraction of threat actions from
In Proceedings of the 33rd Annual
unstructured text of cti sources.
Computer Security Applications Conference, pages 103–115, 2017.
[23] Ghaith Husari, Xi Niu, Bill Chu, and Ehab Al-Shaer. Using entropy
information to extract
threat actions from cyber threat
In 2018 IEEE International Conference on Intelligence

and mutual
intelligence.
and Security Informatics (ISI), pages 1–6. IEEE, 2018.

[24] Eric Michael Hutchins, Michael J. Cloppert, and Rohan M. Amin.
Intelligence-Driven Computer Network Defense Informed by Analysis
of Adversary Campaigns and Intrusion Kill Chains. 2010.

[25] Mandiant. Pick-Six: Intercepting a FIN6 Intrusion, an Actor Recently
Tied to Ryuk and LockerGoga Ransomware. https://www.mandiant.com/
resources/pick-six-intercepting-a-ﬁn6-intrusion.

[26] MITRE. Access Token Manipulation, T1134. https://attack.mitre.org/

techniques/T1134/.

[27] MITRE. Account Discovery, T1087. https://attack.mitre.org/techniques/

[1] SecureBert Hugging Face Model.

https://huggingface.co/jackaduma/

T1087/.

SecBERT.

[28] MITRE. Archive Collected Data, Archive via Utility, NTDS, T1560.001.

[2] Ehsan Aghaei, Xi Niu, Waseem Shadid, and Ehab Al-Shaer. Language

https://attack.mitre.org/techniques/T1560/001/.

model for text analytic in cybersecurity, 2022.

[3] Benjamin Ampel, Sagar Samtani, Steven Ullman, and Hsinchun
Chen. Linking common vulnerabilities and exposures to the mitre
arXiv preprint
att&ck framework: A self-distillation approach.
arXiv:2108.01696, 2021.

[4] Andy Applebaum, Doug Miller, Blake E. Strom, Henry Foster, and Cody
In
Thomas. Analysis of automated adversary emulation techniques.
SummerSim, 2017.

Info

[5] Andy Applebaum, Doug Miller, Blake E. Strom, Chris Korban, and
Ross Wolf. Intelligent, automated red team emulation. Proceedings of
the 32nd Annual Conference on Computer Security Applications, 2016.
APT
https://www.bankinfosecurity.com/

[6] Bank

Security.

Exposes

OilRig

Tools.

Group’s
leak-exposes-oilrig-apt-groups-tools-a-12397.
[7] Steven Bird, Ewan Klein, and Edward Loper.

language
processing with Python: analyzing text with the natural language toolkit.
”O’Reilly Media, Inc.”, 2009.

Natural

Leak

[8] Sunders Bruskin, Polina Zilberman, Rami Puzis, and Shay Shwarz. SoK:
A Survey of Open Source Threat Emulators. ArXiv, abs/2003.01518,
2020.

[9] Lars Buitinck, Gilles Louppe, Mathieu Blondel, Fabian Pedregosa,
Andreas Mueller, Olivier Grisel, Vlad Niculae, Peter Prettenhofer,
Alexandre Gramfort, Jaques Grobler, Robert Layton, Jake VanderPlas,
Arnaud Joly, Brian Holt, and Ga¨el Varoquaux. API design for machine
learning software: experiences from the scikit-learn project. In ECML
PKDD Workshop: Languages for Data Mining and Machine Learning,
pages 108–122, 2013.

[29] MITRE. CALDERA. https://github.com/mitre/caldera.
[30] MITRE. CALDERA documentation. https://caldera.readthedocs.io/en/

latest/.

[31] MITRE. Exﬁltration Over Alternative Protocol, T1048. https://attack.

mitre.org/techniques/T1048/.

[32] MITRE. OS Credential Dumping, NTDS, T1003.003. https://attack.

mitre.org/techniques/T1003/003/.

[33] MITRE. OS Credential Dumping, T1003.

https://attack.mitre.org/

techniques/T1003/.

[34] MITRE. Phishing, T1566. https://attack.mitre.org/techniques/T1566/.
[35] MITRE. Process Injection, T1055. https://attack.mitre.org/techniques/

T1055/.

[36] MITRE. Remote System Discovery, T1018. https://attack.mitre.org/

techniques/T1018/.

[37] MITRE. Standardizing Cyber Threat Intelligence Information with the
Structured Threat Information eXpression. https://www.mitre.org/sites/
default/ﬁles/publications/stix.pdf.

[38] MITRE.

System Network Conﬁguration Discovery, T1016.

https:

//attack.mitre.org/techniques/T1016/.

[39] MITRE.

The Trusted Automated eXchange of

Infor-
mation. https://taxii.mitre.org/about/documents/Introduction to TAXII
White Paper May 2014.pdf.

Indicator

[40] MITRE. TRAM. https://github.com/center-for-threat-informed-defense/

tram/.

[41] MITRE. Valid Accounts, T1078. https://attack.mitre.org/techniques/

T1078/.

[42] Ankur Padia, Arpita Roy, Taneeya Satyapanich, Francis Ferraro, Shimei
Pan, Youngja Park, Anupam Joshi, and Tim Finin. UMBC at SemEval-
In Proceedings of
2018 task 8: Understanding text about malware.
The 12th International Workshop on Semantic Evaluation, pages 878–
884, New Orleans, Louisiana, June 2018. Association for Computational
Linguistics.

[43] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Brad-
bury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein,
Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary
DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit
Steiner, Lu Fang, Junjie Bai, and Soumith Chintala.
Pytorch: An
imperative style, high-performance deep learning library. In Advances
in Neural Information Processing Systems 32, pages 8024–8035. Curran
Associates, Inc., 2019.

[44] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion,
O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vander-
plas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duch-
esnay. Scikit-learn: Machine learning in Python. Journal of Machine
Learning Research, 12:2825–2830, 2011.

[45] Kiavash Satvat, Rigel Gjomemo, and VN Venkatakrishnan. Extractor:
extracting attack behavior from threat reports. In 2021 IEEE European
Symposium on Security and Privacy (EuroS&P), pages 598–615. IEEE,
2021.

[46] Security Intelligence.

ITG08 (aka FIN6) Partners With TrickBot
Gang, Uses Anchor Framework. https://securityintelligence.com/posts/
itg08-aka-ﬁn6-partners-with-trickbot-gang-uses-anchor-framework/.

[47] Symantec.

Japan-Linked Organizations Targeted in Long-Running
and Sophisticated Attack Campaign. https://symantec-enterprise-blogs.
security.com/blogs/threat-intelligence/cicada-apt10-japan-espionage.
[48] The DFIR Report. Ryuk’s Return. https://thedﬁrreport.com/2020/10/08/

ryuks-return/.

[49] The Free Library. MuddyWater APT Group’s Operations Leaked On The
Dark Web. https://www.thefreelibrary.com/MuddyWater+APT+Group%
27s+Operations+Leaked+On+The+Dark+Web.-a0584888340.

[50] The Record.

Inside Conti leaks: The Panama Papers of ransomware.
https://therecord.media/conti-leaks-the-panama-papers-of-ransomware/.
[51] The United States Department of Justice. United States v. Zhu
Hua Indictment. https://www.justice.gov/opa/press-release/ﬁle/1121706/
download.

[52] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion
Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention
is all you need. Advances in neural information processing systems, 30,
2017.

[53] VISA. FIN6 cybercrime group expands threat to ecommerce merchants.
https://usa.visa.com/dam/VCOM/global/support-legal/documents/
ﬁn6-cybercrime-group-expands-threat-To-ecommerce-merchants.pdf.

[54] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement
Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R´emi Louf, Morgan
Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma,
Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger,
Mariama Drame, Quentin Lhoest, and Alexander M. Rush. Hugging-
face’s transformers: State-of-the-art natural language processing, 2019.
[55] Yizhe You, Jun Jiang, Zhengwei Jiang, Peian Yang, Baoxu Liu, Huamin
Feng, Xuren Wang, and Ning Li. TIM: threat context-enhanced TTP
intelligence mining on unstructured threat data. Cybersecurity, 5(1):1–
17, 2022.

