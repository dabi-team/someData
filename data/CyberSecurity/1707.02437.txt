Assessing the risk of advanced persistent threats

Xiaofan Yanga, Tianrui Zhanga, Lu-Xing Yanga,b,∗, Luosheng Wenc, Yuan Yan Tangd

aSchool of Software Engineering, Chongqing University, Chongqing, 400044, China
bSchool of Information Technology, Deakin University, Melbourne, 3125, Australia
cSchool of Mathematics and Statistics, Chongqing University, Chongqing, 400044, China
dDepartment of Computer and Information Science, The University of Macau, Macau

7
1
0
2

c
e
D
8
2

]

R
C
.
s
c
[

2
v
7
3
4
2
0
.
7
0
7
1
:
v
i
X
r
a

Abstract

As a new type of cyber attacks, advanced persistent threats (APTs) pose a severe threat to modern society. This

paper focuses on the assessment of the risk of APTs. Based on a dynamic model characterizing the time evolution

of the state of an organization, the organization’s risk is deﬁned as its maximum possible expected loss, and the

risk assessment problem is modeled as a constrained optimization problem. The inﬂuence of diﬀerent factors on

an organization’s risk is uncovered through theoretical analysis. Based on extensive experiments, we speculate that

the attack strategy obtained by applying the hill-climbing method to the proposed optimization problem, which we

call the HC strategy, always leads to the maximum possible expected loss. We then present a set of ﬁve heuristic

attack strategies and, through comparative experiments, show that the HC strategy causes a higher risk than all these

heuristic strategies do, which supports our conjecture. Finally, the impact of two factors on the attacker’s HC cost

proﬁt is determined through computer simulations. These ﬁndings help understand the risk of APTs in a quantitative

manner.

Keywords: advanced persistent threat, risk assessment, expected loss, attack strategy, constrained optimization

1. Introduction

In this day and age, the functioning of most organizations, ranging from large enterprises and ﬁnancial institutions

to government sectors and military branches, depends heavily on cyber networks interconnecting computer systems.

However, these organizations are vulnerable to multifarious cyber attacks. Traditional cyber attacks tended to compro-

mise lots of unspeciﬁed computer systems, with the goal of picking low hanging fruits. Conventional cyber defense

measures including ﬁrewall and intrusion detection have turned out to be eﬀective in withstanding these cyber attacks

[1, 2].

∗Corresponding author
Email addresses: xfyang1964@gmail.com (Xiaofan Yang), 363726657@qq.com (Tianrui Zhang), ylx910920@gmail.com (Lu-Xing

Yang), wls@cqu.edu.cn (Luosheng Wen), yytang@umac.mo (Yuan Yan Tang)

Preprint submitted to Journal of Parallel and Distributed Computing

December 29, 2017

 
 
 
 
 
 
The cyber security landscape has changed drastically over the past few years. Many high-proﬁle organizations

have experienced a new kind of cyber attacks — advanced persistent threats (APTs) [3]. Compared with traditional

attacks, APTs exhibit the following distinctive characteristics: (a) The attacker is a well-resourced and well-organized

group, with the goal of stealing as many sensitive data as possible from a speciﬁc organization. (b) Based on metic-

ulous reconnaissance, a preliminary advanced social engineering attack is launched on a few target users to gain

footholds in the organization’s network. (c) More and more systems are infected stealthily and slowly to gain access

to critical information, and preys are secretly sent to the attacker [4–6]. APTs can evade traditional detection, causing

tremendous damage to organizations. In practice, the detection of APTs involves complex analysis of activities in the

network of the targeted organization, which is far from mature [7, 8].

Taking a risk-based approach to security has long been the recommended way to secure an organization [9–11].

The critical shift is that in the past it was recommended but today owing to the APT it is required. In fact, it is no

exaggeration to say that everything performed in security should be mapped back to risk and justiﬁed by risk [5].

Normally, we are not going to eliminate a risk, because that would be too expensive or even impossible. Instead, we

are going to reduce the risk to an acceptable level, which depends on the critical information we are protecting. When

it comes to an APT, the risk taken by the targeted organization translates to the organization’s expected loss. When

it comes to an organization, it is appropriate to take the worst-case perspective of assessing the risk as the maximum

possible expected loss of the organization over all possible APT attacks. To our knowledge, there is no literature on

the risk assessment of APTs.

To assess the risk taken by an organization under APTs, the time evolution of the organization’s state has to be

modeled accurately. Due to the propagation nature of APTs, it is appropriate to characterize the evolution process

as an epidemic model [12–17]. In view of the persistence of APTs and taking the relevant network into account, the

evolution process should be modeled as a diﬀerential dynamical system with the network topology. The individual-

level dynamical modeling approach, which has been applied to a wide range of areas, ranging from epidemic spreading

[18–21] and malware spreading [22–30] to rumor spreading[31, 32], meets this requirement. Towards this direction,

a number of APT attack-defense models have recently been suggested [33–35].

This paper addresses the risk assessment of APTs. First, a dynamic model characterizing the time evolution of the

security state of an organization is established by employing the individual-level dynamic modeling approach. Then

an organization’s risk is quantiﬁed as its maximum possible expected loss. On this basis, the risk assessment problem

boils down to a constrained optimization problem, with the expected loss as the objective function. The inﬂuence of

diﬀerent factors on an organization’s risk is illuminated through theoretical analysis. Extensive experiments exhibit

that an organization’s expected loss is unimodal with respect to the attack strategy. Hence, we speculate that the APT

attack strategy obtained by applying the hill-climbing method to the proposed optimization problem, which we call

2

the HC strategy, always inﬂicts the maximum possible expected loss. To validate the conjecture, we formulate a set

of ﬁve heuristic APT attack strategies. A set of comparative experiments clearly show that the HC strategy causes a

higher risk than all the ﬁve heuristic strategies do. Hence, our conjecture is corroborated. Finally, the impact of two

factors, the attack duration and the attack budget per unit time, on the attacker’s HC cost proﬁt is determined through

computer simulations. The results obtained help us understand the risk of APTs in a quantitative manner.

The subsequent materials are organized in this fashion. Section 2 measures an organization’s risk using its max-

imum expected loss, and models the risk assessment problem as an optimization problem. Section 3 reveals the

inﬂuence of diﬀerent factors on an organization’s risk. An attack strategy is proposed in Section 4, which is shown

through comparison experiments to cause the maximum expected loss. Section 5 examines the impact of two factors

on the attacker’s HC cost proﬁt. This work is closed by Section 6.

2. The modeling of the risk assessment problem

Suppose some attacker, who represents a well-resourced and well-organized group, is going to conduct an APT

campaign on an organization. The organization’s defender, who represents the security team aﬃliated with the orga-

nization, faces the following urgent and challenging problem:

The risk assessment (RA) problem: Estimate the potential loss of the organization.

This section is dedicated to the modeling of the RA problem. Our modeling process consists of six successive

steps: (i) characterize the state of the organization, (ii) describe the defense posture, (iii) formulate the attack strategy,

(iv) model the state evolution of the organization, (v) measure the risk of the organization, and (vi) model the RA

problem.

2.1. The state of an organization

Consider an organization with a set of N computer systems labelled 1, 2, · · · , N interconnected by a network. Let

G = (V, E) denote the network, where each node stands for a system, i.e., V = {1, 2, · · · , N}, and there is an edge

between node i and node j, i.e., {i, j} ∈ E, if and only if system i can communicate directly with system j. Let
A(G) = (cid:104)

denote the adjacency matrix for the network, i.e., ai j = 1 or 0 according as {i, j} ∈ E or not.

ai j

(cid:105)

N×N

The security level of a node is measured by the amount of the sensitive data stored in the associated system. Let

wi denote the security level of node i. In this work, we assume wi = di (1 ≤ i ≤ N), where di = (cid:80)N

j=1 ai j denotes the

degree of node i in the network. This is because a node with a higher degree typically has a higher importance.

In what follows, it is assumed that at any time, each and every node in the network is in one of two possible

states: secure, i.e, under the defender’s control, and compromised, i.e, under the attacker’s control. Let Xi(t) = 0 and

1 denote the event that node i is secure and compromised at time t, respectively. The state of the organization at time

3

t is characterized by the vector

Let S i(t) and Ci(t) denote the probability of the event that node i is secure and compromised at time t, respectively.

X(t) = (X1(t), X2(t), · · · , XN(t)).

(1)

S i(t) = Pr {Xi(t) = 0} , Ci(t) = Pr {Xi(t) = 1} ,

1 ≤ i ≤ N.

The expected state of the organization at time t is characterized by the vector

C(t) = (C1(t), C2(t), · · · , CN(t))T .

2.2. The cyber defense posture

(2)

(3)

The cyber defense of an organization against APTs is twofold: prevention and response. The former aims to

protect the secure nodes in the organization’s network from compromise, while the latter is devoted to recovering the

compromised nodes in the network.

The prevention investment on a node consists of three parts: the cost for purchasing a set of security products

for the node, the cost for deploying and conﬁguring the security products, and the cost for enhancing the user’s

awareness against advanced social engineering attacks. Let δi denote the prevention investment on node i. In this

work, we assume the prevention investment on each node is linearly proportional to the security level of the node, i.e.,

δi = δ × wi, where the positive constant δ is referred to as the prevention coeﬃcient.

The response investment on a node consists of four parts: the cost for monitoring and analyzing the activities

related to the node, the cost for deciding on whether the node is compromised or not, the cost for isolating the node

from the network when it is compromised, and the cost for recovering the compromised node. Let γi denote the

response investment on node i. In this work, we assume the response investment on each node is linearly proportional

to the security level of the node, i.e., γi = γ ×wi, where the positive constant γ is referred to as the response coeﬃcient.

2.3. The cyber attack strategy

The threat of an APT campaign to the organization is twofold: external attack and internal infection. The former

is conducted by the attacker from outside of the network, while the latter is caused by the compromised nodes within

the network, both with the same goal of compromising the secure nodes in the network.

Let B denote the budget per unit time for attacking the organization. In this work, we assume B is a constant,

which is determined by the attacker prior to the campaign.

Let xi denote the cost per unit time used for attacking node i when it is secure. In this work, we assume xi is a

constant, which is determined by the attacker prior to the campaign. The attack strategy is characterized by the vector

x = (x1, x2, · · · , xN).

4

(4)

Let ||x||1 denote the 1-norm of x, i.e., ||x||1 = (cid:80)N

i=1 xi. Then, ||x||1 = B. Let ΩB denote the admissible set of attack

strategies,

Then, we have x ∈ ΩB.

ΩB = (cid:110)

u ∈ RN

(cid:111)
+ : ||u||1 = B

.

(5)

2.4. A state evolution model of an organization

For fundamental knowledge on diﬀerential dynamical systems, see Ref. [36].

Suppose an APT campaign on an organization starts at time t = 0 and terminates at time t = T . To model the state

evolution of the organization, let us impose a set of hypotheses as follows.

(H1) Due to external attack and prevention, at any time a secure node i gets compromised at rate αxi
δwi

, where the posi-

tive constant α is referred to as the attack coeﬃcient; which is proportional to the quality of the reconnaissance.

This hypothesis is rational, because the rate is (a) proportional to the attack cost per unit time, and (b) inversely

proportional to the prevention investment.

(H2) Due to internal infection and prevention, at any time a secure node i gets compromised at the average rate

β (cid:80)N

j=1 a jiC j(t)

δwi

, where the positive constant β is referred to as the infection coeﬃcient, which is typically small.

Indeed, this coeﬃcient is controllable by the attacker so as to avoid detection. This hypothesis is rational,

because the average rate is (a) proportional to the probability of the event that each speciﬁc neighboring node

is compromised, and (b) inversely proportional to the prevention investment.

(H3) Due to response, at any time a compromised node i gets secure at rate γwi. This hypothesis is rational, because

the rate is proportional to the response investment.

This set of hypotheses is schematically shown in Fig. 1.

Figure 1: Diagram of hypotheses (H1)-(H3).

Based on the above hypotheses, the evolution of the expected state of the organization is modeled as the following

diﬀerential dynamical system:

dCi(t)
dt

= 1
δwi





αxi + β


a jiC j(t)



N(cid:88)

j=1

[1 − Ci(t)] − γwiCi(t),

0 ≤ t ≤ T, i = 1, · · · , N.

(6)

We refer to the model as the Secure-Compromised-Secure (SCS) model. A SCS model is characterized by the 7-tuple

MS CS = (G, α, β, δ, γ, T, x).

5

(cid:1)(cid:2)(cid:3)(cid:1)(cid:2)(cid:3)(cid:1)(cid:1)(cid:2)(cid:4)(cid:1)(cid:2)(cid:3)(cid:1)(cid:4)(cid:4)(cid:1)(cid:2)(cid:4)(cid:1)(cid:5)(cid:1)(cid:5)(cid:5)(cid:1)(cid:6)(cid:7)(cid:8)(cid:3)(cid:9)(cid:2)(cid:3)(cid:4)(cid:1)(cid:5)(cid:6)(cid:7)(cid:8)(cid:9)(cid:10)(cid:11)(cid:12)(cid:1)(cid:9)(cid:13)2.5. The modeling of the risk assessment problem

For simplicity, we assume (a) the loss per unit time of an organization owing to a compromised node i is wi, and

(b) the proﬁt per unit time of the attacker owing to the compromised node is also wi. This assumption is rational,

because the loss and proﬁt both are proportional to the security level of the node.

Consider a SCS model MS CS = (G, α, β, δ, γ, T, x). The expected loss of the organization caused by implementing

the attack strategy x is

L(x; G, α, β, δ, γ, T ) =

(cid:90) T

N(cid:88)

0

i=1

wiCi(t)dt.

(7)

In what follows, we deﬁne the risk of an organization as the maximum possible expected loss of the organization

over all admissible attack strategies. Let R(G, α, β, δ, γ, T, B) denote the risk of the organization,

R(G, α, β, δ, γ, T, B) = max
x∈ΩB

L(x; G, α, β, δ, γ, T ) = max
x∈ΩB

(cid:90) T

N(cid:88)

0

i=1

wiCi(t)dt.

(8)

Obviously, the risk of an organization is dependent upon not only the security posture, (G, δ, γ), but the attack mecha-

nism, (α, β, T, B).

Therefore, the original risk assessment problem is modeled as the following constrained optimization problem:

max
x∈ΩB

s.t.

L(x; G, α, β, δ, γ, T ) =

(cid:90) T

N(cid:88)

wiCi(t)dt,

dCi(t)
dt

= 1
δwi



αxi + β

0

i=1

N(cid:88)

j=1

a jiC j(t)





Ci(0) = C∗
i ,

i = 1, · · · , N.

[1 − Ci(t)] − γwiCi(t),

0 ≤ t ≤ T, i = 1, · · · , N,

(9)

We refer to the optimization problem as the risk assessment (RA) model. A RA model is characterized by the 7-tuple

MRA = (G, α, β, δ, γ, T, B).

Let ˆx = (x1, x2, · · · , xN−1), and let

ˆΩB =





ˆu = (u1, u2, · · · , uN−1) ∈ RN−1

+

:



ui ≤ B


.

N−1(cid:88)

i=1

Then the RA model (9) can be written in reduced form as follows:

max
ˆx∈ ˆΩB

s.t.

ˆL(ˆx; G, α, β, δ, γ, T ) =

(cid:90) T

N(cid:88)

wiCi(t)dt,

dCi(t)
dt

= 1
δwi





dCN(t)
dt

= 1
δwN

0

N(cid:88)

αxi + β

i=1


a jiC j(t)


α







B −

j=1
N−1(cid:88)

i=1





xi

+ β


N(cid:88)

j=1

Ci(0) = C∗
i ,

i = 1, · · · , N.

[1 − Ci(t)] − γwiCi(t),

0 ≤ t ≤ T, i = 1, · · · , N − 1,

[1 − CN(t)] − γwNCN(t),

0 ≤ t ≤ T,

a jNC j(t)





6

(10)

(11)

We refer to the optimization problem as the reduced risk assessment (RRA) model. An RRA model is also character-

ized by the 7-tuple MRRA = (G, α, β, δ, γ, T, B). Obviously, we have

R(G, α, β, δ, γ, T, B) = max
ˆx∈ ˆΩB

L(ˆx; G, α, β, δ, γ, T ).

(12)

The RRA model will be used in Section 4.

3. The inﬂuence of diﬀerent factors on the risk of an organization

Eq. (8) tells us that the risk of an organization is dependent upon the topology of the network, the fourth coeﬃ-

cients, the attack duration, and the attack budget per unit time. This section is committed to examining the way that

these factors aﬀect the organization’s risk. For this purpose, the following lemma is needed.

Lemma 1. (Chaplygin Lemma, see Theorem 31.4 in [37]) Consider a smooth n-dimensional system of diﬀerential

equations

and consider the following two systems of diﬀerential inequalities:

dx(t)
dt

= f((x(t)),

t ≥ 0,

and

dy(t)
dt

dz(t)
dt

≤ f((y(t)),

t ≥ 0,

≥ f((z(t)),

t ≥ 0,

(13)

(14)

(15)

where x(0) = y(0) = z(0). Suppose that for any a1, · · · , an ≥ 0, there hold

fi(x1 + a1, · · · , xi−1 + ai−1, xi, xi+1 + ai+1, · · · , xn + an) ≥ fi(x1, · · · , xn),

i = 1, · · · , n.

(16)

Then, y(t) ≤ x(t) and z(t) ≥ x(t) for all t ≥ 0.

3.1. The inﬂuence of the network topology

The following theorem discloses the inﬂuence of the network topology on the risk of an organization.

Theorem 1. The risk of an organization increases with the addition of new edges to the network.

Proof. Consider a pair of RA models, M(1)
RA
spanning subgraph of G2, i.e., G1 = (V, E1), G2 = (V, E2), E1 ⊆ E2. Let A(G1) = (cid:104)
i j ≤ a(2)
a(1)

= (G1, α, β, δ, γ, T, B) and M(2)
RA

(cid:16)
1 (t), · · · , C(1)
C(1)

be the solution to the SCS model M(1)
S CS

= (G2, α, β, δ, γ, T, B), where G1 is a
, A(G2) = (cid:104)
a(2)
i j
= (G1, α, β, δ, γ, T, x) with a

i j , 1 ≤ i, j ≤ N. Let

. Then

N (t)

a(1)
i j

N×N

N×N

(cid:17)

(cid:105)

(cid:105)

7

given initial condition,

initial condition. Then,

(cid:16)
1 (t), · · · , C(2)
C(2)

N (t)

(cid:17)

the solution to the SCS model M(2)
S CS

= (G2, α, β, δ, γ, T, x) with the same

(t)

dC(1)
i
dt

= 1
δwi

(t)

dC(2)
i
dt

= 1
δwi

≥

1
δwi



αxi + β



αxi + β



αxi + β

N(cid:88)

j=1

N(cid:88)

j=1
N(cid:88)

j=1

a(1)
ji C(1)

j (t)

a(2)
ji C(2)

j (t)

ji C(2)
a(1)

j (t)













(cid:104)
1 − C(1)

i

(cid:105)

(t)

− γwiC(1)
i

(t),

0 ≤ t ≤ T, i = 1, · · · , N.

(17)

(cid:104)
1 − C(2)

i

(t)

(cid:104)
1 − C(2)

i

(t)

(cid:105)

(cid:105)

− γwiC(2)
i

(t)

− γwiC(2)
i

(t),

0 ≤ t ≤ T, i = 1, · · · , N.

(18)

It follows from Lemma 1 that C(1)

i

(t) ≤ C(2)

i

(t), 0 ≤ t ≤ T , i = 1, 2, · · · , N. So,

L(x; G1, α, β, δ, γ, T ) =

(cid:90) T

N(cid:88)

0

i=1

wiC(1)
i

(t)dt ≤

(cid:90) T

N(cid:88)

0

i=1

wiC(2)
i

(t)dt = L(x; G2, α, β, δ, γ, T ).

(19)

Hence,

R(G1, α, β, δ, γ, T, B) = max
x∈ΩB

L(x; G1, α, β, δ, γ, T ) ≤ max
x∈ΩB

L(x; G2, α, β, δ, γ, T )

(20)

= R(G2, α, β, δ, γ, T, B).

The proof is complete.

This theorem implies that the denser the network of an organization, the higher the risk of the organization will

be. So, busy business is always accompanied with high risk.

3.2. The inﬂuence of the four coeﬃcients

The following theorem illuminates the way that the four coeﬃcient in the RA model aﬀects the risk of an organi-

zation.

Theorem 2. The risk of an organization ascends with the attack and infection coeﬃcients, and descends with the

prevention and response coeﬃcients.

The proof of this theorem is analogous to that of Theorem 1 and hence is omitted. The ﬁrst claim exhibits that a

meticulous reconnaissance can enhance the risk of the target organization. The second claim demonstrates that a fast

infection can increase the risk. The last two claims show that an increase in security investment always reduces the

risk.

3.3. The inﬂuence of the attack duration

The following theorem reveals the inﬂuence of the attack duration on the risk of an organization.

Theorem 3. The risk of an organization goes up with the attack duration.

8

Proof. Consider a pair of RA models, M(1)
RA
(cid:17)
be the solution to the SCS model M(1)
S CS

= (G, α, β, δ, γ, T1, B) and M(2)
RA

= (G, α, β, δ, γ, T2, B), where T1 < T2.
= (G, α, β, δ, γ, T1, x) with a given initial condition,
= (G, α, β, δ, γ, T2, x) with the same initial condition. Then,

(cid:16)
1 (t), · · · , C(1)
C(1)
N (t)
(cid:17)
N (t)

Let
(cid:16)
1 (t), · · · , C(2)
C(2)

the solution to the SCS model M(2)
S CS

C(1)
i

(t) = C(2)

i

(t),

0 ≤ t ≤ T1, i = 1, · · · , N.

So,

Hence,

L(x; G, α, β, δ, γ, T1) =

(cid:90) T1

N(cid:88)

0

i=1

wiC(1)
i

(t)dt =

(cid:90) T1

N(cid:88)

0

i=1

wiC(2)
i

(t)dt ≤

(cid:90) T2

N(cid:88)

0

i=1

wiC(2)
i

(t)dt

= L(x; G, α, β, δ, γ, T2).

R(G, α, β, δ, γ, T1, B) = max
x∈ΩB

L(x; G, α, β, δ, γ, T1) ≤ max
x∈ΩB

L(x; G, α, β, δ, γ, T2)

= R(G, α, β, δ, γ, T2, B).

(21)

(22)

(23)

The proof is complete.

3.4. The inﬂuence of the attack budget per unit time

The following theorem demonstrates the inﬂuence of the attack budget per unit time on the risk of an organization.

Theorem 4. The risk of an organization rises with the attack budget per unit time.

Proof. Consider a pair of RA models, M(1)
RA
Let A(G) = (cid:104)
model M(1)
S CS

ai j

N×N

(cid:105)

. For any x ∈ ΩB1 , we have B2
B1

= (G, α, β, δ, γ, T, B1) and M(2)
RA
(cid:17)
(cid:16)
C(1)
1 (t), · · · , C(1)
x ∈ ΩB2 . Let
N (t)
(cid:17)
(cid:16)
1 (t), · · · , C(2)
C(2)
N (t)

= (G, α, β, δ, γ, T, x) with a given initial condition,

= (G, α, β, δ, γ, T, B2), where B1 < B2.

be the solution to the SCS

the solution to the SCS model

M(2)
S CS

= (G, α, β, δ, γ, T, B2
B1

x) with the same initial condition. Then,

(t)

dC(1)
i
dt

= 1
δwi



αxi + β

N(cid:88)

j=1

a jiC(1)

j (t)





(cid:104)
1 − C(1)

i

(cid:105)

(t)

− γwiC(1)
i

(t),

0 ≤ t ≤ T, i = 1, · · · , N.

(24)

(t)

dC(2)
i
dt

= 1
δwi


α



B2
B1

xi + β



j (t)

a jiC(2)

N(cid:88)

j=1

(cid:104)
1 − C(2)

i

(cid:105)
(t)

− γwiC(2)
i

(t)

≥

1
δwi



αxi + β

N(cid:88)

j=1

a jiC(2)

j (t)





(cid:104)
1 − C(2)

i

(cid:105)

(t)

− γwiC(2)
i

(t),

0 ≤ t ≤ T, i = 1, · · · , N.

(25)

It follows from Lemma 1 that C(1)

i

(t) ≤ C(2)

i

(t), 0 ≤ t ≤ T , i = 1, 2, · · · , N. Thus,

L(x; G, α, β, δ, γ, T ) =

(cid:90) T

N(cid:88)

0

i=1

wiC(1)
i

(t)dt ≤

(cid:90) T

N(cid:88)

0

i=1

9

wiC(2)
i

(t)dt = L

(cid:32)

B2
B1

(cid:33)

x; G, α, β, δ, γ, T

.

(26)

Hence,

R(G, α, β, δ, γ, T, B1) = max
x∈ΩB1

L(x; G, α, β, δ, γ, T ) ≤ max
x∈ΩB1

L

(cid:33)

x; G, α, β, δ, γ, T

(cid:32)

B2
B1

(27)

≤ max
x∈ΩB2

L(x; G, α, β, δ, γ, T ) = R(G, α, β, δ, γ, T, B2).

The proof is complete.

4. An attack strategy

The RA model characterizing the RA problem has been established in Section 2. We are now confronted with the

problem of how to solve the model. As the RA model involves a higher-dimensional nonlinear objective function and

a dynamic constraint, it is extremely diﬃcult, if not impossible, to solve the model analytically. In this section, let us

turn our attention to the numerical solution of the RA model.

4.1. The HC attack strategy

The goal of this subsection is to present a numerical method for solving the RA model. For this purpose, let us

ﬁrst examine the unimodality of the objective function in the RRA model through computer experiments.

Experiment 1. Let G(2) be the connected graph with two nodes labelled 1 and 2. Fig. 2 plots the four functions

ˆL(ˆx; G, α, β, δ, γ, T ) with the following combinations of parameters:

G

G(2)

G(2)

α

β

δ

γ

0.5

0.5

0.5/1 1

0.5/1 1

1

1

T

10

10

B

10

10

For each of these functions, the sole maximum point is marked in Fig. 4.

It is seen that these functions are all

unimodal.

Experiment 2. Up to isomorphism, there are only two diﬀerent graphs with three nodes, G(3)

2 , which are
depicted in Fig. 3. Fig. 4 plots the eight functions ˆL(ˆx; G, α, β, δ, γ, T ) with the following combinations of parameters:

1 and G(3)

G

G(3)
1
G(3)
1
G(3)
2
G(3)
2

α

β

δ

γ

0.5

0.5

0.5/1 1

0.5/1 1

0.5

0.5

0.5/1 1

1

1

0.5/1 1

1

1

T

10

10

10

10

B

10

10

10

10

10

Figure 2: A graphical representation of the objective functions in Experiment 1.

(a) G(3)
1

(b) G(3)
2

Figure 3: Two connected graphs with three nodes.

(a)

(b)

(c)

(d)

(e)

(f)

(g)

(h)

Figure 4: A graphical representation of the objective functions in Experiment 2.

11

1700160015001400 Expected loss108642x1(a)α=0.5 β=0.5 δ=0.5 γ=1x1=5,x2=515001400130012001100 Expected loss108642x1(b) α=0.5 β=0.5 δ=1 γ=1x1=5,x2=5155015001450140013501300 Expected loss108642x1 α=0.5 β=1 δ=1 γ=1(c)x1=5,x2=518001700160015001400 Expected loss108642x1 α=1 β=1 δ=1 γ=1(d)x1=5,x2=5(cid:1)(cid:2)(cid:3)(cid:1)(cid:2)(cid:3)(a) G(4)
1

(b) G(4)
2

(c) G(4)
3

(d) G(4)
4

(e) G(4)
5

(f) G(4)
6

Figure 5: Six connected graphs with four nodes.

For each of these functions, the sole maximum point is marked in Fig. 4.

It is seen that these functions are all

unimodal.

Experiment 3. Up to isomorphism, there are totally six diﬀerent graphs with four nodes, G(4)

i

, i = 1, · · · , 6, which

are shown in Fig. 5. Fig. 6 plots a cross ﬁgure for each of the 12 functions ˆL(ˆx; G, α, β, δ, γ, T ) with the following

combinations of parameters:

G

G(4)
1
G(4)
2
G(4)
3
G(4)
4
G(4)
5
G(4)
6

α

0.5

0.5

0.5

0.5

0.5

0.5

β

0.5

0.5

0.5

0.5

0.5

0.5

δ

γ

0.5/1 1

0.5/1 1

0.5/1 1

0.5/1 1

0.5/1 1

0.5/1 1

T

10

10

10

10

10

10

B

10

10

10

10

10

10

It is seen that these cross functions are all unimodal. More extensive experiments demonstrate that the 12 original

functions are all unimodal.

We conclude from these and many similar experiments that the objective function in each RRA model is unimodal,

which in turn implies that the objective function in each RA model is unimodal. Hence, for each RA model, the

solution obtained through hill climbing is much likely to be optimal.

To formulate our hill-climbing method, we need to introduce a notion as follows.

Let MRA = (G, α, β, δ, γ, T, B), (cid:15) > 0 a small number. The (cid:15)-neighborhood of x ∈ ΩB, denoted N(cid:15)(x), is deﬁned as

N(cid:15)(x) = {y ∈ ΩB : y − x has exactly two nonzero components, one being (cid:15), the other -(cid:15)}.

(28)

12

(cid:1)(cid:2)(cid:3)(cid:4)(cid:1)(cid:2)(cid:3)(cid:4)(cid:1)(cid:2)(cid:3)(cid:4)(cid:1)(cid:2)(cid:3)(cid:4)(cid:1)(cid:2)(cid:3)(cid:4)(cid:1)(cid:2)(cid:3)(cid:4)(a)

(b)

(c)

(d)

(e)

(f)

(g)

(h)

(i)

(j)

(k)

(l)

Figure 6: Some cross ﬁgures of the functions in Experiment 3.

And every y ∈ N(cid:15)(x) is referred to as a (cid:15)-neighbor of x.

Now, we are ready to formulate our method for ﬁnding an attack strategy.

Algorithm 1 HILL-CLIMBING
Input MRA = (G, α, β, δ, γ, T, B); (cid:15) = 10−6.
Output x ∈ ΩB; L(x; G, α, β, δ, γ, T ).

1: randomly choose x ∈ ΩB;

2: while x has a (cid:15)-neighbor y such that L(y; G, α, β, δ, γ, T ) > L(x; G, α, β, δ, γ, T ) do

3:

x := y;

4: end while

5: return (x, L(x; G, α, β, δ, γ, T )).

We refer to the attack strategy obtained by executing the HILL-CLIMBING algorithm on a RA model as the HC

13

strategy for the RA model, and the expected loss owing to the HC strategy as the HC risk for the RA model.

It is seen from Experiments 1-3 that, for each of these RA models, the associated HC strategy is optimal. Through

extensive computer experiments, we conclude the following result.

For each and every RA model, the associated HC strategy is optimal.

4.2. Five heuristic attack strategies

To examine the optimality of the HC strategy, we need to make comparisons on larger networks between this

strategy and some other attack strategies. For this purpose, below let us formulate ﬁve heuristic attack strategies.

The ﬁrst heuristic attack strategy is to use up the attack budget to attack a single node of the highest security level.

That is,

x = (0, · · · , 0, B, 0, · · · , 0),

(29)

where the target node is of the highest security level, with the ice being broken arbitrarily. We refer to the attack

strategy as the highest security-level (HS) strategy.

The second heuristic attack strategy is to deplete the attack budget to attack a single node of the lowest security

level. That is,

x = (0, · · · , 0, B, 0, · · · , 0),

where the target node is of the lowest security level, with the deadlock being broken arbitrarily. We refer to the attack

strategy as the lowest security-level (LS) strategy.

The third heuristic attack strategy is to assign to each node an attack cost that is linearly proportional to the security

level of the node. That is,

x = (

Bw1
i=1 wi

(cid:80)N

,

Bw2
i=1 wi

(cid:80)N

, · · · ,

BwN
i=1 wi

(cid:80)N

).

(30)

We refer to the attack strategy as the security-level ﬁrst (SF) strategy.

The fourth heuristic attack strategy is to assign to each node an attack cost that is inversely linearly proportional

to the security level of the node. That is,

x = (

B
w1
(cid:80)N

i=1

B
w2
(cid:80)N

i=1

1
wi

,

1
wi

, · · · ,

B
wN

(cid:80)N

i=1

).

1
wi

We refer to the attack strategy as the security-level last (SL) strategy.

The ﬁfth heuristic attack strategy is to allocate the attack budget uniformly among all nodes. That is

We refer to the attack strategy as the uniform (UN) strategy.

x = (

B
N

,

B
N

, · · · ,

B
N

).

14

(31)

(32)

Figure 7: The small-world network GS W .

4.3. Comparative experiments

This section conducts experimental comparisons between the HC strategy and the ﬁve heuristic attack strategies

in terms of the expected loss. For this purpose, let us describe three networks that will be used in the following

experiments.

Small-world networks are networks that are generated by randomly rewiring some edges of regular networks. Fig.

7 plots a small-world network with 50 nodes, which is obtained by executing the algorithm proposed by Watts and

Strogatz [38]. Let GS W denote this network.

Scale-free networks are networks with an approximate power-law degree distribution. Fig. 8 depicts a scale-free

network with 50 nodes, which is obtained by executing the algorithm proposed by Barabasi and Albert [39]. Let GS F

denote this network.

Fig. 9 exhibits a realistic network with 49 nodes, which comes from Ref. [40]. Let GKO denote this network.

Experiment 4. Consider a set of RA models (G, 1, 1, 1, 1, T, B), where G ∈ {GS W , GS F, GUS }, either (a) T = 5 and
B ∈ {1, 2, . . . , 10}, or (b) B = 10 and T ∈ {5, 6, · · · , 15}. For each of these RA models, the HC strategy is compared

with the ﬁve heuristic attack strategies in terms of the expected loss, and the experimental results are all shown in Fig.

10. It is seen that, for all these RA models, the HC strategy outperforms the ﬁve heuristic strategies.

Based on extensive experiments, we conclude that the HC strategy for each RA model is optimal, i.e., the HC

risk is exactly the maximum possible expected loss. This implies that the HC strategy is the biggest threat to an

organization, and the HC risk is an indicator of the organization’s risk.

15

1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950Figure 8: The scale-free network GS F .

Figure 9: The realistic network GUS .

5. Further discussions

Consider a RA model MRA = (G, α, β, δ, γ, T, B). For an attack strategy x, the expected cost beneﬁt of the attacker

is

L(x)
BT

= 1
||x||1

·

1
T

(cid:90) T

N(cid:88)

0

i=1

wiCi(t)dt.

(33)

We refer to the expected cost beneﬁt associated with the HC strategy as the attacker’s HC cost beneﬁt. Based on

the results given in the previous section, the HC cost beneﬁt is much likely to be the highest cost beneﬁt an attacker

16

123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495012345678910111213141516171819202122232425262728293031323334353637383940414243444546474849Figure 10: The results in Experiment 4.

can achieve. Therefore, both the attacker and defender should be concerned with the inﬂuence of the attack budget

per unit time and the attack duration on the HC cost beneﬁt. This section examines these inﬂuences.

5.1. The inﬂuence of the attack budget per unit time

First, let us examine the inﬂuence of the attack budget per unit time on the HC cost beneﬁt.

Experiment 5. Consider a set of RA models MRA = (G, 1, 0.5, 1, 0.5, T, B), where G ∈ {GS W , GS F, GUS }, T ∈

{5, 10, 15}, and B ∈ {1, 2, · · · , 10}. For each of the RA models, the HC cost beneﬁt is plotted in Fig. 11.

It is

seen that the HC cost beneﬁt drops with the attack budget per unit time.

Extensive experiments exhibit similar phenomena. Hence, we conclude that the HC cost beneﬁt always declines

with the attack budget per unit time. Therefore, the power of APTs is limited in terms of the HC cost beneﬁt. This

sounds a good news for organizations under APTs.

17

2000150010005000 Expected loss108642 B HC  HS LS   SF SL   UN600050004000300020001000 Expected loss14121086 T HC  HS LS   SF SL   UN300025002000150010005000 Expected loss108642 B HC  HS LS   SF SL   UN1000080006000400020000 Expected loss14121086 T HC  HS LS   SF SL   UN25002000150010005000 Expected loss108642 B HC  HS LS   SF SL   UN80006000400020000 Expected loss14121086 T HC  HS LS   SF SL   UN(b) G=GSF , T=5(c) G=GUS , T=5(a) G=GSW , T=5(e) G=GSF , B=10(f) G=GUS , B=10(d) G=GSW , B=10Figure 11: The results in Experiment 5.

5.2. The inﬂuence of the attack duration

Second, let us examine the inﬂuence of the attack duration on the HC cost beneﬁt.

Experiment 6. Consider a set of RA models (G, 1, 0.5, 0.5, 1, T, B), where G ∈ {GS W , GS F, GUS }, B ∈ {5, 10, 15}, and

T ∈ {1, 2, · · · , 10}. For each of the RA models, the HC cost beneﬁt is plotted in Fig. 12. It is seen that, with the

extension of the attack duration, the HC cost beneﬁt goes up but ﬂattens out quickly.

Extensive experiments exhibit similar phenomena. This result demonstrates that, although a short-term APT can

achieve a signiﬁcant increment in HC cost beneﬁt, this increment would become inappreciable with the prolonged

attack duration. This conclusion is a good news for organizations, because the motive to conduct an extended APT

campaign recedes.

Figure 12: The results in Experiment 6.

6. Concluding remarks

This paper has dealt with the problem of assessing the risk of APTs. Based on a state evolution model of an

organization, the risk of the organization is measured by its maximum expected loss, and the risk assessment problem

is modeled as a constrained optimization problem. Our theoretical study expounds the way that diﬀerent factors aﬀect

an organization’s risk. We speculate from experiments that the attack strategy obtained by applying the hill-climbing

18

1.21.11.00.90.80.7 HC cost benefit108642 B G=GSW G=GSF G=GUS1.31.21.11.00.90.80.7 HC cost benefit108642 B G=GSW G=GSF G=GUS1.41.21.00.8 HC cost benefit108642 B G=GSW G=GSF G=GUS(a) T=5(b) T=10(c) T=151.11.00.90.80.70.60.5 HC cost benefit108642 T G=GSW G=GSF G=GUS1.00.90.80.70.60.5 HC cost benefit108642 T G=GSW G=GSF G=GUS0.90.80.70.60.5 HC cost benefit108642 T G=GSW G=GSF G=GUS(a) B=5(b) B=10(c) B=15method to any instance of the proposed optimization problem leads to the maximum expected loss. Comparative

experiments support our conjecture. The impact of two factors on the attacker’s cost proﬁt is determined through

computer simulations.

There are many open problems toward this direction. This work builds on the premise that the defense posture

is ﬁxed. To enhance the security of an organization, the cyber defender may well ﬂexibly adjust the defense posture

over time. In this context, the optimal control theory provides an appropriate framework for developing cost-eﬀective

defense strategies [41–46]. In situations where the attacker and defender are both strategic, it is feasible to assess

the risk of APTs in the framework of game theory [47–50]. In this work, the network of an organization is assumed

to be ﬁxed.

In reality, this network may well vary over time [51–55]. So, it is of importance to assess the risk

of APTs in this context. The identiﬁcation of propagation resources in complex networks is a hotspot of research

in the ﬁeld of cyber security [56–59]. We suggest to utilize the state evolution model established in this work to

identify the footholds of the attacker in a network. Also, it is rewarding to extend this work to the more realistic

scenarios where queuing networks are involved [60]. In recent years, cloud computing has been extended to the edge

of organizational networks, forming fog computing [61–65]. In this context, the assessment of the risk of APTs must

be a huge challenge.

Acknowledgments

The authors are grateful to the anonymous reviewers and the editor for their valuable comments and suggestions,

which have greatly improved the quality of the paper. This work is supported by National Natural Science Foundation

of China (Grant No. 61572006) and Sci-Tech Support Program of China (Grant No. 2015BAF05B03).

References

[1] G.K. Kostopoulos, Cyberspace and Cybersecurity, Taylor & Francis, 2012.

[2] P.W. Singer, A. Friedman, Cybersecurity and Cyberwar: What Everyone Needs to Know, Oxford University Press, 2014.

[3] N. Virvilis, D. Gritzalis, T. Apostolopoulos, Trusted computing vs. advanced persistent threat: Can a defender win this game? in: Proceedings

of UIC/ATC, pp. 396-403, 2013.

[4] C. Tankard, Advanced persistent threats and how to monitor and deter them, Network Security 2011(8) (2011) 16-19.

[5] E. Cole, Advanced Persistent Threat: Understanding the Danger and How to Protect Your Organization, Elsevier, 2013.

[6] T. Wrightson, Advanced Persistent Threat Hacking: The Art and Science of Hacking Any Organization, McGraw-Hill Education, 2015.

[7] I. Friedberg, F. Skopik, G. Settanni, R. Fiedler, Combating advanced persistent threats: From network event correlation to incident detection,

Computers & Security 48 (2015) 35-57.

[8] M. Marchetti, F. Pierazzi, M. Colajanni, A. Guido, Analysis of high volumes of network traﬃc for advanced persistent threat detection,

Computer Networks 109 (2016) 127-141.

[9] D.J. Landoll, The Security Risk Assessment Handbook: A Complete Guide for Performing Security Risk Assessments, 2nd Edition, CRC

Press, 2011.

19

[10] E. Wheeler, Security Risk Management: Building an Information Security Risk Management Program from the Ground up, Syngress, 2011.

[11] D.W. Hubbard, R. Seiersen, How to Measure Anything in Cybersecurity Risk, 1st Edition, Wiley, 2016.

[12] D.J. Daley, J. Gani, Epidemic Modelling: An Introduction, Cambridge University Press, 2009.

[13] M. Garetto, W. Gong, D. Towsley, Modeling malware spreading dynamics, in: Proceedings of INFOCOM, vol. 3, pp. 1869-1879, 2003.

[14] S. Wen, W. Zhou, J. Zhang, Y. Xiang, W. Zhou, W. Jia, Modeling propagation dynamics of social network worms, IEEE Transactions on

Parallel and Distributed Systems 24(8) (2013) 1633-1643.

[15] Y. Wang, S. Wen, Y. Xiang, W. Zhou, Modelling the propagation of worms in networks: A survey, IEEE Communications Surveys and

Tutorials, 2nd Quarter (2014) 942-960.

[16] S. Wen, J. Jiang, Y. Xiang, S. Yu, W. Zhou, W. Jia, To shut them up or to clarify: Restraining the spread of rumors in online social networks,

IEEE Transactions on Parallel and Distributed Systems 25 (12) (2014) 3306-3316

[17] S. Wen, M.S. Haghighi, C. Chen, Y. Xiang, W. Zhou, W. Jia, A sword with two edges: Propagation studies on both positive and negative

information in online social networks, IEEE Transactions on Computers 64 (3) (2015) 640-653.

[18] A. Ganesh, L. Massoulie, D. Towsley, The eﬀect of network topology on the spread of epidemics, in: Proceedings of INFOCOM, vol. 2, pp.

1455-1466, 2005.

[19] M. Draief, Epidmeic processes on complex networks, Physica A: Statistical Mechanics and its Applications 363(1) (2006) 120-131.

[20] P. Van Mieghem, J.S. Omic, R.E. Kooij, Virus spread in networks, IEEE/ACM Transactions on Networking 17(1) (2009) 1-14.

[21] P. Van Mieghem, The N-Intertwined SIS epidemic network model, Computing 93(2) (2011) 147-169.

[22] M. Draief, A. Ganesh, L. Massoulie, Thresholds for virus spread on networks, The Annals of Applied Probability 18(2) (2008) 359-378.

[23] S. Xu, W. Lu, Z. Zhan, A stochastic model of multivirus dynamics, IEEE Transactions on Dependable and Secure Computing 9(1) (2012)

30-45.

[24] S. Xu, W. Lu, L. Xu, Push- and pull-based epidemic spreading in networks: Thresholds and deeper insights, ACM Transactions on Au-

tonomous and Adaptive Systems 7(3) (2012) Article No. 32.

[25] F.D. Sahneh, F.N. Chowdhury, C.M. Scoglio, On the existence of a threshold for preventive behavioral responses to suppress epidemic

spreading Scientiﬁc Reports 2 (2012) 623.

[26] S. Xu, W. Lu, L. Xu, Z. Zhan, Adaptive epidemic dynamics in networks: Thresholds and control, ACM Transactions on Autonomous and

Adaptive System 8(4) (2014) Article No. 19.

[27] L.X. Yang, M. Draief, X. Yang, The impact of the network topology on the viral prevalence: a node-based approach, PLoS ONE 10(7) (2015)

e0134507.

[28] L.X. Yang, M. Draief, X. Yang, Heterogeneous virus propagation in networks: A theoretical study, Mathematical Methods in the Applied

Sciences 40(5) (2017) 1396-1413.

[29] L.X. Yang, X. Yang, Y. Wu, The impact of patch forwarding on the prevalence of computer virus, Applied Mathematical Modelling 43 (2017)

110-125.

[30] L.X. Yang, X. Yang, Y.Y. Tang, A bi-virus competing spreading model with generic infection rates, IEEE Transactions on Network Science

and Engineering, DOI: 10.1109/TNSE.2017.2734075.

[31] Z. He, Z. Cai, J. Yu, X. Wang, Y. Sun, Y. Li, Cost-eﬃcient strategies for restraining rumor spreading in mobile social networks, IEEE

Transactions on Vehicular Technology 66(3) (2017) 2789-2800.

[32] L.X. Yang, P. Li, X. Yang, Y. Wu, Y.Y. Tang, On the competition of two conﬂicting messages, Nonlinear Dynamics, to appear.

[33] S. Xu, W. Lu, H. Li, A stochastic model of active cyber defense dynamics, Internet Mathematics 11 (2015) 28-75.

[34] R. Zheng, W. Lu, S. Xu, Active cyber defense dynamics exhibiting rich phenomena, in: Proceedings of HotSoS, Article No. 2, 2015.

[35] L.X. Yang, P. Li, X. Yang, Y.Y. Tang, Security evaluation of the cyber networks under advanced persistent threats, IEEE Access 5 (2017)

20111-20123.

20

[36] H.K. Khalil, Nonlinear Systems, Third Edition, Pearson Education, Inc., publishing as Prentice Hall, 2002.

[37] J. Szarski, Diﬀerential Inequalities, Polish Scientiﬁc Publishers, Warszawa, 1965.

[38] D.J. Watts, S.H. Strogatz, Collective dynamics of ’small-world’ networks, Nature 393(6684) (1998) 440-442.

[39] A.L. Barabasi, R. Albert, Emergence of scaling in random networks, Science 286(5439) (1999) 509-512.

[40] https://konect.uni-koblenz.de/networks/contiguous-usa.

[41] M.H.R. Khouzani, E. Altman, S. Sarkar, Optimal quarantining of wireless malware through reception gain control, IEEE Transactions on

Automatic Control 57(1) (2012) 49-61.

[42] M.H.R. Khouzani, S. Sarkar, E. Altman, Maximum damage malware attack in mobile wireless networks, IEEE/ACM Transactions on Net-

working 20(5) (2012) 1347-1360.

[43] P.Y. Chen, S.M. Cheng, K.C. Chen, Optimal control of epidemic information dissemination over networks, IEEE Transactions on Cybernetics

44(12) (2014) 2316-2328.

[44] P.Y. Chen, S.M. Cheng, Sequential defense against random and intentional attacks in complex networks, Physical Review E 91(2) (2015)

022805.

[45] L.X. Yang, M. Draief, X. Yang, The optimal dynamic immunization under a controlled heterogeneous node-based SIRS model, Physica A:

Statistical Mechanics and its Applications 450 (2016) 403-415.

[46] T. Zhang, L.X. Yang, X. Yang, Y. Wu, Y.Y. Tang, Dynamic malware containment under an epidemic model with alert, Physica A 470 (2017)

249-260.

[47] T. Alpcan, T. Basar, Network Security: A Decision and Game-Theoretic Approach, Cambridge University Press, 2011.

[48] M.H.R. Khouzani, S. Sarkar, E. Altman, Saddle-point strategies in malware attack, IEEE Journal on Selected Areas in Communications 30(1)

(2012) 31-43.

[49] X. Liang, Y. Xiao, Game theory for network security, IEEE Communications Surveys and Tutorials 15(1) (2013) 472-486.

[50] P. Hu, H. Li, H. Fu, D. Cansever, P. Mohapatra, Dynamic defense strategy against advanced persistent threat with insiders, in: Proceedings of

INFOCOM, pp. 747-756, 2015.

[51] Y. Schwarzkopf, A. Rakos, D. Mukamel, Epidemic spreading in evolving networks, Physical Review E 82 (2010) 036112.

[52] E. Valdano, L. Ferreri, C. Poletto, V. Colizza, Analytical computation of the epidemic threshold on temporal networks, Physical Review X 5

(2015) 021005.

[53] V. Karyotis, S. Papavassiliou, Macroscopic malware propagation dynamics for complex networks with churn, IEEE Communications Letters

19(4) (2015) 577-580.

[54] M.R. Sanatkar, W.N. White, B. Natarajan, C.M. Scoglio, K.A. Garrett, Epidemic threshold of an SIS model in dynamic switching networks,

IEEE Transactions on System, Man and Cybernetics: System 46(3) (2016) 345-355.

[55] J.H. Cho, J. Gao, Cyber war game in temporal networks, PLoS ONE 11(2) (2016) e0148674.

[56] J. Jiang, S. Wen, S. Yu, Y. Xiang, W. Zhou, K-Center: An approach on the multi-source identiﬁcation of information diﬀusion, IEEE

Transactions on Information Forensics and Security 10(12) (2015) 2616-2626.

[57] F. Yang, R. Zhang, Y. Yao, Y. Yuan, Locating the propagation source on complex networks with propagation centrality algorithm, Knowledge-

Based Systems 100 (2016) 112-123.

[58] J. Manitz, J. Harbering, M. Schmidt, T. Kneib, A. Schobel, Source estimation for propagation processes on complex networks with an

application to delays in public transportation systems, Journal of the Royal Statistical Society: Series C (Applied Statistics) 66(3) (2017)

521-536.

[59] J.J. Jiang, S. Wen, S. Yu, Y. Xiang, W. Zhou, Identifying propagation sources in networks: State-of-the-art and comparative studies, IEEE

Communications Surveys and Tutorials 19(1) (2017) 465-481.

[60] V. Karyotis, A. Kakalis, S. Papavassiliou, Malware-propagative mobile Ad Hoc networks: Asymptotic behavior analysis, Journal of Computer

21

Science & Technology 23(3) (2008) 389-399.

[61] S. Yi, Z. Hao, Z. Qin, Q. Li, Fog computing: Platform and applications, in: Proceedings of HotWeb, pp. 73-78, 2015.

[62] S. Ivan, S. Wen, X. Huang, H. Luan, An overview of fog computing and its security issues, Concurrency and Computation: Practice and

Experience, 28(10) (2015) 2991-3005.

[63] A. Alrawais, A. Alhothaily, C. Hu, X. Cheng, Fog computing for the Internet of Things: Security and privacy issues, IEEE Internet Computing

21(2) (2017) 34-42.

[64] S. Khan, S. Parkinson, Y. Qin, Fog computing security: a review of current applications and security solutions, Journal of Cloud Computing:

Advances, Systems and Applications 6 (2017) 19.

[65] R. Roman, J. Lopez, M. Mambo, Mobile edge computing, Fog et al.: A survey and analysis of security threats and challenges, 78(2) (2018)

680-698.

22

