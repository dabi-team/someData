0
2
0
2

r
a

M
1
3

]
L
C
.
s
c
[

1
v
3
0
5
0
0
.
4
0
0
2
:
v
i
X
r
a

Deep Learning Approach for Enhanced Cyber
Threat Indicators in Twitter Stream

Simran K1, Prathiksha Balakrishna2, Vinayakumar R3,1, and Soman KP1

1 Center for Computational Engineering and Networking, Amrita School Of
Engineering, Amrita vishwa vidyapeetham, Coimbatore, India.
simiketha19@gmail.com
2 Graduate School, Computer Science Department,
Texas State University. prathi.93april8@gmail.com
3 Division of Biomedical Informatics, Cincinnati Children’s Hospital Medical Centre,
Cincinnati, OH, United States.
Vinayakumar.Ravi@cchmc.org, vinayakumarr77@gmail.com

Abstract. In recent days, the amount of Cyber Security text data shared
via social media resources mainly Twitter has increased. An accurate
analysis of this data can help to develop cyber threat situational aware-
ness framework for a cyber threat. This work proposes a deep learn-
ing based approach for tweet data analysis. To convert the tweets into
numerical representations, various text representations are employed.
These features are feed into deep learning architecture for optimal fea-
ture extraction as well as classiﬁcation. Various hyperparameter tuning
approaches are used for identifying optimal text representation method
as well as optimal network parameters and network structures for deep
learning models. For comparative analysis, the classical text represen-
tation method with classical machine learning algorithm is employed.
From the detailed analysis of experiments, we found that the deep learn-
ing architecture with advanced text representation methods performed
better than the classical text representation and classical machine learn-
ing algorithms. The primary reason for this is that the advanced text
representation methods have the capability to learn sequential proper-
ties which exist among the textual data and deep learning architectures
learns the optimal features along with decreasing the feature size.

Keywords: Information Extraction · Twitter · Cyber Security · Deep
learning.

1

Introduction

As social media is an interactive platform where individuals share thoughts,
information, professional interests and diﬀerent types of expression via virtual
communities and systems, it introduces a rich and timely source of informa-
tion on events occurring everywhere throughout the world [13]. Social media
giants like Facebook, Twitter, WhatsApp, etc enable a lot of applications like
recognizing the area of missing people during catastrophic events or earthquake

 
 
 
 
 
 
2

Simran et al.

detection. Past work on event extraction has depended on a large amount of
labeled information or taken an open-domain approach in which general events
are extracted without a particular core interest. Information analyst is often in-
terested in tracking a very speciﬁc type of event, for example, data breaches or
account hijacking and probably won’t have time or expertise to build an infor-
mation extraction framework from scratch in response to emerging incidents. To
address this challenge we introduce a deep learning approach for rapid training
cyber threat indicators for the Twitter stream.

Open-Source Intelligence (OSINT) provides a vital source of information and
has proven to be an important asset for Cyber Threat Intelligence (CTI). One of
OSINT rich sources is Twitter. Twitter’s popularity in the society provides an
environment for defensive and oﬀensive Cyber Security practitioners to debate,
and promote timely indicators of diﬀerent type of cyber events such as attacks,
malware, vulnerabilities, etc. Various initial reports of recent major cyber events
like the exposure of multiple “0-day”Microsoft Windows vulnerabilities, exposure
of ransomware campaigns [1] and user reports on DDoS attacks [2] exhibits the
value of Twitter data to CTI analysts.

Multiple frameworks for detecting as well as analysing the treat indicators in
Twitter stream have come from the research on Twitter-based OSINT collection.
However, most of these proposals have a high false-positive rate in detecting the
relevant tweets as they are using heavily manual heuristics like keyword lists that
are relevant to Cyber Security are used to detect and ﬁlter tweets. Furthermore,
potentially valuable information in tweets is getting neglected by the emergence
of new terminology and ﬂexible typography. In recent days, the applications of
deep learning with natural language processing methods leveraged in various Cy-
ber Security tasks [13,14,15,16,17,18,19,20]. These methods have obtained good
performance and most importantly, these methods performed well compared to
the classical machine learning classiﬁers.

The major contribution of this proposed work are given below:

1. This work proposes a deep learning based framework for cyber threat in-
dicators in the Twitter stream. The framework is highly scalable on using
commodity hardware.

2. To identify a proper tweet representation, various state-of-the-art text rep-
resentation exists in the domain of natural language processing (NLP) are
leveraged for cyber threat indicators in Twitter Stream.

3. To identify an optimal machine learning approach, we have carried out a
comprehensive and in-depth study of the application of classical machine
learning and deep learning theory in the context of cyber threat indicators
in Twitter stream.

4. In particular, we discuss several parameterization options for classical ma-
chine learning, deep learning, and tweet representation and we present a
large variety of benchmarks which have been used to either experimentally
validate our choices or to help us to take the adequate decision.

The remaining of this paper is arranged in the following order: Section 2
documents a survey of the related literature, followed by background related to

Deep Learning based Cyber Threat Indicators in Twitter

3

NLP and deep learning concepts in Section 3. Section 4 provides a description
of Cyber Security related tweets data set used in this work. Section 5 describes
the details of the proposed architecture. Section 6 reports the experiments and
observations made by the proposed architecture. Section 7 concludes the paper
as well as tells the remakes on future work of research.

2 Literature Survey

Classiﬁcation and detection of CTI extraction from Twitter are less investigated
compared to the other area, for example, crime prevention [3], identiﬁcation of
cyber-bullies [4], and disaster response [5]. To distinguish three sorts of threats
and events ie., account hijacking, data breaches, and Distributed Denial of Ser-
vice (DDoS) attacks, Khandpur et al. [6] proposed an architecture to separate
cyber threat as well as security information from the Tweets. Target domain gen-
eration, event extraction, and dynamically typed query expansion are the three
major segments of this framework. This methodology is powerful as it abuses
syntactic, semantic analysis and dependency tree graph yet it requires the per-
sistent tracking of features for each type of threat. It likewise requests a high
computational overhead to produce as well as keep the focus on corpus space of
tweet content for query extension. Also, this architecture can’t ﬂawlessly stretch
out to more classiﬁcations of threats and events.

Furthermore, categorizing Cyber Security events from tweets was proposed
by Le Sceller et al. [7]. The detection of events uses the taxonomy of Cyber
Security and a set of keywords that describes the event type. Expanding of the
set of seed keywords are performed by not only identifying but also attaching new
words with comparative meaning with regards to word embeddings utilizing a
physically indicated edge in the cosine similarity distance between word vectors.
Term frequency - inverse document frequency (TF-IDF) method which produced
events as groups of tweets was used in this framework. Inadvertent biasing eﬀects
of the initial seed keywords caused this algorithm to give a high false-positive
rate.

Security Vulnerability Concept Extractor (SVCE) was utilized to process
tweets in the structure proposed in [8]. SVSE is trained on a data set containing
reports of the national vulnerability database to recognize as well as label the
terms and ideas identiﬁed with CTI, for example, aﬀected software, consequences
of the attack and so forth. To additionally improve the extracted information,
the ideas and substances extracted by SVCE are examined dependent on out-
side freely accessible semantic learning bases such as DBPedia. The client needs
to specify a target framework proﬁle included data about installed software or
hardware, as this system is produced for client-based applications. As per the
information provided, an ontology is produced and utilized alongside SWRL
rules to address as well as organize time-delicate CTI entries. Later conversion
from separated and labeled CTIs to RDF triple proclamations is ﬁnished. The
ready alert system can reason over the information as RDF connected informa-

4

Simran et al.

tion portrayal is put away in the knowledge base. This framework is incapable
of distinguishing novel threat types and indicators.

In [9], ontology-based technique and Named Entity Recognition (NER) were
utilized to classify tweets as related events or not related events. This framework
performs topic identiﬁcation by means of cross-referencing NER results with
other external knowledge bases, for example, DBPedia utilizing Wikipedias Cur-
rent Event Portal just as human info gathered using Amazon Mechanical Turk,
produced an annotated data set of tweet event type and CTI. Diﬀerent machine
learning algorithms, for example, naive bayes, support vector machines (SVM)
and deep learning architectures such as long short term memory (LSTM), recur-
rent neural network (RNN) used this annotated data set and the best outcome
was delivered by LSTM architecture with word embedding. They additionally
show that particular classiﬁcations of NER are useful in classifying the classes
as well as event type, though the nonexclusive class of NER is useful in binary
classiﬁcation. Pagerank algorithm was used in this work for topic recognizable
proof.

[10] proposed a framework which recognizes inﬂuential user or community
of people to prioritize CTI information. This was ﬁnished utilizing a scoring
strategy that is scores were given to the user and community who produced CTI-
related tweets. This work has four segments. For gathering information from the
Twitter platform, a social media connector is referred as the principal segment.
The second segment is a module for recognizing and stretching out the rundown
of specialists to discover developing themes. The third segment comprises of
weight contribution and ﬁtness calculation. Lastly, to recognize emerging threats
the author proposed a topic detection algorithm. Anyhow, threat indicators are
not adequately referred by the specialists in this work.

The framework proposed in [11] is a weekly supervised learning approach
that trains a model for extracting new classes of Cyber Security events. This
framework does extraction by seeding a little amount of positive event tests over
a fundamentally amount of unlabeled data. The target to learn in this work is
done by regularizing the label distribution over the unlabeled distribution. This
work is vigorously reliant on historical seed and neglects to give the details of
coordinating named entities into an event category.

3 Background

3.1 Text representation

To represent the tweet into numeric form, we used various text representations in
this works. The basic idea behind these text representations is discussed below.

Bag-of-Words (TDM, TF-IDF): Bag-of-words is basically a collection of
words. So the texts (tweets) are represented as a bag of its words. Every unique
word passed as an input will have a position in this bag (vector). The vec-
tor records the frequency of the words in the tweets. Term document matrix

Deep Learning based Cyber Threat Indicators in Twitter

5

(TDM) and Term frequency-inverse document frequency (TF-IDF) are features
extracted from the documents. They are the measures used to understand the
similarities between the tweets. TDM will have each corpus word as rows and
document (tweet) as columns. The matrix represents the frequencies of the words
occurring in that particular tweet. The most used words are highlighted because
of their high frequency. TF-IDF tells how frequently a word occurs in a speciﬁc
record contrasted with the whole corpus. The uncommon words are featured to
demonstrate their relative signiﬁcance.

N-gram: N-gram is a contiguous order of n items from a given sample of
content (tweets). N-gram with N = 1 is known as a unigram and it takes
one word/character at once. N = 2 and N = 3 are called bigram and tri-
gram respectively and will take two and three words/characters at a time. If n
words/characters are to be taken at once then N will be equal to n.

Keras Embedding: Word Embedding basically converts words into a dense
vector of real numbers in such a way that sequence and word similarities are
additionally safeguarded. Keras oﬀers an Embedding layer which is initialized
with random weights. It will learn embedding of all the words in the training
set but the input word should be represented by a unique integer. Keras is an
open-source neural network library which contains various executions of gen-
erally utilized neural network building blocks. It also supports convolutional,
recurrent neural networks and other common utility layers like pooling, batch
normalization, and dropout.

fastText: fastText chips away at character n-gram level instead of just word
level (word2vec) and it is better for morphologically rich dialects. To convert
words into vectors it utilizes skip-gram and subword model. Given the present
word, skip-gram model predicts the surrounding words. In the event that window
size is 2, at that point we see just 5 vectors at once. The subword model will
see the internal structure of the words. In this model n-grams per word are
extracted. For example, her will have distinctive vector and n-gram her from the
word where will have a diﬀerent vector.

3.2 Deep learning

To understand which deep learning approach works for enhanced cyber threat
indicators in the Twitter stream, we used various deep learning architectures.
The basic idea behind diﬀerent deep learning approaches is given below.

Deep Neural Network: A deep neural network (DNN) is a neural network
with multiple layers which makes it somewhat mind-boggling. DNN contains
one input layer, at least one hidden layer, and one output layer. Each hidden
layer contains a rectiﬁed linear unit (ReLU). ReLU is an activation function

6

Simran et al.

which characterized the positive piece of its argument. It has less vanishing
gradient problems and computationally eﬃcient. Hidden layer is also called a
fully connected layer since every neuron in one layer is associated with every
neuron in the following layer.

Convolutional Neural Network: A convolutional neural network (CNN) oth-
erwise called ConvNet is a deep neural network which is based on shared-loads
architecture. It lessens the number of free parameters enabling the network to
be deeper with fewer parameters. Generally, CNN architecture contains convolu-
tion, pooling, and fully connected layers. The convolution operation is performed
using a number of ﬁlters which slide through the input and learns the features of
the input data. Pooling layer is used to decrease the size of the feature matrix.
The pooling can be min, max, or average. At the end of the CNN, there will
be at least one fully connected layer where all the neurons are connected to all
the neurons of its previous layer. Also in between these layers batchnomraliza-
tion and dropout can be used. Batch normalization layer allows the network to
learn by itself a little bit more independently of other layers and in turn reduces
overﬁtting as it has slight regularization eﬀects. Dropout is a regularization tech-
nique in which some neurons are randomly ignored during training the model.
This method is treated like a layer and makes neural networks with diﬀerent
architectures to train in parallel.

Recurrent Structures (RNN, LSTM, GRU): A recurrent neural network
(RNN) is a recurrent structure where associations between nodes form a directed
graph along a sequence. This enables RNN to display temporal dynamic behavior
for a time sequence that is applied to natural language processing (NLP). RNNs
can utilize their internal state to process arrangements of inputs yet can do it
for just a short amount of time i.e., they can not remember long term data.

Long short-term memory (LSTM) network is another recurrent structure
that contains a cell, and three gates namely, input, output, and forget gate. A
cell recalls esteems over discretionary time intervals and the three gates direct
the stream of data in and out of the cell. This makes LSTM remember long
term information. LSTMs were created to manage the vanishing and exploding
gradient problems that can be experienced when training conventional RNNs.

Gated recurrent unit (GRU) is an enhanced version of standard RNN and
is also considered as a minor variation from LSTM. To tackle the disappearing
gradient problem of a standard RNN, GRU utilizes update gate and reset gate.
These two vectors choose what information ought to be passed to the output.
They are exceptional in light of the fact that they can be trained to keep in-
formation from a long prior time, without washing it through time or evacuate
information which is superﬂuous to the expectation.

Deep Learning based Cyber Threat Indicators in Twitter

7

4 Description of the Data set

The data set for data analysis of tweets from Twitter social media resource is
provided by [12]. The authors used a stream listener to listen to the streaming of
tweets from Twitter. They selected a set of keywords in order to ﬁlter as well as
narrow down the results of the stream listener. The words like “0day” and “vul-
nerability” were selected for applicability to CTI. For producing more targeted
ﬁlters, words related to a particular type of threat were selected. Preprocessing
of the data set is also performed in [12]. The detailed statistics are tabulated in
Table 1 and 2.

Table 1. Binary class Twitter data samples.

Data set Relevant Irrelevant

Train

11,781

Test

2,989

5,313

1,285

Table 2. Multiclass Twitter data samples.

Category

Train data set Test data set

Vulnerability

Ransomware

DDoS

Data leak

General

Day

Botnet

5,926

2,549

1,776

106

5,588

585

564

1,428

654

469

30

1,410

145

138

5 Proposed Architecture

The proposed architecture is shown in Figure 1. The preprocessed tweets are
sent to Keras embedding layer where the words are converted into dense vectors.
These numerical features are passed into CNN and then to GRU layer for feature
generation. Finally, the output from GRU is sent to a fully connected layer for
classiﬁcation.

8

Simran et al.

Fig. 1. Proposed Architecture.

6 Experiments, Results and Observations

Scikit-learn4 and TensorFlow5 with Keras6 framework were utilized to imple-
ment classical machine learning algorithms and deep learning architectures re-
spectively. All the models are trained on GPU enabled TensorFlow. Various
statistical measures are utilized in order to evaluate the performance of the pro-
posed framework.

Preprocessing steps given in the proposed architecture section is followed for
the data set to convert the unstructured format into a structured format. In this
work, various text representation methods such as TDM, TF-IDF, 3-gram, and
embedding are employed. SVM is implemented along with TDM and TF-IDF.
SVM uses rbf kernel and c value of 100. Scikit-learn default parameters of TDM
and TF-IDF are used. As the tweet length is not huge and there are a lot of
important keywords used in tweets that might be the reason why TF-IDF has
performed better than TDM. We followed n-gram representation speciﬁcally 3-
gram is employed and we constructed a feature vector whose length will very
huge. So in order to decrease the dimension be employed featurization technique
to decrease the length of the sequence. This 1,000 length vector is passed into a
deep neural network (DNN). DNN contains three layers, the ﬁrst layer contains
1,024 neurons, the second layer contains 512 neurons and the third layer contains
128 neurons. In a sequential model, initially random weights are given to the
model and these random values will be updated based on the loss of the function
while backpropagation. When Keras embedding is employed along with the deep

4 https://scikit-learn.org/
5 https://www.tensorﬂow.org/
6 https://keras.io/

Deep Learning based Cyber Threat Indicators in Twitter

9

Table 3. Average performance metrics.

Model

Accuracy (%) Precision (%) Recall (%) F1-Score (%)

Binary class classiﬁcation

SVM-TDM

SVM-TF-IDF

DNN-3gram

CNN-Keras word embedding [12]

RNN-Keras word embedding

LSTM-Keras word embedding

GRU-Keras word embedding

81.9

82.2

82.9

83.6

83.1

84.3

84.7

CNN-GRU-Keras word embedding 85.8

fastText

84.4

68.8

69.2

73.5

71.4

71.7

70.1

73.9

73.7

74.6

Multiclass classiﬁcation

SVM-TDM

SVM-TF-IDF

DNN-3gram

CNN-Keras word embedding [12]

RNN-Keras word embedding

LSTM-Keras word embedding

GRU-Keras word embedding

86.2

86.3

86.9

87.5

87.0

88.0

88.4

CNN-GRU-Keras word embedding 89.3

fastText

87.9

86.2

86.4

87.0

87.8

87.1

88.1

88.8

90.3

88.0

72.8

73.6

67.6

75.9

72.1

83.1

76.0

82.3

73.2

86.2

86.3

86.9

87.5

87.0

88.0

88.4

89.3

87.9

70.7

71.3

70.4

73.6

71.9

76.0

74.9

77.8

73.9

86.2

86.3

86.9

87.6

87.0

88.0

88.5

89.3

87.9

learning model, updation of weight will take place upto the embedding layer
during backpropogation and not just stop at the deep neural layers. Since the
data set is not huge, word embedding like word2vec is not followed in this work.
Various deep learning classiﬁers like CNN, RNN, LSTM, GRU, CNN-GRU are
used along with Keras word embedding in order to ﬁnd the best deep learning
model. Embedding size of 128, batch-size of 32, learning rate of 0.01, 128 hidden
units, and Adam optimizer are hyperparameter value used by RNN, LSTM,
GRU, CNN, and CNN-GRU classiﬁers. The output layer consists of 1 neuron
in binary classiﬁcation and 7 neurons for multiclass classiﬁcation. In CNN, the
number of ﬁlters used is 64 and the ﬁlter length is 3. In CNN-GRU as well as
GRU, the number of hidden units used is 50. Finally, fastText is employed as
fastText has given better performance in recent day applications. The value of
parameters for fastText are learning rate of 0.1, dimension of 128, minimum
word count of 1, 100 epochs, and 2 N-grams. The average performance metrics
of all the models for binary and multiclass data set are reported in Table 3.
Among all, CNN-GRU along with Keras word embedding has performed better

10

Simran et al.

in both binary and multiclass classiﬁcation. For all the models, the training data
set is used for training the models and testing data set is used to test the trained
models.

7 Conclusion and Future Work

Twitter is one of the most popular social networks, where users share their
opinions on various topics. The tweet could be related to security. This work
evaluates the performance of various text representation techniques along with
various deep learning models for cyber threat indicators in the Twitter stream.
CNN-GRU with Keras embedding performed better than any other architecture
in both binary as well as multiclass classiﬁcation. The best part about the pro-
posed architecture is that it does not require any feature engineering technique
to be employed. Present and future work focus on event tracking and event
detection of cyber threats using social media resources like Twitter, Facebook,
etc.

Acknowledgements

This research was supported in part by Paramount Computer Systems and
Lakhshya Cyber Security Labs. We are grateful to NVIDIA India, for the GPU
hardware support to research grant. We are also grateful to Computational En-
gineering and Networking (CEN) department for encouraging the research.

References

1. A. Sapienza, A. Bessi, S. Damodaran, P. Shakarian, K. Lerman, and E. Ferrara,
Early warnings of cyber threats in online discussions, in Data Mining Workshops
(ICDMW), 2017 IEEE International Conference on. IEEE, 2017, pp. 667674
2. C. Sabottke, O. Suciu, and T. Dumitras, Vulnerability disclosure in the age of
social media: Exploiting twitter for predicting real-world exploits. in USENIX
Security Symposium, 2015, pp. 10411056.

3. T. Mackey, J. Kalyanam, J. Klugman, E. Kuzmenko, and R. Gupta, Solution to
detect, classify, and report illicit online marketing and sales of controlled sub-
stances via twitter: Using machine learning and web forensics to combat digital
opioid access, Journal of medical Internet research, vol. 20, no. 4, 2018.

4. P. Galan-Garca, J. G. d. l. Puerta, C. L. Gomez, I. Santos, and P. G. Bringas,
Supervised machine learning for the detection of troll proﬁles in twitter social
network: Application to a real case of cyberbullying, Logic Journal of the IGPL,
vol. 24, no. 1, pp. 4253, 2016.

5. Z. Ashktorab, C. Brown, M. Nandi, and A. Culotta, Tweedr: Mining twitter to

inform disaster response. in ISCRAM, 2014.

6. R. P. Khandpur, T. Ji, S. Jan, G. Wang, C.-T. Lu, and N. Ramakrishnan, Crowd-
sourcing cybersecurity: Cyber attack detection using social media, in Proceedings
of the 2017 ACM on Conference on Information and Knowledge Management.
ACM, 2017, pp. 1049 1057.

Deep Learning based Cyber Threat Indicators in Twitter

11

7. Q. Le Sceller, E. B. Karbab, M. Debbabi, and F. Iqbal, Sonar: Automatic detec-
tion of cyber security events over the twitter stream, in Proceedings of the 12th
International Conference on Availability, Reliability and Security. ACM, 2017, p.
23.

8. S. Mittal, P. K. Das, V. Mulwad, A. Joshi, and T. Finin, Cybertwitter: Using twit-
ter to generate alerts for cybersecurity threats and vulnerabilities, in Proceedings
of the 2016 IEEE/ACM International Conference on Advances in Social Networks
Analysis and Mining. IEEE Press, 2016, pp. 860867.

9. A. Edouard, Event detection and analysis on short text messages, Ph.D. disserta-

tion, Universite CotedAzur, 2017.

10. K.-C. Lee, C.-H. Hsieh, L.-J. Wei, C.-H. Mao, J.- H. Dai, and Y.-T. Kuang, Sec-
buzzer: cyber security emerging topic mining with open threat intelligence retrieval
and timeline event annotation, Soft Computing, vol. 21, no. 11, pp. 28832896, 2017.
11. A. Ritter, E. Wright, W. Casey, and T. Mitchell, Weakly supervised extraction
of computer security events from twitter, in Proceedings of the 24th Interna-
tional Conference on World Wide Web. International World Wide Web Confer-
ences Steering Committee, 2015, pp. 896905.

12. Behzadan, V., Aguirre, C., Bose, A., & Hsu, W. (2018). Corpus and Deep Learning
Classiﬁer for Collection of Cyber Threat Indicators in Twitter Stream. 2018 IEEE
International Conference on Big Data (Big Data), 5002-5007.

13. Vinayakumar, R., Alazab, M., Jolfaei, A., Soman, K. P., & Poornachandran, P.
(2019, May). Ransomware triage using deep learning: twitter as a case study. In
2019 Cybersecurity and Cyberforensics Conference (CCC) (pp. 67-73). IEEE.
14. Vinayakumar, R., Soman, K. P., Poornachandran, P., & Menon, V. K. (2019).
A Deep-dive on Machine Learning for Cyber Security Use Cases. In Machine
Learning for Computer and Cyber Security (pp. 122-158). CRC Press.

15. Vinayakumar, R., Soman, K. P., Poornachandran, P., Alazab, M., & Jolfaei, A.
(2019). DBD: Deep Learning DGA-Based Botnet Detection. In Deep Learning
Applications for Cyber Security (pp. 127-149). Springer, Cham.

16. Vinayakumar, R., Soman, K. P., Poornachandran, P., Akarsh, S., & Elhoseny,
M. (2019). Deep Learning Framework for Cyber Threat Situational Awareness
Based on Email and URL Data Analysis. In Cybersecurity and Secure Information
Systems (pp. 87-124). Springer, Cham.

17. Vinayakumar, R., Soman, K. P., Poornachandran, P., Akarsh, S., & Elhoseny, M.
(2019). Improved DGA Domain Names Detection and Categorization Using Deep
Learning Architectures with Classical Machine Learning Algorithms. In Cyberse-
curity and Secure Information Systems (pp. 161-192). Springer, Cham.

18. Vinayakumar, R., Alazab, M., Srinivasan, S., Pham, Q. V., Padannayil, S. K., &
Simran, K. (2020). A Visualized Botnet Detection System based Deep Learning for
the Internet of Things Networks of Smart Cities. IEEE Transactions on Industry
Applications.

19. Vinayakumar, R., Alazab, M., Soman, K. P., Poornachandran, P., & Venkatraman,
S. (2019). Robust intelligent malware detection using deep learning. IEEE Access,
7, 46717-46738.

20. Vinayakumar, R., & Soman, K. P. (2020). Siamese neural network architecture

for homoglyph attacks detection. ICT Express, 6(1), 16-19.

