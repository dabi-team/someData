1
2
0
2

v
o
N
0
2

]

R
C
.
s
c
[

1
v
7
6
4
5
1
.
1
1
1
2
:
v
i
X
r
a

Car drivers’ privacy concerns and trust
perceptions

Giampaolo Bella1, Pietro Biondi1, and Giuseppe Tudisco1

Dipartimento di Matematica e Informatica
Universit`a degli Studi di Catania, Catania, Italy
giamp@dmi.unict.it
pietro.biondi@phd.unict.it
giuseppe.tudisco@studium.unict.it

Abstract. Modern cars are evolving in many ways. Technologies such
as infotainment systems and companion mobile applications collect a
variety of personal data from drivers to enhance the user experience.
This paper investigates the extent to which car drivers understand the
implications for their privacy, including that car manufacturers must
treat that data in compliance with the relevant regulations. It does so
by distilling out drivers’ concerns on privacy and relating them to their
perceptions of trust on car cyber-security. A questionnaire is designed
for such purposes to collect answers from a set of 1101 participants, so
that the results are statistically relevant. In short, privacy concerns are
modest, perhaps because there still is insuﬃcient general awareness on
the personal data that are involved, both for in-vehicle treatment and for
transmission over the Internet. Trust perceptions on cyber-security are
modest too (lower than those on car safety), a surprising contradiction
to our research hypothesis that privacy concerns and trust perceptions
on car cyber-security are opponent. We interpret this as a clear demand
for information and awareness-building campaigns for car drivers, as well
as for technical cyber-security and privacy measures that are truly con-
siderate of the human factor.

Keywords: Automotive · Cyber physical systems · Crowdsourcing ·
Personal data

1

Introduction

The cars people are driving at present are complicated cyber-physical systems
involving tight interaction between rapidly evolving car technologies and their
human users, the drivers. To meet the needs and preferences of (at least) drivers,
the infotainment system is more and more integrated with the setups for pas-
sengers’ physical preferences, such as seating conﬁguration, driving style and
air conditioning, as well as for non-physical preferences, such as music to play,
preferred numbers to call and on-line payment details.

A plethora of data originates, whose processing enhances the driving experi-
ence and exceeds that towards increased support for autonomous driving, a goal

 
 
 
 
 
 
2

Bella et al.

of large interest at present. Modern cars also come with Internet connectivity
ensuring, at least, that car software always gets over-the-air updates from the
manufacturer. Cars expose services remotely via dedicated apps that the driver
installs on their smartphone to remotely operate functions such as electric doors,
air conditioning, headlights, horn and even start/stop the engine. Therefore, car
and driver’s smartphone apps form a combined system that exposes innovative
services, including locating the car remotely via GPS or even geo-fencing it, so
that the app user would be notiﬁed if their car ever exceeds a predeﬁned geo-
graphical area [1]. Because cars are progressively resembling computers, oﬀering
services while treating personal data, they also attract various malicious aims.
The ﬁeld of car cyber-security shows that software vulnerabilities can be ex-
ploited on a Jeep [10], on a General Motors [6] as well as on a Tesla Model S [2].
Such vulnerabilities may, in particular, impact data protection, and the sequel
of this manuscript will discuss the variety of personal data treated through cars,
thus calling for compliance, at least in the EU, with the General Data Protection
Regulation (GDPR) [5]. Car cyber-security (“security”, in brief) is certain to be
more modern than car safety, hence our overarching research goal is to under-
stand whether the former is understood as well as the former is. We formulate
the hypothesis that privacy concerns decrease when trust perceptions on the
underlying security and data protection measures are correspondingly high. For
example, it means that if a driver feels that their personal data is protected, then
that is because the driver trusts that the car is secure. To assess such hypoth-
esis, this paper does not take a common attack-then-ﬁx approach but, rather,
addresses the following research questions pivoted on drivers’ perceptions.

RQ1. Are drivers adequately concerned about the privacy risks associated with

how that their car and its manufacturer treat their personal data?

RQ2. Do drivers adequately perceive the trustworthiness of their car, in terms

of security especially?

We are aware that these research questions are not conclusive, and we have
gathered data to specialise the answers by categories of drivers, e.g. by age
or education. To the best of our knowledge, this is the ﬁrst large-scale study
targeting and relating privacy concerns and trust perception of car drivers. We
took the approach of questionnaire development and survey execution through
a crowdsourcing platform. Our goal was to get at least 1037 sets of responses in
order for the ﬁndings to be statistically relevant, as explained below. We ﬁrst
piloted the questionnaire with 88 friends and colleagues with the aim of getting
feedback but no signiﬁcant tuning was required. After crowdsourcing, a total
number of 1101 worldwide participants was reached.

We analysed the results obtained from the questionnaire through standard
statistical analysis by Pearson’s correlation coeﬃcient, Spearman’s rank corre-
lation coeﬃcient and Coeﬃcient Phi. In a nutshell, most drivers believe that it
is unnecessary for their car to collect their personal data because they ﬁnd the
collection unnecessary to the full functioning of modern cars; this indicates that
privacy concerns are low, which in turn may be due to wrong preconceptions,
given that cars do collect personal data. Also, it appears that most drivers do

Car drivers’ privacy concerns and trust perceptions

3

not fully agree that their data is protected using appropriate security measures;
this may be interpreted as a somewhat low trust on security. To our surprise,
pairing these two abstracted ﬁndings clearly disproves our hypothesis.

Section 2 comments on the related work, Section 3 outlines our research
method, particularly the questionnaire design, the crowdsourcing task and the
statistical approach, Section 4 discusses our results and Section 5 concludes.

2 Related Work

In 2014, Schoettle and Sivak [9] surveyed public opinions in Australia, the United
States and the United Kingdom regarding connected vehicles. Their research
noted that people (drivers as well as non-drivers) expressed a high level of con-
cern about the safety of connected cars, which does not seem surprising on the
basis of the novelty of the concept at the time. However, participants demon-
strated an overall positive attitude towards connected car technology, with par-
ticular interest in device integration and in-vehicle Internet connectivity. In 2016,
Derikx et al. [4] investigated whether drivers’ privacy concerns can be compen-
sated by oﬀering monetary beneﬁts. They analysed the case of usage-based auto
insurance services where the rate is tailored to driving behaviour and measured
mileage and found out that drivers were willing to give up their privacy when
oﬀered a small ﬁnancial compensation. Therefore, what appears to be missing
is a study on drivers’ understanding on the amount and type of personal data
that modern cars process, which is the core of this paper.

There are relevant publications on drivers’ trust on car safety but are limited
to self-driving cars. Notably, Du et al. [7] conducted an experiment to better
understand whether explaining the actions of automated vehicles promote gen-
eral acceptance by the drivers. They found out that the speciﬁc point in time
when explanations were given was crucial for their eﬀectiveness — explanations
provided before the vehicle started were associated with higher trust by the sub-
jects. Similar results were obtained by Petersen et al. [8] in another study in
2019. They manipulated drivers’ situational awareness by providing them with
diﬀerent types and details of information. Their analysis showed that situational
awareness inﬂuenced the level of trust in automated driving systems, allowing
drivers to immerse themselves in non-driving activities. Clearly, the more people
are aware of something, the more trust they manage to place in it.

It is clear that modern cars technologies are not limited to self-driving fea-
tures. Modern cars include innumerable digital components, often integrated in
the infotainment system, which interact with drivers and collect their data. It
follows that modern cars process personal data to some extent, as detailed in the
next Section, hence car manufacturers must meet speciﬁc sets of requirements to
comply with the relevant regulations. Therefore, it becomes important to assess
drivers’ concerns on their privacy through their use of a car and drivers’ trust
on the security (also in relation to their trust on the safety) of the car.

4

Bella et al.

3 Research method

We took the approach of questionnaire development and survey execution to
assess car drivers’ privacy concerns and trust perceptions. Speciﬁcally, we built
questionnaire with 10 questions, administered it through a crowdsourcing plat-
form and carried out a statistical analysis of the answers. Opinions were mea-
sured using a standard 7-point Likert scale. With a very low margin of error, of
just 4%, and a very high conﬁdence level, of 99%, the necessary sample size to
represent the worldwide population is 1037. Our total respondents were 1101,
including piloting over 88, so our ﬁndings are statistically relevant of the entire
world — a limitation is that, while Proliﬁc ensures that respondents are some-
how geographically dispersed, it cannot guarantee that they are truly randomly
sampled from the entire world.

4 Results

The answers are catalogued and statistically studied by analysing indexes of
central tendency and correlation coeﬃcients. The indexes of central tendency
(mean and median) synthesise with a single numerical value the values assumed
by the data. The mean value is coupled with the standard deviation in order to
measure the amount of variation of the values. There is no room to present the
demographic and its correlations with other answers here; we recall that driving
at least 3 hours a week was a prerequisite to enter the study, along with being
over 18.

To simplify the analysis of the answers to the core questions, we follow the
standard practice of grouping the 7 levels of agreement into three categories.
Speciﬁcally, if the participants reply with “Strongly agree”, “Agree” or “Some-
what agree”, then we consider their value as “Agreeing”; if instead they select
“Neither agree nor disagree”, then we consider them in the category “Unde-
cided”; and ﬁnally, if the participants select “Somewhat disagree”, “Disagree”
or “Strongly disagree”, then we consider those answers as “Disagreeing”.

Knowledge on modern cars Question Q1 evaluates the driver’s knowledge on
modern cars. Considering the values of the mean and the median, shown in Ta-
ble 1, it can be stated that the interviewed sample considers itself knowledgeable
about modern cars. The data show that 55% of participants are quite conﬁdent
about their knowledge, while a minority of the participants (about 29%) think
they are not. Finally, 16% of participants think they have average knowledge
about modern cars. Thus, considering the answers of the preliminary question,
there does not seem to be a substantial diﬀerence between those who drive a few
hours a week and those who drive more with regard to the level of knowledge
they claim to have on modern cars.

Then, question Q2 asks respondents whether or not they agree that modern
cars are similar to modern computers. Also this question receives a high rate of
agreement. We note that 72% of participants agree that a modern car is similar

Car drivers’ privacy concerns and trust perceptions

5

to a modern computer. Furthermore, it turns out that 14% of them are undecided
while 14% of them disagree with the statement. The mean and the median are
shown in Table 1.

Table 1: Q1, Q2 answers and their statistics

Knowledge level

[%]

Agreement level

[%]

55
Knowledgeable about modern cars
16
Average knowledge
Not knowledgeable about modern cars 29

Agreeing
Disagreeing
Undecided

72
14
14

Mean
Median
Standard Deviation

4.37
5
1.55

Mean
Median
Standard Deviation 1.35

5
5

Concerns on data privacy The ﬁrst of these questions (Q3) asks participants
to select all the categories of data they think a car collects. It must be remarked
that this answer allows for multiple choice, so a respondents can choose from mul-
tiple categories of data. Table 2 shows the answers selected by the respondents.
The predominant categories according to the interviewed sample are: “personal
data about the driver” (selected by 56% of the sample); “public data about the
driver” (selected by 54% of the sample); “public data not about the driver” (se-
lected by 47% of the sample). A few participants think that their vehicle collects
more sensitive data belonging to the special categories of personal (13%) and
ﬁnancial data (11%). Finally, we note that just 8% of the participants think that
modern cars do not collect any data at all.

Overall, these ﬁndings conﬁrm a modest level of awareness in terms of what
data a car collects. In particular, while it is positive that the majority (56%)
understands that driver’s personal data are involved, it is concerning that a
similar subset (54%) deem such data about the driver to have been made public.
It would be surprising if any car manufacturer’s privacy policy stated that the
driver’s collected data would be made public (and such policies are well worthy
of a dedicated comparative study). This potential confusion calls for awareness
campaigns, more readability of oﬃcial documents and innovative technologies to
ensure policies are understood. By contrast, a positive sign that a small kernel
of participants is highly informed is the appreciable understanding that special
categories of personal data (13%) or ﬁnancial data (11%) may be gathered.

Question Q4 asks participants whether they think it is necessary to collect
personal data to achieve full vehicle functionality. The indexes and a summary
of the answers are shown in Table 3. It shows that 27% of the participants agree
with the statement above, moreover, 19% of them are undecided and 54% of
them disagree with the statement. Thus, we could argue that the participants
disagree with the statement proposed in the question.

6

Bella et al.

Table 2: Q3 answers

Collected data

[%]

56
Personal data about the driver
54
Public data about the driver
47
Public data not about the driver
Special categories of personal data about the driver 13
11
Financial data about the driver
8
No data at all

This ﬁnding can be interpreted in various ways. On one hand, it denounces a
false preconception because that the customised, driver-tailored experience that
is getting more and more common at present is certain to stand on a trail of
data collected about the driver’s. It clearly also signiﬁes that drivers are neither
adequately informed on what data is being collected and for what purposes,
contradicting art. 5 of GDPR, nor have they been able to grant an informed
consent, contradicting art. 7 of GDPR.

Table 3: Q4, Q5 answers and their statistics

Agreement level

[%]

Agreement level

[%]

Agreeing
Disagreeing
Undecided

27
54
19

Agreeing
Disagreeing
Undecided

21
65
14

Mean
Median
Standard Deviation 1.58

3.35
3

Mean
Median
Standard Deviation 1.67

2.97
3

Moving on to the answers of question Q5, it can be noticed that just 21%
of the sample agrees to the transmission of data over the Internet, only 14% of
participants are undecided moreover 65% of them disagree with the statement.
This means that the sample is not very convinced to send personal data over
the Internet. Table 3 shows agreement levels and indexes of Q5’s answers.

This may again be interpreted as a wrong preconception because it is clear
that remote services, including eCall, location-tailored weather forecasts, music
streaming and many others, must generate Internet traﬃc.

Perceptions of trust on safety Question Q6 asks whether participants agree
that a modern vehicle safeguards the life of its driver. The agreement levels and
the indexes of central tendency are shown in Table 4. It turns out that 77%
of participants agree with the statement above, then just 8% disagree with the
statement, and 15% of them are undecided.

Car drivers’ privacy concerns and trust perceptions

7

Question Q7 asks participants whether a modern car protects its driver’s
personal data better than its driver’s life. It appears that a part of the sample
is undecided with this statement (26%), just 18% of participants agree with the
statement moreover 56% of them disagree. Table 4 shows also that the indexes
of central tendency are not as high when compared to the previous question.

There is considerable uncertainty in front of this question, if not for the
majority’s expression of disagreement (56%). It signiﬁes that trust on security
still has a great lot to grow in comparison to trust on safety, perhaps due to the
much longer establishment of the latter. It is well known that trust may take a
long time to root, and car security is certain to be a somewhat recent problem.

Table 4: Q6, Q7 answers and their statistics

Agreement level

[%]

Agreement level

[%]

Agreeing
Disagreeing
Undecided

77
8
15

Agreeing
Disagreeing
Undecided

18
56
26

Mean
Median
Standard Deviation 1.20

5.26
5

Mean
Median
Standard Deviation 1.46

3.26
4

Perceptions of trust on security Question Q8 asks whether the data col-
lected from the vehicle is legitimately processed according to the relevant reg-
ulations. Table 5 shows that 44% of the participants agree with this statement
moreover 25% disagree and the rest of them (31%) are undecided.

Trust one the legitimacy of the data processing is not higher than 44%. This
indicates, once more, that car drivers need to be better informed, ﬁrst of all.
Conversely, this means that the majority, 56%, are not sure about the legitimacy
of the processing of their personal data. Being informed correctly is essential for
raising awareness, which in turn is essential for trust building.

Question Q9 asks if participants believe that the personal data collected
is systematically analysed and evaluated using automated processes (including
proﬁling). From Table 5, around 42% of participants agree with this statement,
moreover 32% of them disagree and 26% are undecided with the statement.

This question is designed to be self-contained and understandable by every-
one. A notable 42% show concern that proﬁling takes place, which may be taken
to signify a correspondingly low trust on the security of the treatment. There
is no oﬃcial public information on whether car manufacturers really carry out
proﬁling but, if this were the case, then a Data Protection Impact Assessment,
pursuant art. 35 of GDPR, would have been necessary.

The last question (Q10) asks whether the participants feel that the data
transmitted over the Internet are protected by adequate technologies. Table 5

8

Bella et al.

conﬁrms the representation that agrees with the question (46%) to be consider-
able. The fact that those who agree do not exceed the majority of the sample
clearly indicate, also in this case, room for improving drivers’ trust on security.

Table 5: Q8, Q9, Q10 answers and their statistics

Agreement level

[%]

Agreement level

[%]

Agreement level

[%]

Agreeing
Disagreeing
Undecided

44
25
31

Agreeing
Disagreeing
Undecided

42
32
26

Agreeing
Disagreeing
Undecided

46
32
22

Mean
Median
Standard Deviation 1.31

4.28
4

Mean
Median
Standard Deviation 1.43

4.07
4

Mean
Median
Standard Deviation 1.49

4.19
4

4.1 Correlations

There are statistically signiﬁcant correlations that arise by analysing the rel-
evant coeﬃcients over the data obtained from the sample. In brief, Pearson’s
linear correlation coeﬃcient, denoted by the letter r, allows us to evaluate a pos-
sible linearity relationship between two sets of data. Spearman’s rank correlation
coeﬃcient, denoted by the Greek letter ρ, measures the correlation between two
numerical variables; these must be sortable because Spearman’s correlation co-
eﬃcient is deﬁned as Pearson’s correlation coeﬃcient applied to the ranks. The
Phi coeﬃcient (or mean square contingency coeﬃcient), denoted with the Greek
letter φ, is a measure of association for two binary variables and is calculated
from the frequency distributions of the pairs. Correlation coeﬃcient values are
accompanied by a signiﬁcance level (the p-value) to establish the reliability of
the calculated value. The p-value is a number between 0 and 1 representing
the probability that the result would have been obtained if the data had not
been correlated. If the p-value is less than 0.01 then the relationship found is
statistically signiﬁcant.

The analysis looks at the core questions, those from Q1 to Q10, to focus on
general correlations between knowledge on the subject matter, privacy concerns,
trust perceptions of safety and on security.

Core question analysis We noted a signiﬁcant correlation between question
Q1 and question Q2 (ρ = 0.48, p < 0.001). Therefore, it seems that participants
who are knowledgeable about modern cars also think that modern cars are sim-
ilar to modern computers, reinforcing the conclusion. Moreover, thanks to the
correlation between question Q1 and question Q4 (ρ = 0.35, p < 0.001) we can
state that those who consider themselves informed about modern cars also be-
lieve that the data collected by the car is necessary for the full functioning of the

Car drivers’ privacy concerns and trust perceptions

9

car. This aligned with our own, specialist view. There is also a signiﬁcant corre-
lation between question Q1 and question Q6 (ρ = 0.40, p < 0.01), that is, those
who are knowledgeable about modern cars think that a modern car safeguards
its driver’s life. Somewhat surprisingly, it appears that Q1 does not signiﬁcantly
correlate with later questions on trust on car security, signifying that trust on
security must grow even for those who are knowledgeable about the ﬁeld.

We calculated the Phi coeﬃcients between the answers of question Q3 to
determine if there are any associations, i.e. whether there are pairs of categories
of personal data that appear together in the answers. The coeﬃcient values
are shown in Table 6, and it becomes apparent that there are only two values
that may establish a possible association. The Phi Coeﬃcient obtained between
the couple “Special categories of personal data” and “Financial data about the
driver” is 0.3255, which means that those who think that ﬁnancial data are
collected by modern cars also think that special categories of personal data are
collected as well. This exhibits a correct preconception because ﬁnancial data
are routinely grouped with special categories of data. Also, given the 0.3363
value, we notice that drivers who think “Special categories of personal data”
are collected from the car, also think that “Personal data about the driver” are
collected, emphasising a correct understanding that personal data also include
the special categories (of personal data).

No Data Fin

Table 6: Phi Coeﬃcients of question 3
φ
No Data
Fin
Spec
Pub

1
-0.0920
-0.0999 0.3255
-0.2371 0.0004 -0.0624

Spec

1

1

1

Pub Pubdriver Pers

Pubdriver -0.2973 0.1468 0.0759 0.0255
-0.3136 0.2332 0.3363 -0.2099

Pers

1
0.1743

1

Moving on to question Q4, there is a strong statistically signiﬁcant correlation
between question Q4 and question Q5: both the Pearson coeﬃcient and the
Spearman coeﬃcient have very high values (r = 0.55, ρ = 0.68) both with a
reliability value p < 0.001. In consequence, we can aﬃrm that those who think
that it is necessary to collect personal data for the full functioning of their vehicle
also think that this data should be transmitted over the Internet. There is also
another statistically signiﬁcant correlation between question Q4 and question
Q8 (r = 0.39, ρ = 0.50, p < 0.01 for both), showing that those who agree to the
collection of personal data also think that the data are processed legitimately in
a manner consistent with the relevant regulations. Both of these can be taken as
indications that those with modest privacy concerns show some trust on security,
but we are mindful of the generally low agreement with Q4 and Q5 and only fair
agreement with Q8 noted above.

Question Q5 correlates only moderately with question Q8 (ρ = 0.48, p <
0.01) but more signiﬁcantly with question Q10 (r = 0.36, ρ = 0.52, p < 0.01). It

10

Bella et al.

follows that those who think that data should be transmitted over the Internet,
also think that this data will be adequately protected during transmission. This
shows that trust on security is broad if present.

Spearman’s correlation coeﬃcient detects a moderately signiﬁcant correlation
between question Q6 and question Q8 (ρ = 0.45, p < 0.01), so that it seems that
those who think that a modern car safeguards its driver’s life also think that
the personal data collected are processed legitimately according to the relevant
regulations in force. This seems a positive outcome in terms of a spreading of
trust on safety over trust on security. It is unfortunate that this correlation is not
very strong, and we deem it highly desirable to develop socio-technical security
and privacy measures to reinforce it in the future.

There is a statistically signiﬁcant correlation between question Q7 and ques-
tion Q10 (r = 0.38, ρ = 0.52, p < 0.01). In fact, those who think that a modern
car protects its driver’s personal data better than it safeguards its driver’s life
also think that the personal data are protected by adequate technology when the
vehicle transmits it over the Internet. The Spearman’s correlation coeﬃcient also
shows a signiﬁcant correlation between question Q7 and question Q8 (ρ = 0.47,
p < 0.01), that is, those who think that a modern car protects its driver’s data
better than it safeguards its driver’s life also think that the personal data col-
lected are processed legitimately according to the relevant regulations. These
ﬁndings conﬁrm that trust on security is somehow “logical” in the sense that it
covers all relevant elements.

There is also a signiﬁcant correlation between question Q8 and question Q9
(ρ = 0.41, p < 0.01), it appears that those who think that modern cars carry
out a systematic and extensive evaluation of personal data also think that their
data are processed in a legitimate way according to relevant regulations. This
correlation suggests that drivers who consent to the evaluation of their personal
data even consent to proﬁling — perhaps too lightheartedly, raising concern that
the potentially negative consequences of proﬁling may not be fully understood
at present. It may be inferred that drivers are not fully aware that it would be
their right to object to proﬁling, as prescribed by art. 22 of GDPR.

We also noted a moderate correlation between question Q9 and question Q4
(ρ = 0.45, p < 0.01). Those who think that in order to use the full functionality
of the car it is necessary to provide personal data also think that this data is
analysed and studied according to automatic processes to evaluate personal as-
pects of drivers. This reconﬁrms that proﬁling is somewhat ill-understood. There
is also a statistically signiﬁcant correlation between question Q9 and question
Q5 (ρ = 0.46, p < 0.01) indicating that those who think that their data are
analysed by automatic evaluation processes also think that they are transmitted
over the Internet. This outcome correctly indicates that potential proﬁling does
not take place aboard the car.

There is a statistically signiﬁcant correlation between question Q10 and ques-
tion Q4 (r = 0.37, ρ = 0.49, p < 0.01), that is, those who think that the personal
data collected by the vehicle is necessary for the full functioning of the car also
think that their data is adequately protected when transmitted over the Inter-

Car drivers’ privacy concerns and trust perceptions

11

net. Once more, modest privacy concerns lead to some trust on security. Finally,
there is a statistically signiﬁcant correlation between question Q10 and ques-
tion Q8 (r = 0.51, ρ = 0.64, p < 0.01), so we can argue that those who think
that their personal data is processed lawfully also think that the data are ade-
quately protected over the Internet. Here is yet another conﬁrmation that trust
on security, if at all present, covers all relevant aspects.

5 Conclusions

Our study was designed with care to carve out drivers’ privacy concerns and trust
perceptions with the ultimate aim of assessing our research hypothesis that low
privacy concerns imply high trust perceptions. Crowdsourcing was leveraged to
collect a representative sample of participants. Answers were then analysed in
isolation as well as statistically correlated, producing very many insights. There
would be little use in developing amazing technical security and privacy measures
for preserving drivers’ privacy and the security of their cars in case drivers are
not adequately concerned about the privacy issues bound to their driving and
yet do not trust the security of their cars at an appropriate level. That case is
conﬁrmed by the results of our study, thus contradicting our research hypothesis.
We consider this outcome worthy of further attention.

Precisely, we believe that the privacy concerns that arose are insuﬃcient in
the present technological setting. We would have found it more positive if drivers
exhibited higher awareness on the personal data involved through their driving,
on how treating such data is fundamental for delivering driver-tailored services,
and on the fact that such service quality often demands data transmission over
the Internet. Unfortunately, the opposite scenario holds. A somewhat logical ex-
planation of low privacy concerns could be a high trust on security, but we were
surprised once more that also trust on security was somewhat low. Therefore, the
only way to read the general outcome is that privacy is generally ill-understood
by drivers, hence we learn that more information must be delivered to them
in order to raise awareness and then form correct privacy concerns and cor-
respondingly adequate trust perceptions. We strongly argue that this must be
the ultimate eﬀect for the development of more and more advanced technical
security and privacy measures.

The correlations among answers could be seen as somewhat logical. For ex-
ample, knowledge on the ﬁeld correlates with adequate privacy concerns and
well-related trust perceptions. It is noteworthy that the potentially negative im-
plications of proﬁling on the freedoms of natural persons are far from being well
received at the moment. Trust on security is much less represented than trust on
safety, arguably because the former derives from a less rooted perception in our
society due to the relatively young age of the technologies that should support
it. Moreover, trust on cyber-security is normally broad, that is, if it is present
to some extent, it then covers all relevant aspects. We ultimately maintain that
also correlations justify a need for more awareness and trust building campaigns.

12

Bella et al.

The value of our results is multifaceted. They can be read in support of the
ISO/SAE DIS 21434 standard, which is yet to be ﬁnalised. They also oﬀer a
solid baseline to conduct a cyber-security and privacy risk assessment on cars
following standard methodologies such as ISO/IEC 27005. Future work includes
tailoring the eﬀort presented in this paper to speciﬁc car brands in support of a
contrastive analysis among brands. It is clear that the user-level studies in the
automotive ﬁeld that this paper incepted have great potential for growth.

Acknowledgments This research was funded by COSCA (COnceptualising Secure
Cars) [3], a project supported by the European Union’s Horizon 2020 research
and innovation programme under the NGI TRUST grant agreement no 825618.

References

1. ACKO:

Connected

Cars: What

is

it?

Features

and

Beneﬁts.

https://www.acko.com/car-guide/connected-cars-features-benefits/
(2020)

2. Constantin, L.: Researchers hack Tesla Model S with remote

attack.

https://www.pcworld.com/article/3121999/researchers-demonstrate-remote-attack-against-tesla-model-s.html
(2016)
3. COSCA

(COSCA) Website.

CArs

Secure
https://cosca-project.dmi.unict.it/ (2020)

COnceptualising

Team:

4. Derikx, S., de Reuver, M., Kroesen, M.: Can privacy concerns

for
be
Electronic Markets
https://doi.org/10.1007/s12525-015-0211-0,

compensated?

insurance
26(1),
https://doi.org/10.1007/s12525-015-0211-0

connected
(Feb

cars
2016).

of
73–81

5. European Union: General Data Protection Regulation (EU Regulation 2016/679).

https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=OJ:L:2016:119:FULL
(2016)

6. Jeﬀ

Crume:

OwnStar:

Yet

another

car

hack.

https://insideinternetsecurity.wordpress.com/2015/08/05/ownstar-yet-another-car-hack/
(2015)

trust,

on driver’s

explanations

talking now:

7. N. Du and J. Haspiel et al.: Look who’s

Implications of
av’s
anxiety and men-
tal workload. Transportation Research Part C: Emerging Technolo-
https://doi.org/10.1016/j.trc.2019.05.025,
gies
http://www.sciencedirect.com/science/article/pii/S0968090X18313640
8. Petersen, Luke and Robert, Lionel and Yang, Xi Jessie and Tilbury, Dawn: Situ-
ational Awareness, Driver’s Trust in Automated Driving Systems and Secondary
Task Performance (may 2019)

av preference,

(2019).

104,

428

442

–

9. Schoettle, B., Sivak, M.: A survey of public opinion about connected vehi-
cles in the U.S., the U.K., and Australia. In: 2014 International Conference
on Connected Vehicles and Expo (ICCVE). pp. 687–692. IEEE (11 2014).
https://doi.org/10.1109/ICCVE.2014.7297637

10. Valasek, C., Miller, C.: Remote Exploitation of an Unaltered Passenger Vehicle.

http://illmatics.com/Remote%20Car%20Hacking.pdf (2015)

