7
1
0
2

n
u
J

5

]
P
A

.
t
a
t
s
[

1
v
0
4
6
0
0
.
7
0
7
1
:
v
i
X
r
a

Detecting periodic subsequences in cyber

security data

Matthew Price-Williams1, Nick Heard1,2, and Melissa Turcotte3

1Department of Mathematics, Imperial College London

2Heilbronn Institute for Mathematical Research, University of Bristol

3Advanced Research in Cyber Systems, Los Alamos National Laboratory

April 2017

Abstract

Statistical approaches to cyber-security involve building realistic probability mod-

els of computer network data. In a data pre-processing phase, separating automated

events from those caused by human activity should improve statistical model build-

ing and enhance anomaly detection capabilities. This article presents a changepoint

detection framework for identifying periodic subsequences of event times. The open-

ing event of each subsequence can be interpreted as a human action which then

generates an automated, periodic process. Diﬃculties arising from the presence of

duplicate and missing data are addressed. The methodology is demonstrated using

authentication data from the computer network of Los Alamos National Laboratory.

1

 
 
 
 
 
 
1 Introduction

Recent statistical approaches to cyber-security defence [1, 2] utilize anomaly detection

techniques based upon statistical models of normal network behavior, analyzing devia-

tions in an attempt to identify malicious actors. Regarding the arrivals of communica-

tions between each pair of hosts in a computer network as a point process of event times

on R+, this article proposes a method to distinguish between automated network events

and those caused by human behavior.

Polling behavior at a constant periodicity is a common feature of automated signal

traﬃc. [3] presents a method to detect overall polling behavior in a sequence of event data

using Fourier analysis. The work presented here aims to detect more complex polling

behavior where the entire traﬃc sequence can be split up into periodic subsequences,

separated by more random durations of inactivity.

In this scenario, the start of each

periodic subsequence is a user-driven event that initiates subsequent automated polling

events that beacon at a constant periodicity. Since the user-driven events are not labeled,

inferring their identities between the bulk of automated, periodic events can be viewed

as a changepoint detection problem.

When the method of [3] is applied to periodic subsequences of event data, detection

performance can be seen to deteriorate when the lengths of each periodic subsequence are

relatively short. This provides justiﬁcation for devising bespoke procedures for detecting

periodic subsequences.

Treating automated and user-driven data separately should provide a more robust

framework for modeling network data, whereby bespoke models can be speciﬁed for each

type of behavior. Alternatively, as a data reduction tool, identifying only user-driven

events represents a signiﬁcant thinning of the bulk of computer network data, poten-

tially improving anomaly detection capabilities. Examples of periodic subsequences in

2

network data can occur in the constant refreshing of an open webpage, or when validating

log on credentials in authentication data [4].

This article focuses on two types of polling behavior which can be observed in com-

puter network data, each exhibiting a hypothetical periodicity P in diﬀerent ways:

1. Fixed phase polling: Event times occur every P seconds plus a random zero-mean

error; any delay in one event time does not propagate into future event times.

2. Fixed duration polling: Event times occur P seconds after the preceding event, plus

a random zero-mean error.

In this article a full generative model is proposed for event times exhibiting both types of

polling. These models are robust to both missing and duplicate data.

Section 2 will describe the data used for analysis, taken from the Los Alamos National

Laboratory computer network. Section 3 will introduce the screening method used for

detecting periodicity in a sequence of event times, demonstrating eﬀectiveness in the

presence of periodic subsequences. Section 4 will show how directional statistics can be

used to model the error terms of periodic events as angular displacements. Sections 5

and 6 will describe how changepoint detection methods can identify separate periodic

subsequences conditional on an underlying model. Section 7 will present results from

both a simulated data example which exhibits ﬁxed phase polling, and the real computer

network data which exhibits ﬁxed duration polling.

2 Computer Network Authentication

The data analyzed are authentication logs collected over 58 days from the Los Alamos

National Laboratory (LANL) internal computer network [5, 4]. The authentication logs

record a source username and computer, a destination username and computer, and the

3

time when the authentication event was initiated. Additionally, the type of authentica-

tion event is also recorded, such as “Network”, “Kerberos” or “Negotiate”. Authentication

events often exhibit periodic polling, separated by random durations of inactivity. This

can occur when a user initially authenticates their credentials on a computer, and the au-

thentication mechanism then periodically veriﬁes the continued validity of those creden-

tials. Such information cannot be derived from the authentication event types collected

in the data.

The left panel of Figure 1 plots all event times for an example user, U514, authenti-

cating between two particular computers, C528 and C15607, over the 58-day period. It is

apparent that these data comprise several periodic subsequences of evenly-spaced event

times. Each subsequence starts during working hours, and so these initial events are po-

tentially user-driven. Note that within the periodic subsequences there can be duplicate

events or missing data, and so it is important that any proposed model is robust to these

data features. Duplicates can occur when multiple packets are sent, and missing data can

occur when there is packet loss either on the network or on the central authentication

server. A comprehensive explanation of the data is given in [4].

The right panel of Figure 1 shows a circular histogram of the times of day for all 4688

“Log On” events initiated by the same user, U514, connecting between any source and

destination computers. Time-of-day event data are most informatively plotted on a circle

whose circumference represents one day. In this way, event data falling just before and

just after midnight are displayed close together, rather than at opposite ends of a section

of the real line. The limited variation in the number of events within and outside the

working day further implies that there is substantial automated polling behavior.

4

Figure 1: Log on event times over a 58-day period for an example user, U514, from the
LANL computer network. Left: Log on event times between two speciﬁc computers fre-
quented by the user, C528 and C15607. Right: The time of day distribution for all events
generated by the user.

3 Detecting Polling Behavior

A natural approach for detecting polling behavior, described in detail in [3], is to calculate

a discrete Fourier transform [6] of the event times of each point process in the network

in order to uncover any periodicities; a large peak in the resulting periodogram S(f )

indicates polling behavior at frequency f . In particular, a standard signiﬁcance test for a

simple periodicity (see, for example [7]) uses the test statistic

g = max

f

(cid:80)

S(f )

S(f (cid:48))

f (cid:48)

,

(1)

where the sum in the denominator and the maximization are both over the Fourier fre-

quencies. An approximate upper-tail p-value for g can be calculated under the null hy-

pothesis of no polling behavior.

[8] presents a Bayesian model for network authentication behavior which was applied

5

04812162024051015202530354045505560Timeofday(hour)Day01234567891011121314151617181920212223to the data described in Section 2 with some success. As a pre-processing step, any edges

within the network that were identiﬁed as containing signiﬁcant polling behavior ac-

cording to the g-statistic procedure of [3] were removed from the data. This level of

ﬁltering could lead to potentially important user-driven authentication behavior also be-

ing deleted. The proposed methodology seeks to separate the user-driven events from the

automated polling events on a given network edge, rather than completely removing the

edge.

3.1 Detecting Polling Subsequences

This section presents a simulation study to demonstrate the performance of the Fourier

analysis presented in Section 3 for detecting polling behavior contained within peri-

odic subsequences. This study provides justiﬁcation for using a changepoint detection

methodology to detect periodic subsequences. To construct a full generative model for

an ordered sequence of event times with intermittent periodicity, we ﬁrst consider two

sequences

x1, x2, . . . , xS

n1, n2, . . . , nS

i.i.d.
∼
i.i.d.
∼

Exponential(λ),

Geometric(q),

(2)

such that xi speciﬁes the duration of inactivity before the ith polling subsequence com-

mences, ni speciﬁes the number of beaconing periods of length P within that ith subse-

quence and S is the number of polling subsequence within the event sequence.

In each simulation a sequence is sampled from the model (2) for diﬀerent values of

q and S. The constant periodicity is ﬁxed at P = 1 and λ is chosen to be 0.2. The value

for λ generates large durations of inactivity which break the polling cycle. The event

times in the beaconing subsequences are perturbed with U(

0.2, 0.2) errors; more realistic

−

6

representations of this error are provided in Section 4.

The case where q = 1 corresponds to no periodic behavior, and the approximate p-

values from the upper tail of the test statistic (1) will be approximately uniformly dis-

tributed on [0, 1]. As q decreases, the proportion of periodic data increases and the test

should yield statistically smaller p-values. For q < 1, increasing the total number of sub-

sequences S increases the overall sample size, and should also yield statistically smaller

p-values.

Ten thousand Monte Carlo simulations were performed for diﬀerent combinations of

q

∈ {

1, 0.5, 0.25, 0.1

, S
}

. Figures 2 and 3 show the empirical cumulative distribu-
20, 40
}

∈ {

tion function of the resulting p-values for all combinations of q and S.

Figure 2: Distribution of p-values from g-test of simple periodicity for 20 polling subse-
quences generated from (2) with parameters λ = 0.2 and q
. It is clear
}
that a decrease in q yields statistically smaller p-values for periodicity in the event se-
quence.

1, 0.5, 0.25, 0.1

∈ {

7

00.10.20.30.40.50.60.70.80.9100.20.40.60.81p-valueCDFS=20,q=1S=20,q=0.5S=20,q=0.25S=20,q=0.1Figure 3: Distribution of p-values from g-test of simple periodicity for 40 polling subse-
quences generated from (2) with parameters λ = 0.2 and q
. By compar-
}
ing the results with Figure 2 it is clear that increasing the number of polling subsequences
yields statistically smaller p-values for q

1, 0.5, 0.25, 0.1

∈ {

.
0.5, 0.25, 0.1
}

∈ {

When q = 1, the p-values are approximately uniformly distributed. Even when q = 0.5,

which in expectation provides the shortest meaningful subsequence length for exhibiting

a common periodicity, the distribution of p-values is already quite diﬀerent. For a mod-

erate expected subsequence length of 10, q = 0.1, the p-values from observing 20 such

subsequences are concentrated strongly at zero. These simulations imply that the ran-

dom lengths of inactivity in-between periodic subsequences do not signiﬁcantly reduce

the signal of the Fourier transform-based g-test. Polling behavior is still detectable even

in the most extreme cases. By comparing Figures 2 and 3, it is clear that increasing the

number of polling subsequences causes a further decrease in the p-values.

8

00.10.20.30.40.50.60.70.80.9100.20.40.60.81p-valueCDFS=40,q=1S=40,q=0.5S=40,q=0.25S=40,q=0.1This section uses a crude uniform estimate to model the random error of each event in

a periodic subsequence. Section 4 introduces directional statistics and explains how they

can be used to provide a smoother more accurate estimate of this error.

4 Directional Statistics

For modeling data with an underlying periodicity, it is intuitively most simple to consider

noise in the data as angular displacements from the underlying periodic sequence. For

a given period P , event times from a point process can be transformed to directions in

two-dimensional space, represented by points on a unit circle. For an event time y, let

φ(y) =

2πy
P

(mod 2π),

denote the angular position of the corresponding point on the unit circle. Under this

transformation, any variability in the periodic event times corresponds to small angular

displacements from an overall angular mean. This transformation is depicted in Figure

4.

The mean direction and circular variance provide respective measures of the location

and spread of directional data: For a given sample φ = (φ1, . . . , φn), let xi = (xi,1, xi,2)

where xi,1 = cos φi and xi,2 = sin φi, such that xi is the location of a unit vector with angle

φi in two-dimensional space. Then let ¯x = ( ¯x1, ¯x2) denote the mean resultant vector of

the sample, where ¯x1 =
length of ¯x. The mean direction ¯φ is deﬁned to be

i=1 xi,1/n and ¯x2 =

(cid:80)n

(cid:80)n

i=1 xi,2/n, and let ¯R =

1 + ¯x2
¯x2

2 denote the

(cid:113)

¯φ = arctan( ¯x2/ ¯x1)

(mod 2π),

and the circular variance is deﬁned as V = 1

¯R. A comprehensive overview of these and

−

9

Figure 4: Cartoon depiction of the transformation y
to angular positions with respect to a unit periodicity.

(cid:55)→

φ(y) reducing event times on R+

other directional data summaries is provided in [9].

4.1 The von Mises Distribution

A commonly used distribution for directional data is the von Mises distribution [10]. A

random variable θ is said to follow the von Mises distribution with location parameter

[0, 2π) and precision parameter κ > 0, written M(ν, κ), if it has density

ν

∈

fM(θ

|

ν, κ) =

exp(κ cos(θ
−
2πI0(κ)

ν))

,

[0, 2π),

θ

∈

where I(cid:96)(

·

) is the modiﬁed Bessel function of order (cid:96). In Section 5 the von Mises distribu-

tion will be used to construct a model for periodic event subsequences, and so it is useful

to review frequentist and Bayesian parameter estimation for this distribution.

10

0123456Time0π/2π3π/24.1.1 Maximum Likelihood Estimation

Let θ1, . . . , θn be a sequence of realizations drawn from M(ν, κ). The log-likelihood func-

tion for this sample simpliﬁes to

l(ν, κ

log 2π + κ ¯R cos( ¯θ
θ1, . . . , θn) = n
{

|

ν)

log I0(κ)
,
}

−

−

(3)

[9]. Maximizing with respect to the location parameter ν yields the maximum likelihood

estimate (MLE)

ˆν = ¯θ,

(4)

where ¯θ is the mean direction of the sample, deﬁned above. Substituting ¯θ into (3) and

diﬀerentiating with respect to κ yields the equation

ˆκ = A−

1( ¯R)

(5)

for the MLE for κ, where

A(κ) =

I1(κ)
I0(κ)

.

There is no analytic solution for (5), but numerical estimates can be obtained [11, 9].

4.1.2 Bayesian Inference

For relatively straightforward Bayesian inference for the von Mises distribution, [12] and

[13] use the conjugate prior

g(ν, κ)

I0(κ)
−
}

∝ {

c exp (κR0 cos(ν

ν0)) .

−

(6)

This speciﬁcation is analogous to having observed c notional prior directional samples

with a mean direction ν0 and resultant length R0.

11

As in the previous section, let θ1, . . . , θn be samples drawn from M(ν, κ). Then the

posterior distribution is given by

g(ν, κ

|

θ1, . . . , θn)

I0(κ)
−
}

∝ {

(c+n) exp (κRn cos(ν

νn)) ,

−

(7)

where νn is the mean direction of the resultant of the sum of a vector with direction ν0

and length R0 together with unit vectors in each of the directions of the samples θ1, . . . , θn,

and Rn is the magnitude of that resultant vector. The Metropolis Hastings algorithm can

be used to obtain a posterior estimate for the precision parameter κ.

5 A Model for Periodic Subsequences

To construct a full generative model for an ordered sequence of event times with inter-

mittent periodicity, we ﬁrst consider the two sequences deﬁned in (2) on page 6, where xi

speciﬁes the duration of inactivity before the ith polling subsequence commences and ni

speciﬁes the number of beaconing periods of length P within that ith subsequence.

Within a polling subsequence, 0 events (in the case of missing data), 1 event, or mul-

tiple events (in the case of duplication) may be observed during each period. Within the

ith polling subsequence, for j = 1, . . . , ni let mi,j be the number of events observed in the

jth period. The values of each event count mi,j is assumed to be hurdle geometric: Deﬁning

δi,j = 1(mi,j > 0)

we assume δi,j ∼

Bernoulli(1

−

p); if δi,j = 0 then clearly mi,j = 0, and otherwise if δi,j = 1

12

then (mi,j −

1)

∼

Geometric(r) for parameters 0 < p, r < 1, implying

P(mi,j = m) =






p,

(1

m = 0,

p)(1

−

−

r)rm

1, m
−

1.

≥

5.1 Fixed Phase Polling

Figure 5 shows an example of a possible subsequence of event data exhibiting ﬁxed phase

polling, where an error in one event does not propagate into future events. A cross indi-

cates an observed event whilst a square indicates a period with missing data.

Figure 5: Example of a subsequence of periodic event times exhibiting ﬁxed phase polling
with period P .

To construct a subsequence exhibiting ﬁxed phase polling. For the ith polling subse-

quence and the jth period of the ith subsequence, i = 1, 2, . . . and j = 1, . . . , ni, let θi,j,1 <

. . . < θi,j,mi,j be the order statistics from mi,j independent draws from the von Mises distri-

bution M(π, κ). Then for k = 1 . . . , mi,j we deﬁne the ordered event times for that period

to be

y(cid:48)i,j,k =

1(cid:88)
i
−

i(cid:48)=1

(cid:40)

(xi(cid:48)

+ ni(cid:48) P ) + xi + P

1) +

(j

−

(cid:41)

.

θi,j,k
2π

Considering these event times transformed to the unit circle, let

φi,j,k =

2π

y(cid:48)i,j,k
·
P

(mod 2π),

(8)

13

PPPPPy1y2y3y4y7...y01,1,1y01,1,2y01,2,1y01,3,1y01,5,1...be the corresponding angular representation. Since θi,j,k has expected value π, it can

easily be seen that the expected angular position of each event time in the ith periodic

subsequence is given by

νi = E(φi,j,k) =

2π





(cid:80)i

i(cid:48)=1 xi(cid:48)
P





+ π

(mod 2π).

(9)

Therefore the angular displacement error associated with each event time is described by

the M(0, κ) distributed variables

zi,j,k = (φi,j,k −

νi)

(mod 2π)

= (θi,j,k + π)

(mod 2π).

Finally, to complete the speciﬁcation for a point process of event times with periodic

subsequences, let y1 < y2 < . . . be the sequence of observable event times deﬁned by

yσ (i,j,k) = y(cid:48)i,j,k,

σ (i, j, k) =

1(cid:88)
i
−

ni(cid:48)(cid:88)

i(cid:48)=1

j(cid:48)=1

mi(cid:48),j(cid:48)

+

1(cid:88)
j
−

j(cid:48)=1

mi,j(cid:48)

+ k.

(10)

An illustration of this indexing format is provided in Figure 5.

5.2 Fixed Duration Polling

An example of a possible subsequence exhibiting ﬁxed duration polling is shown in Fig-

ure 6. It is most intuitive to deﬁne the event times recursively, since the event times in one

period aﬀect the mean of the distribution of event times for subsequent periods. To con-

struct a subsequence of event times exhibiting ﬁxed duration polling, let z(cid:48)i,j,k ∈

(

π, π] be

−

14

Figure 6: Example of a subsequence of periodic event times exhibiting ﬁxed duration
polling with period P .

the angular displacement error associated with each event time, drawn from M(0, κ). Let






x1

mi,j = 0, i = 1, j = 1,

¯yi

1 + xi

1,ni

−

−

mi,j = 0, i > 1, j = 1,

¯yi,j =

mi,j = 0, j > 1,

1 + P

¯yi,ni
−
(cid:80)mi,j

k=1 y(cid:48)i,j,k/mi,j mi,j > 0,

such that for each non-empty period in a beaconing subsequence ¯yi,j is the arithmetic

mean of all event times in that period. Then we deﬁne the ordered event times for each

period to be

i = 1, j = 1,


x1 + z(cid:48)1,1,k




y(cid:48)i,j,k =

¯yi

1 + xi + z(cid:48)i,1,k

1,ni

−

−

i > 1, j = 1,

¯yi,j

−

1 + P + z(cid:48)i,j,k

j > 1.

The sequence of observable event times is again described by (10).

6 Changepoint Detection

Changepoint detection techniques are widely used in data analysis across a range of scien-

tiﬁc ﬁelds. These methods partition a sequence of data into a possibly unknown number

15

PPPPPy1y2y3y4y7...y1,1,1y1,1,2y1,2,1y1,3,1y1,5,1...of smaller segments, such that the data within each segment are assumed to arise from a

single generative model. Here, discrete changepoint analysis are used to separate a point

process of event times on a computer network edge into periodic subsequences, using one

of the proposed models from Section 5.

Let y1 < . . . < yn be a sequence of event times from a point process. Suppose the se-

quence is partitioned into m+1 segments by m integer-valued changepoints ¯τ = (τ1, . . . , τm),

ordered such that 0

≡
of data is the subsequence of event times yτi

τ0 < τ1 < . . . < τm < τm+1 ≡

1+1:τi = (yτi

−

−

1+1, . . . , yτi ).

n. For each i = 1, . . . , m+1, the ith segment

A common aim of discrete changepoint detection algorithms is to ﬁnd changepoints

that minimize an overall cost function

m+1(cid:88)

i=1

[C(yτi

−

1+1:τi )] + βn,

(11)

where C is a segment-based cost function relating to the ﬁtted likelihood of the data in a

segment and βn ∈

R is a penalty term to discourage over ﬁtting.

There are many changepoint detection algorithms, but here we consider binary seg-

mentation (BS), optimal partitioning (OP) and the pruned exact linear time (PELT) algo-

rithm [14]. [15] introduces the BS method for changepoint detection. This method has

the advantage of being computationally eﬃcient,

(n log n), but it is not guaranteed to

O

ﬁnd the global minimum of (11). [16] introduces the OP method which is guaranteed

to minimize (11). The OP method works by iterating sequentially through each event

time and minimizing (11) conditional on all previous combinations of changepoints. The

disadvantage to this method is that it has computational cost which is quadratic in n.

[14] introduces the PELT method which uses pruning to improve the computational

eﬃciency of the OP method whilst still ensuring that the search algorithm ﬁnds a global

minimum to (11). Under the assumption that the number of changepoints m increases

16

linearly with the size of the data n, PELT has a linear computational cost. Pseudo code

for both the PELT and the OP methods can be found in [14].

Following the changepoint literature [17], C is chosen to be twice the negative log-

likelihood function for a periodic subsequence of data according to a model from Section

5. Furthermore, in accordance with the Bayesian information criterion (BIC) [18], the

penalty is chosen to be of the form

βn = α log n,

(12)

where α notionally represents the number of additional free parameters introduced to

the model by adding a changepoint. Here the natural choice is α = 2, since the only pa-

rameters introduced by adding a changepoint are the position of the changepoint within

the data sequence and the location parameter (9) of the new periodic subsequence.

Using the various deﬁnitions from Section 5, the likelihood of a proposed subsequence

is given by

λe−

λxi (1

q)ni −

1q

−

ni(cid:89)

j=1





(1

δi,j)p + δi,j(1

−

p)(1

−

−

1
r)rmi,j −

κ cos(φi,j,k −
exp
{
2πI0(κ)

ˆνi,j)





,

}

mi,j(cid:89)

k=1

where in the case of ﬁxed phase polling ˆνi,j = ˆνi is the MLE (4) for the location parameter

of the von Mises distribution using the angular representation (8) of all event times from

the proposed subsequence. In the case of ﬁxed duration polling ˆνi,j is the MLE (4) for the

location parameter of the von Mises distribution using the angular representation (8) of

all event times from the previous non-empty period.

When the parameters (p, q, r, λ, κ) are considered unknown, independent conjugate

priors can be deployed such that p, q and r have beta distributions with respective pa-

rameters (αp, βp), (αq, βq), and (αr, βr), whilst λ

gamma(αλ, βλ). The prior distribution

∼

17

for κ is given by (6). A simple Metropolis Hastings algorithm with a uniform proposal

density centered at the current parameter value can be used to obtain a posterior estimate

of κ, (7) using the estimated angular displacements of the event times,

ˆzi,j,k = (φi,j,k −

ˆνi,j)

(mod 2π),

where it is assumed that ˆzi,j,k ∼

M(0, κ).

The proposed procedure is to iterate between three inferential steps:

1. Changepoint analysis for identifying periodic subsequence using PELT

2. Bayesian estimation of the nuisance parameters (p, q, r, λ, κ)

3. Updating the estimated periodicity P

The algorithm simply loops through steps 1-3 repeatedly until convergence is reached:

Convergence is determined to have occurred when identical changepoints are found by

step 1 in two successive iterations of the algorithm. After each iteration of the change-

point algorithm in step 1, the nuisance parameters are re-estimated using their revised

posterior means, conditional on the updated set of changepoints, in step 2. The poste-

rior means of the parameters p, q, r, λ all have closed form under the conjugate priors,

and the posterior mean of κ is estimated by Metropolis Hastings sampling as described

above. Finally, the estimated periodicity P is also updated in step 3 as follows: For each

non-empty period in a beaconing subsequence, let ¯yi,j be the arithmetic mean of all event
¯yi,j be the diﬀerence between
times in that period; then for j = 1, . . . , ni −
the mean event times from two successive periods of events. To reduce the inﬂuence of

1 let wi,j = ¯yi,j+1 −

missing event data, P is estimated to be the median value of

wi,j}
{

over all subsequences i

deﬁned by the current set of changepoints.

Since computational scalability is paramount, changepoints are detected using PELT,

18

which has a computational cost which is linear in the number of data points. For updating

model parameters between successive iterations of the PELT algorithm, maximum like-

lihood estimation can potentially lead to degenerate solutions and therefore a Bayesian

estimation procedure is adopted.

7 Examples

7.1 Simulated Data Example

To gain an understanding of the accuracy and the eﬃciency of two of the changepoint de-

tection algorithms, both the BS and PELT methods described in Section 6 are applied to

sequences of events times sampled from the full generative model for ﬁxed phase polling

from Section 5. The aim is to partition the event times so that each changepoint is posi-

tioned at the start of a new periodic subsequence, therefore changepoints can only occur

at the discrete number of event times within the data.

Three diﬀerent combinations of the model parameters p, q, r, λ and κ are used to gen-

erate diﬀerent types of periodic subsequences which could arise in real world computer

network data. For example, larger values of κ induce smaller error terms in the angular

displacements of the beaconing subsequences, whilst increasing λ leads to longer lengths

of inactivity between the subsequences. Both of these changes should make separate peri-

odic subsequences easier to identify. Without loss of generality, the periodicity is set to 1.

The three sets of parameter choices are presented in Table 1. For each set of parameters,

100 sequences of 10 beaconing subsequences were generated.

Both the BS and the PELT algorithms identify changepoints by minimizing (11). In

this example, the proportion of true positive(TP) changepoints corresponds to the num-

ber of true changepoints correctly identiﬁed divided by the total number of true change-

points, whilst the proportion of false positive(FP) changepoints corresponds to the num-

19

Parameter settings κ

1
2
3

r

q

p

λ
9 10 0.05 0.5 0.1
0.5 0.1
0.1
8 10
0.5 0.1
0.2
7 10

Table 1: Parameter settings for generating periodic subsequences of event times from the
generative model for ﬁxed phase polling in Section 5.

ber of events incorrectly identiﬁed as changepoints, divided by the true number of events

which do not correspond to a changepoint.

Figure 7 plots an example of one sequence of simulated event times comprised of

ten beaconing subsequences with periodicity 1, generated with parameter setting 2 from

Table 1. Changepoints were detected using PELT with the commonly used BIC penalty

βn = 2 log(n) (12). For each event time yσ (i,j,k) from (10), the angular position φi,j,k from

(8), determined by the ﬁtted changepoints, is plotted. The vertical lines indicate the loca-

tions of the changepoints, which correctly partition the event times into the ten separate

subsequences.

To obtain a thorough comparison of the two methods, the performance of both meth-

ods was tested over a range of settings for the penalty βn from (12) by repeating the anal-

ysis for α

3,

. Increasing α corresponds to a higher penalty βn for
1.5, 0, 2, 5, 10, 20, 40
}

−

∈ {−

adding a changepoint, therefore we would expect to detect fewer TP and FP changepoints

as α increases.

Note that for completeness even negative penalties are considered, in order to reach

the extreme case where every event time is selected to be a changepoint. This enables

a receiver operating characteristic (ROC) curve to be plotted in Figure 8, showing how

the true and false positive changepoint rates increase as the penalty term is reduced. If

α was increased further, we would eventually reach the other extreme where no event

times are selected as changepoints. Since PELT only has linear computational cost when

20

Figure 7: A simulated point process representing periodic subsequences, partitioned by
changepoints found using PELT.

the number of changepoints increases linearly with the size of the data, [14] reducing the

number of changepoints towards zero is computationally prohibitive and is therefore not

included.

The proportions of true and false positive changepoints found using PELT closely

resemble those found using the BS method. Table 2 presents the proportion of TP and FP

changepoints found for the commonly used BIC penalty, βn = 2 log(n). In this case PELT

identiﬁes at least as high a proportion of TP changepoints as the BS method, and at least

as small a proportion of FP changepoints for all three parameter settings.

Parameter settings

1
2
3

BS

PELT

TP

FP

TP

FP

0.9587 0.0002 0.9587 0.0002
0.8784 0.0007 0.8845 0.0006
0.6340 0.0012 0.6639 0.0010

Table 2: Proportion of true positive (TP) and false positive (FP) changepoints identiﬁed
under the BIC penalty.

21

0204060801001201401601802000π/2π3π/22πyσ(i,j,k)φi,j,kFigure 8: ROC curves comparing the changepoints detected using PELT and BS for data
generated using the three parameter settings in Table 1.

To further investigate how the two methods diﬀer, the run time of the two algorithms

is measured against the number of changepoints for the commonly used BIC penalty.

For each set of parameters from Table 1, ten sequences formed of diﬀerent numbers of

beaconing subsequences (equivalently, changepoints) were generated. The average run

time in seconds on a computer with an Intel Core i7 processor, clocked at 2.2 GHz, are

presented in Table 3. Both algorithms use the same underlying code for calculating the

cost of a proposed changepoint conﬁguration. In almost all situations, the PELT method

was quicker than the BS method, especially when the number of changepoints in the

model increased.

Changepoint algorithm
Parameter setting

Number of changepoints

BS
3
2
8.2
8.7
36.4
29.0
219.4 171.3

1
14.1
46.8
293.0

3
9.3
10
20.4
20
50
63.4
100 1110.1 995.9 824.7 102.9 99.7 200.4

1
12.1
28.3
57.7

PELT
2
6.2
19.9
45.0

Table 3: Average run times (in seconds) using the two changepoint detection algorithms
for diﬀerent numbers of changepoints and parameter settings from Table 1.

22

10−410−310−210−110000.20.40.60.81FalsepositiverateTruepositiverate10−410−310−210−1100Falsepositiverate10−410−310−210−1100Falsepositiverate(a)Parameterset1(b)Parameterset2(c)Parameterset3When monitoring real computer networks, traﬃc is often observed for several days to

allow construction of an accurate model of normal behavior. It is therefore possible that a

large number of beaconing periodic subsequences could be observed; in such cases, where

there is an unknown but potentially large number of changepoints, the PELT method is

preferable since it has a linear computational cost.

7.2 Real Data Example

The PELT changepoint detection algorithm for detecting periodic subsequences, pre-

sented in Section 6, is applied to the authentication data from the Los Alamos National

Laboratory (LANL) computer network described in Section 2. The analysis in this section

focuses on the “Log On” events for user U514 depicted in Figure 1. The event times for

each source-destination pair of computers are modeled as separate point processes. The

time of day distribution of all Log On events from user U514 are shown in Figure 1, where

the lack of variation in the number of events within and outside the working day indi-

cated the presence of substantial polling behavior associated with this username. The

periodicity detection method was applied separately to each computer-computer point

process, identifying the ﬁrst event after each changepoint as a user-driven Log On event.

Unlike the previous example these data exhibit ﬁxed duration polling, where any error

in the beaconing subsequence propagates into future event times (see Section 5).

To initialize the algorithm, the model parameters (p, q, r, λ, κ) are initially estimated

using the means of the prior distributions given in Section 6. The hyper-parameters of

the prior distributions are estimated empirically from a small segment of a beaconing

subsequence, in one point process in the network. These hyper-parameters are given in

Table 4.

As in Figure 1, the left panel of Figure 9 plots all event times over the entire 58-day

period, where user U514 logs onto computer C528 from computer C15607. The circles

23

Parameter settings R c

αp βp αr
10
1

βr αq βq αλ βλ
1
1
5

10

20

9 10 10

1

Table 4: Parameter settings for generating periodic subsequences of event times from the
generative model in Section 5.

in the diagram now indicate the inferred user-driven events that initiate the start of an

automated polling subsequence.

It is clear that meaningful subsequences of periodic

event times are identiﬁed, and the methodology is robust to duplicate event data, as seen

between days 5 and 10, and missing event data, as seen between days 35 and 40.

The right panel of Figure 9 plots the distribution of the 169 human Log On events

found by applying the PELT changepoint detection algorithm to all pairs of computers

used by user U514 over the entire 58-day period. The distribution of these events is

much more consistent with human behavior than Figure 1, with the majority of events

occurring within the hours of an extended working day (9am-8pm) and a large spike of

Log On events at the start of the working day (9am-10am).

For user U514, automated polling behavior accounts for over 97% of all Log On data.

As a data reduction tool, this represents a signiﬁcant thinning of the bulk of authentica-

tion data. Further analytics operating on only user-driven behavior would become more

manageable and allow for more robust modeling, potentially strengthening anomaly de-

tection capabilities.

7.2.1 Robustness

The proposed procedure of iterating between the changepoint analysis and Bayesian es-

timation of the nuisance parameters introduces random variation to the algorithm due to

the stochastic nature of the Metropolis-Hastings (MH) algorithm. Variation can also be

introduced by varying the speciﬁcation of the prior hyper-parameters displayed in Table

24

Figure 9: Log on event times for U514 from the LANL computer network. Left: Log on
event times between the two speciﬁc computers C528 and C15607, where events have
been attributed as human or automated, periodic events. Right: The time of day distri-
bution for all human-generated events attributed to the user.

4. We examine the robustness of the model by performing 10 repetitions of the algorithm

on the same data set, for each of three diﬀerent sets of prior hyper-parameters. These

hyper-parameters are presented in Table 5.

Parameter settings R c

1
2
3

αp βp αr
10
2
10
1
10
3

8 10 10
9 10 10
7 10 10

βr αq βq αλ βλ
1
1
5
1
1
5
1
1
5

10
10
10

10
20
5

Table 5: Parameter settings for generating periodic subsequences of event times from the
generative model in Section 5.

To measure the eﬀect of the random variation introduced by the MH algorithm for ap-

proximating Bayesian estimation of the posterior parameters, let e1, . . . , eM be the ordered

list of all events in the data sequence. Then let bi,l,1, . . . , bi,l,M be a binary representation

of the changepoint events found by the ith repetition of the algorithm, with prior hyper-

25

048121620240102030405060Timeofday(hour)Day01234567891011121314151617181920212223parameters l

. When the algorithm identiﬁes ek to be a changepoint (user driven
1, 2, 3
}

∈ {

event), bi,l,k = 1. Otherwise ek is assumed to be automated and bi,l,k = 0. For prior hyper-

parameter settings l

1, 2, 3

}

∈ {

i (cid:44) j, let

and each pair of repetitions of the algorithm i, j

1 . . . 10
,
}

∈ {

(cid:80)M

k=1 |

ci,j,l =

bi,l,k −
M

bj,l,k |

be the proportion of events which are assigned diﬀerently. ci,j,l is calculated for all pairs

of repetitions of the algorithm under each choice of hyper-parameters. Finally let cl be

the mean of ci,j,l over all pairs of repetitions, i, j

1 . . . 10, i (cid:44) j.

∈

For the ﬁrst set of hyper-parameters, we ﬁnd that c1 = 0.000103. This value im-

plies that any two repetitions of the algorithm make identical inference except for ap-

proximately 1 in every 1000 events diﬀerently. We also found that c2 = 0.000177 and

c3 = 0.000103.

We are also interested in ﬁnding the eﬀects of changing the prior hyper-parameterisation

of the model. For each prior hyper-parameterisation displayed in Table 5 and event ek, let

¯bl,k =

(cid:80)10

i=1 bi,l,k
10

be the proportion of repetitions of the algorithm which identify the kth event to be user-

driven. Then, for l1, l2 ∈ {

1, 2, 3

, let
}

dl1,l2 =

(cid:80)M

k=1 |

¯bl1,k −

M

¯bl2,k |

be the average proportion of events which are diﬀerently categorized for prior hyper-

parameterisations l1 and l2.

26

For the 2 alternative sets of hyper-parameters proposed in Table 4 we ﬁnd that

d1,2 = 0.000332,

d1,3 = 0.000442.

Compared to the results found for the original parameter settings, approximately three

in every 1000 events are assigned diﬀerently when using prior hyper-parameter settings

2, and approximately four in every 1000 events are assigned diﬀerently when using prior

hyper-parameter settings 3.

The example presented in the left panel of Figure 9 identiﬁed the inferred user-driven

Log-On events when U514 logs onto computer C528 from computer C15607. In this

example, the algorithm ﬁnds the same inferred user-driven Log-On events for all repe-

titions of the algorithm, for all prior hyper-parameterisations. The right panel of Figure

9 plots the distribution of the 169 human Log On events found by applying the algo-

rithm to all pairs of computers used by user U514 over the entire 58-day period. This

plot is visually indistinguishable for all repetitions of the algorithm, for all prior hyper-

parameterisations.

The results in this section show that any variability in the algorithm, due to the

stochastic variability of the MH algorithm or from altering the speciﬁcation of the prior

hyper-parameters, has a very small eﬀect on the resulting inference.

8 Conclusion

In this article we ﬁrst demonstrated that intermittent polling behavior in computer net-

work data can typically be detected using standard Fourier analysis methods, such as

[3]. Secondly, we proposed a methodology for identifying the separate beaconing sub-

sequences within intermittent polling data. Conditional on the presence of intermittent

27

polling behavior, with a constant periodicity estimated by [3], we introduced a change-

point detection methodology to identify the separate polling subsequences within the

overall event sequence. We proposed iterating between the changepoint analysis and es-

timation of nuisance parameters, to reﬂect the dependency between the these quantities.

The proposed method is robust to complications typically encountered in computer event

data collection, such as duplicated and missing data.

The purpose of partitioning event data into periodic subsequences is to identify po-

tentially user-driven actions in computer network event data, with the future intention

of modeling user-driven and automated behavior separately for anomaly detection pur-

poses. User-driven actions are identiﬁed as the ﬁrst events of each beaconing subse-

quence, which are followed by automated periodic updates.

Treating automated and user-driven data separately should provide a more robust

framework for modeling computer network data, whereby bespoke models can be speci-

ﬁed for each type of behavior (see for example [2]). Alternatively, as a data reduction tool,

identifying only user-driven events represents a signiﬁcant thinning of the bulk of com-

puter network data, potentially improving anomaly detection capability and eﬃciency.

In this article the changepoint detection methodology was applied separately to each

edge in a computer network, with the aim of classifying human user activity against au-

tomated events. If the events from an edge in the network consist of a single beaconing

sequence with no phase shifts, this suggests no human activity and the event data will be

best described using the simpler method of [3]. However, if the events consist of multiple,

intermittent periodic subsequences sharing a constant periodicity, the methodology pro-

posed in this article can be used to identify the user-driven events initiating each period

subsequence. If the events exhibit no periodic patterns, then we might conclude that the

events from that edge are potentially all user-driven.

The algorithm was applied to authentication data from the Los Alamos National Lab-

28

oratory (LANL) enterprise computer network. The algorithm identiﬁed meaningful sub-

sequences of periodic event times and was robust to duplicate and missing event data.

In the absence of true classiﬁcation labels for the data, we investigated the time of day

distributions of the inferred user-driven events and compared this with the distribution

for all of the authentication events from one user. The distribution of the inferred user-

driven events was much more consistent with human behavior, displaying a more clear

diurnal pattern.

Further extensions of the model could be considered. For example, within the ith

subsequence, θijk are assumed to be the order statistics of independent identically dis-

tributed draws from a M(π, κ) distribution. However, in reality there is often a correla-

tion exhibited between these angular displacements within a beaconing period, as events

can arrive in bursts. To incorporate this correlation into the model, we could postulate

a hierarchical model for beaconing subsequences of event times, where clusters of event

time variables θijk are considered to be only conditionally independent given some un-

observed location value.

References

[1] Lazarevic A, Ert¨oz L, Kumar V, Ozgur A, Srivastava J. A Comparative Study of

Anomaly Detection Schemes in Network Intrusion Detection. In: SDM. SIAM; 2003.

p. 25–36.

[2] Neil J, Hash C, Brugh A, Fisk M, Storlie CB. Scan statistics for the online detection

of locally anomalous subgraphs. Technometrics. 2013;55(4):403–414.

[3] Heard N, Rubin-Delanchy P, Lawson D. Filtering Automated Polling Traﬃc in Com-

puter Network Flow Data.

In: Intelligence and Security Informatics Conference

29

(JISIC), 2014 IEEE Joint. IEEE; 2014. p. 268–271.

[4] Kent A. Cybersecurity Data Sources for Dynamic Network Research. In: Dynamic

Networks in Cybersecurity. Imperial College Press; 2015. p. 37–65.

[5] Kent A. Comprehensive, Multi-Source Cyber-Security Events; 2015. Los Alamos

National Laboratory.

[6] Halliday DM, Rosenberg JR. Time and frequency domain analysis of spike train and

time series data. In: Modern techniques in neuroscience research. Springer; 1999. p.

503–543.

[7] Jenkins GM, Priestley MB. The spectral analysis of time-series. Journal of the Royal

Statistical Society Series B (Methodological). 1957;p. 1–12.

[8] Turcotte MJM, Heard NA, Kent AD. Modelling user behaviour in a network us-

ing computer event logs. In: Dynamic Networks in Cybersecurity. Imperial College

Press; 2016. p. 67–87.

[9] Mardia KV, Jupp PE. Directional statistics. vol. 494. John Wiley & Sons; 2009.

[10] von Mises R.

¨Uber die Ganzzahligkeit der Atomgewichte und verwandte Fragen.

Phys z. 1918;19:490–500.

[11] Banerjee A, Dhillon IS, Ghosh J, Sra S. Clustering on the unit hypersphere using

von Mises-Fisher distributions. In: Journal of Machine Learning Research; 2005. p.

1345–1382.

[12] Guttorp P, Lockhart RA. Finding the location of a signal: A Bayesian analysis. Jour-

nal of the American Statistical Association. 1988;83(402):322–330.

30

[13] Damien P, Walker S. A full Bayesian analysis of circular data using the von Mises

distribution. Canadian Journal of Statistics. 1999;27(2):291–298.

[14] Killick R, Fearnhead P, Eckley I.

Optimal detection of changepoints with

a linear computational cost.

Journal of the American Statistical Association.

2012;107(500):1590–1598.

[15] Scott AJ, Knott M. A cluster analysis method for grouping means in the analysis of

variance. Biometrics. 1974;p. 507–512.

[16] Jackson B, Scargle JD, Barnes D, Arabhi S, Alt A, Gioumousis P, et al. An algorithm

for optimal partitioning of data on an interval. Signal Processing Letters, IEEE.

2005;12(2):105–108.

[17] Chen J, Gupta AK. Parametric statistical change point analysis: with applications to

genetics, medicine, and ﬁnance. Springer Science & Business Media; 2011.

[18] Schwarz G, et al. Estimating the dimension of a model. The annals of statistics.

1978;6(2):461–464.

31

