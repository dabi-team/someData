Online Dictionary Learning Based Fault and
Cyber Attack Detection for Power Systems

Gabriel Intriago and Yu Zhang
Department of Electrical and Computer Engineering
University of California, Santa Cruz
Emails: {gintriag, zhangy}@ucsc.edu

1
2
0
2

g
u
A
4
2

]

R
C
.
s
c
[

1
v
0
9
9
0
1
.
8
0
1
2
:
v
i
X
r
a

Abstract—The

emerging wide area monitoring systems
(WAMS) have brought signiﬁcant improvements in electric grids’
situational awareness. However, the newly introduced system
can potentially increase the risk of cyber-attacks, which may
be disguised as normal physical disturbances. This paper deals
with the event and intrusion detection problem by leveraging
a stream data mining classiﬁer (Hoeffding adaptive tree) with
semi-supervised learning techniques to distinguish cyber-attacks
from regular system perturbations accurately. First, our proposed
approach builds a dictionary by learning higher-level features
from unlabeled data. Then, the labeled data are represented
as sparse linear combinations of learned dictionary atoms. We
capitalize on those sparse codes to train the online classiﬁer
along with efﬁcient change detectors. We conduct numerical ex-
periments with industrial control systems cyber-attack datasets.
We consider ﬁve different scenarios: short-circuit faults,
line
maintenance, remote tripping command injection, relay setting
change, as well as false data injection. The data are generated
based on a modiﬁed IEEE 9-bus system. Simulation results show
that our proposed approach outperforms the state-of-the-art
method.

I. INTRODUCTION

The ongoing improvements in wide-area monitoring sys-
tems have brought better visibility of the power system and
have exposed the system to malicious cyber-attacks [1], [2].
In this context, event and intrusion detection systems (EIDS)
are indispensable to classify the nature of a power system
disturbance: is it a regular operation, fault condition, or a
cyber-attack? The main challenge of this classiﬁcation task
is to extract relevant information from system measurements.
Over the past decade, various data-driven techniques have been
explored to tackle this problem.

A geometrical analysis of unsynchronized and synchronized
attacks is introduced to detect the presence of attacks and
identify compromised micro-PMUs [3]. Based on text-mining
techniques, a data-driven approach was developed for false
data attacks classiﬁcation [4]. In recent years, classical ma-
chine learning algorithms, such as naive Bayes, support vector
machines (SVM), and random forests (RF), have been applied
to detect cyber-attacks and disturbances in power systems [5],
[6], [7], [8]. It is also possible to build common paths of
critical states by exploiting the relationships among voltage,

This work was supported in part by a Seed Fund Award from CITRIS
and the Banatao Institute at the University of California, and the Hellman
Fellowship.

current, and impedance to discover relevant patterns [9], [10].
Those classical methods, which often have difﬁculties dealing
with large-scale and time-varying data, are unsuitable for
real-time changing environments. Hence, stream data mining
algorithms have recently drawn much attention. These include
nonnested generalized exemplars [11], Hoeffding adaptive tree
(HAT) [12], and HAT with change detectors [13]. Leverag-
ing phasor measurement units (PMUs), those algorithms are
proven to outperform classical methods in real systems. In
[14], the authors proposed a transfer learning HAT model with
one change detector, the adaptive sliding window (ADWIN).
Their approach transferred knowledge from four datasets,
where each dataset corresponds to a speciﬁc frequency os-
cillation.
It

is challenging and costly to label a massive amount
of PMU data on the ﬂy in practice. Compared with data
collection that depends only on data storage capacity, data
labeling often requires rich domain knowledge of experts who
can actively identify instances’ labels. Therefore, we have
abundant unlabeled data and scarce labeled data that share the
same generative distribution. Due to this fact, semi-supervised
learning (SSL) is an appropriate tool that combines a small
amount of labeled data with a large amount of unlabeled data
during training [15].

This paper proposes a novel approach for power system
EIDS to improve the classiﬁcation performance by transform-
ing the data through higher-level representations extracted
from an unlabeled dataset. In addition, we provide perfor-
mance analysis for different sizes of the labeled dataset. To
the best of our knowledge, this is the ﬁrst effort to incorporate
SSL with a stream data mining classiﬁer for the EIDS. The
rest of the paper is organized as follows. Section II presents
the details of the proposed approach. Section III shows the
simulation results. Finally, section IV gives the conclusion.

II. SEMI-SUPERVISED HOEFFDING ADAPTIVE TREE

We learn a dictionary by extracting higher-level features
(such as oscillations, sudden changes, gradual changes, stable
periods) from the unlabeled dataset
later the
labeled data, which are then used to train a classiﬁer incre-
mentally.

to represent

 
 
 
 
 
 
A. Online Dictionary Learning

Given a set of unlabeled instances U =

(cid:111)
,
where x(i)
u ∈ Rn is the i-th input feature vector, we formulate
the following optimization problem to learn a new feature
space representing these data points:

, . . . , x(p)

x(1)
u

(cid:110)

u

minimize
D, {α(i)
u }
subject to

p
(cid:88)

i=1

(cid:13)
2
(cid:13)
(cid:13)
2

u − Dα(i)
u

(cid:13)
(cid:13)x(i)
(cid:13)
(cid:13)
(cid:13)
(cid:13)0

1
2
(cid:13)
(cid:13)α(i)
(cid:13)
(cid:107)dj(cid:107)2 ≤ 1, j = 1, 2, . . . , m

≤ k, i = 1, 2, . . . , p,

u

(1a)

(1b)

(1c)

are

the dictionary Dt =
The optimization variables
(cid:2)d1, . . . , dm
(cid:3) ∈ Rn×m and the sparse codes α(i)
u ∈ Rm, i =
1, 2, . . . , p. Typically, we have m (cid:29) n so that the dictionary is
rich enough. Hence, by the least square objective, each input
x(i)
is approximately represented as a linear combination of
u
very few basis vectors in D with the corresponding coefﬁcients
given by α(i)
u . The zero norm (cid:107)a(cid:107)0 denotes the number of non-
zero coordinates of a. Hence, the ﬁrst constraint forces the
vector α(i)
to have at most k nonzero elements. The energy
u
of each atom (basis) in the dictionary D is bounded by one,
as given by the second constraint. This constraint prevents the
entries of D from being arbitrarily large while the entries of
α(i)

u being very small.
We leverage the alternating minimization method for the
resulting nonconvex problem (1), i.e., minimizing one variable
at each step while keeping all other variables ﬁxed [16]. In the
ﬁrst step, we obtain the sparse codes α(i)
u , i = 1, 2 . . . , p. The
second step updates the dictionary D.

• Sparse coding – optimization over α(i)

u : Start with a
ﬁxed random dictionary D, and solve (1) with the or-
thogonal matching pursuit (OMP) algorithm to obtain
the α(i)
for
u
i = 1, 2, . . . , p.

that corresponds to the unlabeled point x(i)
u

u }p

• Dictionary update – optimization over D: Keep
{α(i)
i=1 ﬁxed, ﬁnd the dictionary Dt by sequentially
updating each atom via the block-coordinate descent
(BCD) algorithm:

uj = A−1

jj (bj − Dt−1aj) + dj,

j = 1, 2, . . . , m (2)

dj =

uj
max((cid:107)uj(cid:107)2, 1)

,

j = 1, 2, . . . , m, (3)

where Dt−1 is the dictionary at the previous iteration.
u α(i)(cid:62)
The matrices A = (cid:2)a1, . . . , am
∈ Rm×m
and B = (cid:2)b1, . . . , bm
(cid:3) = x(i)
∈ Rn×m carry the
u
information of the updated α(i)
u ’s. The update repeats
until Dt converges.

(cid:3) = α(i)

u α(i)(cid:62)

u

B. New Feature Representation

of

Consider

set
a
, y(1)), . . . , (x(q)

=
(cid:8)(x(1)
∈ Rn is the
(cid:96)-th input feature vector with label y(i) ∈ {1, . . . , C}. Upon
learning the dictionary D∗ as elaborated above, the labeled

labeled
, y(q))(cid:9), where x(i)

instances L

(cid:96)

(cid:96)

(cid:96)

Algorithm 1 Semi-supervised HAD (SSHAD)
Require:

u

, . . . , x(p)
u }
, y(1)), . . . (x(q)

1) Unlabeled data U = {x(1)
2) Labeled data L = (cid:8)(x(1)
3) Randomly initialize D from unlabeled data vectors.
4) Maximum iteration: max iter = 200.
1: Normalize the labeled and unlabeled data.
2: for t = 1 to max iter do
3:

Compute the sparse code αu with Dt−1 by solving

, y(q))(cid:9).

(cid:96)

(cid:96)

(1).

Update Dt keeping the matrix αu ﬁxed.

4:
5: end for
6: Solve (4b) to obtain the matrix α(cid:96).
7: Attach to α(cid:96) the labels from x(cid:96).
8: Train HAD with the new labeled dataset ˆL =

(cid:110)

(α(1)
(cid:96)

, y(1)), . . . , (α(q)
9: return The trained HAD classiﬁer.

, y(q))

(cid:96)

(cid:111)

using MOA.

data can be represented by using the basis vectors of D. This
is carried out by solving the following problem via the OMP
for each labeled data point:

(cid:96) − D∗α(i)

(cid:96)

(cid:13)
2
(cid:13)
(cid:13)
2

(4a)

minimize
α(i)
(cid:96)

1
2

(cid:13)
(cid:13)x(i)
(cid:13)
(cid:13)
(cid:13)
(cid:13)0

(cid:96)

subject to

(cid:13)
(cid:13)α(i)
(cid:13)
In other words, a labeled data point is now approximately
represented as a linear combination of the learned atoms as:

≤ k.

(4b)

(cid:96) = Dα(i)
x(i)

(cid:96) + η,

(5)

where η is the reconstruction error. We preserve each original
label of y(i) by attaching it to the new representation; i.e.,
the k-sparse code α(i)
in a higher dimensional space. Finally,
(cid:96)
we train the HAD classiﬁer with these new representations by
using the software package MOA [17].

Remark (Matching pursuit vis-a-vis LASSO). The sparse
dictionary learning problem generally has two different formu-
lations: matching pursuit and LASSO. The former is shown by
problem (1) while the latter is relaxing (cid:96)0 norm to (cid:96)1 norm and
being lifting to the objective as a soft constraint. The matching
pursuit formulation explicitly guarantees k-sparsity, which is
more user-friendly to ﬁnd the “best” value of k by trial-and-
error simulations. According to our numerical experiments
that will be discussed in the next section, we ﬁnd that the
solution to the matching pursuit is more stable numerically.

Algorithm 1 features two essential differences from the
algorithm in [18]. In [18], the authors build the dictionary
using self-taught learning (unlabeled and labeled datasets have
different generative distributions [19]) to later train and test
an SVM classiﬁer with the new representation of the labeled
dataset. In contrast, our model builds the dictionary using
SSL and next
incrementally trains a HAD classiﬁer with
all the transformed labeled dataset instances. In a nutshell,

our algorithm capitalizes on semi-supervised knowledge to
enhance the HAD classiﬁer’s overall performance. We name
the proposed algorithm as SSHAD, where “SS” stands for
semi-supervised, to differentiate it from the original version
of HAD presented in [13].

C. HAD Classiﬁer

HAD is composed of three main ingredients: a window
to remember recent examples, a distribution-change detector,
and an estimator for some statistics of the input data. Once
a change is detected, an alternate tree will be created and
grow with the instances appearing right after the change. The
existing alternate tree will replace the current tree if it is more
accurate. The HAT [20] is the parent tree of HAD, where the
former has only one change detector, ADWIN, whereas HAD
has two change detectors ADWIN and DDM.

ADWIN serves as an estimator and change detector that
keeps a variable-length window W of recent data such that
the window has the maximal length statistically consistent with
the null hypothesis of the average value inside the window has
not changed. When two “big enough” sub-windows of W have
“distinct enough” averages, it can be said with high probability
that a change in the data distribution has occurred and the older
items in W should be dropped. The “big and distinct enough”
can be quantitatively deﬁned by the Hoeffding bound [21].

DDM is a change detector that relies on the concept of
‘context’ deﬁned as a set of contiguous examples whose data
distribution is stationary. DDM incrementally controls the
error rate of the model. Statistical theory guarantees that the
error decreases if the data distribution remains stationary, and
error increases when the distribution changes. A new context
is declared if the error reaches a warning level at instance kw
and a drift level at instance kd. Given that, this indicates a
distribution change, and a new model is learned by using the
examples between kw and kd. A detailed explanation of DDM
can be found in [22].

III. EXPERIMENTS AND RESULTS

A. Datasets

Power system attack datasets [23] are used to test the per-
formance of our proposed approach. There are three datasets:
2-class, 3-class, and 37-class datasets, where each of them
includes 128 features split into two categories: physical (volt-
ages, currents, and impedances) and cyber-physical (control
logs, network alerts, and relay logs) features. Five scenarios
are considered: short-circuit faults, line maintenance, remote
tripping command injection (attack), relay setting change
(attack), as well as data injection (attack). Fig. 5 shows the
testbed architecture used in generating the datasets.

B. Implementation and Parameters

We run all the experiments using MATLAB, WEKA, and
the massive online analysis (MOA) software [24]. The relevant
parameters were obtained by using cross-validation. The value
of max iter = 200 yielded best results. The parameter k was
set to 10 for both OMP procedures, i.e, each of α(i)
u ’s and

Fig. 1. Test-bed architecture for generating the datasets

α(i)
(cid:96) ’s has at most ten nonzero values. We tested different
sizes for the dictionary and found that 130 atoms performed
the best. For both OMP optimization problems, the tolerance
of the squared (cid:96)2-norm residual was set to 0.01. Finally, the
parameters for the HAD were set to the default values given
by MOA.

C. Performance Metrics

In this work, we used the prequential evaluation technique,
where each instance is used to test and then train the model.
Because of this online setup, the accuracy is incrementally up-
dated. We chose the classiﬁcation accuracy, the Kappa statistic,
evaluation time, and model cost to evaluate our approach’s
performance; see also [13]. The Kappa statistic is a measure
for rating classiﬁcation accuracy for imbalance scenarios in
ofﬂine and online classiﬁcation. The Kappa statistic is deﬁned
as:

κ =

ρo − ρe
1 − ρe

,

(6)

where ρo is the accuracy of the classiﬁer under analysis, and ρe
is the accuracy of a random classiﬁer. If the classiﬁer predicts
all the time correctly, κ = 1. If the classiﬁer performs like a
random classiﬁer, κ = 0. The evaluation time consists of both
training and testing time because there is no clear separation
between them [13]. The model cost is measured in RAM per
hour (hereafter referred to as Ram-Hours) [12].

D. Simulation Results

We conduct classiﬁcation experiments using the 2-class, 3-
class, and 37-class datasets. The performance results were
obtained with ﬁve different sizes, determined by the labeled
dataset’s sampling ratio. All values given in ﬁgures and tables
are 10-fold average. The performance of our model improves
with the increased size of the unlabeled dataset. It can be seen
that the performance gets saturated with 50,000 unlabeled data
points.

Fig. 2, 3 and Tab. I show the classiﬁcation results for the 2-
class and 3-class datasets. It can be seen that the performances
of SSHAD and HAD are similar. However, when it comes
to the 37-class dataset, our model clearly outperforms HAD
as shown in Fig. 6, 4 and Tab. II. These results corroborate

the merits of our proposed approach, representing the data
by higher-level features yields more accurate identiﬁcation
of events in power systems. Moreover, as shown in Fig. 5,
SSHAD is robust to the presence of bad data.

TABLE I
THE 3-CLASS DATASET: 10-FOLD AVERAGE KAPPA (κ) AND COST (cost)
COMPARISONS BETWEEN SSHAD (k = 10) AND HAD.

Sampling
Ratio
10%
30%
50%
70%
90%

κ(%)

cost (Ram-Hour)

SSHAD
82.25
88.36
69.87
59.56
51.91

HAD
82.29
88.44
69.57
59.28
51.70

SSHAD
1.43 × 10−8
2.18 × 10−8
2.87 × 10−8
3.67 × 10−8
4.63 × 10−8

HAD
1.37 × 10−8
2.07 × 10−8
2.89 × 10−8
3.83 × 10−8
5.27 × 10−8

Fig. 4. 10-fold average time (¯t) comparison between SSHAD with parameter
k = 10 and HAD using the 37-class dataset.

Fig. 2. 10-fold average accuracy (acc) comparison between SSHAD with
parameter k = 10 and HAD using the 2-class and 3-class datasets.

Fig. 5. 10-fold average time (¯t) comparison between SSHAD with parameter
k = 10 and HAD using the 37-class dataset in the presence of 10% of bad
data.

Fig. 3. 10-fold average accuracy (acc) comparison between SSHAD with
parameter k = 10 and HAD using the 2-class and 3-class datasets.

Fig. 6. 10-fold average accuracy (acc) comparison between SSHAD with
parameter k = 10 and HAD using the 37-class dataset.

TABLE II
THE 37-CLASS DATASET: 10-FOLD AVERAGE KAPPA (κ) AND COST (cost)
COMPARISONS BETWEEN SSHAD (k = 10) AND HAD.

Sampling
Ratio
10%
30%
50%
70%
90%

κ(%)

cost (Ram-Hour)

SSHAD
29.80
69.62
79.48
82.33
85.64

HAD
28.39
62.32
77.41
80.30
84.38

SSHAD
5.80 × 10−8
1.20 × 10−7
9.24 × 10−8
1.09 × 10−7
1.24 × 10−7

HAD
5.88 × 10−8
1.64 × 10−7
1.09 × 10−7
1.13 × 10−7
1.28 × 10−7

IV. CONCLUSION

We develop a semi-supervised online approach (SSHAD)
for the power system event detection in this paper. The labeling
process for a large amount of unlabeled data is often very time-
consuming and costly, requiring speciﬁc domain knowledge
of many experts. Considering this fact, we leverage online
dictionary learning techniques to automatically build a new
feature space for the labeled data examples by extracting
valuable information from the unlabeled dataset. The learned
sparse codes of the labeled instances become the new feature
representations, based on which we train the HAD classiﬁer.
Extensive numerical results corroborate our proposed ap-
proach’s effectiveness that yields a better classiﬁcation per-
formance and compensates for the additional computational
burden of learning the higher dimensional representations.
Despite these results, we acknowledge that future work is
needed to make our approach more robust. For instance, this
work can be extended by studying how a malicious adversary
can modify the data and determining the depth of its attack
from the game theory perspective. Finally, a more detailed
analysis of the temporal dependence of the data should be
considered.

REFERENCES

[1] S. Ntalampiras, “Detection of

integrity attacks in cyber-physical
critical infrastructures using ensemble modeling,” IEEE Transactions
on Industrial Informatics, vol. 11, no. 1, pp. 104–111, Feb. 2015.
[Online]. Available: https://doi.org/10.1109/tii.2014.2367322

[2] H. Lin, Y. Deng, S. Shukla,

J. Thorp, and L. Mili, “Cyber
security impacts on all-PMU state estimator
- a case study on
co-simulation platform GECO,” in 2012 IEEE Third International
Conference on Smart Grid Communications (SmartGridComm).
IEEE,
Nov. 2012. [Online]. Available: https://doi.org/10.1109/smartgridcomm.
2012.6486049

[3] M. Kamal, M. Farajollahi, H. Nazaripouya, and H. Mohsenian-Rad,
“Cyberattacks against event-based analysis in micro-PMUs: Attack
models and counter measures,” IEEE Transactions on Smart Grid, pp. 1–
1, 2020. [Online]. Available: https://doi.org/10.1109/tsg.2020.3029937

[4] R. Ma, S. Basumallik, and S. Eftekharnejad, “A PMU-based data-driven
approach for classifying power system events considering cyberattacks,”
IEEE Systems Journal, vol. 14, no. 3, pp. 3558–3569, Sep. 2020.
[Online]. Available: https://doi.org/10.1109/jsyst.2019.2963546

[5] R. C. B. Hink, J. M. Beaver, M. A. Buckner, T. Morris, U. Adhikari,
and S. Pan, “Machine learning for power system disturbance and
cyber-attack discrimination,” in 2014 7th International Symposium
on Resilient Control Systems (ISRCS).
IEEE, Aug. 2014. [Online].
Available: https://doi.org/10.1109/isrcs.2014.6900095

[6] M. A. Karim, M. Chenine, K. Zhu, L. Nordstrom, and L. Nordstr¨om,
“Synchrophasor-based data mining for power system fault analysis,” in
2012 3rd IEEE PES Innovative Smart Grid Technologies Europe (ISGT
Europe).
IEEE, Oct. 2012. [Online]. Available: https://doi.org/10.
1109/isgteurope.2012.6465843

[7] K. Demertzis and L. Iliadis, “A computational intelligence system iden-
tifying cyber-attacks on smart energy grids,” in Springer Optimization
and Its Applications. Springer International Publishing, 2018, pp. 97–
116. [Online]. Available: https://doi.org/10.1007/978-3-319-74325-7 5
[8] D. Wang, X. Wang, Y. Zhang, and L. Jin, “Detection of power grid
disturbances and cyber-attacks based on machine learning,” Journal of
Information Security and Applications, vol. 46, pp. 42–52, Jun. 2019.
[Online]. Available: https://doi.org/10.1016/j.jisa.2019.02.008

[9] S. Pan, T. Morris, and U. Adhikari, “A speciﬁcation-based intrusion
detection framework for cyber-physical environment in electric power
system,” International Journal of Network Security, vol. 17, pp. 174–
188, 01 2015.

[10] ——, “Classiﬁcation of disturbances and cyber-attacks in power systems
using heterogeneous time-synchronized data,” IEEE Transactions on
Industrial Informatics, vol. 11, no. 3, pp. 650–662, Jun. 2015. [Online].
Available: https://doi.org/10.1109/tii.2015.2420951

[11] U. Adhikari, T. H. Morris, and S. Pan, “Applying non-nested generalized
exemplars classiﬁcation for cyber-power event and intrusion detection,”
IEEE Transactions on Smart Grid, vol. 9, no. 5, pp. 3928–3941, Sep.
2018. [Online]. Available: https://doi.org/10.1109/tsg.2016.2642787
[12] N. Dahal, O. Abuomar, R. King, and V. Madani, “Event stream
processing for improved situational awareness in the smart grid,”
Expert Systems with Applications, vol. 42, no. 20, pp. 6853–6863, Nov.
2015. [Online]. Available: https://doi.org/10.1016/j.eswa.2015.05.003

[13] U. Adhikari, T. H. Morris, and S. Pan, “Applying hoeffding adaptive
trees for real-time cyber-power event and intrusion classiﬁcation,” IEEE
Transactions on Smart Grid, vol. 9, no. 5, pp. 4049–4060, Sep. 2018.
[Online]. Available: https://doi.org/10.1109/tsg.2017.2647778

[14] Z. E. Mrabet, D. F. Selvaraj, and P. Ranganathan, “Adaptive hoeffding
tree with transfer learning for streaming synchrophasor data sets,” in
2019 IEEE International Conference on Big Data (Big Data).
IEEE,
Dec. 2019. [Online]. Available: https://doi.org/10.1109/bigdata47090.
2019.9005720

[15] K. Nigam, A. K. Mccallum, S. Thrun, and T. Mitchell, Machine
Learning, vol. 39, no. 2/3, pp. 103–134, 2000. [Online]. Available:
https://doi.org/10.1023/a:1007692713085

[16] J. Mairal, F. Bach, J. Ponce, and G. Sapiro, “Online dictionary learning
for sparse coding,” in Proceedings of the 26th Annual International
Conference on Machine Learning - ICML '09. ACM Press, 2009.
[Online]. Available: https://doi.org/10.1145/1553374.1553463

[17] A. Bifet, R. Gavald`a, G. Holmes, and B. Pfahringer, Machine
Learning for Data Streams. The MIT Press, 2018. [Online]. Available:
https://doi.org/10.7551/mitpress/10654.001.0001

[18] F. Liu, J. Ma, R. Zhao, and Q. Wang, “Online dictionary self-
taught learning for hyperspectral image classiﬁcation,” in 2018 IEEE
International Instrumentation and Measurement Technology Conference
(I2MTC).
IEEE, May 2018. [Online]. Available: https://doi.org/10.
1109/i2mtc.2018.8409676

[19] R. Raina, A. Battle, H. Lee, B. Packer, and A. Y. Ng, “Self-
taught learning,” in Proceedings of the 24th international conference on
Machine learning - ICML '07. ACM Press, 2007. [Online]. Available:
https://doi.org/10.1145/1273496.1273592

[20] A. Bifet and R. Gavald`a, “Adaptive learning from evolving data
Springer
[Online]. Available: https:

streams,” in Advances in Intelligent Data Analysis VIII.
Berlin Heidelberg, 2009, pp. 249–260.
//doi.org/10.1007/978-3-642-03915-7 22

[21] ——, “Learning from time-changing data with adaptive windowing,”
in Proceedings of the 2007 SIAM International Conference on Data
Mining. Society for Industrial and Applied Mathematics, Apr. 2007.
[Online]. Available: https://doi.org/10.1137/1.9781611972771.42
[22] J. Gama, P. Medas, G. Castillo, and P. Rodrigues, “Learning with
drift detection,” in Advances in Artiﬁcial Intelligence – SBIA 2004.
Springer Berlin Heidelberg, 2004, pp. 286–295. [Online]. Available:
https://doi.org/10.1007/978-3-540-28645-5 29

[23] U. Adhikari, S. Pan, T. H. Morris, and J. Beave, “Industrial control sys-
tem (ics) cyber attack datasets, dataset 1: Power system datasets,” https:
//sites.google.com/a/uah.edu/tommy-morris-uah/ics-data-sets, accessed:
2020-08-11.

[24] A. Bifet, G. Holmes, R. Kirkby, and B. Pfahringer, “Moa: Massive online
analysis,” J. Mach. Learn. Res., vol. 11, p. 1601–1604, Aug. 2010.

