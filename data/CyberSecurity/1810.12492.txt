8
1
0
2

t
c
O
0
3

]

R
C
.
s
c
[

1
v
2
9
4
2
1
.
0
1
8
1
:
v
i
X
r
a

DARKMENTION: A Deployed System to Predict
Enterprise-Targeted External Cyberattacks

Mohammed Almukaynizi1, Ericsson Marin1, Eric Nunes1, Paulo Shakarian1,2
Gerardo I. Simari3,1, Dipsy Kapoor4, Timothy Siedlecki5
1Arizona State University
2Cyber Reconnaissance, Inc.
3Department of Computer Science and Engineering, Universidad Nacional del Sur (UNS)
Institute for C.S. and Eng. (CONICET–UNS)
4University of Southern California
5Lockheed Martin Advanced Technology Laboratories
{malmukay, esmarin, enunes1, shak}@asu.edu
gis@cs.uns.edu.ar, dipsy@isi.edu, timothy.siedlecki@lmco.com

Abstract—Recent incidents of data breaches call for organi-
zations to proactively identify cyber attacks on their systems.
Darkweb/Deepweb (D2web) forums and marketplaces provide
environments where hackers anonymously discuss existing vul-
nerabilities and commercialize malicious software to exploit those
vulnerabilities. These platforms offer security practitioners a
threat intelligence environment that allows to mine for patterns
related to organization-targeted cyber attacks. In this paper, we
describe a system (called DARKMENTION) that learns associa-
tion rules correlating indicators of attacks from D2web to real-
world cyber incidents. Using the learned rules, DARKMENTION
generates and submits warnings to a Security Operations Center
(SOC) prior to attacks. Our goal was to design a system that
automatically generates enterprise-targeted warnings that are
timely, actionable, accurate, and transparent. We show that
DARKMENTION meets our goal. In particular, we show that it
outperforms baseline systems that attempt to generate warnings
of cyber attacks related to two enterprises with an average
increase in F1 score of about 45% and 57%. Additionally,
DARKMENTION was deployed as part of a larger system that is
built under a contract with the IARPA Cyber-attack Automated
Unconventional Sensor Environment (CAUSE) program. It is
actively producing warnings that precede attacks by an average
of 3 days.

I. INTRODUCTION

With the widespread use of technology, cyber-security has
become a concern for both commercial organizations and
governments. With the recent incidents of data breaches at
Equifax, Verizon, Gmail and others1, organizations are looking
at methods to proactively identify if they will be target of
future attacks. A 2017 Verizon investigation report stated that
75% of breaches were perpetrated by outsiders exploiting
known vulnerabilities [1]. Monitoring the vulnerabilities that
are of interest to malicious threat actors from the discussions
on Darkweb/Deepweb (D2web) hacking sites is a key aspect
of predicting cyber-attacks [2].

In this paper, we describe DARKMENTION, a system that
identiﬁes indicators of risks from unconventional sources of

threat intelligence (D2web), monitors those sources in real-
time to reason about the likelihood of future threats, generates
warnings, and submits them to the Security Operations Center.
We use concepts from causal reasoning [3], [4] and logic
programming (in particular, the concepts of Point Frequent
Function (pfr) from APT-logic [5], [6], [7]) to learn asso-
ciation rules. An example of the rules we sought to learn
is “if certain D2web activity is observed in a given time-
point, then there will be an x number of attacks of type
y, targeting organization o in exactly ∆t time-points, with
probability p”. Our data is obtained from a commercially
available API, maintained by a cyber-threat intelligence ﬁrm
(called CYR3CON2), and from over 500 historical records
of real-world targeted cyber incidents. Those incidents are
recorded from the logs of two large enterprises participating
to the IARPA Cyber-attack Automated Unconventional Sensor
Environment (CAUSE) program3.

Throughout the paper, we illustrate the viability of DARK-
MENTION as a tool that addresses problems directly related to
situational awareness, resource allocation, and countermeasure
prioritization. In particular, we show that DARKMENTION
produces warnings that are,

● timely: indicates the exact time-point in which a predicted

attack will occur,

● actionable: provides metadata/warning details, i.e., the
target enterprise, type of attack, volume, and the software
vulnerabilities/threat actor identiﬁed from the D2web
discussions,

● accurate: predicted unseen real-world attacks with an
average increase in F1 of over 45% for one enterprise
and 57% for the other, and

● transparent: allows analysts to easily trace the warnings
back to the rules that were triggered, discussions that ﬁred
the rules, etc.

1https://www.identityforce.com/blog/2017-data-breaches

2https://cyr3con.ai
3https://www.iarpa.gov/index.php/research-programs/cause

1

 
 
 
 
 
 
II. DATASET DESCRIPTION

A. D2web Crawling Infrastructure

Darkweb refers to the portion of the internet that is not
indexed by search engines and cannot be accessed by standard
browsers. Specialized browsers like Tor4 are required to access
darkweb sites. We retrieve information from both market-
places: where users advertise to sell information regarding
vulnerabilities or exploits, and forums: that provide discussions
on discovered vulnerabilities among others.

We summarize the D2web crawling infrastructure that
CYR3CON maintains—originally introduced in [8]. Cus-
tomized lightweight crawlers and parsers were built for each
site to collect and extract data. At the time of writing this
paper, data is collected from more than 400 platforms (fo-
rums and marketplaces). To ensure collection of cybersecurity
relevant data, machine learning models are used to ﬁlter data
related to drugs, weapons and other discussions irrelevant to
cybersecurity.

B. Data Pre-processing

CVE-CPE mapping: Common Vulnerability Enumeration
(CVE) is a unique identiﬁer assigned to each software vul-
nerability reported in the National Vulnerability Database
(NVD [9]). Common Platform Enumeration (CPE) is a list
of software/hardware products that are vulnerable to a given
CVE. CPE data can be obtained from the NVD. We query the
database using API calls to look for postings with software
vulnerability mentions (in terms of CVE number). Regular
expressions5 are used to identify CVE mentions. We map each
CVE to pre-identiﬁed groups of CPEs6 and nation-state threat
actors who are known to leverage that CVE as part of their
attack tactics7. Perhaps among the well-known threat actors is
the North Korean group HIDDEN COBRA, which was recently
identiﬁed to account for an increasing number of cyberattacks
to US targets8. These CPE and nation-state actor mappings
are used as pre-conditions during the rule-learning phase that
is discussed in Sectiona III and IV.

C. Enterprise-Relevant External Threats

To construct rules and evaluate the performance of the
learned model, we use data from historical records of attack
attempts that are recorded from the logs of two enterprises
participating in the IARPA CAUSE program9. One of the two
enterprises is a defense industrial base (referred to Armstrong)
while the other is a ﬁnancial services organization (referred to

4See the Tor Project’s ofﬁcial website (https://www.torproject.org/).
5https://cve.mitre.org/cve/identiﬁers/syntaxchange.html
6We cluster CPEs together based on common vendors/products. We iden-
tiﬁed over 100 groups of CPEs, e.g., Microsoft-Ofﬁce, Apache-Tomcat, and
Intel. However, only 33 were used as preconditions in the rules.

7We have encoded a list of threat actors along with vulnerabilities they favor
by manually analyzing cyberthreat reports that were recently published by cy-
bersecurity companies, e.g., https://media.kaspersky.com/en/business-security/
enterprise/KL Report Exploits in 2016 ﬁnal.pdf.
8https://www.us-cert.gov/ncas/alerts/TA17-164A
9https://www.iarpa.gov/index.php/research-programs/cause.

Dexter). The database is distributed to the performers partic-
ipating in a contest led by IARPA in increments, once every
few months. Each data point is a record of a detected deliberate
malicious attempt to gain unauthorized access, alter or destroy
data, or interrupt services or resources in the environment of
the participating organizations. Those malicious attempts were
detected in uncontrolled environment, and by different security
defense commercial products such as anti-virus,
intrusion
detection systems, and hardware controls. Each ground truth
(GT) record includes: ID, Format Version, Reported Time,
Occurrence Time, Event Type, and Target Industry10. The types
of attacks included in the GT dataset are:

● Malicious Email (M-E). A malicious attempt is identi-
ﬁed as a Malicious Email event if an email is received by
the organization, and it either contains a malicious email
attachment, or a link (embedded URL or IP address) to
a known malicious destination.

● Malicious Destination (M-D). A malicious attempt is
identiﬁed as a visit to a Malicious Destination if the
visited URL or IP address hosts malicious content.

● Endpoint Malware (E-M). A Malware on Endpoint
event is identiﬁed if malware is discovered on an endpoint
device. This includes, but not limited to, ransomware,
spyware, and adware.

Other events related to insider threats are out of the scope
of the current phase of the deployed system. A summary of
the time periods and the number of records for each attack
type is provided in Section V-C.

III. DEPLOYED SYSTEM

In this section we provide an overview of DARKMEN-
TION. Figure 1 provides a graphical illustration of the sys-
tem’s workﬂow. Our system comprises three main compo-
nents, each was designed to serve a set of tasks. There are three
reasons for having this particular design: (1) there are other
base models that were implemented using the same GT data,
(2) this design would result in minimal changes in the roles of
the subteams/members, and (3) model ensembles can improve
the overall predictions of the model generated warnings [10].

Figure 1: The Deployed System.

10We intentionally skip some details about other ﬁelds of the GT records

due to the limitation in space and irrelevance to the scope of this paper.

2

Rule LearningAPT RulesCYR3CON API      (D2web)Ground Truth(Armstrong, Dexter)Generate Warnings      D2web streaming dataConsolidationWarnings Base Models   Warning SubmissionififthenthenSecurity Operations CenterRule learning: The ﬁrst component is responsible for learning
rules, i.e., APT rules with pfr function [5], [6], [7]. The inputs
to the rule learner are: (1) the CPE-groups/actors that were
identiﬁed from the D2web discussions and the time-point
in which they are mentioned, and (2) the GT events with
their types and time-points in which they were observed. The
learner follows the technical approach discussed in Section IV
to generate APT rules. The output of this component
is
a set of APT rules that are determined to be useful, i.e.,
exceeding some thresholds on probability of occurrence and
some support count (frequency with which a rule is satisﬁed in
the historical data). Such capability aids in producing accurate
and timely warnings. Figure 2 shows the percentage increase
in the likelihood of occurrence of attack events per days
following D2web discussions for the rules that were identiﬁed
as useful. We note that the reported records of Malicious
Destination for Dexter only cover a time period that ends
before the testing time period starts. Therefore, no rules were
produced for Malicious Destination. Additionally, the system
did not learn useful rules relating to Armstrong’s Malicious
Destination events when ∆t is 1, 2, or 5.

target organization. Such details help in producing actionable
warnings, i.e., warnings that provide metadata/details includ-
ing the CVEs/tactics, industry, volume of discussions, etc.
Section IV-C provides further details about the way warnings
are generated from rules.

Model fusion: The ﬁnal component deals with consolida-
tion. It fuses warnings from various heterogeneous models
(including DARKMENTION), populates any missing warning
ﬁelds according to the program requirement, and generates
the ﬁnal version of each warning. This completed warning
is submitted to the Security Operations Center. Each warning
submitted is available to view and drill down into using a Web
UI and Audit Trail analysis capability. This audit trail goes
from the submitted warning all the way through model fusion,
the individual models, and each individual model’s raw data
used to generate a warning. In the case of DARKMENTION,
this would include the D2web postings/items with the CVEs
mentioned highlighted. This capability makes the warnings
that DARKMENTION produces transparent warnings, i.e.,
allows analysts to easily trace the warnings back to the
rules that were triggered, discussions that ﬁred the rules, etc.
Figure 3 shows two screenshots taken from the system.

(a) Armstrong

(b) Dexter

Figure 3: Two screenshots from DARKMENTION.

IV. ANNOTATED PROBABILISTIC TEMPORAL LOGIC
(APT-LOGIC)

We will deﬁne here the syntax and semantics of APT-logic
programs (set of APT-logic rules) applied to our domain,
which is built upon the work of Shakarian et al. in [6].

Figure 2: The percentage increase in likelihood of occurrence
for the rules that are identiﬁed to be useful.
Generating warnings: The second component is responsible
for generating warnings using the APT rules. This component
is executed daily by ﬁrst acquiring all CVEs mentioned in
the last 24 hours within the D2web streaming data. The CPE
groups/nation-state actors for these mentioned CVEs are then
obtained. Next, based on the APT-rules, the model tries to
match the CPE/nation-state actor mappings to a particular rule.
If a match exists, the model predicts if and when an attack
exploiting the vulnerabilities will occur by generating warn-
ings. The warning ﬁelds are populated using the information
contained in the rule, such as the probability, event type, and

A. Syntax
Herbrand base. We use BL to denote the Herbrand base
(ﬁnite set of ground atoms) of a ﬁrst order logical
lan-
guage L. Then, we divide BL into two disjoint sets:
BL{conditions} and BL{actions}, so that BL ≡ BL{conditions} ∪
BL{actions}. BL{conditions} comprehends the atoms allowed
representing condi-
only in the premise of APT rules,
tions or users’ actions performed on D2web websites,
e.g., mention on(forum 1 , debian). On the other hand,
BL{actions} comprehends the atoms allowed only in the con-
clusion of APT rules, representing actions or malicious activ-
ities reported by Armstrong or Dexter organizations in their
own facilities, e.g., attack (armstrong, malicious − email , x ).

3

        t P D O L F L R X V  H P D L O P D O L F L R X V  G H V W L Q D W L R Q H Q G S R L Q W  P D O Z D U H ( Y H Q W  W \ S H                   L Q F U H D V H  L Q  O L N H O L K R R G  R I  R F F X U U H Q F H        t P D O L F L R X V  H P D L O H Q G S R L Q W  P D O Z D U H ( Y H Q W  W \ S H                   L Q F U H D V H  L Q  O L N H O L K R R G  R I  R F F X U U H Q F HFormulas. Complex sentences (formulas) are constructed re-
cursively from atoms, using parentheses and the logical con-
nectives: (¬ negation, ∨ disjunction, ∧ conjunction). However,
we note that all formulas in this paper are single atoms.
Time formulas. If F is a formula, t is a time point, then Ft
is a time formula which states that F is true at time t.
Probabilistic time formulas. If φ is a time formula and [l, u]
is a probability interval ⊆ [0, 1], then φ ∶ [l, u] is a probabilistic
time formula (ptf). Intuitively, φ ∶ [l, u] says φ is true with a
probability in [l, u], or using the complete notation, Ft ∶ [l, u]
says F is true at time t with a probability in [l, u].
APT rules. Suppose condition F and action G are formulas, t
is a natural number, [l, u] is a probability interval and f r ∈ F
is a frequency function symbol that we will deﬁne later. Then
f r
↝ G ∶ [t, l, u] is an APT (Annotated Probabilistic Temporal)
F
rule, which informally saying, computes the probability that
G is true in exactly ∆t time units after F becomes true. For
instance, the APT rule below informs that the probability of
Armstrong company being attacked by a malicious-email, in
exactly 3 time units after users mention “debian” on forums 1,
is between 40% and 50%.
pf r
↝ attack(armstrong, malicious-email) ∶ [3,0.4,0.5]

mention on(set forum 1,debian)

B. Semantics

World. In general, a world is any set of ground atoms that
belong to BL. However, due to our constraint that separates
atoms into BL{conditions} and BL{actions}, not all possible
worlds are allowed in our APT rules. Strictly, one atom belong-
ing to BL{conditions} and one atom belonging to BL{actions}
must be present in an allowable world for our pfr rules.

Thread. A thread is a series of worlds that model the domain
over time, where each world corresponds to a discrete time-
point in T = {1, ..., tmax}. T h(i) speciﬁes that according
to the thread T h, the world at time i will be T h(i). Given
a thread T h and a time formula φ, we say T h satisﬁes φ
(denoted T h ⊧ φ) iff:

● If φ ≡ Ft for some ground time formula Ft, then T h(t)

satisﬁes F ;

● If φ ≡ ¬ρ for some ground time formula ρ, then T h does

not satisfy ρ;

● If φ ≡ ρ1 ∧ ρ2 for some ground time formulas ρ1 and ρ2,

then T h satisﬁes ρ1 and T h satisﬁes ρ2;

● If φ ≡ ρ1 ∨ ρ2 for some ground time formulas ρ1 and ρ2,

then T h satisﬁes ρ1 or T h satisﬁes ρ2;

Frequency functions. A frequency function represents tempo-
ral relationships within a thread, checking how often a world
satisfying formula F is followed by a world satisfying formula
G. Formally, a frequency function f r belonging to F maps
quadruples of the form (T h, F, G, t) to [0,1] of real numbers.
Among the possible ones proposed in [5], we investigate
here alternative deﬁnitions for Point Frequency Function (pfr),
which speciﬁes how frequently the action G follows the
condition F in “exactly” ∆t time points. To support ongoing
security operations we need to relax the original assumption

of a ﬁnite time horizon tmax in [5], [6]. We introduce here a
different but equivalent formulation for pfr that does not rely
on a ﬁnite time horizon. To accomplish that, we ﬁrst need to
deﬁne how a ptf can be satisﬁed in our model. If we consider
the ptf Ft ∶ [l, u], and some A′
∈ A, where A is the set of all
ptf ’s satisﬁed by our thread T h, we say T h ⊧ Ft ∶ [l, u] iff:

● If F = a for some ground a,
] ⊒ [l, u];

A s.t. [l′, u′

then ∃ at

∶ [l′, u′

] ∈

t ∶ [l, u] for some ground formula F ′,

● If Ft ∶ [l, u] = ¬F ′
then T h ⊧ F ′
● If Ft ∶ [l, u] = F ′

t ∶ [1 − u, 1 − l];

t ∶ [l, u] ∧ F ′′

t

formulas F ′ and F ′′, then T h ⊧ F ′
[l, u];

∶ [l, u] for some ground
t ∶ [l, u] and T h ⊧ F ′′
∶

t

● If Ft ∶ [l, u] = F ′

t ∶ [l, u] ∨ F ′′

t

formulas F ′ and F ′′, then T h ⊧ F ′
[l, u];

∶ [l, u] for some ground
t ∶ [l, u] or T h ⊧ F ′′
∶

t

We are ready to show the new formulation of pfr in
Equation 1, which is equivalent to the original one proposed
in [5] when tmax comprises the whole thread T h (all time
points):

∑
t∣T h⊧Ft∶[l,u]∧T h⊧Gt+∆t∶[l′,u′]

pf r(T h, F, G, ∆t) =
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎣

∑
t∣T h⊧Ft∶[l,u]

u

l′

,

∑
t∣T h⊧Ft∶[l,u]∧T h⊧Gt+∆t∶[l′,u′]

∑
t∶T h⊧Ft∶[l,u]

l

(1)

u′

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎦

Satisfaction of APT rules and programs. We say T h satisﬁes
pf r
↝ G ∶
an APT Rule F
[∆t, l, u]) iff:

pf r
↝ G ∶ [∆t, l, u] (denoted T h ⊧ F

pf r(T h, F, G, ∆t) ⊆ [l, u]

(2)

C. Rules and warnings

Probability intervals. We derive the probability intervals
related to all pairs [l, u] speciﬁed in this paper using the
standard deviation of the corresponding point probability in
a binomial distribution, i.e., std(p) =
[11], where n
is the number of events that produced the probability p.

n∗p∗(1−p)
n

APT programs. Our algorithms only adds to the logic pro-
grams the pfr rules with lower bounds exceeding the prior
probability of the rule’s head happening at any random time
point.

Warnings generation. The problem is to identify whether a
triggered rule should generate warnings, and the number of
warnings to generate. When there is no triggered rules on a
given day, no warnings are generated. When two rules are
triggered on the same day, both predict the same attack type
is going to happen on the same day (i.e., same ∆t), and one
predicts x number of attacks while the other predicts y number
of attacks, then they will generate x + y warnings if both are
qualiﬁed to generate warnings. A pfr r ∈ R is qualiﬁed to
generate x number of warnings if (1) the rule is triggered,
and (2) there is no other triggered rule r′
∈ R on the same

4

day and same rule head and ∆t as r’s but has higher point
probability than r’s.

the pairs are guaranteed to be mutually exclusive12. We store
in the database the pairs that are returned by the algorithm.

V. EXPERIMENTAL RESULTS

In this section, we provide evidence of the viability of our
approach through a series of experiments. The warnings that
are submitted by our system are evaluated by the Security
Operations Centers (SOCs) on a monthly basis. However, we
internally evaluated DARKMENTION since the external eval-
uations are aggregated for all models, and DARKMENTION
was operationally deployed only after the time periods those
reports cover.

A. Experimental Settings

We perform evaluations on the warnings targeting Arm-
strong that were submitted during July, August, and September
of 2017. The results are aggregated per months for the
experiments on Armstrong data while aggregated on periods
of 7 days for Dexter. The latter starts from July 1 to July
28, 2016. These time windows differ because the Armstrong
dataset covers a longer period of time as compared to the
period covered by Dexter, and there is no more GT data
about Dexter that is going to be provided or evaluated by the
program. The reported records of Malicious Destination for
Dexter only cover a time period that ends before the testing
time period starts, hence they are not evaluated.

B. Evaluation Metrics

To evaluate the accuracy of our system, we use three
metrics: recall, which corresponds to the fraction of GT events
that have matching warnings from the total number of GT
events; precision, which is the fraction of warnings that have
matching GT events from the total number of the generated
warnings; and F1, which is the harmonic mean of recall and
precision.

Matching warnings and GT events. DARKMENTION pre-
dicts the exact number of attacks on each day. Therefore, the
matching problem is to ﬁnd whether a warning w earns credit
for predicting a GT attack event g. If w predicts an attack with
different type than g's, or w predicts an attack on a different
day than the occurrence day of g, then they do not match.
Otherwise, they may or may not match based on whether or
not w or g have already been paired up with another GT event
or a warning, respectively.

To join together warnings with GT events in parings while
ensuring that resulting pairings are mutually exclusive, we
use the Hungarian assignment algorithm [12]. Intuitively, the
algorithm takes as input an n∗n matrix representation of (−1∗
lead-time). Lead-time is the time between warnings and GT
events that are qualiﬁed to match. Then, the algorithm returns
a solution S that maximizes the total lead-time11. Here, S is
a set of pairs, each maps a warnings to a GT event such that

C. Results

We found that our system outperforms a baseline system
that randomly generates x number of warnings on each day
such that each value of x has a chance proportional to its
frequency of occurrence in the historical data. We repeat the
baseline for 100 runs and take the average of each metric. In
the real-time deployment of DARKMENTION, human experts
can evaluate the warnings by leveraging the other capabilities
of the system, i.e., transparency and actionable through a Web
UI dashboard. However, in those experiments any triggered
rule is counted, which is not necessarily important given other
details. That said, our system scored signiﬁcantly higher than
the baseline system as shown in Table I.

VI. RELATED WORK.
To the best of our knowledge, this paper is the ﬁrst to present
a deployed system that applies causal reasoning to predict
enterprise-related external cyber threats. However, there exists
a large body of related research with studies about malicious
hacking community in D2web, and studies related to rule-
learning methods for security applications.

Hacking community on D2web.. While the hacking commu-
nity in D2web sites has been widely investigated in the existing
literature for applications such as analyzing the economics of
D2web forums/markets [13], [14] and identifying future cyber-
threats to mitigate risks [2], [15], none of these studies identify
threats related to speciﬁc corporations or identify when in
the future the predicted events may occur. DARKMENTION
speciﬁcally predicts enterprise-targeted attacks and the periods
in which those threats are predicted.

Rule-learning methods for security applications. A large
body of work on understanding and modeling the behavior
of threat actors and reasoning future risk levels to assist in
the implementation of strategic defense has been proposed.
While a growing number of studies along these lines have
focused on applications related to understanding the behavior
of terrorist and insurgent groups [16], [7], the cyber-security
applications have not received much attention, except in the
line of graph-based and attacker/defender game theoretical
modeling [17], [18]. Our work differs from such theoretical
approaches since we focus on practical details related to
deployment, and evaluate our system with real-world data.

VII. CONCLUSION

We present DARKMENTION, a deployed system that pro-
duces warnings about cyber incidents that will likely occur in
the future. Although the problem is difﬁcult, our system proves
to be useful as a tool that helps SOC teams to identify risks,
potential sources of risk (vulnerabilities or threat actors) and
context on which it builds its reasoning in a timely, actionable,

11Lead-time is a metric set by the program to evaluate the performers, but

we ignore it in this evaluation.

12We add dummy rows (warnings) or columns (GT events) with lead-times
of 1 to make the matrix square, then remove from the solution the pairs where
the lead-time is 1.

5

Table I: Evaluation results. * A simple baseline model that generates x number of warnings on each day based on the prior
probability of each possible value of x that was seen in the training data.

Dataset

type Testing starts #GT-events

DARKMENTION

#warnings Precision Recall

F1

M-E

Armstrong

M-D

E-M

M-E

E-M

Dexter

Jul-17
Aug-17
Sep-17
Jul-17
Aug-17
Sep-17
Jul-17
Aug-17
Sep-17
1-Jul-16
8-Jul-16
15-Jul-16
22-Jul-16
1-Jul-16
8-Jul-16
15-Jul-16
22-Jul-16

24
11
13
4
9
3
14
18
17
2
7
9
4
1
3
3
4

32
3
18
12
23
10
10
45
21
13
10
6
2
2
4
1
2

0.313
1.000
0.167
0.167
0.174
0.100
0.300
0.200
0.286
0.150
0.500
0.333
0.500
0.500
0.250
1.000
0.500

0.417 0.357
0.273 0.429
0.231 0.194
0.500 0.250
0.444 0.250
0.333 0.154
0.214 0.250
0.500 0.286
0.353 0.316
1.000 0.267
0.714 0.588
0.222 0.267
0.250 0.333
1.000 0.667
0.333 0.286
0.333 0.500
0.250 0.333

#warnings Precision Recall

Baseline* (average of 100 runs)
%increase
F1
in F1
0.205 0.271 32%
0.315 0.299 43%
0.249 0.247 -21%
0.091 0.090 178%
0.086 0.120 108%
0.075 0.068 126%
0.200 0.242 3%
0.168 0.217 32%
0.127 0.164 93%
0.205 0.169 58%
0.253 0.348 69%
0.188 0.276 -3%
0.355 0.385 -14%
0.330 0.226 195%
0.167 0.186 54%
0.190 0.217 130%
0.208 0.257 30%

11.759
11.966
12.793
3.534
3.121
2.948
8.552
9.155
8.879
2.720
2.610
2.770
3.050
1.790
1.750
1.740
1.780

0.417
0.289
0.249
0.099
0.232
0.071
0.326
0.324
0.247
0.157
0.655
0.619
0.469
0.189
0.245
0.281
0.383

accurate, and transparent manner. Our team was selected to
progress to the second phase of the CAUSE program.

ACKNOWLEDGMENT

Some of the authors were supported by the Ofﬁce of Naval
Research (ONR) Neptune program, the ASU Global Security
Initiative (GSI), and the National Council for Scientiﬁc and
Technological Development (CNPq-Brazil). Paulo Shakarian,
Dipsy Kapoor, and Timothy Siedlecki are supported by the
Ofﬁce of the Director of National Intelligence (ODNI) and the
Intelligence Advanced Research Projects Activity (IARPA) via
the Air Force Research Laboratory (AFRL) contract number
FA8750-16-C-0112. Gerardo Simari is also partially supported
by Universidad Nacional del Sur (UNS) and CONICET, Ar-
gentina. The U.S. Government is authorized to reproduce and
distribute reprints for Governmental purposes notwithstanding
any copyright annotation thereon. Disclaimer: The views and
conclusions contained herein are those of the authors and
should not be interpreted as necessarily representing the ofﬁ-
cial policies or endorsements, either expressed or implied, of
ODNI, IARPA, AFRL, or the U.S. Government.

REFERENCES

[1] Verizon,

“2017

2017.
[Online]. Available: https://www.ictsecuritymagazine.com/wp-content/
uploads/2017-Data-Breach-Investigations-Report.pdf

investigations

report,”

breach

data

[2] M. Almukaynizi, E. Nunes, K. Dharaiya, M. Senguttuvan, J. Shakarian,
and P. Shakarian, “Proactive identiﬁcation of exploits in the wild through
vulnerability mentions online,” in 2017 International Conference on
Cyber Conﬂict (CyCon U.S.), Nov 2017, pp. 82–88.

[3] P. Suppes, A probabilistic theory of causality. North-Holland Publishing

Company Amsterdam, 1970.

[4] S. Kleinberg and B. Mishra, “The temporal logic of causal structures,” in
Proceedings of the Twenty-Fifth Conference on Uncertainty in Artiﬁcial
Intelligence. AUAI Press, 2009, pp. 303–312.

[5] P. Shakarian, A. Parker, G. I. Simari, and V. S. Subrahmanian, “Anno-
tated probabilistic temporal logic,” ACM Trans. Comput. Logic, vol. 12,
no. 2, pp. 14:1–14:44, Jan. 2011.

6

[6] P. Shakarian, G. I. Simari, and V. S. Subrahmanian, “Annotated prob-
abilistic temporal logic: Approximate ﬁxpoint implementation,” ACM
Trans. Comput. Logic, vol. 13, no. 2, pp. 13:1–13:33, Apr. 2012.
[7] A. Stanton, A. Thart, A. Jain, P. Vyas, A. Chatterjee, and P. Shakarian,
“Mining for causal relationships: A data-driven study of the islamic
state,” in Proceedings of the 21th ACM SIGKDD International Con-
ference on Knowledge Discovery and Data Mining. ACM, 2015, pp.
2137–2146.

[8] E. Nunes, A. Diab, A. Gunn, E. Marin, V. Mishra, V. Paliath, J. Robert-
son, J. Shakarian, A. Thart, and P. Shakarian, “Darknet and deepnet
mining for proactive cybersecurity threat intelligence,” in Proceeding of
ISI 2016.

IEEE, 2016, pp. 7–12.

[9] NIST, “National vulnerability database,” https://nvd.nist.gov/, Last Ac-

cessed: Jan 2018.

[10] J. M. Montgomery, F. M. Hollenbach, and M. D. Ward, “Improving pre-
dictions using ensemble bayesian model averaging,” Political Analysis,
vol. 20, no. 3, pp. 271–291, 2012.
[11] G. Wadsworth and J. Bryan,

Introduction to Probability and
Random Variables, ser. A Wiley publication in mathematical statistics.
McGraw-Hill, 1960.
[Online]. Available: https://books.google.com/
books?id=NNtQAAAAMAAJ

[12] J. Munkres, “Algorithms for the assignment and transportation prob-
lems,” Journal of the society for industrial and applied mathematics,
vol. 5, no. 1, pp. 32–38, 1957.

[13] M. Motoyama, D. McCoy, K. Levchenko, S. Savage, and G. M. Voelker,
“An analysis of underground forums,” in Proceedings of the 2011 ACM
SIGCOMM conference on Internet measurement conference. ACM,
2011, pp. 71–80.

[14] L. Allodi, “Economic factors of vulnerability trade and exploitation,” in
Proceedings of the 2017 ACM SIGSAC Conference on Computer and
Communications Security. ACM, 2017, pp. 1483–1499.

[15] N. Tavabi, P. Goyal, M. Almukaynizi, P. Shakarian, and K. Ler-
man, “Darkembed: Exploit prediction with neural language models,”
in Proceedings of AAAI Conference on Innovative Applications of AI
(IAAI2018), 2018.

[16] V. S. Subrahmanian, A. Mannes, A. Roul, and R. Raghavan, Indian
Springer

Mujahideen: Computational Analysis and Public Policy.
Science & Business Media, 2013.

[17] J. Robertson, V. Paliath, J. Shakarian, A. Thart, and P. Shakarian, “Data

driven game theoretic cyber threat mitigation.” 2016.

[18] M. Brown, W. B. Haskell, and M. Tambe, “Addressing scalability
and robustness in security games with multiple boundedly rational
adversaries,” in International Conference on Decision and Game Theory
for Security. Springer, 2014, pp. 23–42.

