Predicting Cyber Attack Rates with Extreme Values

Zhenxin Zhan, Maochao Xu, and Shouhuai Xu

1

6
1
0
2

r
a

M
4
2

]

R
C
.
s
c
[

1
v
2
3
4
7
0
.
3
0
6
1
:
v
i
X
r
a

Abstract—It is important to understand to what extent, and
in what perspectives, cyber attacks can be predicted. Despite
its evident importance, this problem was not investigated until
very recently, when we proposed using the innovative method-
ology of gray-box prediction. This methodology advocates the
use of gray-box models, which accommodate the statistical
properties/phenomena exhibited by the data. Speciﬁcally, we
showed that gray-box models that accommodate the Long-Range
Dependence (LRD) phenomenon can predict the attack rate (i.e.,
the number of attacks per unit time) 1-hour ahead-of-time with
an accuracy of 70.2-82.1%. To the best of our knowledge, this is
the ﬁrst result showing the feasibility of prediction in this domain.
We observe that the prediction errors are partly caused by the
models’ incapability in predicting the large attack rates, which
are called extreme values in statistics. This motivates us to analyze
the extreme-value phenomenon, by using two complementary
approaches: the Extreme Value Theory (EVT) and the Time
Series Theory (TST). In this paper, we show that EVT can offer
long-term predictions (e.g., 24-hour ahead-of-time), while gray-
box TST models can predict attack rates 1-hour ahead-of-time
with an accuracy of 86.0-87.9%. We explore connections between
the two approaches, and point out future research directions.
Although our prediction study is based on speciﬁc cyber attack
data, our methodology can be equally applied to analyze any
cyber attack data of its kind.

Index Terms—Extreme values, extreme value theory, predic-

tion, gray-box models, time series

I. INTRODUCTION

Data-driven cybersecurity analytics can deepen our under-
standing about the statistical phenomena/properties of cyber
attacks, and can potentially help predict cyber attacks (at least
from certain perspectives). Being able to predict cyber attacks,
even for minutes (if not hours) ahead-of-time, would allow
the defender to proactively allocate resources for adequate
defense (e.g., dynamically allocating sufﬁcient resources for
deep packet inspection or ﬂow-level assembly and analysis).
Despite its apparent importance, there has been little progress
in the prediction of cyber attacks until very recently in [1],
perhaps because of the lack of real data and the lack of readily
usable prediction models.

In [1], we proposed using the methodology of gray-box
prediction to predict the cyber attack rate, namely the number
time. Gray-box prediction uses gray-
of attacks per unit
box models that can accommodate the statistical proper-
ties/phenomena exhibited by the data. In contrast, black-box

Copyright (c) 2013 IEEE. Personal use of this material

is permitted.
However, permission to use this material for any other purposes must be
obtained from the IEEE by sending a request to pubs-permissions@ieee.org
Zhenxin Zhan and Shouhuai Xu are with the Department of Computer
Science, University of Texas at San Antonio, San Antonio, TX 78249. Emails:
jankins.ics@gmail.com (Zhenxin Zhan), shxu@cs.utsa.edu
(Shouhuai Xu; corresponding author)

Maochao Xu is with the Department of Mathematics, Illinois State Univer-

sity, Normal, IL 61790. Email: mxu2@ilstu.edu

models do not care about the statistical properties/phenomena
exhibited by the data. We found for the ﬁrst time that the
Long-Range Dependence (LRD) property/phenomenon is ex-
hibited by honeypot-collected cyber attack data [1]. For three
real data sets that will be called Periods I, II and III, the
gray-box models accommodating the LRD phenomenon can
predict attack rates 1-hour ahead-of-time with an accuracy
of 82.1% (error: 17.9%), 78.3% (error: 21.7%) and 70.2%
(error: 29.8%), respectively. In contrast, the black-box models,
which cannot accommodate the LRD phenomenon, can only
predict attack rates 1-hour ahead-of-time with an accuracy
of 55.4%, 63.7% and 72.7%, respectively. This means that
gray-box models can predict more accurately than black-box
models. While this result is encouraging, we need to further
improve the prediction accuracy of gray-box models to make
them practically employable. For this purpose, we observe that
the aforementioned 17.9%, 21.7% and 29.8% prediction errors
of gray-box models can be partly attributed to their inability to
predict the large attack rates, which are called extreme values
in statistics. Since extreme values are pervasive in the data, we
analyze the extreme-value phenomenon in hope of achieving
substantially more accurate predictions.

A. Our Contributions

We propose a methodology for predicting attack rates in
the presence of extreme values. The methodology analyzes
the extreme-value phenomenon via two complementary ap-
proaches: the Time Series Theory (TST) and the Extreme
Value Theory (EVT). Although our case study is based on
speciﬁc cyber attack data collected by a honeypot, the method-
ology can be equally applied to analyze any cyber attack
data of its kind (e.g., attacks against production networks).
Speciﬁcally, we make two contributions.

First, for short-term predictions, we propose a family of
gray-box TST models, called FARIMA+GARCH models, to
accommodate the LRD and extreme-value phenomena exhib-
ited by the data. For the three real data sets mentioned above,
these gray-box models can predict attack rates 1-hour ahead-
of-time at an accuracy of 86.2% (error: 13.8%), 87.9% (error:
12.1%) and 86.0% (error: 14.0%), respectively. Compared with
the gray-box FARIMA models that can accommodate the LRD
phenomenon but not the extreme-value phenomenon [1], the
accommodation of extreme values allows FARIMA+GARCH
to predict attack rates at an improved accuracy of 4.1%,
9.6% and 15.8%, respectively. We also show that the gray-
box FARIMA+GARCH models offer substantially more ac-
curate predictions than Hidden Markov Models (HMM) and
Symbolic Dynamics (SD) models. Despite that there are two
other data sets for which FARIMA+GARCH cannot predict
as accurately as we want, FARIMA+GARCH predictions

 
 
 
 
 
 
are still substantially more accurate than the other models.
Therefore, this model’s inadequacy does not invalidate the
gray-box prediction methodology; rather, it suggests further
enhancing these FARIMA+GARCH models to accommodate
the other statistical properties/phenomena, which have yet to
be identiﬁed but are exhibited by those two data sets.

Second, we show that the EVT and TST approaches should
be used together in practice because EVT-based methods
are more appropriate for long-term predictions (e.g., 24-hour
ahead-of-time) and TST-based methods are more appropriate
for short-term predictions (e.g., 1-hour ahead-of-time). A
combination of the two approaches can lead to more accu-
rate results. On one hand, the defender can allocate defense
resources utilizing EVT-based predictions of the magnitudes of
attack rates (which are predicted 24-hour ahead-of-time), while
making adjustments incorporating TST-based predictions of
maximum attack rates (which are predicted 1-hour ahead-of-
time). With a certain degree of agility, the defender can allo-
cate defense resources with respect to TST-based predictions
of the maximum attack rates, while taking into account EVT-
based predictions of the magnitudes of attack rates.

B. Related Work

To the best of our knowledge, the problem of predicting
cyber attacks has not be investigated in the literature. This is
perhaps because of (i) the rule of thumb that cyber attacks are
not predictable, (ii) the lack of real data, and/or (iii) the lack
of readily usable prediction methods. However, we recently
showed that cyber attack rates can be predicted 1-hour ahead-
of-time via gray-box models, which accommodate the LRD
phenomenon that is exhibited by the data [1]. Noticing that the
prediction errors in [1] are partly caused by the model’s failure
in predicting large attack rates, we analyze the extreme-value
phenomenon in hope to substantially improve the prediction
accuracy. To the best of our knowledge, this is the ﬁrst study
on analyzing the extreme-value phenomenon in cyber attack
data and the ﬁrst study on predicting cyber attack rates in the
presence of extreme values.

While we believe that studying how to predict cyber attack
rates is important on its own, it is also important to make
predictions practical. This issue is sometimes called the se-
mantic gap [2]. We note that the practical use of gray-box
prediction models is dependent upon the nature of the data,
and that the data we use for our case study in the present paper
is collected by a honeypot. In order to maximize the practical
use of predictions, one might consider blending honeypot IP
addresses into production network IP addresses and frequently
randomizing them. This would make it hard for attackers to
identify those honeypot IP addresses and then evade from
them. It is worth mentioning that both extreme values and
anomaly behaviors are statistical outliers, but of different
kinds. That is, their treatment requires different methodologies.
Since our investigation is based on honeypot-collected data,
we should mentioned that there is a rich body of literature
on analyzing honeypot data from perspectives such as: (i)
distinguishing known vs. unknown attacks [3], (ii) identifying
trafﬁc characteristics [4], [5], [6], [7], [8], [9], (iii) extracting

2

probing and scan activities [10], [11], (iv) characterizing
Denial-of-Service (DoS) attacks [12], (v) studying worm and
botnet activities [13], [14], [15], [16], and others [17], [18],
[19]. However, prediction is the main task of the present paper.
Finally, there are investigations that are loosely related to
ours, such as the analysis of blackhole-collected data (e.g.,
[20], [21]) and one-way trafﬁc [22]. These studies aim to
classify the data into classes (e.g. scanning, peer-to-peer
applications, unreachable services, misconﬁgurations, worms
etc). A more recent study of blackhole-collected data aims
to characterize the cybersecurity posture [23]. However, these
studies do not consider the issue of prediction, which is our
perspective.

The paper is organized as follows. Section II brieﬂy reviews
some preliminary statistical knowledge. Section III describes
our statistical analysis methodology. Section IV uses EVT to
analyze extreme attack rates. Section V uses TST to analyze
the time series data. Section VI compares the prediction
power of multiple methods, and explores connections between
EVT-based and TST-based predictions. Section VII discusses
limitations of the present study and directions for future
research. Section VIII concludes the paper.

II. STATISTICAL PRELIMINARIES
We now review the statistical concepts and techniques that
are used in the present paper. Throughout
the paper, we
use the more intuitive terms “outliers”, “extreme values”,
“extreme events”, “extreme-value events” and the EVT jar-
gon “exceedances” interchangeably. We also use the intuitive
term “average inter-arrival time” between consecutive extreme
values and the EVT jargon “return period” interchangeably.

A. Statistics of the Extreme-Value Phenomenon

Figure 1.
Illustration of the extreme-value phenomenon: the dashed line
represents a threshold; green dots are extreme values or exceedances; black
dots are non-extreme values; extremal index θ indicates the clustering degree
of extreme values (where a cluster is a set of consecutive extreme values).

Figure 1 illustrates a time series of attack rates (per unit
time), where the threshold line corresponds to a threshold
value µ such that the green dots (above the threshold line)
are extreme attack rates or extreme values. At a high level,
the extreme-value phenomenon can be characterized from a
“spatial” perspective (i.e., the distribution of the magnitude
of extreme values), a “temporal” perspective (i.e., the inter-
arrival time between two consecutive extreme values), and a
“spatial-temporal” perspective (i.e., the concept of return level
described below).

1) Distribution of extreme values:

if
X1, . . . , Xn are stationary,
then [Xi − µ|Xi > µ] may
follow the standard Generalized Pareto Distribution (GPD)
with survival function

is known that

It

¯Gξ,σ(µ)(x) = 1 − Gξ,σ(µ) =

(cid:40) (cid:16)

(cid:17)−1/ξ

1 + ξ

x
σ
exp{−x/σ},

,

ξ (cid:54)= 0,

,

ξ = 0.

where x ∈ R+ if ξ ∈ R+ and x ∈ [0, −σ/ξ] if ξ ∈ R−,
and ξ and σ are respectively called the shape and scale
parameters. If X1, . . . , Xn are from a non-stationary process,
then [Xi − µ|Xi > µ] may follow a non-stationary GPD with
time-dependent parameters, namely

¯Gξ(t),σ(t)(x) =






(cid:19)−1/ξ(t)

(cid:18)

1 +

ξ(t)x
σ(t)

,

ξ(t) (cid:54)= 0,

exp{−x/σ(t)},

ξ(t) = 0.

In order to know which of these two scenarios we encounter,
we use the Point Over Threshold (POT) method to ﬁt extreme
values via these distributions [24], [25].

2) Extremal index 0 < θ ≤ 1: This index reﬂects the
degree at which the extreme values are clustered (cf. Figure
1): 1/θ indicates the mean size of clusters (i.e., the mean
number of extreme values in a cluster), where θ = 1 implies
that each cluster has one extreme value (i.e.,
there is no
clustering phenomenon). Formally, let {X1, X2, . . . , } be a
sequence of random variables from a stationary process. Let
Mn = max{X1, . . . , Xn}. Under certain regularity condi-
tions, it holds that

lim
n→∞

P

(cid:18) Mn − bn
an

(cid:19)

≤ x

= H θ

ξ (x),

where an and bn are normalizing constants,
σ )−1/ξ(cid:9) ,
σ },

(cid:26) exp (cid:8)−(1 + ξ x−µ
exp{−e− x−µ

Hξ(x) =

ξ (cid:54)= 0
ξ = 0

(1)

is a non-degenerate distribution function with 1 + ξ x−µ
σ > 0,
and θ ∈ (0, 1] is the extremal index. We will characterize the
extremal index when ﬁtting the extreme attack rates.

3) Return level: This index reﬂects the expected magnitude
of extreme values (but not necessarily the maximum value). Let
T be the average inter-arrival time between two consecutive
extreme values, which is also called the return period. The
probability that an extreme event occurs is p = 1/T . The
concept of return level identiﬁes a special threshold value
such that there is, on average, a single extreme event during
each return period. Formally, suppose random variable X has
a stationary GPD with shape parameter ξ and scale parameter
σ. Then,

P (X > x) = ζµ

1 + ξ

(cid:20)

(cid:19)(cid:21)−1/ξ

(cid:18) x − µ
σ

,

ξ (cid:54)= 0,

where ζµ = P (X > µ). The return level xm is exceeded
(on average) once per m observations (i.e., time intervals),
and is given by xm = µ + σ/ξ (cid:2)(mζµ)ξ − 1(cid:3). For non-
is given by xm = µ +
stationary GPD,
σ(m)/ξ(m) (cid:2)(mζµ)ξ(m) − 1(cid:3). We will use this method to
predict the return level of extreme attack rates.

the return level

3

B. Properties and Models of Time Series

1) Long-Range Dependence (LRD): Unlike the Poisson
process with the memoryless property, a LRD process exhibits
that the autocorrelation decays slower than the exponential
decay. Formally, a stationary time series {Xt} exhibits LRD
if its autocorrelation r(h) = Cor(Xi, Xi+h) ∼ h−βL(h) as
h → ∞, where 0 < β < 1, and L(·) is a slowly varying
L(tx)
L(x) = 1 for all t > 0 [24]. Note that
function with lim
x→∞
(cid:80)
h r(h) = ∞. The degree of LRD is quantiﬁed by the Hurst
parameter H = 1 − β/2, meaning that 1/2 < H < 1 and
the degree of LRD increases as H → 1. LRD is exhibited by
the data, which is analyzed in [1] and further analyzed in the
present paper.

2) FARIMA and GARCH Time Series Models: FARIMA
(Fractional AutoRegressive
Integrated Moving Average)
and GARCH (Generalized AutoRegressive Conditional Het-
eroskedasticity) are two widely used time series models
[26]. FARIMA can accommodate LRD, while GARCH can
accommodate the extreme-value phenomenon. We will use
FARIMA+GARCH models to predict attack rates. Speciﬁcally,
let φ(x) = 1 − (cid:80)p
j=1 φjxj, ψ(x) = 1 + (cid:80)q
j=1 ψjxj, and (cid:15)t
be independent and identical normal random variables with
mean 0 and variance σ2
(cid:15) . A time series {Xt} is called a
FARIMA(p, d, q) process if φ(B)(1 − B)dXt = ψ(B)(cid:15)t,
where −1/2 < d < 1/2, and B is the back shift operator
with BXt = Xt−1, B2Xt = Xt−2, etc. A time series {Xt}
is called a GARCH process [27] if Xt = σt(cid:15)t, where (cid:15)t (also
called innovation) is the standard white noise. We consider two
variants of GARCH. For the Standard GARCH (SGARCH)
model, we have σ2
t−j.
the Integrated GARCH (IGARCH) model, we have
For
t = w + (1 − ψ(B))vt, where vt = (cid:15)2
φ(B)(1 − B)(cid:15)2
t . To
accommodate more general classes of noise, we will use the
skewed Student-T distribution (SSTD) or skewed Generalized
Error distribution (SGED).

t = w + (cid:80)q

t−j + (cid:80)p

j=1 βjσ2

j=1 αj(cid:15)2

t − σ2

3) Hidden Markov Model (HMM) for Time Series: HMM
can describe a Markov process with hidden states that are not
directly observable. Speciﬁcally, suppose xt is the observation
of some Markov process with hidden state st at time t. The
joint distribution of a sequence of states and observations can
be written as

p(x1, . . . , xT ) = p(s1)p(x1|s1)

T
(cid:89)

t=2

p(st|st−1)p(xt|st),

where p(s1) is the probability of the initial state s1, and
p(st|st−1) is the state transition probability. It is often assumed
that p(xt|st) follows the Gaussian distribution [28].

4) Symbolic Dynamics (SD) Model of Time Series: The
basic idea underlying symbolic time series analysis is the
following: partitioning the phase space, encoding the observed
time series data into nonlinear system dynamics, and construct-
ing a ﬁnite state machine model from the symbol sequence.
For example, a time series {Xt
: t = 1, . . . , T } may be
reduced to a string { ¯X1, . . . , ¯Xw}, where w < T , and ¯Xi is
a symbol representing some aggregation as an approximation
to the original time series [29].

III. DATA AND ANALYSIS METHODOLOGY

A. Honeypot

A honeypot is a monitored instrument for passively collect-
ing probe and attack trafﬁc [30]. A honeynet is composed of
multiple honeypots [31]. In general, there are two types of
honeypots. High-interaction honeypots are systems with real
vulnerabilities in their service programs. This instrument is
not scalable because it consumes a lot of computing resources.
Moreover, running high-interaction honeypots often involves
legal issues, which is true at least in the United States. Low-
interaction honeypots usually simulate software vulnerabili-
ties. This instrument is scalable because it conducts limited
interactions with attackers. The data we analyze in the present
data is collected by a low-interaction honeypot, which consists
of 166 consecutive IP addresses. The honeypot runs four
honeypot programs: Amun [32], Dionaea [33], Mwcollector
[34] and Nepenthes [35]. Each program is associated to a
unique IP address. Each physical computer monitors multiple
IP addresses.

B. Data

The data we analyze is the same as in [1]. This is plausible
because our predictions of attack rates directly improve upon
those in [1]. The data was collected during ﬁve periods of
time in 2010-2011, and these ﬁve periods of time correspond
to 47, 18, 54, 21 and 80 days, respectively. We extract the
attack trafﬁc from raw data (in pcap format) with respect
to the ports that are monitored by those honeypot programs.
We treat each TCP ﬂow initiated by a remote computer as
an attack because the honeypot does not offer any legitimate
service. An unsuccessful TCP handshake is also deemed as
attack because a handshake could have been dropped by a
honeypot program. For assembling TCP ﬂows, we set the ﬂow
lifetime as 300 seconds (i.e., an attack/ﬂow does not span over
300 seconds) and the ﬂow timeout time as 60 seconds (i.e.,
an attack/ﬂow expires if there is no activity for 60 seconds);
these parameters have been widely used [36].

C. The Extreme-Value Phenomenon

Figure 2 plots the attack data during the ﬁve periods of
time, with some illustrative thresholds above which attack
rates are considered extreme values. We observe the extreme-
value phenomenon, namely the many extreme attack rates (i.e.,
spikes) caused by intense attacks. For example, the two spikes
at the 1,237th and 1,335th hours in Period III are SSH trafﬁc
(or “SSH scans”); the spike at the 1,693th hour in Period
V is SIP INVITE trafﬁc (or DDoS attacks via SIP INVITE
messages).

D. An Extreme-Value Analysis Methodology

Our methodology is centered on analyzing statistical prop-
erties of attack rates and exploiting these statistical properties
to predict attack rates. For this purpose, we integrate two
complementary statistical approaches. The ﬁrst approach is
based on EVT (Extreme Value Theory), which deals with
extreme attack rates. This approach is appropriate for relatively

4

(a) Period I

(b) Period II

(c) Period III

(d) Period IV

(e) Period V

Figure 2. Time series plots of attack rates (number of attacks per hour). The
red lines are some thresholds, and the attack rates above these thresholds are
extreme values.

long-term prediction of extreme events (e.g., 24-hour ahead-
of-time), because (i) extreme events do not occur often, and (ii)
the analysis only considers extreme attack rates. The second
approach is based on TST (Time Series Theory), which does
not differentiate between the extreme values (above the thresh-
old) and the non-extreme values (below the threshold). These
two approaches are complementary to each other because (i)
the data/information they use is different (i.e., proper subset
vs. superset), and (ii) the predictions they make are different
(i.e., return levels or expected magnitude of extreme attack
rates vs. concrete attack rates). Therefore, it is interesting to
seek connections between them.

For both EVT-based and TST-based analyses, we proceed
as follows. First, we identify the statistical properties exhibited
by the data, such as the stationarity of the processes that
drive the attacks, and the clustering behavior exhibited by the
extreme values. Second, we exploit the identiﬁed statistical
properties to ﬁt the relevant data (i.e., gray-box ﬁtting). Al-
though there are generic methods for analyzing the extreme-
value phenomenon, those generic methods are not sufﬁcient
for our purpose because they do not consider the properties
exhibited by the cyber attack data we analyze. This observation
motivates us to investigate new statistical
techniques that
are relevant to the cybersecurity domain (e.g., a family of
FARIMA+GARCH models). Third, we predict attack rates by
using EVT- and TST-based methods (i.e., gray-box prediction),

and explore relationships (especially, the consistency) between
their predictions.

IV. EVT-BASED EXTREME-VALUE ANALYSIS
In order to ﬁt the distribution of extreme values, we need
to determine whether they are driven by a stationary process
(i.e., the distribution does not change) or they are driven by
a non-stationary process. This will guide us in how we use
time-invariant or time-dependent parameters in the models that
we select to ﬁt the data. For this purpose, we consider four
candidate models: M1, . . . , M4, where M1 corresponds to the
case of stationary processes and the others correspond to the
case of non-stationary processes. Speciﬁcally,

• M1: The standard GPD (Generalized Pareto Distribution).
• M2: GPD with time-invariant shape parameter ξ but time-
dependent scale parameter σ(t) = exp (β0 + β1 log(t)).
• M3: GPD with time-invariant scale parameter σ but time-

dependent shape parameter ξ(t) = γ1 + γ2t.

• M4: GPD with time-dependent parameters σ(t) =

exp (β0 + β1 log(t)) and ξ(t) = γ1 + γ2t.

Since we do not know the stationarity a priori, we ﬁrst use M1
to ﬁt the extreme attack rates. If M1 cannot ﬁt well, we use
non-stationary models M2, . . . , M4 to ﬁt the extreme attack
rates. We use some standard goodness-of-ﬁt statistics and QQ-
plot for evaluating the quality of ﬁtting.

A. Fitting Stationary Extreme Attack Rates

We use Algorithm 1 to ﬁt stationary extreme attack rates.
The algorithm uses QQ-plot and two goodness-of-ﬁt statistics
called CM and AD [37], where both CM and AD measure
the goodness-of-ﬁt of a distribution. If the p-values of both
CM and AD statistics are greater than .1 (which is more
conservative than the textbook criterion .05), and the QQ-
plot also conﬁrms the goodness-of-ﬁt,
then the algorithm
concludes that the extreme attack rates are stationary and
follow the standard GPD; otherwise, the extreme attack rates
are non-stationary and will be ﬁtted via Algorithm 2, which
is described below.

Algorithm 1 Fitting stationary extreme attack rates via M1
INPUT: attack-rate time series
OUTPUT: M1 ﬁtting result

1: initialize quantileSet {assuring ≥ 30 extreme values}
2: for q ∈ quantileSet (from the minimum to the maximum

in increasing order) do

3:

use the standard GPD to ﬁt the extreme attack rates that
are greater than threshold quantile q
evaluate goodness-of-ﬁt statistics CM, AD, QQ-plot
if ﬁtting is good then

estimate GPD parameters (ξ, σ), extremal index θ
{the ﬁrst successful ﬁtting}
return (q, ξ, σ, θ)

4:
5:
6:
7:
end if
8:
9: end for
10: return -1 {stationary distribution ﬁtting failed}

A key ingredient in Algorithm 1 is the threshold quantile,
which speciﬁes the threshold above which an attack rate is an

5

extreme value. Speciﬁcally, quantileSet is an ordered set of
quantiles, where the maximum quantile is chosen to guarantee
that there are at least 30 extreme attack rates (because, as a
rule of thumb, 30 is required for the sake of reliable ﬁtting),
and the minimum quantile is 20% different from the maximum
quantile with step-length 5%. For example, suppose there are
1000 attack rates (corresponding to observations during 1000
hours). The maximum threshold quantile is 1− 30
1000 ×100% =
97% and the minimum threshold quantile is 77%, leading to
quantileSet = {77%, 82%, 87%, 92%, 97%}. The algorithm
starts with threshold quantile 77%, then 82% etc. (i.e., in
increasing order), and halts on the ﬁrst successful ﬁtting (in
which case, parameters are obtained) or until after all of the
ﬁtting attempts fail (i.e., the process is non-stationary).

Table I summarizes the ﬁtting results using M1. Extreme
attack rates in Periods III and V are from stationary processes,
but the other three periods cannot be ﬁtted by M1. Speciﬁcally,
Period III has threshold quantile q = 90% (i.e., there are
130 extreme attack rates that are above the 90% quantile) and
extremal index θ = 0.60 (i.e., a cluster contains, on average,
1/.60 = 1.67 extreme values, or extensive attacks sustain
for 1.67 hours on average). Period V has threshold quantile
q = 95% and extremal index θ = .33. Combining the above
observations and the fact that the ﬁve periods are respectively
47, 18, 54, 21, and 80 days, we suspect that stationary extreme
attack rates may not be observed for a period of time shorter
than 50 days, because Periods III and V correspond to 54 and
80 days, respectively.

θ
0.60
0.33

q
90%
95%

Period
III
V

# of EV
130
96

# of C
95
31
Table I
EVT-BASED FITTING OF STATIONARY ATTACK RATES, WHERE (q, ξ, σ, θ)
ARE OUTPUT BY ALGORITHM 1, “# OF EV” MEANS “NUMBER OF EXTREME
VALUES (I.E., EXTREME ATTACK RATES)”, “# OF C” MEANS “NUMBER OF
CLUSTERS”, PARAMETERS θ, ξ, σ ARE DESCRIBED IN SECTION II. THE
LAST COLUMN INDICATES THE BEST FITTING MODEL.

σ model
3778.19 M1
13553.5 M1

ξ
0.36
0.16

B. Fitting Non-Stationary Extreme Attack Rates

We use Algorithm 2 to select the best ﬁtting model for the
non-stationary extreme attack rates, where quantileSet is the
same as in Algorithm 1. We use the AIC (Akaike Information
Criterion) statistic [26] and QQ-plot to evaluate the goodness-
of-ﬁt, where AIC reﬂects the ﬁtting loss (i.e., the smaller the
AIC value, the better the ﬁtting). As a rule of thumb, two AIC
values are considered fairly close when their difference is less
than 10. If a model Mj ∈ {M2, M3, M4} incurs the minimum
AIC value that is not fairly close to any of the other two
models’ AIC values, we choose Mj as the best ﬁtting model;
otherwise, we choose the simpler/simplest model whose AIC
value is fairly close to the minimum AIC value (note that
model M2 is considered simpler than M3, which is simpler
than M4).

Table II summarizes the ﬁtting results. The AIC values of
these three models for Periods I and II are fairly close, and
thus we choose the simpler model M2. Since the AIC value
of M2 in Period IV is the smallest, we choose M2 as the best

Algorithm 2 Fitting non-stationary extreme attack rates
INPUT: attack-rate time series whose extreme values cannot
be ﬁtted by M1
OUTPUT: ﬁtting result

1: initialize quantileSet {same as in Algorithm 1}
2: for q ∈ quantileSet (from the minimum to the maximum

in increasing order) do

3:

4:
5:
6:

use models M2, M3 and M4 to ﬁt the attack rates that
are greater than threshold quantile q
evaluate goodness-of-ﬁt via AIC and QQ-plot
if any of the three models ﬁts well then

choose the model with the minimum AIC value, or
choose the simpler/simplest model whose AIC value
is fairly close to the minimum AIC value
return (q, AIC value) of the selected model Mj

7:
end if
8:
9: end for
10: return -1 {failed in ﬁtting extreme attack rates}

ﬁtting model for Period IV. For Period IV, models M3 and M4
have smaller AIC values that are fairly close to each other, and
therefore we choose M3 as the best ﬁtting model.

Period
I
II
IV

q
85%
80%
80%

# of EV M2 M3 M4
3656
1776
2016

3653
1774
2014

3656
1774
1774

168
84
105

QQ-plot model
M2
M2
M2

√
√
√

Table II
EVT-BASED FITTING OF NON-STATIONARY EXTREME ATTACK RATES,
WHERE COLUMN Mj (2 ≤ j ≤ 4) REPRESENTS THE AIC VALUE OF

MODEL Mj , “

” INDICATES THAT QQ-PLOT CONFIRMS FITTING WELL

√

(QQ-PLOTS ARE OMITTED FOR SAVING SPACE), AND THE OTHER
NOTATIONS ARE THE SAME AS IN TABLE I.

V. TST-BASED EXTREME-VALUE ANALYSIS

Now we study how TST-based models can ﬁt the extreme
values. Since the attack-rate time series exhibit
the LRD
phenomenon [1] and the extreme-value phenomenon, we need
models that can accommodate both. Since the GARCH model
can accommodate the extreme-value phenomenon [24] and the
FARIMA model can accommodate LRD, we propose to use
the following FARIMA+GARCH model:

φ(B)(1 − B)d(yt − µt) = ψ(B)(cid:15)t,

where parameters φ and ψ are the same as reviewed in Section
II-B2, B is the lag operator, (1 − B)d is the LRD process
with Hurst parameter H satisfying 0 < d = H − .5 < 1,
and µt = µ + ξσt such that the variance σt follows either
the SGARCH (i.e., Standard GARCH) or the IGARCH (i.e.,
Integrated GARCH) with noise distribution SSTD or SGED
(as reviewed in Section II-B2). This actually leads to a family
of FARIMA+GARCH models:

• M (cid:48)
• M (cid:48)
• M (cid:48)
• M (cid:48)

1: FARIMA+SGARCH+SSTD;
2: FARIMA+SGARCH+SGED;
3: FARIMA+IGARCH+SSTD;
4: FARIMA+IGARCH+SGED.

6

For comparison, we also consider the gray-box FARIMA
model, which can accommodate the LRD phenomenon but
not the extreme-value phenomenon. Recall that FARIMA can
predict the time series more accurately than the LRD-less (i.e.
black-box) ARMA model [1]. To select the best ﬁtting model,
we use two model selection criteria: PMAD (Percent Mean
Absolute Deviation) and AIC. To select the best prediction
model, we use PMAD. Suppose Xm, . . . , Xh are the observed
attack rates and X (cid:48)
h are the ﬁtted (predicted) attack
rates. We have PMAD = (cid:80)m+h
t|/ (cid:80)m+h
t=m |Xt−X (cid:48)
t=m Xt, which
captures the overall ﬁtting (prediction) error. Note that the
smaller the PMAD value, the better the ﬁtting (prediction).

m, . . . , X (cid:48)

Figure 3 plots

the ﬁtting results. We observe that
FARIMA+GARCH can indeed ﬁt
the data, especially the
extreme attack rates, better than FARIMA. For Periods I-
III, we observe that
the inaccuracy of FARIMA+GARCH
is mainly because the extreme values (i.e., spikes) are not
ﬁtted 100%. For Period IV, Figure 3(d) visually shows that
FARIMA+GARCH ﬁts the data well. However, the visual
effect is misleading (meaning that purely visual analysis is
not always reliable) because there is some signiﬁcant ﬁtting
error (as shown in Table III below). Again, this is caused by
the incapability in ﬁtting extreme attack rates. For Period V,
FARIMA+GARCH clearly cannot ﬁt the data well, possibly
because there exist some complex statistical patterns that
change rapidly. We are not aware of any statistical tools that
can cope with such time series, but expect to develop some
advanced tools for this purpose in the future.

Table III summarizes the ﬁtting results. For Periods I-
III, we observe that FARIMA+GARCH has smaller AIC
values as well as smaller PMAD values (all < 0.2). For
Periods IV-V, FARIMA+GARCH still has smaller PMAD
and AIC values, but the PMAD values are greater than 0.3.
Therefore, FARIMA+GARCH can ﬁt Periods I-III better than
FARIMA, but not well enough for Periods IV-V (although
FARIMA+GARCH ﬁts these two periods more accurately than
FARIMA).

Period

FARIMA + GARCH

FARIMA

model
M (cid:48)
1
M (cid:48)
1
M (cid:48)
3
M (cid:48)
3
M (cid:48)
4

PMAD AIC PMAD AIC
11.8
11.9
11.3
10.7
12.0

0.192
0.195
0.239
0.439
0.482

0.170
0.185
0.196
0.363
0.441

11.0
11.4
10.7
9.6
11.8

I
II
III
IV
V

Table III
TST-BASED FITTING OF ATTACK RATES (PER HOUR). GRAY-BOX
FARIMA+GARCH MODELS CAN CONSISTENTLY FIT PERIODS I-III
WELL, AND ALWAYS FIT BETTER THAN GRAY-BOX FARIMA MODELS.

VI. PREDICTION ANALYSIS

A. Gray-Box vs. Black-Box Prediction Accuracy

In order

to show the power of gray-box prediction,
we compare (i) the prediction accuracies of the gray-box
FARIMA+GARCH models mentioned above (all of these
models are considered, rather than the best ﬁtting models
only, because the best ﬁtting models may not always offer
the best predictions), (ii) the prediction accuracies of gray-box

7

(a) Period I

(b) Period II

(c) Period III

(d) Period IV

(e) Period V

(f) Period I

(g) Period II

(h) Period III

(i) Period IV

(j) Period V

Figure 3. TST-based model ﬁtting where black-colored circles represent
the ﬁtted values.
FARIMA+GARCH ﬁts Periods I-III better than FARIMA (especially for the extreme attack rates), but cannot ﬁt Periods IV-V well (although FARIMA+GARCH
ﬁts more accurately than FARIMA).

the observed attack rates and red-colored dots represent

FARIMA models that can accommodate the LRD phenomenon
but not the extreme-value phenomenon, (iii) the prediction
accuracies of black-box Hidden Markov Models [28] (which
are reviewed in Section II-B3), and (iv) prediction accuracy of
black-box Symbolic Dynamics (SD) models [29] (which are
reviewed in Section II-B4).

a) FARIMA+GARCH vs. FARIMA: Recall

that Table
III shows that the gray-box FARIMA+GARCH models offer
more accurate ﬁttings than gray-box FARIMA models. Now
we investigate to what extent FARIMA+GARCH can predict
more accurately than FARIMA. Algorithm 3 describes the
FARIMA+GARCH prediction algorithm, where the best pre-
diction model M (cid:48)
1, . . . , M (cid:48)
4} is selected, and the last
120 hours are used for h-hour ahead-of-time prediction (which
is consistent with the FARIMA-based prediction in [1]).

j ∈ {M (cid:48)

Algorithm 3 FARIMA+GARCH-based prediction of attack
rates
INPUT: attack-rate time series {X1, . . . , Xn}, FARIMA-
1, M (cid:48)
GARCH model family {M (cid:48)
4}, 0 < (cid:96) < 1, h
(the number of hours ahead-of-time prediction)
OUTPUT: best prediction model M (cid:48) ∈ {M (cid:48)

3, M (cid:48)

2, M (cid:48)

1, . . . , M (cid:48)
4}

while m + h ≤ n do

1: for i = 1 to 4 do
2: m = (cid:98)n(cid:96)(cid:99), j = 0
3:
4:
5:
6:
7:

use {X1, . . . , Xm} to ﬁt a M (cid:48)
use M (cid:48)
m = m + h

i to predict attack rates {X (cid:48)

end while
evaluate PMAD value of the predictions

8:
9: end for
10: return M (cid:48) ∈ {M (cid:48)

PMAD values

i -type model

m+1, . . . , X (cid:48)

m+h}

1, M (cid:48)

2, M (cid:48)

3, M (cid:48)

4} with the smallest

Table IV summarizes the prediction results of the best
prediction models. We observe that for Periods I-III, 1-hour
ahead-of-time predictions (i.e., h = 1) lead to the highest
prediction accuracy (at least 86%). Recall that FARIMA-based
1-hour ahead-of-time predictions for Periods I-V have PMAD
values 0.179 (error: 17.9%), 0.217 (error: 21.7%), 0.298
(error: 29.8%), 0.548 (error: 54.8%), and 0.517 (error: 51.7%),
respectively [1]. This shows that gray-box FARIMA+GARCH
models can lead to an extra prediction accuracy of 4.1%,
9.6%, 15.8%, 20.9%, and 13.9%, respectively. We note that
predictions for Periods IV and V are substantially less accurate
than predictions for Periods I-III, because their prediction
errors are 33.9% and 37.8% respectively. We suspect this
discrepancy is caused by the data corresponding to Peri-
ods IV and V having some complex statistical properties
(other than LRD and extreme values), which are left for
future investigations. To summarize the above discussion,
we conclude that FARIMA+GARCH-based 1-hour ahead-of-
time predictions offer the best accuracy, and we will use
FARIMA+GARCH for comparison with HMM-based and SD-
based predictions.

Period

I
II
III
IV
V

(cid:96)

0.90
0.70
0.90
0.80
0.95

Selected Model
M (cid:48)
3
M (cid:48)
4
M (cid:48)
3
M (cid:48)
3
M (cid:48)
3

h=1H
0.138
0.121
0.140
0.339
0.378

PMAD

h=4H
0.172
0.343
0.276
0.409
0.388

h=7H
0.255
0.390
0.316
0.535
0.470

h=10H
0.300
0.386
0.282
1.152
0.288

Table IV
ERRORS OF THE GRAY-BOX FARIMA+GARCH MODELS FOR PREDICTING
THE ATTACK RATE h-HOUR AHEAD-OF-TIME: PERIODS I-III CAN BE
PREDICTED ACCURATELY 1-HOUR AHEAD-OF-TIME.

b) FARIMA+GARCH vs. HMM (Hidden Markov Model):
Algorithm 4 describes the HMM-based prediction algorithm

with i hidden states for h-hour ahead-of-time predictions.
The best prediction model is selected among the choices of
different numbers of hidden states (i.e., the number of hidden
states that leads to the smallest PMAD value is selected). To
be speciﬁc, we consider i ∈ {2, 3, . . . , 10} hidden states.

Algorithm 4 HMM-based predictions of attack rates
INPUT: Extreme attack rates {X1, . . . , Xn}; number of hid-
den states i ∈ {2, 3, . . . , 10}; 0 < (cid:96) < 1, h (# of hours ahead-
of-time prediction)
OUTPUT: best prediction model with i hidden states

while m + h ≤ n do

use {X1, . . . , Xm} to ﬁt a model of i hidden state
use the ﬁtted model to predict {X (cid:48)
m+h}
m = m + h

1: for i = 2 to 10 do
2: m = (cid:98)n(cid:96)(cid:99)
3:
4:
5:
6:
7:
8:
9: end for
10: return i ∈ {2, 3, . . . , 10} with the smallest PMAD values

end while
evaluate PMAD value of the predictions

m+1, . . . , X (cid:48)

Table V compares HMM-based predictions of the last
120 hours of attack rates with that of FARIMA+GARCH-
based predictions, where h = 1, 4, 7, 10. In most scenar-
ios, FARIMA+GARCH-based predictions are substantially
more accurate than HMM-based predictions. For Periods I-
III and h = 1, FARIMA+GARCH-based predictions are
respectively 0.8%, 11.0%, and 11.4% more accurate than
HMM-based predictions. For Periods IV-V and h = 1,
FARIMA+GARCH-based predictions are respectively 21.2%
and 2.8% more accurate than HMM-based predictions. Despite
that FARIMA+GARCH cannot predict Periods IV-V well, this
model inadequacy does not invalidate the gray-box prediction
methodology. Instead,
this suggests that we need to use
even more sophisticated models to accommodate the complex
properties/phenomena exhibited by the Periods IV-V data.

Period

I
II
III
IV
V

PMAD
h=1H h=4H h=7H h=10H
0.191
0.146
0.349
0.231
0.427
0.254
1.456
0.551
0.607
0.406

0.193
0.342
0.379
0.872
0.531
Table V
ERRORS OF HMM-BASED h-HOUR AHEAD-OF-TIME PREDICTIONS: FOR
1-HOUR AHEAD-OF-TIME PREDICTION (WHICH IS THE CASE WE
RECOMMEND FOR PRACTICAL USE), HMM PREDICTIONS ARE
SUBSTANTIALLY LESS ACCURATE THAN FARIMA+GARCH
PREDICTIONS.

0.189
0.371
0.401
1.159
0.577

c) FARIMA+GARCH vs. SD (Symbolic Dynamics)
model: The ﬁrst step in using SD models is to transform
attack rates into symbols. For this purpose, we partition
the attack rate range into ﬁve intervals in terms of quan-
tiles, namely [0, 80% quantile], (80% quantile, 85% quantile],
(85% quantile, 90% quantile],
(90% quantile, 95% quantile],
and (95% quantile, 100% quantile]. These are represented as
symbols 1, 2, 3, 4 and 5, respectively. We consider the attack

8

rates that are no greater than the 80% quantile as a single
interval because we are analyzing the extreme attack rates.
For comparison purposes, the time resolution of the resulting
symbolic time series is also an hour. In order to predict
the time series of symbols, we consider two models: one is
the aforementioned HMM, and the other is the Conditional
Random Field (CRF) model that selects symbols based on
the maximum conditional probability [38]. Because SD-based
predictions are also symbols, we need to map the predictions
back into numerical attack rates. Since each symbol corre-
sponds to an interval, we consider three mappings: (i) min-
based mapping, in which case a symbol is mapped to the
minimal value in the corresponding interval, (ii) mean-based
mapping, in which case a symbol is mapped to the mean value
in the corresponding interval, and (iii) max-based mapping,
in which case a symbol is mapped to the maximum value in
the corresponding interval.

Algorithm 5 SD-based predictions of attack rates
INPUT: Symbolic time series {Z1, . . . , Zn}, number of hidden
states i ∈ {2, 3, . . . , 10}, 0 < (cid:96) < 1, h (h-hour ahead-of-time
prediction)
OUTPUT: best prediction models

1: for i = 2 to 10 do
2: m = (cid:98)n(cid:96)(cid:99)
3:
4:

while m + h ≤ n do

5:

6:

7:

use {Z1, . . . , Zm} to ﬁt a HMM model of i hidden
states
use {Z1, . . . , Zm} to ﬁt a CRF model of i hidden
states
use the ﬁtted HMM model
{Z (cid:48)
use the ﬁtted CRF model
{Z (cid:48)
m = m + h

to predict symbols

m+1, . . . , Z (cid:48)

m+1, . . . , Z (cid:48)

to predict

symbols

m+h}

m+h}

end while
evaluate PMAD value of the predictions

8:
9:
10:
11: end for
12: return the best HMM model (i.e., the one with the
smallest PMAD value among the HMM models), and the
best CRF model (i.e., the one with the smallest PMAD
values among the CRF models)

Algorithm 5 is the SD-based prediction algorithm, where
h = 1 (i.e., 1-hour ahead-of-time prediction) and we also
use the last 120 hours of each period for prediction as in
the preceding prediction algorithms (i.e., the (cid:96) is calculated
correspondingly).

Table VI describes the PMAD-values of SD-based 1-hour
ahead-of-time predictions. We observe that mean-based map-
ping from symbols to numerical values offers relatively more
accurate predictions than min- and max-based mappings. We
also observe that for mean-based mapping, HMM and CRF
perform almost the same. However, neither HMM nor CRF
provides accurate prediction in the SD framework (recall that
HMM alone can achieve a certain degree of accuracy, although
not as accurately as FARIMA+GARCH). Therefore, SD is not
appropriate for predicting attack rates. The fundamental reason

CRF cannot predict well in this setting is that the data in
question is univariate. Despite the inaccuracy of SD, we keep
these results for the sake of completeness.

Period

PMAD
min- mean- max- min- mean- max-

I
II
III
IV
V

0.754
0.754
0.635
0.775
0.920

HMM (best model)
0.457
0.336
0.309
0.553
0.528

0.613
0.375
0.367
0.808
0.754
Table VI
ERRORS OF SD-BASED 1-HOUR AHEAD-OF-TIME PREDICTIONS: THE
PREDICTIONS ARE INACCURATE AND DESCRIBED HERE FOR
COMPLETENESS.

CRF (best model)
0.457
0.364
0.316
0.553
0.528

0.754
0.591
0.629
0.775
0.920

0.613
0.404
0.369
0.808
0.754

d) Summary: Based on the above discussion, we con-
clude that gray-box FARIMA+GARCH models, which can
accommodate both the LRD phenomenon and the extreme-
value phenomenon, can predict attack rates 1-hour ahead-
of-time at an accuracy that is substantially greater than that
of gray-box FARIMA models, which can accommodate the
LRD phenomenon but not the extreme-value phenomenon.
Moreover, gray-box FARIMA+GARCH predictions are sub-
stantially more accurate than HMM predictions, and are far
more accurate than SD predictions. Therefore, we will com-
pare FARIMA+GARCH predictions to EVT-based predictions
of expected magnitude of extreme attack rates.

B. EVT-based prediction of extreme attack rates

We use EVT-based methods to predict the return level,
namely the expected magnitude of extreme attack rates within
a future period of time (but not necessarily the expected
maximum attack rate). We use Algorithm 6 to predict return
levels for the return period of h hours (i.e., h-hour ahead-of-
time predictions). Since EVT-based predictions only deal with
extreme values, we cannot use PMAD to measure prediction
errors. Instead, we use the binomial test [39] to measure the
prediction accuracy. A p-value greater than .05 indicates that a
prediction is accurate. For comparison purposes, we set h = 24
and use the last 120 hours in each period for prediction (i.e.,
(cid:96) is chosen such that m = (cid:98)n(cid:96)(cid:99) = n − 120).

C. Making use of EVT- and TST-based predictions

Table VII reports EVT-based predictions of return levels
as well as the corresponding p-values of the binomial test, the
observed maximum attack rates, and the TST-based predictions
of maximum attack rates (more precisely, FARIMA+GARCH
predictions) as well as the corresponding PMAD values. We
make the following observations.

First, EVT-based best prediction models (corresponding to
the ﬁrst row of each period in Table VII) are respectively
simpler than the best EVT-based ﬁtting models (described in
Tables I-II). This means that the best ﬁtting models are not
necessarily the best prediction models. On the other hand,
TST-based best prediction models (corresponding to the third
row in each period in Table VII) are respectively the same as
the TST-based best ﬁtting models (described in Table IV).

9

Algorithm 6 EVT-based prediction of return levels
INPUT: extreme attack rates {X1, . . . , Xn} with respect to
threshold quantiles described in Tables I-II, EVT model family
{M1, M2, M3, M4} described in Section IV, 0 < (cid:96) < 1, h (#
of hours as return period)
OUTPUT:
prediction
{M1, M2, M3, M4}

model

Mj

∈

1: m = (cid:98)n(cid:96)(cid:99)
2: for i = 1 to 4 do
3:
4:

while m + h ≤ n do

5:

Using {X1, . . . , Xm} to ﬁt the Mi-type model
Use Mi to predict the return level between the (m +
1)th and the (m + h)th hours
m = m + h

end while
Evaluate prediction accuracy using the binomial test

6:
7:
8:
9: end for
10: return Mj ∈ {M1, M2, M3, M4} with the highest p-

value (or simpler model with the same p-value)

Per.

H1-24

H25-48

H49-72

H73-96

H97-120

p or
PMAD
0.07

I

II

V

III

IV

0.18
0.07

0.13
0.17

0.21
0.01

82275
82576
71719
60752
60274
51853
32654
29722
27921
30514
8225
5605
45996
109216
55007

78333
62868
58183
62750
38218
37267
32733
92379
77747
30048
6263
5341
43526
120221
54644

76056
53197
50656
60910
83157
72457
33263
32993
30869
29747
23224
20329
40129
101971
40341

76824
60203
53744
60668
101937
83073
32916
30194
28505
29622
11671
9443
41265
105171
43581

77088
57370
52427
63572
45186
43942
32836
21476
21382
28622
6634
6674
42360
114462
50053
Table VII
COMPARISON BETWEEN EVT- AND TST-BASED PREDICTIONS, WHERE
“Ha-b” MEANS THE PREDICTIONS CORRESPOND TO TIME INTERVAL
BETWEEN THE aTH AND THE bTH HOURS (AMONG THE LAST 120 HOURS
OF EACH PERIOD). FOR EACH PERIOD, THERE ARE THREE ROWS. THE
FIRST ROW REPRESENTS EVT-BASED PREDICTIONS OF RETURN LEVELS
(I.E., EXPECTED MAGNITUDE OF EXTREME ATTACK RATES) AND THE
CORRESPONDING p-VALUE OF THE PREDICTIONS, WHERE THE
PREDICTION MODEL IS SELECTED BY ALGORITHM 6. THE SECOND ROW
DESCRIBES THE OBSERVED (I.E., ACTUAL) MAXIMUM ATTACK RATES.
THE THIRD ROW DESCRIBES THE MAXIMUM ATTACK RATES DERIVED
FROM THE TST-BASED PREDICTIONS OF ATTACK RATES MADE BY THE
FARIMA+GARCH MODEL SELECTED BY ALGORITHM 3 WITH h = 1
AND THE CORRESPONDING PMAD VALUE.

0.40
0.00

0.41

Second, we observe a consistency between the predictions
of these two approaches. Speciﬁcally, EVT-based predictions
of return levels (i.e., expected magnitude of extreme attack
rates) are accurate for Periods I-III because their p-values
are greater than 0.05, while TST-based predictions of the
maximum attack rates are also accurate for Periods I-III
because their PMAD values are smaller than or equal to 0.22.
On the other hand, EVT-based predictions of return levels
are not accurate for Periods IV-V because their p-values are
smaller than 0.02, and TST-based predictions of the maximum
attack rates are not accurate for Periods IV-V because their

PMAD values are greater than or equal to 0.40. However,
there is a signiﬁcant difference between Periods IV and V.
For Period IV, we observe that TST-based predictions of
the maximum attack rates are actually accurate with respect
to the observed maximum attack rates. This suggests that
although TST-based predictions are not accurate overall, their
predictions of the maximum attack rates can be accurate. This
is useful because the predicted maximum attack rates can be
the most important factor for the defender’s decision-making
for resource allocation. Unfortunately, TST-based predictions
of the maximum attack rates are not accurate for Period V. This
may be caused by some complex time series patterns, such as
cyclical trends or seasonal trends (i.e., some repeated patterns).
We leave the settlement of this issue to future investigations.
Third, for Periods I-III where both EVT and TST provide
overall accurate predictions, we observe that EVT-based pre-
dictions of return levels, which are given to the defender
24 hours ahead-of-time, can be used as an evidence for
resource allocation. Moreover, EVT-based resource allocations
could be dynamically adjusted by taking into account TST-
based 1-hour ahead-of-time predictions. Speciﬁcally, Figure
4 suggests the following: when TST-based prediction of the
maximum attack rate (which is obtained only 1 hour ahead-
of-time) is above EVT-based prediction of the return level
(which is obtained 24 hours ahead-of-time),
the defender
can dynamically allocate further resources for the anticipated
attack rate predicted by TST-based methods (e.g., the highest
spike in Periods II-III as shown in Figure 4). Clearly, this
strategy is conservative because it (on average) overprovisions
resources to cope with the worst-case scenario (i.e., matching
the highest attack rate). Nevertheless, this strategy gives the
defender more early-warning time. An alternative strategy
is to use TST-based prediction of the maximum attack rate
as the initial evidence for allocating defense resources, then
take into consideration EVT-based long-term predictions (e.g.,
some weighted average). This strategy might prevent resource
overprovisioning, but may not provision sufﬁcient resources
for coping with the highest attack rate (e.g., the highest spike
in Period III as shown in Figure 4). This strategy requires the
defender to be more agile (than in the preceding strategy).

VII. LIMITATIONS AND FUTURE RESEARCH DIRECTIONS

The present study has the following limitations, which
nevertheless suggest directions for future research. First, the
analysis results are limited by the data, but are sufﬁcient for
justifying the value of the gray-box prediction methodology
and the newly introduced family of FARIMA+GARCH mod-
els. Indeed, gray-box FARIMA+GARCH predictions are sub-
stantially more accurate than gray-box FARIMA predictions,
which in turn are much more accurate than black-box ARMA
predictions [1]. The analysis methodology can be equally
applied to analyze other data sets of a similar kind.

Second, we observe that EVT-based predictions of return
levels are often above the actual maximum attack rates, but
TST-based predictions of the maximum attack rates are often
below the actual maximum attack rates. This connection be-
tween EVT and TST is just a good starting point. For example,

10

it may be possible to use some weighted average of EVT-
based predictions of return levels and TST-based predictions of
maximum attack rates as the predicted maximum attack rate.
These heuristics needs to be justiﬁed rigorously. Moreover,
there might be some deeper connections that can be exploited
to formulate more powerful prediction techniques. Finally,
there may be some fundamental trade-off between the early-
warning time we can give to the defender and the prediction
accuracy we can expect. These connections have not be
investigated by the theoretical statistics community, and our
engineering-driven demand might give theoretical statisticians
enough motivation to explore this exciting topic.

Third, Periods IV and V cannot be predicated accurately,
possibly because there exist some properties other than LRD
and extreme values. Further studies are needed in order to
determine, for example, if there are some seasonal or cyclical
trends, and/or if the extreme values are generated by some
self-exciting process [40].

VIII. CONCLUSIONS

We have presented a novel methodology for analyzing the
extreme-value phenomenon exhibited by cyber attack data.
The analysis methodology utilizes a novel integration of EVT
and TST, and aims to predict attack rates more accurately
by accommodating the extreme-value phenomenon. We have
presented gray-box FARIMA+GARCH models, which can
accommodate both the LRD phenomenon and the extreme-
value phenomenon that are exhibited by the data, and can
predict attack rates 1-hour ahead-of-time at an accuracy that
can be deemed practical. We believe that this study will inspire
an exciting research sub-ﬁeld, including the adequate treatment
of the open problems mentioned above.
Acknowledgement. We thank the reviewers for their construc-
tive comments that helped us improve the paper, including the
comparison of FARIMA+GARCH-based predictions to HMM-
based and SD-based predictions. We thank the associate editor,
Professor Wanlei Zhou, for his constructive comments. We
thank Marcus Pendleton and Paul Parker for proofreading the
paper.

This study was IRB-approved. This work was supported
in part by ARO Grant #W911NF-13-1-0141. Any opinions,
ﬁndings, and conclusions or recommendations expressed in
this material are those of the author(s) and do not necessarily
reﬂect the views of the funding agencies.

REFERENCES

[1] Z. Zhan, M. Xu, and S. Xu, “Characterizing honeypot-captured cyber
attacks: Statistical framework and case study,” IEEE Transactions on
Information Forensics and Security, vol. 8, no. 11, pp. 1775–1789, 2013.
[2] R. Sommer and V. Paxson, “Outside the closed world: On using machine
learning for network intrusion detection,” in Proceedings of the 2010
IEEE Symposium on Security and Privacy, pp. 305–316, 2010.

[3] S. Almotairi, A. Clark, G. Mohay, and J. Zimmermann, “A technique
for detecting new attacks in low-interaction honeypot trafﬁc,” in Proc.
International Conference on Internet Monitoring and Protection, pp. 7–
13, 2009.

[4] O. Thonnard and M. Dacier, “A framework for attack patterns’ discovery
in honeynet data,” Digital Investigation, vol. 5, pp. S128–S139, 2008.
[5] F. Pouget and M. Dacier, “Honeypot-based forensics,” in AusCERT2004,
AusCERT Asia Paciﬁc Information technology Security Conference, 05
2004.

11

(a) Period I

(b) Period II

(c) Period III

(d) Period IV

(e) Period V

Figure 4. Comparing EVT-based predictions of return levels (i.e., expected magnitudes of extreme attack rates), observed attack rates during the last 120
hours in each period, and TST-based predictions of attack rates. EVT-based predictions of return levels are produced by Algorithm 6 and summarized in
Table VII, and plotted as horizontal lines during the respective intervals of 24 hours. TST-based predictions are produced by Algorithm 3. For Periods I-III,
EVT-based predictions of return levels are accurate, and TST-based predictions of attack rates as well as the maximum attack rates are also accurate. For
Period IV, EVT-based predictions of extreme attack rates are about one order of magnitude above the observed attack rates, but TST-based predictions of
maximum attack rates are accurate. For Period V, neither EVT nor TST can predict accurately.

[6] S. I. Almotairi, A. J. Clark, M. Dacier, C. Leita, G. M. Mohay, V. H.
Pham, O. Thonnard, and J. Zimmermann, “Extracting inter-arrival time
based behaviour from honeypot trafﬁc using cliques,” in 5th Australian
Digital Forensics Conference, pp. 79–87, 2007.

[7] G. Conti and K. Abdullah, “Passive visual ﬁngerprinting of network
attack tools,” in Proceedings of the 2004 ACM workshop on Visualization
and data mining for computer security, pp. 45–54, 2004.

[8] S. I. Almotairi, A. J. Clark, G. M. Mohay, and J. Zimmermann, “Char-
acterization of attackers’ activities in honeypot trafﬁc using principal
component analysis,” in Proc. IFIP International Conference on Network
and Parallel Computing, pp. 147–154, 2008.

[9] A. Clark, M. Dacier, G. Mohay, F. Pouget, and J. Zimmermann, “Internet
attack knowledge discovery via clusters and cliques of attack traces,”
Journal of Information Assurance and Security, vol. 1, no. 1, pp. 21–
32, 2006.

[10] Z. Li, A. Goyal, Y. Chen, and V. Paxson, “Towards situational aware-
ness of large-scale botnet probing events,” Information Forensics and
Security, IEEE Transactions on, vol. 6, pp. 175–188, march 2011.
[11] M.-S. Kim, H.-J. Kang, S.-C. Hong, S.-H. Chung, and J. W. Hong, “A
ﬂow-based method for abnormal network trafﬁc detection,” in NOMS
(1)’04, pp. 599–612, 2004.

[12] Y. Gao, Z. Li, and Y. Chen, “A dos resilient ﬂow-level intrusion de-
tection approach for high-speed networks,” in Proc. IEEE International
Conference on Distributed Computing Systems (ICDCS’06), pp. 39–,
2006.

[13] F. Dressler, W. Jaegers, and R. German, “Flow-based worm detection
using correlated honeypot logs,” Communication in Distributed Systems
(KiVS), 2007 ITG-GI Conference, pp. 1–6, 2007.

[14] T. Dubendorfer and B. Plattner, “Host behaviour based early detection
of worm outbreaks in internet backbones,” in Proc. IEEE International
Workshops on Enabling Technologies: Infrastructure for Collaborative
Enterprise, pp. 166–171, 2005.

[15] W. T. Strayer, D. Lapsely, R. Walsh, and C. Livadas, “Botnet detection

based on network behavior,” vol. 36, pp. 1–24, 2008.

[16] C. Livadas, R. Walsh, D. Lapsley, and W. T. Strayer, “Using machine
trafﬁc,” in Proc. IEEE LCN

learning techniques to identify botnet
Workshop on Network Security (WoNS’2006), pp. 967–974, 2006.
[17] A. Ghourabi, T. Abbes, and A. Bouhoula, “Data analyzer based on data
mining for honeypot router,” in Computer Systems and Applications
(AICCSA), 2010 IEEE/ACS International Conference on, pp. 1–6, 2010.
traces forensics by means of attack event

[18] V. H. Pham, Honeypot

identiﬁcation. PhD thesis, Thesis, 09 2009.

[19] M. V. Mahoney and P. K. Chan, “Learning nonstationary models of
normal network trafﬁc for detecting novel attacks,” in Proc. 8th ACM
SIGKDD international conference on Knowledge discovery and data
mining (KDD’02), pp. 376–385, 2002.

[20] R. Pang, V. Yegneswaran, P. Barford, V. Paxson, and L. L. Peterson,
“Characteristics of internet background radiation,” in Internet Measure-
ment Conference, pp. 27–40, 2004.

[21] E. Wustrow, M. Karir, M. Bailey, F. Jahanian, and G. Huston, “Internet
background radiation revisited,” in Proceedings of the 10th ACM SIG-
COMM conference on Internet measurement, IMC’10, (New York, NY,
USA), pp. 62–74, ACM, 2010.

[22] E. Glatz and X. A. Dimitropoulos, “Classifying internet one-way trafﬁc,”

in Internet Measurement Conference, pp. 37–50, 2012.

[23] Z. Zhan, M. Xu, and S. Xu, “A characterization of cybersecurity
posture from network telescope data,” in Proc. of the 6th Interna-

tional Conference on Trustworthy Systems (InTrust’14), available at
http:// www.cs.utsa.edu/ ∼shxu/ socs/ intrust14.pdf , 2014.

[24] P. Embrechts, C. Kluppelberg, and T. Mikosch, Modelling Extremal

Events for Insurance and Finance. Springer, Berlin, 1997.

[25] S. Resnick, Heavy-Tail Phenomena: Probabilistic and Statistical Mod-

eling. Springer, 2007.

[26] J. D. Cryer and K.-S. Chan, Time Series Analysis With Applications in

R. New York: Springer, 2008.

[27] T. Bollerslev, J. Russell, and M. W. Watson, Volatility and Time Series
Econometrics: Essays in Honor of Robert Engle. Oxford University
Press, 2010.

[28] W. Zucchini and I. L. MacDonald, Hidden Markov models for time

series: an introduction using R. CRC Press, 2009.

[29] J. Lin, E. Keogh, S. Lonardi, and B. Chiu, “A symbolic representation of
time series, with implications for streaming algorithms,” in Proceedings
of the 8th ACM SIGMOD workshop on Research issues in data mining
and knowledge discovery, pp. 2–11, ACM, 2003.

[30] N. Provos, “A virtual honeypot framework,” in Proceedings of the 13th
Conference on USENIX Security Symposium - Volume 13, SSYM’04,
(Berkeley, CA, USA), pp. 1–1, USENIX Association, 2004.

[31] L. Spitzner, “The honeynet project:

trapping the hackers,” Security

Privacy, IEEE, vol. 1, pp. 15–23, Mar 2003.

[32] “http : //amunhoney.sourcef orge.net/.”
[33] “http : //dionaea.carnivore.it/.”
[34] “https : //alliance.mwcollect.org/.”
[35] P. Baecher, M. Koetter, M. Dornseif, and F. Freiling, “The nepenthes
platform: An efﬁcient approach to collect malware,” in In Proceedings
of the 9 th International Symposium on Recent Advances in Intrusion
Detection (RAID), pp. 165–184, 2006.

[36] S. Almotairi, A. Clark, G. Mohay, and J. Zimmermann, “Characteriza-
tion of attackers’ activities in honeypot trafﬁc using principal component
analysis,” in Proceedings of the 2008 IFIP International Conference on
Network and Parallel Computing, pp. 147–154, 2008.

[37] V. Choulakian and M. Stephens, “Goodness-of-ﬁt tests for the general-

ized pareto distribution,” Technometrics, vol. 43, pp. 478–484, 2001.

[38] J. Lafferty, A. McCallum, and F. C. Pereira, “Conditional random ﬁelds:
Probabilistic models for segmenting and labeling sequence data,” 2001.
[39] A. J. McNeil and R. Frey, “Estimation of tail-related risk measures
for heteroscedastic ﬁnancial time series: an extreme value approach,”
Journal of empirical ﬁnance, vol. 7, no. 3, pp. 271–300, 2000.

[40] A. J. McNeil, R. Frey, and P. Embrechts, Quantitative risk management:
concepts, techniques, and tools. Princeton university press, 2010.

Zhenxin Zhan recently received his
PhD in cyber security from the Depart-
ment of Computer Science, University
of Texas at San Antonio. He received
M.S. degree in Computer Science from
the Huazhong University of Science and
in 2008. His pri-
Technology, China,
mary research interests are in cyber attack analysis and de-
tection.

Maochao Xu is an assistant profes-
sor of Mathematics at the Illinois State

12

University. He received his PH.D.
in
Statistics from Portland State University
in 2010. His research interests include
Applied Statistics, Extreme value the-
ory, Cyber security, and Risk analysis
in actuary and insurance. He currently serves as an associate
editor for Communications in Statistics.

Shouhuai Xu is a full professor in
the Department of Computer Science,
University of Texas at San Antonio. His
research interests include cybersecurity
modeling & analysis (especially, Cyber-
security Dynamics) and applied cryptog-
raphy. He earned his PhD in Computer
Science from Fudan University, China. He is an associate
editor for IEEE TDSC and IEEE T-IFS. More information
about his research can be found at www.cs.utsa.edu/∼shxu.

