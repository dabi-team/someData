0
2
0
2

n
a
J

0
1

]

R
C
.
s
c
[

2
v
4
4
4
2
0
.
8
0
9
1
:
v
i
X
r
a

A Veriﬁed Architecture for Proofs of Execution on Remote Devices under Full
Software Compromise

Ivan De Oliveira Nunes1, Karim Eldefrawy2, Norrathep Rattanavipanon1, and Gene Tsudik1

1University of California, Irvine
2SRI International
{ivanoliv, nrattana, gene.tsudik}@uci.edu, karim.eldefrawy@sri.com

Abstract
Modern society is increasingly surrounded by, and is growing
accustomed to, a wide range of Cyber-Physical Systems (CPS),
Internet-of-Things (IoT), and smart devices. They often per-
form safety-critical functions, e.g., personal medical devices,
automotive CPS as well as industrial and residential automa-
tion (e.g., sensor-alarm combinations). On the lower end of the
scale, these devices are small, cheap and specialized sensors
and/or actuators. They tend to be equipped with small anemic
CPU, have small amounts of memory and run simple software.
If such devices are left unprotected, consequences of forged
sensor readings or ignored actuation commands can be catas-
trophic, particularly, in safety-critical settings. This prompts
the following three questions: (1) How to trust data produced,
or verify that commads were performed, by a simple remote
embedded device?, (2) How to bind these actions/results to
the execution of expected software? and, (3) Can (1) and (2)
be attained even if all software on a device could be modiﬁed
and/or compromised?

In this paper we answer these questions by designing,
showing security of, and formally verifying, VAPE: Veriﬁed
Architecture for Proofs of Execution. To the best of our knowl-
edge, this is the ﬁrst of its kind result for low-end embedded
systems. Our work has a range of applications, especially, to
authenticated sensing and trustworthy actuation, which are in-
creasingly relevant in the context of safety-critical systems.
VAPE architecture is publicly available and our evaluation in-
dicates that it incurs low overhead, affordable even for very
low-end embedded devices, e.g., those based on TI MSP430
or AVR ATmega processors.

1 Introduction

The number and diversity of special-purpose computing de-
vices has been increasing dramatically. This includes all
kinds of embedded devices, cyber-physical systems (CPS) and
Internet-of-Things (IoT) gadgets, utilized in various “smart” or
instrumented settings, such as homes, ofﬁces, factories, auto-
motive systems and public venues. Tasks performed by these
devices are often safety-critical. For example, a typical indus-
trial control system depends on physical measurements (e.g.,
temperature, pressure, humidity, speed) reported by sensors,
and on actions taken by actuators, such as: turning on the A/C,
sounding an alarm, or reducing speed.

A cyber-physical control system is usually composed of mul-
tiple sensors and actuators, at the core of each is a low-cost
micro-controller unit (MCU). Such devices typically run sim-
ple software, often on "bare metal", i.e., with no microkernel
or hypervisor. They tend to be operated by a remote central
control unit. Despite their potential importance to overall sys-
tem functionality, low-end devices are typically designed to
minimize cost, physical size and energy consumption, e.g., TI
MSP430.

Therefore, their architectural security is usually primitive or
non-existent, thus making them vulnerable to malware infesta-
tions and other malicious software modiﬁcations. A compro-
mised MCU can spoof sensed quantities or ignore actuation
commands, leading to potentially catastrophic results. For ex-
ample, in a smart city, large-scale erroneous reports of electric-
ity consumption by smart meters might lead to power outages.
A medical device that returns incorrect values when queried
by a remote physician might result in a wrong drug being pre-
scribed to a patient. A compromised car engine temperature
sensor that reports incorrect (low) readings can lead to unde-
tected overheating and major damage. However, despite very
real risks of remote software compromise, most users believe
that these devices execute expected software and thus perform
their expected function.

In this paper, we argue that Proofs of Execution (PoX) are
both important and necessary for securing low-end MCUs.
Speciﬁcally, we demonstrate in Section 7.3, that PoX schemes
can be used to construct sensors and actuators that “cannot lie”,
even under the assumption of full software compromise. In a
nutshell, a PoX conveys that an untrusted remote (and possibly
compromised) device really executed speciﬁc software, and
all execution results are authenticated and cryptographically
bound to this execution. This functionality is similar to authen-
ticated outputs that can be produced by software execution in
SGX-alike architectures [15, 28]. However, such architectures
are comparatively heavy-weight and unsuitable for low-end
devices.

One key building block in designing PoX schemes is Remote
Attestation (RA). Basically, RA is a means to detect malware
on a remote low-end MCU. It allows a trusted veriﬁer (V rf) to
remotely measure memory contents (or software state) of an
untrusted embedded device (P rv). RA is usually realized as a
2-message challenge-response protocol:

1

 
 
 
 
 
 
1. V rf sends an attestation request containing a challenge
(C hal) to P rv. It might also contain a token derived from
a secret (shared by V rf and P rv) that allows P rv to au-
thenticate V rf.

2. P rv receives the attestation request, authenticates the to-
ken (if present) and computes an authenticated integrity
check over its memory and C hal. The memory region can
be either pre-deﬁned, or explicitly speciﬁed in the request.

3. P rv returns the result to V rf.
4. V rf receives the result, and decides whether it corre-

sponds to a valid memory state.

The authenticated integrity check is typically realized as a Mes-
sage Authentication Code (MAC) computed over P rv memory.
We discuss one concrete RA architecture in Section 3.

Despite major progress and several proposals for RA archi-
tectures with different assumptions and guarantees [6–8, 10, 11,
17,21,22,27,32,36–39,42], RA alone is insufﬁcient to obtain
proofs of execution. RA allows V rf to ascertain integrity of
software residing in P rv attested memory region. However, RA
by itself offers no guarantee that the attested software is ever
executed or that any such execution completes successfully.
Even if the attested software is executed, there is no guarantee
that it has not been modiﬁed (e.g., by malware residing else-
where in memory) in the time between its execution and its
attestation. This phenomenon is well known as the Time-Of-
Check-Time-Of-Use (TOCTOU) problem. Finally, RA does
not guarantee authenticity and integrity of any output produced
by the execution of the attested software.

To bridge this gap, we design and implement VAPE: Veriﬁed
Architecture for Proofs of Execution. In addition to RA, VAPE
allows V rf to request an unforgeable proof that the attested
software executed successfully and (optionally) produced cer-
tain authenticated output. These guarantees hold even in case
of full software compromise on P rv. Our intended contribu-
tions are:
– New security service: we design and implement VAPE for
unforgeable remote proofs of execution (PoX). VAPE is com-
posed with VRASED [17], a formally veriﬁed hybrid RA archi-
tecture. As we discuss in the rest of this paper, obtaining prov-
ably secure PoX requires signiﬁcant architectural support in
addition to a secure RA functionality (see Section 7); Nonethe-
less, we show that VAPE careful design achieves all necessary
properties for secure PoX at fairly low overhead. To the best of
our knowledge, this is the ﬁrst security architecture for proofs
of remote software execution on low-end devices.
– Provable security & implementation veriﬁcation: secure
PoX involves reasoning about several details which can be
easily overlooked. Ensuring that all necessary PoX components
are correctly implemented, composed, and integrated with the
underlying RA functionality is not trivial. In particular, early
RA architectures oversimpliﬁed PoX requirements, leading to
the incorrect conclusion that PoX can be obtained directly from
RA; see Section 2 for examples. In this work, we prove that
VAPE yields a secure PoX architecture. All security properties

expected from VAPE implementation are formally speciﬁed
using Linear Temporal Logic (LTL) and VAPE modules are
veriﬁed to adhere to these properties. We also prove that the
composition of VAPE new modules with a formally veriﬁed
RA architecture (VRASED) implies a concrete deﬁnition of
PoX security.
– Evaluation, publicly available implementation and appli-
cations: VAPE was implemented on a real-world low-end
MCU (TI MSP430) and deployed using commodity FPGAs.
Both design and veriﬁcation are publicly available at [2]. Our
evaluation shows low hardware overhead, affordable even
for low-end MCUs. The implementation is accompanied by
a sample PoX application; see Section 7.3. As a proof of
concept, we use VAPE to construct a trustworthy safety-critical
device, on which malware can not spoof execution results
(e.g., spoof sensed values) without detection.

Targeted Devices & Scope: This work focuses on CPS/IoT
sensors and actuators with relatively low computing power.
These are some of the lowest-end devices based on low-power
single core MCUs with only a few KBytes of program and
data memory. Two prominent examples are: TI MSP430
and Atmel AVR ATmega. These are 8- and 16-bit CPUs,
typically running at 1-16MHz clock frequencies, with ≈ 64
KBytes of addressable memory. SRAM is used as data
memory and its size is normally within 4-16KBytes with
the rest of address space available for program memory.
These devices execute instructions in place (in physical
memory) and have no memory management unit (MMU)
to support virtual memory. Our implementation focuses on
MSP430. This choice is due to public availability of a well-
maintained open-source MSP430 hardware design from Open
Cores [25]. Nevertheless, our machine model and the entire
methodology developed in this paper are applicable to other
low-end MCUs in the same class, such as Atmel AVR ATmega.

Organization: Section 2 discusses related work on remote at-
testation, formal veriﬁcation of security services and control
ﬂow attestation. Section 3 provides some background on au-
tomated veriﬁcation, and VRASEDRA architecture. Section 4
introduces Proofs of Execution (PoX), followed by a realiza-
tion thereof in Section 5, including technical details of VAPE
design, as well as the adversarial model and assumptions. Sec-
tion 6 presents VAPE’s formal veriﬁcation. Next, in Section 7,
we report VAPE’s evaluation results and describe how to use
VAPE to implement authenticated sensing/actuation. Section 8
concludes the paper with a summary of results.

2 Related Work

Remote Attestation (RA)– architectures fall into three cate-
gories: hardware-based, software-based, or hybrid. Hardware-
based [34, 40, 46] relies on dedicated secure hardware compo-
nents, e.g., Trusted Platform Modules (TPMs) [45]. However,

2

the cost of such hardware is normally prohibitive for low-end
IoT/CPS devices. Software-based attestation [30, 43, 44] re-
quires no hardware security features but imposes strong secu-
rity assumptions about communication between P rv and V rf,
which are unrealistic in the IoT/CPS ecosystem (though, it is
the only choice for legacy devices). Hybrid RA [7,21,23,24,33]
aims to achieve security equivalent to hardware-based mecha-
nisms at minimal cost. It thus entails minimal hardware require-
ments while relying on software to reduce overall complexity
and RA footprint on P rv.

The ﬁrst hybrid RA architecture – SMART [22] – acknowl-
edged the importance of proving remote code execution on P rv,
in addition to just attesting P rv’s memory. Using an attest-then-
execute approach (see Algorithm 4 in [22]), SMART attempts
to achieve software execution guarantees by specifying the ad-
dress of the ﬁrst instruction to be executed after completion of
attestation. We consider this to be a best-effort approach which
merely guarantees that the code starts executing. However,
it does not guarantee that execution completes successfully.
For example, SMART’s approach cannot detect if execution
is interrupted (e.g., by malware) and never resumed. It also
cannot detect when a reset (e.g., due to software bugs, or P rv
running low on power) happens during execution, thus pre-
venting its successful completion. Furthermore, direct memory
access (DMA) can occur during execution and it can modify
the code being executed, or its output. In other words, SMART
offers no guarantees beyond “invoking the executable”.

Another notable RA architecture is TrustLite [32], which
builds upon SMART to allow secure interrupts. However,
TrustLite does not enforce temporal consistency of attested
memory; it is thus conceptually vulnerable to self-relocating
malware and memory modiﬁcation during attestation [9].
Consequently, it is challenging to deriving secure PoX from
TrustLite. Several other prominent low-to-medium-end RA ar-
chitectures – e.g., SANCUS [37], HYDRA [21], and TyTaN [7]
– do not offer PoX. In this paper, we show that the execute-then-
attest approach, using a temporally consistent RA architecture,
provides unforgeable proofs of execution that are produced
only if the execution and its results are not tampered with, and
it completes successfully.
Control Flow Attestation (CFA)– In contrast with RA, which
measures P rv’s software integrity, CFA techniques [1, 18, 19,
47] provide V rf with a measurement of the exact control ﬂow
path taken during execution of speciﬁc software on P rv. Such
measurements allow V rf to detect run-time attacks. We believe
that it is possible to construct a PoX scheme that relies on CFA
to produce proofs of execution based on the attested control
ﬂow path. However, in this paper, we advocate a different
approach – speciﬁc for proofs of execution – for two main
reasons:

• CFA requires substantial additional hardware features in
order to attest, in real time, executed instructions along
with memory addresses and the program counter. For ex-
ample, C-FLAT [1] assumes ARM TrustZone, while LO-

FAT [19] and LiteHAX [18] require a branch monitor and
a hash engine. We believe that such hardware components
are not viable for low-end devices, since their cost (in
terms of price, size, and energy consumption) is typically
higher than the cost of a low-end MCU itself. For exam-
ple, the cheapest Trusted Platform Module (TPM) [45],
is about 10× more expensive than MSP430 MCU itself1.
As shown in Section 7.2, current CFA architectures are
also considerably more expensive than the MCU itself
and hence not realistic in our device context.

• CFA assumes that V rf can enumerate a large (potentially
exponential!) number of valid control ﬂow paths for a
given program, and verify a valid response for each. This
burden is unnecessary for determining if a proof of exe-
cution is valid, because one does not need to know the
exact execution path in order to determine if execution
occurred (and terminated) successfully (see Section 4.2
for a discussion on run-time threats).

Instead of relying on CFA, our work constructs a PoX-speciﬁc
architecture – VAPE– that enables low-cost PoX for low-end
devices. VAPE is non-invasive (i.e.,it does not modify MCU
behavior and semantics) and incurs low hardware overhead:
around 2% for registers and 12% for LUTs. Also, V rf is not
required to enumerate valid control ﬂow graphs and the ver-
iﬁcation burden for PoX is exactly the same as the effort to
verify a typical remote attestation response for the same code.
Formally Veriﬁed Security Services– In recent years, several
efforts focused on formally verifying security-critical systems.
In terms of cryptographic primitives, Hawblitzel et al. [26]
veriﬁed implementations of SHA, HMAC, and RSA. Bond
et al. [5] veriﬁed an assembly implementation of SHA-256,
Poly1305, AES and ECDSA. Zinzindohoué, et al. [48] devel-
oped HACL*, a veriﬁed cryptographic library containing the
entire cryptographic API of NaCl [3]. Larger security-critical
systems have also been successfully veriﬁed. Bhargavan [4]
implemented the TLS protocol with veriﬁed cryptographic
security. CompCert [35] is a C compiler that is formally veri-
ﬁed to preserve C code semantics in generated assembly code.
Klein et al. [31] designed and proved functional correctness of
the seL4 microkernel. More recently, VRASED [17] realized a
formally veriﬁed hybrid RA architecture. VAPE architecture,
proposed in this paper, uses VRASED RA functionality (see
Section 3.2 for details) composed with additional formally
veriﬁed architectural components to obtain provably secure
PoX.

3 Background

3.1 Formal Veriﬁcation, Model Checking &

Linear Temporal Logic

Computer-aided formal veriﬁcation typically involves three ba-
sic steps. First, the system of interest (e.g., hardware, software,

1Source: https://www.digikey.com/

3

communication protocol) is described using a formal model,
e.g., a Finite State Machine (FSM). Second, properties that the
model should satisfy are formally speciﬁed. Third, the system
model is checked against formally speciﬁed properties to guar-
antee that the system retains them. This can be achieved by
either Theorem Proving or Model Checking. In this work, we
use the latter to verify the implementation of system modules,
and the former to derive new properties from sub-properties
that were proved for the modules’ implementation.

In one instantiation of model checking, properties are speci-
ﬁed as formulae using Temporal Logic (TL) and system models
are represented as FSMs. Hence, a system is represented by a
triple (S, S0, T ), where S is a ﬁnite set of states, S0 ⊆ S is the set
of possible initial states, and T ⊆ S × S is the transition relation
set – it describes the set of states that can be reached in a single
step from each state. The use of TL to specify properties allows
representation of expected system behavior over time.

We apply the model checker NuSMV [13], which can be
used to verify generic HW or SW models. For digital hardware
described at Register Transfer Level (RTL) – which is the
case in this work – conversion from Hardware Description
Language (HDL) to NuSMV model speciﬁcation is simple.
Furthermore, it can be automated [29], because the standard
RTL design already relies on describing hardware as an FSM.
In NuSMV, properties are speciﬁed in Linear Temporal
Logic (LTL), which is particularly useful for verifying sequen-
tial systems, since LTL extends common logic statements with
temporal clauses. In addition to propositional connectives, such
as conjunction (∧), disjunction (∨), negation (¬), and implica-
tion (→), LTL includes temporal connectives, thus enabling
sequential reasoning. In this paper, we are interested in the
following temporal connectives:

• Xφ – neXt φ: holds if φ is true at the next system state.
• Fφ – Future φ: holds if there exists a future state where φ

is true.

• Gφ – Globally φ: holds if for all future states φ is true.
• φ U ψ – φ Until ψ: holds if there is a future state where ψ

holds and φ holds for all states prior to that.

• φ B ψ – φ Before ψ: holds if the existence of state where
ψ holds implies the existence of an earlier state where φ
holds. This connective can be expressed using U through
the equivalence: φ B ψ ≡ ¬(¬φ U ψ).

This set of temporal connectives combined with propositional
connectives (with their usual meanings) allows us to specify
powerful rules. NuSMV works by checking LTL speciﬁcations
against the system FSM for all reachable states in such FSM.

3.2 Formally Veriﬁed RA

VRASED [17] is a formally veriﬁed hybrid (hardware/software
co-design) RA architecture, built as a set of sub-modules, each
guaranteeing a speciﬁc set of sub-properties. All VRASED sub-
modules, both hardware and software, are individually veriﬁed.
Finally, the composition of all sub-modules is proved to satisfy

formal deﬁnitions of RA soundness and security. RA sound-
ness guarantees that an integrity-ensuring function (HMAC in
VRASED’s case) is correctly computed on the exact memory
being attested. Moreover, it guarantees that attested memory
remains unmodiﬁed after the start of RA computation, protect-
ing against “hide-and-seek” attacks caused by self-relocating
malware [9]. RA security ensures that RA execution generates
an unforgeable authenticated memory measurement and that
the secret key K used in computing this measurement is not
leaked before, during, or after, attestation.

To achieve aforementioned goals, VRASED software
(SW-Att) is stored in Read-Only Memory (ROM) and relies
on a (previously) formally veriﬁed HMAC implementation
from HACL* cryptographic library [48]. A typical execution
of SW-Att is carried out as follows:

1. Read challenge C hal from memory region MR.
2. Derive a one-time key from C hal and the attestation mas-

ter key K .

3. Generate an attestation token H by computing an HMAC
over an attested memory region AR using the derived key:

4. Write H into MR and return the execution to unprivileged

H = HMAC(KDF(K , MR), AR)

software, i.e, normal applications.

VRASED hardware (HW-Mod) monitors 7 MCU signals:

• PC: Current Program Counter value;
• Ren: Signal that indicates if the MCU is reading from

memory (1-bit);

• Wen: Signal that indicates if the MCU is writing to mem-

ory (1-bit);

• Daddr: Address for an MCU memory access;
• DMAen: Signal that indicates if Direct Memory Access

(DMA) is currently enabled (1-bit);

• DMAaddr: Memory address being accessed by DMA.
• irq: Signal that indicates if an interrupt is happening (1-

bit);

These signals are used to determine a one-bit reset signal out-
put. Whenever reset is set to 1 a system-wide MCU reset is trig-
gered immediately, i.e., before the execution of the next instruc-
tion. This condition is triggered whenever VRASED’s hardware
detects any violation of its security properties. VRASED hard-
ware is described in Register Transfer Level (RTL) using Finite
State Machines (FSMs). Then, NuSMV Model Checker [14]
is used to automatically prove that such FSMs achieve claimed
security sub-properties. Finally, the proof that the conjunction
of hardware and software sub-properties implies end-to-end
soundness and security is done using an LTL theorem prover.
More formally, VRASED end-to-end security proof guarantees
that no probabilistic polynomial time (PPT) adversary can win
the RA security game with non-negligible probability in terms
of the security parameter. (See Deﬁnition 7 in Appendix B).

4

Deﬁnition 1 (Proof of Execution (PoX) Scheme).
A Proof of Execution (PoX) scheme is a tuple of algorithms [XRequest, XAtomicExec, XProve, XVerify] performed between P rv and V rf where:

1. XRequestV rf→P rv(S , ·): is an algorithm executed by V rf which takes as input some software S (consisting of a list of instructions {s1, s2, ..., sm}).
V rf expects an honest P rv to execute S . XRequest generates a challenge C hal, and embeds it alongside S , into an output request message asking
P rv to execute S , and to prove that such execution took place.

2. XAtomicExecP rv(ER, ·): an algorithm (with possible hardware-support) that takes as input some executable region ER in P rv’s memory,
containing a list of instructions {i1, i2, ..., im}. XAtomicExec runs on P rv and is considered successful iff: (1) instructions in ER are
executed from its ﬁrst instruction, i1, and end at its last instruction, im; (2) ER’s execution is atomic, i.e., if E is the sequence of instructions
executed between i1 and im, then {e|e ∈ E} ⊆ ER; and (3) ER’s execution ﬂow is not altered by external events, i.e., MCU interrupts or
DMA events. The XAtomicExec algorithm outputs a string O. Note that O may be a default string (⊥) if ER’s execution does not result in any output.

3. XProveP rv(ER,C hal,O, ·): an algorithm (with possible hardware-support) that takes as input some ER, C hal and O and is run by P rv to
output H , i.e., a proof that XRequestV rf→P rv(S , ·) and XAtomicExecP rv(ER, ·) happened (in this sequence) and that O was produced by
XAtomicExecP rv(ER, ·).

4. XVerifyP rv→V rf (H ,O,S ,C hal, ·): an algorithm executed by V rf with the following inputs: some S , C hal, H and O. The XVerify algorithm
checks whether H is a valid proof of the execution of S (i.e., executed memory region ER corresponds to S ) on P rv given the challenge C hal, and if
O is an authentic output/result of such an execution. If both checks succeed, XVerify outputs 1, otherwise it outputs 0.

Remark: In the parameters list, (·) denotes that additional parameters might be included depending on the speciﬁc PoX construction.

Deﬁnition 2 (PoX Security Game).
– Let treq denote time when V rf issues C hal ← XRequestV rf→P rv(S ).
– Let tveri f denote time when V rf receives H and O back from P rv in response to XRequestV rf→P rv.
– Let XAtomicExecP rv(S ,treq → tveri f ) denote that XAtomicExecP rv(ER, ·), such that ER ≡ S , was invoked and completed within the time interval
[treq,tveri f ].
– Let O ≡ XAtomicExecP rv(S ,treq → tveri f ) denote
XAtomicExecP rv(S ,treq → tveri f ) indicates O is not produced by XAtomicExecP rv(S ,treq → tveri f ).
2.1 PoX Security Game (PoX-game): Challenger plays the following game with Adv:

that XAtomicExecP rv(S ,treq → tveri f ) produces output O. Conversely, O (cid:54)≡

1. Adv is given full control over P rv software state and oracle access to calls to the algorithms XAtomicExecP rv and XProveP rv.
2. At time treq, Adv is presented with software S and challenge C hal.
3. Adv wins in two cases:

(a) None or incomplete execution: Adv produces (HAdv,OAdv), such that XVerify(HAdv,OAdv,S ,C hal, ·) = 1,

without calling XAtomicExecP rv(S ,treq → tveri f ).

(b) Execution with tampered output: Adv calls XAtomicExecP rv(S ,treq → tveri f ) and can produce (HAdv,OAdv),

such that XVerify(HAdv,OAdv,S ,C hal, ·) = 1 and OAdv (cid:54)≡ XAtomicExecP rv(S ,treq → tveri f )

2.2 PoX Security Deﬁnition:
A PoX scheme is considered secure for security parameter l if, for all PPT adversaries Adv, there exists a negligible function negl such that:

Pr[Adv, PoX-game] ≤ negl (l)

4 Proof of Execution (PoX) Schemes

A Proof of Execution (PoX) is a scheme involving two parties:
(1) a trusted veriﬁer V rf, and (2) an untrusted (potentially in-
fected) remote prover P rv. Informally, the goal of PoX is to
allow V rf to request execution of speciﬁc software S by P rv.
As part of PoX, P rv must reply to V rf with an authenticated
unforgeable cryptographic proof (H ) that convinces V rf that
P rv indeed executed S . To accomplish this, verifying H must
prove that: (1) S executed atomically, in its entirety, and that
such execution occurred on P rv (and not on some other device);
and (2) any claimed result/output value of such execution, that
is accepted as legitimate by V rf, could not have been spoofed
or modiﬁed. Also, the size and behavior (i.e., instructions) of

S , as well as the size of its output (if any), should be conﬁg-
urable and optionally speciﬁed by V rf. In other words, PoX
should provide proofs of execution for arbitrary (including pos-
sibly buggy) software, along with corresponding authenticated
outputs. Deﬁnition 1 speciﬁes PoX schemes in more detail.

We now justify the need to include atomic execution of S in
the deﬁnition of PoX. On low-end MCUs, software typically
runs on “bare metal" and, in most cases, there is no mechanism
to enforce memory isolation between applications. Therefore,
allowing S execution to be interrupted would permit other
(potentially malicious) software running on P rv to alter the
behavior of S . This might be done, for example, by an appli-
cation that interrupts execution of S and changes intermediate
computation results in S data memory, thus tampering with

5

its output or control ﬂow. Another example is an interrupt that
resumes S at different instruction modifying S execution ﬂow.
Such actions could modify S behavior completely via return
oriented programming (ROP).

4.1 PoX Adversarial Model & Security Deﬁni-

tion

We consider an adversary Adv that might control P rv’s entire
software state, code, and data. Adv can modify any writable
memory and read any memory that is not explicitly protected by
hardware-enforced access control rules. Adv may also have full
control over all Direct Memory Access (DMA) controllers of
P rv. Recall that DMA allows a hardware controller to directly
access main memory (e.g., RAM, ﬂash or ROM) without going
through the CPU.

We consider a scheme PoX = (XRequest, XAtomicExec,
XProve, XVerify) to be secure if the aforementioned Adv has
only negligible probability of convincing V rf that S executed
successfully when, in reality, such execution did not take place,
or was interrupted. In addition we require that, if execution of S
occurs, Adv cannot tamper with, or inﬂuence, this execution’s
outputs. These notions are formalized by the security game in
Deﬁnition 2.

We note that Deﬁnition 2 binds execution of S to the time
between V rf issuing the request and receiving the response.
Therefore, if a PoX scheme is secure according to this deﬁni-
tion, V rf can be certain about freshness of the execution. In
the same vein, the output produced by such execution is also
guaranteed to be fresh. This timeliness property is important to
avoid replays of previous valid executions; in fact, it is essential
for safety-critical applications. See Section 7.3 for examples.
Correctness of the Executable: we stress that the purpose
of PoX is to offer a guarantee that S , as speciﬁed by V rf, was
executed. Similar to Trusted Execution Environments target-
ing high-end CPUs, such as Intel SGX, PoX schemes do not
aim to check correctness and absence of implementation bugs
in S . As such, it is not concerned with run-time attacks that
exploit bugs and vulnerabilities in S implementation itself, to
change its expected behavior (e.g., by executing S with inputs
crafted to exploit S bugs and hijack its control ﬂow). In partic-
ular, correctness of S need not be assured by the low-end P rv.
Since V rf is a more powerful device and knows S , it has the
ability (and more computational resources) to employ various
vulnerability detection methods (e.g., fuzzing [12] or static
analysis [16]) or even software formal veriﬁcation (depending
on the level of rigor desired) to avoid or detect implementation
bugs in S . This type of techniques can be performed ofﬂine
before sending S to P rv and the whole issue is orthogonal to
PoX functionality.

Physical Attacks: physical and hardware-focused attacks
are out of scope of this paper. Speciﬁcally, we assume that Adv
cannot modify code in ROM, induce hardware faults, or retrieve
P rv secrets via physical presence side-channels. Protection

against such attacks is considered orthogonal and could be
supported via standard physical security techniques [41].

4.2 MCU Assumptions

VAPE is composed with VRASED to enable a veriﬁed architec-
ture for proofs of execution. Therefore, we assume the same
machine model introduced in VRASED and make no additional
assumptions. We review these assumptions throughout the rest
of this section and then formalize them as an LTL machine
model in Section 6.

Veriﬁcation of the entire CPU is beyond the scope of this pa-
per. Therefore, we assume the CPU architecture strictly adheres
to, and correctly implements, its speciﬁcations. In particular,
our design and veriﬁcation rely on the following simple ax-
ioms:
A1 – Program Counter (PC): PC always contains the address
of the instruction being executed in a given CPU cycle.
A2 – Memory Address: Whenever memory is read or writ-
ten, a data-address signal (Daddr) contains the address of the
corresponding memory location. For a read access, a data read-
enable bit (Ren) must be set, while, for a write access, a data
write-enable bit (Wen) must be set.
A3 – DMA: Whenever the DMA controller attempts to access
the main system memory, a DMA-address signal (DMAaddr)
reﬂects the address of the memory location being accessed and
a DMA-enable bit (DMAen) must be set. DMA cannot access
memory when DMAen is off (logical zero).
A4 – MCU Reset: At the end of a successful reset routine, all
registers (including PC) are set to zero before resuming normal
software execution ﬂow. Resets are handled by the MCU in
hardware. Thus, the reset handling routine cannot be modiﬁed.
When a reset happens, the corresponding reset signal is set.
The same signal is also set when the MCU initializes for the
ﬁrst time.
A5 – Interrupts: Whenever an interrupt occurs, the correspond-
ing irq signal is set.

5 VAPE: A Secure PoX Architecture

We now present VAPE, a new PoX architecture that realizes
the PoX security deﬁnition in Deﬁnition 2. The key aspect
of VAPE is a computer-aided formally veriﬁed and publicly
available implementation thereof. This section ﬁrst provides
some intuition behind VAPE’s design. All VAPE properties are
overviewed informally in this section and are later formalized
in Section 6.

In the rest of this section we use the term “unprivileged
software” to refer to any software other than SW-Att code
from VRASED. Adv is allowed to overwrite or bypass any
“unprivileged software”. Meanwhile, “trusted software” refers
to VRASED’s implementation of SW-Att (see Section 3) which
is formally veriﬁed and can not be modiﬁed by Adv, since it
is stored in ROM. VAPE is designed such that no changes to

6

Deﬁnition 3 (Proof of Execution Protocol). VAPE instantiates a PoX = (XRequest, XAtomicExec, XProve, XVerify) scheme behaving as
follows:

1. XRequestV rf→P rv(S , ERmin, ERmax, ORmin, ORmax): includes a set of conﬁguration parameters ERmin, ERmax, ORmin, ORmax. The Executable
Range (ER) is a contiguous memory block in which S is to be installed: ER = [ERmin, ERmax]. Similarly, the Output Range (OR) is also conﬁgurable
and deﬁned by V rf’s request as OR = [ORmin, ORmax]. If S does not produce any output ORmin = ORmax =⊥. S is the software to be installed in
ER and executed. If S is unspeciﬁed (S =⊥) the protocol will execute whatever code was pre-installed on ER on P rv, i.e., V rf is not required to
provide S in every request, only when it wants to update ER contents before executing it. If the code for S is sent by V rf, untrusted auxiliary
software in P rv is responsible for copying S into ER. P rv also receives a random l-bit challenge C hal (|C hal| = l) as part of the request, where l is
the security parameter.

2. XAtomicExecP rv(ER, OR, METADATA): This algorithm starts with unprivileged auxiliary software writing the values of: ERmin, ERmax, ORmin,
ORmax and C hal to a special pre-deﬁned memory region denoted by METADATA. VAPE’s veriﬁed hardware enforces immutability, atomic
execution and access control rules according to the values stored in METADATA; details are described in Section 5.1. Finally, it begins execution
of S by setting the program counter to the value of ERmin.

3. XProveP rv(ER,C hal, OR): produces proof of execution H . H allows V rf to decide whether: (1) code contained in ER actually executed; (2) ER
contained speciﬁed (expected) S ’s code during execution; (3) this execution is fresh, i.e., performed after the most recent XRequest; and (4)
claimed output in OR is indeed produced by this execution. As mentioned earlier, VAPE uses VRASED’s RA architecture to compute H by attesting
at least the executable, along with its output, and corresponding execution metadata. More formally:

H = HMAC(KDF(K ,C hal), ER, OR, METADATA, ...)

(1)

METADATA also contains the EXEC ﬂag that is read-only to all software running in P rv and can only be written to by VAPE’s formally
veriﬁed hardware. This hardware monitors execution and sets EXEC = 1 only if ER executed successfully (XAtomicExec) and memory regions of
METADATA, ER, and OR were not modiﬁed between the end of ER’s execution and the computation of H . The reasons for these requirements are
detailed in Section 5.2. If any malware residing on P rv attempts to violate any of these properties VAPE’s veriﬁed hardware (provably) sets EXEC
to zero. After computing H , P rv returns it and contents of OR (O) produced by ER’s execution to V rf.

4. XVerifyP rv→V rf (H ,O,S , METADATAV rf ) : Upon receiving H and O, V rf checks whether H is produced by a legitimate execution of S and
reﬂects parameters speciﬁed in XRequest, i.e., METADATAV rf = C hal||ORmin||ORmax||ERmin||ERmax||EXEC = 1. This way, V rf concludes that
S successfully executed on P rv and produced output O if:

H ≡ HMAC(KDF(K ,C halV rf ),S ,O, METADATAV rf , ...)

(2)

Table 1: Notation

without interfering with each other.

Notation is summarized in Table 1.

AR

Current Program Counter value
Signal that indicates if the MCU is reading from memory (1-bit)
Signal that indicates if the MCU is writing to memory (1-bit)
Address for an MCU memory access
Signal that indicates if DMA is currently enabled (1-bit)
Memory address being accessed by DMA, if any
Signal that indicates if an interrupt is happening

PC
Ren
Wen
Daddr
DMAen
DMAaddr
irq
CR Memory region where SW-Att is stored: CR = [CRmin,CRmax]
MR
(MAC Region) Memory region in which SW-Att computation
result is written: MR = [MRmin, MRmax]. The same region is used
to pass the attestation challenge as input to SW-Att
(Attested Region) Memory region to be attested. Can be
ﬁxed/predeﬁned or speciﬁed in an authenticated request from
V rf: AR = [ARmin, ARmax]
(Key Region) Memory region that stores K
(Exclusive Stack Region) Exclusive memory region that contains
SW-Att’s stack and can be only accessed by SW-Att
A 1-bit signal that reboots/resets the MCU when set to logical 1
(Execution Region) Memory region that stores an executable to
be executed: ER = [ERmin, ERmax]
(Output Region) Memory region that stores execution output:
OR = [ORmin, ORmax]
1-bit execution ﬂag indicating whether a successful execution
has happened

reset
ER

KR
XS

EXEC

OR

METADATA Memory region containing VAPE’s metadata

SW-Att are required. Therefore, both functionalities (RA and
PoX, i.e., VRASED and VAPE) can co-exist on the same device

7

5.1 Protocol and Architecture

Figure 1: Overview of VAPE’s workﬂow

a

VAPE implements

secure PoX = (XRequest,
XAtomicExec, XProve, XVerify) scheme conforming to
Deﬁnition 3. The steps in VAPE workﬂow are illustrated in
Figure 1. The main idea is to ﬁrst execute code contained
in ER. Then, at some later time, VAPE invokes VRASED
veriﬁed RA functionality to attest the code in ER and include,

in the attestation result, additional information that allows
V rf to verify that ER code actually executed. If ER execution
produces an output (e.g., P rv is a sensor running ER’s code
to obtain some physical/ambient quantity), authenticity and
integrity of this output can also be veriﬁed. That is achieved by
including the EXEC ﬂag among inputs to HMAC computed
as part of VRASED RA. The value of this ﬂag is controlled by
VAPE formally veriﬁed hardware and its memory can not be
written by any software running on P rv. VAPE hardware
module runs in parallel with the MCU, monitoring its behavior
and deciding the value of EXEC accordingly.
Figure 2 depicts VAPE’s architecture.

In addition to
VRASED hardware that provides secure RA by monitoring a set
of CPU signals (see Section 3.2), VAPE monitors values stored
in the dedicated physical memory region called METADATA.
METADATA contains addresses/pointers to memory bound-
aries of ER (i.e., ERmin and ERmax) and memory boundaries of
expected output: ORmin and ORmax. These addresses are sent
by V rf as part of XRequest, and are conﬁgurable at run-time.
The code S to be stored in ER is optionally2 sent by V rf.

METADATA includes the EXEC ﬂag, which is initialized
to 0 and only changes from 0 to 1 (by VAPE’s hardware) when
ER execution starts, i.e., when the PC points to ERmin. After-
wards, any violation of VAPE’s security properties (detailed
in Section 5.2) immediately changes EXEC back to 0. After
a violation, the only way to set the ﬂag back to 1 is to re-start
execution of ER from the very beginning, i.e., with PC=ERmin.
In other words, VAPE veriﬁed hardware makes sure that EXEC
value covered by the HMAC’s result (represented by H ) is 1,
if and only if ER code executed successfully. As mentioned
earlier, we consider an execution to be successful if it runs
atomically (i.e., without being interrupted), from its ﬁrst ERmin
to its last instruction ERmax.

MCU’s Address Space

C hal

ORmax
ORmin
ERmax
ERmin
EXEC

ER

OR

MCU CORE

PC,
irq,
Ren,
Wen,
Daddr,
DMAen,
DMAaddr

reset

HW-Mod

VRASED

VAPE

Figure 2: HW-Mod composed of VAPE and VRASED hardware
modules. Shaded area represents VAPE’s METADATA.

2Sending the code to be executed is optional because S might be pre-
installed on P rv. In that case the proof of execution will allow V rf to conclude
that the pre-installed S was not modiﬁed and that it was executed.

8

In addition to EXEC, HMAC covers a set of parame-
ters (in METADATA memory region) that allows V rf to
check whether executed software was indeed located in ER =
[ERmin, ERmax]. If any output is expected, V rf speciﬁes a mem-
ory range OR = [ORmin, ORmax] for storing output. Contents
of OR are also covered by the computed HMAC, allowing V rf
to verify authenticity of the output of the execution.
Remark: Our notion of successful execution requires S to
have a single exit point – ERmax. Any self-contained code with
multiple legal exits can be trivially instrumented to have a sin-
gle exit point by replacing each exit instruction with a jump to
the uniﬁed exit point ERmax. This notion also requires S to run
atomically. Since this constraint might be undesirable for some
real-time systems, we discuss how to relax it in Appendix C.
Finally, V rf is responsible for deﬁning OR memory region
according to S behavior. OR should be large enough to ﬁt all
output produced by S and OR boundaries should correspond
to addresses where S writes its output values to be sent to V rf.

5.2 VAPE’s Sub-Properties at a High-Level

We now describe sub-properties enforced by VAPE. Section 6
formalizes them in LTL and provides a single end-to-end deﬁni-
tion of VAPE correctness. This end-to-end correctness notion is
provably implied by the composition of all sub-properties. Sub-
properties fall into two major groups: Execution Protection and
Metadata Protection. A violation of any of these properties
implies one or more of:

• Code in ER was not executed atomically and in its en-

tirety;

• Output in OR was not produced by ER execution;
• Code in ER was not executed in a timely manner, i.e.,

after receiving the latest XRequest.

Whenever VAPE detects a violation, EXEC is set to 0. Since
EXEC is included among inputs to the computation of HMAC
(conveyed in P rv’s response), it will be interpreted by V rf as
failure to prove execution of code in ER.
Remark: We emphasize that properties discussed below are
required in addition to VRASED veriﬁed properties, i.e., these
are entirely different properties used speciﬁcally to enforce
PoX security and should not be viewed as replacements for
any of VRASED properties that are used to enforce RA security.

5.2.1 Execution Protection:

EP1 – Ephemeral Immutability: Code in ER cannot be mod-
iﬁed from the start of its execution until the end of SW-Att
computation in XProve routine. This property is necessary to
ensure that the attestation result reﬂects the code that executed.
Lack of this property would allow Adv to execute some other
code ERAdv, overwrite it with expected ER and ﬁnally call
XProve. This would result in a valid proof of execution of ER
even though ERAdv was executed instead.

EP2 – Ephemeral Atomicity: ER execution is only considered
successful if ER runs starting from ERmin until ERmax atom-
ically, i.e., without any interruption. This property conforms
with XAtomicExec routine in Deﬁnition 1 and with the notion
of successful execution in the context of our work. As discussed
in Section 4, ER must run atomically to prevent malware re-
siding on P rv from interrupting ER execution and resuming it
at a different instruction, or modifying intermediate execution
results in data memory. Without this property, Return-Oriented
Programming (ROP) and similar attacks on ER could change
its behavior completely and unpredictably, making any proof
of execution (and corresponding output) useless.
EP3 – Output Protection: Similar to EP1, VAPE must ensure
that OR is unmodiﬁed from the time after ER code execution
is ﬁnished until completion of HMAC computation in XProve.
Lack of this property would allow Adv to overwrite OR and
successfully spoof OR produced by ER, thus convincing V rf
that it produced output ORAdv.

5.2.2 Metadata Protection:

min , ERAdv
max ].

MP1 - Executable/Output (ER/OR) Boundaries: VAPE hard-
ware ensures properties EP1, EP2, and EP3 according to val-
ues: ERmin, ERmax, ORmin, ORmax. These values are conﬁg-
urable and can be decided by V rf based on application needs.
They are written into metadata-dedicated physical addresses
in P rv memory before ER execution. Therefore, once ER ex-
ecution starts, VAPE hardware must ensure that such values
remain unchanged until XProve completes. Otherwise, Adv
could generate valid attestation results, by attesting [ERmin,
ERmax], while, in fact, having executed code in a different re-
gion: [ERAdv
MP2 - Response Protection: The appropriate response to
V rf’s challenge must be unforgeable and non-invertible. There-
fore, in the XProve routine, K used to compute HMAC must
never be leaked (with non-negligible probability) and HMAC
implementation must be functionally correct, i.e., adhere to
its cryptographic speciﬁcation. Moreover, contents of memory
being attested must not change during HMAC computation.
We rely on VRASED to ensure these properties. Also, to en-
sure trustworthiness of the response, VAPE guarantees that no
software in P rv can ever modify EXEC ﬂag and that, once
EXEC = 0, it can only become 1 if ER’s execution re-starts
afresh.
MP3 - Challenge Temporal Consistency: VAPE must ensure
that C hal cannot be modiﬁed between ER’s execution and
HMAC computation in XProve. Without this property, the
following attack is possible: (1) P rv-resident malware exe-
cutes ER properly (i.e., by not violating EP1-EP3 and MP1-
MP2), resulting in EXEC = 1 after execution stops, and (2) at
a later time, malware receives C hal from V rf and simply calls
XProve on this C hal without executing ER. As a result, mal-
ware would acquire a valid proof of execution (since EXEC
remains 1 when the proof is generated) even though no ER

execution occurred before C hal was received. Such attacks are
prevented by setting EXEC = 0 whenever the memory region
storing C hal is modiﬁed.

6 Formal Speciﬁcation & Veriﬁed Implementa-

tion

Our formal veriﬁcation approach starts by formalizing VAPE
sub-properties Linear Temporal Logic (LTL) to deﬁne invari-
ants that must hold throughout the MCU operation. We then
use a theorem prover [20] to write a computer-aided proof that
the conjunction of the LTL sub-properties imply an end-to-
end formal deﬁnition for the guarantee expected from VAPE
hardware. VAPE correctness, when properly composed with
VRASED guarantees, yields a PoX scheme secure according to
Deﬁnition 2. This is proved by showing that, if the composition
between the two is implemented as described in Deﬁnition 3,
VRASED security can be reduced to VAPE security.

VAPE hardware module is composed of several sub-modules
written in Verilog Hardware Description Language (HDL).
Each sub-module is responsible for enforcing a set of LTL
sub-properties and is described as an FSM in Verilog at Reg-
ister Transfer Level (RTL). Individual sub-modules are com-
bined into a single Verilog design. The resulting composition
is converted to the SMV model checking language using the
automatic translation tool Verilog2SMV [29]. The resulting
SMV is simultaneously veriﬁed against all LTL speciﬁcations,
using the model checker NuSMV [14], to prove that the ﬁnal
Verilog of VAPE complies with all necessary properties.

6.1 Machine Model

Deﬁnition 4 models, in LTL, the behavior of low-end MCUs
considered in this work. It consists of a subset of the machine
model introduced by VRASED. Nonetheless, this subset models
all MCU behavior relevant for stating and verifying correctness
of VAPE’s implementation.

Deﬁnition 4. Machine Model (subset)

1. Modify_Mem(i) → (Wen ∧ Daddr = i) ∨ (DMAen ∧ DMAaddr = i)
2. Interrupt → irq
3. MR, CR, AR, KR, XS, and METADATA are non-overlapping

memory regions

Modify_Mem models that a given memory address can
be modiﬁed by a CPU instruction or by a DMA access. In
the former, Wen signal must be set and Daddr must contain the
target memory address. In the latter, DMAen signal must be
set and DMAaddr must contain the target DMA address. The
requirements for reading from a memory address are similar,
except that instead of Wen, Ren must be on. We do not explicitly
state this behavior since it is not used in VAPE proofs. For
the same reason, modeling the effects of instructions that only

9

modify register values (e.g., ALU operations, such as add and
mul) is also not necessary. The machine model also captures
the fact that, when an interrupt happens during execution, the
irq signal in MCU hardware is set to 1.

With respect to memory layout, the model states that MR,
CR, AR, KR, XS, and METADATA are disjoint memory re-
gions. The ﬁrst ﬁve memory regions are deﬁned in VRASED.
As shown in Figure 2, METADATA is a ﬁxed memory region
used by VAPE to store information about software execution
status.

6.2 Security & Implementation Correctness

We use a two-part strategy to prove that VAPE is a secure PoX
architecture, according to Deﬁnition 2:
[A]: We show that properties EP1-EP3 and MP1-MP3, dis-
cussed in Section 5.2 and formally speciﬁed next in Sec-
tion 6.3, are sufﬁcient to guarantee that EXEC ﬂag is 1
iff S indeed executed on P rv. To show this, we compose
a computer proof using SPOT LTL proof assistant [20].
[B]: We use cryptographic reduction proofs to show that, as
long as part A holds, VRASED security can be reduced to
VAPE’s PoX security from Deﬁnition 2. In turn, HMAC’s
existential unforgeability can be reduced to VRASED’s
security [17]. Therefore, both VAPE and VRASED rely on
the assumption that HMAC is a secure MAC.

In the rest of this section, we convey the intuition behind

both of these steps. Proof details are in Appendix B.

The goal of part A is to show that VAPE’s sub-properties
imply Deﬁnition 5. LTL speciﬁcation in Deﬁnition 5 captures
the conditions that must hold in order for EXEC to be set
to 1 during execution of XProve, enabling generation of a
valid proof of execution. This speciﬁcation ensures that, in
order to have EXEC = 1 during execution of XProve (i.e, for
[EXEC ∧ PC ∈ CR] to hold), at least once before such time
the following must have happened:

1. The system reached state S0 where software stored in ER
started executing from its ﬁrst instruction (PC = ERmin).
2. The system eventually reached a state S1 when ER ﬁn-
ished executing (PC = ERmax). In the interval between S0
and S1 PC kept executing instructions within ER, there
were no interrupts, no resets, and DMA remained inactive.
3. The system eventually reached a state S2 when XProve
started executing (PC = CRmin). In the interval between S0
and S2, METADATA and ER regions were not modiﬁed.
4. In the interval between S0 and S2, OR region was
only modiﬁed by ER’s execution, i.e., PC ∈ ER ∨
¬ Modify_Mem(OR).

Figure 3 shows the time windows wherein each memory region
must not change during VAPE’s PoX as implied by VAPE’s
correctness (Deﬁnition 5). Violating any of these conditions
will cause EXEC have value 0 during XProve’s computation.
Consequently, any violation will result in V rf rejecting the
proof of execution since it will not conform to the expected

value of H , per Equation 2 in Deﬁnition 3.

The intuition behind the cryptographic reduction (part B) is
that computing H involves simply invoking VRASED SW-Att
with MR = C hal, ER ∈ AR, OR ∈ AR, and METADATA ∈ AR.
Therefore, a successful forgery of VAPE’s H implies break-
ing VRASED security. Since H always includes the value of
EXEC, this implies that VAPE is PoX-secure (Deﬁnition 2).
The complete reduction is presented in Appendix B.

6.3 VAPE’s Sub-Properties in LTL

We formalize the necessary sub-properties enforced by VAPE
as LTL speciﬁcations 3–12 in Deﬁnition 6. We describe how
they map to high-level notions EP1-EP3 and MP1-MP3 dis-
cussed in Section 5.2. Appendix B discusses a computer proof
that the conjunction of this set of properties is sufﬁcient to sat-
isfy a formal deﬁnition of VAPE correctness from Deﬁnition 5.
LTL 3 enforces EP1 – Ephemeral immutability by making
sure that whenever ER memory region is written by either CPU
or DMA, EXEC is immediately set to logical 0 (false).

EP2 – Ephemeral Atomicity is enforced by a set of three
LTL speciﬁcations. LTL 4 enforces that the only way for ER’s
execution to terminate, without setting EXEC to logical 0, is
through its last instruction: PC = ERmax. This is speciﬁed by
checking the relation between current and next PC values using
LTL neXt operator. In particular, if current PC value is within
ER, and next PC value is outside SW-Att region, then either
current PC value is the address of ERmax, or EXEC is set to
0 in the next cycle. Also, LTL 5 enforces that the only way
for PC to enter ER is through the very ﬁrst instruction: ERmin.
This prevents ER execution from starting at some point in the
middle of ER, thus making sure that ER always executes in
its entirety. Finally, LTL 6 enforces that EXEC is set to zero
if an interrupt happens in the middle of ER execution. Even
though LTLs 4 and 5 already enforce that PC cannot change
to anywhere outside ER, interrupts could be programmed to
return to an arbitrary instruction within ER. Although this
would not violate LTLs 4 and 5, it would still modify ER’s
behavior. Therefore, LTL 6 is needed to prevent that.

EP3 – Output Protection is enforced by LTL 7 by making
sure that: (1) DMA controller does not write into OR; (2) CPU
can only modify OR when executing instructions within ER;
and 3) DMA cannot be active during ER execution; otherwise,
a compromised DMA could change intermediate results of
ER computation in data memory, potentially modifying ER
behavior.

Similar to EP3, MP1 – Executable/Output Boundaries
and MP3 – Challenge Temporal Consistency are enforced
by LTL 10. Since C hal as well as ERmin, ERmax, ORmin, and
ORmax are all stored in METADATA reserved memory region,
it sufﬁces to ensure that EXEC is set to logical 0 whenever this
region is modiﬁed. Also, LTL 8 enforces that EXEC is only set
to one if ER and OR are conﬁgured (by METADATA values
ERmin, ERmax, ORmin, ORmax) as valid memory regions.

10

Deﬁnition 5. Formal speciﬁcation of VAPE’s correctness.

{

PC = ERmin ∧ [(PC ∈ ER ∧ ¬Interrupt ∧ ¬reset ∧ ¬DMAen) U PC = ERmax] ∧
[(¬ Modify_Mem(ER) ∧ ¬ Modify_Mem(METADATA) ∧ (PC ∈ ER ∨ ¬ Modify_Mem(OR))) U PC = CRmin]

} B {EXEC ∧ PC ∈ CR}

Deﬁnition 6. Necessary Sub-Properties for Secure Proofs of Execution in LTL.
Ephemeral Immutability:

G : {[Wen ∧ (Daddr ∈ ER)] ∨ [DMAen ∧ (DMAaddr ∈ ER)] → ¬EXEC}

Ephemeral Atomicity:

G : {(PC ∈ ER) ∧ ¬(X(PC) ∈ ER) → PC = ERmax ∨ ¬X(EXEC) }

G : {¬(PC ∈ ER) ∧ (X(PC) ∈ ER) → X(PC) = ERmin ∨ ¬X(EXEC)}

Output Protection:

G : {(PC ∈ ER) ∧ irq → ¬EXEC}

G : {[¬(PC ∈ ER) ∧ (Wen ∧ Daddr ∈ OR)] ∨ (DMAen ∧ DMAaddr ∈ OR) ∨ (PC ∈ ER ∧ DMAen) → ¬EXEC}

Executable/Output (ER/OR) Boundaries & Challenge Temporal Consistency:

G : {ERmin > ERmax ∨ ORmin > ORmax → ¬EXEC}

G : {ERmin ≤ CRmax ∨ ERmax > CRmax → ¬EXEC}

G : {[Wen ∧ (Daddr ∈ METADATA)] ∨ [DMAen ∧ (DMAaddr ∈ METADATA)] → ¬EXEC}

Response Protection:

Remark: Note that C halmem ∈ METADATA.

G : {¬EXEC ∧ X(EXEC) → X(PC = ERmin)}

G : {reset → ¬EXEC}

(3)

(4)

(5)

(6)

(7)

(8)

(9)

(10)

(11)

(12)

Finally, LTLs 11, and 12 (in addition to VRASED veriﬁed
RA architecture) are responsible for ensuring MP2- Response
Protection by making sure that EXEC always reﬂects what
is intended by VAPE hardware. LTL 7 speciﬁes that the only
way to change EXEC from 0 to 1 is by starting ER’s execution
over. Finally, LTL 12 states that, whenever a reset happens (this
also includes the system initial booting state) and execution is
initialized, the initial value of EXEC is 0.

To conclude, recall that EXEC is read-only to all software
running on P rv. Therefore, malware can not change it directly.
VAPE is designed as a set of seven hardware sub-modules,
each veriﬁed to enforce a subset of properties discussed in this
section. Due to space constraints, examples of implementation
of veriﬁed sub-modules as FSMs are discussed in Appendix A.

7

Implementation & Evaluation

VAPE implementation uses OpenMSP430 [25] as its open
core implementation. We implement the hardware architecture
shown in Figure 2. In addition to VAPE and VRASED modules
in HW-Mod, we implement a peripheral module responsible
for storing and maintaining VAPE METADATA. As a periph-
eral, contents of METADATA can be accessed in a pre-deﬁned
memory address via standard peripheral memory access. We
also ensure that EXEC (located inside METADATA) is un-
modiﬁable in software by removing software-write wires in
hardware. Finally, we use Xilinx Vivado to synthesize an RTL
description of the modiﬁed HW-Mod and deploy it on the Artix-
7 FPGA class.

11

State S0

State S1

State S2 H ready

ER execution

Attestation

Unchanged memory
required by VAPE

Unchanged memory
enforced by VRASED

Region

META
DATA

ER

OR

treq

t(ERmin)

t(ERmax)

t(CRmin)

t(CRmax)

tveri f

Time

Figure 3: Illustration of time intervals that each memory re-
gion must remain unchanged in order to produce a valid H
(EXEC = 1). t(X) denotes the time when PC = X.

7.1 Evaluation Results

Hardware & Memory Overhead. Table 2 reports VAPE hard-
ware overhead as compared to unmodiﬁed OpenMSP430 [25]
and VRASED [17]. VAPE hardware overhead is small compared
to the baseline VRASED; it requires 2% and 12% additional
registers and LUTs, respectively. In absolute numbers, it adds
44 registers and 302 Look-Up Tables (LUTs) to the underlying
MCU. In terms of memory, VAPE needs 9 extra bytes of RAM
for storing METADATA. This overhead corresponds to 0.01%
of MSP430 16-bit address space.

Run-time. We do not observe any overhead for software’s
execution time on the VAPE-enabled P rv since VAPE does
not introduce new instructions or modiﬁcations to the MSP430
ISA. VAPE hardware runs in parallel with the original MSP430
CPU. Run-time to produce a proof of S execution includes:
(1) time to execute S (XAtomicExec), and (2) time to compute
an attestation token (XProve). The former only depends on
S behavior itself (e.g., SW-Att can be a small sequence of
instructions or have long loops). As mentioned earlier, VAPE
does not affect S runtime. XProve’s run-time is linear in the
size of ER + OR. In the worst-case scenario where these re-
gions occupy the entire program 8kB memory, XProve takes
around 900ms on an 8MHz device.

Veriﬁcation Efforts. We verify VAPE on an Ubuntu 16.04 ma-
chine running at 3.40GHz. Results are shown in Table 2. VAPE
veriﬁcation requires checking 10 extra invariants (shown in
Deﬁnition 6) in addition to existing VRASED invariants. It also
consumes signiﬁcantly higher run-time and memory usage than
VRASED veriﬁcation. This is because additional invariants in-
troduce ﬁve additional variables (ERmin, ERmax, ORmin, ORmax
and EXEC), potentially resulting in an exponential increase in
complexity of the model checking process. Nonetheless, the
overall veriﬁcation process is still reasonable for a commodity
desktop – it takes around 3 minutes and consumes 280MB of
memory.

7.2 Comparison with CFA

To the best of our knowledge, VAPE is the ﬁrst of its kind and
thus there are no other directly comparable PoX architectures.
However, to provide a (performance and overhead) point of
reference and a comparison, we contrast VAPE overhead with
that state-of-the-art CFA architectures. As discussed in Sec-
tion 2, even though CFA is not directly applicable for producing
proofs of execution with authenticated outputs, we consider it
to be the closest-related service, since it reports on the exact
execution path of a program.

We consider three recent CFA architectures: Atrium [47],
LiteHAX [18], and LO-FAT [19]. Figure 4.a compares VAPE
to these architectures in terms of number of additional LUTs.
In this ﬁgure, the black dashed line represents the total cost of
the MSP430 MCU: 1904 LUTs. Figure 4.b presents a similar
comparison for the amount of additional registers required by
these architectures. In this case, the total cost of the MSP430
MCU itself is of 691 registers. Finally, Figure 4.c presents
the amount of dedicated RAM required by these architectures
(VAPE’s dedicated RAM corresponds to the exclusive access
stack implemented by VRASED).

As expected, VAPE incurs much lower overhead. According
to our results, the cheapest CFA architecture, LiteHAX, would
entail an overhead of nearly 100% LUTs and 300% registers,
on MSP430. In addition, LiteHAX would require 150 kB of
dedicated RAM. This amount far exceeds entire addressable
memory (64 kB) of 16-bit processors, such as MSP430. Results
support our claim that CFA is not applicable to this class of low-
end devices. Meanwhile, VAPE needs a total of 12% additional
LUTs and 2% additional registers. VRASED requires about 2
kB of reserved RAM, which is not increased by VAPE PoX
support.

7.3 Proof of Concept: Authenticated Sensing

and Actuation

As discussed in Section 1 an important functionality attainable
with PoX is authenticated sensing/actuation. In this section, we
demonstrate how to use VAPE to build sensors and actuators
that “cannot lie”.

As a running example we use a ﬁre sensor: a safety-critical
low-end embedded device commonly present in households
and workplaces. It consists of an MCU equipped with analog
hardware for measuring physical/chemical quantities, e.g., tem-
perature, humidity, and CO2 level. It is also usually equipped
with actuation-capable analog hardware, such as a buzzer. Ana-
log hardware components are directly connected to MCU Gen-
eral Purpose Input/Output (GPIO) ports. GPIO ports are physi-
cal wires directly mapped to ﬁxed memory locations in MCU
memory. Therefore, software running on the MCU can read
physical quantities directly from GPIO memory.

In this example, we consider that MCU software periodically
reads these values and transmits them to a remote safety author-

12

OpenMSP430 [25]
VRASED [17]
VAPE +VRASED

Hardware

Reg

691
721
735

LUT

1904
1964
2206

Reserved
RAM (byte)

0
2332
2341

# LTL Invariants

Veriﬁcation
Veriﬁed Verilog LoC

-
10
20

-
481
1385

Time (s) Mem (MB)

-
0.4
183.6

-
13.6
280.3

Table 2: Evaluation results.

department) using a low-power ZigBee radio3 typically used by
low-end CPS/IoT devices. Temperature and humidity analog
devices are connected to a VAPE-enabled MSP430 MCU run-
ning at 8MHz and synthesized using a Basys3 Artix-7 FPGA
board. As shown in Figure 5, MCU GPIO ports connected to
the temperature/humidity sensor and to the buzzer.

(a) Additional HW overhead (%)
in Number of Look-Up Tables

(b) Additional HW overhead (%)
in Number of Registers

(c) Dedicated RAM

Figure 5: Hardware setup for a ﬁre sensor

Figure 4: Overhead comparison between VAPE and CFA archi-
tectures. Dashed lines in (a) and (b)represent the total hardware
cost of MSP430. Dashed line in (c) represents total addressable
memory (64 kB) on MSP430.

ity, e.g., a ﬁre department, which then decides whether to take
action. The MCU also triggers the buzzer actuator whenever
sensed values indicate a ﬁre. Given the safety-critical nature
of this application, the safety authority must be assured that
reported values are authentic and were produced by execution
of expected software. Otherwise, malware could spoof such
values (e.g., by not reading them from the proper GPIO). PoX
guarantees that reported values were read from the correct
GPIO port (since the memory address is speciﬁed by instruc-
tions in the ER executable), and produced output (stored in OR)
was indeed generated by execution of ER and was unmodiﬁed
thereafter. Thus, upon receiving sensed values accompanied by
a PoX, the safety authority is assured that the reported sensed
value can be trusted.

As a proof of concept, we use VAPE to implement a sim-
ple ﬁre sensor that operates with temperature and humidity
quantities. It communicates with a remote V rf (e.g., the ﬁre

VAPE is used to prove execution of the ﬁre sensor software.
This software is shown in Figure 8a in Appendix D. It consists
of two main functions: ReadSensor and SoundAlarm.
Proofs of execution are requested by the safety authority
via XRequest to issue commands to execute these functions.
ReadSensor reads and processes the value generated by
temperature/humidity analog device memory-mapped GPIO,
and copies this value to OR. The SoundAlarm function turns
the buzzer on for 2 seconds, i.e., it writes “1” to the mem-
ory address mapped to the buzzer, busy-waits for 2 seconds,
and then writes “0” to the same memory location. This imple-
mentation corresponds to the one in the open-source reposi-
tory 4 and was ported to a VAPE-enabled MCU. The porting
effort was minimal: it involved around 30 additional lines of
C code, mainly for re-implementing sub-functions originally
implemented as shared APIs, e.g., digitalRead/Write.
Finally, we transformed ported code to be compatible with
VAPE’s PoX architecture. Details can be found in Appendix D.

3https://www.zigbee.org/
4https://github.com/Seeed-Studio/LaunchPad_Kit

13

VAPEAtriumLiteHAXLO−FATNumber of Additional Look−Up Tables0200040006000800010000VAPEAtriumLiteHAXLO−FATNumber of Additional Registers050001000015000VAPEAtriumLiteHAXLO−FATAdditional Dedicated RAM (kB)0501001502008 Conclusion

This paper introduces VAPE, a novel and formally veriﬁed se-
curity service targeting low-end embedded devices. It allows
a remote untrusted prover to generate unforgeable proofs of
remote software execution. We envision VAPE’s use in many
IoT application domains, such as authenticated sensing and
actuation. Our implementation of VAPE is realized on a real
embedded system platform, MSP430, synthesized on an FPGA,
and the veriﬁed implementation is publicly available. Our eval-
uation shows that VAPE has low overhead for both hardware
footprint and time for generating proofs of execution.

References

[1] Tigist Abera et al. C-ﬂat: Control-ﬂow attestation for

embedded systems software. In CCS ’16, 2016.

[2] Anonymous Authors. VAPE source code. https:
//www.dropbox.com/sh/9id1ntfrnjy40tc/
AADONZgUdibXlONxSMdlm6npa, 2018.

[3] Daniel J Bernstein, Tanja Lange, and Peter Schwabe. The
security impact of a new cryptographic library. In In-
ternational Conference on Cryptology and Information
Security in Latin America, 2012.

[4] Karthikeyan Bhargavan, Cédric Fournet, Markulf
Kohlweiss, Alfredo Pironti, and Pierre-Yves Strub.
Implementing TLS with veriﬁed cryptographic security.
In SP, 2013.

[5] Barry Bond, Chris Hawblitzel, Manos Kapritsos, K Rus-
tan M Leino, Jacob R Lorch, Bryan Parno, Ashay Rane,
Srinath Setty, and Laure Thompson. Vale: Verifying high-
performance cryptographic assembly code. In USENIX,
2017.

[6] Ferdinand Brasser, Ahmad-Reza Sadeghi, and Gene
Tsudik. Remote attestation for low-end embedded de-
vices: the prover’s perspective. In DAC, 2016.

[7] F. Brasser et al. Tytan: Tiny trust anchor for tiny devices.

In DAC, 2015.

[8] Xavier Carpent, Karim Eldefrawy, Norrathep Rat-
tanavipanon, and Gene Tsudik. Temporal consistency
of integrity-ensuring computations and applications to
embedded systems security. In ASIACCS, 2018.

[9] Xavier Carpent, Karim Eldefrawy, Norrathep Rat-
tanavipanon, and Gene Tsudik. Temporal consistency
of integrity-ensuring computations and applications to
embedded systems security. In Proceedings of the 2018
on Asia Conference on Computer and Communications
Security, pages 313–327. ACM, 2018.

[10] Xavier Carpent, Norrathep Rattanavipanon, and Gene
Tsudik. ERASMUS: Efﬁcient remote attestation via
In Design,
self-measurement for unattended settings.
Automation and Test in Europe (DATE), 2018.

[11] Xavier Carpent, Norrathep Rattanavipanon, and Gene
Tsudik. Remote attestation of iot devices via SMARM:
Shufﬂed measurements against roving malware. In IEEE
International Symposium on Hardware Oriented Security
and Trust (HOST), 2018.

[12] Jiongyi Chen, Wenrui Diao, Qingchuan Zhao, Chaoshun
Zuo, Zhiqiang Lin, XiaoFeng Wang, Wing Cheong Lau,
Menghan Sun, Ronghai Yang, and Kehuan Zhang. Iot-
fuzzer: Discovering memory corruptions in iot through
app-based fuzzing. In NDSS, 2018.

[13] Alessandro Cimatti, Edmund Clarke, Enrico Giunchiglia,
Fausto Giunchiglia, Marco Pistore, Marco Roveri,
Roberto Sebastiani, and Armando Tacchella. NuSMV 2:
An opensource tool for symbolic model checking. In In-
ternational Conference on Computer Aided Veriﬁcation,
pages 359–364. Springer, 2002.

[14] Alessandro Cimatti, Edmund Clarke, Enrico Giunchiglia,
Fausto Giunchiglia, Marco Pistore, Marco Roveri,
Roberto Sebastiani, and Armando Tacchella. Nusmv 2:
An opensource tool for symbolic model checking. In In-
ternational Conference on Computer Aided Veriﬁcation,
pages 359–364. Springer, 2002.

[15] Victor Costan, Ilia Lebedev, and Srinivas Devadas. Sanc-
tum: Minimal hardware extensions for strong software
In 25th {USENIX} Security Symposium
isolation.
({USENIX} Security 16), 2016.

[16] Andrei Costin, Jonas Zaddach, Aurélien Francillon, and
Davide Balzarotti. A large-scale analysis of the security
of embedded ﬁrmwares. In 23rd {USENIX} Security Sym-
posium ({USENIX} Security 14), pages 95–110, 2014.

[17] Ivan De Oliveira Nunes, Karim Eldefrawy, Norrathep
Rattanavipanon, Michael Steiner, and Gene Tsudik.
Vrased: A veriﬁed hardware/software co-design for re-
mote attestation. USENIX Security’19 (To appear).
Pre-print available at: https://arxiv.org/abs/
1811.00175, 2019.

[18] Ghada Dessouky, Tigist Abera, Ahmad Ibrahim, and
Ahmad-Reza Sadeghi. Litehax: lightweight hardware-
In 2018
assisted attestation of program execution.
IEEE/ACM International Conference on Computer-Aided
Design (ICCAD), pages 1–8. IEEE, 2018.

[19] Ghada Dessouky, Shaza Zeitouni, Thomas Nyman, An-
drew Paverd, Lucas Davi, Patrick Koeberl, N Asokan,
and Ahmad-Reza Sadeghi. Lo-fat: Low-overhead control

14

ﬂow attestation in hardware. In Proceedings of the 54th
Annual Design Automation Conference 2017, page 24.
ACM, 2017.

[20] Alexandre Duret-Lutz, Alexandre Lewkowicz, Amaury
Fauchille, Thibaud Michaud, Etienne Renault, and Lau-
rent Xu. Spot 2.0—a framework for ltl and ω-automata
manipulation. In International Symposium on Automated
Technology for Veriﬁcation and Analysis, pages 122–129.
Springer, 2016.

[21] Karim Eldefrawy, Norrathep Rattanavipanon, and Gene
Tsudik. HYDRA: hybrid design for remote attestation
(using a formally veriﬁed microkernel). In Wisec. ACM,
2017.

[22] Karim Eldefrawy, Gene Tsudik, Aurélien Francillon, and
Daniele Perito. SMART: Secure and minimal architecture
for (establishing dynamic) root of trust. In NDSS. Internet
Society, 2012.

[23] Karim Eldefrawy et al. SMART: Secure and minimal
architecture for (establishing a dynamic) root of trust. In
NDSS, 2012.

[24] Aurélien Francillon et al. A minimalist approach to re-

mote attestation. In DATE, 2014.

[25] Olivier Girard. openMSP430, 2009.

[26] Chris Hawblitzel, Jon Howell, Jacob R Lorch, Arjun
Narayan, Bryan Parno, Danfeng Zhang, and Brian Zill.
Ironclad apps: End-to-end security via automated full-
system veriﬁcation. In OSDI, volume 14, pages 165–181,
2014.

[27] Ahmad Ibrahim, Ahmad-Reza Sadeghi, and Shaza
Zeitouni. SeED: secure non-interactive attestation for
embedded devices. In ACM Conference on Security and
Privacy in Wireless and Mobile Networks (WiSec), 2017.

[28] Intel. Intel Software Guard Extensions (Intel SGX).

[29] Ahmed Irfan, Alessandro Cimatti, Alberto Griggio,
Marco Roveri, and Roberto Sebastiani. Verilog2SMV: A
tool for word-level veriﬁcation. In Design, Automation &
Test in Europe Conference & Exhibition (DATE), 2016,
pages 1156–1159. IEEE, 2016.

Systems Principles, SOSP ’09, pages 207–220, New York,
NY, USA, 2009. ACM.

[32] Patrick Koeberl, Steffen Schulz, Ahmad-Reza Sadeghi,
and Vijay Varadharajan. TrustLite: A security architec-
ture for tiny embedded devices. In EuroSys. ACM, 2014.

[33] P. Koeberl et al. TrustLite: A security architecture for

tiny embedded devices. In EuroSys, 2014.

[34] X. Kovah et al. New results for timing-based attestation.

In IEEE S&P ’12, 2012.

[35] Xavier Leroy. Formal veriﬁcation of a realistic compiler.
Communications of the ACM, 52(7):107–115, 2009.

[36] Yanlin Li, Jonathan M. McCune, and Adrian Perrig.
Viper: Verifying the integrity of peripherals’ ﬁrmware. In
CCS. ACM, 2011.

[37] Job Noorman, Jo Van Bulck, Jan Tobias Mühlberg,
Frank Piessens, Pieter Maene, Bart Preneel, Ingrid Ver-
bauwhede, Johannes Götzfried, Tilo Müller, and Felix
Freiling. Sancus 2.0: A low-cost security architecture
for iot devices. ACM Trans. Priv. Secur., 20(3):7:1–7:33,
July 2017.

[38] Ivan De Oliveira Nunes, Ghada Dessouky, Ahmad
Ibrahim, Norrathep Rattanavipanon, Ahmad-Reza
Sadeghi, and Gene Tsudik. Towards systematic design of
collective remote attestation protocols. In ICDCS, 2019.

[39] Daniele Perito and Gene Tsudik. Secure code update
for embedded devices via proofs of secure erasure. In
ESORICS, 2010.

[40] Jr. Petroni et al. Copilot — A coprocessor-based kernel

runtime integrity monitor. In USENIX, 2004.

[41] Srivaths Ravi, Anand Raghunathan, and Srimat Chakrad-
har. Tamper resistance mechanisms for secure embedded
systems. In VLSI Design, 2004. Proceedings. 17th Inter-
national Conference on, pages 605–611. IEEE, 2004.

[42] Arvind Seshadri, Mark Luk, Adrian Perrig, Leendert van
Doorn, and Pradeep Khosla. Scuba: Secure code update
by attestation in sensor networks. In ACM workshop on
Wireless security, 2006.

[30] Rick Kennell et al. Establishing the genuinity of remote

computer systems. In USENIX, 2003.

[43] A. Seshadri et al. SWATT: Software-based attestation for

embedded devices. In IEEE S&P ’04, 2004.

[31] Gerwin Klein, Kevin Elphinstone, Gernot Heiser, June
Andronick, David Cock, Philip Derrin, Dhammika Elka-
duwe, Kai Engelhardt, Rafal Kolanski, Michael Norrish,
Thomas Sewell, Harvey Tuch, and Simon Winwood.
seL4: Formal veriﬁcation of an OS kernel. In Proceed-
ings of the ACM SIGOPS 22Nd Symposium on Operating

[44] A. Seshadri et al. Pioneer: Verifying code integrity and
enforcing untampered code execution on legacy systems.
In ACM SOSP, 2005.

[45] Trusted Computing Group. Trusted platform module

(tpm), 2017.

15

[46] Trusted Computing Group (TCG).

Website.

http://www.trustedcomputinggroup.org, 2015.

[47] Shaza Zeitouni, Ghada Dessouky, Orlando Arias, Dean
Sullivan, Ahmad Ibrahim, Yier Jin, and Ahmad-Reza
Sadeghi. Atrium: Runtime attestation resilient under
memory attacks. In Proceedings of the 36th International
Conference on Computer-Aided Design, pages 384–391.
IEEE Press, 2017.

[48] Jean-Karim Zinzindohoué, Karthikeyan Bhargavan,
Jonathan Protzenko, and Benjamin Beurdouche. Hacl*:
In Proceed-
A veriﬁed modern cryptographic library.
ings of the 2017 ACM SIGSAC Conference on Computer
and Communications Security, pages 1789–1806. ACM,
2017.

APPENDIX

A Sub-Module Veriﬁcation

VAPE is designed as a set of seven sub-modules. We now de-
scribe VAPE’s veriﬁed implementation, by focusing on two
of these sub-modules and their corresponding properties. The
Verilog implementation of omitted sub-modules is available
in [2]. Each sub-module enforces a sub-set of the LTL speciﬁ-
cations in Deﬁnition 6. As discussed in Section 6, sub-modules
are designed as FSMs. In particular, we implement them as
Mealy FSMs, i.e, their output changes as a function of both
the current state and current input values. Each FSM takes as
input a subset of signals shown in Figure 2 and produces only
one output – EXEC – indicating violation of PoX properties.
To simplify the presentation, we do not explicitly represent
the value of EXEC for each state transition. Instead, we deﬁne
the following implicit representation:

1. EXEC is 0 whenever an FSM transitions to NotExec

state.

2. EXEC remains 0 until a transition leaving NotExec state

is triggered.

3. EXEC is 1 in all other states.
4. Sub-modules composition: Since all PoX properties
must simultaneously hold, the value of EXEC produced
by VAPE is the conjunction (logical AND) of all sub-
modules’ individual EXEC ﬂags.

Figure 6 represents a veriﬁed model enforcing LTLs 4-6,
corresponding to the high-level property EP2- Ephemeral
Atomicity. The FSM consists of ﬁve states. notER and midER
represent states when PC is: (1) outside ER, and (2) within
ER respectively, excluding the ﬁrst (ERmin) and last (ERmax)
instructions. Meanwhile, f stER and lstER correspond to states
when PC points to the ﬁrst and last instructions, respectively.
The only possible path from notER to midER is through f stER.
Similarly, the only path from midER to notER is through lstER.
A transition to the NotExec state is triggered whenever: (1) any

(PC < ERmin ∨ PC > ERmax)

notER

PC = ERmin ∧ ¬ irq

otherwise

(PC < ERmin ∨ PC > ERmax)
∧ ¬ irq

PC = ERmin
∧ ¬ irq

f stER

PC = ERmin ∧ ¬ irq

otherwise

NotExec

otherwise

lastER

PC = ERmax
∧ ¬ irq

(PC > ERmin ∧ PC < ERmax)
∧ ¬ irq

otherwise

otherwise

PC = ERmax ∧ ¬ irq

midER

(PC > ERmin ∧ PC < ERmax)
∧ ¬ irq

Figure 6: Veriﬁed FSM for LTLs 4-6, a.k.a., EP2- Ephemeral
Atomicity.

otherwise

otherwise

PC = ERmin∧
¬[Wen ∧ (Daddr ∈ METADATA)]∧
¬[DMAen ∧ (DMAaddr ∈ METADATA)]

Run

NotExec

[Wen ∧ (Daddr ∈ METADATA)]∨
[DMAen ∧ (DMAaddr ∈ METADATA)]

Figure 7: Veriﬁed FSM for LTL 10, a.k.a., MP3- Challenge
Temporal Consistency.

sequence of values for PC do not follow the aforementioned
conditions, or (2) irq is logical 1 while PC is inside ER. Lastly,
the only way to transition out of the NotExec state is to restart
ER’s execution.

Figure 7 shows the FSM veriﬁed to comply with LTL 10
(MP3- Challenge Temporal Consistency). The FSM has two
states: Run and NotExec. The FSM transitions to the NotExec
state and outputs EXEC = 0 whenever a violation happens, i.e.,
whenever METADATA is modiﬁed in software. It transitions
back to Run when ER’s execution is restarted without such
violation.

B Proofs for Implementation Correctness &

Security

In this section we discuss the computer proof for VAPE’s im-
plementation correctness (Theorem 1) and the reduction proof
that VAPE is a secure PoX architecture as long as VRASED is
a secure RA architecture (Theorem 2). A formal LTL computer

Theorem 1. Deﬁnition 4 ∧ LTLs 3 –12 → Deﬁnition 5.

16

proof for Theorem 1 is available at [2]. We here discuss the
intuition behind such proof. Theorem 1 states that LTLs 3 –
12, when considered in conjunction with the machine model in
Deﬁnition 4, imply VAPE’s implementation correctness.

modiﬁcation of intermediate results in data memory. There-
fore, the timeline presented in Figure 3 is strictly implied by
VAPE’s implementation. This concludes the reasoning behind
Theorem 1.

Recall that Deﬁnition 5 states that, in order to have EXEC =
1 during the computation of XProve, at least once before such
time the following must have happened:

1. The system reached state S0 in which the software stored
in ER started executing from its ﬁrst instruction (PC =
ERmin).

2. The system eventually reached a state S1 when ER ﬁn-
ished executing (PC = ERmax). In the interval between
S0 and S1 PC remained executing instructions within ER,
there were no interrupts, no resets, and DMA remained
inactive.

3. The system eventually reached a state S2 when XProve
started executing (PC = CRmin). In the interval between
S0 and S2 the memory regions of METADATA and ER
were not modiﬁed.

4. In the interval between S0 and S2 the OR memory region
was only modiﬁed by ER’s software execution (PC ∈
ER ∨ ¬ Modify_Mem(OR)).

The ﬁrst two properties to be noted are LTL 12 and LTL 11.
LTL 12 establishes the default state of EXEC is 0. LTL 11
enforces that the only possible way to change EXEC from 0 to
1 is by having PC = ERmin. In other words, EXEC is 1 during
the computation of XProve only if, at some before that, the
code stored in ER started to execute (state S0).

To see why state S1 (when ER execution ﬁnishes, i.e., PC =
ERmax) is reached and until then ER executes atomically, we
look at LTLs 4, 5, 6, and 9. LTLs 4, 5 and 6 enforce that PC
will stay inside ER until S1 or otherwise EXEC will be set to
0. On the other hand, it is impossible to execute instructions
of XProve (PC ∈ CR) without leaving ER, because LTL 9
guarantees that ER and CR do not overlap, or EXEC = 0.

So far we have argued that to have a token H that reﬂects
EXEC = 1 the code contained in ER must have executed suc-
cessfully. What remains to be shown is: producing this token
implies the code in ER and METADATA are not modiﬁed in
the interval between S0 and S2 and only ER’s execution can
modify OR in the same time interval.

Clearly, the contents of ER cannot be modiﬁed after S0 be-
cause Modify_Mem(ER) directly implies that LTL 3 will set
EXEC = 0. The same reasoning is applicable for modiﬁca-
tions to METADATA region with respect to LTL 10. The same
argument applies to modifying OR, with the only exception
that OR modiﬁcations are allowed only by the CPU and when
PC ∈ ER (LTL 7). This means that OR can only be modiﬁed by
the execution of ER. In addition, LTL 7 also ensures that DMA
is disabled during the execution of ER to prevent unauthorized

Theorem 2. VAPE is secure according to Deﬁnition 2 as
long as VRASED is a secure RA architecture according
to Deﬁnition 7.

Deﬁnition 7. VRASED’s Security Game [17]
7.1 RA Security Game (RA-game):
Notation:
- l is the security parameter and |K | = |C hal| = |MR| = l
- AR(t) denotes the content of AR at time t
RA-game:

1. Setup: Adv is given oracle access to SW-Att calls.
2. Challenge: A random challenge C hal ← ${0, 1}l is gener-

ated and given to Adv.

3. Response: Adv responds with a pair (M, σ), where σ is ei-
ther forged by Adv, or is the result of calling SW-Att at some
arbitrary time t.

4. Adv wins

if and only
HMAC(KDF(K ,C hal), M).

if M (cid:54)= AR(t)

and σ =

7.2 RA Security Deﬁnition:
An RA scheme is considered secure if for all PPT adversaries Adv,
there exists a negligible function negl such that:

Pr[Adv, RA-game] ≤ negl (l)

Proof. Assume that AdvPoX is an adversary capable of winning the
security game in Deﬁnition 2 against VAPE with more than negli-
gible probability. We show that, if such AdvPoX exists, then it can
be used to construct (in a polynomial number of steps) AdvRA that
wins VRASED’s security game (Deﬁnition 7) with more than negligi-
ble probability. Therefore, by contradiction, nonexistence of AdvRA
(i.e., VRASED’s security) implies nonexistence of AdvPoX (VAPE’s
security).

First we recall that to win VAPE’s security game AdvPoX must
provide (HAdv, OAdv), such that XVerify(HAdv,OAdv,S ,C hal, ·) = 1.
To comply with conditions 3.a and 3.b in Deﬁnition 2, this must be
done either of the following two cases:

Case1 Adv does not execute S in the time window between treq and

tveri f (i.e., ¬XAtomicExecP rv(S ,treq → tveri f )).

Case2 Adv calls XAtomicExecP rv(S ,treq → tveri f ) but modiﬁes its
output O in between the time when the execution of S completes
and the time when XProve is called.

However, according to the speciﬁcation of VAPE’s XVerify al-
gorithm (see Deﬁnition 3) a token HAdv will only be accepted if
it reﬂects an input value with EXEC = 1, as expected by V rf. In
VAPE’s implementation O is stored in region OR, and S in region ER.
Moreover, given Theorem 1, we know that having EXEC = 1 during
XProve implies three conditions have been fulﬁlled:

Cond1 The code in ER executed successfully.

17

Cond2 The code in ER and METADATA were not modiﬁed after

starting ER’s execution and before calling XProve.

Cond3 Outputs in OR were not modiﬁed after completing ER’s

execution and before calling XProve.

The third condition rules out the possibility of Case2 since that case
assumes Adv can modify O, resided in OR, after ER execution and
EXEC stays logical 1 during XProve. We further break down Case1
into three sub-cases:

Case1.1 Adv does not follow Cond1-Cond3. The only way for
Adv to produces (HAdv, OAdv) in this case is to not call XProve,
i.e., by directly guessing H .

Case1.2 Adv follows Cond1-Cond3 but does not execute S be-
tween treq and tveri f . Instead, it produces (HAdv, OAdv) by call-
ing:

OAdv ≡ XAtomicExecP rv(ERAdv,treq → tveri f )

(13)

where ERAdv is a memory region different from the one spec-
iﬁed by V rf on XRequest (AdvPoX can do this by modifying
METADATA to different values of ERmin and ERmax before
calling XAtomicExec).

Case1.3 Similar to Case1.2, but ERAdv is the same region speciﬁed

by V rf on XRequest containing a different executable SAdv.

We show that an adversary that succeeds in any of these cases
can be used win VRASED’s security game. To see why this is the
case, we note that VAPE’s XProve function is implemented by using
VRASED’s SW-Att without any modiﬁcation. SW-Att covers mem-
ory regions MR (challenge memory) and AR (attested region). Hence,
VAPE instantiates these memory regions as:

1. MR = C hal;
2. ER ⊂ AR;

3. OR ⊂ AR;

4. METADATA ⊂ AR;

Doing so ensures that all sensitive memory regions used by VAPE
are included among the inputs to VRASED’s attestation. Let X(t)
denote the content in memory region X at time t. AdvRA can then be
constructed using AdvPoX as follows:

1. AdvRA receives C hal from the challenger in step (2) of RA

security game of Deﬁnition 7.

2. At arbitrary time t, AdvRA has 3 options to write AR(t) = ARAdv

and call AdvPoX:

3. AdvRA replies to the challenger with the pair (M,HAdv), where
M corresponds to the values of S , O and METADATAV rf ,
matching HAdv and OAdv generated by AdvPoX. By construc-
tion M (cid:54)= ARAdv = AR(t), as required by Deﬁnition 7.

4. Challenger will accept (M,HAdv) with the same non-negligible
probability that AdvPoX has of producing (HAdv,OAdv) such
that XVerify(HAdv,OAdv,S ,C hal, ·) = 1.

C Executable Limitations

We now discuss the limitations of our approach on the exe-
cutable types.
Shared libraries. In order to produce a valid proof, V rf must
ensure that execution of S does not depend on external code
located outside its execution range ER (e.g., shared libraries). A
call to such code would violate LTL 4, resulting in EXEC = 0
during the HMAC computation. One possible way to support
this type of executable is to transform it into a self-contained
executable by statically linking all dependencies during the
compilation time. Another is to appropriately set ER to cover
all external code used by S .
Self-modifying code (SMC). SMC is a type of executable that
alters itself while executing. Clearly, this executable type vio-
lates LTL 3 that requires the code in ER to remain unchanged
during ER execution. It is unclear how VAPE can be adapted to
support SMC; however, we are unaware of any legitimate and
realistic use-case of SMC in our target bare-metal applications.
Interrupts. Our notion of successful execution in Section 5.1
prohibits an interrupt to happen during S ’s execution. This
limitation can be problematic especially for interrupt-driven
programs such as the ones in real-time systems. Nonetheless,
simply allowing interrupts to happen during the execution may
result in attacks that allow malware to modify intermediate
execution results in data memory and consequently inﬂuence
the execution output. One possible way to remedy this issue
is to allow interrupts as long as all interrupt handlers are: (1)
immutable from the start of execution till the end of attestation
and (2) included in the attested memory range during the attes-
tation process. V rf then can determine whether an interrupt
that may have happened during the execution is malicious by
inspecting all interrupt handlers from the proof of execution.

(a) Modify ER(t) (cid:54)= S or OR(t) (cid:54)= O or METADATA(t) (cid:54)=
METADATAV rf . It then calls AdvPoX in Case1.1.
(b) Modify ER to be different from the range chosen by
V rf. Therefore, METADATA(t) (cid:54)= METADATAV rf . It
then calls AdvPoX in Case1.2.

(c) Modify ER(t) to be different from S . It then calls AdvPoX

in Case1.3.

In any of these options, AdvRA will produce (HAdv,OAdv), such
that XVerify(HAdv,OAdv,S ,C hal, ·) = 1 with non-negligible
probability.

D Software Transformation

Recall that our notion of successful execution (in Section 5.1)
requires the function’s entry point to be at the ﬁrst instruction
and the exit point to be at the last instruction. In this section,
we discuss an efﬁcient way to transform arbitrary software
(besides the ones in Appendix C) implementing a function to
conform with this requirement.

Line 10-17 of Figure 8 shows an (partial) implementa-
tion of the ReadSensor function described in Section 7.3.
This implementation, when converted to an executable, does

18

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82

# d e f i n e
# d e f i n e
# d e f i n e
# d e f i n e
# d e f i n e

P4IN
P4OUT
P4DIR
P4SEL
BIT4

( * ( v o l a t i l e u n s i g n e d c h a r * ) 0 x001C )
( * ( v o l a t i l e u n s i g n e d c h a r * ) 0x001D )
( * ( v o l a t i l e u n s i g n e d c h a r * ) 0 x001E )
( * ( v o l a t i l e u n s i g n e d c h a r * ) 0 x001F )
( 0 x0010 )

# d e f i n e MAXTIMINGS

85

# d e f i n e OR

0xEEE0 / / OR i s

i n AR

# d e f i n e HIGH
# d e f i n e LOW
# d e f i n e INPUT
# d e f i n e OUTPUT

0 x1
0 x0
0 x0
0 x1

_ _ a t t r i b u t e _ _ ( ( s e c t i o n ( ".exec.entry" ) , n a k e d ) ) void R e a d S e n s o r E n t r y ( ) {

// ERmin
R e a d S e n s o r ( ) ;
__asm__ volatile ( "br #__exec_leave" "\n\t" ) ;

}

_ _ a t t r i b u t e _ _ ( ( s e c t i o n ( ".exec.body" ) ) ) int d i g i t a l R e a d ( ) {

if ( P3IN & BIT4 ) return HIGH ;
else return LOW;

}

_ _ a t t r i b u t e _ _ ( ( s e c t i o n ( ".exec.body" ) ) ) void d i g i t a l W r i t e ( u i n t 8 _ t v a l ) {

if ( v a l == LOW)

P3OUT &= ~BIT4 ;

else

P3OUT | = BIT4 ;

}

_ _ a t t r i b u t e _ _ ( ( s e c t i o n ( ".exec.body" ) ) ) void pinMode ( u i n t 8 _ t v a l ) {

if ( v a l ==

INPUT )

P3DIR &= ~BIT4 ;
else if ( v a l == OUTPUT)
P3DIR | = BIT4 ;

}

_ _ a t t r i b u t e _ _ ( ( s e c t i o n ( ".exec.body" ) ) ) void R e a d S e n s o r ( ) {

// Tell the sensor that we are about to read
d i g i t a l W r i t e ( HIGH ) ;
delayMS ( 2 5 0 ) ;
pinMode (OUTPUT) ;
d i g i t a l W r i t e (LOW) ;
delayMS ( 2 0 ) ;
d i g i t a l W r i t e ( HIGH ) ;
d e l a y M i c r o s e c o n d s ( 4 0 ) ;
pinMode ( INPUT ) ;
u i n t 8 _ t
u i n t 8 _ t d a t a [ 5 ] = { 0 } ;
// Read the sensor’s value
for (

l a s t s t a t e = HIGH ,

i < MAXTIMINGS ;

c o u n t e r = 0 ,

i ++) {

i = 0 ;

j = 0 ,

i ;

c o u n t e r = 0 ;
while ( d i g i t a l R e a d ( ) == l a s t s t a t e ) {

c o u n t e r ++;
if ( c o u n t e r == 2 5 5 ) {

break ;

}

}
l a s t s t a t e = d i g i t a l R e a d ( ) ;
if ( c o u n t e r == 2 5 5 ) break ;
if ( ( i >= 4 ) && ( i %2 == 0 ) ) {

d a t a [ j / 8 ] <<= 1 ;
if ( c o u n t e r > 1 0 0 ) {

d a t a [ j / 8 ]
| = 1 ;
avg += c o u n t e r ;
k ++;

}
j ++;

}

}
// Copy the reading to OR
memcpy (OR, d a t a , 5 ) ;

}

_ _ a t t r i b u t e _ _ ( ( s e c t i o n ( ".exec.exit" ) , n a k e d ) ) void R e a d S e n s o r E x i t ( ) {

__asm__ volatile ( "ret" "\n\t" ) ;
// ERmax

}

(a) Fire Sensor’s code written in C

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17

. . .
SECTIONS
{

. . .
. t e x t
{

:

. . .

* ( . e x e c . e n t r y )
. = ALIGN ( 2 ) ;
* ( . e x e c . body )
. = ALIGN ( 2 ) ;
PROVIDE ( _ _ e x e c _ l e a v e = . ) ;
* ( . e x e c . e x i t )
> REGION_TEXT

}
. . .

}
. . .

(b) Linker script

Figure 8: Code snippets for (a) ﬁre sensor described in Section 7.3 (b) linker script
19

not guarantee VAPE’s executable requirement since the com-
piler may choose to place one of its sub-functions, instead of
ReadSensor, to the entry and/or exit points of the executable.
One obvious way to ﬁx this issue is to implement all of its sub-
functions as inline functions; however, such approach may
be inefﬁcient as in this example it will create multiple dupli-
cate code for the same sub-functions (e.g., digitalWrite)
inside the executable.

Instead, we created the dedicated functions for the entry
(Line 1-4) and exit (Line 6-8) points, and assign those functions

to separated executable sections – “.exec.entry” for the entry
and “.exec.exit” for the exit. Then, we labeled all sub-functions
used by ReadSensor as well as ReadSensor itself to the
same section – “.exec.body” – and modiﬁed the MSP430 linker
to place “.exec.body” between “.exec.entry” and “.exec.exit”
sections. The modiﬁed linker script is shown in Figure 8b. This
way, we ensure that the entry and exit function locate at the
beginning and the end of the executable, respectively, and thus
the resulting executable conforms with VAPE’s requirement.

20

