A Deep Learning Approach for Ontology
Enrichment from Unstructured Text

Lalit Mohan Sanagavarapu§
IIIT Hyderabad
Hyderabad, India
lalit.mohan@research.iiit.ac.in

Vivek Iyer§
IIIT Hyderabad
Hyderabad, India
vivek.iyer@research.iiit.ac.in

Y Raghu Reddy
IIIT Hyderabad
Hyderabad, India
raghu.reddy@iiit.ac.in

1
2
0
2
c
e
D
6
1

]
L
C
.
s
c
[

1
v
4
5
5
8
0
.
2
1
1
2
:
v
i
X
r
a

and

threat

available

reasoning

intelligence,

and advisories

on web provides

to mitigate some of

Abstract—Information Security in the cyber world is a major
cause for concern, with signiﬁcant increase in the number of
attack surfaces. Existing information on vulnerabilities, attacks,
controls,
an
opportunity to represent knowledge and perform security
analytics
the concerns. Representing
security knowledge in the form of ontology facilitates anomaly
relevance
detection,
attribution of attacks, and many more. This necessitates
dynamic and automated enrichment of information security
ontologies. However, existing ontology enrichment algorithms
based on natural
language processing and ML models have
issues with contextual extraction of concepts in words, phrases
and sentences. This motivates the need for sequential Deep
Learning architectures that traverse through dependency paths
in text and extract embedded vulnerabilities, threats, controls,
products and other security related concepts and instances
from learned path representations. In the proposed approach,
Bidirectional LSTMs trained on a large DBpedia dataset and
Wikipedia corpus of 2.8 GB along with Universal Sentence
Encoder is deployed to enrich ISO 27001 [1] based information
security ontology. The model is trained and tested on an high
to handle Wiki
performance computing (HPC) environment
text dimensionality. The approach yielded a test accuracy of
over 80% when tested with knocked out concepts
from
ontology and web page instances to validate the robustness.

Index Terms—Ontology Enrichment, Information Security,

Bidirectional LSTM, Universal Sentence Encoder

I. INTRODUCTION

In recent times, there is an exponential increase in the
number of content providers and content consumers on the
internet due to various reasons like improved digital literacy,
affordable devices, better network, etc. Further, the number
of
internet-connected devices per person is expected to
increase even more with adoption of emerging technologies
such as Internet of Things and 5G. This change in users and
usage is leading to an increase in data breaches1. In many
cases, realization of an impact happens long after the attack.
The Fig. 1 shows changing attack surface for organizations
with remote work force and connected devices.

Typically, organizations

in security tools and
infrastructure that are based on rules, statistical models and
machine learning (ML) techniques to identify and mitigate
intrusion
the risks arising from the threats. Firewalls,

invest

and

systems,

prevention

authentication

detection
and
authorization mechanisms to data and servers, encryption
layers, anti-virus software, endpoint controls and permissions
are some of the tools and processes are used to protect
Information Technology (IT) systems. Apart
from these
controls and processes, IT systems are regularly patched to
mitigate the risks.

contain unstructured threat

In addition, organizations purchase threat

intelligence
feeds to continuously monitor IT infrastructure for anomaly
detection. The subscription fee of threat intelligence feeds
from service providers is expensive and to a large extent, it
contains threat intelligence that is already available in public
forums. Public forums such as blogs, discussion forums,
government sites, social media channels including Twitter
intelligence on
and others
vulnerabilities, attacks, and controls. Tech-savvy internet
users interested in information security access public forums,
search, and browse on security products, their conﬁgurations,
for
reviews, vulnerabilities
awareness and to protect IT assets.
years,

security
organization’s
infrastructure use Structured Threat Information eXchange
Intelligence
(STIX)
Information (TAXII) knowledge representation from OASIS2
to represent observable objects and their properties in the
cyber
of
unstructured text to generate STIX format is a formidable
transformations
challenge
available to convert
to
ontological ‘OWL’ or ‘RDF’ formats, which in part, has
inﬂuenced OASIS to adopt ontology for representations.

/ Trusted Automated Exchange of

from XML based STIX format

domain. However,

related content

Interestingly,

information

and other

processing

automated

recent

there

[2].

are

In

Evidently, the research to use unstructured security related
content to enrich ontologies is gaining ground to mitigate
risks related to zero-day attacks, malware characterization,
digital forensics and incidence response and management
analyze
[2]–[4].
vulnerabilities and model attacks [1],
[6]. The
concepts, relationships and instances of security ontologies
are used to validate level of defence-in-depth to protect IT
assets, map security product features to controls which leads
to assurance of the security infrastructure. The constraints

ontologies

used
[3],

Security

to
[5],

are

§Equal contribution
1https://digitalguardian.com/blog/history-data-breaches

2https://www.oasis-open.org/

 
 
 
 
 
 
Fig. 1: Changing Attack Surface

and properties of ontologies allow root cause analysis of
attacks. Additionally, given that security-related data is in
structured, semi-structured or unstructured forms, unifying
them with ontologies aids in situational awareness and
readiness to defend an attack [2].

can be

Traditionally, domain experts constructed and maintained
ontologies. Given the extent of effort and cost
involved,
access to domain content and ability to process text with
advanced natural language processing (NLP) techniques and
ML models on powerful IT infrastructure opens up research
to construct and manage ontologies. The
opportunities
constructed or
information security ontologies
enriched from unstructured text available on public forums,
vulnerability databases
such as National Vulnerability
Database (NVD) 3 and other information security processing
systems [7], [8] sources. Also, standards and guidelines from
ISO/IEC [9], NIST from US, ENISA from European Nation,
Cloud Security Alliance (CSA) and others
to protect
conﬁdentiality, integrity and availability of IT assets, contain
embedded concepts. The ISO 27001:2015 [1] based security
ontologies that encompass most of these guidelines are being
extensively explored for protection, auditing and compliance
checking. Hence, enrichment of ISO 27001 based ontology
provides wider
and
interoperability.

easier management

acceptance,

In this work, we propose to enrich a widely accepted
Information Security ontology instead of constructing a new
ontology from text. This avoids inclusion of trivial concepts
and relations. The success of enrichment also enables wider
the
acceptance and usage by domain experts. However,
available literature on ontology enrichment
is
based on approaches utilizing word similarity and supervised
enrichment
ML models
approaches, albeit useful to extract word-level concepts, are

[10]. These

from text

ontology

[3],

3https://nvd.nist.gov

limited with respect
to (a) extraction of longer concepts
embedded in compound words and phrases (b) factoring
context while identifying relevant concepts and (c) extracting
and classifying instances [11].

In

the

proposed

factors context

(OntoEnricher), we
approach
implemented a supervised sequential deep learning model
that: a)
from grammatical and linguistic
information encoded in the dependency paths of a sentence,
and then b) utilizes sequential neural networks, such as
Bidirectional Long Short Term Memory (LSTM) [12] to
traverse (forward and backward directions) dependency paths
constitute
and learn relevant path representations
relations. Bidirectional LSTM model has ability to forget
unrelated stream of data to identify related concepts that are
available in the form of a word, a phrase or a sentence in the
text. In addition, we utilized pre-trained transformer-based
architecture of Universal Sentence Encoder (USE) [13] to
handle distributional
representations of compound words,
phrases, and instances.

that

is

The

implemented

proposed OntoEnricher

on
Information security ontology. As availability of information
security datasets is a concern, a semi-automatic approach
with a training dataset of 97,425 related terms (hypernyms,
hyponyms and instances) is extracted from DBpedia for all
concepts of a information security ontology [1]. To learn
syntactic and semantic dependency structure in sentences, a
2.6 GB training corpus on information security is extracted
from Wikipedia of all terms in the ontology and the DBpedia
dataset. The curated dataset and corpus are used to train
bidirectional LSTM model
in the proposed ontology
enrichment approach. The trained model is tested to enrich
concepts, relations, and instances in information security
ontology from unstructured text on the internet. The
OntoEnricher is also tested with 10% of training dataset,
knocking out terms from ontology and unstructured text from
web pages and achieved an average accuracy of 80%, which

is better than current state-of-the-art approaches. As the text
in corpus is multi-dimensional and dependency path gets
generated for very matching pair of dataset terms, we used a
high performance computing (HPC) cluster for training and
testing of model faster [14]. The code and documentation of
ontology enrichment pipeline are publicly available on
GitHub for reuse and extension. The subsequent sections in
this chapter includes (a) an elaboration of OntoEnricher
approach along with an example;
(b) Experiment and
Results; (c) Discussion and potential future work.

II. RELATED WORK

This section discusses related work on enrichment of
ontologies from unstructured text as well as approaches to
create and maintain information security ontologies. The
from
work on enrichment of knowledge graphs
unstructured text is also discussed as it represents knowledge
and contains similarities with ontologies.

(KG)

Researchers worked on knowledge acquisition from text to
construct ontologies for past couple of decades [15], [16].
The last decade witnessed signiﬁcant progress in the ﬁeld of
information extraction from web with projects such as
DBpedia, Freebase and others. The work of Mitchell et. al
[17] known as ‘NELL’ states that it is a never-ending system
to learn from web, their work bootstraps knowledge graphs
on a continuous basis. Tools such as ReVerb [18] and OLLIE
[19] are based on open information systems to extract a
triple from a sentence using syntactic and lexical patterns.
Although these approaches extract triples from unstructured
text using shallow and fast models,
they do not handle
ambiguity while entity mapping and do not learn expressive
features compared to deep and multi-layer models.

The ML models based on probabilistic, neural networks
and others are also explored for ontology enrichment from
text [16], [20], [21]. In 2017, Wang et al [22] conducted a
survey on knowledge graph completion, entity classiﬁcation
and resolution, and relation extraction. The study classiﬁed
embedding techniques into translational distance models and
semantic matching models. The study also stated that
additional information in the form of entity types, textual
descriptions, relation paths and logical rules strengthen the
research. Deep learning models such as CNN [23], LSTM
[24], [25] and variants are used to construct knowledge
graphs from text as they carry memory cells and forget gates
to build the context and reduce noise. The work of Vedula et
al. [26] proposed an approach to bootstrap newer ontologies
from related domains.

Some of the recent approaches are based on Word2Vec
[27] and its variants such as Phrase2Vec or Doc2Vec that use
distributional similarities to identify concepts to enrich an
ontology. However,
these approaches underperform in the
extraction of concepts embedded in words, phrases and
sentences due to their inability to adequately characterize
context. Compared to Word2Vec and its variants, Universal
Sentence Encoder (USE) [13] stands promising to identify
into high
concepts in long phrases as it encodes text

for

vectors

semantic

dimensional
similarity. Lately,
researchers [28] are exploring USE to produce sentence
in queries.
embeddings and deduce semantic closeness
transformer-based models such as BERT and
Although,
XLNet [29], [30] are of interest
to ontology enrichment
researchers, training them to a domain is effort intensive.

The literature to enrich security ontologies from text drew
attention with OASIS’s STIX/TAXII standardization and
open source threat intelligence. Most of the current work on
security ontologies from text (construction or enrichment)
are based on usage of string, substring, pre-ﬁx and post-ﬁx
matching of terms, Word2Vec and other basic ML models
[2], [21], [31]. In ontologies as well,
the deep learning
approaches based on recurrent neural networks are trending
because of their ability to build the context over multiple
words [5], [32]. The research of Houssem et al. [32] used
LSTM for population of security ontologies. However, the
details to create corpus, handle phrases and robustness of the
approach are not elaborated, only 40 entities are used in the
model. The literature revealed that security ontologies based
on ISO 27001 [1] and MITRE Corporation’s cyber security
effort [2] are most referred.

III. ONTOLOGY ENRICHMENT APPROACH

In the proposed approach, whenever a new concept
is
introduced, current memory state of LSTMs are updated to
replace old concept, or add new concept by multiplying with
forget gates as needed. The concept in current memory are
mapped to instances and relations between concepts in
current state are constructed. Concepts extracted are used to
update the ontology automatically or after manual validation
by a domain expert.

a

four stages:

The OntoEnricher

seed ontology with
enriches
concepts, relations and instances extracted from unstructured
text. As shown in Fig. 2, the ontology enrichment approach
(i) DatasetCreation : creates
consists of
training dataset by extracting and curating related terms from
DBpedia
(ii)
CorpusCreation : creates domain-speciﬁc training corpus
by parsing Wikipedia dump using various ﬁltering measures
(iii) T raining
relation
classiﬁcation of term pairs using training dataset and corpus,
and (iv) T esting :
tests the approach by enriching the
ontology from domain-speciﬁc web pages.

trains OntoEnricher

ontology

concepts

the

for

for

all

in

:

Control’,

1) Stage 1: Creation of Dataset: The information security
seed ontology is based on ISO 27001 [1]. The standard ISO
27001:2015 [9] contains 114 controls across 14 groups.
These groups are ‘Human Resources’, ‘Asset Management’,
and
‘Access
‘System
environmental’,
development
relations’,
‘Information security incident management’, ‘Compliance’,
‘Security Policies’ and ‘Security organisation’. These groups
and controls are represented as 408 concepts in the security
ontology to protect assets from vulnerabilities and threats.

‘Communications’,

‘Cryptography’,

‘Operations’,

acquisition’,

‘Supplier

‘Physical

and

Fig. 2: Approach used for Ontology Enrichment

The upper ontology of the seed ontology is shown in Fig. 3
and the ontology is available on GitHub.

OntoEnricher approach. The SPARQL queries
(query
III-1) to extract hypernyms and hyponyms from DBpedia for
concepts in information security ontology are :

SELECT * WHERE
{<\protect\vrule width0pt\protect\href{http://dbpedia.org/resource/}{http://dbpedia.org/resource/}$concept>
<\protect\vrule width0pt\protect\href{http://purl.org/linguistics/gold/hypernym}{http://purl.org/linguistics/gold/hypernym}>
?hypernyms}

Fig. 3: Information Security Upper Ontology [1]

These 408 concepts are extracted from security ontology
‘to query related terms, namely hypernyms and hyponyms
from DBpedia. DBpedia contains over 5 million entities,
allows querying of semantic relationships, concepts and
properties encoded in the form of RDF triples. Typically, the
RDF triples (subject-verb-object) in an ontology contain a
‘verb’ relationship between concepts. Verbs are typically
domain-speciﬁc
general-purpose
unavailable
knowledge graphs like DBPedia. Hypernyms and hyponyms
that denote ‘is-a’ relationship between concepts, are easily
available in DBPedia and widely used in ontologies, making
demonstrate
these

relations

choice

ideal

and

an

to

in

SELECT * WHERE ?hypernyms
< width0pthttp://purl.org/linguistics/gold/hypernym>
< width0pthttp://dbpedia.org/resource/$concept>

The extracted terms with SPARQL queries are converted
the form (a, b, label) where a denotes the
to triples of
ontology concept, b denotes the DBPedia term and label
determines the DBPedia relation between a and b. This leads
to a dataset of 97,425 triples. These triples are then curated
by three domain experts and authors to mark unrelated terms
as ‘none’. This includes pairs that are not related to the
domain and pairs that are not related to each other, as both
these cases are not needed for ontology enrichment.
In
since DBPedia often categorizes ontological
addition,
instances under
some pairs are separately
labelled as ‘instances’ if b is an instance of a or as a
‘concept’ if b denotes the concept of which a is an instance.
The terms classiﬁed include names of experts, organizations,
products and tools, attacks, vulnerabilities, malware, virus

‘hyponyms’,

is

signiﬁcantly higher

and many others. Finally, since the number of ‘none’ pairs
(89,820)
than the number of
‘non-none’ (7,605) pairs, ‘none’ pairs are sorted in order of
increasing similarity. The ﬁrst 5% of ‘none’ pairs are ﬁltered
out, this is experimentally determined to yield better results.
The Table I shows composition of dataset after extraction,
curation and ﬁltration.

Relationship
Hypernymy
Hyponymy
Instances
Concepts
None
Total

Count
2,939
794
2,685
1,187
4,490
12,096

TABLE I: Composition of the Dataset

is moderated and structured for model

2) Stage 2: Creation of Corpus: Once the training dataset
is created, a training corpus to provide linguistic information
for all terms in the dataset is extracted. Wikipedia is used as
training. The
it
DBPedia is a part of the Wikipedia project, and therefore
assures unambigous articles of all extracted dataset terms. As
a ﬁrst step, all corresponding Wikipedia articles for terms in
the dataset are extracted and added to the corpus. In addition,
other articles related to the information security ontology
domain are also extracted. This is done by comparing
Doc2Vec [33] similarity of each article with the Wikipedia
article on ‘Information Security’4 and then ﬁltering in
articles with a similarity score higher than a certain threshold
(0.27 after manual validation). This threshold is determined
to optimize classiﬁcation accuracy after a validation with a
sample corpus. The two-step ﬁltering yielded a 2.6 GB size
information security training corpus.

A. Stage 3: Training OntoEnricher

Training dataset and corpus are parsed to generate various
dependency paths to connect each pair of terms provided in
the training dataset. Here, ‘dependency paths’ refers to the
multi-set of all paths that connect a pair of terms in the
training corpus. These paths are encoded as a sequence of
form
nodes, where
is
(word, P OS tag, dep tag, dir).
and
dep tag denote POS and dependency tags of
the word
respectively, while dir denotes the direction of the edge
connecting it to the next node in that dependency path. The
term pairs along with extracted dependency paths between
them are passed to OntoEnricher for training.

the
P OS tag

a 4-tuple of

each node

The

4

The

Fig.

the
architecture
layer in proposed model

shows
diagram of
OntoEnricher. The ﬁrst
is the
embedding layer. The distributional embeddings for the terms
(words) are obtained using a pre-trained state-of-the-art
Universal Sentence Encoder (USE) [13] model. This model
is preferred over other vocabulary-based distributional
models such as Word2Vec, Glove and others as it returns

4https://en.wikipedia.org/wiki/Information security

Fig. 4: Architecture diagram of OntoEnricher

distributional embeddings for not just single words, but also
compound words, phrases and sentences. In addition, USE is
pretrained on Wikipedia along with other corpora, making it
suited for this task. Apart from pre-trained word embeddings,
embeddings for POS tags, dependency tags and direction
tags are obtained from trainable embedding layers. The node
embeddings constructed from the concatenation of words,
POS, dependency, and direction tag embeddings are arranged
in a sequence to obtain path embeddings. A dropout layer is
applied after each embedding. The path embeddings for each
to a
term pair
path connecting the
bidirectional, two-layer LSTM which trains on a sequence of
linguistically and semantically encoded nodes and learns the
type of sequences that characterize a particular kind of
relation. The bidirectional LSTM allows the network to have
both backward and forward information about
the path
embeddings at every time step, while the two layers enable
capturing of complex relations among dependency paths.

then input

are

The output of last hidden state of LSTM is taken as the
path representation. Since a pair of terms may have multiple
paths between them,
these path
representations is taken by using path counts as weights, to

a weighted sum of

yield a ﬁnal context vector. This context vector encodes
syntactic and linguistic information,
is passed through a
layer and then concatenated with distributional
dropout
embeddings of both terms in order
to encode semantic
information. The concatenated vector is then passed through
two Feedfoward Neural Networks with a Rectiﬁer Linear
Unit (ReLU) layer in between, to yield ﬁnal class probability
vector. The class with maximum probability is output as
predicted relation between the term pair.

‘Real-time adaptive security’ is converted to a feature vector
that uses ‘security’ as the word, ‘PROPN’ as POS tag,
‘nsubj’ as dependency tag and ‘+’ denotes the direction of
the edge connecting it
to the lowest common root node
between the term pair. Similarly, the next word ‘be’ is a verb
and a root word of ‘is’ does not have any direction ‘∼’. The
last word of this path, ‘model’, has ‘NOUN’ as POS tag,
‘attr’ as dependency tag and ‘+’ as direction of the arrow
going away from ‘model’ to ‘is’.

B. Stage 4: Testing OntoEnricher

The procedure to extract concepts and instances from
(web page) text, during testing stage is detailed here. To
avoid usage of every unstructured (web page) text to enrich
an ontology, a lightweight evaluation technique [34] that
checks for sufﬁciency of new security terms is deployed.
After passing the sufﬁciency evaluation as a pre-processing
stage, co-reference resolution is applied and then noun
chunks are extracted from web page. A cartesian product
(nC2)
is taken of extracted noun chunks to construct
potential
to
term pairs. However, a cartesian product
OntoEnricher is computationally expensive and also leads
to error propagation. A two-stage ﬁltering is applied to
related to
if noun chunks are ‘sufﬁciently’
validate (a)
Information Security and (b) if they are ‘sufﬁciently’ related
to each other. Both these conditions are checked to compare
distributional similarity using USE against experimentally
determined threshold values. The sufﬁciently similar term
pairs are then input
to classify the
relationship. The pairs classiﬁed as ‘None’ are discarded and
the rest are converted to RDF triples for information security
ontology enrichment.

to pre-trained model

C. Example

(R-TAS)

‘Real-time

‘Real-time adaptive security’

The Fig. 5 illustrates ontology enrichment approach with
is a
an example.
in information security ontology. The
concept present
corresponding article
adaptive
in DBPedia,
security’ has ‘model’ as its hypernymy entry, which is
returned using a SPARQL query. The information security
corpus extracted from Wikipedia dump using Doc2Vec ﬁlter
contains multiple paired mentions of these terms, out of
which one article contains two mentions. The corpus, the
aforementioned sentences, are passed to SpaCy5 dependency
parser and all corresponding dependency paths to connect
every extracted term pair. These dependency paths which
contain encoded linguistic information are passed to a
serialization layer that converts the dependency graph into a
series of nodes to form the input to OntoEnricher.

The serialization layer reduces the word in every node in
the dependency path to its lemma, a root word to enable
meaningful
‘Real-time
training and generalization. Thus,
adaptive security’ is reduced to ‘security’ and ‘is’ is reduced
to ‘be’. It also converts every node to a feature vector. The

5https://spacy.io/

for word

embedding

(ii) POS tag

term pair are passed as input

The same approach is followed for second dependency
path and nodes are sequenced similarly. These two paths are
then passed to the embedding layer that calculates (i) USE
embedding
(iii)
dependency tag embedding and (iv) direction embedding.
The last 3 embeddings are trainable while word embeddings
are pre-trained using USE. These are concatenated together
to yield a node embedding. All paths (node sequences) that
connect
to Bidirectional
two-layer LSTM. In this example, both the paths connecting
to
‘Real-Time Adaptive Security’ and ‘model’ are input
LSTM, post which the last hidden state is taken as path-wise
contextual output. A weighted sum of these paths is then
calculated using frequency of occurrence as weights to yield
ﬁnal context vector, this has encoded linguistic information
of paths that connect ‘R-TAS’ and ‘model’. This context
vector
is concatenated with distributional embeddings of
‘Real-Time Adapative Security’ and ‘model’. Reducing
words to their root form during serialization stage enables to
construct a contextualized representation. The characterized
paths constitutes a speciﬁc relation and the most frequent
ones, while distributional word and phrase embeddings
enable semantic relevance and speciﬁcity at a conceptual
level. This
and
linguistic information that are passed to 2 Feedforward
Neural Networks with a ReLU layer in between, yielding a
ﬁnal class probability vector as output. This class probability
vector is trained to identify relationship between ‘model’ and
‘Real-Time Adapative Security’ as hypernymy.

concatenated vector denotes

semantic

IV. EXPERIMENTAL SETTINGS AND RESULTS

The experiment is conducted with two ontologies, namely
the ISO 27001-based Information Security and Stanford
Pizza ontologies. While the former is focus of this section
and use case to build knowledge base, Pizza ontology is
used to demonstrate generalizability of the approach. The
Table II shows the composition of security and pizza datasets
respectively. While the information security corpus is 2.8 GB
in volume,
the pizza corpus is signiﬁcantly
smaller and only 95 MB. This can be attributed to the fact
that
the pizza ontology represents a very narrow domain
(‘pizza’ out of food domain) and thus contains few relevant
Wiki articles. Information security ontology contains broader,
information about assets, controls
systems-level concepts,
etc. that return a variety of related articles.

interestingly,

The OntoEnricher is implemented using deep learning
for

library Pytorch with ‘0’ as

random seed number

Fig. 5: Example illustrating Ontology Enrichment approach

Parameters
# of Concepts
Dataset size
Corpus size

Security
408
12,096
2.8GB

Pizza
143
7,119
95MB

TABLE II: Dataset Composition

consistency in results. Also, various other Python libraries
such as Pronto6 to extract ontology terms, Wikiextractor7 to
extract articles from Wikipedia dump, spaCy for dependency
graph extraction, and Tensorﬂow-Hub to load Universal
Sentence Encoder are used. The deployed HPC expedites
training and testing performance of OntoEnricher, this also
aids in parallel processing of adding or retrieving concepts,
relations and instances from ontology. The performance of
OntoEnricher is evaluated on three diverse test datasets :

6https://pypi.org/project/pronto/
7https://github.com/attardi/wikiextractor

1) DBPedia test dataset: This is created by randomly
extracting 10% of the training dataset extracted from
DBpedia. It mostly consists of small-medium length
words.

2) ‘Knocked-out’ test dataset: This is created by knocking
out concepts and relations from the seed ontology. This
evaluates the ability of OntoEnricher to identify
multi-word or phrase-level concepts, as is common in
information security ontology, and identiﬁcation of
highly-domain speciﬁc, non-English terms as in Pizza
ontology.

related webpages. The Top

3) Instance dataset: This is created by extracting text from
security-domain
10
vulnerability related web pages from OWASP and
product pages on ‘ﬁrewall’ are extracted to test
the
model. The ability to identify concepts and instances
from web pages conﬁrms that OntoEnricher can use
text from public forums and other unstructured data

sources. This evaluation is done without
factoring
sufﬁciency requirement [34] of new terms in text to
by
of
evaluate
OntoEnricher.

identiﬁcation

ontology

terms

The Table III shows optimized hyperparameters after
tuning OntoEnricher. Grid search is used to experiment
with and arrive at optimal values of various hyperparameters.
It includes hidden dimensions (120, 180, 200, 250, 300, 500,
900), input dimension of 2nd NN (60, 90, 120, 180, 300,
500), number of LSTM layers (1,2), activation functions
(Softmax, ReLU, LogSoftmax), loss functions (NLL Loss,
Cross Entropy loss), and learning and weight decay rates
experimentation data with various
(0.001, 0.01). The
embeddings, epochs,
learning rate, activation functions,
hidden layers and the related results are available as
spreadsheet on GitHub.

Security
Log Softmax
2

Hyperparameters
Activation Function
Number of Layers
Hidden Dimension of LSTM 180
120
Input Dimension (2nd NN)
0.35
Embedding layer Dropout
0.8
Hidden layer Dropout
0.8
Hidden layer Dropout
AdamW
Optimizer
NLL Loss
Loss function
200
Epochs
0.001
Learning Rate
0.001
Weight Decay
Xavier
Weight Initialization

Pizza
Log Softmax
2
250
90
0.35
0.8
0.8
AdamW
NLL Loss
200
0.001
0.001
Xavier

TABLE III: Hyperparameters of the Model

and comparable

The evaluation results of OntoEnricher on information
security and pizza ontologies are shown in Tables IV and VI
scores on
respectively. A competent
information security ontology enrichment with all
three
datasets are achieved. The test results with 10% test dataset
performed better, while test results on knockout concepts or
information security related web pages are not far apart,
proving that performance did not dip in extraction of
phrases, multi-word concepts and instances which is a key
component missing from previous ontology enrichment
approaches. As
existing
approaches are different, only a qualitative comparison is
performed
in
OntoEnricher, the number of terms and the size of the
corpus used for training and testing are much larger. It is
observed that the difference between Precision and Recall
value is less, indicates that terms are not skewed towards
proposed
establishes
domain
OntoEnricher approach.

in Table V. Additionally,

and output

format of

robustness

shown

input

and

and

the

of

Interestingly, the pizza enrichment results shown in Table
VI are better than security enrichment results, presumably due
to domain being narrow as mentioned earlier and concepts are
easily identiﬁable as a consequence.

Most of the existing ontology evaluation metrics [39] are
information retrieval

extensions of Precision and Recall

Metrics
Terms
Accuracy
Precision
Recall
F1-Score

DBPedia Knocked out Web pages
5538
0.77
0.84
0.77
0.80

1197
0.81
0.76
0.76
0.76

153
0.83
0.84
0.73
0.78

TABLE IV: Security Ontology Enrichment Results

metrics. Hence, precision score for k documents (shown in
Table VII) is measured to validate consistency in ontology
the
enrichment with webpages. The scores indicate that
proposed approach can identify concepts for any large
number of domain documents. The Fig. 6 shows
the
relationship accuracy for each of the classes. It is observable
that all relationships are classiﬁed equally and hypernymy
classiﬁcation seems to be relatively higher.

Fig. 6: Accuracy on Class Identiﬁcation in Information
Security Ontology

V. CONCLUSION AND FUTURE WORK

that

The

security

Information

implemented

ontology
enrichment approach is comprehensive with an ability to
handle new terms, changing domain content
includes
concepts, relations and instances. Usage of well accepted
ISO 27001 based security ontology, an exhaustive data
source such as DBpedia and Wikipedia, Universal Sentence
Encoder
for distributional embeddings and Bidirectional
LSTM for sequential learning makes it extensible to other
domains as well. In the implemented enrichment approach,
concepts in seed ontology can be a single or multiple words,
is an improvement from state-of-the-art. The approach also
incorporated instances from unstructured text (web pages) so
that organizations or individuals have ﬂexibility to reason
information security ontologies for mitigation strategies,
vulnerabilities assessment, attack graphs detection and many
other use cases. The enriched security ontology can also be
used by search engines to display relevant results, top trends
in
controls. The
implemented OntoEnricher is trained on 408 Information
Security ontology terms, 97,425 DBpedia terms and 2.8 GB
a HPC cluster. The
size Wikipedia
OntoEnricher is
tested with 20 random information
security related web pages extracted from internet with an
accuracy of 80% and an F1-score of 78%. While

vulnerabilities,

articles with

threats,

attacks

and

Approach

Dataset

Model

Evaluation Metric

Relation between two named entities
identiﬁed using NER technique [21]

Open source threat intelligence Neural Network and Word2Vec

96% as accuracy

Dual Iterative Pattern Relation
Expansion for relation extraction [35]

Security related articles from
web page

Semi-supervised models

82% as accuracy

Named Entity recognition to
identify vulnerabilities and relations [36]

NVD, DBPedia and other open
source threat intelligence

Support Vector Machines

90% as accuracy

Malware text classiﬁcation [37]

MalwareTextDB

Named Entities are considered as
concepts in security content [32]

NVD, Microsoft Bulletins

Entity extraction from DBPedia [38]

Wikipedia and DBPedia

Convolutional Neural Network and
Conditional Random Field
Long Short Term Memory and
Conditional Random Field
Semantic Role Labeler and
coreference resolution

25 - 36% as accuracy

96% as accuracy

66.3% as F1 score

Observation
Single words are only handled and there is
no base ontology. Evaluation is performed
on pre-trained data
Not enough volume of training data to
validate scalability and generalizability.
Ontology and dataset details are not available
Only vulnerability related words are handled
and there is no base ontology. Evaluation
is performed on pre-trained data
Used Glove for word embeddings that is
not fully context sensitive
The dataset was similar and there are no
references to handle multi-word and instances
No base ontology and references to handle
multi-words or instances

TABLE V: Ontology Enrichment Comparison

Metrics
Terms
Accuracy
Precision
Recall
F1-Score

DBPedia Knocked out Web pages
85
0.79
0.99
0.79
0.88

791
0.99
0.81
0.91
0.86

99
0.88
0.84
0.81
0.82

TABLE VI: Pizza Ontology Enrichment Results

Web pages
Score

P@5
0.89

P@10
0.80

P@15
0.82

P@20
0.84

TABLE VII: Precision scores for 20 Random Web Pages in
Information Security

achieved implementing,
are
state-of-the-art
following activities are being explored as future work -

results

the

• Optimize effort required to create DBPedia dataset such

as ﬁltering out irrelevant terms.

• Test

the approach with other security ontologies and

extend training corpus beyond Wikipedia.

• Compare results with other knowledge graph and
ontology enrichment approaches after curation of input
and output format of dataset and corpus.

• While there is a need for domain experts to evaluate an
enriched ontology, it is effort intensive and brings in other
dependencies. A syntactic and semantic evaluation with a
easily conﬁgurable rules and AI models to reduce effort.

REFERENCES

[1] S. Fenz

and A. Ekelhart,

“Formalizing Information Security
Knowledge,” in Proceedings of the 4th International Symposium on
Information, Computer, and Communications Security. ACM, 2009.

[2] Z. Syed, A. Padia, T. Finin, L. Mathews, and A. Joshi, “UCO: A Uniﬁed
Cybersecurity Ontology,” in Workshops at the 30th AAAI Conference on
Artiﬁcial Intelligence, 2016.

[3] M. Iannacone, S. Bohn, G. Nakamura, J. Gerth, K. Huffer, R. Bridges,
E. Ferragut, and J. Goodall, “Developing an Ontology for Cyber Security
Knowledge Graphs,” in Proceedings of the 10th Annual Cyber and
Information Security Research Conference, 2015, pp. 1–4.

[4] F. N. Al-Aswadi, H. Y. Chan, and K. H. Gan, “Automatic Ontology
Construction from Text: a Review from Shallow to Deep Learning
Trend,” Artiﬁcial Intelligence Review, pp. 1–28, 2019.

[5] Y. Jia, Y. Qi, H. Shang, R. Jiang, and A. Li, “A Practical Approach
to Constructing a Knowledge Graph for Cybersecurity,” Engineering,
vol. 4, no. 1, pp. 53–60, 2018.

[6] H. Zheng, Y. Wang, C. Han, F. Le, R. He, and J. Lu, “Learning and
Applying Ontology for Machine Learning in Cyber Attack Detection,” in
17th IEEE International Conference On Trust, Security And Privacy In
Computing And Communications/ 12th IEEE International Conference
On Big Data Science And Engineering, 2018, pp. 1309–1315.

[7] L. M. Sanagavarapu, N. Mathur, S. Agrawal, and Y. R. Reddy, “SIREN-
Security Information Retrieval and Extraction eNgine,” in European
Conference on Information Retrieval. Springer, 2018, pp. 811–814.

[8] AlienVault,

Open

Threat

Intelligence,

Feb.

2021,

https://otx.alienvault.com/.

[9] ISO/IEC 27001, Information Security Management, Feb. 2021, https:

//www.iso.org/isoiec-27001-information-security.html.

[10] C. Sayan, S. Hariri, and G. L. Ball, “Semantic Knowledge Architecture
for Cyber Security,” in Proceedings of the International Conference
on Security and Management (SAM).
The Steering Committee of
The World Congress in Computer Science, Computer Engineering, and
Applied Computing, 2019, pp. 69–76.

[11] V. Iyer, L. Mohan, Y. R. Reddy, and M. Bhatia, “A Survey on
Ontology Enrichment from Text,” Proceedings of the 16th International
Conference on Natural Language Processing, 2019.

[12] M. Schuster and K. K. Paliwal, “Bidirectional Recurrent Neural
Networks,” IEEE Transactions on Signal Processing, vol. 45, no. 11,
pp. 2673–2681, 1997.

[13] D. Cer, Y. Yang, S.-y. Kong, N. Hua, N. Limtiaco, R. S. John,
N. Constant, M. Guajardo-Cespedes, S. Yuan, C. Tar et al., “Universal
Sentence Encoder,” ArXiv preprint arXiv:1803.11175, 2018.

[14] R. Lim, “Methods

for Accelerating Machine Learning in High
Performance Computing,” University of Oregon—Area-2019-01, 2019.
[15] P. Buitelaar, P. Cimiano, and B. Magnini, Ontology Learning from Text:

Methods, Evaluation and Applications.

IOS Press, 2005, vol. 123.

[16] K. Liu, W. R. Hogan, and R. S. Crowley, “Natural Language Processing
Methods and Systems for Biomedical Ontology Learning,” Journal of
Biomedical Informatics, vol. 44, no. 1, pp. 163–179, 2011.

[17] T. Mitchell, W. Cohen, E. Hruschka, P. Talukdar, B. Yang, J. Betteridge,
A. Carlson, B. Dalvi, M. Gardner, B. Kisiel et al., “Never-Ending
Learning,” Communications of the ACM, vol. 61, no. 5, pp. 103–115,
2018.

[18] A. Fader, S. Soderland, and O. Etzioni, “Identifying Relations for Open
Information Extraction,” in Proceedings of the Conference on Empirical
Methods in Natural Language Processing. ACL, 2011, pp. 1535–1545.
[19] M. Schmitz, R. Bart, S. Soderland, O. Etzioni et al., “Open Language
Learning for Information Extraction,” in Proceedings of
the Joint
Conference on Empirical Methods in Natural Language Processing
and Computational Natural Language Learning.
Association for
Computational Linguistics, 2012, pp. 523–534.

[20] G. Petasis, V. Karkaletsis, G. Paliouras, A. Krithara, and E. Zavitsanos,
“Ontology Population and Enrichment: State of the Art,” in Knowledge-
driven Multimedia Information Extraction and Ontology Evolution.
Springer, 2011, pp. 134–166.

[21] A. Pingle, A. Piplai, S. Mittal, A. Joshi, J. Holt, and R. Zak, “RelExt:
Relation Extraction using Deep Learning Approaches for Cybersecurity
Knowledge Graph Improvement,” in Proceedings of the 2019 IEEE/ACM
International Conference on Advances in Social Networks Analysis and
Mining, 2019, pp. 879–886.

[22] Q. Wang, Z. Mao, B. Wang, and L. Guo, “Knowledge Graph Embedding:
A Survey of Approaches and Applications,” IEEE Transactions on
Knowledge and Data Engineering, vol. 29, no. 12, pp. 2724–2743, 2017.

[23] T. Dettmers, P. Minervini, P. Stenetorp, and S. Riedel, “Convolutional 2D
Knowledge Graph Embeddings,” in 32nd AAAI Conference on Artiﬁcial
Intelligence, 2018.

[24] B. Nie and S. Sun, “Knowledge Graph Embedding via Reasoning over
Entities, Relations, and Text,” Future Generation Computer Systems,
vol. 91, pp. 426–433, 2019.

[25] D. Li, L. Huang, H. Ji, and J. Han, “Biomedical Event Extraction
based on Knowledge-driven Tree-LSTM,” in NAACL-HLT 2019: Annual
Conference of
the Association for
the North American Chapter of
Computational Linguistics, 2019, pp. 1421–1430.

[26] N. Vedula, P. Maneriker, and S. Parthasarathy, “BOLT-K: Bootstrapping
Ontology Learning via Transfer of Knowledge,” in The World Wide Web
Conference, 2019, pp. 1897–1908.

[27] G. Wohlgenannt and F. Minic, “Using Word2Vec to Build a Simple
Ontology Learning System,” in International Semantic Web Conference,
2016.

[28] B. Ganesan, R. Dasgupta, A. Parekh, H. Patel, and B. Reinwald, “A
Neural Architecture for Person Ontology Population,” arXiv preprint
arXiv:2001.08013, 2020.

[29] Q. Liu, M. J. Kusner, and P. Blunsom, “A Survey on Contextual

Embeddings,” arXiv preprint arXiv:2003.07278, 2020.

[30] A. Ezen-Can, “A Comparison of LSTM and BERT for Small Corpus,”

arXiv preprint arXiv:2009.05451, 2020.

[31] L. Obrst, P. Chase, and R. Markeloff, “Developing an Ontology of the

Cyber Security Domain,” in STIDS, 2012, pp. 49–56.

[32] H. Gasmi, J. Laval, and A. Bouras, “Cold-start Cybersecurity Ontology
Population using Information Extraction with LSTM,” in International

Conference on Cyber Security for Emerging Technologies.
pp. 1–6.

IEEE, 2019,

[33] J. H. Lau and T. Baldwin, “An Empirical Evaluation of Doc2Vec with
Practical Insights into Document Embedding Generation,” arXiv preprint
arXiv:1607.05368, 2016.

[34] L. Sanagavarapu, S. Gollapudi, S. Chimalakonda, Y. Reddy, and
V. Choppella, “A Lightweight Approach for Evaluating Sufﬁciency of
Ontologies,” in SEKE, 2017.

[35] C. L. Jones, R. A. Bridges, K. M. Huffer, and J. R. Goodall, “Towards
a Relation Extraction Framework for Cyber-security Concepts,” in
Proceedings of
the 10th Annual Cyber and Information Security
Research Conference, 2015, pp. 1–4.

[36] V. Mulwad, W. Li, A.

Joshi, T. Finin, and K. Viswanathan,
“Extracting Information about Security Vulnerabilities from Web Text,”
in Proceedings of the IEEE/WIC/ACM International Conferences on Web
Intelligence and Intelligent Agent Technology, vol. 3.
IEEE, 2011, pp.
257–260.

[37] R. Manikandan, K. Madgula, and S. Saha, “Cybersecurity Text Analysis
using Convolutional Neural Network and Conditional Random Fields,”
in Proceedings of
the 12th International Workshop on Semantic
Evaluation, 2018, pp. 868–873.

[38] P. Exner and P. Nugues, “Entity Extraction: From Unstructured Text to
DBpedia RDF Triples,” in Proceedings of the WoLE@ ISWC, 2012, pp.
58–69.

[39] M. Sabou, C. Wroe, C. Goble,

“Learning
Domain Ontologies for Web Service Descriptions: An Experiment in
Bioinformatics,” in Proceedings of the 14th International Conference
on World Wide Web, 2005, pp. 190–198.

and G. Mishne,

