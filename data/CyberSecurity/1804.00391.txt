8
1
0
2

g
u
A
2
2

]
T
G
.
s
c
[

2
v
1
9
3
0
0
.
4
0
8
1
:
v
i
X
r
a

Securing Infrastructure Facilities: When
does proactive defense help?

Manxi Wu, and Saurabh Amin ∗

Abstract

Infrastructure systems are increasingly facing new security threats due to the
vulnerabilities of cyber-physical components that support their operation. In this
article, we investigate how the infrastructure operator (defender) should prioritize
the investment in securing a set of facilities in order to reduce the impact of a
strategic adversary (attacker) who can target a facility to increase the overall usage
cost of the system. We adopt a game-theoretic approach to model the defender-
attacker interaction and study two models: normal-form game – where both players
move simultaneously; and sequential game – where attacker moves after observing
the defender’s strategy. For each model, we provide a complete characterization of
how the set of facilities that are secured by the defender in equilibrium vary with the
costs of attack and defense. Importantly, our analysis provides a sharp condition
relating the cost parameters for which the defender has the ﬁrst mover advantage.
Speciﬁcally, we show that to fully deter the attacker from targeting any facility, the
defender needs to proactively secure all “vulnerable facilities” at an appropriate level
of eﬀort. We illustrate the outcome of the attacker-defender interaction on a simple
transportation network. We also suggest a dynamic learning setup to understand
how this outcome can aﬀect the ability of imperfectly informed users to make their
decisions about using the system in the post-attack stage.

Index terms: Infrastructure security, Normal form game, Sequential game.

1

Introduction

In this article, we consider the problem of strategic allocation of defense eﬀort to secure
one or more facilities of an infrastructure system that is prone to a targeted attack by
a malicious adversary. The setup is motivated by the recent incidents and projected
threats to critical infrastructures such as transportation, electricity, and urban water net-
works ([39], [42], [44], and [35]). Two of the well-recognized security concerns faced by
infrastructure operators are: (i) How to prioritize investments among facilities that are

∗M. Wu is with the Institute for Data, Systems, and Society, and S. Amin is with the Department
of Civil and Environmental Engineering, Massachusetts Institute of Technology (MIT), Cambridge, MA,
USA {manxiwu,amins}@mit.edu

1

 
 
 
 
 
 
heterogeneous in terms of the impact that their compromise can have on the overall ef-
ﬁciency (or usage cost) of the system; and (ii) Whether or not an attacker can be fully
deterred from launching an attack by proactively securing some of the facilities. Our
work addresses these questions by focusing on the most basic form of strategic interac-
tion between the system operator (defender) and an attacker, modeled as a normal form
(simultaneous) or a sequential (Stackelberg) game. The normal form game is relevant to
situations in which the attacker cannot directly observe the chosen security plan, whereas
the sequential game applies to situations where the defender proactively secures some
facilities, and the attacker can observe the defense strategy.

In recent years, many game-theoretical models have been proposed to study problems
in cyber-physical security of critical infrastructure systems; see [5], and [36] for a survey
of these models. These models are motivated by the questions of strategic network design
([25], [34] and [46]), intrusion detection ([18], [4], [23], and [47]), interdependent security
([40], and [6]), network interdiction ([50], and [22]), and attack-resilient estimation and
control ([17], and [48]).

Our model is relevant for assessing strategic defense decisions for an infrastructure
system viewed as a collection of facilities.
In our model, each facility is considered as
a distinct entity for the purpose of investment in defense, and multiple facilities can be
covered by a single investment strategy. The attacker can target a single facility and
compromise its operation, thereby aﬀecting the overall operating eﬃciency of the system.
Both players choose randomized strategies. The performance of the system is evaluated
by a usage cost, whose value depends on the actions of both players. In particular, if
an undefended facility is targeted by the attacker, it is assumed to be compromised, and
this outcome is reﬂected as a change in the usage cost. Naturally, the defender aims
to maintain a low usage cost, while the attacker wishes to increase the usage cost. The
attacker (resp. defender) incurs a positive cost in targeting (resp. securing) a unit facility.
Thus, both players face a trade-oﬀ between the usage cost and the attack/defense costs,
which results in qualitatively diﬀerent equilibrium regimes.

We analyze both normal form and sequential games in the above-mentioned setting.
First, we provide a complete characterization of the equilibrium structure in terms of
the relative vulnerability of diﬀerent facilities and the costs of defense/attack for both
games. Secondly, we identify ranges of attack and defense costs for which the defender
gets the ﬁrst mover advantage by investing in proactive defense. Furthermore, we relate
the outcome of this game (post-attack stage) to a dynamic learning problem in which the
users of the infrastructure system are not fully informed about the realized security state
(i.e. the identity of compromised facility).

We now outline our main results. To begin our analysis, we make the following ob-
servations. Analogous to [24], we can represent the defender’s mixed strategy by a vector
with elements corresponding to the probabilities for each facility being secured. The de-
fender’s mixed strategy can also be viewed as her eﬀort on each facility. Moreover, the
attacker/defender only targets/secures facilities whose disruption will result in an increase
in the usage cost (Proposition 1). If the increase in the usage cost of a facility is larger
than the cost of attack, then we say that it is a vulnerable facility.

Our approach to characterizing Nash equilibrium (NE) of the normal form game is

2

based on the fact that it is strategically equivalent to a zero-sum game. Hence, the set
of attacker’s equilibrium strategies can be obtained as the optimal solution set of a linear
optimization program (Proposition 2). For any given attack cost, we show that there exists
a threshold cost of defense, which distinguishes two equilibrium regime types, named as
type I and type II regimes. Theorem 1 shows that when the defense cost is lower than
the cost threshold (type I regimes), the total attack probability is positive but less than
1, and all vulnerable facilities are secured by the defender with positive probability. On
the other hand, when the defense cost is higher than the threshold (type II regimes), the
total attack probability is 1, and some vulnerable facilities are not secured at all.

We develop a new approach to characterize the subgame perfect equilibrium (SPE)
of the sequential game, noting that the strategic equivalence to zero-sum game no longer
holds in this case. In this game, the defender, as the ﬁrst mover, either proactively secures
all vulnerable facilities with a threshold security eﬀort so that the attacker does not target
any facility, or leaves at least one vulnerable facility secured with an eﬀort less than the
threshold while the total attack probability is 1. For any attack cost, we establish another
threshold cost of the defense, which is strictly higher than the corresponding threshold in
the normal form game. This new threshold again distinguishes the equilibrium strategies
into two regime types, named as type (cid:101)I and type (cid:101)II regimes. Theorem 2 shows that
when the defense cost is lower than the cost threshold (type (cid:101)I regimes), the defender can
fully deter the attacker by proactively securing all vulnerable facilities with the threshold
security eﬀort. On the other hand, when the defense cost is higher than the threshold
(type (cid:101)II regimes), the defender maintains the same level of security eﬀort as that in NE,
while the total attack probability is 1.

Our characterization shows that both NE and SPE satisfy the following intuitive
properties: (i) Both the defender and attack prioritize the facilities that results in a high
usage cost when compromised; (ii) The attack and defense costs jointly determine the
set of facilities that are targeted or secured in equilibrium. On one hand, as the attack
cost decreases, more facilities are vulnerable to attack. On the other hand, as the defense
cost decreases, the defender secures more facilities with positive eﬀort, and eventually
when the defense cost is below a certain threshold (deﬁned diﬀerently in each game),
all vulnerable facilities are secured with a positive eﬀort; (iii) Each player’s equilibrium
payoﬀ is non-decreasing in the opponent’s cost, and non-increasing in her own cost.

It is well-known in the literature on two player games that so long as both players can
choose mixed strategies, the equilibrium utility of the ﬁrst mover in a sequential game
is no less than that in a normal form game ([8] (pp. 126), [49]). However, cases can be
found where the ﬁrst mover advantage changes from positive to zero when the attacker’s
observed signal of the defender’s strategy is associated with a noise ([7]). In the security
game setting, the paper [12] analyzed a game where there are two facilities, and the
attacker’s valuation of each facility is private information. They identify a condition
under which the defender’s equilibrium utility is strictly higher when his strategy can be
observed by the attacker. In contrast, our model considers multiple facilities, and assumes
that both players have complete information of the usage cost of each facility.

In fact, for our model, we are able to provide sharp conditions under which proactive
defense strictly increases the defender’s utility. Given any attack cost, unless the defense

3

cost is “relatively high” (higher than the threshold cost in the sequential game), proactive
defense is advantageous in terms of strictly improving the defender’s utility and fully
deterring the attack. However, if the defense cost is “relatively medium” (lower than the
threshold cost in sequential game, but higher than that in the normal form game), a higher
security eﬀort on each vulnerable facility is required to gain the ﬁrst mover advantage.
Finally, if the defense cost is “relatively low” (lower than the threshold cost in the normal
form game), then the defender can gain advantage by simply making the ﬁrst move with
the same level of security eﬀort as that in the normal form game.

Note that our approach to characterizing NE and SPE can be readily extended to
models with facility-dependent cost parameters and less than perfect defense. We conjec-
ture that a diﬀerent set of techniques will be required to tackle the more general situation
in which the attacker can target multiple facilities at the same time; see [22] for related
work in this direction. However, even when the attacker targets multiple facilities, one can
ﬁnd game parameters for which the defender is always strictly better oﬀ in the sequential
game.

Finally, we provide a brief discussion on rational learning dynamics, aimed at under-
standing how the outcome of the attacker-defender interaction – which may or may not
result in compromise of a facility (state) – eﬀects the ability of system users to learn
about the realized state through a repeated use of the system. A key issue is that the
uncertainty about the realized state can signiﬁcantly impact the ability of users to make
decisions to ensure that their long-term cost corresponds to the true usage cost of the
system. We explain this issue using a simple transportation network as an example, in
which rational travelers (users) need to learn about the identity of the facility that is likely
to be compromised using imperfect information about the attack and noisy realizations
of travel time in each stage of a repeated routing game played over the network.

The results reported in this article contribute to the study on the allocation of defense
resources on facilities against strategic adversaries, as discussed in [41] and [12]. The
underlying assumption that drives our analysis is that an attack on each facility can be
treated independently for the purpose of evaluating its impact on the overall usage cost.
Other papers that also make this assumption include [11], [13], [2], and [16].
Indeed,
when the impact of facility compromises are related to the network structure, facilities
can no longer be treated independently, and the network structure becomes a crucial
factor in analyzing the defense strategy ([26]). Additionally, network connections can also
introduce the possibility of cascading failure among facilities, which is addressed in [1],
and [30]. These settings are not covered by our model.

The paper is structured as follows: In Sec. 2, we introduce the model of both games,
and discuss the modeling assumptions. We provide preliminary results to facilitate our
analysis in Sec. 3. Sec. 4 characterizes NE, and Sec. 5 characterizes SPE. Sec. 6
compares both games. We discuss some extensions of our model and brieﬂy introduce
dynamic aspects in Sec. 7.

All proofs are included in the appendix.

4

2 The Model

2.1 Attacker-Defender Interaction: Normal Form versus Sequen-

tial Games

Consider an infrastructure system modeled as a set of components (facilities) E. To
defend the system against an external malicious attack, the system operator (defender)
can secure one or more facilities in E by investing in appropriate security technology.
The set of facilities in question can include cyber or physical elements that are crucial
to the functioning of the system. These facilities are potential targets for a malicious
adversary whose goal is to compromise the overall functionality of the system by gaining
unauthorized access to certain cyber-physical elements. The security technology can be a
combination of proactive mechanisms (authentication and access control) or reactive ones
(attack detection and response). Since our focus is on modeling the strategic interaction
between the attacker and defender at a system level, we do not consider the speciﬁc
functionalities of individual facilities or the protection mechanisms oﬀered by various
technologies.

We now introduce our game theoretic model. Let us denote a pure strategy of the
defender as sd ⊆ E, with sd ∈ Sd = 2E. The cost of securing any facility is given by the
parameter pd ∈ R>0. Thus, the total defense cost incurred in choosing a pure strategy
sd is |sd| · pd, where |sd| is the cardinality of sd (i.e., the number of secured facilities).
The attacker chooses to target a single facility e ∈ E or not to attack. We denote a pure
strategy of the attacker as sa ∈ Sa = E ∪ {∅}. The cost of an attack is given by the
parameter pa ∈ R>0, and it reﬂects the eﬀort that attacker needs to spend in order to
successfully targets a single facility and compromise its operation.

We assume that prior to the attack, the usage cost of the system is C∅. This cost
represents the level of eﬃciency with which the defender is able to operate the system
for its users. A higher usage cost reﬂects lower eﬃciency. If a facility e is targeted by
the attacker but not secured by the defender, we consider that e is compromised and the
usage cost of the system changes to Ce. Therefore, given any pure strategy proﬁle (sd, sa),
the usage cost after the attacker-defender interaction, denoted C(sd, sa), can be expressed
as follows:

C(sd, sa) =

(cid:26) Ce,
C∅,

if sa = e, and sd (cid:54)(cid:51) e,
otherwise.

(1)

To study the eﬀect of timing of the attacker-defender interaction, prior literature on
security games has studied both normal form game and sequential games ([5]). We study
both models in our setting. In the normal form game, denoted Γ, the defender and the
attacker move simultaneously. On the other hand, in the sequential game, denoted (cid:101)Γ,
the defender moves in the ﬁrst stage and the attacker moves in the second stage after
observing the defender’s strategy. We allow both players to use mixed strategies. In Γ,
we denote the defender’s mixed strategy as σd
∈ ∆(Sd), where σd(sd) is
the probability that the set of secured facilities is sd. Similarly, a mixed strategy of the
∈ ∆(Sa), where σa(sa) is the probability that the realized
attacker is σa

∆= (σd(sd))sd∈Sd

∆= (σa(sa))sa∈Sa

5

∆= ((cid:101)σd(sd))sd∈Sd

action is sa. Let σ = (σd, σa) denote a mixed strategy proﬁle. In (cid:101)Γ, the defender’s mixed
∈ ∆(Sd) is deﬁned analogously to that in Γ. The attacker’s
strategy (cid:101)σd
strategy is a map from ∆(Sd) to ∆(Sa), denoted by (cid:101)σa((cid:101)σd) ∆= ((cid:101)σa(sa, (cid:101)σd))sa∈Sa
∈ ∆(Sa),
where (cid:101)σa(sa, (cid:101)σd) is the probability that the realized action is sa when the defender’s
strategy is (cid:101)σd. A strategy proﬁle in this case is denoted as (cid:101)σ = ((cid:101)σd, (cid:101)σa((cid:101)σd)).

The defender’s utility is comprised of two parts: the negative of the usage cost as
given in (1) and the defense cost incurred in securing the system. Similarly, the attacker’s
utility is the usage cost net the attack cost. For a pure strategy proﬁle (sd, sa), the utilities
of defender and attacker can be respectively expressed as follows:

ud(sd, sa) = −C(sd, sa) − pd · |sd|,

ua(sd, sa) = C(sd, sa) − pa · 1{sa (cid:54)= ∅}.

For a mixed strategy proﬁle (σd, σa), the expected utilities can be written as:

Ud(σd, σa) =

Ua(σd, σa) =

(cid:88)

(cid:88)

sd∈Sd
(cid:88)

sa∈Sa
(cid:88)

sd∈Sd

sa∈Sa

ud(sd, sa) · σa(sa) · σd(sd) = −Eσ[C] − pd · Eσd[|sd|],

ua(sd, sa) · σa(sa) · σd(sd) = Eσ[C] − pa · Eσa[|sa|],

(2a)

(2b)

where Eσ[C] is the expected usage cost, and Eσd[|sd|] (resp. Eσa[|sa|]) is the expected
number of defended (resp. targeted) facilities, i.e.:

Eσ[C] =

(cid:88)

(cid:88)

C(sd, sa) · σa(sa) · σd(sd),

Eσd[|sd|] =

sa∈Sa
(cid:88)

sd∈Sd
|sd|σd(sd), Eσa[|sa|] =

sd∈Sd

(cid:88)

e∈E

σa(e).

An equilibrium outcome of the game Γ is deﬁned in the sense of Nash Equilibrium

(NE). A strategy proﬁle σ∗ = (σ∗

d, σ∗

a) is a NE if:

Ud(σ∗
Ua(σ∗

d, σ∗
d, σ∗

a) ≥ Ud(σd, σ∗
a) ≥ Ua(σ∗

a),
d, σa),

∀σd ∈ ∆(Sd),
∀σa ∈ ∆(Sa).

In the sequential game (cid:101)Γ, the solution concept is that of a Subgame Perfect Equi-
librium (SPE), which is also known as Stackelberg equilibrium. A strategy proﬁle (cid:101)σ∗ =
((cid:101)σ∗

d, (cid:101)σ∗

a((cid:101)σd)) is a SPE if:
d)) ≥ Ud((cid:101)σd, (cid:101)σ∗
a((cid:101)σ∗
d, (cid:101)σ∗
Ud((cid:101)σ∗
a((cid:101)σd)),
Ua((cid:101)σd, (cid:101)σ∗
a((cid:101)σd)) ≥ Ua((cid:101)σd, (cid:101)σa((cid:101)σd)),

∀(cid:101)σd ∈ ∆(Sd),
∀(cid:101)σd ∈ ∆(Sd),

∀(cid:101)σa((cid:101)σd) ∈ ∆(Sa).

(3a)
(3b)

Since both Sd and Sa are ﬁnite sets, and we consider mixed strategies, both NE and SPE
exist.

6

2.2 Model Discussion

One of our main assumptions is that the attacker’s capability is limited to targeting at
most one facility, while the defender can invest in securing multiple facilities. Although
this assumption appears to be somewhat restrictive, it enables us to derive analytical
results on the equilibrium structure for a system with multiple facilities. The assumption
can be justiﬁed in situations where the attacker can only target system components in
a localized manner. Thus, a facility can be viewed as a set of collocated components
that can be simultaneously targeted by the attacker. For example, in a transportation
system, a facility can be a vulnerable link (edge), or a set of links that are connected by
a vulnerable node (an intersection or a hub). In Sec. 7.1, we brieﬂy discuss the issues in
solving a more general game where multiple facilities can be simultaneously targeted by
the attacker.

Secondly, our model assumes that the costs of attack and defense are identical across all
facilities. We make this assumption largely to avoid the notational burden of analyzing the
eﬀect of facility-dependent attack/defense cost parameters on the equilibrium structures.
In fact, as argued in Sec. 7.1, the qualitative properties of equilibria still hold when cost
parameters are facility-dependent. However, characterizing the equilibrium regimes in
this case can be quite tedious, and may not necessarily provide new insights on strategic
defense investments.

Thirdly, we allow both players to choose mixed strategies. Indeed, mixed strategies
are commonly considered in security games as a pure NE may not always exists. A mixed
the
strategy entails a player’s decision to introduce randomness in her behavior, i.e.
manner in which a facility is targeted (resp. secured) by the attacker (resp. defender).
Consider for example, the problem of inspecting a transportation network facing risk
of a malicious attack. In this problem, a mixed strategy can be viewed as randomized
allocation of inspection eﬀort on subsets of facilities. Mixed strategy of the attacker can
be similarly interpreted.

Fourthly, we assume that the defender has the technological means to perfectly secure
a facility. In other words, an attack on a secured facility cannot impact its operation. As
we will see in Sec. 3, the defender’s mixed strategy can be viewed as the level of security
eﬀort on each facility, where the eﬀort level 1 (maximum) means perfect security, and 0
(minumum) means no security. Under this interpretation, the defense cost pd is the cost
of perfectly securing a unit facility (i.e., with maximum level of eﬀort), and the expected
defense cost is pd scaled by the security eﬀort deﬁned by the defender’s mixed strategy.

Fifthly, we do not consider a speciﬁc functional form for modeling the usage cost. In
our model, for any facility e ∈ E, the diﬀerence between the post-attack usage cost Ce
and the pre-attack cost C∅ represents the change of the usage cost of the system when
e is compromised. This change can be evaluated based on the type of attacker-defender
interaction one is interested in studying. For example, in situations when attack on a
facility results in its complete disruption, one can use a connectivity-based metric such as
the number of active source-destination paths or the number of connected components to
evaluate the usage cost ([25] and [26]). On the other hand, in situations when facilities
are congestible resources and an attack on a facility increases the users’ cost of accessing

7

it, the system’s usage cost can be deﬁned as the average cost for accessing (or routing
through) the system. This cost can be naturally evaluated as the user cost in a Wardrop
equilibrium ([13]), although socially optimal cost has also been considered in the literature
([3]).

Finally, we note that for the purpose of our analysis, the usage cost as given in (1)
fully captures the impact of player’ actions on the system. For any two facilities e, e(cid:48) ∈ E,
the ordering of Ce and Ce(cid:48) determines the relative scale of impact of the two facilities.
As we show in Sec. 4–5, the order of cost functions in the set {Ce}e∈E plays a key role
in our analysis approach.
Indeed the usage cost is intimately linked with the network
structure and way of operation (for example, how individual users are routed through the
network and how their costs are aﬀected by a compromised facility). Barring a simple (yet
illustrative) example, we do not elaborate further on how the network structure and/or
the functional form of usage cost changes the interpretations of equilibrium outcome. We
also do not discuss the computational aspects of arriving at the ordering of usage costs.

3 Rationalizable Strategies and Aggregate Defense

Eﬀort

We introduce two preliminary results that are useful in our subsequent analysis. Firstly,
we show that the defender’s strategy can be equivalently represented by a vector of facility-
speciﬁc security eﬀort levels. Secondly, we identify the set of rationalizable strategies of
both players.

For any defender’s mixed strategy σd ∈ ∆(Sd), the corresponding security eﬀort vector

is ρ(σd) = (ρe(σd))e∈E, where ρe(σd) is the probability that facility e is secured:

ρe(σd) =

(cid:88)

sd(cid:51)e

σd(sd).

(4)

In other words, ρe(σd) is the level of security eﬀort exerted by the defender on facility
e under the security plan σd. Since σd(sd) ≥ 0 for any sd ∈ Sd, we obtain that 0 ≤
ρe(σd) = (cid:80)
σd(sd) = 1. Hence, any σd induces a valid probability
vector ρ ∈ [0, 1]|E|. In fact, any vector ρ ∈ [0, 1]|E| can be induced by at least one feasible
σd. The following lemma provides a way to explicitly construct one such feasible strategy.

sd(cid:51)e σd(sd) ≤ (cid:80)

sd∈Sd

Lemma 1. Consider any feasible security eﬀort vector ρ ∈ [0, 1]|E|. Let m be the number
of distinct positive values in ρ, and deﬁne ρ(i) as the i-th largest distinct value in ρ, i.e.
ρ(1) > · · · > ρ(m). The following defender’s strategy is feasible and induces ρ:

σd((cid:8)e ∈ E|ρe ≥ ρ(i)
σd((cid:8)e ∈ E|ρe ≥ ρ(m)
σd(∅) = 1 − ρ(1).

(cid:9)) = ρ(i) − ρ(i+1),
(cid:9)) = ρ(m),

∀i = 1, . . . , m − 1

(5a)

(5b)
(5c)

For any remaining sd ∈ Sd, σd(sd) = 0.

8

We now re-express the player utilities in (2) in terms of (ρ(σd), σa) as follows:

Ud(σd, σa) = −

(cid:32)

(cid:88)

(cid:88)

(cid:33)

σd(sd)C(sd, sa)

σa(sa) −

(cid:33)

σd(sd)C(sd, e)

σa(e) − C∅σa(∅) −

(cid:33)

|sd|σd(sd)

pd

(cid:32)

(cid:88)

sd∈Sd

(cid:33)

ρe(σd)

pd

(cid:32)

(cid:88)

e∈E

(cid:33)

(cid:32)

σd(sd)

C∅ +

1 −

(cid:33)

(cid:33)

σd(sd)

Ce

σa(e) − C∅σa(∅)

(cid:88)

sd(cid:51)e

sd∈Sd

(cid:88)

sa∈Sa
(cid:32)

(cid:88)

e∈E

= −

sd∈Sd

(cid:32)(cid:32)

(cid:88)

(cid:88)

(1)
= −

e∈E
(cid:32)

(cid:88)

e∈E

−

sd(cid:51)e

(cid:33)

ρe(σd)

pd

= −

(cid:88)

e∈E

(ρe(σd) ((C∅ − Ce) σa(e) + pd) + Ceσa(e)) − C∅σa(∅),

(6a)

Ua(σd, σa) =

(cid:88)

e∈E

(ρe(σd) (C∅ − Ce) σa(e) + Ceσa(e)) + C∅σa(∅) −

(cid:33)

σa(e)

pa.

(6b)

(cid:32)

(cid:88)

e∈E

Thus, for any given attack strategy and any two defense strategies, if the induced security
eﬀort vectors are identical, then the corresponding utility for each player is also identical.
Henceforth, we denote the player utilities as Ud(ρ, σa) and Ua(ρ, σa), and use σd and
ρe(σd) interchangeably in representing the defender’s strategy. For the sequential game
(cid:101)Γ, we analogously denote the security eﬀort vector given the strategy (cid:101)σd as ˜ρ((cid:101)σd), and the
defender’s utility (resp. attacker’s utility) as (cid:101)Ud(˜ρ, (cid:101)σa) (resp. (cid:101)Ua(˜ρ, (cid:101)σa)).

We next characterize the set of rationalizable strategies. Note that the post-attack
usage cost Ce can increase or remain the same or even decrease, in comparison to the
pre-attack cost C∅. Let the facilities whose damage result in an increased usage cost be
grouped in the set ¯E. Similarly, let (cid:98)E denote the set of facilities such that a damage to
any one of them has no eﬀect on the usage cost. Finally, the set of remaining facilities is
denoted as

(cid:98)
E. Thus:

¯E ∆= {e ∈ E|Ce > C∅} ,
(cid:98)E ∆= {e ∈ E|Ce = C∅} ,
(cid:98)
E ∆= {e ∈ E|Ce < C∅} .

(7a)

(7b)

(7c)

(cid:98)
Clearly, ¯E ∪ (cid:98)E ∪
E = E. The following proposition shows that in a rationalizable strategy
proﬁle, the defender does not secure facilities that are not in ¯E, and the attacker only
considers targeting the facilities that are in ¯E.

Proposition 1. The rationalizable action sets for the defender and attacker are given by
2 ¯E and ¯E ∪ {∅}, respectively. Hence, any equilibrium strategy proﬁle (ρ∗, σ∗
a) in Γ (resp.

9

(˜ρ∗, (cid:101)σ∗

a) in (cid:101)Γ) satisﬁes:

ρ∗
e = σ∗
e = (cid:101)σ∗
˜ρ∗

∀e ∈ E \ ¯E,
a(e) = 0,
a(e, ˜ρ) = 0, ∀e ∈ E \ ¯E,

∀˜ρ ∈ [0, 1]E.

If ¯E = ∅, then the attacker/defender does not attack/secure any facility in equilibrium.
Henceforth, to avoid triviality, we assume ¯E (cid:54)= ∅. Additionally, we deﬁne a partition of
facilities in ¯E such that all facilities with identical Ce are grouped in the same set. Let
the number of distinct values in {Ce}e∈ ¯E be K, and C(k) denote the k-th highest distinct
value in the set {Ce}e∈ ¯E. Then, we can order the usage costs as follows:

C(1) > C(2) > · · · > C(K) > C∅.

(8)

We denote ¯E(k) as the set of facilities such that if any e ∈ ¯E(k) is damaged, the usage
∆= | ¯E(k)|. Clearly,
cost Ce = C(k), i.e. ¯E(k)
¯E(k) = ¯E, and (cid:80)K
k=1 E(k) = | ¯E|. Facilities in the same group have identical impact on
∪K
the infrastructure system when compromised.

(cid:9). We also deﬁne E(k)

∆= (cid:8)e ∈ ¯E|Ce = C(k)

k=1

4 Normal Form Game Γ

In this section, we provide complete characterization of the set of NE for any given attack
In Sec. 4.1, we show that Γ is strategically
and defense cost parameters in game Γ.
equivalent to a zero-sum game, and hence the set of attacker’s equilibrium strategies can
be solved by a linear program. In Sec. 4.2, we show that the space of cost parameters
(pa, pd) ∈ R2

>0 can be partitioned into qualitatively distinct equilibrium regimes.

4.1 Strategic Equivalence to Zero-Sum Game

Our notion of strategic equivalence is the same as the best-response equivalence deﬁned
in [43]. If Γ and another game Γ0 are strategically equivalent, then given any strategy
of the defender (resp. attacker), the set of attacker’s (resp. defender’s) best responses is
identical in the two games. This result forms the basis of characterizing the set of NE.

We deﬁne the utility functions of the game Γ0 as follows:

d (σd, σa) = −Eσ[C] − Eσd[|sd|] · pd + pa · Eσa[|sa|],
U 0
a (σd, σa) = Eσ[C] + Eσd[|sd|] · pd − pa · Eσa[|sa|].
U 0

(9a)
(9b)

Thus, Γ0 is a zero-sum game. We denote the set of defender’s (resp. attacker’s) equilibrium
strategies in Γ0 as Σ0

d (resp. Σ0

a).

Lemma 2. The normal form game Γ is strategically equivalent to the zero sum game
Γ0. The set of defender’s (resp. attacker’s) equilibrium strategies in Γ is Σ∗
d ≡ Σ0
d (resp.
Σ∗
d ∈ Σ∗
a) is an equilibrium
strategy proﬁle of Γ.

a). Furthermore, for any σ∗

d and any σ∗

a ≡ Σ0

a ∈ Σ∗

a, (σ∗

d, σ∗

10

Based on Lemma 2, the set of attacker’s equilibrium strategies Σ∗

a can be expressed

as the optimal solution set of a linear program.

Proposition 2. The set Σ∗
problem:

a is the optimal solution set of the following optimization

max
σa

V (σa)

s.t. V (σa) =

(cid:88)

e∈ ¯E

min {σa(e) · (C∅ − pa) + pd, σa(e) · (Ce − pa)} + σa(∅) · C∅,

(10a)

(cid:88)

σa(e) + σa(∅) = 1,

e∈ ¯E
σa(∅) ≥ 0,

σa(e) ≥ 0,

∀e ∈ ¯E.

Furthermore, (10) is equivalent to the following linear optimization program:

max
σa,v

(cid:88)

e∈ ¯E

ve + σa(∅) · C∅

s.t. σa(e) · (C∅ − pa) + pd − ve ≥ 0,
σa(e) · (Ce − pa) − ve ≥ 0,
(cid:88)

σa(e) + σa(∅) = 1,

∀e ∈ ¯E,

∀e ∈ ¯E,

σa(e) ≥ 0,
where v = (ve)e∈ ¯E is an | ¯E|-dimensional variable.

e∈ ¯E
σa(∅) ≥ 0,

∀e ∈ ¯E.

(10b)

(10c)

(11a)
(11b)

(11c)

(11d)

In Proposition 2, the objective function V (σa) is a piecewise linear function in σa.

Furthermore, given any σa and any e ∈ ¯E, we can write:

min {σa(e) · (C∅ − pa) + pd, σa(e) · (Ce − pa)}
(cid:40)

=

σa(e) · (C∅ − pa) + pd
σa(e) · (Ce − pa)

if σa(e) > pd
if σa(e) ≤ pd

Ce−C∅

Ce−C∅

,
.

(12)

Thus, we can observe that if σa(e) equals to pd/ (Ce − C∅), then −σa(e)·C∅ −pd = −σa(e)·
Ce, i.e. if a facility e is targeted with the threshold attack probability pd/(Ce − C∅), the
defender is indiﬀerent between securing e versus not. The following lemma analyzes the
defender’s best response to the attacker’s strategy, and shows that no facility is targeted
with probability higher than the threshold probability in equilibrium.

Lemma 3. Given any strategy of the attacker σa ∈ ∆(Sa), for any defender’s security
eﬀort ρ that is a best response to σa, denoted ρ ∈ BR(σa), the security eﬀort ρe on each
facility e ∈ E satisﬁes:




(cid:110) ¯E|σa(e) < pd
(cid:110) ¯E|σa(e) = pd
(cid:110) ¯E|σa(e) > pd

∈ [0, 1],

∪ (cid:98)E ∪

(cid:98)
E,

∀e ∈

∀e ∈

∀e ∈

= 1,

= 0,

(13)

Ce−C∅

Ce−C∅

ρe

(cid:111)

(cid:111)

(cid:111)

.

,

Ce−C∅

11

Furthermore, in equilibrium, the attacker’s strategy σ∗

a satisﬁes:

σ∗
a(e) ≤

pd
Ce − C∅

σ∗
a(e) = 0,

, ∀e ∈ ¯E,

∀e ∈ E \ ¯E.

(14a)

(14b)

Lemma 3 highlights a key property of NE: The attacker does not target at any facility
e ∈ ¯E with probability higher than the threshold pd/(Ce − C∅), and the defender allo-
cates a non-zero security eﬀort only on the facilities that are targeted with the threshold
probability.

Intuitively, if a facility e were to be targeted with a probability higher than the thresh-
old pd/(Ce − C∅), then the defender’s best response would be to secure that facility with
probability 1, and the attacker’s expected utility will be −C∅ − paσa(e), which is smaller
than −C∅ (utility of no attack). Hence, the attacker would be better oﬀ by choosing the
no attack action.

Now, we can re-write V (σa) as deﬁned in (10) as follows:

V (σa)

(14)
=

(cid:88)

e∈{ ¯E|σa(e)≤

pd
Ce−C∅

}

σa(e) (Ce − pa) + C∅ · σa(∅),

(15)

and the set of attacker’s equilibrium strategies maximizes this function.

4.2 Characterization of NE in Γ

We are now in the position to introduce the equilibrium regimes. Each regime corresponds
to a range of cost parameters such that the qualitative properties of equilibrium (i.e. the
set of facilities that are targeted and secured) do not change in the interior of each regime.
We say that a facility e is vulnerable if Ce − pa > C∅. Therefore, given any attack cost
pa, the set of vulnerable facilities is given by { ¯E|Ce − pa > C∅}. Clearly, only vulnerable
facilities are likely targets of the attacker. If pa > C(1) − C∅, then there are no vulnerable
facilities. In contrast, if pa < C(1)−C∅, we deﬁne the following threshold for the per-facility
defense cost:

¯pd(pa) ∆=

1

(cid:80)

e∈{ ¯E|Ce−pa>C∅}

.

1
Ce−C∅

(16)

We can check that for any i = 1, . . . , K − 1 (resp. i = K), if C(i+1) − C∅ ≤ pa < C(i) − C∅
(resp. 0 < pa < C(K) − C∅), then

¯pd(pa) =

(cid:32) i

(cid:88)

k=1

(cid:33)−1

.

E(k)
C(k) − C∅

(17)

Recall from Lemma 3 that σ∗
pd/(Ce − C∅).

If the defense cost pd < ¯pd(pa), then (cid:80)i

a(e) is upper bounded by the threshold attack probability
< 1, which implies

E(k)pd
C(k)−C∅

k=1

12

that even when the attacker targets each vulnerable facility with the threshold attack
probability, the total probability of attack is still smaller than 1. Thus, the attacker
must necessarily choose not to attack with a positive probability. On the other hand, if
pd > ¯pd(pa), then the no attack action is not chosen by the attacker in equilibrium.

Following the above discussion, we introduce two types of regimes depending on
whether or not pd is higher than the threshold ¯pd(pa).
In type I regimes, denoted as
{Λi|i = 0, . . . , K}, the defense cost pd < ¯pd(pa), whereas in type II regimes, denoted as
{Λj|j = 1, . . . , K}, the defense cost pd > ¯pd(pa). Hence, we say that pd is “relatively low”
(resp. “relatively high”) in comparison to pa in type I regimes (resp. type II regimes).
We formally deﬁne these 2K + 1 regimes as follows:

(a) Type I regimes Λi, i = 0, . . . , K:

• If i = 0:

pa > C(1) − C∅, and pd > 0

• If i = 1, . . . , K − 1:

C(i+1) − C∅ < pa < C(i) − C∅, and 0 < pd <

(cid:33)−1

(cid:32) i

(cid:88)

k=1

E(k)
C(k) − C∅

• If i = K:

0 < pa < C(K) − C∅, and 0 < pd <

(cid:33)−1

(cid:32) K
(cid:88)

k=1

E(k)
C(k) − C∅

(b) Type II regimes, Λj, j = 1, . . . , K:

• If j = 1:

0 < pa < C(1) − C∅, and pd >

(cid:18) E(1)

(cid:19)−1

C(1) − C∅

(18)

(19)

(20)

(21)

• If j = 2, . . . , K:

0 < pa < C(j) − C∅, and

(cid:33)−1

(cid:32) j

(cid:88)

k=1

E(k)
C(k) − C∅

< pd <

(cid:33)−1

(cid:32) j−1
(cid:88)

k=1

E(k)
C(k) − C∅

(22)

We now characterize equilibrium strategy sets Σ∗

d and Σ∗

a in the interior of each regime.1

1For the sake of brevity, we omit the discussion of equilibrium strategies when cost parameters lie
exactly on the regime boundary, although this case can be addressed using the approach developed in
this article.

13

Theorem 1. The set of NE in each regime is as follows:

(a) Type I regimes Λi:

• If i = 0,

ρ∗
e = 0,
σ∗
a(∅) = 1.

∀e ∈ E

• If i = 1, . . . , K,

ρ∗
e =

C(k) − pa − C∅
C(k) − C∅

,

ρ∗
e = 0,

σ∗
a(e) =

pd
C(k) − C∅
(cid:88)

,

σ∗
a(∅) = 1 −

σ∗
a(e).

∀e ∈ ¯E(k),
∀e ∈ E \ (cid:0)∪i
∀e ∈ ¯E(k),

∀k = 1, . . . , i

(cid:1)

¯E(k)

k=1

∀k = 1, . . . , i

e∈∪i

k=1

¯E(k)

(b) Type II regimes Λj:

• j = 1:

ρ∗
e = 0,

0 ≤ σ∗

a(e) ≤

pd
C(1) − C∅

∀e ∈ E
∀e ∈ ¯E(1),

σ∗
a(e) = 1.

(cid:88)

e∈ ¯E(1)

• j = 2, . . . , K:

ρ∗
e =

C(k) − C(j)
C(k) − C∅

,

∀e ∈ ¯E(k), ∀k = 1, . . . , j − 1

(23a)
(23b)

(24a)

(24b)

(24c)

(24d)

(25a)

(25b)

(25c)

(26a)

(26b)

ρ∗
e = 0,

σ∗
a(e) =

0 ≤ σ∗

a(e) ≤

,

,

pd
C(k) − C∅
pd
C(j) − C∅
j−1
(cid:88)

σ∗
a(e) = 1 −

(cid:88)

e∈ ¯E(j)

pd · E(k)
C(k) − C∅

k=1

∀e ∈ E \ (cid:0)∪j−1
∀e ∈ ¯E(k),

k=1

(cid:1)

¯E(k)

∀k = 1, . . . , j − 1 (26c)

∀e ∈ ¯E(j)

.

(26d)

(26e)

Let us discuss the intuition behind the proof of Theorem 1.
Recall from Proposition 2 and Lemma 3 that the set of attacker’s equilibrium strategies
a is the set of feasible mixed strategies that maximizes V (σa) in (15), and the attacker

Σ∗

14

never targets at any facility e ∈ E with probability higher than the threshold pd/(Ce −C∅).
Also recall that the costs {C(k)}K
k=1 are ordered according to (8). Thus, in equilibrium,
the attacker targets the facilities in ¯E(k) with the threshold attack probability starting
from k = 1 and proceeding to k = 2, 3, . . . K until either all the vulnerable facilities are
targeted with the threshold attack probability (and no attack is chosen with remaining
probability), or the total attack probability reaches 1.

Again, from Lemma 3, we know that the defender secures the set of facilities that are
targeted with the threshold attack probability with positive eﬀort. The equilibrium level
of security eﬀort ensures that the attacker gets an identical utility in choosing any pure
strategy in the support of σ∗
a, and this utility is higher or equal to that of choosing any
other pure strategy.

The distinctions between the two regime types are summarized as follows:

(1) In type I regimes, the defense cost pd < ¯pd(pa). The defender secures all vulnerable
facilities with a positive level of eﬀort. The attacker targets at each vulnerable
facility with the threshold attack probability, and the total probability of attack is
less than 1.

(2) In type II regimes, the defense cost pd > ¯pd(pa). The defender only secures a subset
of targeted facilities with positive level of security eﬀort. The attacker chooses the
facilities in decreasing order of Ce − C∅, and targets each of them with the threshold
probability until the attack resource is exhausted, i.e. the total probability of attack
is 1.

5 Sequential game (cid:101)Γ

In this section, we characterize the set of SPE in the game (cid:101)Γ for any given attack and
defense cost parameters. The sequential game (cid:101)Γ is no longer strategically equivalent to
a zero-sum game. Hence, the proof technique we used for equilibrium characterization in
game Γ does not work for the game (cid:101)Γ. In Sec. 5.1, we analyze the attacker’s best response
to the defender’s security eﬀort vector. We also identify a threshold level of security
eﬀort which determines whether or not the defender achieves full attack deterrence in
equilibrium. In Sec. 5.2, we present the equilibrium regimes which govern the qualitative
properties of SPE.

5.1 Properties of SPE

By deﬁnition of SPE, for any security eﬀort vector ˜ρ ∈ [0, 1]|E| chosen by the defender in
the ﬁrst stage, the attacker’s equilibrium strategy in the second stage is a best response
to ˜ρ, i.e. (cid:101)σ∗
a(˜ρ) satisﬁes (3b). As we describe next, the properties of SPE crucially depend
on a threshold security eﬀort level deﬁned as follows:

∆=

(cid:98)ρe

Ce − pa − C∅
Ce − C∅

,

∀e ∈ ¯E.

(27)

15

The following lemma presents the best response correspondence BR(˜ρ) of the attacker:
Lemma 4. Given any ˜ρ ∈ [0, 1]|E|, if ˜ρ satisﬁes ˜ρe ≥ (cid:98)ρe, for all e ∈ { ¯E|Ce − pa > C∅},
then BR(˜ρ) = ∆( ¯E ∗ ∪ {∅}), where:

¯E ∗ ∆= (cid:8) ¯E |Ce − pa > C∅,

˜ρe = (cid:98)ρe

(cid:9) .

Otherwise, BR(˜ρ) = ∆( ¯E (cid:5)), where:

¯E (cid:5) ∆=

argmax
e∈{ ¯E|Ce−pa>C∅}

{˜ρeC∅ + (1 − ˜ρe)Ce} .

(28)

(29)

In words, if each vulnerable facility e is secured with an eﬀort higher or equal to the
threshold eﬀort (cid:98)ρe in (27), then the attacker’s best response is to choose a mixed strategy
with support comprised of all vulnerable facilities that are secured with the threshold level
of eﬀort (i.e., ¯E ∗ as deﬁned in (28)) and the no attack action. Otherwise, the support of
attacker’s strategy is comprised of all vulnerable facilities (pure actions) that maximize the
expected usage cost (see (29)). In particular, no attack action is not chosen in attacker’s
best response.

Now recall that any SPE (˜ρ∗, (cid:101)σ∗

a(˜ρ∗)) must satisfy both (3a) and (3b). Thus, for an
equilibrium security eﬀort ˜ρ∗, an attacker’s best response (cid:101)σa(˜ρ∗) ∈ BR(˜ρ∗) is an equilib-
rium strategy only if both these constraints are satisﬁed. The next lemma shows that
depending on whether the defender secures each vulnerable facility e with the threshold
eﬀort (cid:98)ρe or not, the total attack probability in equilibrium is either 0 or 1. Thus, the
defender being the ﬁrst mover determines whether the attacker is fully deterred from
conducting an attack or not. Additionally, in SPE, the security eﬀort on each vulnerable
facility e is no higher than the threshold eﬀort (cid:98)ρe, and the security eﬀort on any other
edge is 0.

Lemma 5. Any SPE (˜ρ∗, (cid:101)σ∗

(cid:88)

e∈ ¯E

a(e, ˜ρ∗) =
(cid:101)σ∗

a(˜ρ∗)) of the game (cid:101)Γ satisﬁes the following property:
(cid:26) 0,
1,

∀e ∈ { ¯E|Ce − pa > C∅},

if ˜ρ∗
e ≥ (cid:98)ρe,
otherwise.

Additionally, for any e ∈ { ¯E|Ce − pa > C∅}, ˜ρ∗
˜ρ∗
e = 0.

e ≤ (cid:98)ρe. For any e ∈ E \ { ¯E|Ce − pa > C∅},

The proof of this result is based on the analysis of following three cases:
Case 1: There exists at least one facility e ∈ { ¯E|Ce − pa > C∅} such that ˜ρ∗
case, by applying Lemma 4, we know that (cid:101)σ∗
in (29). Hence, the total attack probability is 1.
Case 2: For any e ∈ { ¯E|Ce − pa > C∅}, ˜ρ∗
e > (cid:98)ρe. In this case, the set ¯E ∗ deﬁned in (28) is
empty. Hence, Lemma 4 shows that the total attack probability is 0.
e ≥ (cid:98)ρe, and the set ¯E ∗ in (28) is non-empty.
Case 3: For any e ∈ { ¯E|Ce − pa > C∅}, ˜ρ∗
a(˜ρ∗) ∈ BR(˜ρ∗) = ∆( ¯E ∗ ∪ {∅}). Now assume that
Again from Lemma 4, we know that (cid:101)σ∗
the attacker chooses to target at least one facility e ∈ ¯E ∗ with a positive probability in

e < (cid:98)ρe. In this
a(˜ρ∗) ∈ BR(˜ρ∗) = ∆( ¯E (cid:5)), where ¯E (cid:5) is deﬁned

16

equilibrium. Then, the defender can deviate by slightly increasing the security eﬀort on
each facility in ¯E ∗. By introducing such a deviation, the defender’s security eﬀort satisﬁes
the condition of Case 2, where the total attack probability is 0. Hence, this results in
a higher utility for the defender. Therefore, in any SPE (˜ρ∗, (cid:101)σ∗
a(˜ρ∗)), one cannot have a
second stage outcome in which the attacker targets facilities in ¯E ∗. We can thus conclude
that the total attack probability must be 0 in this case.

In both Cases 2 and 3, we say that the attacker is fully deterred.
Clearly, these three cases are exhaustive in that they cover all feasible security eﬀort
vectors, and hence we can conclude that the total attack probability in equilibrium is
either 0 or 1. Additionally, since the attacker is fully deterred when each vulnerable
facility is secured with the threshold eﬀort, the defender will not further increase the
security eﬀort beyond the threshold eﬀort on any vulnerable facility. That is, only Cases
1 and 3 are possible in equilibrium.

5.2 Characterization of SPE

Recall that in Sec. 4, type I and type II regimes for the game Γ can be distinguished based
on a threshold defense cost ¯pd(pa). It turns out that in (cid:101)Γ, there are still 2K + 1 regimes.
Again, each regime denotes distinct ranges of cost parameters, and can be categorized
either as type (cid:101)I or type (cid:101)II. However, in contrast to Γ, the regime boundaries in this case
are more complicated; in particular, they are non-linear in the cost parameters pa and pd.
d (pa) for each

To introduce the boundary (cid:101)pd(pa), we need to deﬁne the function pij

i = 1, . . . , K and j = 1, . . . , i as follows:

pij
d (pa) =






C(1)−C∅

(cid:80)i

k=1 E(k)−(cid:80)i

k=1

,

paE(k)
C(k)−C∅

if j = 1,

(C(j)−C∅)·

(cid:18)

(cid:80)j−1
k=1

C(j)−C∅
(cid:19)
+(cid:80)i

E(k)
C(k)−C∅

k=j E(k)−(cid:80)i

k=1

,

if j = 2, . . . , i.

paE(k)
C(k)−C∅

(30)

For any i = 1, . . . , K, and any attack cost C(i+1) − C∅ ≤ pa < C(i) − C∅, but 0 < pa <
C(K) − C∅ if i = K, the threshold (cid:101)pd(pa) is deﬁned as follows:

(cid:101)pd(pa) =






pij
d (pa),

if

(cid:80)i

k=j+1 E(k)
E(k)
C(k)−C∅

k=1

(cid:80)i

pii
d (pa),

if 0 ≤ pa <

≤ pa <

E(i)

(cid:80)i

k=1

E(k)
C(k)−C∅

.

(cid:80)i

k=j E(k)
E(k)
C(k)−C∅

(cid:80)i

k=1

, and j = 1, . . . , i − 1,

(31)

Lemma 6. Given any attack cost 0 ≤ pa < C(1) − C∅, the threshold (cid:101)pd(pa) is a strictly
increasing and continuous function of pa.

Furthermore, for any 0 < pa < C(1) − C∅, (cid:101)pd(pa) > ¯pd(pa). If pa = 0, (cid:101)pd(0) = ¯pd(0). If

pa → C(1) − C∅, (cid:101)pd(pa) → +∞.

Since (cid:101)pd(pa) is a strictly increasing and continuous function function of pa, the inverse
d (pd) is well-deﬁned. Now we are ready to formally deﬁne the regimes for the

function (cid:101)p−1
game (cid:101)Γ:

17

(1) Type (cid:101)I regimes (cid:101)Λi, i = 0, . . . , K:

• If i = 0:

pa > C(1) − C∅, and

pd > 0.

• If i = 1, . . . , K − 1:

C(i+1) − C∅ < pa < C(i) − C∅, and

0 < pd < (cid:101)pd(pa).

• If i = K:

0 < pa < C(K) − C∅, and

0 < pd < (cid:101)pd(pa).

(2) Type (cid:101)II regimes (cid:101)Λj, j = 1, . . . , K:

• If j = 1:

0 < pa < (cid:101)p−1

d (pd), and

pd >

(cid:18) E(1)

(cid:19)−1

C(1) − C∅

(32)

(33)

(34)

(35)

• If j = 2, . . . , K:

0 < pa < (cid:101)p−1

d (pd), and

(cid:33)−1

(cid:32) j

(cid:88)

k=1

E(k)
C(k) − C∅

< pd <

(cid:33)−1

(cid:32) j−1
(cid:88)

k=1

E(k)
C(k) − C∅

(36)

Analogous to the discussion in Section 4.2, we say pd is “relatively low” in type (cid:101)I
regimes, and “relatively high” in type (cid:101)II regimes. We now provide full characterization of
SPE in each regime.

Theorem 2. The defender’s equilibrium security eﬀort vector ˜ρ∗ = (˜ρ∗
each regime. Speciﬁcally, SPE in each regime is as follows:

e)e∈E is unique in

(1) Type (cid:101)I regimes (cid:101)Λi:

• If i = 0,

• If i = 1, . . . , K,

˜ρ∗
e = 0, ∀e ∈ E,
a(∅, ˜ρ) = 1, ∀˜ρ ∈ [0, 1]|E|.
(cid:101)σ∗

(37a)

(37b)

˜ρ∗
e =

C(k) − pa − C∅
C(k) − C∅

, ∀e ∈ ¯E(k),

∀k = 1, . . . , i,

(38a)

˜ρ∗
e = 0,
a(∅, ˜ρ∗) = 1,
(cid:101)σ∗

(cid:101)σ∗
a(˜ρ) ∈ BR(˜ρ),

18

∀e ∈ E \ (cid:0)∪i

k=1

¯E(k)

(cid:1) ,

∀˜ρ ∈ [0, 1]|E| \ ˜ρ∗.

(38b)
(38c)

(38d)

(2) Type (cid:101)II regimes (cid:101)Λj:

• If j = 1,

• If j = 2, . . . , K,

˜ρ∗
e = 0,
a(˜ρ∗) ∈ ∆( ¯E(1)),
(cid:101)σ∗
(cid:101)σ∗
a(˜ρ) ∈ BR(˜ρ),

∀e ∈ E,

∀˜ρ ∈ [0, 1]|E| \ ˜ρ∗.

(39a)
(39b)

(39c)

˜ρ∗
e =

C(k) − C(j)
C(k) − C∅

,

˜ρ∗
e = 0,
a(˜ρ∗) ∈ ∆ (cid:0)∪j
(cid:101)σ∗
k=1
(cid:101)σ∗
a(˜ρ) ∈ BR(˜ρ),

¯E(k)

(cid:1) ,

∀e ∈ ¯E(k),

∀k = 1, . . . , j − 1,

(40a)

∀e ∈ E \ (cid:0)∪j−1

k=1

¯E(k)

(cid:1) ,

∀˜ρ ∈ [0, 1]|E| \ ˜ρ∗.

(40b)

(40c)

(40d)

In our proof of Theorem 2 (see Appendix C), we take the approach by ﬁrst constructing
a partition of the space (pa, pd) ∈ R2
>0 deﬁned in (52), and then characterizing the SPE for
cost parameters in each set in the partition (Lemmas 7–8). Theorem 2 follows directly by
regrouping/combining the elements of this partition such that each of the new partition
has qualitatively identical equilibrium strategies.

From the discussion of Lemma 5, we know that only Cases 1 and 3 are possible in
equilibrium, and that in any SPE, the security eﬀort on each vulnerable facility e is no
higher than the threshold eﬀort (cid:98)ρe. It turns out that for any attack cost, depending on
whether the defense cost is lower or higher than the threshold cost (cid:101)pd(pa), the defender
either secures each vulnerable facility with the threshold eﬀort given by (31) (type (cid:101)I
regime), or there is at least one vulnerable facility that is secured with eﬀort strictly less
than the threshold (type (cid:101)II regimes):

• In type (cid:101)I regimes, the defense cost pd < (cid:101)pd(pa). The defender secures each vulnerable

facility with the threshold eﬀort (cid:98)ρe. The attacker is fully deterred.

• In type (cid:101)II regimes, the defense cost pd > (cid:101)pd(pa). The defender’s equilibrium security
eﬀort is identical to that in NE of the normal form game Γ. The total attack
probability is 1.

6 Comparison of Γ and (cid:101)Γ

Sec. 6.1 deals with the comparison of players’ equilibrium utilities in the two games. In
Sec. 6.2, we compare the equilibrium regimes and discuss the distinctions in equilibrium
properties of the two games. This leads us to an understanding of the eﬀect of timing of
play, i.e. we can identify situations in which the defender gains by proactively investing
in securing all of the vulnerable facilities at an appropriate level of eﬀort.

19

6.1 Comparison of Equilibrium Utilities

The equilibrium utilities in both games are unique, and can be directly derived using
Theorems 1 and 2. We denote the equilibrium utilities of the defender and attacker in
(resp. U Λj
regime Λi (resp. Λj) as U Λi
(resp.
(cid:101)U (cid:101)Λj
d and (cid:101)U (cid:101)Λj

a ) in regime (cid:101)Λi (resp. (cid:101)Λj) in (cid:101)Γ.

a ) in Γ, and (cid:101)U (cid:101)Λi

d and U Λj

d and U Λi

d and (cid:101)U (cid:101)Λi

a

a

Proposition 3. In both Γ and (cid:101)Γ, the equilibrium utilities are unique in each regime.
Speciﬁcally,

(a) Type I ((cid:101)I) regimes Λi ((cid:101)Λi):

• If i = 0:

d = (cid:101)U (cid:101)Λ0
U Λ0

d = −C∅, and

a = (cid:101)U (cid:101)Λ0
U Λ0

a = C∅.

• If i = 1, . . . , K:

U Λi

d = −C∅ −

(cid:32) i

(cid:88)

(cid:33)

E(k)

pd,

and

U Λi

a = C∅,

k=1

(cid:32) i

(cid:88)

(cid:101)U (cid:101)Λi
d = −C∅ −

k=1

(b) Type II ((cid:101)II) regimes Λj ((cid:101)Λj):

• If j = 1:

(Ce − pa − C∅) E(k)
Ce − C∅

(cid:33)

pd, and

(cid:101)U (cid:101)Λi
a = C∅.

U Λ1
d = (cid:101)U (cid:101)Λ1

d = −C(1), and

• If j = 2, . . . , K:

U Λ1

a = (cid:101)U (cid:101)Λ1

a = C(1) − pa.

d = (cid:101)U (cid:101)Λj
U Λj

d = −C(j) −

j−1
(cid:88)

(cid:0)C(k) − C(j)

(cid:1) pdE(k)

k=1

C(k) − C∅

, and

U Λj

a = (cid:101)U (cid:101)Λj

a = C(j) − pa.

From our results so far, we can summarize the similarities between the equilibrium
outcomes in Γ and (cid:101)Γ. While most of these conclusions are fairly intuitive, the fact that
they are common to both game-theoretic models suggests that the timing of defense
investments do not play a role as far as these insights are concerned. Firstly, the support
of both players equilibrium strategies tends to contain the facilities, whose compromise
results in a high usage cost. The defender secures these facilities with a high level of eﬀort
in order to reduce the probability with which they are targeted by the attacker. Secondly,
the attack and defense costs jointly determine the set of facilities that are targeted or

20

secured in equilibrium. On one hand, the set of vulnerable facilities increases as the cost
of attack decreases. On the other hand, when the cost of defense is suﬃciently high,
the attacker tends to conduct an attack with probability 1. However, as the defense cost
decreases, the attacker randomizes the attack on a larger set of facilities. Consequently, the
defender secures a larger set of facilities with positive eﬀort, and when the cost of defense
is suﬃciently small, all vulnerable facilities are secured by the defender. Thirdly, each
player’s equilibrium payoﬀ is non-decreasing in the opponent’s cost, and non-increasing
in her own cost. Therefore, to increase her equilibrium payoﬀ, each player is better oﬀ as
her own cost decreases and the opponent’s cost increases.

6.2 First Mover Advantage

We now focus on identifying parameter ranges in which the defender has the ﬁrst mover
advantage, i.e., the defender in SPE has a strictly higher payoﬀ than in NE. To identify the
ﬁrst mover advantage, let us recall the expressions of type I regimes for Γ in (18)–(20) and
type (cid:101)I regimes for (cid:101)Γ in (32)–(34). Also recall that, for any given cost parameters pa and
pd, the threshold ¯pd(pa) (resp. (cid:101)pd(pa)) determines whether the equilibrium outcome is of
type I or type II regime (resp. type (cid:101)I or (cid:101)II regime) in the game Γ (resp. (cid:101)Γ). Furthermore,
from Lemma 6, we know that the cost threshold ¯pd(pa) in Γ is smaller than the threshold
(cid:101)pd(pa) in (cid:101)Γ. Thus, for all i = 1, . . . , K, the type I regime Λi in Γ is a proper subset of
the type (cid:101)I regime (cid:101)Λi in (cid:101)Γ. Consequently, for any (pa, pd) ∈ R2
>0, we can have one of the
following three cases:

• 0 < pd < ¯pd(pa): The defense cost is relatively low in both Γ and (cid:101)Γ. We denote the

set of (pa, pd) that satisfy this condition as L (low cost). That is,

L ∆= {(pa, pd) |0 < pd < ¯pd(pa)} = ∪K

i=0Λi.

(41)

• ¯pd(pa) < pd < (cid:101)pd(pa): The defense cost is relatively high in Γ, but relatively low
in (cid:101)Γ. We denote the set of (pa, pd) that satisfy this condition as M (medium cost).
That is,

M ∆= {(pa, pd) |¯pd(pa) < pd < (cid:101)pd(pa)} = ∪K

i=1

(cid:16)

(cid:101)Λi \ Λi(cid:17)

.

(42)

• pd > (cid:101)pd(pa): The defense cost is relatively high in both Γ and (cid:101)Γ. We denote the set

of (pa, pd) that satisfy this condition as H (high cost). That is,

H ∆= {(pa, pd) |pd > (cid:101)pd(pa)} = ∪K

j=1 (cid:101)Λj.

We next compare the properties of NE and SPE for cost parameters in each set based

on Theorems 1 and 2, and Propositions 3.

21

• Set L:

Attacker : In Γ, the total attack probability is nonzero but smaller than 1, whereas
in (cid:101)Γ, the attacker is fully deterred. The attacker’s equilibrium utility is identical in
both games, i.e., Ua = (cid:101)Ua.
Defender : The defender chooses identical equilibrium security eﬀort in both games,
i.e. ρ∗ = ˜ρ∗, but obtains a higher utility in (cid:101)Γ in comparison to that in Γ, i.e.,
Ud < (cid:101)Ud.

• Set M :

Attacker : In Γ, the attacker conducts an attack with probability 1, whereas in (cid:101)Γ
the attacker is fully deterred. The attacker’s equilibrium utility is lower in (cid:101)Γ in
comparison to that in Γ, i.e., Ua > (cid:101)Ua.
Defender : The defender secures each vulnerable facility with a strictly higher level of
eﬀort in (cid:101)Γ than in Γ, i.e. ˜ρ∗
e for each vulnerable facility e ∈ {E|Ce − pa > C∅}.
The defender’s equilibrium utility is higher in (cid:101)Γ in comparison to that in Γ, i.e.,
Ud < (cid:101)Ud.

e > ρ∗

• Set H:

Attacker : In both games, the attacker conducts an attack with probability 1, and
obtains identical utilities, i.e. Ua = (cid:101)Ua.
Defender : The defender chooses identical equilibrium security eﬀort in both games,
i.e., ρ∗ = ˜ρ∗, and obtains identical utilities, i.e. Ud = (cid:101)Ud.

Importantly, the key diﬀerence between NE and SPE comes from the fact that in
(cid:101)Γ, the defender as the leading player is able to inﬂuence the attacker’s strategy in her
favor. Hence, when the defense cost is relatively medium or low (both sets M and L), the
defender can proactively secure all vulnerable facilities with the threshold eﬀort to fully
deter the attack, which results in a higher defender utility in (cid:101)Γ than in Γ. Thus, we say
the defender has the ﬁrst-mover advantage when the cost parameters lie in the set M or
L. However, the reason behind the ﬁrst-mover advantage diﬀers in each set:

• In set M , the defender needs to proactively secure all vulnerable facilities with

strictly higher eﬀort in (cid:101)Γ than that in Γ to fully deter the attacker.

• In set L, the defender secures facilities in (cid:101)Γ with the same level of eﬀort as that in

Γ, and the attacker is still deterred with probability 1.

On the other hand, in set H, the defense cost is so high that the defender is not able to
secure all targeted facilities with an adequately high level of security eﬀort. Thus, the
attacker conducts an attack with probability 1 in both games, and the defender no longer
has ﬁrst-mover advantage.

Finally, for the sake of illustration, we compute the parameter sets L, M , and H for
transportation network with three facilities (edges); see Fig. 1. If an edge e ∈ E is not
damaged, then the cost function is (cid:96)e(we), which increases in the edge load we. If edge e is

22

successfully compromised by the attacker, then the cost function changes to (cid:96)⊗
e (we), which
is higher than (cid:96)e(we) for any edge load we > 0. The network faces a set of non-atomic

Figure 1: Three edge network

travelers with total demand D = 10. We deﬁne the usage cost in this case as the average
cost of travelers in Wardrop equilibrium [21]. Therefore, the usage costs corresponding to
attacks to diﬀerent edges are C1 = 20, C2 = 19, C3 = 18 and the pre-attack usage cost is
C∅ = 17. From (8), K = 3, and ¯E(1) = {e1}, ¯E(2) = {e2} and ¯E(3) = {e3}. In Fig. 2, we
illustrate the regimes of both Γ and (cid:101)Γ, and the three sets H, M , and L distinguished by
the thresholds ¯pd(pa) and (cid:101)pd(pa).

(a)

(b)

(c)

Figure 2: (a) Regimes of NE in Γ, (b) Regimes of SPE in (cid:101)Γ, (c) Comparison of NE and
SPE.

7 Model Extensions and Dynamic Aspects

In this section, we ﬁrst discuss how relaxing our modeling assumptions inﬂuence our
main results. Next we introduce a dynamic setup in which the users of the infrastructure
system face uncertainty about the outcome of attacker-defender interaction (i.e., identity
of the compromised facility), and follow a repeated learning procedure to make their usage
decisions.

23

7.1 Relaxing Model Assumptions

Our discussion centers around extending our results when the following modeling aspects
are included: facility-dependent cost parameters, less than perfect defense, and attacker’s
ability to target multiple facilities.

(1) Facility-dependent attack and defense costs.

Our techniques for equilibrium characterization of games Γ and (cid:101)Γ — as presented in
Sections 4 and 5 respectively — can be generalized to the case when attack/defense
costs are non-homogeneous across facilities. We denote the attack (resp. defense)
cost for facility e ∈ E as pa,e (resp. pd,e). However, an explicit characterization of
equilibrium regimes in each game can be quite complicated due to the multidimen-
sional nature of cost parameters.

In normal form game Γ, it is easy to show that the attacker’s best response corre-
spondence in Lemma 3 holds except that the threshold attack probability for any
facility e ∈ ¯E now becomes pd,e/(Ce − C∅). The set of vulnerable facilities is given
by {E|Ce − pa,e > C∅}. The attacker’s equilibrium strategy is to order the facilities
in decreasing order of Ce − pa,e, and target the facilities in this order each with the
threshold probability until either all vulnerable facilities are targeted or the total
probability of attack reaches 1. As in Theorem 1, the former case happens when
the cost parameters lie in a type I regime, and the latter case happens for type II
regimes, although the regime boundaries are more complicated to describe. In equi-
librium, the defender chooses the security eﬀort vector to ensure that the attacker
is indiﬀerent among choosing any of the pure actions that are in the support of
equilibrium attack strategy.

In the sequential game (cid:101)Γ, Lemmas 4 and 5 can be extended in a straightforward
manner except that the threshold security eﬀort for any vulnerable facility e ∈
{E|Ce − C∅ > pa,e} is given by (cid:98)ρe = (Ce − pa,e − C∅)/(Ce − C∅). The SPE for
this general case can be obtained analogously to Theorem 2, i.e. comparing the
defender’s utility of either securing all vulnerable facilities with the threshold eﬀort
to fully deter the attack, or choosing a strategy that is identical to that in Γ. These
cases happen when the cost parameters lie in (suitably deﬁned) Type (cid:101)I and Type (cid:101)II
regimes, respectively. The main conclusion of our analysis also holds: the defender
obtains a higher utility by proactively defending all vulnerable facilities when the
facility-dependent cost parameters lie in type (cid:101)I regimes.

(2) Less than perfect defense in addition to facility-dependent cost parameters.

Now consider that the defense on each facility is only successful with probability
γ ∈ (0, 1), which is an exogenous technological parameter. For any security eﬀort
vector ρ, the actual probability that a facility e is not compromised when targeted
by the attacker is γρe. Again our results on NE and SPE in Sec. 4 – Sec. 5 can
be readily extended to this case. However, the expressions for thresholds for attack
probability and security eﬀort level need to be modiﬁed. In particular, for Γ, in

24

Lemma 3, the threshold attack probability on any facility e ∈ ¯E is pd,e/γ(Ce − C∅).
For (cid:101)Γ, the threshold security eﬀort (cid:98)ρe for any vulnerable facility e ∈ {E|Ce − C∅ >
pd,e} is (Ce − pa,e − C∅)/γ(Ce − C∅). If this threshold is higher than 1 for a particular
facility, then the defender is not able to deter the attack from targeting it.

(3) Attacker’s ability to target multiple facilities.

If the attacker is not constrained to targeting a single facility, his pure strategy set
would be Sa = 2E. Then for a pure strategy proﬁle (sd, sa), the set of compromised
facilities is given by sa \ sd, and the usage cost Csa\sd. Unfortunately, our approach
cannot be straightforwardly applied to this case. This is because the mixed strategies
cannot be equivalently represented as probability vectors with elements represent-
ing the probability of each facility being targeted or secured. In fact, for a given
attacker’s strategy, one can ﬁnd two feasible defender’s mixed strategies that induce
an identical security eﬀort vector, but result in diﬀerent players utilities. Hence,
the problem of characterizing defender’s equilibrium strategies cannot be reduced
to characterizing the equilibrium security eﬀort on each facility. Instead, one would
need to account for the attack/defense probabilities on all the subsets of facilities
in E. This problem is beyond the scope of our paper, although a related work [22]
has made some progress in this regard.

Finally, we brieﬂy comment on the model where all the three aspects are included. So
long as players’ strategy sets are comprised of mixed strategies, the defender’s equilibrium
utility in (cid:101)Γ must be higher or equal to that in Γ. This is because in (cid:101)Γ, the defender
can always choose the same strategy as that in NE to achieve a utility that is no less
than that in Γ. Moreover, one can show the existence of cost parameters such that the
defender has strictly higher equilibrium utility in SPE than in NE. In particular, consider
that the attacker’s cost parameters (pa,e)e∈E in this game are such that there is only one
vulnerable facility ¯e ∈ E such that C¯e − C∅ > pa,¯e, and the threshold eﬀort on that facility
(cid:98)ρ¯e = (C¯e − pa,¯e − C∅) /γ(C¯e − C∅) < 1. In this case, if the defense cost pd,¯e is suﬃciently
low, then by proactively securing the facility ¯e with the threshold eﬀort (cid:98)ρ¯e, the defender
can deter the attack completely and obtain a strictly higher utility in (cid:101)Γ than that in Γ.
Thus, for such cost parameters, the defender gets the ﬁrst mover advantage in equilibrium.

7.2 Rational Learning Dynamics

We now discuss an approach for analyzing the dynamics of usage cost after a security
attack. Recall that the attacker-defender model enables us to evaluate the vulnerability of
individual facilities to a strategic attack for the purpose of prioritizing defense investments.
One can view this model as a way to determine the set of possible post-attack states,
denoted s ∈ S ∆= E ∪ {∅}. In particular, we consider situations in which the distribution of
the system state, denoted θ ∈ ∆(S), is determined by an equilibrium of attacker-defender
game (Γ or (cid:101)Γ). In Γ, for each s ∈ S, the probability θ(s) is given as follows:

θ(s) =

(cid:26) σ∗

a(e) · (1 − ρ∗
e),
1 − (cid:80)
e∈E θ(e),

if s = e,
if s = ∅.

(43)

25

a and ˜ρ∗.

For (cid:101)Γ the probability distribution θ can be analogously deﬁned in terms of (cid:101)σ∗

Let the realized state be s = e, i.e., the facility e ∈ E is compromised by the attacker.
If this information is known perfectly to all the users immediately after the attack, they
can shift their usage choices in accordance to the new state. Then the cost resulting
from the users’ choices indeed corresponds to the usage cost Cs = Ce, which governs the
realized payoﬀs of both attacker and defender. However, from our results (Theorems 1
and 2), it is apparent that the support of equilibrium player strategies (and hence the
support of θ) can be quite large. Due to inherent limitations in perfectly diagnosing the
location of attack, in some situations, the users may not have full knowledge of the realized
state. Then, the issues of how users with imperfect information make their decisions in
a repeated learning setup, and whether or not the long-run usage cost converges to the
actual cost Ce become relevant.

To contextualize the above issues, consider the situation in which a transportation
system is targeted by an external hacker, and that the operation of a single facility is
compromised. Furthermore, the nature of attack is such that travelers are not able to
immediately know the identity of this facility. This situation can arise when the diagnosis
of attack and/or dissemination of information about the attack is imperfect. Examples
include cyber-security attacks to transportation facilities that can result in hard-to-detect
eﬀects such as compromised traﬃc signals of a major intersection, or tampering of con-
trollers governing the access to a busy freeway corridor. Then, one can study the problem
of learning by rational but imperfectly informed travelers using a repeated routing game
model. We now discuss the basic ideas behind the study of this problem. A more rigorous
treatment is part of our ongoing work, and will be detailed in a subsequent paper.

Let the stages of our repeated routing game be denoted as t ∈ T = {1, 2, . . . }. In this
game, travelers are imperfectly informed about the network state. In particular, in each
stage t ∈ T , they maintain a belief about the state θt. The initial belief θ0 can be diﬀerent
from the prior state distribution θ. However, we require that θ0 is absolutely continuous
with respect to θ ([32]):

∀s ∈ S,

θ(s) > 0, ⇒ θ0(s) > 0.

That is, the initial belief of travelers does not rule out any possible state.

The solution concept we use for this repeated game is Markov-perfect Equilibrium (see
[38]), in which travelers use routes with the smallest expected cost based on the belief
in each stage. Equivalently, the equilibrium routing strategy in stage t is a Wardrop
equilibrium of the stage game with belief θt ([21]). We also consider that at the end
of each stage, travelers receive noisy information of the realized costs on routes that are
taken. However, no information is available for routes that are not chosen by any traveler.
Based on the received information, travelers update their belief of the state using Bayes’
rule.

We note that numerous learning schemes have been studied in the literature; for e.g.
ﬁctitious play ([15], [29], and [31]); reinforcement learning ([10], [19] and [20]), and regret
minimizations ([14] and [37]). These learning schemes typically assume that strategies in
each stage are determined by a certain function of the history payoﬀ or actions. To explain

26

the learning dynamics in our set-up we consider that in each stage travelers are rational,
and they aim to maximize the payoﬀ myopically based on their current belief about other
travelers’ strategies. The players update their beliefs based on observed actions on the
play-path. This so-called rational learning dynamics has been investigated by [9], [27],
[32], and [33]. Our model is diﬀerent from the ones in literature in that travelers are
uncertain about the payoﬀ functions, but correctly anticipate the opponents’ strategies.
Additionally, the information of the payoﬀ in each stage is noisy and limited (only the
realized costs on the taken routes are known).

r (θt))r∈{r1,r2}, where qt∗

The game can be understood easily via an example of a transportation network in
Fig. 1. In each stage t, travelers with inelastic demand D choose route r1 (e2 − e1) or
route r2 (e3 − e1). We denote the equilibrium routing strategy in stage t as qt∗(θt) =
(qt∗
r (θt) is the demand of travelers using route r given the belief θt.
Hence, aggregate ﬂow on edge e2 (resp. e3) is wt∗
2 (θt)),
and the aggregate ﬂow on edge e1 is wt∗
1 (θt) = D. Each stage game is a congestion game,
and hence admits a potential function. The equilibrium routing strategy qt∗(θt) can be
computed eﬃciently for this game. Moreover, in each stage, the equilibrium is essentially
unique in that the equilibrium edge load is unique for a given belief ([45]).

1 (θt) (resp. wt∗

2 (θt) = qt∗

3 (θt) = qt∗

The realized cost on each edge e ∈ E, denoted cs

e(wt∗

e (θt)), equals to the cost (shown

in Fig. 1 for the example network) plus a random variable (cid:15)e:

e(qt∗(θt)) =
cs

(cid:26) (cid:96)⊗

e (wt∗
(cid:96)e(wt∗

e (θt)) + (cid:15)e,
e (θt)) + (cid:15)e,

if s = e,
otherwise.

(44)

We illustrate two cases that can arise in rational learning:

• Long-run usage cost equals to Cs for any s ∈ {e1, e2, e3, ∅}.

Consider the case where the initial belief is θ(e1) = 1/12, θ(e2) = 1/3, θ(e3) = 1/12,
θ(∅) = 1/2 (The initial belief can be any probability vector which satisﬁes the
continuity assumption). For any e ∈ E, the random variable (cid:15)e in (44) is distributed
as U [−3, 3]. The total demand D = 10. Fig. 3a–3d show how the belief of each
state evolves. We see that eventually travelers learn the true state, and hence the
long-run usage cost converges to the actual post-attack usage cost Cs, even though
initially all travelers are imperfectly informed about the state.

• Long-run usage cost is higher than Cs.

Consider the case when, as a result of attack on edge e2, the cost function on e2
changes to (cid:96)⊗
2 (w2) = 7/3w2 + 50. The total demand is D = 5, and the initial
belief is θ(e1) = 1/12, θ(e2) = 1/3, θ(e3) = 1/12, θ(∅) = 1/2. Starting from this
initial belief, travelers exclusively take route r2, and hence they do not obtain any
information about e2. Even when the realized state is s = ∅, travelers end up
repeatedly taking r2 as if e2 is compromised. Thus, the long-run average cost is Ce2,
which is higher than the cost corresponding to the true state C∅. Therefore, rational
learning dynamics can lead to long-run ineﬃciency. We illustrate the equilibrium
routing strategies and beliefs in each stage in Fig. 4a and Fig. 4b respectively.

27

(a) s = e1.

(b) s = e2.

(c) s = e3.

(d) s = ∅.

Figure 3: Rational learning leads to the usage cost of the true state.

(a)

(b)

Figure 4: Learning leads to long-run ineﬃciency s = ∅: (a) Equilibrium routing strategies;
(b) Beliefs.

28

02004006008001000t00.20.40.60.81θt(s)θt(e1)θt(e2)θt(e3)θt(∅)02004006008001000t00.20.40.60.81θt(s)θt(e1)θt(e2)θt(e3)θt(∅)02004006008001000t00.20.40.60.81θt(s)θt(e1)θt(e2)θt(e3)θt(∅)02004006008001000t00.20.40.60.81θt(s)θt(e1)θt(e2)θt(e3)θt(∅)0100200300400500t00.20.40.60.81qt∗r(θt)/Dq∗1(θt)/Dq∗2(θt)/D0100200300400500t00.20.40.60.81θt(s)θt(e1)θt(e2)θt(e3)θt(∅)These cases illustrate that if the post-attack state is not perfectly known by the users
of the system, then the cost experienced by the users depend on the learning dynamics
induced by the repeated play of rational users. Particularly, the learning dynamics can
induce a higher usage cost in the long-run in comparison to the cost corresponding to
the true state. Following previously known results [28], one can argue that if suﬃcient
amount of “oﬀ-equilibrium” experiments are conducted by travelers, then the learning
will converge to Wardrop equilibrium with the true state. However, such experiments are
in general not costless.

As a ﬁnal remark, we note another implication of proactive defense strategy in ranges
of attack/ defense cost parameters where the ﬁrst-mover advantage holds. In particular,
when the cost parameters are in the sets L and M as given in (41)-(42), the attack is
completely deterred in the sequential game (cid:101)Γ and there is no uncertainty in the realized
state.
In such a situation, one does not need to consider uncertainty in the travelers’
belief about the true state and issue of long-run ineﬃciency due to learning behavior does
not arise.

Acknowledgments

We are sincerely thankful to Prof. Georges Zaccour and two anonymous referees whose
constructive comments helped us to improve our initial manuscript. We thank seminar
participants at MIT, HEC Montreal, University of Pennsylvania, and NYU Abu Dhabi for
helpful comments. The authors are grateful to Professors Alexandre Bayen, Patrick Jail-
let, Karl Johansson, Patrick Loiseau, Samer Madanat, Hani Mahmassani, Asu Ozdaglar,
Galina Schwartz, Demos Teneketzis, Rakesh Vohra, Dan Work, Georges Zaccour for in-
sightful comments and discussions in the early phase of this research. This work was
supported in part by Singapore-MIT Alliance for Research and Technology (SMART)
Center for Future Mobility (FM), NSF grant CNS 1239054, NSF CAREER award CNS
1453126.

References

[1] Daron Acemoglu, Azarakhsh Malekian, and Asu Ozdaglar. Network security and

contagion. Journal of Economic Theory, 166:536–585, 2016.

[2] David L Alderson, Gerald G Brown, W Matthew Carlyle, and R Kevin Wood. Solv-
ing defender-attacker-defender models for infrastructure defense. Technical report,
NAVAL POSTGRADUATE SCHOOL MONTEREY CA DEPT OF OPERATIONS
RESEARCH, 2011.

[3] David L Alderson, Gerald G Brown, W Matthew Carlyle, and R Kevin Wood. As-
sessing and improving the operational resilience of a large highway infrastructure
system to worst-case losses. Transportation Science, 2017.

29

[4] Tansu Alpcan and Tamer Basar. A game theoretic approach to decision and analysis
In Decision and Control, 2003. Proceedings. 42nd

in network intrusion detection.
IEEE Conference on, volume 3, pages 2595–2600. IEEE, 2003.

[5] Tansu Alpcan and Tamer Ba¸sar. Network security: A decision and game-theoretic

approach. Cambridge University Press, 2010.

[6] Saurabh Amin, Galina A Schwartz, and S Shankar Sastry. Security of interdependent

and identical networked control systems. Automatica, 49(1):186–192, 2013.

[7] Kyle Bagwell. Commitment and observability in games. Games and Economic Be-

havior, 8(2):271–280, 1995.

[8] Tamer Ba¸sar and Geert Jan Olsder. Dynamic noncooperative game theory. SIAM,

1998.

[9] Pierpaolo Battigalli, Mario Gilli, and M Cristina Molinari. Learning and convergence
to equilibrium in repeated strategic interactions: an introductory survey. Universit`a
Commerciale” L. Bocconi”, Istituto di Economia Politica, 1992.

[10] Alan W Beggs. On the convergence of reinforcement learning. Journal of Economic

Theory, 122(1):1–36, 2005.

[11] MGH Bell, U Kanturska, J-D Schm¨ocker, and A Fonzone. Attacker–defender models
and road network vulnerability. Philosophical Transactions of the Royal Society of
London A: Mathematical, Physical and Engineering Sciences, 366(1872):1893–1906,
2008.

[12] Vicki Bier, Santiago Oliveros, and Larry Samuelson. Choosing what to protect:
Strategic defensive allocation against an unknown attacker. Journal of Public Eco-
nomic Theory, 9(4):563–587, 2007.

[13] Vicki M Bier and Kjell Hausken. Defending and attacking a network of two arcs
subject to traﬃc congestion. Reliability Engineering & System Safety, 112:214–224,
2013.

[14] Avrim Blum, Eyal Even-Dar, and Katrina Ligett. Routing without regret: On con-
vergence to nash equilibria of regret-minimizing algorithms in routing games.
In
Proceedings of the twenty-ﬁfth annual ACM symposium on Principles of distributed
computing, pages 45–52. ACM, 2006.

[15] George W Brown. Iterative solution of games by ﬁctitious play. Activity analysis of

production and allocation, 13(1):374–376, 1951.

[16] Gerald Brown, Matthew Carlyle, Javier Salmer´on, and Kevin Wood. Defending

critical infrastructure. Interfaces, 36(6):530–544, 2006.

30

[17] Alvaro A C´ardenas, Saurabh Amin, Zong-Syun Lin, Yu-Lun Huang, Chi-Yen Huang,
and Shankar Sastry. Attacks against process control systems: risk assessment, de-
tection, and response. In Proceedings of the 6th ACM symposium on information,
computer and communications security, pages 355–366. ACM, 2011.

[18] Lin Chen and Jean Leneutre. A game theoretical framework on intrusion detection in
heterogeneous networks. IEEE Transactions on Information Forensics and Security,
4(2):165–178, 2009.

[19] Roberto Cominetti, Francisco Facchinei, and Jean B Lasserre. Adaptive dynam-
ics in traﬃc games. In Modern Optimization Modelling Techniques, pages 239–257.
Springer, 2012.

[20] Roberto Cominetti, Emerson Melo, and Sylvain Sorin. A payoﬀ-based learning pro-
cedure and its application to traﬃc games. Games and Economic Behavior, 70(1):71–
83, 2010.

[21] Jos´e R Correa and Nicol´as E Stier-Moses. Wardrop equilibria. Wiley encyclopedia of

operations research and management science, 2011.

[22] Mathieu Dahan and Saurabh Amin. Network ﬂow routing under strategic link dis-
ruptions. In Communication, Control, and Computing (Allerton), 2015 53rd Annual
Allerton Conference on, pages 353–360. IEEE, 2015.

[23] Lemonia Dritsoula, Patrick Loiseau, and John Musacchio. A game-theoretical ap-
proach for ﬁnding optimal strategies in an intruder classiﬁcation game. In Decision
and Control (CDC), 2012 IEEE 51st Annual Conference on, pages 7744–7751. IEEE,
2012.

[24] Lemonia Dritsoula, Patrick Loiseau, and John Musacchio. A game-theoretic anal-
ysis of adversarial classiﬁcation. IEEE Transactions on Information Forensics and
Security, 12(12):3094–3109, 2017.

[25] Marcin Dziubi´nski and Sanjeev Goyal. Network design and defence. Games and

Economic Behavior, 79:30–43, 2013.

[26] Marcin Dziubi´nski and Sanjeev Goyal. How do you defend a network? Theoretical

economics, 12(1):331–376, 2017.

[27] Drew Fudenberg and David M Kreps. Learning in extensive-form games i. self-

conﬁrming equilibria. Games and Economic Behavior, 8(1):20–55, 1995.

[28] Drew Fudenberg and David K Levine. Steady state learning and nash equilibrium.

Econometrica: Journal of the Econometric Society, pages 547–573, 1993.

[29] Drew Fudenberg and David K Levine. Consistency and cautious ﬁctitious play.

Journal of Economic Dynamics and Control, 19(5-7):1065–1089, 1995.

31

[30] Sanjeev Goyal and Adrien Vigier. Attack, defence, and contagion in networks. The

Review of Economic Studies, 81(4):1518–1542, 2014.

[31] Josef Hofbauer and William H Sandholm. On the global convergence of stochastic

ﬁctitious play. Econometrica, 70(6):2265–2294, 2002.

[32] Ehud Kalai and Ehud Lehrer. Subjective equilibrium in repeated games. Economet-

rica: Journal of the Econometric Society, pages 1231–1240, 1993.

[33] Ehud Kalai and Eran Shmaya. Learning and stability in big uncertain games. Tech-

nical report, Tech. rep, 2015.

[34] Gilbert Laporte, Juan A Mesa, and Federico Perea. A game theoretic framework for
the robust railway transit network design problem. Transportation Research Part B:
Methodological, 44(4):447–459, 2010.

[35] Kalev Leetaru. How the internet of things will turn your living room into the future

cyber battleground. Forbes, Nov 2015.

[36] Mohammad Hossein Manshaei, Quanyan Zhu, Tansu Alpcan, Tamer Bac¸sar, and
Jean-Pierre Hubaux. Game theory meets network security and privacy. ACM Com-
puting Surveys (CSUR), 45(3):25, 2013.

[37] Jason R Marden, G¨urdal Arslan, and Jeﬀ S Shamma. Regret based dynamics: conver-
gence in weakly acyclic games. In Proceedings of the 6th international joint conference
on Autonomous agents and multiagent systems, page 42. ACM, 2007.

[38] Eric Maskin and Jean Tirole. Markov perfect equilibrium: I. observable actions.

Journal of Economic Theory, 100(2):191–219, 2001.

[39] John Moteﬀ and Paul Parfomak. Critical infrastructure and key assets: deﬁnition and
identiﬁcation. LIBRARY OF CONGRESS WASHINGTON DC CONGRESSIONAL
RESEARCH SERVICE, 2004.

[40] Kien C Nguyen, Tansu Alpcan, and Tamer Basar. Stochastic games for secu-
rity in networks with interdependent nodes. In Game Theory for Networks, 2009.
GameNets’ 09. International Conference on, pages 697–703. IEEE, 2009.

[41] Robert Powell. Defending against terrorist attacks with limited resources. American

Political Science Review, 101(3):527–541, 2007.

[42] Steven M Rinaldi, James P Peerenboom, and Terrence K Kelly.

Identifying, un-
derstanding, and analyzing critical infrastructure interdependencies. IEEE Control
Systems, 21(6):11–25, 2001.

[43] Robert W Rosenthal. Correlated equilibria in some classes of two-person games.

International Journal of Game Theory, 3(3):119–128, 1974.

32

[44] Henrik Sandberg, Saurabh Amin, and Karl Henrik Johansson. Cyberphysical security
in networked control systems: An introduction to the issue. IEEE Control Systems,
35(1):20–23, 2015.

[45] William H Sandholm. Potential games with continuous player sets. Journal of Eco-

nomic theory, 97(1):81–108, 2001.

[46] Galina A Schwartz, Saurabh Amin, Assane Gueye, and Jean Walrand. Network
design game with both reliability and security failures. In Communication, Control,
and Computing (Allerton), 2011 49th Annual Allerton Conference on, pages 675–681.
IEEE, 2011.

[47] Abhishek Rajkumar Sethi, Saurabh Amin, and Galina Schwartz. Value of intrusion
In American Control Conference

detection systems for countering energy fraud.
(ACC), 2017, pages 2739–2746. IEEE, 2017.

[48] Siddharth Sridhar, Adam Hahn, and Manimaran Govindarasu. Cyber–physical sys-
tem security for the electric power grid. Proceedings of the IEEE, 100(1):210–224,
2012.

[49] Bernhard Von Stengel and Shmuel Zamir. Leadership with commitment to mixed

strategies. 2004.

[50] Alan Washburn and Kevin Wood. Two-person zero-sum games for network interdic-

tion. Operations research, 43(2):243–251, 1995.

33

A Proofs of Section 3

Proof of Lemma 1. We ﬁrst show that the strategy in (5) is feasible. Since ρ(1) ≤ 1,
and for any i = 1, . . . , m − 1, ρ(i) − ρ(i+1) > 0, σd(sd) is non-negative for any sd ∈ Sd.
Additionally,

(cid:88)

sd∈Sd

σd(sd) = σd (∅) +

m−1
(cid:88)

i=1

(cid:0)(cid:8)e ∈ E|ρe ≥ ρ(i)

(cid:9)(cid:1) + σd

(cid:0)(cid:8)e ∈ E|ρe ≥ ρ(m)

(cid:9)(cid:1)

σd

= (cid:0)1 − ρ(1)

(cid:1) +

m−1
(cid:88)

i=1

(cid:0)ρ(i) − ρ(i+1)

(cid:1) + ρ(m)

= 1 − ρ(1) + ρ(1) − ρ(m) + ρ(m)
= 1.

Thus, σd in (5) is a feasible strategy of the defender. Now we check that σd in (5)
indeed induces ρ. Consider any e ∈ E such that ρe = 0. Then, since e /∈ (cid:8)E|ρe ≥ ρ(i)
(cid:9)
for any i = 1, . . . , m, and e /∈ ∅, for any sd (cid:51) e, we must have σd(sd) = 0. Thus,
(cid:80)
sd(cid:51)e σd(sd) = 0 = ρe. Finally, for any j = 1, . . . , m, consider any e ∈ E, where ρe = ρ(j):

(cid:88)

sd(cid:51)e

σd(sd) =

m
(cid:88)

i=j

(cid:0)(cid:8)e ∈ E|ρe ≥ ρ(i)

(cid:9)(cid:1) = ρ(j).

σd

Therefore, σd in (5) induces ρ.

Proof of Proposition 1. We prove the result by the principal of iterated dominance. We
d = sd ∩ ¯E.
ﬁrst show that any sd such that sd (cid:42) ¯E is strictly dominated by the strategy s(cid:48)
Consider any pure strategy of the attacker, sa ∈ E, the utilities of the defender with
strategy sd and s(cid:48)

d are as follows:

ud(sd, sa) = −C(sd, sa) − |sd|pd = −C(sd, sa) − (|s(cid:48)
ud(s(cid:48)

d, sa) = −C(s(cid:48)

d, sa) − |s(cid:48)

d|pd.

d| + |sd \ ¯E|)pd,

If sa ∈ ¯E or sa /∈ sd or sa = ∅, then C(sd, sa) = C(s(cid:48)
d, sa), and thus Ud(sd, sa) < Ud(s(cid:48)
d, sa).
If sa = e ∈ sd \ ¯E, then e /∈ ¯E, and Ce ≤ C∅. We have C(sd, sa) = C∅ ≥ Ce = C(s(cid:48)
d, sa),
d|pd > Ud(sd, sa). Therefore, any sd such that sd (cid:42) ¯E
and thus Ud(s(cid:48)
is a strictly dominated strategy. Hence, in Γ, any equilibrium strategy of the defender
satisﬁes σ∗

d, sa) ≥ −C(sd, sa) − |s(cid:48)

d(sd) = 0. From (4), we know that ρ∗

e = 0 for any e ∈ E \ ¯E.

We denote the set of defender’s pure strategies that are not strictly dominated as
¯Sd = {sd|sd ⊆ ¯E}. Consider any sd ∈ ¯Sd, we show that any sa ∈ E \ ¯E is strictly
dominated by strategy ∅. The utility functions of the attacker with strategy sa and ∅ are
as follows:

ua(sd, sa) = C(sd, sa) − pa,
ua(sd, ∅) = C(sd, ∅).

34

Since sd ⊆ ¯E and sa ∈ E \ ¯E, sa /∈ sd, thus C(sd, sa) = Csa ≤ C∅. However, C(sd, ∅) = C∅
and pa > 0. Therefore, Ua(sd, ∅) > Ua(sd, sa). Hence, any sa ∈ E \ ¯E is strictly dominated.
Hence, in equilibrium, the probability of the attacker choosing facility e ∈ E \ ¯E is 0 in Γ.

We can analogously argue that in (cid:101)Γ, ˜ρ∗

e = 0 and (cid:101)σ∗

a(e, ˜ρ) = 0 for any e ∈ E \ ¯E.

B Proofs of Section 4

Proof of Lemma 2. The utility functions of the attacker with strategy σa in Γ0 and Γ are
related as follows:

a (σd, σa) = Ua(σd, σa) + Eσd [|sd|] · pd.
U 0

Thus, for a given σd, any σa that maximizes U 0
a (σd, σa) also maximizes Ua(σd, σa). So the
set of best response strategies of the attacker in Γ0 is identical to that in Γ. Analogously,
given any σa, the set of best response strategies of the defender in Γ is identical to that in
Γ0. Thus, Γ0 and Γ are strategically equivalent, i.e. they have the same set of equilibrium
strategy proﬁles. Using the interchangeability property of equilibria in zero-sum games,
we directly obtain that for any σ∗
a) is an equilibrium
strategy proﬁle.

d and any σ∗

d ∈ Σ∗

a ∈ Σ∗

a, (σ∗

d, σ∗

Proof of Proposition 2. From Lemma 2, the set of attacker’s equilibrium strategies Σ∗
the optimal solution of the following maximin problem:

a is

max
σa

min
sd∈Sd

(cid:40)

(cid:88)

e∈ ¯E

(C(sd, e) + |sd|pd − pa) · σa(e) + (C(sd, ∅) + |sd|pd) · σa(∅)

(cid:41)

(cid:88)

s.t.

σa(e) + σa(∅) = 1,

e∈ ¯E
σa(∅) ≥ 0,

σa(e) ≥ 0,

∀e ∈ ¯E.

(45a)

(45b)

35

Given any sd ∈ Sd, we can express the objective fucntion in (45) as follows:

(cid:88)

e∈ ¯E

(cid:88)

e∈ ¯E
(cid:88)

e∈ ¯E

(cid:88)

e∈ ¯E
(cid:88)

e∈ ¯E
(cid:88)

e∈sd

=

(45a)
=

=

=

(1)
=

(C(sd, e) + |sd|pd − pa) · σa(e) + (C(sd, ∅) + |sd|pd) · σa(∅)

(C(sd, e) − pa) · σa(e) + C(sd, ∅)σa(∅) + |sd|pd ·

(cid:33)

σa(e) + σa(∅)

(cid:32)

(cid:88)

e∈E

σa(e) · (C(sd, e) − pa) + |sd|pd + σa(∅) · C∅

σa(e) · (C(sd, e) − pa) + pd ·

(cid:33)

1{sd (cid:51) e}

+ σa(∅) · C∅

(cid:32)

(cid:88)

e∈ ¯E

(σa(e) · (C(sd, e) − pa) + pd · 1{sd (cid:51) e}) + σa(∅) · C∅

(σa(e) · (C∅ − pa) + pd) +

(cid:88)

e∈ ¯E\sd

σa(e) · (Ce − pa) + σa(∅) · C∅.

Therefore, we can write:

min
sd∈Sd

= min
sd∈Sd

(cid:40)

(cid:88)

e∈ ¯E

(cid:88)






e∈sd

(C(sd, e) + |sd|pd − pa) · σa(e) + (C(sd, ∅) + |sd|pd) · σa(∅)

(σa(e) · (C∅ − pa) + pd) +

(cid:88)

e∈ ¯E\sd

σa(e) · (Ce − pa) + σa(∅) · C∅






(cid:41)

(cid:88)

=

min {σa(e) · (C∅ − pa) + pd, σa(e) · (Ce − pa)} + σa(∅) · C∅

e∈ ¯E
=V (σa).

Thus (45) is equivalent to (10), and Σ∗

a is the optimal solution set of (10)

By introducing an | ¯E|-dimensional variable v = (ve)e∈ ¯E, (10) can be changed to a linear

optimization program (11), and Σ∗

a is the optimal solution set of (11).

Proof of Lemma 3. We ﬁrst argue that the defender’s best response is in (13). For edge
e ∈ E such that σa(e) < pd
, we have (C∅ − Ce) σa(e) + pd > 0. Since ρ ∈ BR(σa)
maximizes Ud(σd, σa) as given in (6a), ρe must be 0. Additionally, Proposition 1 ensures
that for any e ∈ E \ ¯E, ρe is 0.
Analogously, if σa(e) > pd
ρe = 1. Finally, if σa(e) = pd

, then (C∅ − Ce) σa(e) + pd < 0, and the best response
, any ρe ∈ [0, 1] can be a best response.

Ce−C∅

Ce−C∅

Ce−C∅

We next prove (14). We show that if a feasible σa violates (14a), i.e., there exists
, then σa cannot be an equilibrium

a facility, denoted ¯e ∈ ¯E such that σa(¯e) > pd
strategy. There are two cases:

C¯e−C∅

36

(a) There exists another facility (cid:98)e ∈ ¯E such that σa((cid:98)e) < pd
(cid:98)e−C∅

C

strategy σ(cid:48)

a deﬁned as follows:

. Consider an attacker’s

∀e ∈ ¯E \ {¯e, (cid:98)e},

σ(cid:48)
a(e) = σa(e),
σ(cid:48)
a(¯e) = σa(¯e) − (cid:15),
σ(cid:48)
a((cid:98)e) = σa((cid:98)e) + (cid:15),

σ(cid:48)
a(∅) = σa(∅),

where (cid:15) is a suﬃciently small positive number so that σ(cid:48)

a(¯e) > pd

C¯e−C∅

and σ(cid:48)

a((cid:98)e) <

pd
(cid:98)e−C∅

C

. We obtain:

V (σ(cid:48)

a) − V (σa) = (cid:15) (C

(cid:98)e − C∅) > 0

The last inequality holds from (7a) and (cid:98)e ∈ ¯E. Therefore, σa cannot be an attacker’s
equilibrium strategy.

(b) If there does not exist such ¯e as deﬁned in case (a), then for any e ∈ ¯E, we have

σa(e) ≥ pd

Ce−C∅

. Now consider σ(cid:48)

a as follows:

∀e ∈ E \ {¯e},

σ(cid:48)
a(e) = σa(e),
σ(cid:48)
a(¯e) = σa(¯e) − (cid:15),
σ(cid:48)
a(∅) = σa(∅) + (cid:15),

where (cid:15) is a suﬃciently small positive number so that σ(cid:48)

a(¯e) > pd

C¯e−C∅

. We obtain:

V (σ(cid:48)

a) − V (σa) = (cid:15) (C∅ − (C∅ − pa)) = (cid:15)pa > 0.

Therefore, σa also cannot be an attacker’s equilibrium strategy.

Thus, we can conclude from cases (a) and (b) that in equilibrium σ∗
Additionally, from Proposition 1, (14b) is also satisﬁed.

a must satisfy (14a).

Proof of Theorem 1. We ﬁrst prove the attacker’s equilibrium strategies in each regime.
From Proposition 2 and Lemma 3, we know that σ∗
a maximizes V (σa), which can be
equivalently re-written as in (15). We analyze the attacker’s equilibrium strategy set in
each regime subsequently:

(a) Type I regimes Λi:

• i = 0:

Since pa > C(1) − C∅, we must have C∅ > Ce − pa for any e ∈ ¯E. There is no
vulnerable facility, and thus σ∗

a(∅) = 1.

• i = 1, . . . , K:

Since pd satisﬁes (19) or (20), we obtain:

(cid:88)

e∈∪i

k=1

¯E(k)

pd
Ce − C∅

=

i
(cid:88)

k=1

pd · E(k)
C(k) − C∅

< 1

(46)

37

Therefore, the set of feasible attack strategies satisfying (24c)-(24d) is a non-
empty set. We also know from Lemma 3 that σ∗
a satisﬁes (14a). Again from (19)
or (20), for any k = 1, . . . , i, we have C(k)−pa > C∅ and for any k = i+1, . . . , K,
we have C(k) − pa < C∅. Since {C(k)}K
k=1 satisfy (8), to maximize V (σa) in (15),
the optimal solution must satisfy (24c)-(24d).

(b) Type II regimes Λj:

• j = 1: From (21), we know that:

1 =

(cid:88)

e∈ ¯E(1)

σ∗
a(e) <

pdE(1)
C(1) − C∅

.

(47)

Thus, the set of feasible attack strategies satisfying (25b)-(25c) is a non-empty
set. Additionally, from Lemma 3, we know that σ∗
a satisﬁes (25b). Since
C(1) > C(k) for any k = 2, . . . , K, and C(1) − pa > C∅. From (15) and (47), we
know that in equilibrium the attacker targets facilities in ¯E(1) with probability
1. The set of strategies satisfying (25b)-(25c) maximizes (15), and thus is the
set of attacker’s equilibrium strategies.

• j = 2, . . . , K: From (22), we know that:

0 < 1 −

j−1
(cid:88)

k=1

pd · E(k)
C(k) − C∅

<

pd · E(j)
C(j) − C∅

.

Thus, the set of feasible attack strategies satisfying (26c)-(26e) is a non-empty
set. From Lemma 3, we know that σ∗
a satiﬁes (26d). Since {C(k)}k=1,...,j satisﬁes
the ordering in (8), in order to maximize V (σa) in (15), σ∗
a must also satisfy
(26c) and (26e), and the remaining facilities are not targeted.

We next prove the defender’s equilibrium security eﬀort. By deﬁnition of Nash equi-
librium, the probability vector ρ∗ is induced by an equilibrium strategy if and only if it
satisﬁes the following two conditions:

(1) ρ∗ is a best response to any σ∗

a ∈ Σ∗
a.

(2) Any attacker’s equilibrium strategy is a best response to ρ∗, i.e. the attacker has
identical utilities for choosing any pure strategy in his equilibrium support set, and
the utility is no less than that of any other pure strategies.

Note that in both conditions, we require ρ∗ to be a best response to any attacker’s
equilibrium strategy. This is because given any σ∗
a) is an equilibrium strategy
proﬁle (Lemma 2). We now check these conditions in each regime:

a, (ρ∗, σ∗

a ∈ Σ∗

(a) Type I regimes Λi:

38

• If i = 0:
Since σ∗
defender is ρ∗

e = 0 for any e ∈ E.

a(e) = 0 for any e ∈ E. From Lemma 3, the best response of the

• If i = 1, . . . , K:

From Lemma 3, we know that ρ∗
0, ρ∗
is identical to that of choosing no attack ∅. Consider any e ∈ ∪i

(cid:1). Since σ∗
e must ensure that the attacker’s utility of choosing any facility e ∈ ∪i
¯E(k):

e = 0 for any e ∈ E \ (cid:0)∪i

¯E(k)

k=1

a(∅) >
¯E(k)
k=1

k=1

(6b)
⇒ ρ∗

e (C∅ − pa) + (1 − ρ∗

e) (Ce − pa) = C∅,

Ua(ρ∗, e) = Ua(ρ∗, ∅),

⇒

ρ∗
e =

Ce − pa − C∅
Ce − C∅

,

∀e ∈ ∪i

k=1

¯E(k).

For any ¯e ∈ E \ (cid:0)∪i
¯e = 0, the attacker receives utility C¯e − pa
by targeting ¯e, which is lower than C∅. Therefore, ρ∗ in (24a)-(24b) satisﬁes
both conditions (1) and (2). ρ∗ is the unique equilibrium strategy.

(cid:1), since ρ∗

¯E(k)

k=1

(b) Type II regimes Λj:

• If j = 0:

Consider an attacker’s strategy σa such that:

σa(e) =

1
E(1)

,

∀e ∈ ¯E(1),

σa(e) = 0,

∀e ∈ E \ ¯E(1).

Since pd satisﬁes (21), we know that
satisﬁes (25b)-(25c), and thus σa ∈ Σ∗
that ρ∗

e = 0 for any e ∈ E.

<

pd
C(1)−C∅

1
. One can check that σa
E(1)
a. Therefore, we know from Lemma 3

• If j = 1, . . . , K:

Analogous to our discussion for j = 0, the following is an equilibrium strategy
of the attacker:

pd
Ce − C∅

(cid:32)

σ∗
a(e) =

,

∀e ∈ ∪j−1
k=1

σ∗
a(e) =

1
E(j)

σ∗
a(e) = 0,

1 −

j−1
(cid:88)

i=1

∀e ∈ E \ (cid:0)∪j

pdE(k)
C(k) − C∅
(cid:1) .
¯E(k)

k=1

¯E(k),
(cid:33)

,

∀e ∈ ¯E(j),

(cid:1).
From Lemma 3, we immediately obtain that ρ∗
¯E(k), the utility of the attacker in choosing e must
Furthermore, for any e ∈ ∪j−1
k=1
be the same as the utility for choosing any facility in ¯E(j), which is C(j) − pa.

e = 0 for any e ∈ E \ (cid:0)∪j−1

¯E(k)

k=1

39

Therefore, for any e ∈ ∪j−1
k=1

¯E(k), ρ∗ satisﬁes:

(6b)
⇒ ρ∗

e (C∅ − pa) + (1 − ρ∗

⇒

Ua(ρ∗, e) = C(j) − pa,
(cid:1) = C(j) − pa,
C(k) − C(j)
C(k) − C∅

e) (cid:0)C(k) − pa
ρ∗
e =

.

(cid:1), the utility for the attacker targeting
Additionally, for any e ∈ E \ (cid:0)∪j
e is Ce − pa, which is smaller than C(j) − pa. Thus, both condition (1) and (2)
are satisﬁed. ρ∗ is the unique equilibrium security eﬀort.

¯E(k)

k=1

C Proofs of Section 5

Proof of Lemma 4. For any non-vulnerable facility e, the best response strategy (cid:101)σa must
be such that (cid:101)σa(e, ˜ρ) = 0 for any ˜ρ.

Now consider any e ∈ {E|Ce − pa > C∅}. If ˜ρe > (cid:98)ρe, then we can write:

Ua(˜ρ, e) = ˜ρeC∅ + (1 − ˜ρe)Ce − pa < C∅ = Ua(˜ρ, ∅).

(48)

That is, the attacker’s expected utility of targeting the facility e is less than the expected
utility of no attack. Thus, in any attacker’s best response, (cid:101)σa(e, ˜ρ) = 0 for any such
facility e. Additionally, if ˜ρe = (cid:98)ρe, then Ua(e, ˜ρ) = Ua(∅, ˜ρ), i.e. the utility of targeting
such facility is identical with the utility of choosing no attack, and is higher than that
of any other pure strategies. Hence, the set of best response strategies of the attacker is
∆( ¯E ∗ ∪ {∅}), where ¯E ∗ is the set deﬁned in (28).

Otherwise, if there exists a facility e ∈ {E|Ce − pa > C∅} such that ˜ρe < (cid:98)ρe, then we

obtain:

Ua(˜ρ, e) = ˜ρeC∅ + (1 − ˜ρe)Ce − pa > C∅ = Ua(˜ρ, ∅).

Thus, no attack cannot be chosen in any best response strategy, which implies that the
attacker chooses to attack with probability 1. Finally, ¯E (cid:5) is the set of facilities which
incur the highest expected utility for the attacker given ˜ρ, thus BR(˜ρ) = ∆( ¯E (cid:5)).

Proof of Lemma 5. We ﬁrst prove that the total attack probability is either 0 or 1 in any
SPE. We discuss the following three cases separately:

• There exists at least one single facility e ∈ { ¯E|Ce − pa > C∅} such that ˜ρ∗
a(e, ˜ρ∗) = 1.

a(˜ρ∗) ∈ BR(˜ρ∗), from Lemma 4, we know that (cid:80)

Since (cid:101)σ∗

e∈ ¯E (cid:101)σ∗

e < (cid:98)ρe.

• For all e ∈ { ¯E|Ce − pa > C∅}, ˜ρ∗

e > (cid:98)ρe, i.e. the set ¯E ∗ in (28) is empty.

Since (cid:101)σ∗
i.e. (cid:80)

a(˜ρ∗) ∈ BR(˜ρ∗), from Lemma 4, we know that no edge is targeted in SPE,
e∈ ¯E (cid:101)σ∗

a(e, ˜ρ∗) = 0.

• For all e ∈ { ¯E|Ce − pa > C∅}, ˜ρ∗

e ≥ (cid:98)ρe, and the set ¯E ∗ in (28) is non-empty.

For the sake of contradiction, we assume that in SPE, there exists a facility e ∈ ¯E ∗

40

such that (cid:101)σ∗
follows:

a(e, ˜ρ∗) > 0, i.e. (cid:101)σ∗

a(∅, ˜ρ∗) < 1. Then, we can write Ud(˜ρ∗, (cid:101)σ∗

a(˜ρ∗)) as

Ud(˜ρ∗, (cid:101)σ∗

a(˜ρ∗)) = −C∅ − (1 − (cid:101)σ∗

a(∅, ˜ρ∗))pa −

(cid:32)

(cid:88)

(cid:33)

˜ρ∗
e

pd.

e∈ ¯E

(49)

Now, consider ˜ρ(cid:48) as follows:

e = ˜ρ∗
˜ρ(cid:48)
e = ˜ρ∗
˜ρ(cid:48)

e + (cid:15) > (cid:98)ρe, ∀e ∈ ¯E ∗,
e = 0,

∀e ∈ E \ ¯E ∗,

where (cid:15) is a suﬃciently small positive number. Given such a ˜ρ(cid:48), we know from
Lemma 4 that the unique best response is (cid:101)σa(∅, ˜ρ(cid:48)) = 1. Therefore, the defender’s
utility is given by:

Ud(˜ρ(cid:48), (cid:101)σa(˜ρ(cid:48))) = −C∅ −

(cid:32)

(cid:88)

(cid:33)

˜ρ(cid:48)
e

pd.

e∈E

Additionally,

Ud(˜ρ(cid:48), (cid:101)σa(˜ρ(cid:48))) − Ud(˜ρ∗, (cid:101)σa(˜ρ∗)) = (1 − (cid:101)σa(∅, ˜ρ∗))pa − (cid:15)pd| ¯E ∗|.
Since (cid:15) is suﬃciently small and (cid:101)σa(∅, ˜ρ∗) < 1, we obtain that Ud(˜ρ(cid:48), (cid:101)σa(˜ρ(cid:48))) >
Ud(˜ρ∗, (cid:101)σa(˜ρ∗)). Therefore, ˜ρ∗ cannot be a SPE. We can conclude that in this case,
the attacker chooses not to attack with probability 1.

We next show that in any SPE, the defender’s security eﬀort on each vulnerable facility
e is no higher than the threshold (cid:98)ρe deﬁned in (27). Assume for the sake of contradiction
that there exists a facility ¯e ∈ { ¯E|Ce − pa > C∅} such that ˜ρ¯e > (cid:98)ρ¯e. We discuss the
following two cases separately:

• The set (cid:98)e ∈ { ¯E|Ce − pa > C∅, ˜ρe < (cid:98)ρe} is non-empty. We know from Lemma 4
that BR(˜ρ) = ∆( ¯E (cid:5)), where the set ¯E (cid:5) in (29) is the set of facilities which incur the
highest utility for the attacker. Clearly, ¯E (cid:5) ⊆ { ¯E|Ce − pa > C∅, ˜ρe < (cid:98)ρe}, and hence
¯e /∈ ¯E (cid:5).
We consider ˜ρ(cid:48) such that ˜ρ(cid:48)
¯e = ˜ρ¯e − (cid:15), where (cid:15) is a suﬃciently small positive number,
¯e > (cid:98)ρ¯e still holds, and the set ¯E (cid:5) does
and ˜ρ(cid:48)
not change. The attacker’s best response strategy remains to be BR(˜ρ(cid:48)) = ∆( ¯E (cid:5)).
Hence, the utility of the defender given ˜ρ(cid:48) increases by (cid:15)pd compared to that given
˜ρ, because the expected usage cost Eσ[C] does not change, but the expected defense
cost decreases by (cid:15)pd. Thus, such ˜ρ cannot be the defender’s equilibrium eﬀort.

e = ˜ρe for any other facilities. Then ˜ρ(cid:48)

• For all e ∈ { ¯E|Ce − pa > C∅}, ˜ρe ≥ (cid:98)ρe. We have already argued that (cid:101)σ∗

a(∅, ˜ρ) = 1
in this case. Since the defense cost pd > 0, if there exists any e such that ˜ρe > (cid:98)ρe,
then by decreasing the security eﬀort on e, the utility of the defender increases.
Therefore, such ˜ρ cannot be an equilibrium strategy of the defender.

41

From both cases, we can conclude that for any e ∈ { ¯E|Ce − pa > C∅}, ˜ρ∗

e ≤ (cid:98)ρe

Finally, any non-vulnerable facilities e ∈ E \ {E|Ce − pa > C∅} will not be targeted,

hence we must have ˜ρ∗

e = 0.

Proof of Lemma 6. We ﬁrst show that the threshold (cid:101)pd(pa) as given in (31) is a well-
deﬁned function of pa. Given any 0 ≤ pa < C(1) − C∅, there is a unique i ∈ {1, . . . , K}
such that C(i+1) − C∅ ≤ pa < C(i) − C∅. Now, we need to show that there is a unique

j ∈ {1, . . . , i} such that

≤ pa <

(or 0 ≤ pa <

(cid:80)i

k=j+1 E(k)
E(k)
C(k)−C∅

k=1

(cid:80)i

(cid:80)i

k=j E(k)
E(k)
C(k)−C∅

(cid:80)i

k=1

(cid:80)i

k=1

(cid:34)

0,

(cid:80)i

k=1 E(k)
E(k)
C(k)−C∅

(cid:80)i

k=1

if

E(i)

E(k)
C(k)−C∅
(cid:35)

. Since

j = i). Note that functions {pij

d }i

j=1 are deﬁned on the range

{C(k)}i

k=1 satisﬁes (8), we have:

(cid:80)i

k=1 E(k)
E(k)
C(k)−C∅

k=1

(cid:80)i

≥

(cid:80)i

1
C(i)−C∅

k=1 E(k)
(cid:80)i

k=1 E(k)

= C(i) − C∅.

Hence, for any C(i+1) − C∅ ≤ pa < C(i) − C∅, the value (cid:101)pd(pa) is deﬁned as pij
d (pa) for a
unique j ∈ {1, . . . , i}. Therefore, we can conclude that for any 0 ≤ pa < C(1) − C∅, (cid:101)pd(pa)
is a well-deﬁned function.

We next show that (cid:101)pd(pa) is continuous and strictly increasing in pa. Since for any
i = 1, . . . , K, and any j = 1, . . . , i, the function pij
d (pa) is continuous and strictly increasing
in pa, (cid:101)pd(pa) must be piecewise continuous and strictly increasing in pa. It remains to be
shown that (cid:101)pd(pa) is continuous at pa ∈ (cid:8)C(i) − C∅

(cid:9)K
i=2 ∪

(cid:40)

(cid:41)

(cid:80)i

(cid:80)i

.

k=j E(k)
E(k)
C(k)−C∅

k=1

j=1,...,i,i=1,...K

We now show that for any i = 2, . . . , K, (cid:101)pd(pa) is continuous at C(i) − C∅. Consider
pa = C(i) − C∅ − (cid:15) where (cid:15) is a suﬃciently small positive number. There is a unique
ˆj ∈ {1, . . . , i} such that (cid:101)pd(pa) = piˆj

d (pa). We want to argue that ˆj (cid:54)= i:

pa ·

(cid:32) i

(cid:88)

k=1

(cid:33)

E(k)
C(k) − C∅

= (cid:0)C(i) − C∅ − (cid:15)(cid:1) ·

(cid:32) i

(cid:88)

k=1

(cid:33)

E(k)
C(k) − C∅

= E(i) +

i−1
(cid:88)

(cid:0)C(i) − C∅

(cid:1) E(k)

C(k) − C∅

k=1

− (cid:15)

(cid:32) i

(cid:88)

k=1

(cid:33)

E(k)
C(k) − C∅

> E(i),

⇒

pa = C(i) − C∅ − (cid:15) >

E(i)

(cid:80)i

k=1

E(k)
C(k)−C∅

Thus, ˆj ∈ {1, . . . , i − 1}, and from (31),

(cid:80)i

k=ˆj+1

E(k)
E(k)
C(k)−C∅

≤ C(i) − C∅ − (cid:15) <

(cid:80)i

k=ˆj

(cid:80)i

k=1

E(k)
E(k)
C(k)−C∅

. Since

(cid:80)i

k=1

42

(cid:15) is a suﬃciently small positive number, we have:

i
(cid:88)

k=ˆj+1

E(k) ≤

(cid:32) i

(cid:88)

k=1

(cid:33)

E(k)
C(k) − C∅

· (cid:0)C(i) − C∅ − (cid:15)(cid:1)

= E(i) +

i−1
(cid:88)

(cid:0)C(i) − C∅

(cid:1) E(k)

k=1

(cid:0)C(i) − C∅

C(k) − C∅
(cid:1) E(k)

+ (cid:15)

C(k) − C∅

− (cid:15)

(cid:32) i

(cid:88)

k=1

(cid:33)

E(k)
C(k) − C∅
(cid:33)

(cid:32) i−1
(cid:88)

k=1

E(k)
C(k) − C∅

⇒

⇒

i−1
(cid:88)

E(k) ≤

i−1
(cid:88)

k=1

(cid:80)i−1

k=ˆj+1
k=ˆj+1 E(k)
E(k)
C(k)−C∅

(cid:80)i−1
k=1

≤ C(i) − C∅ + (cid:15).

Analogously, we can check that C(i) − C∅ + (cid:15) <

(cid:80)i−1
k=ˆj

E(k)
E(k)
C(k)−C∅

(cid:80)i−1
k=1

. Hence, from (31), when

pa = C(i) − C∅ + (cid:15), we have (cid:101)pd(pa) = pi−1ˆj

d

(pa). Then,

lim

pa→(C(i)−C∅)− (cid:101)pd(pa) = lim

(cid:15)→0

piˆj
d (C(i) − C∅ − (cid:15))

(30)
=

(cid:16)

= lim
(cid:15)→0

C(ˆj) − C∅
pi−1ˆj

d

(cid:17)

(cid:16)(cid:80)ˆj−1

k=1

·

C(ˆj) − C∅
(cid:17)

E(k)
C(k)−C∅

+ (cid:80)i−1

k=ˆj E(k) − (cid:80)i−1

k=1

paE(k)
C(k)−C∅

(C(i) − C∅ + (cid:15)) =

lim

pa→(C(i)−C∅)+ (cid:101)pd(pa).

Thus, (cid:101)pd(pa) is continuous at C(i) − C∅ for any i = 2, . . . , K.

For any i = 1, . . . , K, we next show that (cid:101)pd(pa) is continuous at pa =

j = 1, . . . , i:

(cid:80)i

k=j E(k)
E(k)
C(k)−C∅

(cid:80)i

k=1

for



pa→




lim
(cid:80)i

k=j

E(k)
E(k)
C(k)−C∅

(cid:80)i

k=1

− (cid:101)pd(pa) = pij

d










(cid:80)i

k=j E(k)
E(k)
C(k)−C∅

k=1

(cid:80)i



 =

(cid:32) j−1
(cid:88)

k=1

E(k)
C(k) − C∅

(cid:33)−1





= pi(j−1)
d

(cid:80)i

k=j E(k)
E(k)
C(k)−C∅

k=1

(cid:80)i



 =



pa→




lim
(cid:80)i

k=j

E(k)
E(k)
C(k)−C∅

(cid:80)i

k=1

+ (cid:101)pd(pa).






Hence, we can conclude that (cid:101)pd(pa) is continuous and strictly increasing in pa.

43

Additionally, for any i = 1, . . . , K, consider any pa such that C(i+1) − C∅ < pa ≤

C(i) − C∅ (or 0 < pa ≤ C(K) − C∅ if i = K), then for any j = 1, . . . , i, we have:

pij
d (pa)

(30)
=

(cid:0)C(j) − pa − C∅

(cid:1) ·

(cid:16)(cid:80)j−1

>

=

(8)
>

(cid:16)(cid:80)j−1

k=1

(cid:1) ·
C(j) − C∅
(cid:16)(cid:80)i
(cid:1) ·

k=1

(cid:33)−1

(cid:0)C(j) − C(i+1)

(cid:0)C(j) − C(i+1)
(cid:32) i

(cid:88)

k=1

E(k)
C(k) − C∅

+ (cid:80)i

k=j

(C(k)−pa−C∅)E(k)
C(k)−C∅

+ (cid:80)i

k=j

(C(k)−C(i+1))E(k)
C(k)−C∅

C(j) − C∅
(cid:17)
E(k)
k=1
C(k)−C∅
C(j) − C∅
(cid:17)
E(k)
C(k)−C∅

(cid:17)

E(k)
C(k)−C∅

(17)
= ¯pd(pa).

Therefore, for any 0 < pa < C(1) − C∅, we have:

(cid:101)pd(pa)

(31)
≥ min
j=1,...,i

pij
d (pa) > ¯pd(pa),

(50)

Finally, if pa = 0, then we know that (cid:101)pd(0) = pKK
(cid:17)−1
pKK
(0) =
d
and we have:

E(k)
C(k)−C∅

(cid:16)(cid:80)K

k=1

d

(0). From (30), we can check that

= ¯pd(0). If pa approaches C(1) − C∅, then (cid:101)pd(pa) = p11

d (pa),

lim
pa→C(1)−C∅

(cid:101)pd(pa)

(30)
=

lim
pa→C(1)−C∅

C(1) − C∅
E(1) − paE(1)
C(1)−C∅

= +∞

We deﬁne the partition as:

P ∆=

(cid:110)(cid:8)Λi(cid:9)K

i=0 , (cid:8)Λi

j

(cid:9)

j=1,...,i,i=1,...,K,

(cid:111)

,

(51)

where {Λi}K
the set of (pd, pa), which satisfy:

i=0 are type I regimes in the normal form game deﬁned in (18)-(20), and Λi

j is




(cid:18)(cid:16) E(1)
C(1)−C∅

(cid:17)−1

(cid:19)

, +∞

,

(cid:18)(cid:16)(cid:80)j

E(k)
C(k)−C∅


,
(cid:26) (cid:0)C(i+1) − C∅, C(i) − C∅

k=1

(cid:0)0, C(K) − C∅

(cid:1) ,

pd ∈

pa ∈

(cid:17)−1

(cid:16)(cid:80)j−1

k=1

if j = 1,

(cid:17)−1(cid:19)

E(k)
C(k)−C∅

,

if j = 2, . . . , K,

(cid:1) ,

if i = 1, . . . , K − 1,
if i = K,

(52a)

(52b)

We can check that sets in P are disjoint, and cover the whole space of (pd, pa). Lemma 7
characterizes SPE in sets {Λi}K

i=0, and Lemma 8 characterizes SPE in sets (cid:8)Λi

(cid:9)i=K,j=i
i=1,j=1

.

j

44

Lemma 7. In (cid:101)Γ, for any (pa, pd) in the set Λi, where i = 0, . . . , K:

• If i = 0, then SPE is as given in (37).

• If i = 1, . . . , K: then SPE is as given in (38).

Proof of Lemma 7.

• If i = 0:

The set of vulnerable facilities { ¯E|Ce − pa > C∅} is empty. Thus, (cid:101)σ∗
˜ρ∗
e = 0 for all e ∈ E.

a(∅, ˜ρ) = 1, and

• For any i = 1, . . . , K:

The set of vulnerable facilities is ∪i
that for any e ∈ ∪i
exists a facility ¯e ∈ ∪i
a(∅, ˜ρ) = 0, and BR(˜ρ) = ∆( ¯E (cid:5)), where ¯E (cid:5) is in (29). Clearly, ¯E (cid:5) ⊆ ∪i
(cid:101)σ∗
deﬁne λ as follows:

¯E(k). From Lemma 5, we have already known
e ≤ (cid:98)ρe. Assume for the sake of contradiction that there
¯E(k) such that ˜ρ¯e < (cid:98)ρ¯e. From Lemma 4, we know that
¯E(k). We

¯E(k), ˜ρ∗

k=1

k=1

k=1

k=1

λ = max
e∈∪i
k=1

¯E(k)

{˜ρeC∅ + (1 − ˜ρe)Ce} = ˜ρeC∅ + (1 − ˜ρe)Ce,

∀e ∈ ¯E (cid:5).

The utility of the defender can be written as:

Ud(˜ρ, (cid:101)σ∗

a(˜ρ)) = −λ −

(cid:33)

˜ρe

· pd.

(cid:32)

(cid:88)

e∈E

We now consider ˜ρ(cid:48) as follows:

˜ρ(cid:48)
e = ˜ρe +

˜ρ(cid:48)
e = ˜ρe,

(cid:15)
Ce − C∅

, ∀e ∈ ¯E (cid:5),

∀e ∈ E \ ¯E (cid:5),

where (cid:15) is a suﬃciently small positive number. Under this deviation, we can check
that the set ¯E (cid:5) does not change, but λ changes to λ − (cid:15). Therefore, the defender’s
utility can be written as:

Ud(˜ρ(cid:48), (cid:101)σa(˜ρ(cid:48))) = −λ + (cid:15) −

(cid:33)

(cid:32)

(cid:88)

e∈E

˜ρ(cid:48)
e

· pd = −λ + (cid:15) −

(cid:32)

=Ud(˜ρ, (cid:101)σa(˜ρ)) + (cid:15)

1 −

(cid:32)

=Ud(˜ρ, (cid:101)σa(˜ρ)) + (cid:15)

1 −

(cid:33)

pd
Ce − C∅

(cid:33)

pdE(k)
Ce − C∅

(cid:88)

e∈ ¯E (cid:5)

i
(cid:88)

k=1

≥ Ud(˜ρ, (cid:101)σa(˜ρ)) + (cid:15)

1 −

(cid:88)

e∈∪i

k=1

¯E(k)

(19)

> Ud(˜ρ, (cid:101)σa(˜ρ)).

(cid:33)

˜ρe

· pd −

(cid:88)

e∈ ¯E (cid:5)

(cid:32)

(cid:88)

e∈E


(cid:15)pd
Ce − C∅


pd
Ce − C∅



Therefore, such ˜ρ cannot be an equilibrium strategy proﬁle. We thus know that ˜ρ∗
is as given in (38). The attacker’s equilibrium strategy can be derived from Lemmas
4 and 5 directly.

45

Lemma 8. For (pa, pd) in Λi
of SPE:

j, where i = 1, . . . , K, and j = 1, . . . , i, there are two cases

• If pd > pij

d , where pij

d is as given in (30):

– If j = 1, then SPE is as given in (39).

– If j = 2, . . . , i, then SPE is as given in (40).

d , then the SPE is as given in (38).

• If pd < pij
Proof of Lemma 8. Consider cost parameters in the set Λi
j deﬁned in (52), where
¯E(k). From Lemma
i = 1, . . . , K and j = 1, . . . , i. The set of vulnerable facilities is ∪i
¯E(k) with
5, we know that the defender can either secure all vulnerable facilities e ∈ ∪i
the threshold eﬀort (cid:98)ρe deﬁned in (27), or leave at least one vulnerable facility secured less
than the threshold eﬀort. We discuss the two cases separately:

k=1

k=1

(1) If any e ∈ ∪i

¯E(k) is secured with the threshold eﬀort (cid:98)ρe, then from Lemma 5, we
know that the total probability of attack is 0. The defender’s utility can be written
as:

k=1

Ud((cid:98)ρ, (cid:101)σ∗

a((cid:98)ρ)) = −C∅ −

(cid:32) i

(cid:88)

k=1

(cid:0)C(k) − pa − C∅
C(k) − C∅

(cid:1) · E(k)

(cid:33)

· pd.

(53)

(2) If the set {E|Ce − pa > C∅,

˜ρe < (cid:98)ρe} is non-empty, then we deﬁne (cid:101)P as the set
of feasible ˜ρ in this case. We denote ˜ρ† as the secure eﬀort vector that incurs the
highest utility for the defender among all ˜ρ ∈ (cid:101)P . Then, ˜ρ† can be written as:
(cid:32)

(cid:33)

(cid:32)

(cid:33)

˜ρ† ∈ argmax

˜ρ∈ (cid:101)P
(cid:32)

Ud(˜ρ, (cid:101)σ∗

a(˜ρ)) = argmax

˜ρ∈ (cid:101)P

−E(˜ρ,(cid:101)σ∗
(cid:32)

=argmax
˜ρ∈ (cid:101)P

−E(˜ρ,(cid:101)σ∗

a(˜ρ))[C] −

(cid:33)

˜ρe

· pd +

(cid:32)

(cid:88)

e∈E

a(˜ρ))[C] −

(cid:88)

˜ρe

· pd

(cid:88)

e∈E

e∈E
(cid:33)

(cid:101)σ∗
a(e, ˜ρ)

· pa −

(cid:32)

(cid:88)

e∈E

(cid:33)

(cid:33)

· pa

.

(cid:101)σ∗
a(e, ˜ρ)

(54)

We know from Lemma 4 that (cid:101)σ∗
can be re-expressed as:

a(∅, ˜ρ) = 0. Therefore, (cid:80)

e∈E (cid:101)σ∗

a(e, ˜ρ) = 1, and (54)

˜ρ† ∈ argmax

˜ρ∈ (cid:101)P

= argmax

˜ρ∈ (cid:101)P

(cid:32)

a(˜ρ))[C] −

−E(˜ρ,(cid:101)σ∗
(cid:32)

−E(˜ρ,(cid:101)σ∗

a(˜ρ))[C] −

(cid:33)

˜ρe

· pd +

(cid:33)

˜ρe

· pd +

(cid:32)

(cid:88)

(cid:32)

e∈E

(cid:88)

e∈E

(cid:32)

(cid:88)

(cid:32)

e∈E

(cid:88)

e∈E

(cid:33)

(cid:33)

(cid:101)σ∗
a(e, ˜ρ)

· pa − pa

(cid:33)

(cid:33)

· pa

.

(cid:101)σ∗
a(e, ˜ρ)

Since in equilibrium, the attacker chooses the best response strategy, we have:
(cid:33)

(cid:32)

(cid:33)

(cid:33)

(cid:32)

(cid:32)

E(˜ρ,(cid:101)σ∗

a(˜ρ))[C] −

(cid:88)

e∈E

(cid:101)σ∗
a(e, ˜ρ)

· pa = max

(cid:101)σa∈∆(Sa)

E(˜ρ,(cid:101)σa)[C] −

46

(cid:88)

(cid:101)σa(e)

· pa

.

e∈E

(55)

Hence, ˜ρ† can be re-expressed as:

˜ρ† (55)

= argmax

˜ρ∈ (cid:101)P

(cid:32)

= argmax

˜ρ∈ (cid:101)P

− max

(cid:101)σa∈∆(Sa)
(cid:32)

E(˜ρ,(cid:101)σa)[C] −
(cid:32)

= argmax

˜ρ∈ (cid:101)P

min
(cid:101)σa∈∆(Sa)

−E(˜ρ,(cid:101)σa)[C] +

(9a)
= argmax

˜ρ∈ (cid:101)P

min
(cid:101)σa∈∆(Sa)

U 0
d (˜ρ, (cid:101)σa).

(cid:32)

(cid:32)

(cid:32)

− max

(cid:101)σa∈∆(Sa)
(cid:32)

E(˜ρ,(cid:101)σa)[C] −
(cid:32)

(cid:88)

e∈E

(cid:101)σa(e)
(cid:33)

(cid:33)

(cid:33)

· pa

−

(cid:32)

(cid:88)

(cid:33)

(cid:33)

˜ρe

· pd

(cid:32)

e∈E

(cid:33)

(cid:33)(cid:33)

(cid:88)

e∈E

(cid:101)σa(e)
(cid:33)

· pa +

(cid:32)

(cid:101)σa(e)

· pa −

(cid:88)

e∈E

˜ρe

(cid:33)

· pd

(cid:33)

˜ρe

· pd

(cid:88)

e∈E

(cid:88)

e∈E

Therefore, ˜ρ† is the defender’s equilibrium strategy in the zero sum game, which
is identical to the equilibrium strategy in the normal form game (recall Lemma 2).
From Theorem 1, when pa and pd are in Λi
j, ˜ρ† is in (40) (or (39) if j = 1). The
defender’s utility in this case is:

Ud(˜ρ†, (cid:101)σ∗

a(˜ρ†)) = −C(j) −

(cid:32) j−1
(cid:88)

(cid:0)C(k) − C(j)

(cid:1) · E(k)

(cid:33)

k=1

C(k) − C∅

· pd.

(56)

Finally, by comparing Ud in (56) and (53), we can check that if pd > pij
Ud((cid:98)ρ, (cid:101)σ∗
Ud((cid:98)ρ, (cid:101)σ∗
Proof of Theorem 2.

a((cid:98)ρ)). Thus, SPE is in (40) (or (39) if j = 1). If pd < pij
a((cid:98)ρ)), and SPE is in (38).

d , then Ud(˜ρ†, (cid:101)σ∗

a(˜ρ†)) >

d , then Ud(˜ρ†, (cid:101)σ∗

a(˜ρ†)) <

(a) Type (cid:101)I regimes (cid:101)Λi:

– If i = 0:

There is no vulnerable facility. Therefore, the attacker chooses not to attack
with probability 1, and the defender does not secure any facility. SPE is as
given in (37).

– If i = 1, . . . , K:

Consider any C(i+1) − C∅ < pa < C(i) − C∅. From Lemma (6), we know that
(cid:101)pd(pa) > ¯pd(pa), where (cid:101)pd(pa) is deﬁned in (31) and ¯pd(pa) is as deﬁned in (16).
From Lemma 7, we know that SPE is as given in (38) for any pd < ¯pd(pa).
It remains to be shown that for any ¯pd(pa) ≤ pd < (cid:101)pd(pa), SPE is also as given
in (38). For any C(i+1) − C∅ ≤ pa < C(i) − C∅, there is a unique ˆj ∈ {1, . . . , i}

47

such that

(cid:80)i

k=ˆj+1

E(k)
E(k)
C(k)−C∅

≤ pa <

(cid:80)i

k=ˆj

(cid:80)i

k=1

E(k)
E(k)
C(k)−C∅

, and from (31), we have:

(cid:80)i

k=1

(cid:101)pd(pa) = piˆj

d (pa) ≥ piˆj

d

(cid:101)pd(pa) = piˆj

d (pa) < piˆj

d









(30)
=





ˆj
(cid:88)

k=1



−1



,

E(k)
C(k) − C∅



ˆj−1
(cid:88)



−1



.

E(k)
C(k) − C∅

 =









(cid:80)i

(cid:80)i

k=ˆj+1 E(k)
E(k)
C(k)−C∅

k=1

(cid:80)i

(cid:80)i

k=1

k=ˆj E(k)
E(k)
C(k)−C∅
(cid:16)(cid:80)j

Consider any j = ˆj+1, . . . , i, and any
k=1
the cost parameters (pa, pd) are in the set Λi
from our deﬁnition of ˆj, we know that pa >

k=1

(cid:17)−1

(cid:16)(cid:80)j−1

≤ pd <

E(k)
E(k)
C(k)−C∅
C(k)−C∅
j as deﬁned in (52). Additionally,
. We now show that

k=1

(cid:80)i

k=j E(k)
E(k)
C(k)−C∅

(cid:80)i

k=1

(cid:17)−1

,

in Λi

j, pd < pij

d (pa):

pij
d (pa)

(30)
> pij
d





(cid:80)i

k=j E(k)
E(k)
C(k)−C∅

k=1

(cid:80)i



 =

(cid:32) j−1
(cid:88)

k=1

E(k)
C(k) − C∅

(cid:33)−1

(52)
> pd.

k=1

(cid:17)−1

E(k)
C(k)−C∅

Hence, from Lemma 8, we know that for any
(cid:16)(cid:80)ˆj

, SPE is as given in (38). For any
ˆj
(cid:101)pd(pa), the cost parameters (pa, pd) are in the set Λ
Again from Lemma 8, SPE is in (38).
Therefore, we can conclude that in regime (cid:101)Λi, SPE is in (38).

(cid:16)(cid:80)ˆj

k=1

(cid:16)(cid:80)i

k=1

(cid:17)−1

E(k)
C(k)−C∅
E(k)
C(k)−C∅

≤ pd ≤

(cid:17)−1

< pd <

i , and pd < (cid:101)pd(pa) = piˆj

d (pa).

(b) Type (cid:101)II regimes (cid:101)Λj, where j = 1, . . . , K:

Since (cid:101)pd(pa) is strictly increasing in pa and limpa→C(1)−C∅ (cid:101)pd(pa) = +∞, we know
that for any pd > 0, pa < (cid:101)p−1
d (pd) < C(1) − C∅. Therefore, we can re-express (cid:101)Λ1 as
follows:

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:40)

(pa, pd)

(cid:101)Λ1 (35)
=

(cid:40)

=

(pa, pd)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

pa < (cid:101)p−1

d (pd), pd >

(cid:19)−1 (cid:41)

(cid:18) E(1)

C(1) − C∅

pd > (cid:101)pd(pa), pd >

(cid:18) E(1)

(cid:19)−1

C(1) − C∅

, 0 ≤ pa ≤ C(1) − C∅

(cid:41)

(52)
= =

K
(cid:91)

(cid:16)

i=1

(cid:92)

Λi
j

{(pa, pd) |pd > (cid:101)pd(pa)}

(cid:17)

.

For any j = 2, . . . , K, if pa > C(j) − C∅, then from Lemma 6, we have:

(cid:101)pd(pa) > ¯pd(pa)

(cid:32) j−1
(cid:88)

(17)
≥

k=1

(cid:33)−1

.

E(k)
C(k) − C∅

48

(57)

(58)

Therefore, for any pd <

(cid:16)(cid:80)j−1

k=1

E(k)
C(k)−C∅

(cid:17)−1

, we know that pa < (cid:101)p−1

d (pd) < C(j) − C∅.

Analogous to (57), we re-express the set (cid:101)Λj as follows:

(36)
=

(cid:101)Λj

(58)
=

(pa, pd)





(cid:40)

(pa, pd)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

pa < (cid:101)p−1

d (pd),

(cid:33)−1

(cid:32) j

(cid:88)

k=1

E(k)
C(k) − C∅

≤ pd <

(cid:32) j−1
(cid:88)

k=1

E(k)
C(k) − C∅

(cid:33)−1 




(cid:16)(cid:80)j

pd > (cid:101)pd(pa),
0 ≤ pa ≤ C(j) − C∅

k=1

(cid:17)−1

E(k)
C(k)−C∅

≤ pd <

(cid:16)(cid:80)j−1

k=1

E(k)
C(k)−C∅

(cid:41)

(cid:17)−1

,

(52)
=

K
(cid:91)

(cid:16)

Λi
j

i=j

(cid:92)

{(pa, pd) |pd > (cid:101)pd(pa)}

(cid:17)

.

We next show that for any j = 1, . . . , K, and any i = j, . . . , K, the set Λi
{(pa, pd) |pd > (cid:101)pd(pa)} ⊆ Λi
(pa, pd) in the set Λi
(cid:80)i
E(k)
E(k)
C(k)−C∅

j ∩
d (pa)}. Consider any cost parameters
j ∩ {(pa, pd) |pd > (cid:101)pd(pa)}, from (31), we can ﬁnd ˆj such that
d (pa). We discuss the following

, and (cid:101)pd(pa) = piˆj

j ∩ {(pa, pd) |pd > pij

E(k)
E(k)
C(k)−C∅

≤ pa <

k=ˆj+1

k=ˆj

(cid:80)i

(cid:80)i

(cid:80)i

k=1

k=1

three cases separately:

– If ˆj > j, then we must have pa <

(cid:16)(cid:80)j

k=1

(cid:17)−1

E(k)
C(k)−C∅

pij
d (pa) <
that pd > pij

d (pa) in this set, and thus (pa, pd) ∈ Λi
– If ˆj = j, then we directly obtain that (pa, pd) ∈ Λi

(cid:80)i

k=ˆj

(cid:80)i

k=1

E(k)
E(k)
C(k)−C∅

≤

(cid:80)i

k=j+1 E(k)
E(k)
C(k)−C∅

k=1

(cid:80)i

. Hence, from (30),

. From the deﬁnition of the set Λi

j in (52), we know

j ∩ {(pa, pd) |pd > pij
j ∩ {(pa, pd) |pd > pij
, from (30), we have (cid:101)pd(pa) = piˆj
(cid:17)−1

d (pa)}.
d (pa)}.

d (pa) ≥

(cid:17)−1

(cid:16)(cid:80)ˆj

E(k)
C(k)−C∅
(52), the set Λi

k=1

≥

k=1

. From the deﬁnition of the set Λi
j ∩ {(pa, pd) |pd > (cid:101)pd(pa)} is empty, and thus can be omitted.
j ∩ {(pa, pd) |pd > (cid:101)pd(pa)} ⊆ Λi

j ∩
d (pa)}. Therefore, from Lemma 8, SPE is in (40) (or (39) if j = 1)

j in

We can conclude from all three cases that Λi
{(pa, pd) |pd > pij
in the regime (cid:101)Λj.

(cid:80)i

(cid:80)i

k=1

k=ˆj+1

E(k)
E(k)
C(k)−C∅
E(k)
C(k)−C∅

(cid:16)(cid:80)j−1

– If ˆj < j, then since pa ≥

49

