BinImg2Vec: Augmenting Malware Binary Image
Classiﬁcation with Data2Vec

Lee Joon Sern
Ensign Labs
Ensign InfoSecurity
Singapore
lee_joonsern@ensigninfosecurity.com

Tay Kai Keng
Ensign Consulting
Ensign InfoSecurity
Singapore
kaikeng_tay@ensigninfosecurity.com

Chua Zong Fu
Ensign Consulting
Ensign InfoSecurity
Singapore
zongfu_chua@ensigninfosecurity.com

2
2
0
2

p
e
S
2

]

R
C
.
s
c
[

1
v
2
8
7
0
0
.
9
0
2
2
:
v
i
X
r
a

Abstract—Rapid digitalisation spurred by the Covid-19 pan-
demic has resulted in more cyber crime. Malware-as-a-service
is now a booming business for cyber criminals. With the
it is vital for cyber defenders
surge in malware activities,
to understand more about the malware samples they have
at hand as such information can greatly inﬂuence their next
course of actions during a breach. Recently, researchers have
shown how malware family classiﬁcation can be done by
ﬁrst converting malware binaries into grayscale images and
then passing them through neural networks for classiﬁcation.
However, most work focus on studying the impact of different
neural network architectures on classiﬁcation performance.
In the last year, researchers have shown that augmenting
supervised learning with self-supervised learning can improve
performance. Even more recently, Data2Vec was proposed as
a modality agnostic self-supervised framework to train neural
networks. In this paper, we present BinImg2Vec, a framework
of training malware binary image classiﬁers that incorpo-
rates both self-supervised learning and supervised learning to
produce a model that consistently outperforms one trained
only via supervised learning. We were able to achieve a
4% improvement in classiﬁcation performance and a 0.5%
reduction in performance variance over multiple runs. We also
show how our framework produces embeddings that can be
well clustered, facilitating model explanability.
Index Terms—Malware, Neural Networks

I. INTRODUCTION
The rapid digital adoption, spurred largely by the Covid-
19 pandemic, to support work-from-home arrangements all
over the world, has resulted in a surge in worldwide Internet
usage. [1]. This has in turn fueled cyber-attacks; In 2021,
Governments worldwide experienced a 1,885% increase in
ransomware attacks, while the healthcare industry alone
experienced a 775% increase in those attacks in 2021 [2].
In fact, Malware-as-a-service (MaaS) is now a booming
business for cybercrime organisations with new malware
samples increasing 106% year-on-year in 2021 [3]. Tradi-
tional signature-based matching approaches to detect and
proﬁle malware into their respective families may no longer
work simply because of the inability to capture and obtain
signatures for every single malware out there in the wild. In
fact, Vijayan found that around three quarters of malware
samples collected in Q1 2021 would have evaded traditional
signature-based secturity tools [4]. As such, it is increasingly

important for cyber defenders to move away from signature-
based methods and ﬁnd generalizable, scalable methods to
detect and proﬁle the rapidly increasing number of malware.
In this paper, we study how image classiﬁcation methods
can be applied to the malware family classiﬁcation problem.
This is particularly important as the ability to classify the
malware family will provide cyber defenders an idea of what
the malware was designed to do, thus reducing the search
space for cyber incident responders when trying to contain
a breach by the malware.

II. RELATED WORK

In 2011, Nataraj et al. coined a novel

idea to turn
malware binaries into byte images. They then made use of
the well known GIST image descriptor method to extract
feature vectors from each of the images. They found that
malware belonging to the same family tend to have similar
feature vectors resulting in them being loosely clustered
together [5]. Though extremely promising,
it was noted
that improvements could be made through a learning based
algorithm such as artiﬁcial neural networks[6].

In 2015, Makandar and Patrot proposed to enhance
Nataraj et al.’s work by applying the Discrete Wavelet
Transformation on the malware images to extract additional
features, on top of GIST, before passing them all through
a multi-layered perceptron (MLP) neural network to train a
malware family classiﬁer [6]. Subsequently, with the advent
and adoption of Convolutional Neural Networks (CNN)
over multiple domains, Luo and Lo proposed passing the
entire malware image binary through a CNN without any
hand engineered features [7]. They showed that they were
able to get 93.17% classiﬁcation accuracy over 32 malware
families. Separately, Bensaoud et al. also showed good
performance of CNN based techniques, achieving 99.24%
accuracy over 25 families [8]. With deep learning showing
promising results in this domain, Prajapati and Mark, in
2021, conducted an empirical analysis of various well known
deep learning methods ranging from MLPs, CNNs, Recur-
rent Neural Networks (RNN), Long Short-Term Memory
(LSTM), etc. He found that CNN based methods provided
the best results empirically [9].

To the best of our knowledge, all previous works in this
domain trained the deep neural networks via supervised

 
 
 
 
 
 
Fig. 1. Data2Vec Framework

learning, using the softmax cross-entropy loss function,
which is commonly used to train multi-class classiﬁers.
While supervised learning has conventionally been shown
to be the de-facto method to train neural networks,
if
labels are available, due to the fact that its associated loss
functions like the softmax cross-entropy loss function is
convex, a number of recent works have proposed methods
that have been shown to be able to surpass supervised-only
training. In particular, recent work showed that augmenting
supervised learning with self-supervised learning techniques
could improve model performance signiﬁcantly. For exam-
ple, He et al.,
in 2021, showed that randomly masking
pixels of an input image helps an autoencoder learn more
robust embeddings, which would be useful for subsequent
ﬁne tuning tasks [10]. Separately, Bao et al. showed that
pre-training transformer based neural networks via a self-
supervised approach helped improve classiﬁcation accuracy
by approximately 2% [11]. A signiﬁcant drawback of these
ﬁndings is that they are domain dependent, meaning that
some of these proposed methods only work well for natural
language processing, while others work well on image
tasks; they may not work well across multiple domains (i.e.
modalities). To address this issue Baevski et al., in Feb 2022,
proposed a possible modality agnostic framework that they
showed could work equally well across multiple modalities,
from image processing to natural language processing and
even speech processing [12].

In particular, Baevski et al. proposed the data2vec frame-
work as shown in Fig. 1 [12]. Similar to He et al., they
ﬁrst proposed to apply a random mask to the input, be
it an image, speech or even text. The unmasked input is
then passed to a teacher neural network (TNN) to output a
series of embeddings. Similarly, the masked input is passed
to a student neural network (SNN) to output another series
of embeddings. It is important to note that the TNN and
the SNN are identical in architecture. However, the weights
of the TNN are actually an exponential moving average
of the SNN as it is updated. The weights of the TNN
are parameterised as shown in Equation (1), where (cid:52)n+1
represents the weights of the TNN at training step n+1, (cid:52)n
represents the weights of the TNN at step n, θ represents the
weights of the SNN at step n and τ represents the exponetial

moving average multiplier. Finally, the loss between the
series of embeddings output by both the TNN and SNN
is minimised, while holding the embedding output of the
TNN constant (i.e. a ﬁxed non-differentiable target).

(cid:52)n+1 = (cid:52)nτ + (1 − τ )θn

(1)

Data2Vec has been well received by the deep learning
community not only because of it being modality agnostic
but also because it precludes the need to train the decoding
portion of auto-encoders. Conventionally, one would train
an auto-encoder neural network comprising an encoder and
a decoder, to obtain embeddings that contain summarized
information of the encoder’s input [10]. However, the de-
coder is rarely used once the embeddings are obtained as
the main purpose of the autoencoder was to obtain the
encoder and its ouput embeddings. Furthermore, conducting
backpropagation of gradients through the decoder is an
expensive process as the decoder needs to reconstruct the
encoder’s input. Data2Vec is a signiﬁcant step up as it
precludes the need to train a decoder. Instead, it bootstraps
the training using an exponential moving average of the
SNN’s weights. This together with its modality agnostic
characteristic have resulted in data2vec garnering alot of
interest from the research community recently [13] [14].

We now highlight our main contributions. Our major
contribution is the study of how the data2vec framework
can be applied to the malware image binary classiﬁcation
problem. We will validate if data2vec is applicable even
to malware binary images and we will also propose a
method to incorporate the data2vec framework in order to
train a malware binary image family classiﬁer in an end-to-
end fashion. We will also evaluate the performance of our
proposed framework. Our other contribution is an in-depth
study of the neural network’s output to better understand
what the network has learnt in order to aid explanability
and deeper analysis.

III. PRELIMINARIES AND PROBLEM SETUP
In this section, we will review how malware binaries can
be converted to images and formally deﬁne the classiﬁcation
problem. In this paper, the malware binaries that we analyse
pertain only to Windows malware. Thus, they would be in

Fig. 2. Examples of Malware Binary Images

Fig. 3. Model Design

Portable Executable format, having ﬁle extensions .bin, .dll
and .exe [8]. These malware binaries comprise of a series
of bits and can be converted 8 bits at a time to pixels in
a grayscale image, comprising of textural patterns. This is
because each byte (i.e. 8 bit) can be mapped to an integer
between 0 to 255 and the entire byte array can be mapped
to a grayscale image.

Our dataset of malware binaries were obtained from
multiple online data sources [15] [16] and comprise of 61
Windows malware families. To convert them to images, we
ﬁrst studied the size of the byte array. We found that a
majority of the malware binaries, when converted to a byte
array had lengths around 640,000 (i.e. 640 kilobytes). Thus
we set the width of the image to be 800 so that most of
the images would be square in nature. This would facilitate
downstream resizing without signiﬁcant information loss. It
would also facilitate easier CNN designs as the kernel sizes
can all be square too. The steps below summarize how we

preprocess each of the malware binaries into images before
passing them as input to the classiﬁcation model.
1) Read in malware binaries as a byte array.
2) Zero pad the byte array so that its length is divisible

by 800.

3) Reshape the zero padded byte array such that its width

is 800.

4) Resize the entire array into a 400 × 400 grayscale
image. This facilitates a larger batch size when training
on RAM constrained Graph Processing Units (GPUs)
Figure 2 depicts samples of 2 malware families from
our dataset after the above preprocessing steps. As can
be seen, malware of the same family show similar visual
textures. In particular, those of the Gandcrab malware have
near identical characteristics at the top of the image, while
those of AgentTesla have diagonal lines cutting across the
image. These hint at the possibility of image classiﬁcation
methods being used to classify malwares into their family.

After images of the malware binaries are obtained, methods
described in previous works [7][8][9] all train a CNN using
the softmax cross entropy loss function. The softmax cross
entropy loss is as deﬁned in (2), where m is the batch
size, yi is a one hot vector indicating the labelled class for
that particular sample and ˆyi is the softmax output of the
CNN, which is actually a discrete probability distribution
describing the probability a particular malware binary image
sample belongs to each of the known malware families in
the dataset. This loss function is convex and is therefore
typically used to train multi-class classiﬁers.

Lce = −1/m

m
(cid:88)

i=1

yi · ln( ˆyi)

(2)

As mentioned earlier, recent deep learning research has
shown that incorporating self-supervised learning as part of
the neural network’s training process can improve model
performance [10][11][12]. Inspired by these promising re-
sults, we will next describe how we incorporated Baevski
et al.’s data2vec algorithm into our training process.

IV. METHODOLOGY
One of the drawbacks of neural networks is the lack of
explanability. To the best of our knowledge, all previous
works in this domain treated the CNN models that they
trained as a blackbox. After training the CNN, they only
evaluated the output of the CNN with no additional insight
as to how the model was able to produce its prediction.
In this paper, we propose to make use of data2vec to not
only enhance performance but also improve explanability
of the neural network so as to provide greater conﬁdence
that the model is indeed learning as we expect it to be. To
do this, we broke the model into 2 sub nueral networks as
shown in Figure 3. Essentially, we will make use of a CNN
to ingest the various malware binary images and produce
embeddings. These embeddings will then be passed to a
MLP to produce a softmax output, indicating the probability
of the input malware binary image belonging to each of the
known malware families in the training dataset. Intuitively,
we would like the CNN to be a feature extractor while the
MLP to be a feature analyzer and class prediction module.
We propose to train the entire network (both the CNN and
MLP) using the softmax cross entropy loss, while regularis-
ing the embeddings output by the CNN using the data2vec
framework. Figure 4 shows our proposed framework.

As shown,

it comprises 2 main workﬂows. The ﬁrst
workﬂow is the conventional supervised learning workﬂow
whereby the entire model, comprising both the CNN and
MLP are trained end-to-end using the labelled dataset via the
conventional softmax cross entropy loss function described
in (2). Do note that in this workﬂow, the entire unmasked
image is fed to the CNN model. Also, we use the student
CNN for this workﬂow as the teacher CNN is in fact a
frozen moving average of the student CNN (i.e. gradient

propagation should not go through the teacher CNN). The
second workﬂow aims to regularise the output of the student
CNN to encourage the model’s output embeddings contain
information representative of the input image. It also helps
to prevent the model from over-ﬁtting to the dataset. This
workﬂow is as what was proposed in [12] whereby the
student CNN is input a masked version of the malware
binary image and the teacher CNN is input
the entire
malware binary image. The difference between the output
embeddings are then minimized via (3), where zt is the
output embeddings produced by the teacher CNN, ˆzt is the
output embeddings produced by the student CNN. Note that
β is used to control the loss function’s sensitivity to outliers.
In our experiments, we set this to 0.5.

Our ﬁnal proposed composite loss function to train the
model end-to-end is (4), where λ is a weighting factor, which
we set to 1.

Ldata2vec =

(cid:40) 1

2 (zt − ˆzt)2/β,
(|zt − ˆzt| − 1

2 β),

if |zt − ˆzt| ≤ β
otherwise

L = Lce + λLdata2vec

(3)

(4)

A. Network Design

Table I summarizes the network architectural design. It
should be noted that although Baevski et al. proposed a
transformer architecture, he also noted that the data2vec
methodology would also be applicable to other alternative
architectures [12]. In this paper, we chose a CNN archi-
tecture in place of transformer given that it has achieved
good results in this domain and is less computationally
intensive. The ﬁrst 3 convolutional layers that does "same"
padding aims to extract features from the input image, with
minimal information loss from the periphereal pixels. The
next few convolutional layers are feature extractors. It should
be noted that the output of the convolutional layers is a
matrix of size 3 × 3 × 256. This is then passed through
a dense layer (i.e. Dense (CNN)) to output a matrix of
the same size but with linear activation. This matrix forms
the embedding layer, which will be trained using Ldata2vec.
The next few layers are part of the MLP network. It ﬁrst
ﬂattens the 3 dimensional matrix into a single vector, before
passing it through 3 Dense layers of the same number of
units. These Dense layers follow the ResNet architecture
to facilitate back-propagation of gradients. In addition, we
added a dropout of 0.2 throughout the entire network to
prevent overﬁtting.
B. Experimental Setup

To showcase the improvement of our methods over the
existing literature, we will
train 2 models on 90% of
our dataset, segmented by family to ensure that the test
dataset has every malware family. The ﬁrst model is trained
using only Lce while the second model is trained using
our composite loss function L. We will then repeat this
process thrice using different random seeds to objectively

Fig. 4. BinImg2Vec Framework

TABLE I
NEURAL NETWORK ARCHITECTURE

Filters

Stride Kernel Convolution

Padding

activation

32
64
128
128
128
256
256
256
256
256
-
128
128
128
61

[1,1]
[1,1]
[1,1]
[2,2]
[2,2]
[2,2]
[2,2]
[2,2]
[2,2]
-
-
-
-
-
-

[3,3]
[3,3]
[3,3]
[5,5]
[5,5]
[5,5]
[5,5]
[5,5]
[5,5]
-
-
-
-
-
-

Type
Conv2D (CNN)
Conv2D (CNN)
Conv2D (CNN)
Conv2D (CNN)
Conv2D (CNN)
Conv2D (CNN)
Conv2D (CNN)
Conv2D (CNN)
Conv2D (CNN)
Dense (CNN)
Flatten (MLP)
Dense (MLP)
Dense (MLP)
Dense (MLP)
Dense (MLP)

Same
Same
Same
Valid
Valid
Valid
Valid
Valid
Valid
-
-
-
-
-
-

leaky relu
leaky relu
leaky relu
leaky relu
leaky relu
leaky relu
leaky relu
leaky relu
leaky relu
linear
-
leaky relu
leaky relu
leaky relu
softmax

determine whether our proposed framework can improve
the malware family classiﬁcation accuracy. All models took
approximately 12 hours of training to converge. Loss curves
were also observed throughout the entire training process to
ensure convergence has been reached.

V. RESULTS AND DISCUSSION
The results of our experiments are as shown in II. As can
be seen our proposed method of training the malware binary
image classiﬁcation model produce a marked improvement
of nearly 4% consistently across the 3 runs. Furthermore the
variance across the runs was reduced from 0.7% to 0.2%.
This shows that our framework of using both supervised
and self-supervised training to train the neural network gives
better results.

TABLE II
ACCURACY & F1-SCORE OF VARIOUS EXPERIMENTS AND SCENARIOS

Family
Classiﬁcation
Accuracy
Mean Accuracy

Experiment
1
2
3

Lce
0.956
0.950
0.949
0.952

L
0.989
0.991
0.990
0.991

To better understand why this is so, we present the training
loss curves of the 2 different approaches in Figure 5. The red
curve depicts the softmax cross entropy loss as the model
is trained using just Lce while the blue curve depicts the
softmax cross entropy loss component of our composite loss
function when the model is trained using L. As can be seen,
the blue curve settles on a higher loss but is much more
stable compared to the red one. We opine that this is one
reason why the model, when trained using L results in less
variation over multiple seeds compared to if it were just
trained using Lce.

Secondly, we also note that the Ldata2vec loss function for
the red curve settled on at least 2 orders of magnitude higher
than the blue curve. This is as expected as the red curve
was not trained using this loss function (although we log it
too for comparison). However, it is interesting to discover
that the difference would be so huge. Intuitively, what this
means is that the embeddings produced by the 2 networks
could have vastly different meanings. For the blue curve, the
embeddings must contain information of the original input
image. On the other hand, this may not be the case for the
red curve; its embeddings may well be tailored to overﬁt to
the training dataset.

We attempt

to explain this phenomenon by trying to
understand the inner-workings of the model. To do this, we
took the embeddings produced by the CNN model (1 trained
using Lce and another using L) and passed them through
UMAP [17] to reduce the embeddings to 2 dimensions,
allowing us to plot them in a 2-dimensional plane. As can be
seen in Figure 6, the embeddings produced by our proposed
framework are actually well clustered by the various families
in the dataset (i.e. each color represents a particular family
and each cluster is predominantly made up of one color,
indicating that each cluster is predominantly made up of 1
family), even though this was not explicitly expressed in the
Ldata2vec loss function. On the other hand, the embeddings
of the model trained using just the softmax cross entropy loss

Fig. 5. Comparing Training Loss Curves

Fig. 6. Comparison of Embeddings

is rather erratic with no clear cluster. This characteristic is
extremely helpful to us because of the following:

1) Firstly, it enhances the explanability of the model. We
are now sure that the CNN trained under our proposed
framework indeed extracts interpretable features for the
MLP network to analyse. In contrast, this is not the
case if the model was simply trained using the Lce
loss function.

2) Secondly, it facilitates the discovery of new malware
families. If the MLP’s conﬁdence is low, we can analyse
the embeddings output by the CNN to see if it is indeed
far from all the known clusters. If so, the malware
sample is probably a new malware family.

VI. CONCLUSION AND FUTURE WORK

In this paper we have made a few ﬁndings. First, we
verify that the data2vec framework indeed also works in
the cyber domain. To the best of our knowledge, we are the

ﬁrst to apply this framework to the cybersecurity domain.
Secondly, we demonstrate how the addition of Ldata2vec as
a regularising term in the loss function is able to improve
malware family classiﬁcation and also stabilise training so
that the variance of the model’s performance over multiple
runs is relatively stable. Thirdly, we show how our proposed
framework can enhance explanability of the model and
possibly identify new malware families through clustering
of the embeddings output by the CNN network. In this
work, we have veriﬁed our proposed framework over 61
malware families, which is more than all previous work to
the best of our knowledge. Future work, could extend this to
even more families and also explore malware functionality
classiﬁcation (i.e. Trojan, Worm, etc.)

REFERENCES
[1] Colleen Mcclain. The internet and the pandemic. 2021.
URL https://www.pewresearch.org/internet/2021/09

learns equally well from visual, written or spoken
materials. 2022. URL https://ﬁnance.yahoo.com/n
ews/meta-researchers-build-ai-learns-170457912.html.
[15] Josh Stroschein. Malware samples. URL https://gith
ub.com/jstrosch/malware-samples. [Online; accessed
26-Mar-2022].

[16] vx underground. vx underground. URL https://samp
[Online;

les.vx-underground.org/samples/Families/.
accessed 26-Mar-2022].

[17] L McInnes and J Healy. Umap: Uniform manifold
approximation and projection for dimension reduction.
2018. URL https://arxiv.org/pdf/1802.03426.pdf.

/01/the-internet-and-the-pandemic. [Online; accessed
26-Mar-2022].

[2] Amiah Taylor. There’s a huge surge in hackers holding
data for ransom, and experts want everyone to take
these steps. 2022. URL https://fortune.com/2022/02/
17/ransomware-attacks-surge-2021-report.
[Online;
accessed 26-Mar-2022].

[3] Ron Davidson. Malware-as-a-service is a booming
business. 2021. URL https://www.infosecurity-magaz
ine.com/opinions/malware-service-booming-business/.
[Online; accessed 26-Mar-2022].

[4] Jai Vijayan. 74% of q1 malware was undetectable via
signature-based tools. 2021. URL https://www.dark
reading.com/vulnerabilities---threats/74--of-q1-ma
lware-was-undetectable-via-signature-based-tools/.
[Online; accessed 26-Mar-2022].

[5] L. Nataraj, Karthikeyan S., Jacob G., and Manjunath
B.S. Malware images: Visualization and automatic
In VizSec ’11: Proceedings of the 8th
classiﬁcation.
International Symposium on Visualization for Cyber
Security, 2011.

[6] Aziz. Makandar and Anita Patrot. Malware analysis
In
and classiﬁcation using artiﬁcial neural network.
International Conference on Trends in Automation,
Communications and Computing Technology, 2015.
[7] Jhu-Sin Luo and Dan Chia-Tien Lo. Binary malware
image classiﬁcation using machine learning with local
In IEEE International Conference on
binary pattern.
Big Data, 2017.

[8] Ahmed Bensaoud, Nawaf Abudawaood, and Jugal
Kalita. Classifying malware images with convolutional
neural network models. 2020. URL https://arxiv.org/
pdf/2010.16108.pdf.

[9] Pratikkumar Prajapati and Stamp Mark. An empir-
ical analysis of image-based learning techniques for
In Malware Analysis Using
malware classiﬁcation.
Artiﬁcial Intelligence and Deep Learning, 2020.
[10] Kaiming He, Xinlei Chen, Saining Xie, and Yangbao
Li. Masked autoencoders are scalable vision learners.
2021. URL https://arxiv.org/pdf/2111.06377.pdf.
[11] Hangbo Bao, Li Dong, and Furu Wei. Beit: Bert pre-
training of image transformers. 2021. URL https:
//arxiv.org/pdf/2106.08254.pdf.

[12] Alexi Baevski, Wei-Ning Hsu, Qiantong Xu, Arun
Babu, Jiatao Gu, and Michael Auli. data2vec: A gen-
eral framework for self-supervised learning in speech,
vision and language. 2022. URL https://ai.facebook.
com/blog/the-first-high-performance-self-supervised-
algorithm-that-works-for-speech-vision-and-text/.
[13] Ray Tiernan. Meta’s ’data2vec’ is a step toward one
neural network to rule them all. 2022. URL https:
//www.zdnet.com/article/metas-data2vec-is-the-next-s
tep-toward-one-neural-network-to-rule-them-all/.
[14] Devin Coldewey. Meta researchers build an ai that

