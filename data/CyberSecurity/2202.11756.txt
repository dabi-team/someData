ML-based Anomaly Detection in Optical Fiber Monitoring

Khouloud Abdelli 1,2, Joo Yeon Cho 2, Carsten Tropschug 3
1 Christian-Albrechts-Universit¨at zu Kiel, Kaiserstr. 2, Kiel, Germany, 24143
2 ADVA Optical Networking SE, Fraunhoferstrasse 9a, Martinsried, Germany, 82152
3 ADVA Optical Networking SE, M¨arzenquelle 1-3, Meiningen, Germany, 98617
{KAbdelli, JCho, CTropschug}@adva.com

2
2
0
2

b
e
F
3
2

]

R
C
.
s
c
[

1
v
6
5
7
1
1
.
2
0
2
2
:
v
i
X
r
a

Abstract

Secure and reliable data communication in optical networks
is critical for high-speed internet. We propose a data driven
approach for the anomaly detection and faults identiﬁcation
in optical networks to diagnose physical attacks such as ﬁber
breaks and optical tapping. The proposed methods include an
autoencoder-based anomaly detection and an attention-based
bidirectional gated recurrent unit algorithm for the ﬁber fault
identiﬁcation and localization. We verify the efﬁciency of our
methods by experiments under various attack scenarios using
real operational data.

Introduction
Optical ﬁber is the essential medium for transporting a
large amount of data through the aggregated internet, mo-
bile backhaul and core network. A single ﬁber link connects
thousands of customers and enterprises, carrying a mixture
of personal, business and public data. Therefore, the impact
of a broken ﬁber can be enormous and must be responded to
immediately.

It is well known that an optical ﬁber is vulnerable to var-
ious types of attacks such as ﬁber cut and ﬁber tapping
(eavesdropping). Such attacks compromise the availability
and the conﬁdentiality of an optical network. Speciﬁcally, a
manual discovery of incidents occurring in the ﬁber require
considerable expert knowledge and probing time until a fault
(e.g. broken ﬁber) is identiﬁed.

Fiber monitoring aims at detecting anomalies in an optical
layer by logging and analyzing the monitoring data. It has
mainly been performed using optical time domain reﬂectom-
etry (OTDR), a technique based on Rayleigh backscattering,
widely applied for ﬁber characteristics’ measurements and
for ﬁber fault detection and localization (Lee et al. 2014).
OTDR operates like an optical radar. It sends a series of op-
tical pulses into the ﬁber under the test. The backscattered
signals are then recorded as a function of time, which can
be converted into the position on the optical ﬁber. As result,
a recorded OTDR trace illustrating the positions of faults
along the ﬁber, is generated, and used for event analysis.

However, OTDR traces are difﬁcult to interpret even by
highly experienced engineers mainly due to the noise over-

Copyright © 2022, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.

Figure 1: Overview of the ML-based ﬁber monitoring pro-
cess

whelming the signals. Analyzing OTDR signals using con-
ventional methods can be time consuming as performing a
lot of averaging of OTDR measurements is required to re-
move the noise and thereby to achieve a good event detec-
tion and localization accuracy. Therefore, it would be highly
beneﬁcial to develop a reliable automated diagnostic method
that accurately and quickly detects, diagnoses, and pinpoints
ﬁber faults given the OTDR data. It reduces operation-
and-maintenance expenses (OPEX) and eliminates the time
needed to investigate the cause and determine a search area.
Upon ﬁnding the fault location, appropriate action is taken to
remedy the fault and restore service as quickly as possible.
Recently, machine learning (ML) based approaches have
shown great potential to tackle the problem of ﬁber event
detection and localization (Nyarko-Boateng, Adekoya, and
Weyori 2021). In this respect, long short-term memory and
convolutional neural networks have been proposed to detect
and localize the reﬂective ﬁber events induced by the con-
nectors and mechanical splices (Abdelli et al. 2021; Abdelli,
Grießer, and Pachnicke 2021).

In this paper, we propose an ML-based ﬁber fault de-
tection, localization, and diagnosis framework, leveraging
OTDR data. The proposed approach includes an autoen-
coder to detect a ﬁber fault (e.g. ﬁber cut or bending) and an
attention-based bidirectional gated recurrent unit model to

 
 
 
 
 
 
identify the type of the detected fault and localize it. The pro-
posed framework is validated by noisy experimental OTDR
data with the SNR varying from 0 dB to 30 dB. Fig. 1 shows
that an overview of the ML-based ﬁber monitoring process.

Background
Multi-Task Learning Multi-task learning (MTL) is a
learning paradigm in ML that aims to improve the gener-
alization performance of multiple tasks by learning them
jointly while sharing knowledge across them. It has been
widely used in various ﬁelds ranging from natural language
processing to computer vision. The MTL approaches can be
classiﬁed as hard- and soft parameter sharing. The hard pa-
rameter sharing method is done by sharing the hidden lay-
ers with the different tasks (completely sharing the weights
and the parameters between all tasks) while preserving task-
speciﬁc output layers learnt independently by each task.
Whereas for the soft parameter sharing approach, a model
with its own parameters is learned for each task and the
distance between the parameters of the model is then reg-
ularized to encourage similarities among related parameters
(Ruder 2017).

Autoencoder An autoencoder (AE) is a type of artiﬁcial
neural network seeking to learn a compressed representa-
tion of an input in an unsupervised manner (Kramer 1991).
An AE is composed of two sub-models namely the encoder
and the decoder. The encoder is used to compress an input
X into lower-dimensional encoding (i.e. latent-space repre-
sentation) Z through a non-linear transformation, which is
expressed as follows:

controlling the ﬂow of the information. The update gate reg-
ulates the information that ﬂows into the memory, while the
reset gate controls the information ﬂowing out the memory.
The GRU cell is updated at each time step t by applying the
following equations:

zt = σ(Wz · xt + Wz · h(t−1) + bz)
rt = σ(Wr · xt + Wr · h(t−1) + br)
(5)
ˆht = tanh(Wh · xt + Wh · (rt ◦ h(t−1)) + bh) (6)
ht = zt ◦ h(t−1) + (1 − zt) ◦ ˆht
(7)

(4)

where zt denotes the update gate, rt represents the reset
gate, xt is the input vector, ht is the output vector, W and b
represent the weight and the bias matrices respectively. σ is
the gate activation function and tanh represents the output
activation function. The ’·’ operator denotes a matrix multi-
plication and the ’◦’ operator represents the dot product.

Bidirectional GRU (BiGRU) is an extension of GRU that
helps to improve the performance of the model. It consists
of two GRUs: one is a forward GRU model that takes the
input in a forward direction, and the other is a backward
GRU model that learns the reversed input. The output yt of
−→
ht
the model is generated by combining the forward output
←−
ht as described by the following
and the backward output
equations:

−→
ht = GRU (xt,
←−
ht = GRU (xt,
−→
ht ⊕
yt =

←−
ht

−−→
ht−1)
←−−
ht−1)

(8)

(9)

(10)

Z = f (W X + b),

(1)

where ⊕ denotes an element-wise sum.

where W and b denote the weight and bias matrices of the
encoder and f represents the activation function of the en-
coder.

The decoder attempts to reconstruct the output ˆX given
the representation Z via a nonlinear transformation, which
it is formulated as follows:

ˆX = g(W (cid:48)X + b(cid:48)),

(2)

where W (cid:48) and b(cid:48) represent the weight and the bias matrices
of the decoder and g denotes the activation function of the
decoder.

The AE is trained by minimizing the reconstruction er-
ˆbmX and the input X, which is the
ror between the output
loss function L(θ), typically the mean square error (MSE),
deﬁned as:

L(θ) =

(cid:88)

||X − ˆX||2

(3)

where θ = {W , b, W (cid:48), b(cid:48)} denotes the set of the parame-
ters to be optimized.

Bidirectional GRU Gated recurrent unit (GRU) is a spe-
ciﬁc type of Recurrent Neural Networks (RNNs) to solve
the problem of gradient vanishing (Cho et al. 2014). It has
been widely adopted to process sequential data and to cap-
ture long-term dependencies. The typical structure of GRU
is composed of two gates namely reset and update gates,

Physical Attacks on Fiber
Fiber cut:
Intentional ﬁber cut attack is an attempt to
deny or disrupt service by cutting the ﬁber optic cables and
thereby inducing a widespread denial of service attack. Fiber
break is considered as the single largest cause of service out-
ages. As reported by the Federal Communication Commis-
sion (FCC), more than one-third of service disruptions are
caused by ﬁber-cable breaks (Bakar et al. 2007). Any ser-
vice outage due to a ﬁber cut results in massive data loss,
network disruption, and huge ﬁnancial loss etc (Chan et al.
1999). In 1991, a severed ﬁber-optic cable shut down all the
New York airports and induced air trafﬁc control problems
(Gorman 2005). It is time-consuming to locate and repair
ﬁber breaks.

Optical eavesdropping: Optical eavesdropping attack
permits the eavesdropper to gain an unauthorized access to
the carried data by directly accessing the optical channel via
ﬁber tapping for the purpose of stealing mission-critical and
sensitive information. There are several ﬁber tapping tech-
niques which can be adopted to launch the eavesdropping at-
tack, such as ﬁber bending, optical splitting, evanescent cou-
pling, V Groove cut and so on (Shaneman and Gray 2004).
However, the easiest method to make the eavesdropping in-
trusion undetected is micro-ﬁber bending by using commer-
cially available clip-on coupler. Fiber-optic cable tapping in-

cidents have been reported such as the eavesdropping de-
vice, which was discovered illegally installed on Verizon’s
optical network in 2003 to glean information from a mutual
fund company regarding its quarterly statement prior to its
public disclosure (Miller 2006). Although, it is easy to per-
form an eavesdropping intrusion, it is challenging to detect
such intrusion using conventional intrusion detection meth-
ods such as OTDR-based techniques.

Fiber Monitoring Framework
As shown in Figure 1, the proposed framework can be bro-
ken into ﬁve main stages: (1) optical ﬁber network mon-
itoring and data collection, (2) data processing, (3) ﬁber
anomaly detection, (4) ﬁber fault diagnosis and localization,
(5) mitigation and recovery from ﬁber failures. The optical
ﬁbers deployed in the network infrastructure are periodically
monitored using OTDR (i.e ﬁber monitoring unit).

The generated OTDR traces (i.e monitoring data) are sent
to the software-deﬁned networking (SDN) controller man-
aging the optical infrastructure. Then, the said data is seg-
mented into ﬁxed length sequences and normalized. After-
wards, the processed data is fed to the ML based anomaly
detection model for recognizing the ﬁber faults. If a ﬁber
failure is detected, a ML model for fault diagnosis and local-
ization is adopted to identify the fault and pinpoint it. Based
on the identiﬁed failure, a set of recovery rules is applied to
mitigate such fault. The SDN controller notiﬁes the network
operation center in case of failure, which informs the cus-
tomer about the type of detected fault and its location, and
notiﬁes the maintenance and repair service in case of ﬁber
break.

For this work, we consider the physical ﬁber attacks
namely ﬁber cut and optical eavesdropping attacks, as ex-
amples of harmful ﬁber faults. Given that the patterns of
faults namely bad splice and dirty connector are similar to
the physical attacks’ patterns particularly under very low
SNR conditions, we include them during the training phase
of the ML model for fault diagnosis to ensure a reliable fault
identiﬁcation and reduce the false alarms.

Autoencoder-based Anomaly Detection The proposed
ML model for ﬁber anomaly detection is based on autoen-
coder. The autoencoder is trained with only normal data rep-
resenting the normal behavior in order to learn the distribu-
tion characterizing the normal state. After the training of the
autoencoder and for the inference phase, the reconstruction
error is adopted as an anomaly score to detect any potential
fault. A well-trained autoencoder will reconstruct the normal
instances very well since they will have the same pattern or
distribution as the training data, while it will fail to repro-
duce the anomalous observations by yielding high recon-
struction errors. The process of the classiﬁcation of an in-
stance as anomalous/normal is illustrated in Algorithm 1. If
the computed anomaly score is higher than a set threshold θ,
the instance is classiﬁed as ”anomalous”, else it is assigned
as ”normal”. θ is a hyperparameter optimized to ensure high
detection accuracy and is adjusted by taking into considera-
tion the degradation and the aging effect of the optical ﬁber.

Algorithm 1: Autoencoder-based anomaly detection

Input Normal dataset x, Anomalous dataset x(i), i =
1, . . . , N , threshold θ
Output Reconstruction error ||x − ˆx||
f, g ← train an autoencoder using the normal dataset x
for i = 1, · · · , N do

reconstruction error(i) ← ||x(i) − g ◦ f (x(i))||
if reconstruction error(i) > θ then

x(i) is anomalous.

else

x(i) is normal.

end if

end for

Figure 2: Structure of the proposed gated recurrent unit
based autoencoder for optical ﬁber anomaly detection.

The architecture of the proposed autoencoder model for
ﬁber anomaly detection is illustrated in Figure 2. The
model contains an encoder and a decoder sub-model with
4 layers. The encoder takes a sequence of OTDR traces
[P1, P2, . . . , P30] as an input, representing the attenuation of
the ﬁber along the distance, combined with the sequence’s
computed SNR (γ). The information about the sequence’s
SNR during the training phase helps the ML model to learn
the behavior of the normal signal pattern for each input SNR
level and thereby to boost the performance (Abdelli et al.
2021). The fed input to the encoder is then compressed into
a low dimensional representation by adopting 2 GRU layers
composed of 64 and 32 cells, respectively, which captures
the relevant sequential features modeling the normal state
under different SNRs. Afterwards, the decoder reconstructs
the output, given the compressed representation output of
the encoder. The decoder is inversely symmetric to the en-
coder part. Rectiﬁed Linear Unit (ReLU) is selected as an
activation function for the hidden layers of the model. The
cost function is set to the mean square error (MSE), which
is adjusted by the Adam optimizer.

Fault Diagnosis and Localization Let us denote the fault
diagnosis task by T1 and the fault position estimation task
by T2. Obviously, T1 and T2 can get beneﬁts each other by
sharing their features. The proposed model for T1 and T2 is
an MTL framework which can learn these tasks simultane-
ously, enhancing their generalization capability. The archi-
tecture of the proposed framework is composed of the shared
hidden layers distributing the knowledge across T1 and T2

Experiments

Experimental setup To validate the proposed approach,
an experimental setup is established, as shown in Figure
4. The setup is used to record OTDR traces incorporating
different types of ﬁber faults namely ﬁber cut, ﬁber eaves-
dropping (ﬁber tapping), dirty connector and bad splice. To
reproduce a real passive optical network environment, four
couplers are employed. Optical components such as connec-
tors, a variable optical attenuator (VOA) and a reﬂector are
utilized to model normal events in the ﬁber optic link. To
vary the ﬁber bending pattern and thereby to enhance the
generalizability capability of the ML model, the bend radius
of the clip-on coupler is ranged from 2.5 mm to 10 mm.
Different bad splices with dissimilar losses are performed
to create a varying bad splicing fault pattern. The OTDR
conﬁguration parameters, namely the pulse width, the wave-
length and the sampling time, are set to 10 ns, 1650 nm and
1 ns, respectively. The OTDR records from 62 up to 65,000
are collected and averaged.

Data Preprocessing The generated OTDR traces are seg-
mented by every 30 traces and normalized to form a se-
quence. For each sequence, its SNR γ is computed and as-
signed. The GRU-based autoencoder (GRU-AE) is trained
with only the normal sequences, that is, a series of traces
induced in a normal state of the optical components with-
out fault. Whereas, for testing, both normal and abnormal
sequences are used to incorporate an anomaly. For training
GRU-AE, 47,904 traces are generated in total and split into
a training dataset (70%) and a test dataset (30%). For train-
ing the attention-based BiGRU model, we consider only the
faulty sequences. Each sequence is assigned with the fault
type (ﬁber eavesdropping, bad splice, ﬁber cut, dirty con-
nector) and the fault position, which is deﬁned as the index
within the sequence. To train the fault diagnosis and localize
an ML model, total 61,849 traces are used, where those data
are divided into a training (60%), a validation (20%) and a
test dataset (20%).

Performance Evaluation

Evaluation metrics The fault detection is modeled as a
binary classiﬁcation. The “positive” sequences are labeled
with “1: fault”, whereas the “negative” sequences are with
“0: normal”. Then, the following classes are considered for
the evaluation metric:

• True positives (TP): number of sequences of type ‘1’ cor-

rectly classiﬁed with label ‘1’;

• True negatives (TN): number of sequences of type ‘0’

correctly classiﬁed with label ‘0’;

• False positives (FP): number of sequences of type ‘0’

Figure 3: Structure of the proposed attention-based bidirec-
tional gated recurrent unit model for ﬁber fault diagnosis and
localization

followed by a speciﬁc task layer. The shared hidden layers
adopt a combination of a bidirectional gated recurrent unit
(BiGRU) network and attention mechanisms. The BiGRU
is used to capture the sequential features characterizing the
pattern of each fault, whereas the attention mechanisms help
the model to concentrate more on the relevant features to
improve the fault diagnosis and localization accuracy.

As shown in Figure 3, the input (i.e., the abnormal sam-
ple detected by the GRU-based autoencoder) is ﬁrstly fed
into 2 BiGRU layers which are composed of 64 and 32
cells, respectively, to learn the relevant sequential features
[h1, h2, . . . , h31]. Then, in the attention layer, the extracted
feature hi attains a weight (i.e., attention score) αi which is
calculated as follows:

ei = tanh(Whhi)
αi = sof tmax(wT ei)

(11)

(12)

where Wh and w denote weight matrices, and sof tmax
represents a normalizing function for ensuring that αi ≥ 0,
and (cid:80)
i αi = 1. By aggregating the computed weights αi
and hi, a weighted feature vector (i.e. attention context vec-
tor) c is computed as follows:

(cid:88)

c =

αihi,

i

(13)

which captures the relevant information to improve the per-
formance of the model.

Afterwards, the vector c is transferred to two task-speciﬁc
layers which are dedicated to solving the task T1 and T2 by
leveraging the knowledge extracted from the attention-based
BiGRU shared layers. The model is trained by minimizing
the loss function formulated as:

Ltotal = λ1LT1 + λ2LT2 ,

(14)

misclassiﬁed with label ‘1’;

where LT1 and LT2 represent the loss of T1 and T2. The LT1
is the cross-entropy loss whereas the LT2 is the regression
loss in MSE. The loss weights λ1 and λ2 are hyperparame-
ters to be tuned.

• False negatives (FN): number of sequences of type ‘1’

misclassiﬁed with label ‘0’.

To assess the detection capability, the following metrics are
adopted.

Figure 4: Experimental setup for generating OTDR data containing different faults induced at different locations in an optical
network (PC - physical contact, APC – angled PC, LC – Lucent connector, SFP+ – small form-factor pluggable)

Precision (P): P quantiﬁes the relevance of the predictions

made by the ML model. It is expressed as:

P =

T P
(T P + F P )

(15)

Recall (R): R provides the total relevant results correctly

classiﬁed by the ML model. It is formulated as:

R =

T P
(T P + F N )

(16)

F1 score: F 1 is the harmonic mean of the precision and

recall, calculated as:

F 1 = 2 ·

P · R
(P + R)

(17)

Fault detection capability The anomaly detection capa-
bility of GRU-AE is varied depending on the selected thresh-
old θ. Figure 5 shows the precision, the recall, and the F1
score curves as function of θ.

false negative ratio. Therefore, the optimal threshold that en-
sures the best precision and recall tradeoff (i.e., maximizing
the F1 score) should be chosen. According to Figure 5, the
fault detection capability is optimal when θ is equal to 0.09,
and the precision, the recall, and the F1 scores are 96.8%,
95.7%, and 96.2%, respectively.

Another way to illustrate the performance of the model
is to draw a receiver operating characteristic (ROC) curve
at different threshold settings. Figure 6 shows that the dis-
tinguishability of GRU-AE between the normal and faulty
classes is outstanding since an area under the curve (AUC)
(i.e., degree of separability between classes) is as high as
0.98.

Figure 5: The optimal threshold selection based on the pre-
cision, recall and F1 scores yielded by GRU-AE.

If the selected threshold is too low, many faults will be
classiﬁed as normal, leading to a higher false positive ratio.
Whereas, if the chosen threshold is too high, many ”normal”
sequences will be classiﬁed as ”faulty”, resulting in a higher

Figure 6: The receiver operating characteristic curve of
GRU-AE

Fault diagnosis capability The confusion matrix of the
attention-based BiGRU model (A-BiGRU) is illustrated in
Figure 7. Our experiments show that the A-BiGRU model
identiﬁes the different faults with an accuracy higher than
95% and the ﬁber physical attacks with an accuracy higher
than 98%. As for the low SNR sequences, the ML model
mis-classiﬁed these classes with 1.1% probability since
there are similarities between the patterns of the eavesdrop-
ping and the bad splice faults. The same justiﬁcation applies
for the patterns of a dirty connector and a ﬁber break under
low SNR conditions.

(a) 5 dB SNR

(b) 10 dB SNR

Figure 7: The confusion matrix of the attention-based Bi-
GRU model

Figure 8 shows the effects of SNR on the diagnosis ac-
curacy of A-BiGRU. The accuracy increases with the SNR.
For the SNR values higher than 10 dB, the accuracy is ap-
proaching to 1. For the SNR lower than 2 dB, the accuracy
is sharply dropped as it is difﬁcult to differentiate the fault
types by the patterns of the faults mainly due to the noise
which adversely impacts the patterns under very low SNR
levels.

(c) 15 dB SNR

(d) 25 dB SNR

Figure 9: Visualization of the feature learning under differ-
ent SNR conditions

0.2m, and it could be further reduced up to less than 0.1m
for SNR values higher than 30 dB.

Figure 8: Fault diagnosis performance evaluation

Figure 10: Fault position estimation error (in RMSE) for the
ML model

The feature learning ability of A-BiGRU for solving the
task T1 is investigated using the t-distributed stochastic
neighbor embedding (t-SNE) technique under different SNR
conditions (Van der Maaten and Hinton 2008). As compared
in Figure 9, the learned features become more and more
prominent with the increase of the SNR. Furthermore, A-
BiGRU is able to learn effective features for accurate fault
diagnosis even under low SNR conditions.

Fault localization capability To measure the accuracy
of the fault localization capability of A-BiGRU, an aver-
age root mean square error (RMSE) is introduced. Fig-
ure 10 shows that A-BiGRU localizes the faults accurately
by achieving the RMSE of 0.21m. For lower SNR values
(e.g., SNR ≤ 10 dB), the RMSE can be higher than 0.37m,
whereas for SNR values higher than 15 dB, it is less than

Conclusion
Fiber monitoring is essential for long-lasting optical network
operations and high service availability. Our experiments
show that ML techniques can enhance the performance of
the anomaly detection and fault identiﬁcation in ﬁber mon-
itoring, and minimizing the false positive alarm. For the fu-
ture work, we apply our framework and methods for the cy-
bersecurity of a cyber-physical system (CPS) which is usu-
ally operated in a very complex, sophisticated, intelligent
and autonomous environment.

References
Abdelli, K.; Grießer, H.; Ehrle, P.; Tropschug, C.; and Pach-
nicke, S. 2021. Reﬂective ﬁber fault detection and charac-

terization using long short-term memory. Journal of Optical
Communications and Networking, 13(10): E32–E41.
Abdelli, K.; Grießer, H.; and Pachnicke, S. 2021. Convolu-
tional Neural Networks for Reﬂective Event Detection and
Characterization in Fiber Optical Links Given Noisy OTDR
Signals. Photonic Networks, 22th ITG Symposium.
Bakar, A. A. A.; Jamaludin, M. Z.; Abdullah, F.; Yaacob,
M. H.; Mahdi, M. A.; and Abdullah, M. K. 2007. A new
technique of real-time monitoring of ﬁber optic cable net-
works transmission. Optics and Lasers in Engineering,
45(1): 126–130.
Chan, C.-K.; Tong, F.; Chen, L.-K.; Ho, K.-P.; and Lam,
D. 1999.
Fiber-fault identiﬁcation for branched access
networks using a wavelength-sweeping monitoring source.
IEEE Photonics Technology Letters, 11(5): 614–616.
Cho, K.; van Merrienboer, B.; Gulcehre, C.; Bahdanau, D.;
Bougares, F.; Schwenk, H.; and Bengio, Y. 2014. Learn-
ing Phrase Representations using RNN Encoder-Decoder
for Statistical Machine Translation. arXiv:1406.1078.
Gorman, S. P. 2005. Networks, security and complexity: The
role of public policy in critical infrastructure protection. Ed-
ward Elgar Publishing.
Kramer, M. A. 1991. Nonlinear principal component anal-
ysis using autoassociative neural networks. AIChE Journal,
37(2): 233–243.
Lee, W.; Myong, S. I.; Lee, J. C.; and Lee, S. 2014. Identiﬁ-
cation method of non-reﬂective faults based on index distri-
bution of optical ﬁbers. Opt. Express, 22(1): 325–337.
Miller, S. K. 2006. Hacking at the Speed of Light. Security
Solutions Magazine.
Nyarko-Boateng, O.; Adekoya, A. F.; and Weyori, B. A.
2021. Predicting the actual location of faults in underground
optical networks using linear regression. Engineering Re-
ports, 3(3): eng212304.
Ruder, S. 2017. An Overview of Multi-Task Learning in
Deep Neural Networks. arXiv:1706.05098.
Shaneman, K.; and Gray, S. 2004. Optical network security:
technical analysis of ﬁber tapping mechanisms and methods
for detection amp; prevention. In IEEE MILCOM 2004. Mil-
itary Communications Conference, 2004., volume 2, 711–
716 Vol. 2.
Van der Maaten, L.; and Hinton, G. 2008. Visualizing data
using t-SNE. Journal of machine learning research, 9(11).

Acknowledgments
This work has been performed in the framework of the
CELTIC-NEXT project AI-NET-PROTECT (Project ID
C2019/3-4), and it is partly funded by the German Federal
Ministry of Education and Research (FKZ16KIS1279K).

