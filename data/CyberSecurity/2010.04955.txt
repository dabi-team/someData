1

0
2
0
2

t
c
O
0
1

]

R
C
.
s
c
[

1
v
5
5
9
4
0
.
0
1
0
2
:
v
i
X
r
a

A Distributed Hierarchy Framework for Enhancing
Cyber Security of Control Center Applications

Chetan Kumar Kuraganti, Bryan Paul Robert, Gurunath Gurrala, Senior Member, IEEE, Ashish Joglekar,
Arun Babu Puthuparambil, Rajesh Sundaresan, Senior Member, IEEE, Himanshu Tyagi, Senior Member, IEEE,

Abstract—Recent cyber-attacks on power grids highlight the
necessity to protect the critical functionalities of a control center
vital for the safe operation of a grid. Even in a distributed
framework one central control center acts as a coordinator in
majority of the control center architectures. Such a control center
can become a prime target for cyber as well as physical attacks,
and, hence, a single point failure can lead to complete loss of
visibility of the power grid. If the control center which runs
the critical functions in a distributed computing environment
can be randomly chosen between the available control centers
in a secure framework, the ability of the attacker in causing
a single point failure can be reduced to a great extent. To
achieve this, a novel distributed hierarchy based framework to
secure critical functions is proposed in this paper. The proposed
framework ensures that the data aggregation and the critical
functions are carried out at a random location, and incorporates
security features such as attestation and trust management to
detect compromised agents. A theoretical result is proved on the
evolution and convergence of the trust values in the proposed
trust management protocol. It is also shown that the system
is nominally robust so long as the number of compromised
nodes is strictly less than one-half of the nodes minus 1. For
demonstration, a Kalman ﬁlter-based state estimation using
phasor measurements is used as the critical function to be
secured. The proposed framework’s implementation feasibility
is tested on a physical hardware cluster of Parallella boards.
The framework is also validated using simulations on the IEEE
118 bus system.

Index Terms—Leader Election, Attestation, Trust Manage-

ment, State Estimation, Kalman Filter.

I. INTRODUCTION

P OWER grids are becoming potential targets for various

kinds of cyber and physical attacks because of the massive
economic and social disruptions that can arise in the event of
a widespread and prolonged outage of the electric grid. A
comprehensive survey of data attacks against power system
operations and control is presented in [1]. For example, an at-
tacker may gain operational access to the SCADA control cen-
ter and could disrupt the power grid’s operation [2]. Different
detection, protection, and mitigation strategies are presented in
[2] to enhance the resilience and operational endurance of the
energy delivery infrastructure against cyber attacks. Various
research directions to evaluate the cyber security and develop
novel algorithms for securing future power state estimation
and grid operation are presented in [3].

In recent years, there have been signiﬁcant research ef-
forts in securing SCADA and Energy Management Systems
(SCADA-EMS) [4], [2], which are the backbone of energy
control center operations. A class of false data injection

This work was supported in part by the Bosch Research and Technology
Centre, Bengaluru, India and by the Robert Bosch Centre for Cyber-Physical
Systems, Indian Institute of Science, Bengaluru, India, (under Project E-Sense:
Sensing and Analytics for Energy Aware Smart Campus), and in part by the
Science and Engineering Research Board (grant no. EMR/2016/002503).

attacks (FDIAs) on contingency analysis (CA) through state
estimation (SE) is proposed in [5], [6]. A secure distributed
state estimation method is proposed in [7] to address false data
injection threat in distributed microgrids. A residual detector
method to detect individual compromised sensors is proposed
in [8]. A reinforcement learning-based FDIA attack strategy is
presented in [9]. A class of sparse undetectable attacks (SUAs),
designed to deteriorate the state estimation performance, is
presented in [10]. In [11], a robust method to detect random
errors and cyber attacks targeting AC dynamic state estimation
through false data injection is presented.

Distributed processing is widely used in large power sys-
tems [12] where a central control center coordinates the
activities of sub-area control centers. Distributed processing of
load ﬂow, state estimation, security assessment, etc., requires
a coordinator to ﬁrst gather the sub-area data, and then
process them to get the entire system view. This coordinator
is usually ﬁxed in the existing installations. Even though
processing is distributed and loss of one sub-area data can
be handled by the coordinator, the loss of the coordinator
itself leads to the loss of visibility and control of the entire
system. To avoid this, back-up control centers are put
in
place. Even so, simultaneous attacks on the coordinator and
its backup control center can bring the system down. If the
role of the coordinating control center is randomly switched
among the existing control centers and automatic detection of
compromised control centers, their isolation, and subsequent
recovery are enabled, then the possibility of complete loss
of system visibility and controllability can be reduced. In
particular, single point of failure vulnerability is mitigated to
a great extent. With this motivation, a distributed hierarchy-
based framework is proposed in this paper. Note that in a
centralized environment, intelligent electronic devices (IEDs)
are responsible for data exchange between the control centers.
Future IEDs [13] will have the capability to perform not only
state estimation, but also complex data analysis and many
more of the control center’s system level algorithms in a fully
decentralized manner. In such scenarios, one or more IEDs
in a sub-area may act as coordinators for that area’s activity,
visibility, and control.

From a broader perspective, this work enables a distributed
implementation of the meta-function of monitoring the in-
tegrity of critical functionalities, with state estimation in a
power system being one such critical function example. We
focus on the integration of various existing schemes to prove
the proposed concept using a physical demonstration. While
development of new security features is beyond the scope
of this paper, we provide a novel theoretical analysis of a
security feature that suggests signiﬁcant nominal robustness
for scenarios where up to nearly half of the number of agents

 
 
 
 
 
 
may be compromised (more precisely, up to strictly less than
N/2 − 1). The hierarchy is obtained through a leader election
process. Attestation and trust management schemes are mainly
used to detect malicious devices.

compromised, say by a majority of the agents, a trigger to elect
a new leader from among the non-malicious agents is issued. A
new leader is then elected and control is subsequently handed
over to it.

2

II. PROPOSED DISTRIBUTED HIERARCHY FRAMEWORK

The proposed distributed hierarchy framework assumes the
presence of a proprietor, who is responsible for coordinating
each agent and running critical algorithms in the network.
This includes the code/programs/ﬁrmware that the agents will
run. An agent can represent an IED having edge compute
capabilities or a computer in a control center responsible for
coordination and running various algorithms. An attacker may
compromise some agents by corrupting some of the processes
associated with these agents. Speciﬁcally, the attacker corrupts
some part of the code running on the compromised agent.
As a consequence, the compromised device actions may not
follow the proprietor’s protocol. Such compromised devices
are termed malicious. Data from these agents may no longer be
reliable and if any of the analysis algorithms executed by the
proprietor have dependency on this data, they may result in in-
accurate results. In this paper, SE is the critical algorithm that
is to be secured. A completely connected network is assumed
between agents, and the devices exchange information through
broadcasting. In the case of a mesh network, broadcast can
be achieved via a multicast protocol that achieves broadcast.
In this framework all the agents are assumed to have equal
capabilities in terms of computational and communication
features, so that any agent can run the proprietor functions at
any time. A simple leader election (LE) protocol is proposed
to randomize the location of the proprietor among the devices.
When there are no malicious agents in the network, SE
will run normally at a randomly elected proprietor or leader
agent. If malicious agents are present, this should be detected,
such agents should be isolated, and actions must be taken
to continue SE. If the leader itself is a malicious agent, SE
must continue through another agent automatically without
interruption.

An overview of the proposed framework is shown in Fig.1.
The functional modules of the proposed hierarchical frame-
work, shown in the ﬁgure, are:
Leader Election: This module hosts leader election algorithm.
Proprietor Functions: This module aggregates the data from
other agents and runs the system level algorithms (e.g. state
estimation).
Malicious Activity Detection: This module checks the integrity
of the code running on the agents using attestation mecha-
nisms. Further, using a trust management scheme this module
infers the presence of malicious agents in the network and
identiﬁes whether a leader is malicious or any other agents
are malicious.

Initially, agents communicate with each other to establish
a network. Then, a leader election scheme is employed to
transfer the control to a single randomly elected agent, where
the SE will be performed. In parallel, attestation and trust
management are continuously used to monitor the network
for compromised agents, if any, and leader will ignore all the
data from these agents. If the leader itself is identiﬁed to be

Fig. 1: Overview of the distributed hierarchy framework.

A. Leader Election

Leader election is a fundamental problem in distributed
computing. A single agent, among the many in the network,
is chosen to coordinate and perform a critical meta-function,
SE in this paper. The election of the leader is done in a
distributed way. The proposed scheme, inspired by [14], not
only tries to prevent malicious agents from hijacking the
election process, but also ensures that each agent has an equal
probability of being elected. Numerous protocols are available
for this purpose (see [15], [16]) when there are no malicious
agents, but [17], [18] contain extensions to deal with malicious
agents. The proposed choice of leader election scheme makes
signiﬁcant usage of commitment schemes [19]. In general, a
commitment scheme follows a two stage process:

• Stage 1 (Commit): The sender locks a message in a

“box”, and sends the box to the receiver.

• Stage 2 (Reveal): Later, the sender provides a “key” to

open the box, which contains the original message.
This classic cryptographic primitive was proposed in [20]; see
also [21], [22]. Commitment means an agent chooses a value
from a ﬁnite set and electronically commits to that choice so
that it is difﬁcult to change the value later even if it wanted
to. Multiple malicious agents are assumed, even during leader
election, and the malicious agents may try to inﬂuence the
outcome of election. For example, one of them may desire to
be the leader, or avoid becoming the leader, or favor another
malicious agent to become the leader. Furthermore, during
the election process agents can communicate with each other
only via broadcast, and unicast/multicast modes are blocked.
Availability of secure broadcast channel is a fair assumption
in this scenario and the broadcast messages are taken to
be common knowledge. A detailed description of the leader
election scheme shown in Fig.2, is provided below. Suppose
there are N agents in the network.

1) Each agent i chooses a 32-bit identity number, IDi,
which is broadcast to all agents. Once an agent receives
ID := [ID0, ID1, . . . , IDN −1], it will then sort them
in ascending order, and store them in IDsorted.

2) In the next step, each agent chooses a number Ci ∈

{0, ..., N − 1} and a random string Ri.

3) Agent i then commits Ci. To commit Ci, the agent uses
a cryptographic hash function H, which takes the hash

AGENT - 1AGENT - iAGENT - NMalicious Activity DetectionAgent - iMaliciousLeaderMaliciousIf Elected as LeaderData AggregationState EstimationLeader ElectionAttestationTrust ManagementProposed Hierarchical Framework on Each AgentAgent NetworkProprietor Functions3

Fig. 2: Overview of the leader election scheme.

of Ci appended with the random string to give HCi :=
H(Ci||Ri).

4) Each agent i broadcasts its own hash HCi, and aggre-
gates the hashes HC := [HC0, HC1, ..., HCN −1] of all
agents.

5) Agents reveal their Ci and Ri

to every other agent
(via broadcast). This information, along with respective
hashes, is used to verify that the agent is committed to
its Ci, and has not changed it.

6) Each agent will compute k =

(cid:32)

(cid:33)

(cid:80)N −1

i=0 Ci

mod N..

7) The agent with the kth smallest ID in IDsorted is

chosen as the leader.

Since each agent will possess IDi
from every agent i,
IDsorted will be identical across agents. Similarly, all agents
will be able to arrive at the same k, since each agent will
possess Ci from every agent i. They can thus agree on a
particular agent becoming the leader without need for a central
entity.

The leader election process is triggered by the other agents
when an existing leader is compromised. Then new IDs are
generated by the agents. This forces a different ordering of
agents in IDsorted each time. Since the collection of Cs is
used by agents to obtain k, a malicious agent must not be
able to change its Ci after learning the Cs from other agents.
Therefore commitment schemes are used to force an agent to
pledge to its chosen Ci. In general, commitment schemes have
two properties, hiding and binding. The hiding property makes
it difﬁcult for other agents to determine Ci of agent i from
the hash, before the revelation phase. The binding property
makes it difﬁcult for agent i to change its Ci after commitment.
The random string Ri is appended to Ci when hashing to
randomize the resulting hash.

The algorithm above is a modiﬁcation of the algorithm
A − LEADps,uni in [14] which is used to elect a leader in
an asynchronous unidirectional ring network of agents. The
presented algorithm differs from A − LEADps,uni in two
ways. First, a hash-based commitment scheme is used instead
of Naor’s protocol [14]; second, A − LEADps,uni algorithm
embeds a unidirectional ring into a completely connected
network. However, this approach is time consuming, since
any communication must pass through the entire ring. Instead,
we assume the availability of a secure broadcast channel for
communication. More advanced leader election schemes such
as [23] also can be used in the proposed framework.

A hash-based commitment scheme is used, as it is practical
and easy to implement. Moreover, commitment schemes built
on cryptographic hash functions are known to be secure [19].
The hash function in this work is taken from the libhydrogen

cryptographic library [24], which is based on the Gimli
permutation [25]. The hash function can be replaced by other
well-accepted hash functions like BLAKE and SHA3, keeping
in mind the pitfalls pointed out in [26].
B. Threat Model

The threat model assumes a cyber-attack in which an
attacker can capture an agent or group of agents, re-program
them with malicious code, and then re-deploy them back into
network with the intent of affecting SE. The threat model
makes the following assumptions:

• The number of malicious agents is < N
• A compromised agent stays compromised until

2 − 1.

it

is

detected.

Note that physical attacks are not considered, such as trans-
mission blockage, modiﬁcation of physical sensors, enlarging
the agents’ memory, increasing processor speed, etc., which
are other ways by which an agent’s integrity could be com-
promised.
C. Malicious Activity Detection

In this section, the attestation scheme and the trust man-
agement scheme are described. Together they help detect
malicious activity of agents in the network.

1) Attestation: There are many mechanisms for detecting
compromised agents, for e.g., watch-dog [27], reputation-
based systems [28], etc. However, these methods are error
prone, because they rely on accurate observation and reasoning
of agents’ misbehaviour. In this work, a distributed software-
based attestation scheme, inspired by the one proposed in [29],
to verify the integrity of the code running within an agent,
without physically accessing it. Typically, software-based re-
mote attestation uses a challenge-response protocol between
two agents, as described in SWATT [30]. The challenge-
response protocol involves a veriﬁer and an interrogated device
(attester). The veriﬁer sends a challenge to the attester, which
performs a checksum on its process memory, and acknowl-
edges back with a response. Then, the veriﬁer validates the
response, by comparing it with an anticipated response, which
it has pre-computed locally.

The proposed attestation framework differs from the others
in using the concept of a report, i.e., after every attestation,
the veriﬁer broadcasts the details of attestation to all other
agents. We choose to broadcast reports to other agents to
prevent tampering of the report itself. This report contains
various parameters used in attestation, along with the outcome,
i.e., whether the veriﬁer suspects the attester to be malicious
or otherwise. Agents make use of the reports to arrive at a
consensus on whether or not malicious agents are present, and
if yes, identify these malicious agents [31]. The attestation
algorithm is designed to check if the program code has
been corrupted by an attacker. The program memory, which

Creates IDi  andbroadcastsReceives ID-i from otheragents. Sorts into ascending orderChooses a number Ci anda random string RiHashes Ci || Ri to getcommitted hash HCiBroadcasts HCiReveals Ci and RiReceives C-i and R-i fromother agents	Veriﬁes HC-i of other agentsusing their C-i and R-iCalculates keq. (12)Agent with kth smallest IDin IDsorted is the leaderAgent icontains the vital code is checked during the attestation. This
vital code also include the code of the proposed security
algorithm. Every agent serves as a veriﬁer at least once in a
window of approximately T seconds. During this interval, an
agent will provision itself as a veriﬁer at a random instant of
time, and challenge a randomly chosen attester, and then stay
idle for the remainder of the time interval. However, in this
interval, an agent can receive multiple challenges. This process
is repeated every T seconds, ad inﬁnitum. The frequency of
attestations an agent can perform (the value of T ) can be
limited based on its computational capability. Details of the
attestation algorithm used are not included due to lack of
space; see [31].

On the choice of software-based attestation: Software-based
attestation is an attractive choice for assessing integrity as it
requires no extra hardware. However, there are attacks on
software-based attestation; see [32], [33]. Use of time re-
strictions on the attestation process provides extra guarantees.
Some attestation schemes [34], [35] make use of hardware
components like Trusted Platform Modules (TPMs) to estab-
lish a root of trust, i.e., ability to store secret keys, calculate
hashes of memory during boot, etc. Also, trusted execution
environments like ARM TrustZone [36] have been explored for
attestation in [37], as they provide features like memory pro-
tection and isolated execution of code. Generally, hardware-
based attestation techniques have better security guarantees
and a wider range of use-cases than software-based techniques
[38]. Since the primary focus was the demonstration of a
critical meta-function SE through distributed attestation and
trust management, the simplest software-based attestation is
chosen on account of its straightforward implementation. Any
well designed attestation protocol can be integrated with the
proposed scheme, for e.g. [37],[34], with suitable modiﬁcation
for operation in a distributed fashion can be incorporated.
Indeed, the Parallella board contains ARM TrustZone that can
be used to improve the attestation scheme; see [31].

2) Trust Management: Suppose there are N agents in the
network. Whenever an agent k attests an agent j (cid:54)= k and
broadcasts its report, the evolution of trust of agent j at agent
i at time t + 1 can be expressed as



pij(t) + ∆k→j(pik(t))

i (cid:54)= j

(cid:105)1

(cid:104)

0

(1)

pij(t + 1) =



1

i = j,

where [x]1
0 is the projection of x on the set [0, 1], pik(t) is the
trust of agent k at agent i at time t, and ∆k→j(pik(t)) is (in
the proposed design)

(cid:40) pik(t)
N ,
− pik(t)
N ,

if attestation is positive,
if attestation is negative,

(2)

∆k→j(pik(t)) =

where the subscript k → j indicates that agent k is the
veriﬁer and agent j is the attester. When the agent j fails an
attestation, it is called as a negative attestation, whereas if an
attestation is successful, it is called as a positive attestation.
It is assumed that every agent has its own opinion of trust
for every other agent in the network and must perform an
attestation on another agent in a set time interval. Moreover,
it is also assumed that there will be no report losses during
the attestation process, i.e., every report sent by an agent is
received by the other agents. Handling report losses is beyond

4

the scope of the work. At the beginning, an agent’s opinion
of trust for every agent in the network is initialized to 1.

As stated earlier, the purpose of attestation is to check
the integrity of each agent by using a challenge-response
mechanism. Whenever an agent k attests agent j, agent k
broadcasts the status to all other agents. Then, every agent
i, i ∈ {1, . . . , N } \ {j}, in the network, updates the trust of
agent j using eq. (1) by considering its own opinion of trust of
agent j and agent k, which are pij(t) and pik(t), respectively.
If the opinion of trust of a particular agent reduces to 0,
then agents perform majority voting to cast out the malicious
agent from the network. Any agent can initiate this procedure,
and analogous to leader election, this too can be done in a
distributed fashion. Trust of a non-malicious agent may reduce
because of false accusations by the malicious agents. However,
other non-malicious agents increase the trust for that agent
with every positive attestation. The factor 1
N is used to ensure
graceful updates.

A short summary of the analysis of a tractable variation of
the proposed trust management scheme with a diminishing
step size rule is provided. The result highlights interesting
issues which will be discussed after stating the analytical
result. Consider the following: A uniformly randomly selected
agent k veriﬁes, from among others, a uniformly randomly
selected attesting agent j; the increments in (1) are modiﬁed
from (2) to be
∆k→j(pik(t)) =

if the attestation is positive,
if the attestation is negative,
(3)
where a(t) = 1/(t + 1). (If a(t) ≡ 1
N , we can recover (2).)
Now (1) and (3) constitute a projected stochastic approxima-
tion scheme with a step size that decreases with time.

a(t)pik(t),
−a(t)pik(t),

(cid:40)

Let H be the set of honest (non-malicious) agents, with the
remaining agents taken to be compromised or malicious. Let

(cid:40)

ej :=

1
−1

j ∈ H
j /∈ H.

(4)

iM (t) := (cid:80)

The quantity p(t) := (pij(t), i ∈ H, 1 ≤ j ≤ N ) is the trust
values held by each of the honest agents about each of the
iH (t) := (cid:80)
other agents at time t. Further, p(j)
k∈H\{i,j} pik(t),
and p(j)
k:k /∈H∪{i,j} pik(t), are the sum of the trust
values of all the honest agents except j and i, as held by i
at time t and the sum of the trust values of all the malicious
agents including j and i, as held by i at time t, respectively.
For p = (pij, i ∈ H, 1 ≤ j ≤ N ), deﬁne h(p) := (hij(p), i ∈
H, 1 ≤ j ≤ N ), where, with [·]+ and [·]− denoting positive
and negative parts, respectively,
iH −p(j)
p(j)
N (N −1)
(cid:104)
iH −p(j)
p(j)
ej
iM
N (N −1)
(cid:17)(cid:105)
iH −p(j)
p(j)
iM
N (N −1




pij ∈ (0, 1)

hij(p) :=

pij = 0.

pij = 1

−
(cid:104)

(5)



(cid:17)(cid:105)

ej

ej

iM

(cid:16)

(cid:17)

(cid:16)

(cid:16)

−

+

Let hE be an enlargement of h as follows: it is the smallest up-
per semi-continuous set-valued map with compact convex val-
ues such that h(p) ∈ hE(p) for almost all p ∈ [0, 1]H⊗N .For
our security analysis, we make the following simplifying
assumptions:

1) The attestation primitive is ideal and reveals the correct
labeling H and M for honest and malicious agents,
respectively.

2) All malicious agents cooperate to report a failed at-
testation on honest attesting agents and a successful
attestation on other malicious attesting agents.

Under these assumptions, we get the next result.

Proposition 1: Under the aforementioned threat model and
attestation model, almost surely, p(t) converges as t → ∞ to
a connected, closed, internally chain transitive invariant set1
of the differential inclusion ˙p(s) ∈ hE(p(s)).

Proof: See Appendix A.

Remarks: The reason that the differential inclusion ˙p(s) ∈
hE(p(s)) is tracked, and not the differential equation ˙p(s) =
h(p(s)), is because h(·) has discontinuities on the facets of the
unit cube, a fact that can be easily checked. The main reason
for this is the projection operation. When the driving function
for the differential equation has discontinuities, the differential
equation may not be well-posed, i.e., a solution may not exist
or there may be multiple solutions. One must therefore view
the solution to the differential equation in a generalized, the
so-called Filippov, sense; again, see [39, Sec. 5.4]. This gener-
alization involves hE(·), the smallest upper semi-continuous,
compact, convex, set-valued enlargement of h(·), and solutions
to the differential inclusion ˙p(s) ∈ hE(p(s)).

To get some insight on the consequences of Proposition 1,
ij = 1H(j), i ∈ H, 1 ≤ j ≤ N ),
the trust values p∗ := (p∗
where 1H is the indicator function, is a ﬁxed point for the
dynamics ˙p(s) = h(p(s)) since h(p∗) = 0. Indeed, if the
agents begin the process with an initial state p(0) = (pij(0) =
1, 1 ≤ i, j ≤ N ), i.e., all agents are assigned a trust value of
1, and |H| > N/2 + 1, i.e., the number of malicious agents is
strictly less than N/2 − 1, then p∗ is the point to which the
differential equation dynamics will settle.

However, there are also other ﬁxed points for the dynamics,
for e.g., q = (qij = 1Hc (j), i ∈ H, 1 ≤ j ≤ N ). If the
dynamics settles at this point, then each honest agent views
every other malicious agent with a trust value of 1 but every
other honest agent with a trust value of 0. This is exactly the
opposite of what we desire, and we should avoid entering the
basin of this attractor.

Let us now discuss the stochastic iterates. Our analysis
assumes that an agent is randomly chosen to be a veriﬁer and
that this agent randomly chooses another agent for attestation.
Thanks to Proposition 1,
the stochastic iterates track the
differential inclusion dynamics. When we start at p(0), with
all trust values 1, we are in the setting of the ﬁrst observation
above, and the stochastic iterates will converge to p∗ with high
probability, see [39] for theoretical estimates of the so-called
lock-in probability. However, randomness can also push the
system from the initial trusting state of p(0) into the basin of
the undesired attractor q, for example when the randomness

1Connectedness and closedness of sets are familiar notions. Invariant sets
are those that are invariant for the dynamics given by the differential inclusion
˙p(s) ∈ hE (p(s)). Not all invariant sets are settlement sets for the iterations.
Internally chain transitive invariant sets are speciﬁc invariant sets for the
dynamics ˙p(s) ∈ hE (p(s)), see [39] for a deﬁnition, and the iterates settle
in one such set (possibly random).

5

overwhelmingly chooses the malicious agents as veriﬁers in
the veriﬁcation procedure. Of course this happens with lower
probability when there are a larger number of honest agents,
but since this is in-principle possible, Proposition 1 cannot be
strengthened any further. However, larger the number of honest
agents, lower is the probability of randomness overwhelmingly
picking the malicious agents as veriﬁers, and lower is the
probability of settling in such undesired equilibria. In our
empirical experiments, we did not encounter settlement at such
undesirable equilibria; see section III. A way to pro-actively
address the issue is to ensure that every agent veriﬁes only
once in one round of approximately T seconds; results of the
corresponding implementation are in section III.

III. EXPERIMENTAL SETUP AND RESULTS

The proposed framework is prototyped and tested on a
cluster of ﬁve Parallella development boards connected in a
star network [40] as shown in Fig.3a. Parallella contains a
Xilinx Zynq SoC (ARM+FPGA) with Linux-capability and a
16-core co-processor which can perform parallel processing. In
this work, each IED is a Parallella which would record voltage
and current data, gather data from other IEDs, and perform
SE if elected as a leader. The framework for communication
between agents is created using serf [41], which allows broad-
cast and unicast communication. It provides a platform for
devices to execute the challenge-response protocol, and gives
them the capability to broadcast events and trigger responses.
Each Parallella 32 GB SD card is loaded with voltage and
current data generated using MATLAB, representing PMU
data (IED performs PMU operation) at each bus of the IEEE
5-bus system shown in Fig.3b. A server shown in the ﬁgure is
used to gather data for activity tracking and display purposes.
Kalman ﬁlter based SE using PMU data [42] is used as the
critical algorithm to be secured. Additionally, the scalability
of the proposed framework is tested using simulations on the
IEEE 118 bus system.

(a) IED Cluster

(b) IEEE 5 Bus System

Fig. 3: The experimental setup for testing the framework.
Initially, after the devices are started-up, they are synchro-
nized using the NTP. Then, they start broadcasting information
to each other, so that each device can have a view of the
network, which is designed using serf. Once they become part
of the serf cluster, a leader will be elected, as explained in
section II-A. Now, devices start sending data to the leader
periodically (once a minute).
SE when there is no malicious agent: The 5 bus system
data is taken from the MATPOWER toolbox. SE will begin
immediately after the leader election scheme. The estimated
phase angles are shown in Fig.4a without any malicious agent.
the red line indicates true state of the system,
In Fig.4a,

PMUPMUPMUPMUPMUBus 1Bus 2Bus 3Bus 4Bus 56

reducing its own trust. Now, through majority voting, agent 3
will be identiﬁed as malicious and its measurements will be
subsequently ignored by the leader. Also, it is evident from
Figures 4b to 4f that the trust for the other agents is varying,
since agent 3 is constantly accusing others of being malicious
through negative attestations. However, their trust increases
and reaches 1 due to positive attestations from the other non-
malicious agents. This process is constantly running in the
background to track any suspicious activity for safe operation
of the grid.

The state estimation result of this case is presented in
Fig.4g. The squared error observed in this case—after a single
Kalman iteration—is 0.2034. During the simulation, data from
device 3 is ignored. Fig.4h, shows the maximum absolute error
observed in the system when a malicious agent is present.
The simulation is carried out for a duration of 40 samples.
A malicious agent is introduced at the 21st sample, and is
detected at the 28th sample; note that the observed error in the
system is elevated because of the fabricated data reported by
the malicious agent. Once detected, the data from malicious
agent is automatically ignored by the leader.

Multiple malicious agents: In this section effectiveness of
the proposed framework with multiple malicious agents is
veriﬁed. Two cases, cooperative malicious agents when agents
cooperate with each other to increase their own trust and non-
cooperative agents when malicious agents do not necessarily
cooperate with each other, are evaluated. In the cooperative
case, a malicious agent always chooses a malicious agent as
an attester whenever it gets a chance of being a veriﬁer and
always reports in favor of a malicious agent. In addition to
this, when a non-malicious agent reports against one of the
malicious agent, all malicious agents increase the trust of this
agent instead of reducing it.
IEEE 5 Bus System: For the IEEE 5 bus system two malicious
agents are created. Evolution of trust at non-malicious agent,
is presented for non-cooperative agents and cooperative agents
in Fig.5a and Fig.5b respectively. In both simulated cases, the
proposed framework is able to identify all the malicious agents
in the system, even though the number of malicious agents is
≮ N/2 − 1. Furthermore, from Fig.5a and Fig.5b, one can
observe that the detection of malicious agents, when they are
cooperating with each other, takes more number of attestations
in comparison to non-cooperating case.
IEEE 118 Bus System: The IEEE 118 bus system is used to
test the scalability of the proposed framework and a group of
5 malicious agents at buses 45 to 49 which represents a big
interconnection point with two generator buses, is simulated.
Considering the high cost of Parallella devices, we resort
to simulations on this test system to evaluate the proposed
framework. Simulation results on 118 bus systems for both
non-cooperative and cooperative cases are presented in Fig.5c
and Fig.5d, respectively. Though the framework is able to
identify all the malicious agents, the number of attestations
performed in both the cases are high. For a bigger system with
hundreds of buses, the proposed framework might take some
time to reach a consensus through majority voting. Therefore,
suitable methods to reduce the number of attestations can be
explored as one of the future research directions. One approach

(a) SE, No malicious agent.

(b) Trust at agent 1.

(c) Trust at agent 2.

(d) Trust at agent 3.

(e) Trust at agent 4.

(f) Trust at agent 5.

(g) SE, one malicious agent.

(h) Maximum absolute error.

Fig. 4: 5 bus system, with and without a malicious agent.

whereas the blue line indicates the estimated states. This result
is obtained after a single Kalman iteration, and the squared
error (L2-norm of the error vector) observed is 0.147.
SE when agent at Bus 3 is malicious: The IED at bus 3
is deliberately made malicious by modifying its core process.
After the leader election, attestation between devices begins
and the trust of a device is updated based on the reports
obtained from attestation. In this implementation, every device
randomly performs an attestation in a 40 second interval. This
interval can be further reduced based on the computational
capability of agents. Whenever the trust values for a device
drops to 0 at a majority of devices, data from that device is
ignored. The combined choice of attestation and trust man-
agement used in the framework is able to detect the malicious
device in near real time. The Fig.4 shows the evolution of trust
at each agent about all the other agents, using (1). One can
observe that opinion of trust for agent 3 is reduced to 0 at
agents 1, 2, 4, and 5, as shown in Figures 4b, 4c, 4e and 4f,
respectively. However its own opinion of trust, in Fig.4d is
very high—because it does not want to become a target by

11.522.533.544.55Bus Number-1-0.500.511.522.533.5AngleTrue StatesEstimated States0510153540455020 25 30 Number of Attestations00.20.40.60.811.2Opinion of TrustAgent 1Agent 2Agent 3Agent 4Agent 50510153540455020 25 30 Number of Attestations00.20.40.60.811.2Opinion of TrustAgent 1Agent 2Agent 3Agent 4Agent 50510153540455020 25 30 Number of Attestations00.20.40.60.811.2Opinion of TrustAgent 1Agent 2Agent 3Agent 4Agent 50510153540455020 25 30 Number of Attestations00.20.40.60.811.2Opinion of TrustAgent 1Agent 2Agent 3Agent 4Agent 50510153540455020 25 30 Number of Attestations00.20.40.60.811.2Opinion of TrustAgent 1Agent 2Agent 3Agent 4Agent 511.522.533.544.55Bus Number-1-0.500.511.522.533.5AngleTrue StatesEstimated States0510152025303540Time00.20.40.60.811.21.4Maximum absolute error observed in the systemcould be that we sub-divide the network into different areas
and a few nodes in an area can be designated for leader
election in each cluster; this reduces the number of attestations
and costs associated with communication infrastructure.

(a) IEEE 5 bus system.

(b) IEEE 5 bus system.

(c) IEEE 118 Bus System.

(d) IEEE 118 Bus System.

Fig. 5: Non-malicious agent’s trust with > 1 malicious agents.

7

an attestation and trust management protocol that maintains
and updates the trust metric of every agent in the system,
and from a consensus algorithm that isolates the malicious
agents. All these are distributed algorithms. Assertions coming
from attestations are used to measure trust. A graceful trust
update protocol ensures that the malicious agents’ trust have a
tendency to decrease if there are enough honest agents deemed
as honest. The malicious agents are eventually identiﬁed
as malicious as empirically veriﬁed in the simulations. The
theoretical results identiﬁes the points of settlement of the trust
management algorithm. While there is a nonzero probability
that the trust values may settle at undesirable values, if the
number of malicious agents is strictly less than N
2 − 1 and
the initial trust values are all 1, then the system has a high
probability of settling at the values where all agents statuses
are correctly identiﬁed by all the honest agents, as veriﬁed
empirically in the simulations and experimental setup. The
design results in a logical hierarchy from the perspective of the
critical functionality (SE), since it is performed at a randomly
elected leader/coordinator agent. We have thus demonstrated
a decentralized framework to protect a critical function (such
as SE) at a control center.

APPENDIX A
PROOF OF PROPOSITION 1

Let us recall the iteration

pij (t + 1) = [pij (t) + ∆k→j (pik(t))]1

0 , ∀i ∈ H, 1 ≤ j ≤ N, j (cid:54)= i, j (cid:54)= k

when agent k attests agent j at time t + 1. The notation. [·]1
0 refers to the projection
operation. If i = j, take pii(t) = 1. Recall that ej = 1 if j ∈ H and ej = −1
otherwise. Write 1{·} for the indicator function of an event. Recognising that the choice
of the agent pair e(t + 1) for the veriﬁer and attester is uniformly random across the
agents

(a) Min trust, non-mal. agents.

(b) Max trust, malicious agents

pij(t + 1) =

(cid:104)
pij(t) +

(cid:88)

∆k→j(pik(t))1{e(t + 1) = (k, j)}

(cid:105)1

0

Fig. 6: Min. and max. values of trust, 118 bus system.
The proposed framework will be able to handle any number
of malicious agents that is strictly less than N
2 −1; in this case
the ordinary differential equation starting from the all ones
(trusting) initial condition settles at p∗ where all malicious
and honest agents are correctly identiﬁed. It can be veriﬁed
empirically as follows. In Fig.6a, the minimum and maximum
values of trust for non-malicious and malicious agents are
presented. The simulation is stopped the moment N
2 or more
honest agents identify the status of each agent correctly. The
ﬁrst plot in Fig.6a represents the minimum value of trust
for the non-malicious agents, and the second plot represents
the maximum value of trust for the malicious agents. From
Fig.6a, one can observe that the worst-case non-malicious
agents minimum trust values always exceed the maximum of
the malicious agents trust values, i.e., the proposed framework
is able to identify all the malicious agents (via a majority rule)
as long as they are strictly less than N
IV. CONCLUSION

2 − 1 in number.

In this paper a distributed hierarchy-based framework to
protect critical functions of a coordinating control center in
a distributed environment is proposed. Kalman ﬁlter based
SE is used as the critical function that
is to be secured
for demonstration. The protection comes from choosing the
agent that becomes the coordinator in a random fashion, from

(3)
=

(cid:104)
pij(t) + a(t)

(cid:88)

ekejpik(t)1{e(t + 1) = (k, j)}

k:k(cid:54)=j

(cid:105)1

0

(cid:104)

=

pij(t) + a(t)

k:k(cid:54)=j
(cid:16)

ej
N (N − 1)

(cid:88)

k:k(cid:54)=j

(cid:18)

ekpik(t)

ekejpik(t)

1{e(t + 1) = (k, j)} −

(cid:88)

+

=

k:k(cid:54)=j
(cid:104)

pij(t) + a(t)

(cid:16)

ej
N (N − 1)

(p(j)

iH (t) − p(j)

iM (t)) + Mij(t + 1)

(cid:17)(cid:105)1

0

1
N (N − 1)

(cid:19) (cid:17)(cid:105)1

0

where Mij is a martingale noise (with respect to the ﬁltration generated by the p(·) =
(pij (·), i ∈ H, 1 ≤ j ≤ N ) process. If the projection operation were not present,
then one would have anticipated that the iterates would track the ordinary differential
equation system

˙pij (t) =

ej
N (N − 1)

(p(j)

iH (t) − p(j)

iM (t)).

(6)

However, the projection operation changes the dynamics, and the goal is to identify this
modiﬁed dynamics.

Let us write p := (pij , i ∈ H, 1 ≤ j ≤ N ) and [p]1

0, i ∈
H, 1 ≤ j ≤ N ). The projection operation is deﬁned component-wise, and so the
Fr´echet derivative of [p] at p in the direction q, denoted γ(p; q) and deﬁned by

0 := ([pij ]1

is given by

γ(p; q)ij =

[p + δq]1

0 − p

δ

,

γ(p; q) := lim
δ↓0



0
0
qij



pij = 1 and qij > 0
pij = −1 and qij < 0
otherwise.

(7)

Since the martingale noise vector, whose ij component is

Mij(t) =

(cid:88)

k:k(cid:54)=j

(cid:18)

ekejpik(t)

1{e(t + 1) = (k, j)} −

1
N (N − 1)

(cid:19)

,

0102050607030 40Number of Attestations00.20.40.60.811.2Opinion of TrustAgent 1Agent 2Agent 3Agent 4Agent 5Two Non-cooperative Malicious 010203070809010040 50 60 Number of Attestations00.20.40.60.811.2Opinion of TrustAgent 1Agent 2Agent 3Agent 4Agent 5Two cooperative MaliciousFive Non-Cooperative MaliciousOpinion of 00.511.544.552 2.5 3 3.5 Number of Attestations10400.20.40.60.811.2Opinion of TrustAgent 36Agent 45Agent 46Agent 47Agent 48Agent 49Agent 78Five Cooperative Maliciousis conditionally independent of the history given p(t), the driving vector ﬁeld for the
dynamics is not given by the right-hand side (6), but instead is given by

h(p(t)) := E [γ (p(t); q(t)) | p(t)]

where

q(t) = (cid:80)

k:k(cid:54)=j ekej pik(t)1{e(t + 1) = (k, j), }, i ∈ H, 1 ≤ j ≤ N.

(8)

(9)

Using (7) and (9) in (8), one gets

h(p(t))ij =

1
N (N − 1)

(cid:104)

ej (piH (t) − piM (t)) · 1{pij (t) ∈ (0, 1)}

− [ej (piH (t) − piM (t))]− · 1{pij (t) = 1}
(cid:105)

+[ej (piH (t) − piM (t))]+ · 1{pij (t) = 0}

which is the same as the driving function (5). It is easy to check that the driving function

mapping p (cid:55)→ h(p) is not continuous at some boundary points. Then, by the results

of [39, Sec. 5.4], all subsequential limits of the iterates track the differential inclusion

˙p(t) ∈ hE (p(t)) and, further, the iterates converge to a possibly random, connected,

compact, internally chain transitive, invariant set for the differential inclusion ˙p(t) ∈

hE (p(t)). This completes the proof.

REFERENCES

[1] S. Basumallik, “A taxonomy of data attacks in power systems,” arXiv

preprint arXiv:2002.11011, 2020.

[2] T. Nguyen, S. Wang, M. Alhazmi, M. Nazemi, A. Estebsari, and
P. Dehghanian, “Electric power grid resilience to cyber adversaries: State
of the art,” IEEE Access, vol. 8, pp. 87 592–87 608, 2020.

[3] Y. Chakhchoukh and H. Ishii, Cyber Security for Power System State

Estimation. Cham: Springer Intnl. Pub., 2019, pp. 241–256.

[4] S. Lakshminarayana and D. K. Yau, “Cost-beneﬁt analysis of moving-

target defense in power grids,” IEEE Trans. on Power Systems, 2020.

[5] J. Kang, I. Joo, and D. Choi, “False data injection attacks on contingency
analysis: Attack strategies and impact assessment,” IEEE Access, vol. 6,
pp. 8841–8851, 2018.

[6] Y. Li and Y. Wang, “False data injection attacks with incomplete network
topology information in smart grid,” IEEE Access, vol. 7, pp. 3656–3664,
2018.

[7] M. H. Cintuglu and D. Ishchenko, “Secure distributed state estimation
for networked microgrids,” IEEE Internet of Things Journal, vol. 6,
no. 5, pp. 8046–8055, 2019.

[8] M. H. Basiri, J. G. Thistle, J. W. Simpson-Porco, and S. Fischmeister,
“Kalman ﬁlter based secure state estimation and individual attacked
sensor detection in cyber-physical systems,” in American Control Con-
ference (ACC), 2019, pp. 3841–3848.

[9] Y. Chen, S. Huang, F. Liu, Z. Wang, and X. Sun, “Evaluation of
reinforcement learning-based false data injection attack to automatic
voltage control,” IEEE Trans. Smart Grid, vol. 10, no. 2, pp. 2158–
2169, 2019.

[10] A.-Y. Lu and G.-H. Yang, “False data injection attacks against state
estimation in the presence of sensor failures,” Information Sciences, vol.
508, pp. 92 – 104, 2020.

[11] Y. Chakhchoukh, H. Lei, and B. K. Johnson, “Diagnosis of outliers
and cyber attacks in dynamic pmu-based power state estimation,” IEEE
Transactions on Power Systems, vol. 35, no. 2, pp. 1188–1197, 2020.

[12] M. Shahidehpour and Y. Wang, Communication and control in electric
power systems: applications of parallel and distributed processing.
Hoboken, New Jersey, US: IEEE, John Wiley & Sons, 2004.

[13] F. Samie, L. Bauer, and J. Henkel, “Edge computing for smart grid:
An overview on architectures and solutions,” in IoT for Smart Grids.
Springer, 2019, pp. 21–42.

[14] I. Abraham, D. Dolev, and J. Y. Halpern, “Distributed protocols for
leader election: A game-theoretic perspective,” in Distributed Comput-
ing, 2013, pp. 61–75.

[15] N. A. Lynch, Distributed Algorithms. San Francisco, CA, USA: Morgan

Kaufmann Publishers Inc., 1996.

[16] G. L. Peterson, “An o(nlog n) unidirectional algorithm for the circular
extrema problem,” ACM Trans. Program. Lang. Syst., vol. 4, no. 4, pp.
758–762, 1982.

[17] P. Feldman and S. Micali, “An optimal probabilistic protocol for syn-
chronous byzantine agreement,” SIAM Journal on Computing, vol. 26,
no. 4, pp. 873–933, 1997.

[18] J. Katz and C.-Y. Koo, “On expected constant-round protocols for
byzantine agreement,” J. Comput. Syst. Sci., vol. 75, no. 2, pp. 91–112,
2009.

8

[19] I. Damgard and J. B. Nielsen, “Commitment schemes and zero-

knowledge protocols, 2006,” 2008.

[20] M. Blum, “Coin ﬂipping by telephone a protocol for solving impossible

problems,” SIGACT News, vol. 15, no. 1, pp. 23–27, 1983.

[21] G. Brassard and C. Crepeau, “Non-transitive transfer of conﬁdence: A
perfect zero-knowledge interactive protocol for sat and beyond,” in 27th
Annual Symp. on Foundations of Computer Science, 1986, p. 188–195.
[22] S. Goldwasser, S. Micali, and R. Rivest, “A digital signature scheme
secure against adaptive chosen-message attacks,” SIAM Journal on
Computing, vol. 17, no. 2, pp. 281–308, 1988.

[23] L. Gasieniec, G. Stachowiak, and P. Uznanski, “Almost logarithmic-time
space optimal leader election in population protocols,” in Proceedings
of the 31st ACM Symposium on Parallelism in Algorithms and Archi-
tectures, 2019, p. 93–102.

[24] F. Denis, “A lightweight, secure, easy-to-use crypto library suitable
for constrained environments.” https://github.com/jedisct1/libhydrogen,
2019.

[25] D. J. Bernstein, S. K¨olbl, S. Lucks, P. M. C. Massolino, F. Mendel,
K. Nawaz, and Schneider, “Gimli : A cross-platform permutation,” in
Cryptographic Hardware and Embedded Systems – CHES 2017, 2017,
pp. 299–320.

[26] S. Halevi and S. Micali, “Practical and provably-secure commitment
schemes from collision-free hashing,” in Advances in Cryptology —
CRYPTO ’96. Springer Berlin Heidelberg, 1996, pp. 201–215.
[27] S. Marti, T. J. Giuli, K. Lai, and M. Baker, “Mitigating routing
misbehavior in mobile ad hoc networks,” in 6th Annual International
Conference on Mobile Computing and Networking, 2000, pp. 255–265.
[28] S. Ganeriwal, L. K. Balzano, and M. B. Srivastava, “Reputation-based
framework for high integrity sensor networks,” ACM Trans. Sen. Netw.,
vol. 4, no. 3, pp. 15:1–15:37, 2008.

[29] Y. Yang, X. Wang, S. Zhu, and G. Cao, “Distributed software-based
attestation for node compromise detection in sensor networks,” in 26th
IEEE International Symposium on Reliable Distributed Systems, 2007,
p. 219–230.

[30] A. Seshadri, A. Perrig, L. van Doorn, and P. Khosla, “Swatt: software-
based attestation for embedded devices,” in IEEE Symposium on Security
and Privacy, 2004, pp. 272–282.

[31] B. P. Robert, P. A. Babu, N. Kashyap, and G. Gurrala, “Practical
approaches towards securing edge devices in smart grid,” in IEEE 8th
International Conference on Power Systems (ICPS), 2019, pp. 1–6.
[32] X. Kovah, C. Kallenberg, C. Weathers, A. Herzog, M. Albin, and
J. Butterworth, “New results for timing-based attestation,” in IEEE
Symposium on Security and Privacy, 2012, p. 239–253.

[33] C. Castelluccia, A. Francillon, D. Perito, and C. Soriente, “On the
difﬁculty of software-based attestation of embedded devices,” in 16th
ACM Conference on Computer and Communications Security, ser. CCS
’09, 2009, p. 400–409.

[34] C. Kil, E. C. Sezer, A. M. Azab, P. Ning, and X. Zhang, “Remote
attestation to dynamic system properties: Towards providing complete
system integrity evidence,” in IEEE-IFIP International Conference on
Dependable Systems Networks, 2009, pp. 115–124.

[35] H. Tan, W. Hu, and S. Jha, “A tpm-enabled remote attestation protocol
(trap) in wireless sensor networks,” in 6th Workshop on Performance
Monitoring and Measurement of Heterogeneous Wireless and Wired
Networks, ser. PM2HW2N ’11, 2011, p. 9–16.

[36] A. S. Technology, “Building a secure system using trustzone technol-

ogy,” ARM Security Technology, Tech. Rep., 2009.

[37] T. Abera, N. Asokan, L. Davi, J.-E. Ekberg, T. Nyman, A. Paverd, A.-R.
Sadeghi, and G. Tsudik, “C-ﬂat: Control-ﬂow attestation for embedded
systems software,” in Proceedings of the 2016 ACM SIGSAC Conference
on Computer and Communications Security, ser. CCS ’16, 2016, p.
743–754.

[38] T. Abera, N. Asokan, L. Davi, F. Koushanfar, A. Paverd, A.-R. Sadeghi,
and G. Tsudik, “Invited - things, trouble, trust: On building trust in iot
systems,” in 53rd Annual Design Automation Conference, 2016.
[39] V. S. Borkar, Stochastic approximation: a dynamical systems viewpoint.

Springer, 2009, vol. 48.

[40] A. Olofsson, T. Nordstr¨om, and Z. Ul-Abdin, “Kickstarting high-
performance energy-efﬁcient manycore architectures with epiphany,” in
48th Asilomar Conference on Signals, Systems and Computers.
IEEE,
2014, pp. 1719–1726.

[41] HashiCorp, “Serf,” HashiCorp, 2019. [Online]. Available: http://serf.io/
[42] H. Tebianian and B. Jeyasurya, “Dynamic state estimation in power
systems using kalman ﬁlters,” in 2013 IEEE Electrical Power & Energy
Conference.

IEEE, 2013, pp. 1–5.

