CyNER: A Python Library for Cybersecurity Named Entity Recognition

Md Tanvirul Alam1, Dipkamal Bhusal1, Youngja Park2, Nidhi Rastogi1
1Rochester Institute of Technology, USA
{ma8235,db1702,nxrvse}@rit.edu
2IBM T. J. Watson Research Center, USA
young_park@us.ibm.com

Abstract

for

Open Cyber threat
intelligence (OpenCTI)
information is available in an unstructured
format from heterogeneous sources on the
Internet. We present CyNER, an open-source
python library for
cybersecurity named
entity recognition (NER). CyNER combines
transformer-based models
extracting
cybersecurity-related entities, heuristics for
extracting different indicators of compromise,
and publicly available NER models for generic
entity types. We provide models trained on
a diverse corpus that users can readily use.
Events are described as classes in previous
research - MALOnt2.0 (Christian et al., 2021)
and MALOnt (Rastogi et al., 2020) and to-
gether extract a wide range of malware attack
details from a threat intelligence corpus. The
user can combine predictions from multiple
different approaches to suit their needs. The
library is available in Github 1 and a video
demonstrating the use case is available in
YouTube.2

1

Introduction

A large amount of open cyber threat and attack
information, also called cyber threat intelligence
(openCTI), is available on the Internet on platforms
such as security blogs, the dark web, software ven-
dors bulletin boards, ofﬁcial news and social net-
works (Yi et al., 2020). Both structured and un-
structured forms of openCTI can beneﬁt security
operations center (SOC) analysts and researchers
in their increasingly complex jobs of triaging false
alerts, ﬁnding zero-day attacks, protecting intellec-
tual property, and preventing intrusions from adver-
saries. However, access to this information from
openCTI has remained relatively untapped due to
limited research enabling aggregation and structur-
ing of threat intelligence incidents. Furthermore,

there is a lack of a gold standard dataset in cyber-
security, which is the ﬁrst prerequisite for the basic
task of information extraction or train any modern
natural language processing (NLP) method.

Current methods rely on structured knowledge
bases such as the cybersecurity vulnerability enu-
meration (CVE)3 database, mitre att&ck frame-
work(att&ck)4 to extract named entities which re-
sult in high accuracy but produce poor performance
when similar entities are extracted from unstruc-
tured, complex threat reports, which is more often
the case. Conditional random ﬁelds (CRF) (Joshi
et al., 2013), support vector machine (SVM) (Deliu
et al., 2017), and many learning models have been
unsuccessful in yielding satisfactory results in ex-
tracting cybersecurity events from openCTI. While
transformer-based methods, such as BERT (Devlin
et al., 2018), have been explored, the cybersecurity
concepts extracted provided a limited advantage
over information extracted from structured sources
such as CVE (Xie et al., 2021).

To address the challenges above, we propose
CyNER, a generic python library for extracting
cybersecurity threat intelligence incidents. Speciﬁ-
cally, we make the following contributions:

1. We provide a manually-labeled, benchmark
dataset annotated on a wide range of cyberse-
curity incidents. While the annotated corpus
relates to Android malware threat analysis, the
concepts are generic enough to apply to other
security threats. We also provide a corpus
of noise-free, high-quality openCTI reports
written on android malware analysis.

2. We provide CyNER, an easy to use python li-
brary that allows access to transformer-based
NER models pre-trained on high-ﬁdelity secu-
rity events (e.g., malware, vulnerability) and
a heuristic model for threat indicators (e.g.,

1https://github.com/aiforsec/CyNER
2https://youtu.be/E4uKCrKKaP8

3https://cve.org
4https://attack.mitre.org/

2
2
0
2

r
p
A
8

]

R
C
.
s
c
[

1
v
4
5
7
5
0
.
4
0
2
2
:
v
i
X
r
a

 
 
 
 
 
 
malware hashes, compromised IP addresses).
In addition, we include support for extract-
ing generic entity types with popular NLP
libraries.

3. We provide a ﬂexible and modular imple-
mentation of CyNER and user documentation.
The library provides the option to combine
prediction from multiple models with conﬁg-
urable priority settings.

Our proposed framework, CyNER allows cyber-
security information extraction using NER mod-
els that deliver high accuracy. The malware-
related threat intelligence discovery combines mal-
ware data with general world concepts, integrates
"knowledge," correlation, and concept grouping,
and therefore, generates inference and insights for
SOC analysts.

In this work, we instantiate existing malware
ontologies (Rastogi et al., 2020; Christian et al.,
2021) using a corpus comprising over 60 high
quality and large threat intelligence reports written
between 2018-2021 and downloaded from web-
sites belonging to security and technology orga-
nizations (Kaspersky, Symantec, McAfee). The
annotated text contains entities manually generated
by graduate students trained by their advisor expe-
rienced in cybersecurity. We build on the existing
strengths of the security, semantic web, and natural
language domains. Security ontologies (Rastogi
et al., 2020) (Swimmer, 2008) are extended to ex-
tract cyber security threat intelligence from online
sources. Other beneﬁts include the interoperability
of information across applications and creating la-
beled features for machine learning models. Using
ontologies when labeled data allows queries over
large datasets to identify trends and predict future
occurrences.

2 Related Work

Security ontologies (like malware) have attempted
to provide a structure to security concepts that cap-
ture event analysis (Swimmer, 2008) primarily to
collate data and distribute it across organizations
and institutions (Barnum, 2012; Connolly et al.,
2014). Other models for extracting and structuring
threat intelligence focus on one of the following -
identifying attack patterns, software vulnerabilities,
threats, or information dissemination.

CVE5, NVD6 are vulnerability tracking pro-
grams where the security community feeds infor-
mation. For sharing threat intelligence, there are
industry standards like Structured Threat Informa-
tion eXpression (STIX)(Barnum, 2012), which pro-
vides a language-agnostic framework to capture
threat intelligence into a shareable package.
In
contrast, a trusted automated exchange of indica-
tor information (TAXII) (Connolly et al., 2014)
is a platform that can send and receive the STIX
package.

3 System Overview

The primary goal of our library is to provide cy-
bersecurity researchers with models for extracting
cybersecurity entities and provide the framework to
train new models on annotated datasets. We show
a detailed system diagram of our library in Figure
1. In this section, we discuss the three key compo-
nents of our framework - using pretrained models
for prediction, training models on new datasets,
and augmenting prediction using a combination of
different models.

3.1 Pretrained Model for Prediction

We provide three different types of models that
users can readily use to extract cybersecurity
entities-

3.1.1 Transformer models pretrained on

cybersecurity corpus

We train transformer models on an annotated cy-
bersecurity corpus and add the pretrained mod-
els in our library. Our dataset consists of ﬁve
classes-malware, indicator, system, organization,
and vulnerability. These models allow users to ex-
tract named entities related to the cybersecurity do-
main. We use the tner library (Ushio and Camacho-
Collados, 2021) to train the models.

3.1.2 Heuristic for indicators of compromise
We provide a heuristic-based approach for cate-
gorizing different indicators of compromise, e.g.,
URL, IP address, hash, etc. These entities do not
require an understanding of the context they ap-
pear in and can be usually extracted with regular
expression matching. We use regular expression
templates proposed in earlier work on cybersecu-
rity NER (Yi et al., 2020; Piplai et al., 2020). We
show some example regex patterns in Table 1.

5https://cve.mitre.org/
6https://nvd.nist.gov/

Figure 1: System diagram of the CyNER library

3.1.3 Generic NER models

Entity Types Regular Expression

Sometimes entities that do not fall under cyberse-
curity concepts may be of interest when analyzing
threat reports. For example, extracting targeted
countries of a malware attack from threat reports
can give important insight regarding its behavior.
Off-the-shelf NER models provided in popular
NLP libraries, which are trained on generic cor-
pus like Ontonotes (Hovy et al., 2006) can achieve
good accuracy on such classes of entities (Kim
et al., 2020). We integrate Flair (Akbik et al., 2019)
and spaCy7 with our library, and users can readily
use the pretrained NER models available in those
libraries.

3.2 Model Training

We provide modules for ﬁnetuning transformer
language models on user-provided datasets. We
use Huggingface’s transformer library (Wolf et al.,
2019) for ﬁnetuning. The user can use pretrained
language models available in the transformer li-
brary and set different hyperparameters during
model ﬁnetuning.

3.3 Combining Prediction from Multiple

Approaches

We provide a simple yet intuitive mechanism for
combining predictions from different methods. The
user can use any combination of the available mod-
els (transformers, heuristics, ﬂair, spacy) for mak-
ing a prediction. The user can also deﬁne priority
when merging outputs from multiple models using

FilePath
Email
SHA256
SHA1
CVE
IPv4

r’[a-zA-Z]:\\([0-9a-zA-Z]+)’, r’(\/[^\s\n]+)+’
r’[a-z][_a-z0-9-.]+@[a-z0-9-]+[a-z]+’
r’[a-f0-9]{64}|[A-F0-9]{64}’
r’[a-f0-9]{40}|[A-F0-9]{40}’
r’CVE—[0-9]{4}—[0-9]{4,6}’
r’^((25[0-5]|(2[0-4]|1\d|[1-9]|)\d)(\.(?!)|)){4}$’

Table 1: Example regular expressions used in heuristics
based detection

a keyword argument priority. The default value of
the priority is ’HTFS,’ which indicates that the out-
put from the heuristic approach will be given the
highest priority, followed by the prediction from the
given transformer model, followed by the Flair and
Spacy models (if provided). If there is an overlap
between predicted entity positions from multiple
approaches, we use the prediction from the highest
priority one.

4 Datasets

We collected approximately 60 threat intelligence
reports referenced in the MITRE att&ck website
under the software category.8 Each threat report de-
scribes a unique malware. Since cleaning unstruc-
tured CTI reports can be very challenging (Kim
et al., 2020), we manually extract the clean text
from each report. We use the BRAT annotation
tool (Stenetorp et al., 2012) for annotating the cor-
pus. Example annotation is shown in Figure 2.

Our dataset consists of ﬁve classes of high impor-
tance for analyzing threat reports - malware, indica-

7https://spacy.io/

8https://attack.mitre.org/software/

Figure 2: Example annotation from BRAT

Split Malware

Indicator System Organization Vulnerability

Model

Precision Recall F1-score

Train
Dev
Test

703
254
242

1021
208
261

837
182
248

284
92
131

48
9
10

Table 2: Dataset statistics showing the number of in-
stances of different classes.

tors of compromise, system, organization, and vul-
nerability. The malware class encapsulates viruses,
trojans, ransomware, etc. Operating system (e.g.,
Android, Windows), software (e.g., Adobe ﬂash
player, Skype), and hardware. Indicators of com-
promise comprise domain name, URL, IP address,
ﬁlename, Hash, email, port number, etc. Vulnera-
bility includes both CVE ID (e.g., CVE-2012-2825)
and mention of exploits (e.g., master key vulnera-
bility). It is worth noting that other types of entities
like location and person are also important when
analyzing threat reports. However, these and other
generic entities can be extracted well using differ-
ent off-the-shelf models (Kim et al., 2020). As a
result, we added the support to extract such entities
using other NLP libraries and did not include them
in our annotation.

We split the corpus into train, dev, and test split
containing 40, 10, and 10 documents, respectively.
Statistics of different types of entities in each split
are displayed in Table 2. We convert the annotation
in BIO format for training, B-preﬁx indicating the
beginning of a tag and the I-preﬁx indicating the
inside of that tag. An outside (O) tag is used to
indicate a token that does not belong to any of the
ﬁve categories. We have 106991 total tokens in the
complete corpus, with 4530 tagged entities.

BERT-base-uncased
BERT-large-uncased
RoBERTa-base
RoBERTa-large
XLM-RoBERTa-base
XLM-RoBERTa-large

69.67
72.69
37.22
34.76
74.57
75.30

69.88
73.45
42.50
44.18
77.23
78.07

69.77
73.07
39.69
38.91
75.88
76.66

Table 3: Result on the test dataset for different Trans-
former models.

(Liu et al., 2019) and XLM-RoBERTa (Conneau
et al., 2019) models. We add a linear layer to the
hidden layer representation obtained from the trans-
former model for the token classiﬁcation task. We
train each model for 20 epochs with a sequence
length of 128. We use an initial learning rate of 1e-
5 for the base models and 5e-6 for the large models.
We use 32 samples for each mini-batch. All models
are trained using AdamW optimizer (Loshchilov
and Hutter, 2017) on a single Nvidia Tesla V100
GPU.

5.2 Results

We report the span micro-F1 score computed by
the seqeval 9 library. We report results for the six
different transformer models on Table 3. XLM
models outperform both BERT and RoBERTa mod-
els, despite being multilingual. XLM-RoBERTa-
large model achieves the best average F1 score
of 76.66%. Class-speciﬁc precision, recall, and
F1-score are displayed in Table 4. The model per-
forms relatively poorly on the Organization class
compared to others.

5 Evaluation

5.1 Experimental Settings

6 System Demonstration

6.1

Installation

We ﬁnetune transformer models available in Hug-
gingface’s transformers library (Wolf et al., 2019)
for sequence tagging. We train both base and large
variants of BERT (Devlin et al., 2018), RoBERTa

CyNER is available as a python framework in
Github. Users can run the following command
for installation:

9https://pypi.org/project/seqeval/

import cyner

text=’Proofpoint report mentions that the German-language messages were turned off
once the UK messages were established, indicating a conscious effort to spread
FluBot 446833e3f8b04d4c3c2d2288e456328266524e396adbfeba3769d00727481e80 in
Android phones.’

model = cyner.CyNER(’xlm-roberta-large’, use_heuristic=False, flair_model=None)

entities = model.get_entities(text)
for e in entities:

print(e)

#output
Mention: Proofpoint, Class: Organization, Start: 0, End: 10, Confidence: 0.82
Mention: FluBot, Class: Malware, Start: 156, End: 162, Confidence: 0.92
Mention: 446833e3f8b04d4c3c2d2288e456328266524e396adbfeba3769d00727481e80, Class:

Indicator, Start: 163, End: 227, Confidence: 0.90

Mention: Android, Class: System, Start: 231, End: 238, Confidence: 1.00

Listing 1: Prediction with only pretrained transformer model (Mention: entity extracted from the text, Class:
entity label, Start: starting character position in the given text, End: ending character position in the given text,
Conﬁdence: conﬁdence/probability of detection)

model = cyner.CyNER(transformer_model=’xlm-roberta-large’, use_heuristic=True,

flair_model=None, priority=’HTFS’)

entities = model.get_entities(text)
for e in entities:

print(e)

#output
Mention: 446833e3f8b04d4c3c2d2288e456328266524e396adbfeba3769d00727481e80, Class:

SHA256, Start: 163, End: 227, Confidence: 1.00

Mention: Proofpoint, Class: Organization, Start: 0, End: 10, Confidence: 0.82
Mention: FluBot, Class: Malware, Start: 156, End: 162, Confidence: 0.92
Mention: Android, Class: System, Start: 231, End: 238, Confidence: 1.00

Listing 2: Prediction with a pretrained transformer model and heuristic for indicators

model = cyner.CyNER(transformer_model=’xlm-roberta-large’, use_heuristic=True,

flair_model=’ner’, priority=’HTFS’)

entities = model.get_entities(text)
for e in entities:

print(e)

#output
Mention: 446833e3f8b04d4c3c2d2288e456328266524e396adbfeba3769d00727481e80, Class:

SHA256, Start: 163, End: 227, Confidence: 1.00

Mention: Proofpoint, Class: Organization, Start: 0, End: 10, Confidence: 0.82
Mention: FluBot, Class: Malware, Start: 156, End: 162, Confidence: 0.92
Mention: Android, Class: System, Start: 231, End: 238, Confidence: 1.00
Mention: German-language, Class: MISC, Start: 36, End: 51, Confidence: 1.00
Mention: UK, Class: LOC, Start: 86, End: 88, Confidence: 1.00

Listing 3: Prediction using pretrained transformer model, heuristic for indicators and Flair NER model

Class

Precision Recall F1-score

Malware
Indicator
System
Organization
Vulnerability

79.82
78.34
70.36
70.64
100.0

75.11
86.62
79.93
60.16
80.0

77.39
82.27
74.84
64.98
88.89

Table 4: Result for different classes in test set for XLM-
RoBERTa-large model.

pip install git+https://github.com/

aiforsec/CyNER.git

6.2 Entity extraction with a pretrained model

CyNER allows users to use different combinations
of models for extracting entities. In Listing 1 we
show a model initialized to use only pretrained
XLM-RoBERTa-large model. The model can suc-
cessfully detect the four cybersecurity-related en-
tities in the text - ’Proofpoint’ as Organization,
’FluBot’ as malware, ’Android’ as System, and
the hash as Indicator.

In listing 2, we combine prediction from the
same transformer model with the heuristic-based
approach. We use priority ’HTFS,’ which means
prediction from the heuristic-based detection will
be prioritized. The only difference from the pre-
vious output is that the hash is now detected as
SHA256, a subcategory of the Indicator obtained
from regular expression matching. Since the output
from the transformer overlaps with the detection
from the heuristic and has a lower priority, it is
omitted from the merged prediction.

In listing 3, we add the NER model from Flair
on top of transformer and heuristic approaches.10
Note that we do not use the Spacy model by default,
so it is not used for this prediction. Using the Flair
NER model allows us to capture two more generic
entities - ’German-language’ as MISC (Miscella-
neous) and ’UK’ as LOC (Location).

6.3 Fine tuning Models

Users can ﬁne-tune transformer language models
on annotated NER datasets. The dataset needs to
be annotated in the CoNLL 2003 as shown below:

B-Organization

Proofpoint
wrote O
about O
the O
DroidJack B-Malware
RAT I-Malware

10This is the default parameter setting for prediction

side-loaded O
with
O
Pokemon B-System
GO
I-System
. O

cfg = {’checkpoint_dir’: ’.ckpt’,

’dataset’: ’dataset/mitre’,
’transformers_model’: ’xlm-

roberta-large’,
’lr’: 5e-6,
’epochs’: 20,
’max_seq_length’: 128}

model = cyner.TransformersNER(cfg)
model.train()

Listing 4: Finetuning xlm-roberta-large model

Users can conﬁgure different parameters, in-
cluding dataset path, pretrained transformer model,
learning rate, epochs, maximum sequence length,
as shown in Listing 4.

7 Conclusion

In this paper, we have presented a python library
for extracting cybersecurity named entities. We
have provided pretrained transformer-based NER
models trained on annotated threat reports. In ad-
dition, we have added a heuristic-based approach
for extracting different indicators and incorporated
popular NLP libraries that will allow the user to
extract more generic entity types. We have added
ﬂexible options to enable the user to combine pre-
dictions from multiple models with a deﬁned prior-
ity order and support ﬁnetune language models on
annotated NER corpus. We believe this library will
beneﬁt cybersecurity researchers and practitioners
to analyze cybersecurity threat reports and gather
meaningful insights.

References

Alan Akbik, Tanja Bergmann, Duncan Blythe, Kashif
Rasul, Stefan Schweter, and Roland Vollgraf. 2019.
Flair: An easy-to-use framework for state-of-the-art
nlp. In Proceedings of the 2019 Conference of the
North American Chapter of the Association for Com-
putational Linguistics (Demonstrations), pages 54–
59.

Sean Barnum. 2012. Standardizing cyber threat intelli-
gence information with the structured threat informa-
tion expression (stix). Mitre Corporation, 11:1–22.

Ryan Christian, Sharmishtha Dutta, Youngja Park, and
Nidhi Rastogi. 2021. An ontology-driven knowl-
In Proceedings
edge graph for android malware.
of the 2021 ACM SIGSAC Conference on Computer
and Communications Security, pages 2435–2437.

Pontus Stenetorp, Sampo Pyysalo, Goran Topi´c,
Tomoko Ohta, Sophia Ananiadou, and Jun’ichi Tsu-
jii. 2012. Brat: a web-based tool for nlp-assisted
In Proceedings of the Demonstra-
text annotation.
tions at the 13th Conference of the European Chap-
ter of the Association for Computational Linguistics,
pages 102–107.

Morton Swimmer. 2008. Towards an ontology of mal-

ware classes. Online] January, 27.

Asahi Ushio and Jose Camacho-Collados. 2021. T-
ner: An all-round python library for transformer-
based named entity recognition. In Proceedings of
the 16th Conference of the European Chapter of the
Association for Computational Linguistics: System
Demonstrations, pages 53–62.

Thomas Wolf, Lysandre Debut, Victor Sanh, Julien
Chaumond, Clement Delangue, Anthony Moi, Pier-
ric Cistac, Tim Rault, Rémi Louf, Morgan Fun-
towicz, et al. 2019. Huggingface’s transformers:
State-of-the-art natural language processing. arXiv
preprint arXiv:1910.03771.

Bo Xie, Guowei Shen, Chun Guo, and Yunhe Cui. 2021.
The named entity recognition of chinese cybersecu-
rity using an active learning strategy. Wireless Com-
munications and Mobile Computing, 2021.

Feng Yi, Bo Jiang, Lu Wang, and Jianjun Wu. 2020.
Cybersecurity named entity recognition using multi-
IEEE Access, 8:63214–
modal ensemble learning.
63224.

Alexis Conneau, Kartikay Khandelwal, Naman Goyal,
Vishrav Chaudhary, Guillaume Wenzek, Francisco
Guzmán, Edouard Grave, Myle Ott, Luke Zettle-
moyer, and Veselin Stoyanov. 2019. Unsupervised
cross-lingual representation learning at scale. arXiv
preprint arXiv:1911.02116.

Julie Connolly, Mark Davidson, and Charles Schmidt.
2014. The trusted automated exchange of indicator
information (taxii). The MITRE Corporation, pages
1–20.

Isuf Deliu, Carl Leichter, and Katrin Franke. 2017.
Extracting cyber threat intelligence from hacker fo-
rums: Support vector machines versus convolutional
neural networks. In 2017 IEEE International Con-
ference on Big Data (Big Data), pages 3648–3656.
IEEE.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2018. Bert: Pre-training of deep
bidirectional transformers for language understand-
ing. arXiv preprint arXiv:1810.04805.

Eduard Hovy, Mitch Marcus, Martha Palmer, Lance
Ramshaw, and Ralph Weischedel. 2006. Ontonotes:
the 90% solution. In Proceedings of the human lan-
guage technology conference of the NAACL, Com-
panion Volume: Short Papers, pages 57–60.

Arnav Joshi, Ravendar Lal, Tim Finin, and Anupam
Joshi. 2013. Extracting cybersecurity related linked
data from text. In 2013 IEEE Seventh International
Conference on Semantic Computing, pages 252–259.
IEEE.

Gyeongmin Kim, Chanhee Lee, Jaechoon Jo, and
Heuiseok Lim. 2020.
Automatic extraction of
named entities of cyber threats using a deep bi-lstm-
crf network. International journal of machine learn-
ing and cybernetics, 11(10):2341–2355.

Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-
dar Joshi, Danqi Chen, Omer Levy, Mike Lewis,
Luke Zettlemoyer, and Veselin Stoyanov. 2019.
Roberta: A robustly optimized bert pretraining ap-
proach. arXiv preprint arXiv:1907.11692.

Ilya Loshchilov and Frank Hutter. 2017. Decou-
pled weight decay regularization. arXiv preprint
arXiv:1711.05101.

Aritran Piplai, Sudip Mittal, Anupam Joshi, Tim Finin,
James Holt, and Richard Zak. 2020. Creating cyber-
security knowledge graphs from malware after ac-
tion reports. IEEE Access, 8:211691–211703.

Nidhi Rastogi, Sharmishtha Dutta, Mohammed J Zaki,
Alex Gittens, and Charu Aggarwal. 2020. Mal-
ont: An ontology for malware threat intelligence.
In SIGKDD’20: International Workshop on Deploy-
able Machine Learning for Security Defense, pages
28–44. Springer.

