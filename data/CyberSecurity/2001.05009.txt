International Journal of Information Security (IJIS) manuscript No.
(will be inserted by the editor)

A Content-Based Deep Intrusion Detection System

Mahdi Soltani1 · Mahdi Jafari Siavoshani1 · Amir Hossein Jahangir1

1
2
0
2

g
u
A
6
1

]
I

N
.
s
c
[

2
v
9
0
0
5
0
.
1
0
0
2
:
v
i
X
r
a

Received: date / Accepted: date

Abstract The growing number of Internet users and
the prevalence of web applications make it necessary
to deal with very complex software and applications
in the network. This results in an increasing number
of new vulnerabilities in the systems, and leading to
an increase in cyber threats and, in particular, zero-
day attacks. The cost of generating appropriate signa-
tures for these attacks is a potential motive for using
machine learning-based methodologies. Although there
are many studies on using learning-based methods for
attack detection, they generally use extracted features
and overlook raw contents. This approach can lessen
the performance of detection systems against content-
based attacks like SQL injection, Cross-site Scripting
(XSS), and various viruses.

In this work, we propose a framework, called deep
intrusion detection (DID) system, that uses the pure
content of traﬃc ﬂows in addition to traﬃc metadata
in the learning and detection phases of a passive DNN
IDS. To this end, we deploy and evaluate an oﬄine IDS
following the framework using LSTM as a deep learning
technique. Due to the inherent nature of deep learning,
it can process high dimensional data content and, ac-
cordingly, discover the sophisticated relations between
the auto extracted features of the traﬃc. To evaluate
the proposed DID system, we use the CIC-IDS2017
and CSE-CIC-IDS2018 datasets. The evaluation met-

Mahdi Soltani
E-mail: mahdi@ce.sharif.edu

Mahdi Jafari Siavoshani
E-mail: mjafari@sharif.edu

(cid:0)Amir Hossein Jahangir
E-mail: jahangir@sharif.edu

1Department of Computer Engineering, Sharif Univer-
sity of Technology, Azadi Ave. Tehran 1458889694, Iran

rics, such as precision and recall, reach 0.992 and 0.998
on CIC-IDS2017, and 0.933 and 0.923 on CSE-CIC-
IDS2018 respectively, which show the high performance
of the proposed DID method.

Keywords Deep Learning · Intrusion Detection ·
Content-Based Attacks · Recurrent Neural Networks ·
Long Short-Term Memory · Machine Learning ·
Misuse · Malware Detection · DoS Attacks

1 Introduction

We live in the cyber era in which network-based tech-
nologies have become omnipresent. Meanwhile, threats
and attacks are rapidly growing in the cyberspace.
Nowadays, mainly signature-based intrusion detection
systems (IDSs) are used to detect these malicious
traﬃc. However, since new vulnerabilities and, conse-
quently, zero-day attacks appear each day, the cost of
generating accurate signatures with a low false-positive
rate is growing.

The traditional approach to intrusion detection sys-
tems is based on detecting some form of a signature. A
signature is extracted from the known attacks by em-
ploying security experts. A signature must completely
cover diﬀerent variants of the attack for which it has
been extracted. Also, benign traﬃc and other types of
attacks should not be falsely confused with it. Hence,
extracting an accurate signature is a complicated and
time-consuming process. By the increasing growth of
the Internet’s applications and users, more vulnerabil-
ities are expected to appear, which results in emerg-
ing more new attacks. Therefore, the signature extrac-
tion process becomes a more challenging problem in the
coming years.

 
 
 
 
 
 
2

Mahdi Soltani1 et al.

The learning-based approach is an alternative solu-
tion to the signature-based intrusion detection systems.
In addition to resolving the signature extraction prob-
lem, some learning approaches can also detect zero-day
attacks by determining abnormal traﬃc.

There are several research studies on the use of ma-
chine learning methods to detect intrusions in computer
networks. Among them, we can mention pioneers like
Bayesian networks [25], support vector machine (SVM)
[21], decision trees [49], and the new deep learning
techniques (e.g., see [6] and [39]). These studies gen-
erally focus on some speciﬁc features of traﬃc as in-
puts, and they usually have a low potential to detect
content-based attacks. However, it is well known that
the content-based attacks, like SQL injection, malicious
software, and viruses are the most destructive attacks
against assets that are accessible on the Internet.

According to our study, only a few of previous
learning-based works on IDSs have considered content-
based attacks. These works, like [46], [45], [38], and [15],
use n-gram methods for extracting the frequencies of
characters in deterministic windows. However, as shown
in [42], n-gram methods are vulnerable to mimicry at-
tacks. In these kinds of attacks, some unused parts of
packets like IP options or PADDING parts in exploits
can be used for adjusting the frequencies of n-grams.

A severe obstacle for analyzing the contents of net-
work traﬃc is the large dimension of payloads. Nowa-
days, this challenge can be handled eﬀectively by em-
ploying Deep Learning techniques [10, 34]. In this pa-
per, a deep learning-based intrusion detection method,
called deep intrusion detection (DID) system is pro-
posed. It uses the pure content of traﬃc (i.e., packet
payload) as the input data. In the pre-processing phase,
the content of each ﬂow is converted to a numerical ma-
trix. The learning and detection phases use this matrix
for separating normal traﬃc from the malicious one.

In this work, our primary contribution is to use all
content bytes of traﬃc during the learning and detec-
tion phases. This goal is achieved by employing deep
learning methods (in particular, in this work, we lever-
age using the LSTM neural network). Besides, we pro-
pose an appropriate pre-processing phase for feeding
the traﬃc ﬂows into the learning models. There are
many studies around using deep learning models in IDS
scope, as are reviewed in this paper. Still the main nov-
elty of this paper is the use of the enriched raw content
bytes of ﬂows (not pre-extracted features) as the input,
and the ability to distinguish the content-based attacks.
Finally, we evaluate our proposed scheme on the CIC-
IDS2017 dataset [40]. This dataset has an appropriate
variety of full captured normal and attacks traﬃc; in

particular, it contains some content-based attacks like
Heartbleed.

The remainder of the paper is organized as follows.
In Section 2, we summarize the most relevant related
works. Section 3 presents the details of the proposed
DID system. This system also includes a pre-processing
phase for preparing contents of traﬃc ﬂows to be fed to
a deep learning model (i.e., an LSTM neural network).
In Section 4, the conducted experiments and results
obtained are discussed. Finally, Section 5 concludes the
paper and explains the possible future directions.

2 Related Works

In the following, we will review some of the learning-
based approaches used in intrusion detection systems.

2.1 Traditional Machine Learning Approach

In the literature, various learning-based techniques such
as support vector machine (SVM), naive Bayes, decision
tree, random forest, and neural networks have been pro-
posed for intrusion detection systems.

SVM is one of the most popular classiﬁcation algo-
rithms used so far. It has been used in research studies
like [21], [13], [26] and [44]. In this algorithm, the clas-
siﬁcation process is performed by detecting a set of hy-
perplanes, as separators, in a high-dimensional space.
The high time-complexity of the learning phase and
the diﬃculty of ﬁnding a suitable kernel function are
the most important challenges of this method. Learn-
ing time complexity has a superlinear relation with the
number of input instances. Besides, there is a quadratic
relation between the size of the kernel matrix and the
number of instances.

Bayesian classiﬁers [22] use Bayes’ rule for predict-
ing the membership of input data to classes. They
are built by using expert knowledge or eﬃcient algo-
rithms that perform inference. In Naive Bayesian classi-
ﬁers, features are assumed to be conditionally indepen-
dent. Though this assumption is not satisﬁed in prac-
tice, however, experiments have proved its good perfor-
mance. Many papers have used this technique, e.g., see
[32] and [25].

Authors in [32] have suggested generating multi-
Bayesian network models in which each one separately
generates an anomaly score for the input traﬃc. In [25],
an IDS based on Bayesian network classiﬁers is pro-
posed. In this research, association rules are used for
the detection of normal/intrusion traﬃc. New traﬃc
will get a low probability level for each of the normal
or attack groups. So, these suspicious connections will

A Content-Based Deep Intrusion Detection System

3

also be labeled as an attack. In the second phase, these
attacks are classiﬁed into four known or unknown at-
tack categories by Bayesian rules.

One of the main data mining techniques used in
intrusion detection systems is associated with decision
trees. In [33], the misuse detection engine of Snort [3] is
replaced by decision trees. Firstly, the existing rules are
provided to a clustering algorithm to reduce the com-
parison needed to determine rules that are triggered
by speciﬁc input data. These clusters are based on the
values of important features. When the clustering al-
gorithm reaches a rule set for the given feature of the
input data, the decision tree determines the triggered
rules inside that cluster.

Random forests (RF) [12] consist of a collection of
decision trees. In addition to good performance in com-
parison with SVM and neural networks (NNs), this ap-
proach can run eﬃciently on large datasets with many
features. RF is robust against overﬁtting and can han-
dle unbalanced data. Works like [49] and [17] use this
technique.

Artiﬁcial neural networks (ANNs) were the most
popular models used until the 1990s when SVM was
invented. One of the beneﬁts of SVM against ANN is
its lower learning time besides having a less local min-
imum problem. However, with the emergence of new
ANN variants like recurrent and convolutional NNs, the
ANNs have begun to be used again.

In [35], a detector for ﬁnding attacks on Telnet is
proposed. This system extracts 89 pre-deﬁned keywords
from the Telnet sessions. These keywords represent the
suspicious actions or well-known attacks in Telnet. Af-
ter extracting the distribution of these keywords, their
statistics are given to a binary neural network. Finally,
the instances recognized as attacks are given to a sec-
ondary NN, which determines the class name of the
attack. They have ﬁnally obtained detection rates up
to 80%.

ANNs can also be used for the detection of DoS
attacks like SYNFLOOD, UDPSTORM, and SMURF
(for example, see [11]). For this purpose, authors of
[11] use a time window, which is then labeled as nor-
mal or attack traﬃc. Since the input size of an ANN
is ﬁxed, they use a pre-processing phase with the aid
of an anomaly-based ANN, namely, a self-organization
map (SOM). SOM can cluster the input data into a
ﬁxed number of clusters. Hence, independently from
the number of packets in the time window, a ﬁxed num-
ber of inputs is provided for the ANN by this cluster-
ing technique. The model is evaluated by DARPA 1999
dataset [36] and reaches 100% detection of normal traf-
ﬁc and 76% false-positive rate for attacks.

In 2017, feature reduction techniques had been pro-
posed by using ANNs [7]. The authors use a combi-
nation of information gain and correlation for feature
selection. Then, after normalizing the numbers of each
class in the KDD99 dataset [2], their model achieves
the average recall value of 91.72%.

2.2 Deep Learning Approach

The recurrent neural network (RNN) is a class of ANNs
in which nodes have some amount of memory. As a re-
sult, in addition to the current input, the previous in-
puts can also inﬂuence the current output. These net-
works are suitable for sequential inputs that possess
a dependency with each other. Long short-term mem-
ory (LSTM) network is a class of RNNs [23]. LSTM
has been proposed to solve the vanishing and exploding
gradient by introducing some gates to the neural net-
work structure. Therefore, LSTM can eﬀectively learn
the relations between items that are far away from each
other in a sequence. Computer network ﬂows, consisting
of packets, form a sequence of data; hence, RNN and
LSTM are natural candidates for analyzing of computer
network traﬃcs.

Authors of [6] have employed gated recurrent unit
(GRU), which is a variant of LSTM. They have slightly
modiﬁed GRU and used SVM as a classiﬁer instead of
the softmax function. The goal of this modiﬁcation is
to increase the computational eﬃciency of the model.
They have evaluated the proposed model with 2013 net-
work traﬃc data obtained by the honeypot systems at
Kyoto University. The inputs of this model are 24 sta-
tistical features of the dataset. For improving perfor-
mance and reducing the computation cost of the mode,
the continuous features are converted to bins and, ﬁ-
nally, are represented in a one-hot format. Their model
has an average accuracy of 80.53%.

In another work, Kim et al. [30] have applied LSTM
architecture in IDS and use the KDD99 dataset for eval-
uating their proposed model. Their input vector con-
tains 41 normalized features, and the output vector is
composed of 4 attack classes and one non-attack class.
In their evaluation, the average values of recall and fall-
out are 98.79% and 10%, respectively.

In [43], the authors use deep learning for detect-
ing anomalies in a software-deﬁned network (SDN) en-
vironment. They use six basic features of the NSL-
KDD dataset (duration, protocol type, SRC bytes, DST
bytes, count, and SRV count) to detect anomaly ﬂows.
Finally, the attack detection accuracy is reported as
75.75%.

Also, in some other research studies like [8], [24],
and [31], the deep learning approach is employed for

4

Mahdi Soltani1 et al.

the reduction of input dimensions by selecting among
pre-extracted features.

The authors of [29] propose a scalable hybrid IDS
with two-stages: the ﬁrst stage is the anomaly detector
module implemented by Spark ML traditional machine
learning models; the next stage is the misuse detector,
which is based on the Conv-LSTM network. Their eval-
uation is based on ISCX IDS 2012 dataset with 10-fold
cross-validation tests. The results show a 97.29% detec-
tion rate of attacks and a 0.71% of false alarm rate.

Although deep learning methods have been pro-
posed for solving intrusion detection problems so far, to
the best of our knowledge, they use extracted features
of inputs, as in traditional approaches. These features
mostly represent general aspects of traﬃc ﬂow, like
source/destination port/IP address, duration time,
start time, and packet/byte number of sent or re-
ceived packets. These features are generally crucial to
the detection of some kinds of attacks like DDoS and
portscan. However, many important attacks, like SQL
injections, worms, viruses, and XSS, which are content-
based attacks, have general features very similar to be-
nign traﬃcs. In the following, some traditional research
studies which have paid attention to these kinds of at-
tacks are reviewed.

2.3 Content-Based Approach

Generally, some restricting extracted features are used
in machine learning-based intrusion detectors. These
general features are rarely based on contents trans-
mitted through the established ﬂow. Consequently,
content-based attacks have a high impact on the se-
curity and privacy of network applications and services
in such systems.

In the following, we review some related works on
content inspection for intrusion detection. Most of the
payload-based detectors extract statistical features by
using the n-gram technique. PYLE [46], Anagram [45],
and McPAD [38] are among the most well-known works.
PYLE uses 1-gram method and extracts the frequency
of values in each byte of the packet. Anagram uses 5-
gram and stores the extracted 5-grams in Bloom ﬁlters.
There are two kinds of Bloom ﬁlters in this work: one
designed for attacks and the other for benign n-grams.
Finally, these two Bloom ﬁlters examine the input traf-
ﬁc.

It is evident that in n-gram analysis, the dimension
of feature space grows dramatically. Hence, limited by
the curse of dimensionality problem, in practice, this
approach can be used at most for n = 2, which yields
65536 features. To mitigate this problem, McPAD [38]

measures the frequency of the occurrences of pairs of
symbols (bytes), which are k bytes apart from each
other in the payload. In this way, some information in
n-grams with n > 2 can be extracted by such pairs of
bytes. Moreover, this method will only generate 2562
features regardless of the value of k.

In [42], the authors show that blending attacks can
defeat n-gram methods. These attacks ﬁll unused parts
of network traﬃcs with new characters in proportion
to the target frequency and, consequently, convert the
statistics of characters to become similar to benign traf-
ﬁcs. Their evaluation shows that to launch an attack
against a 5-gram detector, at least two packets (i.e.,
about 2000 bytes) are needed. Besides, they propose
fragmentation overlapping for solving larger values of
n. Diﬀerent operating systems (OSs) have diﬀerent be-
haviors for extracting bytes in overlapping situations.
They may prefer the ﬁrst or last arrived overlapped
bytes. The other bytes will be ignored by the OS. So
these ignored bytes can be used in higher values of n
for deluding the n-gram detectors.

In another research [41], after encoding the content
by Base64, the integer values are extracted. Finally, the
frequencies of these integer values are enumerated. Even
though authors do not mention an n-grams method, but
in fact, they use a 1-gram approach.

Another related work is [9]. This paper focuses on
false data injection attacks (FDIA) on phasor measure-
ment units (PMU), which are utilities for monitoring
power systems. In this paper, CNN is compared with
RNN, LSTM, and traditional classiﬁers such as SVM.
PMU packet data consists of d diﬀerent instances of
data items, including n univariate voltage and current
phasor data stream. Finally, this work proposes a CNN
model with 2 CNN layers, a dropout probability of 0.5,
and a fully connected layer with 512 neurons, which
achieves a 98.67% accuracy.

3 METHODOLOGY

The high dimensionality of traﬃc content is one of
the biggest challenges in the detection of content-based
attacks. Although this challenge can be addressed by
employing deep learning methodology, according to
our survey, all the previous proposed studies have fo-
cused on pre-extracted features which are vulnerable to
content-based attacks.

In this work, we propose a deep learning-based IDS
method to extend the detection scope by covering the
content-based attacks as well. Since traﬃc contents
can have long-time dependencies, input feature space
should have a high dimension. As deep learning meth-
ods are designed for such large data spaces, we propose

A Content-Based Deep Intrusion Detection System

5

using deep learning techniques directly on the raw bytes
of contents instead of applying it to the extracted traﬃc
features. The proposed method is called deep intrusion
detection (DID). This method can be applied to both
passive and on-line traﬃc. In this research, the passive
mode is followed, as illustrated in Figure 1.

Fig. 1 General illustration of DID system in the passive
mode.

Since traﬃc ﬂows consist of sequences of data, al-
gorithms like RNN and LSTM that are developed for
sequential data are among the best candidates for the
DID approach. In the following, we describe the pro-
posed DID approach and explain how it uses deep learn-
ing methods to detect content-based attacks. In the fol-
lowing, we have two main subsections. The ﬁrst one
provides a complete description of the pre-processing
module, and the second highlights the deep learning
module of DID. In particular, in this work, we will em-
ploy LSTM for the deep learning module of DID. How-
ever, it should be noted that DID is not limited to use
LSTM, rather, other algorithms can also be employed
in the deep learning module.

3.1 Pre-processing Phase in Deep Intrusion Detection

Traditional learning methods highly depend on the pre-
extracted features. As a result, the accuracy of such
algorithms depends heavily on the selection of input
features. Hence, these features should be found and ex-
tracted by experts, which makes the process expensive,
time-consuming, and prone to error. Moreover, due to
the increase of variant of known attacks and the emer-
gence of new ones, extracting some static and deﬁnite
features cannot provide adequate information for intru-
sion detection tasks.

In contrast, deep learning algorithms can extract
complicated features from the raw data automatically.
Consequently, to address the above issues, DID uses
deep learning techniques to learn various cyber-attacks,
including content-based attacks. It is well known that
deep learning algorithms can detect sophisticated rela-
tions in high dimensional spaces. Hence, they are good
candidates for the detection of content-based attacks.

Although some content-based intrusion detection
systems like [46], [45], and [38] focus on packet-level
granularity, in real-world, some packets can belong to
both benign and attack ﬂows (e.g., SYN or FIN pack-
ets, or HTTP GET requests in DDoS attacks). More-
over, some attacks are distributed among more than
one packet. Therefore, the concept of malicious traﬃc
resides in the ﬂow contents. As a result, we assume that
the input to the DID method is based on ﬂows instead
of packets.

3.1.1 Basic Normalized Matrix

In this work, we propose an oﬄine version of DID,
where each ﬂow is considered as an input sequence to an
LSTM neural network. Each packet represents a data
point in the input sequence. Since the maximum Ether-
net frame size is around 1514 bytes, so we consider 1514
as the dimension for each packet. Hence, the input is
assumed to be a sequence of 1514-dimensional points.
Additionally, the size of input sequences depends on
the number of packets in the traﬃc ﬂows. In the oﬄine
DID, we assume some reasonable maximum value for
the number of packets (which we will later determine
this parameter by inspecting the dataset). Finally, since
each byte is in the range of 0 to 255, in order to improve
the deep network performance and make the parame-
ters on the same scale, we normalize each byte value to
a number between 0 and 1, by dividing it to 255.

According to the pre-processing phase explained
above, we have a normalized matrix per each ﬂow (as
depicted in Figure 2), where rows describe diﬀerent
packets in the ﬂow, and the ith column contains the
normalized value of the ith bytes of packets. Moreover,
we add a column to the matrix for storing inter-arrival
times of packet ﬂows to detect attacks such as HTTP
ﬂooding, which sends some benign requests continu-
ously over the established connection. These normalized
matrices can be the input of the deep learning module
of DID (we will later enrich these matrices).

Considering a large number of parameters in deep
learning algorithms, and a limited number of ﬂows that
are used in the training phase, there is a reasonable
chance of overﬁtting if the datasets are not used with
enough care. As an example, IP addresses can be a
misleading factor. This misleading eﬀect exists in most
available public datasets like CIC-IDS2017 [40] and
KDD99 [2]. In [37], authors have shown that many pa-
rameters of the DARPA 99 [36] traﬃc, like TTL (Time
To Live), ToS (Type of Service), and the IP addresses,
can cause overﬁtting. For example, TTLs of the attack
traﬃcs are mostly 126 and 253, but benign traﬃc has
nine restricted values, which are diﬀerent from the at-

Pcap FileFlow SplitterEnriched Normaized Matrix per FlowDeep Learning ModelLabeledFlows6

Mahdi Soltani1 et al.

tacks can be detected by adding time intervals between
ﬂows. Since in the real world, the normal and attack
ﬂows are interleaved, the computation of the time in-
terval between ﬂows should be based on the original
ﬂows’ arrival times. The other approach is based on
splitting the ﬂows into benign traﬃc and attack, and
then extracting the time interval in each subgroup. This
approach can increase the detection error ratio when
there exists normal traﬃc between attacks.

To address the intra-ﬂow attacks, we use four more
extensive intra-ﬂows features as follows: aggregative
source or destination address repetition in a ﬁxed-size
bucket of packets or in a time window. Attacks like
DDoS use multiple diﬀerent IP addresses to send re-
quests to the victim server, called Type I attacks. De-
tection of this kind of attack can be done by aggregat-
ing ﬂows that have the same destination IP address. On
the other hand, in some attacks like port scanning, a
single client IP address tries to recognize diﬀerent ac-
tive services (ports) on a speciﬁc victim IP address or a
speciﬁc service (port), which is activated on a network
range. The mentioned scenarios have the same source
address and destination port or same source and desti-
nation address, respectively. For simpliﬁcation, we call
these kinds of attacks as Type II.

Another important aspect of detecting intra-ﬂow
attacks is network bandwidth. For networks with low
bandwidth, a ﬁxed size window (or bucket) is used for
aggregation. As the time interval between ﬂows can ex-
ceed the time threshold, time windows cannot detect
the attacks. On the other hand, the ﬁxed-size window
cannot detect attacks in high-speed traﬃcs because the
window will be ﬁlled rapidly, and the new information
will overwrite the older ones. A time window can han-
dle this situation as well. In real networks, bandwidth
has no ﬁxed value, and according to the conditions like
days vs. nights, it can have low or high bandwidth. So
we use a combination of these two kinds of windows for
the detection of intra-ﬂow attacks.

The four aforementioned intra-ﬂow features are ex-
tracted per each ﬂow. Detection of Type I attacks de-
pends on the aggregation of ﬂows based on their desti-
nation IP addresses. Hence, as a new ﬂow arrives, it is
compared with ﬂows that are observed in the ﬁxed-size
and ﬁxed-time windows. The number of ﬂows having
the same IP address as the new one in both windows
is used as features. Similarly, aggregation based on the
source IP address is done for the detection of Type II
attacks. In this case, the source address of each ﬂow
is compared with the source addresses of ﬂows in the
ﬁxed-size and ﬁxed-time windows.

Finally, the ﬁve new intra-ﬂow features will be
added to the ﬁrst row of the basic normalized matrix

Fig. 2 The output of the pre-processing phase in the form of
a normalized matrix fed into the deep learning module. Each
cell, Cij , represents the content of the jth byte of the ith
packet. The ﬁrst column is diﬀerent from other columns and
represents the time interval between ith packet and (i − 1)th
packet.

tack ones. Besides, source IP addresses of attacks are
diﬀerent from benign traﬃcs and can simply be used for
discrimination. The KDD99 dataset also has inherited
these vulnerabilities. Since the attack traﬃc constitutes
a small part of the dataset, there are so many IP ad-
dresses that are purely normal, and the algorithm can
assign a substantial weight for IP addresses to attain
higher accuracy. However, we know that this is not a
valid assumption in the real-world.

Considering the above issues, in our pre-processing
that
phase, we eliminate some bytes of packets
like CHECKSUM and IP ad-
belong to ﬁelds
dresses. Speciﬁcally, the total data-link header, the
Source/Destination IP addresses and the checksum
from the network header, and the checksum of the
transport layer are the removed items in the pre-
processing phase. It should be noted that this elimina-
tion can cause some performance reduction in the detec-
tion phase. For example, ignoring the client’s IP address
in a monolithic environment, like a university, can avoid
overﬁtting, but in heterogeneous networks with diﬀer-
ent types of clients, some valuable information can be
missed. Besides, server IP addresses can be beneﬁcial
in server-side IDSes. So, in the real world, this elimi-
nation should be applied according to the conditions of
the deployment environment.

3.1.2 Enriched Normalized Matrix

The pre-processing phase can be completed by en-
riching the normalized matrices. The basic pre-
processing matrices are adequate for detecting ﬂow-
based attacks. However, other kinds of attacks can
be recognized by considering some intra-ﬂows features.
These features are also added to the ﬁrst row of the ba-
sic pre-processing matrix to make it richer. For exam-
ple, ﬂooding attacks can be generated by making many
legitimate connections rapidly, and these kinds of at-

3rdbytepacket s timeinterval1stbyte2ndbyte2ndpacket1stpacket3rdpacket...kthpacket...nthbyteA Content-Based Deep Intrusion Detection System

7

(see Figure 3). This enriched matrix will be used as an
input of the deep learning module of DID. In the fol-
lowing, some candidates for DID deep learning module
are discussed, and the LSTM model is implemented.

Fig. 3 The structure of enriched normalized matrices used
as the input to the deep learning module of DID. The main
diﬀerence with Figure 2 is the ﬁrst row of the matrix, added
as the features that represent the intra-ﬂow context.

3.2 Deep Learning Module of Deep Intrusion Detection

As mentioned earlier, in DID, we prepare a rich nor-
malized matrix as the input for a deep learning al-
gorithm. This matrix has the potential for extracting
content-based and some intra-ﬂow attacks. In the fol-
lowing, some candidates for deep learning modules are
discussed. The main important point, which is common
among the proposed methods, is the sequential nature
of these algorithms. In fact, since packets, ﬂows, and
network traﬃcs are all, in general, sequential data, the
chosen algorithms should match or beneﬁt from this
feature.

3.2.1 Recurrent Neural Networks

Recurrent Neural Network (RNN) is suitable for learn-
ing patterns in data sequences and time series, such as
processing natural languages and genetic data [16]. This
feature makes RNN an extremely useful tool for ana-
lyzing computer network traﬃc. The diﬀerence between
recurrent neural networks and feed-forward neural net-
works is that besides the current input, some informa-
tion from previous inputs is also processed. In RNN,
decision making related to an input instant at the mo-
ment t depends on the decision made at the moment
t − 1.

The mathematical deﬁnition of the forward mem-
ory transfer process in recursive neural networks is as
follows

ht = φ(W xt + U ht−1),

where ht is the state of the hidden layer of the recurring
neural network at the moment t. The value of ht is a

Fig. 4 The internal structure of an LSTM cell.

function of the input at the moment t (i.e., xt) which
is multiplied to hidden layer weights W, and the last
moment hidden layer feedback ht−1 which is multiplied
to its own weights U . The weight matrices apply the
relative importance of the input at the current moment
and the feedback input from the previous moment.

3.2.2 LSTM

LSTM is a special type of recurring neural network
which is capable of learning long-term dependencies.
These networks have proven to be very eﬀective in
many diﬀerent circumstances and are now widely used
in practice. An LSTM layer consists of some similar
units, called LSTM cell. Inside each cell, four neural
networks are linked to each other in a speciﬁc structure
(see Figure 4). This special structure enables an LSTM
network to learn simultaneously short and long-term
dependencies very well. For more details on the LSTM
the interested readers can refer to [20].

3.2.3 LSTM-Based Classiﬁer

Since, in practice, it has been observed that LSTM
based classiﬁers and their variants perform very well
on sequential data, we construct a deep learning model
with two LSTM layers as a proof of concept for our pro-
posed deep intrusion detection (DID) framework. The
hyper-parameters that are dedicated to this model are
based on the evaluations which are discussed later.

Figure 5 presents the details of the proposed model.
As shown in Figure 5, after extraction of sequential
features with LSTM layers (with 100 and 50 units,
respectively), some fully connected layers (with 2500,
1250, 512, 256, 64, and 16 neurons) are employed to
extract the more complicated features. Finally, a soft-
max layer is applied for binary classiﬁcation between
attack and benign traﬃcs. The activation functions of
all layers (except the last one) are ReLU, and in order
to avoid overﬁtting, some dropout layers with a 20%

…Packet’s Time Interval1stbyte2ndbyte3rdbyte…00……Added RowFlow’s time intervalFlow’s informationAggregate src in time windowAggregate dst in time windowAggregate src in fixed sized windowAggregate dst in fixed sized windowkthpacket3rdpacket2ndpacket1stpacketbytenth4thbytetx1-th+Xσ tfσ tanhXσ titgto1-tCtCththtanhX8

Mahdi Soltani1 et al.

drop rate are added among fully connected ones. Fi-
nally, the Adam algorithm is used for optimization in
the training phase, and the loss value is computed by
binary cross-entropy as the loss function.

Fig. 5 The proposed LSTM-based classiﬁer used in the our
DID framework.

4 EXPERIMENT

This section contains a real implementation of a DID
instance on the CIC-IDS2017 and CSE-CIC-IDS2018
datasets.
In the following, ﬁrst, the CIC-IDS2017
and CSE-CIC-IDS2018 datasets are brieﬂy introduced.
Then, after explaining the pre-processing phase, the
experimental results are presented and compared with
previous works. The reported results in this paper are
based on the 10-fold cross-validation tests.

4.1 Dataset

In this work, we use the CIC-IDS2017 and CSE-
CIC-IDS2018 datasets to benchmark the proposed
DID method. According to [19], there are few labeled
datasets with PCAP format traﬃc ﬁles; among them,
ISCX/CIC IDS is one of the best and up-to-date ones.
CIC IDS is the only option with adequate labeled
attacks/benign traﬃcs in PCAP format. Hence, we
made our evaluations based on this dataset solely. This
dataset is made of 50 GB network traﬃc captured in
ﬁve diﬀerent days, which is the most recent IDS evalua-
tion dataset and contains diﬀerent types of attacks. Es-
pecially, content-based attacks like Heartbleed are also
included in this dataset. Traﬃc capturing is done in a
simulated computer network with several servers and
clients. The developers of CIC-IDS2017 have analyzed
real traces of a client-server network and have tried to
create the same proﬁle for the clients. The details of the
ﬁve days of network traﬃc are shown in Table 1.

Table 1 Details of the CIC-IDS2017 dataset.

Day

Monday
Tuesday
Wednesday
Thursday
Friday

Attack type

Attack Size Benign Size

-
Brute Force
DoS / DDoS
Web Attack, Inﬁltration
Botnet ARES, Port Scan

0B
51MB
2GB
42MB
2GB

11GB
11GB
11GB
8.4GB
7.5 GB

The main advantages of this dataset compared to

the previous ones are:

– Implementing a complete network conﬁguration, in-
cluding Modem, Firewall, Switches, Routers, and a
variety of operating systems.

– Simulation of user proﬁles.
– The dataset is labeled. This is a requirement for
classiﬁcation purposes. Besides, it presents the full
captured traﬃc without anonymization techniques.
– Implementing all kinds of interactions in the net-

work.

– Using a wide range of protocols and network at-

tacks.

Although, as explained above, this dataset has many
advantages, it has its shortcomings too. One of the most
important deﬁciencies of this dataset is its limited va-
riety of protocols and attacks compared to real-world
traﬃcs. For example, IP addresses of attack traﬃc are
very limited, and hence, the other IP addresses can
be recognized as pure benign traﬃc. More precisely,
attacks on Tuesday and Wednesday are just focused
on one and two destination addresses, respectively. Be-
sides, DoS attacks on Friday are all from a speciﬁc client
IP address. On the other hand, real network conditions
like packet loss and diﬀerent TTLs are not presented in
this dataset. Moreover, so many kinds of applications
like social networking are not considered.

For reporting more reliable results we also evalu-
ated the DID over a newer version of the IDS evalua-
tion dataset which is called CSE-CIC-IDS2018 [4] and
is introduced by CIC (Canadian Institute for Cyberse-
curity) and CSE (Communications Security Establish-
ment) collaboratively. This dataset extends the variety
of packets, OSes, network topology, and servers. For
example, the attacking infrastructure includes 50 ma-
chines and the victim organization has 5 departments
includes 420 PCs and 30 servers. However, the attack
types and normal protocols remain the same as the
CIC-IDS2017 dataset. Due to its better implementation
topology, this dataset can provide a better challenge for
the DID framework.

Finally, as mentioned above, according to our sur-
vey, the CIC-IDS2017 and CSE-CIC-IDS2018 are the
best datasets available in the context of IDS. However,
we should be aware of their weaknesses and simplic-

LSTM LayersEnriched Normalized MatrixFully Connected LayersLabeled Flow50 units100 units100 * 200 Flow Matrix2500 neurons1250 neurons512 neurons256 neurons64  neurons16   neuronsBenignAttackFlatten LayerA Content-Based Deep Intrusion Detection System

9

ity. Obviously, in the real world, we need to implement
more sophisticated ML models with a higher number of
layers and nodes in each layer. Moreover, as discussed in
Section 3.1, we should be aware of the lack of diversity
of these datasets in the pre-processing phase.

of each ﬂow can yield almost a complete evaluation of
the nature of ﬂows in the ISCX/CIC 2017 dataset.

Finally, we have chosen the ﬁrst 200 bytes of the ﬁrst
100 packets of each ﬂow as an input matrix according
to the nature of ﬂows in this dataset.

4.2 Pre-processing

In this phase, we prepare the dataset as the input of
a neural network. First, we need to extract and split
the network ﬂows from the pcap ﬁles. To this end, we
read the large pcap ﬁles and make separate ﬁles per
each ﬂow. Flow separation is based on the source port,
destination port, source IP address, destination IP ad-
dress, and ﬂow start time. The end of ﬂow is reached
when the TCP FIN packet is read, or the maximum
ﬂow time (1,200,000 ms) is passed.

4.2.1 Constructing the Input Matrix

Network ﬂows are not suitable to be input directly to
the neural network. To make the ﬂows applicable, we
have to apply several changes to them. First, we read
the frames of each ﬂow. The data link header is removed
for extracting the packet since it does not have any
information for network intrusion detection tasks. Then
we read the bytes of the packet and divide them by 255
to obtain a normalized value between 0 and 1.

The maximum size of each packet is 1514 bytes, and
smaller packets are padded by zero-value bytes. Besides,
since the header length of UDP is less than TCP, we
add zero to the end of the UDP header so it will have
the same size as TCP header. There are some ﬁelds
in network traﬃc, which can mislead the deep learning
model. For example, the checksum ﬁeld can have ran-
dom values, and most probably, it is useless. Moreover,
as explained above, IP addresses can lead to the overﬁt-
ting problem. We mask the value of these ﬁelds by zero.
In the end, we will have an n × 1514 matrix, where n is
the number of packets.

The dimensions of the input matrix for this dataset
can be reduced by inspecting the dataset traﬃc. As
shown in Figure 6, packet size in normal and attack
traﬃc has two distinct ranges: packets with only the
ﬁrst 200 bytes, and packets with the maximum size
of 1514 bytes. By performing several experiments on
the dataset, we found that the ﬁrst 200 bytes of each
packet constitutes the discriminant bytes, and inspect-
ing extra bytes has no signiﬁcant impact on the learning
accuracy. In addition, benign and attack ﬂows in this
dataset contain mainly less than 100 packets (as shown
in Figure 7). So, inspecting only the ﬁrst 100 packets

Fig. 6 The distribution of number of bytes per packet in the
benign and attack traﬃcs.

Fig. 7 The distribution of the number of packets per ﬂow in
benign and attack traﬃcs.

4.2.2 Subsampling

As shown in Table 1, the size of the CIC-IDS2017
dataset is 50GB before the pre-processing phase, and
the pre-processing phase increases its size tremendously
to more than 500GB. Due to hardware limitations, we
cannot use all traﬃc ﬂows to train the neural network.
Therefore, we need to reduce the size of the dataset.

10

Mahdi Soltani1 et al.

Table 2 Details of the CSE-CIC-IDS2018 dataset.

Day

Attack type

Pcap size

Friday-02-03-2018
Friday-16-02-2018/
Friday-23-02-2018
Thursday-01-03-2018
Thursday-15-02-2018
Thursday-22-02-2018
Tuesday-20-02-2018
Wednesday-14-02-2018
Wednesday-21-02-2018
Wednesday-28-02-2018

Botnet
DoS
Web Attacks
Inﬁltration
DoS
Web Attacks
DDoS
Brute Force
DDoS
Inﬁltration

45GB
39GB
59GB
53GB
41GB
50GB
46GB
40GB
55GB
53GB

Also, the dataset is imbalanced, and the number of be-
nign ﬂows is much higher than the number of attack
ﬂows. This imbalance in data does not allow to train
the neural network correctly. To ﬁx these issues, we
choose all of the attack ﬂows and randomly select the
same amount of benign ﬂows, balancing the dataset and
reducing the input data size. Finally, we have a pre-
processed dataset with a size of around 40GB.

The size of the CSE-CIC-IDS2018 dataset is even
more challenging. Its original size is around 480GB and
captured in 10 diﬀerent days which is represented in Ta-
ble 2. Table 3 represents the selected ﬂow numbers of
each category in these two datasets. The categories and
their sub-category attacks are as follows: Botnet, Port
Scan, DoS/DDoS (DoS slowloris, DoS Slowhttptest,
DoS Hulk, DoS GoldenEye), Heartbleed/Inﬁltration,
Brute Force (FTP-Patator, SSH-Patator), Web Attack
(Brute Force, XSS, SQL Injection). The two datasets
have the same attack categories with some little dif-
ferences such as The 2017 version contains heartbleed
attacks. On the other side, the 2018 version has lots of
inﬁltration attacks. Besides, the port scan attacks are
absent in the CSE-CIC-IDS2018 and the number of its
web attacks is more limited.

Table 3 The balanced number of evaluated ﬂows in the bi-
nary classiﬁcation experiment.

Category

Sub-Category

CIC-IDS2017

Benign

-

Attack

Web Attacks

Botnet

Port Scan

DoS / DDoS

Brute Force

Heartbleed /
Inﬁltration

15000

1500

2000

2000

6000

3500

10

CSE-CIC-
IDS2018

15000

200

3000

-

6000

3000

3000

As mentioned above, the subsampling technique is
one of the main approaches to pre-process an unbal-
anced dataset before input to ML models. As mentioned
above, in the binary classiﬁcation scenario, we have
balanced the two classes (benign and attack). When
we consider a multi-class classiﬁcation setup, the same
technique can be applied. In this case, the subsampling
equalizes all classes, including the benign and other at-
tack categories.

Finally, the two evaluated CIC datasets have the
same attack types and categories. The attack types of
each attack category and the selected number of ﬂows
for each attack category of the datasets are described
in Table 4.

Table 4 The balanced number of evaluated ﬂows in the
multi-class classiﬁcation experiment.

Category

Sub-Category

CIC-IDS2017

CSE-CIC-
IDS2018

Benign

-

Attack

Web Attacks

Botnet

Port Scan

DoS / DDoS

Brute Force

Heartbleed /
Inﬁltration

5000

1500

2000

2000

6000

3500

10

5000

200

3000

-

6000

3000

3000

4.3 Experimental Results

After converting each ﬂow to an enriched input matrix,
we have split the dataset randomly into three subsets.
The ﬁrst set, which contains 64% of the ﬂows, is used to
train and tune the weights of the deep learning model.
The second and third sets are used during validation
and test phases and contain 16% and 20% of ﬂows, re-
spectively. We performed 10-fold cross-validation and
grid search for the hyper-parameter tuning.

There exist several metrics for evaluating the per-
formance of the trained model. Among them, we have
chosen precision (PR), recall (RC), fall-out (FO), and
F1 score (F1). Based on a confusion matrix, equations
of these parameters are stated as follows (TP: true pos-
itive, FP: false positive, TN: true negative, and FN:
false negative)

A Content-Based Deep Intrusion Detection System

11

Table 5 The hardware speciﬁcation of the experiment envi-
ronment.

OS

CPU

RAM

GPU

Debian version 9.3 with kernel 4.9.0-
amd64

Intel(R) Xeon(R) X5680 3.33GHz
with 24 virtual cores

18 GB

GeForce GTX 1080 Ti

GPU Frame Buﬀer

11 GB

Table 6 The traditional ML models for the binary classiﬁ-
cation evaluated on the pre-extracted features given in CSV
ﬁles of CIC-IDS2017 and CSE-CIC-IDS2018.

Dataset

Model

Precision

Recall

F1 score

CIC-IDS2017

CSE-CIC-IDS2018

SVM

RF

NB

SVM

RF

NB

0.79

0.98

0.66

0.77

0.95

0.72

0.76

0.98

0.61

0.69

0.95

0.61

0.75

0.98

0.58

0.66

0.95

0.56

PR = TP/(TP + FP),

RC = TP/(TP + FN),

FO = FP/(FP + TN),

F1 =

2 × PR × RC
PR + RC

.

(1)

(2)

(3)

(4)

to the size of the input data, and also according to the
huge size of the pre-processed dataset, the SVM model
cannot be ﬁt in our server and it is impractical for the
real world IDSs. Among the traditional ML models, the
RF shows remarkable results than the others over the
raw data.

Recall (RC) is a valuable metric in IDSs as it de-
termines the ratio of attacks that have been detected
to the actual attacks. Besides, the ratio of benign ﬂows,
labeled as attacks, to the total actual benign ﬂows is de-
termined by the fall-out (FO). Precision (PR) shows the
ratio of correctly generated alerts (existence of attacks)
to all alerts. This metric represents the trust of net-
work administrators to the generated security alarms.
Finally, F1 score tries to make a balance between the
importance of precision and recall. This is achieved by
calculating the harmonic mean of these valuable met-
rics.

To implement our deep learning model, we have
used the Keras library [14], with Tensorﬂow [5] as its
backend. The characteristic of our experiment environ-
ment is shown in Table 5.

Table 7 The traditional ML models for the binary classiﬁ-
cation evaluated on the enriched raw data of CIC-IDS2017
and CSE-CIC-IDS2018.

Dataset

Model

Precision

Recall

F1 score

CIC-IDS2017

CSE-CIC-IDS2018

RF

NB

RF

NB

0.96

0.91

0.90

0.75

0.96

0.91

0.89

0.75

0.96

0.90

0.89

0.75

The results of the multi-class RF model as the best
traditional ML model over the enriched raw data are
also presented in Table 8.

4.3.1 Evaluation of the Traditional ML Models

4.3.2 Determining the Hyper-Parameters for the
DID-based LSTM

First, we evaluate the performance of diﬀerent tradi-
tional machine learning classiﬁers like Support Vec-
tor Machine (SVM), Random Forests (RF), and Naive
Bayes (NB) over both the CIC-IDS2017 and CSE-CIC-
IDS2018 datasets. We have only presented the best re-
sults obtained by the hyper-parameters chosen through
an empirical random search (see Table 6). The results
are based on pre-extracted features, which are pre-
sented in CSV ﬁles alongside the dataset.

In the next step, we evaluate the traditional ML
models based on detection with the enriched raw data
(i.e., here, we do not use the pre-extracted features
of datasets). The traditional ML models are evaluated
over the pre-processed vectorized ﬂows (see Table 7).
Due to the dependence of the size of the SVM model

As mentioned before, the sequential nature of ﬂows,
packets, and bytes leads us to use LSTM models for
the DID framework. Hence, the next step is to de-
termine the appropriate hyper-parameters of the pro-
posed LSTM models. The main hyper-parameters of
an LSTM model are the number of layers and the num-
ber of units in each layer. The main results of the grid
search to tune hyper-parameters are reported in the
following. LSTM-1a has one LSTM layer with 50 units
and some fully-connected layers with 2500, 1250, 512,
256, 64, and 16 neurons. LSTM-2a has the same fully-
connected layers but two LSTM layers, whereas the
number of units of the ﬁrst LSTM layer is 100, and
the second one is 50 units. LSTM-1b and LSTM-2b
are similar to LSTM-1a and LSTM-1b respectively. The

12

Mahdi Soltani1 et al.

Table 8 The RF multi-class classiﬁer evaluated on the en-
riched raw data of CIC-IDS2017 and CSE-CIC-IDS2018.

Dataset

Category

Precision

Recall

F1 score

CIC-IDS2017

Benign

Botnet

Port Scan

DoS/DDoS

Heartbleed/
Inﬁltration

Brute Force

Web Attacks

Total

Benign

Heartbleed/
Inﬁltration

Botnet

CSE-CIC-IDS2018

DoS/DDoS

Web Attacks

Brute Force

Total

0.97

0.99

0.99

0.96

0.00

0.98

0.85

0.96

0.74

0.33

0.99

0.95

1.00

1.00

0.82

0.84

0.94

0.99

1.00

0.00

1.00

0.91

0.96

0.93

0.12

1.00

0.91

0.79

0.93

0.84

0.90

0.96

0.99

0.98

0.00

0.99

0.88

0.96

0.82

0.18

0.99

0.93

0.88

0.97

0.82

main diﬀerence between these two models comes from
their fully connected layers. They have simpler fully-
connected layers than “a” models (they only have two
64 and 16 neurons layers). In all models, all layers’ ac-
tivation functions (except the last one) are ReLU, and
dropout layers with a 20% drop rate are added among
fully-connected ones.

Table 9 The comparison of diﬀerent LSTM models em-
ployed in the DID framework.

Model

Precision

LSTM-1a

LSTM-1b

LSTM-2a

LSTM-2b

0.989

0.983

0.992

0.987

Recall

0.995

0.990

0.998

0.993

F1 score

0.991

0.987

0.994

0.990

Table 9 represents the results of diﬀerent LSTM
models introduced above, evaluated on the CIC-
IDS2017 dataset. As the results show, LSTM-2a out-
performs other models; however, the performance and
simplicity of LSTM-1b can also be a good candidate for
practical implementations.

Figure 8 depicts the loss value in the training phase
with selected hyper-parameters for LSTM-2a. At the
end of the training phase, the mean of loss in training
and validation data is 0.03 and 0.01, respectively. The
lower value of loss in the validation phase is due to the
dropout layers applied during the training phase, which
improves the generalization of the deep model. Conse-
quently, by removing them in the validation phase, bet-

ter results are achieved. The results of the evaluation of
this model by the test data are also presented in Table
11 for comparison with previous works.

We also evaluated our model as a multi-class clas-
siﬁer. In this scenario, not only the type of traﬃc but
also its category type will be determined. The perfor-
mance of the multi-class classiﬁcation over the attack
categories of the CIC-IDS2017 and CSE-CIC-IDS2018
datasets are presented in Table 10.

Table 10 The LSTM based DID multi-class classiﬁer eval-
uated on the enriched raw data of CIC-IDS2017 and CSE-
CIC-IDS2018.

Dataset

Category

Precision

Recall

F1 score

CIC-IDS2017

Benign

Botnet

Port Scan

DoS/DDoS

Heartbleed/
Inﬁltration

Brute Force

Web Attacks

Total

Benign

Heartbleed/
Inﬁltration

Botnet

CSE-CIC-IDS2018

DoS/DDoS

Web Attacks

Brute Force

Total

0.99

0.86

0.99

1.00

0.00

1.00

0.95

0.99

0.96

0.53

1.00

0.99

0.95

1.00

0.93

0.94

1.00

0.99

1.00

0.00

1.00

0.98

0.99

0.77

0.90

1.00

1.00

0.97

1.00

0.90

0.97

0.92

0.99

1.00

0.00

1.00

0.96

0.99

0.85

0.67

1.00

1.00

0.96

1.00

0.90

Fig. 8 The loss of the proposed deep learning module
(LSTM-2a) of DID during the training phase.

A Content-Based Deep Intrusion Detection System

13

Table 11 The results achieved by the proposed DID frame-
work on the CIC-IDS2017 and CSE-CIC-IDS2018 alongside
its comparison to [47], McPAD, and Deepcoin which are eval-
uated on the CIC-IDS2017. Besides, the reported values of
[41], [28], [29], and [48] over ISCX IDS 2012 are presented.

Dataset

CSE-CIC
IDS 2018

CIC-IDS
2017

ISCX IDS
2012

Model

Precision

Fall-out

Recall

F1 score

DID (with LSTM)

Random Forest

DID (with LSTM)

Zavrak et al. [47]

McPAD [38]

DeepCoin [18]

Soheily-Khah and et al. [41]

PCA-based TMAD [28]

Kahn and et al. [29]

DFR [48]

0.933

0.902

0.992

-

0.993

0.983

0.987

0.999

0.972

0.981

0.105

0.196

0.002

0.550

0.019

0.009

0.001

0.012

0.007

-

0.923

0.891

0.998

0.950

0.177

-

0.989

0.970

0.975

0.991

0.927

0.892

0.994

-

0.300

-

0.988

0.984

0.973

0.986

4.3.3 Comparison with Similar Researches

Our work is comparable with two categories of related
works. The ﬁrst category belongs to studies evaluated
on ISCX/CIC IDS datasets and the second one con-
cerns those that focus on the contents of the traﬃc
payloads. Soheily-Khah et al. [41] use 50 features of the
ISCX 2012 dataset to evaluate their model, which is
achieved by combining K-means and random forest al-
gorithms. This research is somehow comparable to our
work since it uses some learning algorithms over the
ISCX dataset, and this method can be compared with
deep learning. Their model has achieved recall and fall-
out of around 98.9 and 0.1, respectively. Note that since
they have not announced the average evaluation met-
rics, we have used their reported tables and the mean of
their metrics for diﬀerent protocols (since PR was not
reported, we calculate its value). The ﬁrst category also
comprises some other works such as [29], [48], and [18],
which all focus on using deep-learning methods over fea-
tures that are extracted from ISCX/CIC IDS datasets.
The main point that makes related works on ISCX IDS
2012 comparable with studies on CIC-IDS2017 is that
the CIC 2017 just an updated version of ISCX 2012. It
includes more benign proﬁles and attack version [40].
Due to the more complexity and completeness of the
CIC-IDS2017, the produced results are more reliable.

In the second category, we have works like [38],
which is one of the best research studies about detecting
content-based attacks. We have evaluated this method
by using its source code, which is available at [1]. Even
though this code yields good results over the dataset
used by themselves in [38], but it shows a weak per-
formance in learning CIC-IDS2017 dataset. This weak-
ness is related to the ISCX/CIC IDS dataset’s com-
prehensiveness against previous ones like DARPA or
KDD99. The results of the evaluation of McPAD by
CIC-IDS2017 are also represented in Table 11.

The main weakness of McPAD is its detection rate,
represented by the recall, which is around 20%. Al-
though McPAD has a signiﬁcant detection rate over
the dataset used in [38], it cannot be beneﬁcial in real-
world traﬃc. Further inspections show that while their
benign traﬃc is suitable, the attack ones used for the
evaluation have some notable weaknesses. For example,
allShellcode.pcap ﬁle has only 11 TCP sessions, which
in each one contains a shell-code attack. As the NOP
sled in these attacks has many repetitions of bytes like
0x90 and 0x61, they can be easily detected. Besides, the
other attack ﬁle, which is called allGeneric.pcap, has 66
HTTP attacks. Among them, 11 shell-code attacks can
be detected as the previous one, and the others have
hostnames that do not exist in the training dataset (like
www and www.i-pi.com). Consequently, the n-gram
mechanism can detect these kinds of attacks. However,
in the case of the CIC-IDS2017 dataset, although its
alarm has signiﬁcant reliability (PR = 99.3%), its de-
tection rate is low (RC = 17.7%).

Another related work in the second category is [28],
which focuses on extracting features of HTTP packet
payloads by the PCA algorithm. Finally, using a Text
Mining-based Anomaly Detection (TMAD) model tries
to detect attack traﬃcs.

Zavrak et al. [47] use variational autoencoders as
anomaly-based IDS sensors. Their evaluation has been
done over the CIC-IDS2017 dataset. The anomaly
model is trained by the records from Monday’s CSV
ﬁle that only contains benign traﬃc. Other days of the
dataset are used for the test phase. Finally, the FPR
and TPR metrics are reported that are equivalent to
the FO and RC, respectively.

Finally, we would like to report the resource and
time consumption of the proposed model and the com-
parison with the RF model as the best traditional ML
model over the enriched raw network data. The RF
model requires much lower resources in comparison
with the LSTM model according to our evaluations.
On average, the RF model needs about 208MB mem-
ory and 100% usage of one CPU core of the machine.
In contrast, the LSTM model uses about 900MB mem-
ory and 20% of the GPU processing power for the same
training data records. As presented in Table 12, the RF
model is much faster in the training phase than the
LSTM model. But the two models are competitive in
the test phase. Since an IDS is mainly used in the test
mode in the real world, the training time can have less
weight on the ﬁnal comparison of these two models. On
the other side, as shown in Tables 8 and 10, the strength
of the LSTM model can be highlighted in more com-
plicated dataset like CSE-CIC-IDS2018. Deﬁnitely, in
the real world, there are complicated data that makes

14

Mahdi Soltani1 et al.

Table 12 The average processing time per ﬂow in the train-
ing and test phases.

Model

Type

Training (sec) Test (sec)

DID

RF

Binary

Multi-Class

Binary

Multi-Class

0.014

0.016

0.004

0.005

0.007

0.008

0.004

0.005

the LSTM model more applicable. However, for a more
relaxed scenario where the RF model has an acceptable
performance and requires lower hardware resources, the
RF might be a better choice for the IDS implementa-
tion.

The input data to DID are ﬂows and time consump-
tion of evaluation of each ﬂow is around 7 milliseconds.
According to [27], on average, we can assume each ﬂow
contains 78 packets, and each packet contains 870 bytes.
As a result, the proposed model in our test environment
can handle around 75 Megabit per second traﬃc data
per GPU. This can be a challenge in high-performance
applications. However, by applying various optimiza-
tions, the above performance can be signiﬁcantly in-
creased and this can be an interesting direction for fu-
ture works.

4.4 Discussion

According to our experiments, the proposed deep intru-
sion detection (DID) approach can have a comparative
advantage over previous works in inspecting more va-
rieties of attacks, especially those who manipulate the
payload of traﬃc. However, the proposed approach has
some challenges which should be addressed in future
works. Some of these challenges are discussed below.

The main current shortcoming of using deep learn-
ing in network detection is its throughput. By increas-
ing the Internet bandwidth, we have to count on de-
vices with high throughput along with a high detec-
tion rate and low false alarm. Consequently, according
to the complexity of deep learning algorithms, one of
the main forward steps toward this goal is to optimize
the deep intrusion detectors and implement them over
high-performance devices like FPGAs or ASICs.

One of the most challenging issues in the scope of
intrusion detection systems is analyzing the encrypted
traﬃcs. Since the content of encrypted ﬂows is random-
ized, most of the signature-based IDSes have signiﬁcant
issues with these kinds of traﬃcs. Evaluation of DID
framework over encrypted traﬃcs can be studied in fu-
ture works.

Another challenge to making ML-based IDSes more
applicable in practice is to adapt them to imbalanced

data. The imbalance of data can make a machine learn-
ing model tend to the “more observed” (major) cate-
gory. However, detecting the minor category may be
of high value for us (such as detecting cancer in med-
ical applications or attack detection in computer net-
works). Alongside, if the test dataset is also imbalanced,
the overall detection rate of the algorithm cannot pro-
vide a useful measure of the performance of the intru-
sion detection method in real scenarios. For example,
for a dataset with 95% benign traﬃc, this can lead to
a model that labels all the inputs as benign traﬃc to
achieve 95% accuracy while the desired goal of the in-
trusion detection system is to detect attacks as much as
possible with low false positive. In this paper, the data
reduction mechanism for the majority group has been
applied. However, this solution can cause some losses in
the diversity of the major category (i.e., in this paper,
the benign traﬃc). Consequently, some kinds of benign
ﬂows may be detected as attacks in a more comprehen-
sive dataset, which has more complicated attacks.

Finally, in this research, we have used a labeled
dataset for training the model. However, the lack of
adequate diversity in this dataset can lead to poor per-
formance in real networks. On the other hand, each
network has its own behavior for normal traﬃcs (like
the number of new connections per second), which may
be considered an abnormal behavior in other networks.
Hence, it is very crucial that we learn the models ac-
cording to their deployment environment.

5 Conclusion

This paper presented a Deep Intrusion Detection ap-
proach that uses deep learning algorithms for detect-
ing a wide range of attacks, including content-based
ones like SQL injection and Heartbleed attack. We have
used an LSTM-based model as an implementation of
the deep learning module of the DID approach. LSTM
layers can extract meaningful relations among bytes
of packets of each ﬂow. Besides using dropout layers,
we tried to avoid overﬁtting. Four metrics that pro-
vide valuable information in intrusion detection appli-
cations have been selected for evaluation, namely, preci-
sion, recall, fall-out, and F1 score. On the CIC-IDS2017
dataset, we have achieved a precision of 0.992, fall-out
of 0.2, recall of 0.998, and F1 score of 0.994. Further-
more, on the CSE-CIC-IDS2018, the recall of 0.923 and
precision of 0.933 achieved. The experimental results
show that the proposed approach has better perfor-
mance than the previous works.

A Content-Based Deep Intrusion Detection System

15

Acknowledgements The authors would like to thank
Ramin Shirali and Jafar Gholamzadeh for their invaluable
help, discussion, and feedback on this work.

Compliance with Ethical Standards

Funding: No funding was received to assist with the
preparation of this manuscript.
Conﬂicts of interests: The authors have no conﬂicts
of interest to declare that are relevant to the content of
this article.
Ethical approval: This article does not contain any
studies with human participants or animals performed
by any of the authors.

References

1. Mcpad

project.

http://roberto.perdisci.com/
projects/mcpad (2009). [Online; accessed 12-November-
2018]

2. Kdd cup 1999.

http://kdd.ics.uci.edu/databases/
[Online; accessed 12-

kddcup99/kddcup99.html (2018).
November-2018]

3. Snort 2.9. https://www.snort.org (2018).

[Online; ac-

cessed 18-October-2018]

4. Cse-cic-ids2018.

https://www.unb.ca/cic/datasets/

ids-2018.html (2021). [Online; accessed 18-May-2021]
5. Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen,
Z., Citro, C., Corrado, G.S., Davis, A., Dean, J., Devin,
M., Ghemawat, S., Goodfellow, I., Harp, A., Irving, G.,
Isard, M., Jia, Y., Jozefowicz, R., Kaiser, L., Kudlur, M.,
Levenberg, J., Man´e, D., Monga, R., Moore, S., Mur-
ray, D., Olah, C., Schuster, M., Shlens, J., Steiner, B.,
Sutskever, I., Talwar, K., Tucker, P., Vanhoucke, V., Va-
sudevan, V., Vi´egas, F., Vinyals, O., Warden, P., Wat-
tenberg, M., Wicke, M., Yu, Y., Zheng, X.: TensorFlow:
Large-scale machine learning on heterogeneous systems
(2015). URL http://tensorflow.org/. Software avail-
able from tensorﬂow.org

6. Agarap Abien, F.M.: A neural network architecture com-
bining gated recurrent unit (GRU) and support vector
machine (SVM) for intrusion detection in network traﬃc
data. Proceedings of the 2018 10th International Con-
ference on Machine Learning and Computing pp. 26–30
(2018)

7. Akashdeep, Manzoor, I., Kumar, N.: A feature reduced
intrusion detection system using ann classiﬁer. Expert
Systems with Applications 88, 249–257 (2017)

8. Aminanto Muhamad, E., Choi, R., Tanuwidjaja Harry,
C., Yoo Paul, D., Kwangjo, K.: Deep abstraction and
weighted feature selection for wi-ﬁ impersonation detec-
tion.
IEEE Transactions on Information Forensics and
Security 13(3), 621–636 (2018)

9. Basumallik, S., Ma, R., Eftekharnejad, S.: Packet-data
anomaly detection in pmu-based state estimator using
convolutional neural network.
International Journal of
Electrical Power & Energy Systems 107, 690–702 (2019)
10. Bengio, Y., Courville, A., Vincent, P.: Representation
learning: A review and new perspectives. IEEE Trans-
actions on Pattern Analysis and Machine Intelligence
35(8), 1798–1828 (2013)

11. Bivens, A., Palagiri, C., Smith, R., Szymanski, B., Em-
brechts, M.: Network-based intrusion detection using
neural networks. Intelligent Engineering Systems through
Artiﬁcial Neural Networks 12(1), 579–584 (2002)

12. Breiman, L.: Random forests. Machine Learning 45(1),

5–32 (2001)

13. Chen, R.C., Cheng, K.F., Chen, Y.H., Hsieh, C.F.: Us-
ing rough set and support vector machine for network in-
trusion detection system. In: First Asian Conference on
Intelligent Information and Database Systems, pp. 465–
470. IEEE (2009)

14. Chollet, F.: keras. https://github.com/fchollet/keras

(2017)

15. Cretu-Ciocarlie, G.F., Stavrou, A., Locasto, M.E., Stolfo,
S.J., Keromytis, A.D.: Casting out demons: Sanitizing
training data for anomaly sensors. IEEE Symposium on
Security and Privacy pp. 81–95 (2008)

16. Dorﬀner, G.: Neural networks for time series processing.

Neural Network World 6, 447–468 (1996)

17. Farnaaz, N., Jabbar, M.: Random forest modeling for net-
work intrusion detection system. Procedia Computer Sci-
ence 89, 213–217 (2016)

18. Ferrag, M.A., Maglaras, L.: Deepcoin: A novel deep learn-
ing and blockchain-based energy exchange framework for
smart grids. IEEE Transactions on Engineering Manage-
ment (2019)

19. Ferrag, M.A., Maglaras, L., Moschoyiannis, S., Janicke,
H.: Deep learning for cyber security intrusion detection:
Approaches, datasets, and comparative study. Journal of
Information Security and Applications 50, 102419 (2020)
20. Goodfellow, I., Bengio, Y., Courville, A.: Deep Learning.

MIT Press (2016). http://www.deeplearningbook.org

21. Heba, F.E., Darwish, A., Hassanien Aboul, E., Abraham,
A.: Principle components analysis and support vector
machine based intrusion detection system. 2010 10th In-
ternational Conference on Intelligent Systems Design and
Applications pp. 363–367 (2010)

22. Heckerman, D.: A tutorial on learning with bayesian net-
works. In: Innovations in Bayesian networks, pp. 33–82.
Springer (2008)

23. Hochreiter, S., Schmidhuber, J.: Long short-term mem-

ory. Neural computation 9(8), 1735–1780 (1997)

24. Javaid, A., Niyaz, Q., Sun, W., Mansoor, A.: A deep
learning approach for network intrusion detection sys-
tem. BICT’15 Proceedings of the 9th EAI International
Conference on Bio-inspired Information and Communi-
cations Technologies (formerly BIONETICS) pp. 21–26
(2016)

25. Jemili, F., Zaghdoud, M., Ahmed Mohamed, B.: A frame-
work for an adaptive intrusion detection system using
Bayesian network. 2007 IEEE Intelligence and Security
Informatics pp. 66–70 (2007)

26. Jia, N., Liu, D.: Application of svm based on information
entropy in intrusion detection. In: International Confer-
ence on Intelligent and Interactive Systems and Applica-
tions, pp. 464–468. Springer (2017)

27. Jurkiewicz, P., Rzym, G., Borylo, P.: Flow length and
size distributions in campus internet traﬃc. CoRR
abs/1809.03486 (2018)

28. Kakavand, M., Mustapha, N., Mustapha, A., Abdul-
lah, M.T.: Eﬀective dimensionality reduction of payload-
based anomaly detection in tmad model for http payload.
TIIS 10(8), 3884–3910 (2016)

29. Khan, M.A., Karim, M., Kim, Y., et al.: A scalable
and hybrid intrusion detection system based on the
convolutional-lstm network. Symmetry 11(4), 583 (2019)

16

Mahdi Soltani1 et al.

on Recent Advances in Intrusion Detection pp. 203–222
(2004)

47. Zavrak, S., Iskeﬁyeli, M.: Anomaly-based intrusion detec-
tion from network ﬂow features using variational autoen-
coder. IEEE Access 8, 108346–108358 (2020)

48. Zeng, Y., Gu, H., Wei, W., Guo, Y.: deep − f ull − range:
A deep learning based network encrypted traﬃc classiﬁ-
cation and intrusion detection framework. IEEE Access
7, 45182–45190 (2019)

49. Zhang, J., Zulkernine, M., Haque, A.: Random-forests-
based network intrusion detection systems. IEEE Trans-
actions on Systems, Man, and Cybernetics, Part C (Ap-
plications and Reviews) 38(5), 649–659 (2008)

30. Kim, J., Kim, J., Thu Huong, L.T., Kim, H.: Long short
term memory recurrent neural network classiﬁer for in-
trusion detection. 2016 International Conference on Plat-
form Technology and Service (PlatCon) pp. 1–5 (2016)

31. Kim, K., Aminato Muhaamad, E.: Deep learning in in-
trusion detection perspective: Overview and further chal-
lenges. 2017 International Workshop on Big Data and
Information Security (IWBIS) pp. 5–10 (2017)

32. Kruegel, C., Mutz, D., Robertson, W., Valeur, F.:
Bayesian event classiﬁcation for intrusion detection. Pro-
ceedings of the 19th Annual Computer Security Applica-
tions pp. 14–23 (2003)

33. Kruegel, C., Toth, T.: Using decision trees to improve sig-
nature based intrusion detection. International Workshop
on Recent Advances in Intrusion Detection pp. 173–191
(2003)

34. LeCun, Y., Bengio, Y., Hinton, G.: Deep learning. nature

521(7553), 436–444 (2015)

35. Lippmann Richard, P., Cunningham Robert, K.: Improv-
ing intrusion detection performance using keyword selec-
tion and neural networks. Computer Networks 34(4),
597–603 (2000)

36. Lippmann, R., Haines Joshua, W., Fried David, J., Ko-
rba, J., Das, K.: The 1999 darpa oﬀ-line intrusion de-
tection evaluation. Computer Networks 34(4), 579–595
(2000)

37. Mahoney Matthew, V., Chan Philip, K.: An analysis
of the 1999 darpa/lincoln laboratory evaluation data
for network anomaly detection. International Workshop
on Recent Advances in Intrusion Detection pp. 220–237
(2003)

38. Perdisci, R., Ariu, D., Fogla, P., Giacinto, G., Lee, W.:
Mcpad- a multiple classiﬁer system for accurate payload-
based anomaly detection. Computer Networks 53(6),
864–881 (2009)

39. Salama Mostafa, A., Eid Heba, F., Ramadan Rabie, A.,
Darwish, A., Hassanein Aboul, E.: Hybrid intelligent in-
trusion detection scheme. In: Soft computing in Indus-
trial Applications, pp. 293–303. Springer (2011)

40. Sharafaldin, I., Lashkari Arash, H., Ghorbani Ali, A.: To-
ward generating a new intrusion detection dataset and in-
trusion traﬃc characterization. In: ICISSP, pp. 108–116
(2018)

41. Soheily-Khah, S., Marteau, P.F., B´echet, N.: Intrusion
detection in network systems through hybrid supervised
and unsupervised mining process-a detailed case study on
the ISCX benchmark dataset. In: 2018 1st International
Conference on Data Intelligence and Security (ICDIS),
pp. 219–226. IEEE (2018)

42. Song, Y., Locasto Michael, E., Starvrou, A., Keromytis,
A., Stolfo Salvatroe, J.: On the infeasibility of modeling
polymorphic shellcode. Machine Learning 81(2), 179–205
(2010)

43. Tang Tuan, A., Mhamdi, L., McLernon, D., Zaidi Syed,
A.R., Ghogho, M.: Deep learning approach for network
intrusion detection in software deﬁned networking. 2016
International Conference on Wireless Networks and Mo-
bile Communications (WINCOM) pp. 258–263 (2016)
44. Wang, H., Gu, J., Wang, S.: An eﬀective intrusion detec-
tion framework based on svm with feature augmentation.
Knowledge-Based Systems 136, 130–139 (2017)

45. Wang, K., Parekh Janak, J., Stolfo Salvatore, J.: Ana-
gram: A content anomaly detector resistant to mimicry
attack. International Workshop on Recent Advances in
Intrusion Detection pp. 226–248 (2006)

46. Wang, K., Stolfo Salvatore, J.: Anomalous payload-based
International Workshop

network intrusion detection.

