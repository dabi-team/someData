Anomaly Detection from Cyber Threats via Infrastructure to
Automated Vehicle

Chris van der Ploeg1,2, Robin Smit1, Alexis Siagkris-Lekkos1, Frank Benders1, Emilia Silvas1,3

1
2
0
2

r
p
A
3
2

]

R
C
.
s
c
[

1
v
0
9
7
1
1
.
4
0
1
2
:
v
i
X
r
a

Abstract— Using Infrastructure-to-Vehicle (I2V) information
can be of great beneﬁt when driving autonomously in high-
density trafﬁc situations with limited visibility, since the sensing
capabilities of the vehicle are enhanced by external sensors. In
this research, a method is introduced to increase the vehicle’s
self-awareness in intersections for one of the largest foreseen
challenges when using I2V communication: cyber security.
The introduced anomaly detection algorithm, running on the
automated vehicle, assesses the health of the I2V communication
against multiple cyber security attacks. The analysis is done in a
simulation environment, using cyber-attack scenarios from the
Secredas Project (Cyber Security for Cross Domain Reliable
Dependable Automated Systems) and provides insights into the
limitations the vehicle has when facing I2V cyber attacks of
different types and amplitudes and when sensor redundancy
is lost. The results demonstrate that anomalies injected can be
robustly detected and mitigated by the autonomous vehicle, al-
lowing it to react more safely and comfortably and maintaining
correct object tracking in intersections.

I. INTRODUCTION

Connected and automated driving is emerging as a so-
lution to safer, more efﬁcient, sustainable and comfortable
road transport system, [1]. Different driver assisting or
autonomous functions are brought to the road by vehicle
manufacturers, with increased connectivity possibilities, such
as vehicle-to-vehicle (V2V), vehicle-to-infrastructure (V2I,
I2V) or vehicle-to-everything (V2X, X2V). These bring func-
tionality and performance beneﬁts but also risks and concerns
in terms of cyber security and privacy: the automated vehicle
is a thing in the Internet of Things (IoT), that can cause
dangerous situations and that collects large amounts of data.
Via X2V communications it is now possible to breach a
vehicle without being in a certain physical range or using
previously installed hardware, [2]. A lack of cyber security
can lead to unsafe situations and will result in a lack of trust
and reluctant users. This calls for improved safe- and secure-
by-design concepts for connected and automated driving that
can detect spoofed and tampered X2V messages and will
react proactively and safely.

An anomaly, deﬁned in the ISO 26262 standard as a
condition that deviates from expectations, based for ex-
ample on requirements, speciﬁcations, design documents,
user documents, standards or on experience [3], can have

1Netherlands Organisation for Applied Scientiﬁc Research, Integrated

Vehicle Safety Group, 5700 AT Helmond, The Netherlands.

2Eindhoven University of Technology, Dynamics and Control Group,
Mechanical Engineering Dept., P.O. Box 513, 5600 MB, Eindhoven, The
Netherlands. (e-mail: c.j.v.d.ploeg@tue.nl).

3Eindhoven University of Technology, Control Systems Technology
Group, Mechanical Engineering Dept., P.O. Box 513, 5600 MB, Eindhoven,
The Netherlands.

multiple forms and patterns. More speciﬁcally, cyber network
anomalies (i.e. intrusion attempts or threats) are used to
access and manipulate information or to render a system as
unreliable or unusable. Detecting cyber network anomalies
refers to the problem of detecting in real-time wrong patterns
and anomalies in I2V trafﬁc that do not conform to the
expected normal behaviour, [4]. I2V communication can be
very beneﬁcial especially in intersection scenarios where a
Road Side Unit (RSU) is used to communicate the position
of observed Vulnerable Road Users (VRU), enhancing the
tracking range and the state estimation accuracy of the
detected objects, [5].

Multiple anomaly detection methods have been developed
that can be applied for I2V cyber attacks as well, with many
focusing on single and known types of anomalies for limited
scenarios or on taking into account the state of another
leading vehicle as available in cooperative driving, [6]. For
example, particle ﬁltering and maximum likelihood methods
are used in [7], comparing sensor outputs using pairwise
inconsistency graphs in [8], [9] uses a combination between
a convolutional neural network and a Kalman ﬁlter and
[10] uses long short-term memory (LSTM) neural networks.
Furthermore, several studies have introduced the types of
anomalies that can typically be expected from cyber attacks,
[4], [9] and the possible attackers’ behaviours, [11], yet no
methods have been introduced that can deal with multiple
types of attacks around intersections, via I2V communica-
tion, as depicted in Fig. 1. It is also unknown how sensor
redundancy can help in ensuring a safe operation of the
vehicle and can be used to identify the anomaly.

Fig. 1.
(RSUs) communicate information to the vehicle about other road users.

Intersection crossing scenario considered, where road side units

To address this challenge, in this paper we propose an
extended Kalman ﬁlter (EKF) to detect object
tracking
anomalies that result from in-vehicle cyber attacks coming
from I2V communication. We chose this algorithm to beneﬁt

 
 
 
 
 
 
from the domain knowledge about the vulnerable road users
and since EKF is a well-established anomaly detection
method, [9]. Unlike previous works, we develop and validate
our method on multiple types of attacks for intersection
scenarios that the automated vehicle can encounter and we
discuss the importance of sensor redundancy depending on
different anomalies.

This paper is organized as follows. Section II introduces
the functional architecture of the automated vehicle and the
types of attacks considered while Section III introduces the
anomaly detection problem, the scenarios and the developed
simulation environment. Sections IV and V introduce the
extended Kalman ﬁlter and simulation results resulting from
this design. Finally, the conclusions and recommendations
for future work are described in Section VI.

II. PRELIMINARIES

In an automated driving (AD) vehicle, internal and possi-
bly external sensors are used to monitor the environment. The
system architecture and the types of anomalies are important
to be able to develop a robust method for detecting these
anomalies. This section introduces the vehicle functional
architecture used, an overview of the types of existing
anomalies and a selection relevant for cyber-attacks via I2V.

A. Sensor fusion and object tracking

The functional architecture of the AD vehicle is depicted
in Fig. 2, where world modeling contains the ego vehicle
state estimation functions, object detection and tracking
functions and road modeling functions, such as lane and
empty drivable space models. The dynamic objects in the

Fig. 2. The functional architecture of the AD application, highlighting the
used components for I2V anomaly detection (based on [12], [13])

B. Types of anomalies

Anomalous sensor behaviour can have different forms,
which pose different challenges in detecting the deviation
from the healthy behaviour. Besides a malicious attack, these
anomalies could come from e.g. wrong sensor calibration,
limited sensor capabilities and environmental inﬂuence, [9].
Categories of possible sensor signals anomalies are intro-
duced in [14], with three main classes being explained
as important and observed in real-life deployments,
i.e.
short, noise and constant. In more detail, the authors in
[9] distinguish between four types of anomalies, i.e. bias,
gradual drift, instant and miss. Bias anomalies imply that the
anomalous signal has a temporally constant error compared
to the normal sensor reading. Gradual drift refers to a
gradual drift (increasing or decreasing) in the observed data,
for a period of time, with or without a bias. The longer the
period of the drift, the more dangerous and unrepresentative
the speciﬁc signal can become with respect to the true state
of the observed object. Instant anomalies imply sharp, unex-
plained changes in the observed data between two successive
sensor readings, while miss anomalies refer simply to the
lack of available object or signal data during a time period.
The authors in [6] consider that additional anomalies can
be noise, in which the signal gets perturbed (e.g. random
variation of brightness or color information in an camera
image), or burst, where the signal gets disturbed for a short
amount of time (e.g., driving over a pothole).

To ensure a safe operation of the ego vehicle in case of
I2V cyber-attacks, see Fig. 1, it is crucial to detect those
anomalies that will offer wrong information in such a way
that the automated vehicle will take the wrong decision (e.g.,
collide with the pedestrian or cyclist approaching). As the
overview in [15] shows, cyber-attacks can also induce other
anomalies (e.g. in-vehicle communication), but the focus of
this research is on attacks comings from infrastructure to
the vehicle that can lead to unsafe situations. Therefore, this
work focuses speciﬁcally on instant, bias, and gradual drift
anomalies, claiming that e.g. the noise and burst anomalies
can be classiﬁed as an intense temporal instant, bias and/or
drift anomalies, and the miss anomaly will be handled by
the Target Tracker internally. These types of anomalies pose
the highest threat and are the most dangerous for cooper-
ative automated vehicles, [16][17]. Since in the considered
scenario the malicious data comes from a RSU, the focus
in this work will be on detecting sensor anomalies (i.e. any
sensor embedded in or attached to the vehicle, as well as
sensors located in the environment). Anomalies that come
from the fused state output are not addressed here as this
poses a different type of problem.

vehicle’s environment are tracked by on-board sensors (i.e.,
radar, lidar, camera) providing relative measurements to the
vehicle. Furthermore, in the scenario of Fig. 1, the camera at-
tached to the RSU is providing absolute measurements using
I2V communication. These sensor measurements, together
with the ego vehicle state estimation, are fused into a single
object state estimate by a module, i.e. Target Tracker.

III. PROBLEM DESCRIPTION

While I2V can enhance the object detection capabilities
of an AD vehicle in terms of ﬁeld-of-view and sensor
redundancy, communicating object information for sensor
fusion does however introduce a cyber security threat as the
data could potentially be spoofed or tampered with. Using
this tampered data for sensor fusion could result in wrong

SensingEnvironment SensingDriver SensingVehicleCommunication (e.g. V2X)ThinkingPlanningThinkingDecisionThinkingControlActuationBrakingActuationPropulsionActuationSteeringActuationIndicatingActuationCleaningThinkingWorld ModellingHuman Machine Interfaceobject position or velocity estimations and as a result could
lead to safety-critical situations.

When anomalies are detected in the fused state estimate (in
the World Modelling block in Fig. 2), a driver can be warned
that the perception model might be compromised or the AD-
system can bring the vehicle to a safe state. However, a com-
promised integrity of the state estimate cannot be avoided.
By monitoring the sensors individually for anomalies, their
health can be determined and compromised sensors can be
temporarily ignored or permanently disabled in the sensor
fusion algorithm.

A. System description

The automated vehicle considered is equipped with dedi-
cated automotive sensors (radar, camera, lidar, GPS) as well
as dedicated units for software and communication. The
RSU is a monitoring system at the side of the intersection,
e.g. cameras which detect the VRUs. The communication is
done via the Collective Perception Message (CPM) receiver
and object parser which takes the relative camera object
detections and transforms them to a global reference frame,
so that they can be correlated with the vehicle’s reference
frame. This parser also adapts the information to an interface
for the Target Tracker software.

B. The Scenario and its variations

In the considered scenario, an AD vehicle is approaching
the intersection and receives malicious information from the
hacked RSU, which is the only sensor considered in this
study as affected by the attack. The vehicle detects the
attack and mitigates it by ignoring the faulty external sensor
information in the Target Tracker. In this scenario, a RSU
transmits the wrong position of a VRU (a pedestrian or a
cyclist), as shown in Fig. 3. Examples of variations include:

on the side of the intersection. The vehicle is intentionally
not alerted about the passing VRU, which could lead to a
collision;
(iii) A VRU is either at the side of the intersection or at
different locations on the intersection. The RSU sends wrong
information about the heading or velocity of the VRU to the
automated vehicle which can mislead prediction or intention
classiﬁcation models of the vehicle.

C. Simulation environment

Since real measured data is very hard to ﬁnd for these
scenarios, data is simulated for the considered scenario
and its actors in a Gazebo simulator, [18] as depicted in
Fig. 4. The intersection’s road network is deﬁned using
the OpenDrive standard, [19]. The scenario itself, including
actions and events, is described in the OpenScenario format
[20]. To mimic realistic intrusion situations that can lead

Fig. 4. Gazebo-based simulation scenario

to unsafe situations, when the pedestrian is in the ﬁeld of
view of all on-board vehicle sensors as well as the RSU,
an anomaly is injected as described next. Furthermore, to
make the simulation as realistic as possible, sensor noises
are introduced for both the on-board vehicle sensors, as well
as the road side camera. Following typical sensor noises
at automotive object tracking sensors, the noises levels, σ,
are independent zero-mean white noises with the following
standard deviations (used from [21] as 3σ values of a normal
distribution):

x , σ(1)
σ(1)
, σ(2)
σ(2)
vy
vx
, σ(3)
σ(3)
vy
vx
, σ(4)
σ(4)
vy
vx

y = 0.03 [m],

= 0.17 [m/s],

= 0.17 [m/s],

= 0.17 [m/s],

y = 0.0067 [m],
y = 0.03 [m],
y = 0.03 [m],

x , σ(2)
σ(2)
σ(3)
x , σ(3)
σ(4)
x , σ(4)
σ(4)
θ , σ(4)
vθ

= 0.011 [rad]

(1)

Fig. 3. Examples of scenarios for anomalous RSU data

(i) a VRU at the side of the intersection, waiting to cross.
The hacked RSU communicates that
the VRU is in the
intersection instead (case A in Fig. 3), possibly causing the
AD vehicle to unnecessarily stop at the crossing. This can
lead, for example, to other dangerous situations for upcoming
trafﬁc behind the ego vehicle;
(ii) a VRU is crossing the intersection (case B in Fig. 3).
The hacked RSU communicates that the VRU is located

where the counter values j ∈ {1, 2, 3, 4} indicate the sensor
source of the signals, being the radar, the lidar, the camera
and the RSU respectively. For ease of notation, this counter
j is used throughout the rest of the paper with identical
the subscripts x, y, vx, vy refer to
meaning. Moreover,
the objects’ longitudinal and lateral positions and velocity
respectively.

D. Anomaly injection

It

is assumed that

the vehicle is observed in 2D by
the RSU, measuring at each time sample k the positions
k , y(4)
x(4)
k , and the corresponding velocities

k , the heading θ(4)

Roadside Surveillance Monitoring SystemReal VRU positionRSU communicated (hacked) position to the vehicleABCAssumedmaximum sensor rangev(4)
xk , v(4)
u(4)
k

yk , v(4)
θk
and deﬁned as

. The RSU measurement state is denoted by

(cid:104)

u(4)
k =

x(4)
k ,

y(4)
k ,

θ(4)
k ,

v(4)
xk ,

v(4)
yk ,

v(4)
θk

(cid:105)(cid:124)

.

(2)

The error injected for the different anomalies is deﬁned by

ek = (cid:2) ex
k,

ey
k,

eθ
k,

evx
k ,

evy
k ,

evθ
k

(cid:3)(cid:124)

,

(3)

with (·)x referring to the anomaly injected in each respective
dimension. The hacked output going into the vehicle on-
board sensor fusion algorithm at time k will be denoted by
ˆu(4)
k .
Three different injected anomalies are deﬁned: eD for
gradual drift, eB for bias, and eI for instant. Usually, ||eD|| <
||eB|| < ||eI ||, resulting in three different hacked outputs,

k = u(4)
ˆu(4)

k + eI ∆(k, kanomaly),

(4)

for instant anomalies, with ∆(k, kanomaly) a Kronecker delta
function at the anomaly time kanomaly,

k = u(4)
ˆu(4)

k + eB,

for bias anomalies, and
k = u(4)
ˆu(4)

k + ˆu(4)

k−1 − u(4)

k−1 + eD,

(5)

(6)

for gradual drift anomalies. The drift and bias anomalies
will be injected for different durations, from time kstart until
kend, such that

ek (cid:54)= 0 f or kstart ≤ k < kend,
ek = 0 f or k < kstart

|| k ≥ kend,

where kstart is chosen such that the pedestrian is observed
by the RSU as well as by all on-board vehicle sensors at the
time of the anomaly injection.

IV. IN-VEHICLE CYBER THREATS ANOMALY DETECTION

Using simulated data from Section III, the scenario de-
picted in Fig. 1 and the available in-vehicle sensors and the
RSU measurements, a fault diagnosis can be done.

A. Multi-sensor EKF anomaly detection algorithm

The algorithm for detecting anomalous sensor behaviour
follows the architecture shown in Fig. 2 and the more detailed
view is shown in Fig. 5. The anomaly detector is designed for
detection of an anomaly on any of the sensor states. Once an
anomaly is detected, the affected sensor state is disregarded
in the Target Tracker for as long as the anomaly persists.
This information can be used to disregard that measurement
from the sensor fusion of the Target Tracker, in order to
mitigate anomalies in the fused estimate of a certain state.
For detection of the aforementioned fault types, an Extended
Kalman Filter (EKF) is combined with a L2 norm-based
test for residual evaluation [22, Section 11.2.2]. The EKF
algorithm uses an omnidirectional motion model with state
X = [x, y, θ, v, vθ, a] where x, y denote the longitudinal
and lateral positions and θ represents the heading of the
target with respect to the automated vehicle. With v and a

Fig. 5. Schematic representation of the anomaly detection algorithm and
how it interacts with the Target Tracker.

we denote the resultant planar velocity and acceleration and
vθ the ﬁrst time derivative of the heading. These resultant
components can be expressed in the velocities vx, vy and
accelerations ax, ay as follows:

(cid:113)

v =

x + v2
v2
y

(cid:113)

a =

x + a2
a2
y

In the model, a constant acceleration a and a constant yaw-
rate vθ, is assumed. This assumption is made due to the fact
that we consider a VRU (e.g., a pedestrian or a cyclist) in
the scenario and thus can assume low-dynamic behavior. The
model of this VRU can be denoted as

ak cos (θk)∆2

1
2
1
ak sin (θk)∆2
2

t + w(1)
k ,

t + w(2)
k ,

xk+1 = xk + vk cos (θk)∆t +

yk+1 = yk + vk sin (θk)∆t +
θk+1 = θk + vθk ∆t + w(3)
k ,
vk+1 = vk + ak∆t + w(4)
k ,
vθk+1 = vθk + w(6)
k ,
ak+1 = ak + w(7)
k ,

k ∼ (0, σ2

where k denotes the discrete time counter, w(i)
i ) ∀i
is a zero-mean white process noise and ∆t denotes the
discrete sampling step. Note that
the VRU is modelled
as an undriven system, i.e., the object is only externally
observed, using sensors on the automated vehicle as well as
the RSU measurements. These available measurements can
be modelled in the VRU model, used for EKF synthesis, as

uk = h(Xk) + zk,

where zk is a vector signal of independent zero-mean white
noises and the measurement matrix H is deﬁned by

h(1)(Xk) = δ(1)
k
h(2)(Xk) = δ(2)
k
h(3)(Xk) = δ(3)
k
h(4)(Xk) = δ(4)
k

,

(cid:124)
[xk, yk]
(cid:2)xk, yk, vk cos(θk), vk sin(θk)(cid:3)(cid:124)
(cid:2)xk, yk, vk cos(θk), vk sin(θk)(cid:3)(cid:124)
(cid:2)xk, yk, θk, vk cos(θk), vk sin(θk), vθ

,

,

(cid:3)(cid:124)

,

where δ(j)
on the availability of a new measurement h(j)
is available,
a speciﬁc sensor measurement

k ∀j denotes a set of indicator signals, which depend
k ∀j. I.e., when
the indicator

CameraLidarRadarRoad Side UnitMonitoring SystemAnomalous state found[0/1]TCP / CPM receiver and Object ParserIn vehicle sensorsExternal sensorsTarget  trackerAnomaly detectionFig. 6. An example of the EKF residuals for a bias fault of eB
introduced on the yk measurement of the RSU at time t = 45 seconds.

x = 1.28m

function for that measurement is set to 1, otherwise it is
equal to 0. The fused state prediction ˆXk|k−1 of the EKF
and its covariance matrix can be denoted as

ˆXk|k−1 = f ( ˆXk−1|k−1),
Pk|k−1 = AkPk−1|k−1A

(cid:124)
k + Q,

Ak =

∂f (Xk)
∂Xk

(cid:12)
(cid:12)
(cid:12)
(cid:12) ˆXk−1|k−1

,

(7)

where Pk,k−1 is the state prediction covariance matrix, Ak is
the jacobian of f (Xk) and Q is the process noise covariance
matrix. The Kalman gain, used to update the internal state
estimate for the current time-step, is calculated by

Hk =

,

∂h(j)
∂Xk

(cid:12)
(cid:12)
(cid:12)
(cid:12) ˆXk|k−1
k HkPk|k−1H
(cid:124)

Sk = ε(j)
Kk = Pk|k−1H

(cid:124)

k ε(j)
k S−1
k ,

k + R(j),

(8)

(9)

k ε(j)
where Hk represents the linearized state measurement ma-
trix, R represents the sensor noise covariance matrix for
each respective sensor j and Kk represents the Kalman
gain. Finally, ε(j)
is a set of indicator signals dependent on
k
the presence of a fault for a certain sensor measurement,
something which is explained further on in the residual
evaluation. For the next time-step, the generated residual,
the state estimate and its covariance matrix are predicted by
the following equations

rk = (uk − h(j)( ˆXk|k−1))

ˆXk|k = ˆXk|k−1 + Kkrk,
Pk|k = (I − KkHk) Pk|k−1.

(10)

(11)

(12)

where rk denotes the innovation residual signal. Note that
this residual rk is used as a fault detection indicator, i.e.,
the residual signal is used to detect whether a measurement
deviates too much from the predicted measurement. This
concludes the EKF algorithm. An illustrative example of the
residuals coming out of the algorithm is given in Fig. 6.
Herein, a bias anomaly is injected in the RSU and it can be
observed that the RSU residual is sensitive to this bias. As
mentioned before, the EKF generates a residual signal (10)
which gives information about the deviation of the predicted
measurement, calculated based on the predicted state ˆXk|k−1
and the measurement model with the measurements uk. A
next layer of residual evaluation is needed. The residual

evaluation is done using a L2 norm-based detector of the
form

ˆrk =

1
n

k
(cid:88)

i=k−n

ri ◦ ri,

(13)

where the operator ◦ represents the pointwise Hadamard
product. Each entry of the resulting vector of signals ˆrk
is compared with a pre-deﬁned positive-valued threshold
vector α(j) of which the size is equal to the number of
measured states per measurement of each respective sensor
j. Subsequently, given a predetermined time horizon n, an
appropriate reaction is given using the indicator function εk,

ˆr(j)
i,k ≤ α(j)
ˆr(j)
i,k > α(j)

i

i

No fault detected
−−−−−−−−−→ ε(j)
Fault detected
−−−−−−−→ ε(j)

i,k = 0,

i,k = 1,

∀i, j,

(14)

where i selects the index of the measurement state. The reac-
tion of a detected fault appears directly in the equations (8)
and (9), where the affected measurement state is no longer
taken into account in the update step (11), (12). However,
the affected measurement is taken into account in (10) as
to detect whether a fault is still present or not.

V. RESULTS ANALYSIS

As mentioned in Section III, in order to benchmark the
performance of the anomaly detection algorithm, simulations
are carried out with anomalies of varying size and duration.
For the instant anomaly, an anomaly size eI
x is chosen
following a logarithmic distribution of 10 samples between
0.1 m and 10 m. The duration of the instant anomaly is
d = 0.05 s. This results in a total of 10 tests for evaluation
of the algorithm in the case of instant anomalies.
For the bias anomaly, an anomaly size eB

x is chosen fol-
lowing a logarithmic distribution of 5 samples between 0.1 m
and 3 m. A logarithmic distribution is chosen to determine
which order of magnitude for fault size can be ﬂagged by the
anomaly detector. Furthermore, the anomaly duration is var-
ied with the following variations: d = [0.25, 0.5, 1.0, 2.5] s.
This results in a total of 20 tests for evaluation of the
algorithm in the case of bias faults. For the drift anomaly,
an anomaly size eD
x is chosen again by following a loga-
rithmic distribution of 5 samples between 0.1 m/s and 3 m/s.
Furthermore, the anomaly duration is varied again with the
following variations: d = [0.25, 0.5, 1.0, 2.5] s. This results
in a total of 20 tests for evaluation of the algorithm in the
case of drift faults.

A. Statistical results

To test the performance and reliability of the fault detec-
tion algorithm, the tests introduced before are applied online
in the simulation environment. The initial state covariance
matrix and state are chosen as P0 = I, ˆX0 = 0. The
measurement noise covariance matrix R from (8) is chosen
by directly substituting squared of the measurement noises
deﬁned in (1). The process noise covariance matrix, Q,
from (7) is chosen as Q = 0.001 · I. The residual evaluation
horizon (13) is chosen as n = 30 and ﬁnally the evaluation

4041424344454647484950Time [s]-0.500.511.5Residual [m]ResidualofthepositionykstateRadarRSULidarCameraare being considered faulty due to their difference with the
internal state estimate. It is expected that this effect would
grow even further when losing sensor redundancy. In order
to test this hypothesis, the matrix is retested without the
lidar and radar sensor measurements, using the same initial
conditions and parameters as in Section V-A. The results of

thresholds (14) are chosen to be equal to αx = αy = αθ =
0.18 for all position states and αvx = αvy = αvθ = 0.7
for all velocity states. These threshold have been determined
iteratively using the magnitude of the noise as a starting
point. Using these parameters and initial conditions,
the
results are given in Fig. 7. This type of ﬁgure is interpreted
as follows; faults are injected of certain type (bias, drift
or instant) with a certain magnitude (y-axis) and a certain
duration (x-axis). If the injected fault (blue star) is detected,
it is marked (red circle). If a fault is detected on a sensor
for which no fault is injected, it is marked as false positive
(green circle). Using this graphical representation, it becomes
straightforward to observe the actual fault, whether it was
detected or not and whether any false positives on other
sensors occurred.

Fig. 8. Results of the fault detection performance and reliability without
radar and lidar redundancy, 68% true positive, 22% false positive

this analysis are shown in Fig. 8. Here, one can observe that
the cumulative sum of the false positive detection increases.
This can be explained by the fact that there are only two
sensors that construct the internal state estimate, ˆXk, and as
such the error between ˆXk and the healthy measurements
increase as well. In comparison with the full redundancy-
case however, the number of true positives only decreased
by 4%, showing robustness of the algorithm for true positive
detection in the case of loss of redundancy.

C. Discussion

Detecting anomalies from external sensors as deﬁned here
does not offer information nor does it determine the cause
of the fault (i.e., fault classiﬁcation). The primary interest
here was to detect the fault and as a mitigating action, to no
longer incorporate the affected state in the sensor fusion. It
depends on the safety criticality of the function whether the
driver of the vehicle should be made aware of the cause of
a fault.

The external observed object, is only observed using the
vehicle’s sensors and sensors from the road infrastructure,
while its intention and actual movement are unknown (no
sensors are present on this external object). This implies
that, to have a reliable fault detection algorithm, a degree of
sensor redundancy is required which is a limitation of this
algorithm. By using all these sensors to predict the same
internal state of the externally observed object, the internal
state estimate can be pushed off its true trajectory by a
fault with sufﬁcient amplitude. Nonetheless, it is possible
that this problem can be circumvented by augmenting the
model with predicted or known intentions of the externally
observed object.

VI. CONCLUSIONS AND FUTURE WORK

The contribution of this work is twofold. The anomaly
detection algorithm introduced here provides insights into
types of attacks from
the possibility to detect different

Fig. 7.
robustness, 72% true positive, 6% false positive

Results of the fault detection performance and false positive

These results show that the fault detection algorithm is
able to detect 72% of the injected faults, where in 6% of
the test cases a false positive is also detected on a different
sensor measurement state. The undetected faults either have
a too low maximum value (effect of threshold α, preventing
noise on the residual to be classiﬁed as a fault), or the fault
duration is too short (ﬁltering effect of the fault horizon n).
The false positives that are detected at high amplitudes of
faults are caused by the combined internal estimate, ˆXk,
being pushed up due to the faulty measurement before it
is being disregarded. This phenomenon causes a discrepancy
between the internal estimate and the healthy sensors, hence
potentially classifying them as faulty.

B. Case-study when losing sensor redundancy

The results from Section V-A show that the algorithm is
able to detect faults above a certain uncertainty threshold
very well. This threshold, determined by α, could be set
lower, yet that is not desirable since it would compromise
robustness as the remaining noise in the residual could induce
false positives. However, it also shows that the algorithm
starts detecting false positives for high fault amplitudes. The
faulty measurements are not detected instantaneously due
to the ﬁltering effect of the EKF as well as the estimation
horizon n of the residual evaluation. Therefore, the faulty
measurement is used for a certain time to update the internal
state estimate.

For a sufﬁciently high fault, the state estimate temporarily
increases up to such an extent, that non-faulty measurements

0204060Fault duration [epoch]10-1100101Fault amplitude [m]Bias fault0204060Fault duration [epoch]10-1100101Fault slope [m/s]Drift fault012Fault duration [epoch]10-1100101Faultamplitude[m]Instant faultInjected faultsTrue positiveFalse positive0204060Fault duration [epoch]10-1100101Fault amplitude [m]Bias fault0204060Fault duration [epoch]10-1100101Fault slope [m/s]Drift fault012Fault duration [epoch]10-1100101Faultamplitude[m]Instant faultInjected faultsTrue positiveFalse positivethe automated vehicle’s point of view, in I2V-enabled road
intersections. The results show that majority of relevant and
potentially dangerous anomalies can be detected, especially
if the fault magnitude is limited and in-vehicle sensor re-
dundancy exists. In addition, the results show the beneﬁts of
having sensor redundancy for object tracking and the limi-
tation when this does not exist. This implies the automated
vehicle can maintain a safe and comfortable operation even
in the face of I2V cyber-attacks. This methodology, used to
detect attacks in the I2V communication can, be applied on
detecting in-vehicle sensor anomalies as well, using a fusion
of in-vehicle and I2V sensor data.

Future work includes the extension towards more sce-
narios, investigating robustness to network effects (delays,
package drop), incorporating more I2V signals (e.g. trafﬁc
light information) and incorporating the EKF anomaly de-
tection method with the vehicle control mitigation strategies
for cases where the anomalies can be detected. Furthermore,
the extension of the method with data-driven methods can be
considered to improve the false positive and false negative
rates in case of large faults amplitudes.

VII. ACKNOWLEDGMENTS

This work is supported by EU Horizon 2020 R&D
programme under grant agreement No. 783119, project
SECREDAS (Product Security for Cross Domain Reliable
Dependable Automated Systems).

REFERENCES

[1] E. van Nunen, M. Kwakkernaat, J. Ploeg, and B.
Netten, “Cooperative competition for future mobility,”
IEEE Transactions on Intelligent Transportation Sys-
tems, vol. 13, no. 3, pp. 1018–1025, 2012.

[2] S. Checkoway, D. McCoy, B. Kantor, D. Anderson,
H. Shacham, S. Savage, K. Koscher, A. Czeskis, F.
Roesner, and T. Kohno, “Comprehensive experimental
analyses of automotive attack surfaces,” in USENIX
Security Symposium, 2011.
I. 26262-1, Road vehicles - functional safety. Geneva,
Switzerland: International organization for standard-
ization, 2011.

[3]

[4] M. Bhuyan, D. Bhattacharyya, and J. Kalita, “Network
anomaly detection: Methods, systems and tools,” IEEE
Communications Surveys Tutorials, vol. 16, no. 1,
pp. 303–336, 2014.

[5] O. Grembek, A. Kurzhanskiy, A. Medury, P. Varaiya,
and M. Yu, “Making intersections safer with i2v com-
munication,” Elsevier: Transportation Research Part
C: Emerging Technologies, vol. 102, pp. 396–410,
May 2019.

[6] Y. Wang, N. Masoud, and A. Khojandi, “Real-time
sensor anomaly detection and recovery in connected
automated vehicle sensors,” IEEE transactions on
intelligent transportation systems, Nov. 2019.

[7] E. Lampiri, “Sensor anomaly detection and recovery
in a nonlinear autonomous ground vehicle model,” in
Asian Control Conference, 2017, pp. 430–435.

[8]

J. Park, R. Ivanov, J. Weimer, M. Pajic, and I. Lee,
“Sensor attack detection in the presence of transient
faults,” in Proceedings of the ACM/IEEE Int. Confer-
ence on Cyber-Physical Systems, 2015, 1–10.

[9] F. van Wyk, Y. Wang, A. Khojandi, and N. Masoud,
“Real-time sensor anomaly detection and identiﬁca-
tion in automated vehicles,” IEEE Transactions on
Intelligent Transportation Systems, pp. 1–13, 2019.

[10] N. Negi, O. Jelassi, H. Chaouchi, and S. Clemençon,
“Distributed online data anomaly detection for con-
nected vehicles,” in International Conference on Arti-
ﬁcial Intelligence in Information and Communication,
2020, pp. 494–500.

[11] S. Panda, I. Oliver, and S. Holtmanns, “Behavioural
modelling of attackers’ choices,” in Asian Control
Conference, Jun. 2018, pp. 119–126.

[12] Y. Luo, A. Saberi, T. Bijlsma, J. Lukkien, and M.
van den Brand, “An architecture pattern for safety
critical automated driving applications: Design and
analysis,” in IEEE International Systems Conference,
2017, pp. 1–7.

[13] A. Khabbaz Saberi, “Functional safety: A new archi-
tectural perspective: Model-based safety engineering
for automated driving systems,” Ph.D. dissertation,
2020.

[14] A. Sharma, L. Golubchik, and R. Govindan, “Sensor
faults detection methods and prevalence in real-world
datasets,” TOSN, vol. 6, Jan. 2010.

[15] S. K. Khan, N. Shiwakoti, P. Stasinopoulos, and
Y. Chen, “Cyber-attacks in the next-generation cars,
mitigation techniques, anticipated readiness and future
directions,” Accident Analysis & Prevention, vol. 148,
p. 105 837, 2020, ISSN: 0001-4575.
J. Petit and S. Shladover, “Potential cyberattacks on
automated vehicles,” IEEE transactions on intelligent
transportation systems, Sep. 2014.

[16]

[17] Y. Mo, E. Garone, A. Casavola, and B. Sinopoli,
“False data injection attacks against state estimation
in wireless sensor networks,” IEEE conference on
Decision and Control, Dec. 2010.

[18] N. Koenig and A. Howard, “Design and use paradigms
for gazebo, an open-source multi-robot simulator,”
IEEE/RSJ International Conference on Intelligent
Robots and Systems, Sep. 2004.

[19] M. Dupuis, M. Strobl, and H. Grezlikowski, “Open-
drive 2010 and beyond – status and future of the de
facto standard for the description of road networks,”
Driving Simulation Conference Europe, pp. 231–242,
2010.

[20] ASAM,

Asam

openscenario
https://www.asam.net/project-detail/asam-
openscenario-v1x/ (Accessed: 2020-10-23), 2020.

v1.x,

[21] F. de Ponte Müller, “Survey on ranging sensors and
cooperative techniques for relative positioning of ve-
hicles,” Sensors, vol. 17, no. 2, 2017.

[22] S. Ding, Model-based fault diagnosis techniques: De-
sign schemes, algorithms, and tools. Springer Berlin
Heidelberg, 2008, pp. 1–473.

