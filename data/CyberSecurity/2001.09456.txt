1
2
0
2

y
a
M
1
2

]
P
A

.
t
a
t
s
[

3
v
6
5
4
9
0
.
1
0
0
2
:
v
i
X
r
a

Graph link prediction in computer networks
using Poisson matrix factorisation

Francesco Sanna Passino†, Melissa J. M. Turcotte‡∗ ,
and Nicholas A. Heard†

† – Department of Mathematics, Imperial College London
‡ – Advanced Research in Cyber-Systems, Los Alamos National Laboratory

Abstract: Graph link prediction is an important task in cyber-security: relationships
between entities within a computer network, such as users interacting with computers,
or system libraries and the corresponding processes that use them, can provide key
insights into adversary behaviour. Poisson matrix factorisation (PMF) is a popular
model for link prediction in large networks, particularly useful for its scalability. In
this article, PMF is extended to include scenarios that are commonly encountered in
cyber-security applications. Speciﬁcally, an extension is proposed to explicitly handle
binary adjacency matrices and include known categorical covariates associated with
the graph nodes. A seasonal PMF model is also presented to handle seasonal networks.
To allow the methods to scale to large graphs, variational methods are discussed for
performing fast inference. The results show an improved performance over the standard
PMF model and other statistical network models.

MSC 2010 subject classiﬁcations: Primary 90B15; secondary 62M20, 62P30.
Keywords and phrases: anomaly detection, dynamic networks, new link prediction,
Poisson matrix factorisation, statistical cyber-security, variational inference.

1. Introduction

In recent years, there has been a signiﬁcant increase in investment from both government and
industry in improving cyber-security using statistical and machine learning techniques on a
wide range of data collected from computer networks (Heard et al., 2018; Jeske et al., 2018).
One signiﬁcant research challenge associated with these networks is link prediction, deﬁned
as the problem of predicting the presence of an edge between two nodes in a network graph,
based on observed edges and attributes of the nodes (Liben-Nowell and Kleinberg, 2007).
Adversaries attacking a computer network often aﬀect relationships (links) between nodes
within these networks, such as users authenticating to computers, or clients connecting to
servers. New links (previously unobserved relationships) are of particular interest, as many
attack behaviours such as lateral movement (Neil et al., 2013), phishing, and data retrieval,
can create new edges between network entities (Metelli and Heard, 2019). In practical cyber
applications, it is necessary to use relatively simple and scalable statistical methods, given
the size and inherently dynamic nature of these networks.

Away from cyber applications, the link prediction problem has been an active ﬁeld of
research (see, for example, Dunlavy, Kolda and Acar, 2011; L¨u and Zhou, 2011; Menon and
Elkan, 2011), being similar, especially in its static formulation, to recommender systems
(Adomavicius and Tuzhilin, 2005). Static link prediction (for example, Clauset, Moore and

∗The author is currently at Microsoft 365 Defender, Microsoft Corporation. This work was completed

while the author was at the Los Alamos National Laboratory.

1

 
 
 
 
 
 
Sanna Passino, Turcotte and Heard/Graph link prediction in computer networks using PMF

2

Newman, 2008) aims at ﬁlling in missing entries in a single incomplete graph adjacency ma-
trix, as opposed to temporal link prediction (for example, Dunlavy, Kolda and Acar, 2011),
which aims at predicting future snapshots of the graph given one or more fully observed
snapshots. Static link prediction problems have been successfully tackled using probabilistic
matrix factorisation methods, especially classical Gaussian matrix factorisation (Salakhut-
dinov and Mnih, 2007), and are currently widely used in the technology industry (see, for
example, Agarwal, Zhang and Mazumder, 2011; Khanna et al., 2013; Paquet and Koenigstein,
2013). For dyadic count data, Poisson matrix factorisation (PMF) (Canny, 2004; Dunson and
Herring, 2005; Cemgil, 2009; Gopalan, Hofman and Blei, 2015) emerged as a suitable model
in the static link prediction framework. This work mainly focuses on temporal link predic-
tion, showing that PMF is also useful for link prediction in this context, and it seems to be
particularly well-suited for cyber-security applications.

The methodological contribution of this article is to present extensions of the PMF model,
suitably adapted to scenarios which are commonly encountered in cyber-security computer
network applications. Traditionally, Poisson matrix factorisation methods are used on par-
tially observed adjacency matrices of natural numbers representing, for example, ratings of
movies provided by diﬀerent users. In computer networks, the matrix is fully observed, and
the counts associated with network edges are complicated by repeated observations, polling at
regular intervals, and the intrinsic burstiness of the events (Heard, Rubin-Delanchy and Law-
son, 2014). Hence, each edge is usually represented by a binary indicator expressing whether
at least one connection between the corresponding nodes was observed. Consequently, the
standard PMF model, where counts associated with links are assumed to follow a Poisson
distribution with unbounded support, cannot be applied directly. Instead, indicator func-
tions are applied, leading to an extension for PMF on binary adjacency matrices. Next, a
framework for including categorical covariates within the PMF model is introduced, which
also allows for modelling of new nodes appearing within a network. Finally, extensions of the
PMF model to incorporate seasonal dynamics are presented.

The rest of the article is organised as follows: Section 2 presents the computer network
data which are to be analysed. Section 3 formally introduces Poisson matrix factorisation
for network link prediction, and Section 4 discusses the proposed PMF model for binary
matrices and labelled nodes. A seasonal extension is described in Section 5. Finally, results
of the analysis are presented in Section 6.

2. LANL computer network data

The methodologies in this article have been developed to provide insight into authentication
data extracted from the publicly released “Uniﬁed Host and Network Dataset” from Los
Alamos National Laboratory (LANL) (Turcotte, Kent and Hash, 2018).

The data contain authentication logs collected over a 90-day period from computers in the
Los Alamos National Laboratory enterprise network running a Microsoft Windows operating
system. An example record is:

{"UserName": "User865586", "EventID": 4624, "LogHost": "Comp256596",

"LogonID": "0x5aa8bd4", "DomainName": "Domain001",
"LogonTypeDescription": "Network", "Source": "Comp782342",
"AuthenticationPackage": "Kerberos", "Time": 87264, "LogonType": 3}.

Sanna Passino, Turcotte and Heard/Graph link prediction in computer networks using PMF

3

From each authentication record, the following ﬁelds are extracted for analysis: the user
credential that initiated the event (UserName), the computer where the authentication origi-
nated (Source), and the computer the credential was authenticating to (most often LogHost).
Two bipartite graphs are then generated: ﬁrst, the network users and the computers from
which they authenticate, denoted User – Source; second, the same users and the comput-
ers or servers they are connecting to, denoted User – Destination. The two graphs are ﬁrst
analysed separately, before a joint model is explored.

As generic notation, let G = (U, V, E) represent one of these bipartite graphs, where
U = {u1, u2, . . .} is the set of users and V = {v1, v2, . . .} a set of computers (sometimes
referred to as hosts). The set E ⊆ U × V represents the observed edges, such that (u, v) ∈ E
if user u ∈ U connected to host v ∈ V in a given time interval. A ﬁnite set of edges E can be
represented as a rectangular |U | × |V | binary adjacency matrix A, where Aij = 1E{(ui, vj)}.
Importantly, some additional node-level categorical covariates were also available for this
analysis. Six covariates were obtained for the users, corresponding to position within the
hierarchy of the organisation as well as location and job category. For the computer hosts,
three covariates were available, relating to the machine type, subnet and location within the
organisation. To preserve privacy these covariates are anonymised in this study.

In total, there are K = 1,064 factor levels available for the user credentials and H = 735
factor levels for the computers. One objective of this article is to present methodology for
incorporating such covariates within Poisson matrix factorisation. Within cyber-security,
the availability of the LANL network with covariates is particularly signiﬁcant, since the
lack of appropriate datasets has been identiﬁed as one of the main limitations to widespread
applications of data science methods to cyber-security problems (Kumar, Wicker and Swann,
2017; Anderson et al., 2018; Amit et al., 2019).

As mentioned in Section 1, for cyber-security applications it would be valuable to ac-
curately predict and assess the signiﬁcance of new links. Importantly, many new links are
formed each day as part of normal operating behaviour of a computer network; to demon-
strate this, Figure 1 shows the the total number of edges formed each day and the proportion
of those that are new for the User – Source and User – Destination graphs. Even though
the relative percentage is small, this would still provide many more alerts than could be
practically acted upon each day.

3. Background on Poisson matrix factorisation

Let N ∈ N|U |×|V | be a matrix of non-negative integers Nij. For recommender system appli-
cations, Nij could represent information about how a user i rated an item j, or a count of
the times they have clicked on or purchased the item. The cyber-security application has a
major diﬀerence: in recommender systems, if user i never interacted with the item j, then
Nij is considered as a missing observation, implying that the that the number of observations
is a possibly very small fraction of |U ||V |. On the other hand, in cyber-security, the absence
of a link from i to j is itself an observation, namely Nij = 0, and |U ||V | data points are
observed. Such a diﬀerence has practical consequences, particularly regarding scalability in
cyber-security of models borrowed from the recommender systems literature.

The hierarchical Poisson factorisation model (Gopalan, Hofman and Blei, 2015) speciﬁes
a distribution for Nij using a Poisson link function with rate given by the inner product
between user-speciﬁc latent features αi ∈ RR
+, for

+ and host-speciﬁc latent features βj ∈ RR

Sanna Passino, Turcotte and Heard/Graph link prediction in computer networks using PMF

4

Fig 1: Number of links per day (top), and proportion of those that are new (bottom), after 20 days of
observation of the LANL computer network. Solid red curve: User – Source. Dashed blue curve: User –
Destination.

a positive integer R ≥ 1:

Nij ∼ Pois(α

(cid:124)
i βj) = Pois

(cid:33)

αirβjr

.

(cid:32) R
(cid:88)

r=1

(3.1)

If two latent features are close in the latent space, the corresponding nodes are expected
to exhibit similar connectivity patterns. The speciﬁcation of the model is completed with
gamma hierarchical priors:

i

αir ∼ Γ(a(α), ζ (α)
βjr ∼ Γ(a(β), ζ (β)
i ∼ Γ(b(α), c(α)), ζ (β)
ζ (α)

j

), i = 1, . . . , |U |, r = 1, . . . , R,

), j = 1, . . . , |V |, r = 1, . . . , R,

j ∼ Γ(b(β), c(β)).

(3.2)

Each of the gamma distribution parameters a(α), b(α), c(α), a(β), b(β), c(β) are positive real
numbers which must be speciﬁed.

In the cyber-security context there are no missing observations in the matrix N. Conse-
quently, an advantage of PMF over other models for link prediction (for example, Salakhut-
dinov and Mnih, 2007) is that the likelihood function only depends on the observed links,
meaning evaluating the likelihood is (cid:79)(nnz(N)), where nnz(·) is the number of non-zero el-
ements in the matrix, compared to (cid:79)(|U ||V |) for most statistical network models. In cyber-
security, networks tend to be very large in the number of nodes, but extremely sparse:
nnz(N) (cid:28) |U ||V |. Hence, PMF appears to be a particularly appealing modelling framework
for this application.

The PMF model has been used as a building block for multiple extensions. For exam-
ple, Chaney, Blei and Eliassi-Rad (2015) developed social Poisson factorisation to include

100002000030000400000.0000.0250.0500.0750.1000.1252126313641465156616671768186DayNumberofedgesProportionofnewedgesSanna Passino, Turcotte and Heard/Graph link prediction in computer networks using PMF

5

latent social inﬂuences in personalised recommendations. Gopalan, Charlin and Blei (2014)
developed collaborative topic Poisson factorisation, which adds a document topic oﬀset to
the standard PMF model to provide content-based recommendations and thereby tackle the
challenge of recommending new items, referred to in the literature as cold starts. These
ideas of combining collaborative ﬁltering and content-based ﬁltering are further developed in
Zhang and Wang (2015), Singh and Gordon (2008) and da Silva, Langseth and Ramampiaro
(2017), where social inﬂuences are added as constraints in the latter.

In general, most PMF-based methods presented in this section model binary adjacency
matrices using the Poisson link function for convenience. This approach is computationally
advantageous, but implies an incorrect model for the range: the entries Aij of the adjacency
matrix are binary, whereas the Poisson distribution has support over the natural numbers.
It must be noted that many other models besides PMF have been proposed in the literature
to tackle the link prediction task and for graph inference. Comprehensive surveys of the most
popular statistical network models are given in Goldenberg et al. (2010) and Fienberg (2012).
The problem of link prediction is also studied in other disciplines, for example physics (L¨u
and Zhou, 2011), or computer science, where graph neural networks (Zhang and Chen, 2018;
Wu et al., 2020) have recently gained popularity. The model presented in this article can
be classiﬁed as a latent feature model (LFM, Hoﬀ, Raftery and Handcock, 2002). For a
bipartite graph G = (U, V, E) with adjacency matrix A, the LFM assumes that the nodes
have R-dimensional latent representations ui ∈ RR, i ∈ U and vj ∈ RR, j ∈ V . The entries
of the adjacency matrix are then obtained independently as P(Aij = 1) = κ(ui, vj), where
κ : RR × RR → [0, 1] is a kernel function. A popular special case of LFM is the random dot
product graph (RDPG, Athreya et al., 2018), where κ(·) is chosen to be the inner product
between the latent positions. The extended PMF model proposed in this article is also a
special case of LFM, assuming a particular form of kernel function with nodal covariates.

Dynamical extensions to PMF have also been studied. Charlin et al. (2015) use Gaussian
random walk updates on the latent features to dynamically correct the rates of the Poisson
distributions. Schein et al. (2015, 2016) propose a temporal version of PMF using the two
main tensor factorisation algorithms: canonical polyadic and Tucker decompositions. Hos-
seini et al. (2018) combine the PMF model with the Poisson process to produce dynamic
recommendations. Dynamic network models have also been widely studied outside the do-
main of matrix factorisation techniques (for a survey, see Kim et al., 2017). For example,
Sewell and Chen (2015) extend LFMs to a temporal setting. The dynamic models described
above could handle generic network dynamics, but seasonality, a special case of temporal
structure, has not been explicitly accounted for in the PMF literature. This article further
aims to ﬁll this gap and propose a viable seasonal PMF model.

4. PMF with labelled nodes and binary adjacency matrices

Suppose that there are K covariates associated with each user and H covariates for each
host. Let the value of the covariate k for user i be denoted as xik. Similarly, let the value of
the covariate h for host j be yjh. In cyber-security applications, most available information
types are categorical, indicating memberships of known groupings or clusters of nodes. For
the remaining of this article, the covariates will be assumed to be binary indicators represent-
ing categorical variables. This type of encoding of categorical variables is commonly known
in the statistical literature as dummy variable encoding, whereas the term one-hot encoding

Sanna Passino, Turcotte and Heard/Graph link prediction in computer networks using PMF

6

is used in the machine learning community. Several approaches for including nodal covariates
in recommender systems using non-probabilistic matrix factorisation methods such as the
Singular Value Decomposition (SVD) have been discussed in the literature (for some exam-
ples, see Nguyen and Zhu, 2013; Fithian and Mazumder, 2018; Dai et al., 2019). Regression
methods for network data with covariates are also studied in Hoﬀ (2005). In Section 1 and 3,
it has been remarked that, for binary adjacency matrices, the standard PMF model for count
data cannot be applied directly, since the observations are binary, whereas the Poisson dis-
tribution has support on the natural numbers. To model binary links, it is assumed here
that the count Nij is a latent random variable, and the binary indicator Aij = 1N+(Nij) is
a censored Poisson draw with a corresponding Bernoulli distribution. This type of link has
been referred to in the literature as the Bernoulli-Poisson (BerPo) link (Acharya et al., 2015;
Zhou, 2015). The full extended model is

Aij|Nij = 1N+(Nij),

Nij|αi, βj, Φ ∼ Pois (cid:0)α
(cid:32) R
(cid:88)

(cid:124)
i βj + 1

(cid:124)
K(Φ (cid:12) xiy
H
K
(cid:88)
(cid:88)

= Pois

αirβjr +

(cid:124)
j )1H

(cid:1)

(cid:33)

φkhxikyjh

,

(4.1)

r=1

k=1

h=1

where 1n is a vector of n ones, (cid:12) is the Hadamard element-wise product, and xi and yj are
K and H-dimensional binary vectors of covariates. The R-dimensional latent features αi and
βj appear in the traditional PMF model given in (3), and Φ = {φkh} ∈ RK×H
is a matrix
+
of interaction terms for each combination of the covariates. Under model (4),

P(Aij = 1) = 1 − exp

−

(cid:32)

R
(cid:88)

r=1

αirβjr −

K
(cid:88)

H
(cid:88)

k=1

h=1

(cid:33)

φkhxikyjh

.

(4.2)

To provide intuition for these extra terms, assume for the cyber-security application that
a binary covariate for job title manager is provided for the users, and that a binary covariate
for the location research lab for the hosts. If user i is a manager and host j is located in
(cid:124)
a research lab, then φkh expresses a correction to the rate α
i βj for a manager connecting
to a machine in a research lab. The covariate term is inspired by the bilinear mixed-eﬀects
models for network data in Hoﬀ (2005).

The same hierarchical priors (3) are used for αi and βj and the following prior distribution

completes the speciﬁcation of the model:

φkh|ζ (φ) ∼ Γ(a(φ), ζ (φ)), k = 1, . . . , K, h = 1, . . . , H,

ζ (φ) ∼ Γ(b(φ), c(φ)).

Note that this model provides a natural way for handling what the literature commonly
refers to as cold starts, where new users or hosts appear in the network. Provided that
covariate-level information is known about new entities, then the estimates for Φ can be
used to make predictions about links where αi and βj for new user i or new host j could be
initialised from the prior or some other global statistic based on other users and hosts.

Another signiﬁcant advantage of the model proposed in (4) is that the likelihood is
(cid:79)(nnz(A)), analogously to the standard PMF model in (3), implying that the model scales

Sanna Passino, Turcotte and Heard/Graph link prediction in computer networks using PMF

7

well to large sparse networks. From (4):

log L(A) =

(cid:88)

log (cid:0)eψij − 1(cid:1) −

i,j:Aij >0

(cid:32)

(cid:88)

(cid:33)(cid:124) 


(cid:88)

αi

i

j



βj

 −

K,H
(cid:88)

k,h

φkh ˜xk ˜yh,

where ψij = α

(cid:124)
i βj + 1

(cid:124)
K(Φ (cid:12) xiy

(cid:124)

j )1H , ˜xk = (cid:80)|U |

i=1 xik, and ˜yh = (cid:80)|V |

j=1 yjh.

4.1. Bayesian inference

Given an observed matrix A, inferential interest is on the marginal posterior distributions of
the parameters αi and βj for all the users and hosts, and the parameters Φ for the covariates,
since these govern the predictive distribution for the edges observed in the future.

A common approach for performing inference is adopted, where additional latent variables
are introduced. Given the (assumed) unobserved count Nij, a further set of latent counts
Zijl, l = 1, . . . , R + KH, are used to represent the contribution of each component l to the
total latent count, such that Nij = (cid:80)
l Zijl. For l ≤ R, Zijl ∼ Pois(αilβjl). Otherwise, l
refers to a (k, h) covariate pair, and Zijl ∼ Pois(φkh). This construction ensures that Nij has
precisely the Poisson distribution speciﬁed in (4).

Inference using Gibbs sampling is straightforward, as the full conditionals all have closed
form expressions, but sampling-based methods do not scale well with network size. In-
stead, a variational inference procedure is proposed. Variational inference schemes have al-
ready been commonly and successfully used in the literature for network models (Nakajima,
Sugiyama and Tomioka, 2010; Seeger and Bouchard, 2012; Salter-Townshend and Murphy,
2013; Hern´andez-Lobato, Houlsby and Ghahramani, 2014), despite the issue of introducing
bias and potentially reducing estimation accuracy, in particular on the posterior variability
(see, for example, Huggins et al., 2019).

Gibbs sampling also presents an additional diﬃculty in PMF models: the inner product
(cid:124)
(cid:124)
i βj is invariant to permutations of the latent features. In particular, (Qαi)(cid:124)(Qβj) = α
α
i βj
for any permutation matrix Q ∈ RR×R, which makes the posterior invariant under such
transformation. This implies that the posterior is highly multimodal, a well-known burden
for MCMC-based inference in Bayesian factor models (Papastamoulis and Ntzoufras, 2020).
Hence, parameter estimates obtained as averages from MCMC samples from the posterior
could be meaningless, since the algorithm could have switched among diﬀerent modes. On
the other hand, variational inference is well understood to be a “mode-seeking” algorithm,
a desirable property for this problem. A practical comparison of the estimates of the inner
products for prediction purposes will be brieﬂy illustrated in Section 6.2.

4.2. Variational inference

Variational inference (see, for example, Blei, Kucukelbir and McAuliﬀe, 2017) is an optimisa-
tion based technique for approximating intractable distributions, such as the joint posterior
density p(α, β, Φ, ζ, N, Z|A), with a proxy q(α, β, Φ, ζ, N, Z) from a given distributional
family (cid:81), and then ﬁnding the member q(cid:63) ∈ (cid:81) that minimises the Kullback-Leibler (KL)
divergence to the true posterior. Usually the KL-divergence cannot be explicitly computed,

Sanna Passino, Turcotte and Heard/Graph link prediction in computer networks using PMF

8

and therefore an equivalent objective, called the evidence lower bound (ELBO), is maximised
instead:

ELBO(q) = Eq[log p(α, β, Φ, ζ, N, Z, A)] − Eq[log q(α, β, Φ, ζ, N, Z)],

(4.3)

where the expectations are taken with respect to q(·). The proxy distribution q(·) is usually
chosen to be of much simpler form than the posterior distribution, so that maximising the
ELBO is tractable. As in Gopalan, Hofman and Blei (2015) the mean-ﬁeld variational family
is used, where the latent variables in the posterior are considered to be independent and
governed by their own distribution, so that:

q(α, β, ζ, Φ, N, Z) =

(cid:89)

q(αir|λ(α)

ir , µ(α)

ir ) ×

q(βjr|λ(β)

jr , µ(β)
jr )

(cid:89)

j,r

q(φkh|λ(φ)

kh , µ(φ)

kh ) ×

i,r
(cid:89)

i

×

(cid:89)

k,h

q(ζ (α)
i

|ν(α)
i

, ξ(α)
i

) ×

q(ζ (β)
j

|ν(β)
j

, ξ(β)
j

)

(cid:89)

j

×q(ζ (φ)|ν(φ), ξ(φ)) ×

(cid:89)

i,j

q(Nij, Zij|θij, χij).

(4.4)

The objective function (4.2) is optimised using coordinate ascent mean ﬁeld variational in-
ference (CAVI), whereby each density or variational factor is optimised while holding the
others ﬁxed (see Bishop, 2006; Blei, Kucukelbir and McAuliﬀe, 2017, for details). Using this
algorithm the optimal form of each variational factor is:

q(cid:63)(vj) ∝ exp (cid:8)Eq

−j [log p(vj|v−j, A)](cid:9) ,

(4.5)

where vj is an element of a partition of the full set of parameters v, and the expectation
is taken with respect to the variational densities that are currently held ﬁxed for v−j, de-
ﬁned as v excluding the parameters in the subset vj. Convergence of the CAVI algorithm is
determined by monitoring the change in the ELBO over subsequent iterations.

Since the prior distributions are chosen to be conjugate, the full conditionals in (4.2) are
all available analytically. Full details are given in Appendix A. Also, since all the conditionals
are exponential families, each q(vj) obtained from (4.2) is from the same exponential family
(Blei, Kucukelbir and McAuliﬀe, 2017). Hence, with the exception of q(Nij, Zij|θij, χij), the
proxy distributions in (4.2) are all gamma; for example, q(αir|λ(α)
ir ). The
update equations for the parameters {λ, µ, ν, ξ, θ, χ} of the variational approximation can
be obtained using (4.2), which is eﬀectively the expected parameter of the full conditional
with respect to q. The full variational inference algorithm is detailed in Algorithm 1. Note
that each update equation only depends upon the elements of the matrix where Aij > 0,
providing computational eﬃciency for large sparse matrices. Further details concerning the
update equations for the Poisson and multinomial parameters θ and χ are also given in
Appendix B.

ir ) = Γ(λ(α)

ir , µ(α)

ir , µ(α)

4.3. Link prediction

Given the optimised values of the parameters of the variational approximation q(cid:63)(·) to the
posterior, a Monte Carlo posterior model estimate of P(Aij = 1) can be obtained by averaging

Sanna Passino, Turcotte and Heard/Graph link prediction in computer networks using PMF

9

Algorithm 1: Variational inference for binary PMF with covariates.
1 initialise λ, µ and ξ from the prior,
2 set ν(α)
i = b(α) + Ra(α), ν(β)
3 calculate ˜xk = (cid:80)|U |
4 repeat
5

i=1 xik, k = 1, . . . , K and ˜yh = (cid:80)|V |

j = b(β) + Ra(β), ν(φ) = b(φ) + KHa(φ),

for each entry of A such that Aij > 0, update the rate θij:

j=1 yjh,

θij =

R
(cid:88)

r=1

exp

(cid:110)
Ψ(λ(α)

ir ) − log(µ(α)

ir ) + Ψ(λ(β)

jr ) − log(µ(β)
jr )

(cid:111)

+

K
(cid:88)

H
(cid:88)

k=1

h=1

xikyjh exp

(cid:110)
Ψ(λ(φ)

kh ) − log(µ(φ)
kh )

(cid:111)

,

where Ψ(·) is the digamma function,
for each entry of A such that Aij > 0, update χijl:

6

χijl ∝






exp

(cid:110)
il ) − log(µ(α)
Ψ(λ(α)
(cid:110)
Ψ(λ(φ)

xikyjh exp

kh ) − log(µ(φ)
kh )

jl ) − log(µ(β)
il ) + Ψ(λ(β)
jl )
(cid:111)

(cid:111)

l ≤ R,

l > R,

where, for l > R, l corresponds to a covariate pair (k, h),

7

update the user-speciﬁc ﬁrst-level parameters:

λ(α)
ir = a(α) +

|V |
(cid:88)

j=1

Aijθijχijr
1 − e−θij

, µ(α)

ir =

ν(α)
i
ξ(α)
i

+

|V |
(cid:88)

j=1

λ(β)
jr
µ(β)
jr

,

8

update the host-speciﬁc ﬁrst-level parameters:

λ(β)
jr = a(β) +

|U |
(cid:88)

i=1

Aijθijχijr
1 − e−θij

, µ(β)

jr =

ν(β)
j
ξ(β)
j

+

|U |
(cid:88)

i=1

λ(α)
ir
µ(α)
ir

,

9

update the covariate-speciﬁc ﬁrst-level parameters:

λ(φ)
kh = a(φ) +

|U |,|V |
(cid:88)

i,j=1

Aijθijχijl
1 − e−θij

, µ(φ)

kh =

ν(φ)
ξ(φ) + ˜xk ˜yh,

10

update the second-level parameters:

ξ(α)
i = c(α) +

R
(cid:88)

r=1

λ(α)
ir
µ(α)
ir

, ξ(β)

j = c(β) +

R
(cid:88)

r=1

λ(β)
jr
µ(β)
jr

, ξ(φ) = c(φ) +

K,H
(cid:88)

k,h

λ(φ)
kh
µ(φ)
kh

.

11 until convergence;

Sanna Passino, Turcotte and Heard/Graph link prediction in computer networks using PMF

10

(4) over M samples from q(cid:63)(αir|λ(α)

ir , µ(α)

ir ), q(cid:63)(βjr|λ(β)

jr , µ(β)

ˆP(Aij = 1) = 1 −

1
M

M
(cid:88)

m=1



exp

−

R
(cid:88)

r=1

K,H
(cid:88)

h,k

ir β(m)
α(m)

jr −

φ(m)
kh xikyjh

 .

(4.6)

jr ), and q(cid:63)(φkh|λ(φ)
kh , µ(φ)
kh ):


Alternatively, a computationally fast way to approximate P(Aij = 1) plugs in the param-

eters of the estimated variational distributions:


˜P(Aij = 1|ˆαir, ˆβjr, ˆφkh) = 1 − exp

−

R
(cid:88)

r=1

ˆαir ˆβjr −

K,H
(cid:88)

h,k



ˆφkhxikyjh

 ,

(4.7)

ir /µ(α)

where, for example, ˆαir = λ(α)
ir , the mean of the gamma proxy distribution. Note that
(4.3) clearly gives a biased estimate, and by Jensen’s inequality ˆP(Aij = 1) ≤ ˜P(Aij = 1) in
expectation, but it carries a much lower computational burden. The approximation in (4.3)
has been successfully used for link prediction and network anomaly detection purposes in
Turcotte et al. (2016).

5. Seasonal PMF

The previous sections have been concerned with making inference from a single adjacency
matrix A. Now, consider observing a sequence of adjacency matrices A1, . . . , AT , represent-
ing snapshots of the same network over time. Further, suppose this time series of adjacency
matrices has seasonal dynamics with some known ﬁxed seasonal period, P ; for example, P
could be one day, one week or one year. To recognise time dependence, a third index t is
required, such that Aijt denotes the (i, j)-th element of the matrix At, t = 1, . . . , T .

As in Section 4, there are assumed to be underlying counts Nijt which are treated as latent
variables, and the sequence of observed adjacency matrices is obtained by Aijt = 1N+(Nijt).
To account for seasonal repetition in connectivity patterns, the model proposed for the latent
counts is:

Nijt ∼ Pois

(cid:32) R
(cid:88)

r=1

αirγit(cid:48)rβjrδjt(cid:48)r +

K
(cid:88)

H
(cid:88)

φkhxikyjh

(cid:33)

(5.1)

= Pois (cid:0)(αi (cid:12) γit(cid:48))

(cid:124)

k=1
(βj (cid:12) δjt(cid:48)) + 1

h=1
(cid:124)
K(Φ (cid:12) xiy

(cid:124)
j )1H

(cid:1) ,

where, for example, t(cid:48) = 1 + (t mod P ). In general, more complicated functions for t(cid:48) might
be required, as in Section 6.7.

The priors on αir and βjr are those given in (3); these parameters represent a baseline
level of activity, which is constant over time. The two additional parameters γit(cid:48)r and δjt(cid:48)r
represent corrections to these rates for seasonal segment t(cid:48) ∈ {1, . . . , P }. Note that for some
applications, it may be anticipated that there is a seasonal adjustment to the rate for the
interaction terms of the covariates, in which case temporal adjustments could be also added
to Φ. For identiﬁability, it is necessary to impose constraints on the seasonal adjustments so
that, for example, for all i, j, r, γi1r = δj1r = 1.

Sanna Passino, Turcotte and Heard/Graph link prediction in computer networks using PMF

11

For t(cid:48) > 1, the following hierarchical priors are placed on γit(cid:48)r and δjt(cid:48)r:

γit(cid:48)r ∼ Γ(a(γ), ζ (γ)
δjt(cid:48)r ∼ Γ(a(δ), ζ (δ)

t(cid:48) ), ζ (γ)
t(cid:48) ), ζ (δ)

t(cid:48) ∼ Γ(b(γ), c(γ)),
t(cid:48) ∼ Γ(b(δ), c(δ)).

Inference for the seasonal model can be performed following the same principles of Section
4.2; full details are given in Appendix C. The constraint is implemented in the variational
inference framework by setting the variational approximation to γi1r and δj1r to a delta
function centred at 1.

6. Results

The extensions to the PMF model detailed in Sections 4 and 5 are used to analyse the LANL
authentication data described in Section 2. In order to assess the predictive performance
of the models, the data are split into a training set corresponding to the ﬁrst 56 days of
activity, and a test set corresponding to days 57 through 82. During the latter time period,
LANL conducted a red-team exercise, where the security team test the robustness of the
network by attempting to compromise other network hosts; labels of known compromised
authentication events will be used for evaluating the model performance in anomaly detec-
tion. The parameters are estimated from the training set adjacency matrix, constructed by
setting Aij = 1 if a connection from user i to host j is observed during the training period,
and Aij = 0 otherwise. The predictive performance of the model is then evaluated on the
test set adjacency matrix, constructed similarly using the connections observed in the last
25 days.

Summary statistics about the data are provided in Table 1, where “cold starts” refer to
links originating from new users and hosts in the test data. Figure 2 shows binary heat
map plots of the adjacency matrices obtained from the training period for each the two
graphs, User – Source and User – Destination. In all analyses, variational inference is used
to estimate the parameters based on the the training data, with a threshold for convergence
being 10−5 for relative diﬀerence between two consecutive values of the ELBO (4.2). The
prior hyperparameters are set to a∗ = b∗ = 1 and c∗ = 0.1, although the algorithm is fairly
robust to the choice of these parameters. The number of latent features R = 20 and was
chosen using the criterion of the elbow in the scree-plot of singular values.

Table 1
Summary of training and test sets for User – Destination and User – Source.

User – Destination

User – Source

Training set

Test set

Training set

Test set

Users

Hosts

Links

New links

Cold starts

11,688

3,801

82,517

534 new

1,246 new

76,240

11,418

3,401

12,027

15,881

60,059

507 new

1,236 new

50,412

12,080

3,014

Sanna Passino, Turcotte and Heard/Graph link prediction in computer networks using PMF

12

6.1. Including covariates

Results are now presented for the extended PMF (EPMF) model, discussed in Section 4,
making use of the nodal covariates described in Section 2 relating to user roles and categories
of computers within the organisation. Performance is evaluated by the receiver operating
characteristic (ROC) curve and the corresponding area under the curve (AUC). The AUC is
used as a measure of quality of classiﬁcation and will allow for the predictive power of the
diﬀerent models to be ranked. Due to the large computational eﬀort of scoring all entries in
(cid:124)
(cid:124)
the adjacency matrix for EPMF, mostly due to the calculation of 1
j )1H , the AUC
K(Φ (cid:12) xiy
is estimated by subsampling the negative class at random from the zeros in the adjacency
matrix formed from the test data; the sample sizes is chosen to be three times the size of the
number of edges in the test set. In general, if the sample size is chosen to be at least on the
same order of magnitude as nnz(A), this procedure leads to reliable estimates of the AUC,
as demonstrated via simulation at the end of this subsection. The estimated AUC scores are
summarised in Table 2. For evaluating the AUC scores for new links (edges in the test set not
present in the training set), the negative class was also restricted to entries in the training
adjacency matrix for which Aij = 0.

Table 2 shows that the AUC for User – Destination does not change signiﬁcantly when
the extended model is used; however, for User – Source, the extended PMF model oﬀers
a signiﬁcant improvement. The diﬀerence in the results between the two networks can be
explained by the contrasting structures of the adjacency matrices. The edge density for User
– Destination is 0.184% and for User – Source, 0.031%. However, despite User – Destination

(a) User – Source

(b) User – Destination

Fig 2: Training set adjacency matrices for the two graphs (spy-plot). Nodes are sorted by in-degree and
out-degree.

Table 2
AUC scores for prediction of all and new links using standard and extended PMF. Number of latent
features: R = 20.

User – Destination

User – Source

PMF

EPMF

PMF

EPMF

All links

0.98479

0.98707

0.85797

0.96602

New links

0.95352

0.95474

0.89759

0.95260

020004000600080001000012000050001000015000UsersSource IPs0200040006000800010000120000100020003000UsersDestination IPsSanna Passino, Turcotte and Heard/Graph link prediction in computer networks using PMF

13

having a higher density, the links are concentrated on a small number of dominant nodes, as
can be seen in Figure 2b. Therefore, the prediction task is relatively easy: the probability of
a link is roughly approximated by a function of the degree of the node, and adding additional
information is not particularly beneﬁcial. For User – Source, as can be seen by Figure 2a,
the links are more evenly distributed between the nodes, and the prediction task is more
diﬃcult. Hence, in this setting, including additional information about known groupings, for
example the location of machines or job category of users, is crucial to improve the predictive
capability of the model. The ROC curves for the User – Source graph are shown in Figure 3.
Some of the covariates might be more predictive than others. To evaluate such diﬀerences,
the AUC for all links on User – Source have been recalculated excluding each user and host
covariate in turn. The diﬀerence between the AUC for EPMF ﬁtted with all the covariates,
and for EPMF with covariate k removed, could then be used to quantify the predictive power
of covariate k. According to this methodology, the most relevant user covariates are job title,
with a loss in AUC of 0.05442 when it is removed from the model, followed by location, with
a loss in AUC of 0.03001. Similarly, for the hosts, the most predictive covariates appear to
be location, with a loss in AUC of 0.05761, and subnet, with a loss in AUC of 0.03116.

In order to assess the accuracy of the AUC approximation obtained from a subsample
of the negative class, 500 simulations have been carried out. For standard PMF on User –
Destination, estimates of the AUC for all links across diﬀerent subsampled negative classes
had standard deviation ≈ 4.3 · 10−5 for a sample size of 3nnz(A). If nnz(A) or 0.1nnz(A) are
used, the standard deviation increases to ≈ 7.6 · 10−5 and ≈ 2.4 · 10−4 respectively, whereas
using 5nnz(A) gives a value of ≈ 3.5 · 10−5.

6.2. Comparison with Gibbs sampling

As discussed in Section 4.1, a possible drawback of variational inference is the introduction
of bias in the posterior estimates, in particular regarding the variability. Therefore, it is
necessary to assess the loss in predictive performance caused by switching to the proposed

Fig 3: ROC curves for standard PMF and extended PMF on User – Source, R = 20.

00.10.20.30.40.50.60.70.80.9100.20.40.60.81FalsepositiverateTruepositiverateAlllinks,PMFAlllinks,EPMFNewlinks,PMFNewlinks,EPMF00.10.20.30.40.50.60.70.80.9100.20.40.60.81FalsepositiverateTruepositiverateAlllinks,PMFAlllinks,EPMFNewlinks,PMFNewlinks,EPMFSanna Passino, Turcotte and Heard/Graph link prediction in computer networks using PMF

14

Table 3
AUC scores for prediction of all and new links using Gibbs sampling. Number of latent features: R = 20.

User – Destination

User – Source

PMF

EPMF

PMF

EPMF

All links

0.98737

0.98835

0.87130

0.95809

New links

0.94311

0.94768

0.83979

0.92723

variational approximation to the posterior. This task is not straightforward, since perform-
ing full Bayesian inference on the the standard PMF and EPMF model is computationally
extremely demanding when the graph is large, because many posterior samples (usually in
the order of tens of thousands) are required to conﬁdently estimate the parameters.

Appendix A gives details about the conditional distributions required to develop a Gibbs
sampler. Table 3 presents the results obtained from 10,000 posterior samples with burnin
1,000. The link probabilities have been estimated using the unbiased score (4.3). No issues
with convergence of the Markov chain were observed, and the performance seems comparable
to the results obtained using variational inference, demonstrating that the loss in performance
due to the variational approximation seems to be minimal.

It must be noted that variational inference converges in our application in less than 200
iterations. For example, for PMF on User – Source IP, the computation time is ≈ 4.5 seconds
per iteration on a MacBook Pro 2017 with a 2.3GHzIntel Core i5 dual-core processor. On
the other hand, Gibbs sampling, despite the lower cost of ≈ 2.6s per iteration, requires many
more posterior samples. Hence, the computational advantages guaranteed by the variational
inference procedure are particularly relevant in this context.

6.3. Cold starts

As discussed in Section 4, the extended PMF model allows for prediction of new entities or
nodes in the network (cold starts). To assess performance on links in the test set involving
new users or hosts, the estimates of the covariate coeﬃcients ˆφkh = λ(φ)
kh from the
training period are used. The latent feature values are set equal to the mean of all users and
hosts observed in the training set. For comparison against a baseline model, the regular PMF
model is used where the latent features are set as above; this has the eﬀect of comparing
against the global mean.

kh /µ(φ)

Cold starts can be divided between new users and new hosts, and the AUC scores for
prediction for each case are presented in Table 4. To calculate the AUC, the negative class
is randomly sampled from the rows and columns corresponding to the new users and hosts,
respectively. Again, there are only minor performance gains for User – Destination, and the
regular PMF model using the global average of the latent features provides surprisingly good
results. As discussed above, this can be explained by the prediction task being much simpler,
and well approximated by a simple degree-based model. In contrast, for the User – Source
graph the extended PMF model shows very good predictive performance for cold starts.

Sanna Passino, Turcotte and Heard/Graph link prediction in computer networks using PMF

15

Table 4
AUC scores for prediction of cold starts.

User – Destination

User – Source

PMF

EPMF

PMF

EPMF

New Users

0.96826

0.97785

0.73362

0.93148

New Hosts

0.81789

0.82715

0.79541

0.91138

6.4. Red-team

The motivation for this work is the detection of cyber attacks; to assess performance from an
anomaly detection standpoint, the event labels from the red-team attack are used as a binary
classiﬁcation problem. Figure 4 plots the ROC curves and AUC scores from the standard and
extended PMF models, and improvements in detection capability are obtained using EPMF.
Similarly to the previous cases, the predictive performance gain is most notable for User –
Source.

6.5. Comparisons with alternative prediction methods

The results in Table 2 are compared in this section with alternative link prediction methods:

• Probabilistic matrix factorisation (Salakhutdinov and Mnih, 2007): Aij ∼ α

(cid:124)
i βj +
β), where (cid:78)(·) denotes a
εij, εij
normal distribution. The parameters were obtained by maximum a posteriori estima-
tion using gradient ascent optimisation techniques.

iid∼ (cid:78)(0, σ2), with αir ∼ (cid:78)(0, σ2

α) and βjr ∼ (cid:78)(0, σ2

• Logistic matrix factorisation (Johnson, 2014): Aij ∼ Bernoulli(pij) where logit(pij) =
β). The parameters were estimated using

α) and βjr ∼ (cid:78)(0, σ2
α
the same procedure described for probabilistic matrix factorisation.

(cid:124)
i βj, with αir ∼ (cid:78)(0, σ2

Fig 4: ROC curves for prediction of red-team events for standard PMF and extended PMF.

00.10.20.30.40.50.60.70.80.9100.20.40.60.81FalsepositiverateTruepositiverateUser–Destination,PMF,AUC=0.90222User–Destination,EPMF,AUC=0.90903User–Source,PMF,AUC=0.86270User–Source,EPMF,AUC=0.96473Sanna Passino, Turcotte and Heard/Graph link prediction in computer networks using PMF

16

Table 5
AUC scores for diﬀerent link prediction algorithms on the two data sets, with R = 20.

User – Destination

User – Source

All links New links All links New links

Probabilistic matrix factorisation

Logistic matrix factorisation

0.93886

0.98079

0.61006

0.95357

0.83022

0.85252

0.64154

0.84330

Random dot product graph – tSVD

0.95050

0.69184

0.86202

0.60935

Random dot product graph – tKatz

0.95392

0.71754

0.86247

0.61120

Non-negative matrix factorisation

0.93985

0.61675

0.86941

0.61107

Degree-based model

0.95433

0.72505

0.82719

0.70393

(cid:124)

⊥, where D ∈ RR×R

• Bipartite random dot product graph (Athreya et al., 2018): Aij ∼ Bernoulli (α

(cid:124)
i βj). The
latent positions αi and βj can be estimated using tSVD (Dhillon, 2001). Assume A =
UDV(cid:124) +U⊥D⊥V
is diagonal matrix containing the top R singular
values in decreasing order, U ∈ R|U |×R and V ∈ R|V |×R contain the corresponding left
and right singular vectors, and the matrices D⊥, U⊥, and V⊥ contain the remaining
singular values and vectors. The tSVD estimates of αi and βj are respectively the i-th
and j-th row of UD1/2 and VD1/2. A comparison with tKatz (Dunlavy, Kolda and
Acar, 2011) is also provided. The scores are estimated similarly to tSVD, replacing the
diagonal entries of the matrix D with a transformation of the top R singular values
d1, . . . , dR of A: f (di) = (1 − ηdi)−1 − 1, with η = 10−4.

+

+

• Non-negative matrix factorisation (for example, see Chen et al., 2017): nodes are as-
signed features W ∈ R|U |×R
obtained as solutions to (cid:107)A − WH(cid:124)(cid:107)2
F,
where (cid:107) · (cid:107)F is the Frobenius norm. The score associated with any link (i, j) is then
(cid:124)
(cid:124)
obtained as w
j are respectively the i-th and j-th row of W and
i and h
H.

and H ∈ R|V |×R

(cid:124)
i hj, where w

• Degree-based model, where the probability of a link is approximated as P(Aij = 1) =
j are the out-degree and in-degree of each node.

j ), where dout

1 − exp(−dout

and din

i din

+

i

The results are presented in Table 5. Overall, when compared to the results of PMF with
Ber-Po link in Table 2, the PMF models achieve better results compared to other popular
techniques, especially for new link prediction. Non-negative matrix factorisation and random
dot product graph methods seem to slightly outperform standard PMF when predicting all
links, but their performance for new link prediction, a more interesting and diﬃcult task,
is signiﬁcantly worse than PMF. It must be remarked that some of the alternative methods
have been also used for complex applications and purposes other than link prediction. This
article does not claim that PMF is globally better than such methods, but only that PMF
appears to have a better performance for link prediction on the LANL network.

(cid:124)
K(Φ (cid:12) xiy

In principle, it would be also possible to add covariates to the probabilistic models analysed
(cid:124)
j )1H within the link functions. However, this
in this section, including the term 1
would be extremely unpractical, since the likelihood for such models is (cid:79)(|U ||V |), and the
(cid:124)
calculation of xiy
j for all pairs (i, j) is computationally expensive and carries a large memory
requirement (18 gigabytes on User – Source), in the order of magnitude of (cid:79)(|U ||V |KH).
Therefore, in this section, only the standard models, without the covariate extension, were
(cid:124)
compared. On the other hand, ﬁtting EPMF in (4) only requires to calculate xiy
j for all

Sanna Passino, Turcotte and Heard/Graph link prediction in computer networks using PMF

17

Table 6
AUC scores for prediction of all and new links using the joint PMF model. Number of latent features:
R = 20.

User – Destination

User – Source

PMF

EPMF

PMF

EPMF

All links

0.98206

0.98290

0.86061

0.95585

New links

0.94563

0.94565

0.89414

0.94637

pairs such that Aij > 0, which is (cid:79)(nnz(A)KH). This operation only takes 6.5 megabytes
in memory for User – Source, since A is extremely sparse in the cyber-security application.
This is a signiﬁcant practical advantage of the proposed model.

6.6. Comparison with a joint model

In the previous sections, the graphs User – Source and User – Destination were analysed
separately. In this section, the predictive performance of the two individual models is com-
pared to a joint PMF model, where the user-speciﬁc latent features are shared between the
two graphs. In particular, assume that A ∈ {0, 1}U ×V represents the adjacency matrix for
User – Source, and A(cid:48) ∈ {0, 1}U ×V (cid:48)
for User – Destination. The users are assigned latent
positions αi, i = 1, . . . , |U | and covariates xi, whereas the source and destination hosts are
given latent positions βj, j = 1, . . . , |V | and β(cid:48)
j, j = 1, . . . , |V (cid:48)| respectively, and covariates
yj and y(cid:48)

j. The joint extended PMF model (JEPMF) assumes:

Aij = 1N+ (Nij) , Nij ∼ Poisson (cid:0)α
ij ∼ Poisson (cid:0)α
(cid:1) , N (cid:48)
ij = 1N+
A(cid:48)

(cid:0)N (cid:48)

ij

(cid:124)
(cid:124)
K(Φ (cid:12) xiy
i βj + 1
(cid:124)
(cid:124)
i β(cid:48)
K(Φ(cid:48) (cid:12) xiy(cid:48)
j + 1

(cid:124)
j )1H
(cid:124)

(cid:1) ,
)1H (cid:48)

j

(cid:1) .

(6.1)

Similarly, a standard joint PMF model would have the same structure as (6.6), without the
covariate term. Variational inference for the joint model proceeds similarly to Algorithm 1,
ir and µ(α)
with minor diﬀerences in the updates for λ(α)
ir . More details are given in Appendix D.
The results are presented in Table 6. The AUC scores were obtained ﬁtting the joint model
and then assessing the predictive performance on User – Source and User – Destination
separately. Comparing the results with the predictions in Table 2 for the two individual
models, joint PMF produces similar results to the individual models. This suggests that
users have a similar behaviour across the two graphs, since adding the constraint of identical
user features does not signiﬁcantly decrease the predictive performance. Therefore, it could
be concluded that there are latent features for users which vary only slightly between the
two graphs, and so are well-suited to a joint modelling approach. This assumption is often
made in multiplex networks (see, for example, Kivel¨a et al., 2014).

6.7. Seasonal modelling

To investigate dynamic modelling, binary adjacency matrices A1, . . . , A82 are calculated for
each day across the train and test periods. The seasonal PMF model with the inclusion of
covariates (SEPMF) (5) is then compared against EPMF; for EPMF, the adjacency matrices
are assumed to be independent realisations randomly generated from a ﬁxed set of latent

Sanna Passino, Turcotte and Heard/Graph link prediction in computer networks using PMF

18

Table 7
AUC scores for prediction of all and new links using seasonal PMF.

User – Destination

User – Source

EPMF

SEPMF

EPMF

SEPMF

All links

0.96550

0.96205

0.93559

0.92829

New links

0.87107

0.89337

0.85009

0.85748

features. Due to a “9 day-80 hour” work schedule operated at LANL, whereby employees can
elect to take vacation every other Friday, the seasonal period is assumed to be comprised of
four segments: weekdays (Monday - Thursday), weekends (Saturday and Sunday), and two
separate segments for alternating Friday’s. For each model, binary classiﬁcation is performed
using the model predictive scores calculated across the entire period. For the positive class,
scores are calculated for all user-host pairs (i, j) such that Aijt = 1 for at least one t in the
test set; for the negative class, a random sample of (i, j) pairs such that Aijt = 0 for all t in
the test set are obtained, with sample size equal to three times the total number of observed
links.

Table 7 presents the resulting AUC scores. For both networks, the seasonal model does
not globally outperform the extended PMF model for all links. However, improvements are
obtained for prediction of the new links. One explanation for the weaker overall performance
could be the reduced training sample size implied for the seasonal model: EPMF in a dy-
namic setting assumes that the all daily graphs have been sampled from the same process,
whereas if the seasonal model is used then the daily graphs are only informative for the cor-
responding seasonal segments. In addition, as brieﬂy mentioned in Section 1, elements of the
data exhibit strong polling patterns, often due to computers automatically authenticating
on users’ behalves (Turcotte, Kent and Hash, 2018); some of the links that exhibit polling
will not exhibit seasonal patterns, as the human behaviour has not been separated from the
automated behaviour.

On the other hand, improvements in the estimation of new links, despite the reduced
training sample size, demonstrates that it can be beneﬁcial to understand the temporal
dynamics of the network for these cases. Considering the context of the application, it might
be perfectly normal for a user to authenticate to a computer during the week; however,
that same authentication would be extremely unusual on the weekends when the user is not
present at work. Without the seasonal model this behavioural diﬀerence in would be missed.

7. Conclusion and discussion

Extensions of the standard Poisson matrix factorisation model have been proposed, motivated
by applications to computer network data, in particular the LANL enterprise computer
network. The extensions are threefold: handling binary matrices, including covariates for
users and hosts in the PMF framework, and accounting for seasonal eﬀects. The counts
Nijt have been treated as censored, and it has been assumed that only the binary indicator
Aijt = 1N+(Nijt) is observed. Starting from the hierarchical Poisson matrix factorisation
model of Gopalan, Hofman and Blei (2015), which only includes the latent features αi and
βj, covariates have been included through the matrix of coeﬃcients Φ. Seasonal adjustments
for the coeﬃcients are obtained through the variables γit(cid:48) and δjt(cid:48). A variational inference

Sanna Passino, Turcotte and Heard/Graph link prediction in computer networks using PMF

19

algorithm is proposed, suitably adapted for the Bernoulli-Poisson link. This article mainly
considered categorical covariates, but the methodology could be extended to include other
forms of covariates, with minimal modiﬁcations to the inferential algorithms.

The results show improvements over alternative models for link prediction purposes on
the real computer network data. Including covariates provides signiﬁcant uplift in predictive
performance and allows prediction for new nodes arriving into the network. This discovery
provides valuable insight on the potential beneﬁts of including nodal covariates when inferring
network structure. In particular, user covariates like job title and location were found to be
particularly informative for the users, and location and subnet for the hosts. The seasonal
model provides time-varying anomaly scores and oﬀers marginal improvements for predicting
new links, which are of primary interest in cyber-security applications.

Despite the focus on bipartite graphs here, the proposed methodologies could be readily
adapted to undirected and general directed graphs. For an undirected graph, the PMF model
with Ber-Po link would assume:

Aij = 1N+ (Nij) , Nij ∼ Poisson (α

(cid:124)
i αj) , i < j, Aij = Aji.

(7.1)

For directed graphs on the same node set, it could be assumed that each node has the same
behaviour as source and destination of the connection, implying equation (7) for undirected
graphs applies, removing the constraint Aij = Aji. Alternatively, each node could be given
two latent features: αi for its behaviour as source and βi for its behaviour as destination.
This is a special case of the bipartite graph model, where U ≡ V , hence (4) applies. Note
that mean-ﬁeld variational inference within the directed graph context might be problematic,
since the mean-ﬁeld assumption Cov(Nij, Nji) = 0 would be unrealistic if network reciprocity
is observed. This is often the case in cyber-security applications, for example in network ﬂow
data, representing directed summaries of connections between IP addresses.

Acknowledgements

The authors acknowledge funding from Los Alamos National Laboratory, EPSRC and the
Heilbronn Institute for Mathematical Research. Research presented in this article was sup-
ported by the Laboratory Directed Research and Development program of Los Alamos Na-
tional Laboratory (New Mexico, USA) under project number 20180607ECR.

References

Acharya, A., Teffer, D., Henderson, J., Tyler, M., Zhou, M. and Ghosh, J. (2015).
Gamma Process Poisson Factorization for Joint Modeling of Network and Documents. In
Proceedings of the European Conference on Machine Learning and Knowledge Discovery
in Databases 1 283–299.

Adomavicius, G. and Tuzhilin, A. (2005). Toward the Next Generation of Recommender
Systems: A Survey of the State-of-the-Art and Possible Extensions. IEEE Transactions on
Knowledge and Data Engineering 17 734–749.

Agarwal, D., Zhang, L. and Mazumder, R. (2011). Modeling item-item similarities for
personalized recommendations on Yahoo! front page. Annals of Applied Statistics 5 1839–
1875.

Sanna Passino, Turcotte and Heard/Graph link prediction in computer networks using PMF

20

Amit, I., Matherly, J., Hewlett, W., Xu, Z., Meshi, Y. and Weinberger, Y. (2019).
Machine Learning in Cyber-Security - Problems, Challenges and Data Sets. In AAAI-19
Workshop on Engineering Dependable and Secure Machine Learning Systems.

Anderson, B., Vejman, M., McGrew, D. and Paul, S. (2018). Towards Generalisable
Network Threat Detection In Data Science for Cyber-Security 4, 77-94. World Scientiﬁc.
Athreya, A., Fishkind, D. E., Tang, M., Priebe, C. E., Park, Y., Vogelstein, J. T.,
Levin, K., Lyzinski, V., Qin, Y. and Sussman, D. L. (2018). Statistical Inference on
Random Dot Product Graphs: a Survey. Journal of Machine Learning Research 18 1-92.
Bishop, C. M. (2006). Pattern Recognition and Machine Learning. Information Science and

Statistics. Springer-Verlag, Berlin, Heidelberg.

Blei, D. M., Kucukelbir, A. and McAuliffe, J. D. (2017). Variational Inference: A
Review for Statisticians. Journal of the American Statistical Association 112 859-877.
Canny, J. (2004). GaP: A Factor Model for Discrete Data. In Proceedings of the 27th Annual

International ACM SIGIR Conference. SIGIR ’04 122–129.

Cemgil, A. T. (2009). Bayesian Inference for Nonnegative Matrix Factorisation Models.

Computational Intelligence and Neuroscience.

Chaney, A. J. B., Blei, D. M. and Eliassi-Rad, T. (2015). A Probabilistic Model for
Using Social Networks in Personalized Item Recommendation. In Proceedings of the 9th
ACM Conference on Recommender Systems. RecSys ’15 43–50. ACM.

Charlin, L., Ranganath, R., McInerney, J. and Blei, D. M. (2015). Dynamic Poisson
Factorization. In Proceedings of the 9th ACM Conference on Recommender Systems 155–
162. ACM.

Chen, B., Li, F., Chen, S., Hu, R. and Chen, L. (2017). Link prediction based on non-

negative matrix factorization. PLOS ONE 12 1-18.

Clauset, A., Moore, C. and Newman, M. E. J. (2008). Hierarchical structure and the

prediction of missing links in networks. Nature 453.

da Silva, E. d. S., Langseth, H. and Ramampiaro, H. (2017). Content-Based Social
Recommendation with Poisson Matrix Factorization. In Machine Learning and Knowledge
Discovery in Databases 530–546.

Dai, B., Wang, J., Shen, X. and Qu, A. (2019). Smooth neighborhood recommender

systems. Journal of Machine Learning Research 20 1-24.

Dhillon, I. S. (2001). Co-clustering Documents and Words Using Bipartite Spectral Graph
Partitioning. In Proceedings of the Seventh ACM SIGKDD Conference on Knowledge Dis-
covery and Data Mining. KDD ’01 269–274. ACM, New York, NY, USA.

Dunlavy, D. M., Kolda, T. G. and Acar, E. (2011). Temporal link prediction using
matrix and tensor factorizations. ACM Transactions on Knowledge Discovery from Data
5.

Dunson, D. B. and Herring, A. H. (2005). Bayesian latent variable models for mixed

discrete outcomes. Biostatistics 6 11-25.

Fienberg, S. E. (2012). A Brief History of Statistical Models for Network Analysis and

Open Challenges. Journal of Computational and Graphical Statistics 21 825-839.

Fithian, W. and Mazumder, R. (2018). Flexible Low-Rank Statistical Modeling with Side

Information. Statistical Science 33 238–260.

Goldenberg, A., Zheng, A. X., Fienberg, S. E. and Airoldi, E. M. (2010). A Survey

of Statistical Network Models. Found. Trends Mach. Learn. 2 129–233.

Gopalan, P., Charlin, L. and Blei, D. M. (2014). Content-based Recommendations

Sanna Passino, Turcotte and Heard/Graph link prediction in computer networks using PMF

21

with Poisson Factorization. In Proceedings of the 27th International Conference on Neural
Information Processing Systems. NIPS’14 2 3176–3184. MIT Press.

Gopalan, P., Hofman, J. M. and Blei, D. M. (2015). Scalable Recommendation with
Hierarchical Poisson Factorization. In Proceedings of the 31st Conference on Uncertainty
in Artiﬁcial Intelligence. UAI’15 326–335. AUAI Press.

Heard, N. A., Rubin-Delanchy, P. T. G. and Lawson, D. J. (2014). Filtering au-
tomated polling traﬃc in computer network ﬂow data. Proceedings - 2014 IEEE Joint
Intelligence and Security Informatics Conference, JISIC 2014 268-271.

Heard, N. A., Adams, N., Rubin-Delanchy, P. and Turcotte, M. (2018). Data Science

for Cyber-Security. World Scientiﬁc (Europe).

Hern´andez-Lobato, J. M., Houlsby, N. and Ghahramani, Z. (2014). Stochastic In-
ference for Scalable Probabilistic Modeling of Binary Matrices. In Proceedings of the 31st
International Conference on Machine Learning. ICML’14 32 II-379–II-387.

Hoff, P. D. (2005). Bilinear Mixed-Eﬀects Models for Dyadic Data. Journal of the American

Statistical Association 100 286-295.

Hoff, P. D., Raftery, A. E. and Handcock, M. S. (2002). Latent space approaches to
social network analysis. Journal of the American Statistical Association 97 1090–1098.
Hosseini, S., Khodadadi, A., Alizadeh, K., Arabzadeh, A., Farajtabar, M.,
Zha, H. and Rabiee, H. R. R. (2018). Recurrent Poisson factorization for temporal
recommendation. IEEE Transactions on Knowledge and Data Engineering.

Huggins, J. H., Campbell, T., Kasprzak, M. and Broderick, T. (2019). Scalable
Gaussian Process Inference with Finite-data Mean and Variance Guarantees. In Proceed-
ings of Machine Learning Research 89 796–805.

Jeske, D. R., Stevens, N. T., Tartakovsky, A. G. and Wilson, J. D. (2018). Statisti-
cal methods for network surveillance. Applied Stochastic Models in Business and Industry
34 425-445.

Johnson, C. C. (2014). Logistic matrix factorization for implicit feedback data. In Proceed-
ings of the NIPS 2014 Workshop on Distributed Machine Learning and Matrix Computa-
tions.

Khanna, R., Zhang, L., Agarwal, D. and Chen, B. C. (2013). Parallel matrix factor-
ization for binary response. In IEEE International Conference on Big Data 2013 430–438.
Kim, B., Lee, K., Xue, L. and Niu, X. (2017). A Review of Dynamic Network Models

with Latent Variables. arXiv e-prints.

Kivel¨a, M., Arenas, A., Barthelemy, M., Gleeson, J. P., Moreno, Y. and
Porter, M. A. (2014). Multilayer networks. Journal of Complex Networks 2 203-271.
Kumar, R. S. S., Wicker, A. and Swann, M. (2017). Practical Machine Learning for
Cloud Intrusion Detection: Challenges and the Way Forward. In Proceedings of the 10th
ACM Workshop on Artiﬁcial Intelligence and Security. AISec ’17 81–90.

Liben-Nowell, D. and Kleinberg, J. (2007). The Link-prediction Problem for Social
Networks. Journal of the American Society for Information Science and Technology 58
1019–1031.

L¨u, L. and Zhou, T. (2011). Link prediction in complex networks: A survey. Physica A:

Statistical Mechanics and its Applications 390 1150 - 1170.

Menon, A. K. and Elkan, C. (2011). Link Prediction via Matrix Factorization. In Machine
Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD
2011, Part II 437–452. Springer Berlin Heidelberg, Berlin, Heidelberg.

Sanna Passino, Turcotte and Heard/Graph link prediction in computer networks using PMF

22

Metelli, S. and Heard, N. A. (2019). On Bayesian new edge prediction and anomaly

detection in computer networks. Annals of Applied Statistics 13 2586-2610.

Nakajima, S., Sugiyama, M. and Tomioka, R. (2010). Global Analytic Solution for
Variational Bayesian Matrix Factorization. In Advances in Neural Information Processing
Systems 23 1768–1776.

Neil, J., Hash, C., Brugh, A., Fisk, M. and Storlie, C. B. (2013). Scan Statistics for

the Online Detection of Locally Anomalous Subgraphs. Technometrics 55 403-414.

Nguyen, J. and Zhu, M. (2013). Content-boosted matrix factorization techniques for rec-
ommender systems. Statistical Analysis and Data Mining: The ASA Data Science Journal
6 286–301.

Papastamoulis, P. and Ntzoufras, I. (2020). On the identiﬁability of Bayesian factor

analytic models. arXiv e-prints arXiv:2004.05105.

Paquet, U. and Koenigstein, N. (2013). One-class Collaborative Filtering with Random
Graphs. In Proceedings of the 22nd International Conference on World Wide Web. WWW
’13 999–1008. ACM, New York, NY, USA.

Salakhutdinov, R. and Mnih, A. (2007). Probabilistic Matrix Factorization. In Pro-
ceedings of the 20th International Conference on Neural Information Processing Systems.
NIPS’07 1257–1264.

Salter-Townshend, M. and Murphy, T. B. (2013). Variational Bayesian inference for
the Latent Position Cluster Model for network data. Computational Statistics & Data
Analysis 57 661–671.

Schein, A., Paisley, J., Blei, D. M. and Wallach, H. (2015). Bayesian Poisson tensor
factorization for inferring multilateral relations from sparse dyadic event counts. In Pro-
ceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and
Data Mining 1045–1054. ACM.

Schein, A., Zhou, M., Blei, D. M. and Wallach, H. (2016). Bayesian Poisson Tucker
decomposition for learning the structure of international relations. In Proceedings of the
33rd International Conference on Machine Learning , New York, NY, USA.

Seeger, M. and Bouchard, G. (2012). Fast variational Bayesian inference for non-
conjugate matrix factorization models. In Artiﬁcial Intelligence and Statistics 1012–1018.
Sewell, D. K. and Chen, Y. (2015). Latent Space Models for Dynamic Networks. Journal

of the American Statistical Association 110 1646-1657.

Singh, A. P. and Gordon, G. J. (2008). Relational Learning via Collective Matrix Factor-
ization. In Proceedings of the 14th ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining. KDD ’08 650–658. ACM, New York, NY, USA.

Turcotte, M. J. M., Kent, A. D. and Hash, C. (2018). Uniﬁed Host and Network Data

Set In Data Science for Cyber-Security 1, 1-22. World Scientiﬁc.

Turcotte, M., Moore, J., Heard, N. A. and McPhall, A. (2016). Poisson factorization
for peer-based anomaly detection. In 2016 IEEE Conference on Intelligence and Security
Informatics (ISI) 208–210.

Wu, Z., Pan, S., Chen, F., Long, G., Zhang, C. and Yu, P. S. (2020). A Comprehensive
Survey on Graph Neural Networks. IEEE Transactions on Neural Networks and Learning
Systems 1-21.

Zhang, M. and Chen, Y. (2018). Link Prediction Based on Graph Neural Networks. In

Advances in Neural Information Processing Systems 31 5165–5175.

Zhang, W. and Wang, J. (2015). A Collective Bayesian Poisson Factorization Model for

Sanna Passino, Turcotte and Heard/Graph link prediction in computer networks using PMF

23

Cold-start Local Event Recommendation. In Proceedings of the 21th ACM SIGKDD In-
ternational Conference on Knowledge Discovery and Data Mining 1455–1464.

Zhou, M. (2015). Inﬁnite Edge Partition Models for Overlapping Community Detection and
Link Prediction. In Proceedings of the Eighteenth International Conference on Artiﬁcial
Intelligence and Statistics, AISTATS.

Appendix A: Full conditional distributions in the extended PMF model

First note that, conditional on Nij, Zij = (Zij1, . . . , Zij(R+KH)) has a multinomial distribu-
tion,

Zij|Nij, αi, βj, Φ ∼ Mult (Nij, πij) ,

where πij is the probability vector proportional to

(αi1βj1, . . . , αiRβjR, φ11xi1yj1, . . . , φKH xiKyjH ).

Therefore, setting ψij = α

(cid:124)
(cid:124)
K(Φ (cid:12) xiy
i βj + 1

(cid:124)
j )1H ,

p(Nij, Zij|αi, βj, Φ, A) =

(cid:26) Pois+(ψij)Mult(Nij, πij) Aij > 0,
Aij = 0,

δ0(Nij)δ0(Zij)

(A.1)

where Pois+(·) denotes the zero-truncated Poisson distribution. The user and host latent
features complete conditionals are gamma, where

αir|β, ζ (α)

i

, Z ∼ Γ

βjr|α, ζ (β)

j

, Z ∼ Γ


a(α) +


a(β) +

|V |
(cid:88)

j=1

|U |
(cid:88)

i=1

Zijr, ζ (α)

i +

Zijr, ζ (β)

j +



βjr

 ,



αir

 ,

|V |
(cid:88)

j=1

|U |
(cid:88)

i=1

and

Similarly,

(cid:32)

ζ (α)
i

|αi ∼ Γ

b(α) + Ra(α), c(α) +

(cid:32)

ζ (β)
j

|βj ∼ Γ

b(β) + Ra(β), c(β) +

(cid:33)

(cid:33)

,

.

αir

βjr

R
(cid:88)

r=1

R
(cid:88)

r=1

(A.2)

φkh|ζ (φ), Z ∼ Γ


a(φ) +

|U |
(cid:88)

|V |
(cid:88)

i=1

j=1

(cid:32)

Zijl, ζ (φ) +

|U |
(cid:88)

i=1

xik



yjh

 ,

|V |
(cid:88)

j=1
(cid:33)

ζ (φ)|Φ ∼ Γ

b(φ) + KHa(φ), c(φ) +

φkh

,

K
(cid:88)

H
(cid:88)

k=1

h=1

where l is the index corresponding to the covariate pair (k, h).

Sanna Passino, Turcotte and Heard/Graph link prediction in computer networks using PMF

24

Appendix B: Variational inference in the extended PMF model

As all of the factors in the variational approximation given in (4.2) take the same distribu-
tional form of the complete conditionals,

q(Nij, Zij|θij, χij) =

(cid:26) Pois+(θij)Mult(Nij, χij) Aij > 0,
Aij = 0.

δ0(Nij)δ0(Zij)

(B.1)

Let ψij denote the rate (cid:80)R
h=1 φkhxikyjh of the Poisson distribution for
Nij, and ψijl, l = 1, . . . , R + KH, represent the individual elements in the sum. To get the
update equations for θ and χ, following (4.2), for Aij > 0,

r=1 αirβjr + (cid:80)K

(cid:80)H

k=1

Eq

−Nij ,Zij

{log p(Nij, Zij|αi, βj, Φ)} =

(cid:88)

l

(cid:110)

ZijlEq

−Nij ,Zij (log ψijl) − log(Zijl!)

+ k, (B.2)

(cid:111)

where k is a constant with respect to Nij and Zij. Hence:

q(cid:63)(Nij, Zij) ∝

R+KH
(cid:89)

l=1

exp

(cid:110)

Eq

−Nij ,Zij (log ψijl)

(cid:111)Zijl (cid:46)

Zijl!,

l exp{Eq

l exp{Eq

with domain of Zij constrained to have (cid:80)
l Zijl > 0. Multiplying and dividing the ex-
pression by Nij! and [(cid:80)
−Nij ,Zij (log ψijl)}]Nijl gives a distribution which has the
same form of (B). Therefore the rate θij of the zero truncated Poisson is updated using
(cid:80)
−Nij ,Zij (log ψijl)}, see step 5 in Algorithm 1 for the resulting ﬁnal expression. The
update for the vector of probabilities χij is given by a slight extension of the standard result
for variational inference in the PMF model (Gopalan, Hofman and Blei, 2015) to include the
covariate terms, see step 6 of Algorithm 1. The remaining updates are essentially analogous
to standard PMF (Gopalan, Hofman and Blei, 2015).

Appendix C: Inference in the seasonal model

The inferential procedure for the seasonal model follows the same guidelines used for the
non-seasonal model. Given the unobserved count Nijt, latent variables Zijtl are added, rep-
resenting the contribution of the component l to the total count Nijt: Nijt = (cid:80)
l Zijtl. The
full conditional for Nijt and Zijt follows (A), except the rate for the Poisson and probabil-
ity vectors for the multinomial will now depend on the seasonal parameters γitr, δjtr, and
ωkht. Letting p denote a seasonal segment in {1, . . . , P } the full conditionals for the rate
parameters are:

αir|Z, β, γ, δ, ζ (α)

i

d∼ Γ


a(α) +

|V |
(cid:88)

T
(cid:88)

Zijtr, ζ (α)

i +

γipr|Z, α, β, δ, ζ (γ)

p

d∼ Γ


a(γ) +

j=1

t=1

|V |
(cid:88)

(cid:88)

j=1

t:t=p

Zijtr, ζ (γ)

p + αir

T
(cid:88)

t=1

γitr

|V |
(cid:88)

j=1



βjrδjtr

 ,

|V |
(cid:88)

j=1



(cid:88)

βjr

δjtr

 ,

t:t=p


φkh|Z, ζ (φ) d∼ Γ


a(φ) +

|U |
(cid:88)

|V |
(cid:88)

T
(cid:88)

i=1

j=1

t=1

Zijtl, ζ (φ) + T ˜xk ˜yh

 ,

Sanna Passino, Turcotte and Heard/Graph link prediction in computer networks using PMF

25

where ˜xk = (cid:80)|U |

i=1 xik and ˜yh = (cid:80)|V |

j=1 yjh. Similar results are available for βjr and δjpr. Also:

p |γ d∼ Γ
ζ (γ)


b(γ) + |U |Ra(γ), c(γ) +



γipr

 ,

|U |
(cid:88)

R
(cid:88)

i=1

r=1

and similarly for ζ (δ)
, the conditional distribution is equivalent to (A).
The mean-ﬁeld variational family is again used implying a factorisation similar to (4.2), so
that

p . For ζ (α)

and ζ (β)

j

i

q(α, β, Φ, γ, δ, ζ, N, Z) =

(cid:89)

q(Nijt, Zijt|θijt, χijt) ×

(cid:89)

q(αir|λ(α)

ir , µ(α)
ir )

×

×

×

(cid:89)

j,r
(cid:89)

q(βjr|λ(β)

jr , µ(β)

jr ) ×

i,j,t
(cid:89)

q(φkh|λ(φ)

kh , µ(φ)

kh ) ×

(cid:89)

i,r
q(ζ (α)
i

|ν(α)
i

, ξ(α)
i

)

k,h

q(ζ (β)
j

|ν(β)
j

, ξ(β)
j

) × q(ζ (φ)|ν(φ), ξ(φ)) ×

(cid:89)

i
q(γipr|λ(γ)

ipr, µ(γ)
ipr)

j
(cid:89)

j,p,r

q(δjpr|λ(δ)

jpr, µ(δ)

jpr) ×

(cid:89)

p

q(ζ (γ)

p |ν(γ)

p , ξ(γ)

p |ν(δ)

p , ξ(δ)

p ).

i,q,r
p )q(ζ (δ)

As in Section 4.2, each q(·) has the same form of the full conditional distributions for
the corresponding parameter or group of parameters. Again the variational parameters are
updated using CAVI and a similar algorithm is obtained to that detailed in Algorithm 1,
where steps 7, 8, 9 and 10 are modiﬁed to include the time dependent parameters. It follows
that for the user-speciﬁc parameters the update equations take the form:

λ(α)
ir = a(α) +

|V |
(cid:88)

T
(cid:88)

λ(γ)
ipr = a(γ) +

j=1

t=1

|V |
(cid:88)

(cid:88)

j=1

t:t=p

Aijtθijtχijtr
1 − e−θijt

, µ(α)

ir =

Aijtθijtχijtr
1 − e−θijt

, µ(γ)

ipr =

ν(α)
i
ξ(α)
i

ν(γ)
p
ξ(γ)
p

+

+

T
(cid:88)

t=1

λ(α)
ir
µ(α)
ir

λ(γ)
itr
µ(γ)
itr

|V |
(cid:88)

j=1

|V |
(cid:88)

j=1
λ(β)
jr
µ(β)
jr

λ(β)
jr
µ(β)
jr

(cid:88)

t:t=p

,

λ(δ)
jtr
µ(δ)
jtr
λ(δ)
jtr
µ(δ)
jtr

,

and similar results can be obtained for the host-speciﬁc parameters λ(β)
The updates for ν(α)
the covariates

jpr and µ(δ)
jpr.
are identical to steps 7 and 8 in Algorithm 1. For

ir , µ(β)

jr , λ(δ)

and ξ(β)

, ν(β)
j

, ξ(α)
i

j

i

λ(φ)
kh = a(φ) +

|U |
(cid:88)

|V |
(cid:88)

T
(cid:88)

i=1

j=1

t=1

Aijtθijtχijtl
1 − e−θijt

, µ(φ)

kh =

ν(φ)
ξ(φ) + ˜xk ˜yhT.

The updates for ν(φ) and ξ(φ) are the same as step 9 in Algorithm 1. Finally, for the time
dependent hyperparameters:

p = b(γ) + |U |Ra(γ), ξ(γ)
ν(γ)

p = c(γ) +

|U |
(cid:88)

R
(cid:88)

i=1

r=1

λ(γ)
ipr
µ(γ)
ipr

,

Sanna Passino, Turcotte and Heard/Graph link prediction in computer networks using PMF

26

and similarly for ν(δ)
p

and ξ(δ)
p .

The updates for θijt and χijt are similar to Appendix B. An expansion similar to (B) can
{log p(Nijt, Zijt|αi, βj, γit, δjt, Φ}, and the update

be applied to the expectation Eq
equations for θijt and χijtr can be derived similarly to Appendix B:

−Nijt,Zijt

θijt =

R
(cid:88)

r=1

exp

(cid:110)
Ψ(λ(α)

ir ) − log(µ(α)

ir ) + Ψ(λ(β)

jr ) − log(µ(β)
jr )

+ Ψ(λ(γ)

itr ) − log(µ(γ)

itr ) + Ψ(λ(δ)

jtr) − log(µ(δ)
jtr)

(cid:111)

+





χijtl ∝

K
(cid:88)

H
(cid:88)

k=1

h=1

xikyjh exp

(cid:110)
Ψ(λ(φ)

kh ) − log(µ(φ)
kh )

(cid:111)

,

exp

il ) + Ψ(λ(β)

il ) − log(µ(α)

(cid:110)
Ψ(λ(α)
+ Ψ(λ(γ)
itl ) − log(µ(γ)
(cid:110)
Ψ(λ(φ)

itl ) + Ψ(λ(δ)
(cid:111)
kh ) − log(µ(φ)
kh )

xikyjh exp

jl ) − log(µ(β)
jl )
jtl ) − log(µ(δ)
jtl )

(cid:111)

l ≤ R,

l > R.

Appendix D: Inference in the joint model

Variational inference for the joint PMF model presented in Section 6.6 proceeds similarly to
Algorithm 1. The conditional posterior distributions are essentially the same as PMF and
EPMF. The only exception is the conditional posterior distribution of αir:

αir|Z, Z(cid:48), β, β(cid:48), ζ (α)

i ∼ Γ


a(α) +

|V |
(cid:88)

j=1

Zijr +

|V (cid:48)|
(cid:88)

j=1

ijr, ζ (α)
Z (cid:48)

i +

|V |
(cid:88)

j=1

βjr +



β(cid:48)
jr

 .

|V (cid:48)|
(cid:88)

j=1

For variational inference, a factorisation similar to (4.2) is assumed, further multiplied by
the approximation for the posteriors of the additional components of the model: mainly
q(β(cid:48)
ij). Therefore variational inference is
also essentially unchanged, except the CAVI update for the parameters of variational ap-
proximation for the components αir, which become:

kh , µ(φ(cid:48))

jr , µ(β(cid:48))

kh ), q(N (cid:48)

jr ), q(φ(cid:48)

kh|λ(φ(cid:48))

jr|λ(β(cid:48))

ij, χ(cid:48)

ij, Z(cid:48)

ij|θ(cid:48)

λ(α)
ir = a(α) +

|V |
(cid:88)

j=1

Aijθijχijr
1 − e−θij

+

|V (cid:48)|
(cid:88)

j(cid:48)=1

A(cid:48)
ijχ(cid:48)
ijθ(cid:48)
ijr
1 − e−θ(cid:48)

ij

,

µ(α)
ir =

ν(α)
i
ξ(α)
i

Updates for the approximations of the additional components N (cid:48)
from the updates for the variational parameters θij, χijr, λ(β)
rithm 1.

jr , µ(β)

λ(β(cid:48))
jr
µ(β(cid:48))
jr

.

+

+

|V |
(cid:88)

|V (cid:48)|
(cid:88)

λ(β)
jr
µ(β)
j(cid:48)=1
jr
ijr, β(cid:48)
jr and φ(cid:48)
kh and µ(φ)

j=1
ij, Z (cid:48)
jr , λ(φ)

kh follow
kh in Algo-

Francesco Sanna Passino, Nicholas A. Heard
Department of Mathematics
Imperial College London
180 Queen’s Gate
SW7 2AZ London (United Kingdom)

E-mail: f.sannapassino@imperial.ac.uk
n.heard@imperial.ac.uk

Melissa J. M. Turcotte
Microsoft 365 Defender
Microsoft Corporation
One Microsoft Way
Redmond, WA 98052 (USA)

E-mail: melissa.turcotte@microsoft.com

