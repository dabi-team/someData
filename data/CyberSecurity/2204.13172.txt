An Adversarial Attack Analysis on Malicious Advertisement
URL Detection Framework

Ehsan Nowroozi, Member, IEEE, Abhishek, Member, IEEE, Mohammad Reza Mohammadi, Member, IEEE, and
Mauro Conti, Fellow Member, IEEE

1

2
2
0
2

r
p
A
7
2

]

G
L
.
s
c
[

1
v
2
7
1
3
1
.
4
0
2
2
:
v
i
X
r
a

Abstractâ€”Malicious advertisement URLs pose a security risk
since they are the source of cyber-attacks, and the need to
address this issue is growing in both industry and academia.
Generally, the attacker delivers an attack vector to the user by
means of an email, an advertisement link or any other means of
communication and directs them to a malicious website to steal
sensitive information and to defraud them. Existing malicious
URL detection techniques are limited and to handle unseen
features as well as generalize to test data.

In this study, we extract a novel set of lexical and web-scrapped
features and employ machine learning technique to set up system
for fraudulent advertisement URLs detection. The combination
set of six different kinds of features precisely overcome the
obfuscation in fraudulent URL classiï¬cation. Based on different
statistical properties, we use twelve different formatted datasets
for detection, prediction and classiï¬cation task. We extend our
prediction analysis for mismatched and unlabelled datasets. For
this framework, we analyze the performance of four machine
learning techniques: Random Forest, Gradient Boost, XGBoost
and AdaBoost in the detection part. With our proposed method,
we can achieve a false negative rate as low as 0.0037 while
maintaining high accuracy of 99.63%. Moreover, we devise
a novel unsupervised technique for data clustering using K-
Means algorithm for the visual analysis. This paper analyses
the vulnerability of decision tree-based models using the limited
knowledge attack scenario. We considered the exploratory attack
and implemented Zeroth Order Optimization adversarial attack
on the detection models.

Index Termsâ€”Malicious advertising URL, cybersecurity, ma-
chine learning, web-scrapped features, classiï¬cation, clustering,
adversarial attack.

I. INTRODUCTION

I N recent years, the network of web pages has grown faster

with the expansion of the Internet. Online services, busi-
ness, banking, and online marketing have made the Internet an
integral part of our lives. Because of the numerous advantages
of this platform for online advertising, it has also become a
primary source of malicious activities. Attackers deliberately
put malicious links in online advertisements that, when visited,

researcher

E. Nowroozi

is a Postdoctoral

in Faculty of Engineer-
ing and Natural Sciences (FENS), Center of Excellence in Data An-
alytics (VERË™IM), Sabanci University,
Istanbul Turkey 34956. He is a
also external collaborator at
the University of Padua, Security and Pri-
vacy Research Group (SPRITZ), Italy. (e-mail:ehsan.nowroozi65@gmail.com,
ehsan.nowroozi@sabanciuniv.edu, nowroozi@math.unipd.it).

Abhishek is a researcher afï¬liated from Department of Mathematics, MN-
NIT Allahabad, India and afï¬liated from Mathematics Department, University
of Delhi-110007, India (e-mail:abhishek1verma99@gmail.com).

M. R. Mohammadi, is with the Department of Mathematics, Security and
Privacy Research Group (SPRITZ), University of Padua, 35121, Padua, Italy.
(email: mohammadreza.mohammadi@studenti.unipd.it).

M. Conti is a professor in the Department of Mathematics and the Director
of the Security and Privacy Research Group (SPRITZ) at the University of
Padua, Italy. (e-mail: mauro.conti@unipd.it).

redirect the users to unauthorised websites. Attackers make it
easy for people to be steered to phishing or malware websites
to steal their conï¬dential data, make a fast buck, or defraud
them by injecting dangerous code into these websites. Every
year, such illegal activities cost billions of dollars [1]. Most
harmful websites are almost identical to genuine websites,
and the user cannot distinguish between them. In order to
minimise the effects of this scam, organisations and enterprises
are investing a signiï¬cant amount of money in keeping their
systems secure against these harmful links and URLs.

The researchers made several attempts to distinguish the
malicious URL using statistical analysis and the popularity
feature of the domain name [2]. Though most phishing and
malicious sites have a short lifespan, these features may not
be available to them for analysis. As a result, the rate of
misclassiï¬cation rises. The creation of new URLs daily makes
the job more challenging. URL analysis also serves as a barrier
between the victim and the malicious website. There are
currently two primary trends in identifying malicious URLs:
the ï¬rst is detecting malicious URLs based on ruleâ€™s set, and
the second is based on a behavioural analysis approach. The
approach based on rules set can efï¬ciently and precisely detect
harmful URLs. However, this strategy cannot recognise latest
malicious advertisement URLs which do not match any of
the speciï¬ed indicators. Deep learning and machine learning
algorithms have wide use in categorising malicious URLs
based on their behaviour analysis techniques. Classiï¬cation
tasks across a wide range of domains have been found to
perform better with deep learning approaches than feature-
based learning approaches. Nevertheless, the performance of
every deep learning model
is determined by a variety of
aspects such as hyper-parameter tuning, neural network design,
and more.

A. Contribution

The following is a summary of our contributions to this

article:

â€¢ We devise and integrate the collection of innovative
lexical and web-scrapped features [3] for the precise
categorisation of legitimate and malicious advertisement
URLs. Additionally, we utilize several essential human-
engineered and URL segmentation features. Furthermore,
we examine a range of statistical properties of the URL
for a brief idea about the malicious and legitimate class
of URL.

â€¢ We conduct our study on a number of datasets with
various URL schemes and orientations, and we analysed

 
 
 
 
 
 
our modelâ€™s performance on these datasets. This method
aims to train machine learning models for all URL forms
thoroughly.

â€¢ We investigate the performance of our four distinct classi-
ï¬ers using a range of parameters and the detection results
using a balanced matched and mismatched URL dataset.
With the right combination of features, we achieve the
highest detection accuracy up to 99.63% and the lowest
false negative rate as low as 0.0037 in detection.

â€¢ We use the K-Means clustering technique to integrate
the result in a visual comprehension with the formation
of clusters. We also make use of the elbow approach to
determine the number of cluster classes.

â€¢ We analyse how adversarial attacks affect our ensembles
and our classiï¬ersâ€™ vulnerability. We use the Zeroth
Order Optimization black-box approach on our models
to account for the limited knowledge scenario.

B. Organisation

This paper is divided into six sections that begin with the
Introduction section, afterwards the related work in Section
III, Background task and knowledge of our framework in
Section II, followed by the feature extraction process, machine
learning-based malicious URL detection model, prediction,
clustering, and adversarial attack implementation in Section
IV, then presenting the outcomes of our approach, as well
as a comparative study of past workâ€™s results, and discussion
in Section V, and lastly, we discussed the conclusion of our
research and future work in Section VI. Our code and all the
datasets are available on GitHub [4].

II. BACKGROUND

Here, we lay out the background information of datasets
used in our experiment in Section II-A, statistical properties
in Section II-B, and pre-processing task in Section II-C. Here,
we will also talk about classiï¬cation methods in Section II-D
and the setting of an adversarial attack in Section II-E.

A. Datasets

The experiment setup for advertising URLs from 12 distinct
datasets includes 3980870 URLs. There are two kinds of URLs
in these contained in these datasets: benign and malicious.
Furthermore, the malicious URL dataset includes four distinct
sub-categories: spam, defacement, malware, and phishing. We
also examined all of the URLs using the VirusTotal [5] tool
to conï¬rm their authenticity. Each URL is labelled with â€™0â€™
for benign and a â€™1â€™ for malicious in the dataset. The URLs
that performed the classiï¬cation task are divided into two
categories listed here.

1) Benign Dataset: The benign URLs were gathered from
available sources on the Internet. Table I gives an overview
of the six benign URL datasets. In Alexa, [6] trafï¬c rating is
used to rate the URLs, which is calculated by a combination
of the browsing behaviour of online users, the total unique
visitors, and the number of site trafï¬c. CrowdFlower [7] is
a large-enhanced dataset of categorised websites; contributors

2

visited supplied links and chose a primary and sub-category for
URLs. DMOZ [8] is a big open directory that is communally
managed and categorises web material. The information is
presented in a sophisticated XML format. Benign set URL
[9] and Non-malicious URL [10] are the open-source datasets
available on Kaggle. ISCX-URL-2016 [11] is produced by the
research and development unit Canadian Institute for Cyber-
security that draws on the experience of social researchers,
business researchers, computer scientists, engineers, lawyers,
and scientists. [12]. If we talk about the format, Alexa and
CrowdFlower datasets have sub-domain and domain in the
URL, DMOZ and Benign set URLs (Benign) have protocol
and hostname, and Non-malicious url and ISCX-URL-2016
(Benign) have all URL components.

TABLE I
BENIGN DATASETS

Sr. No.
1
2
3
4
5
6

Dataset Name
Alexa [6]
CrowdFlower [7]
DMOZ [8]
Benign set URL [9]
Non-malicious URL [10]
ISCX-URL-2016 [11]

Volume
1000000
31084
1048576
345737
344821
35378

Year
2019
2020
2019
2019
2019
2016

2) Malicious Dataset: We gather

the malicious URL
datasets from various open sources on the Internet and divide
into four sub-categories: spam, defacement, phishing, and
malware. Table II contains the summary of the six malicious
URL datasets. As an open community website, Phishtank [13]
is a free service for sharing phishing URLs, and users can send
suspicious URLs to Phishtank for veriï¬cation. Cisco Talos
Intelligence Group updates data on this website on an hourly
basis. Phishstrom [14] is a malicious dataset with features
built and used for evaluation in the paper [15]. Phishing
Site URL [16], Malicious data URL [10], and Malicious set
URl [9] are the open-source datasets available on the web.
ISCX-URL-2016 (malicious) [11] dataset of malicious URLs
contains four different sub-categories of malicious URLs. All
of the malicious datasets in this section have complete URL
components.

TABLE II
MALICIOUS DATASETS

Sr. No.
1
2
3
4
5
6

Dataset Name
Phishing Site URL [16]
Phishtank [13]
Malicious data URL [10]
ISCX-URL-2016 [11]
Phishstrom [14]
Malicious set URL [9]

Volume
549347
223056
75643
129988
47909
104438

Year
2020
2021
2019
2016
2013
2019

The six benign and six malicious URL datasets are com-
bined to create six balanced datasets which contain an equal
number of malicious and benign URLs with a split size
of half of the benign data. The benign datasets are then
combined based on their resemblance to malicious datasets.
The combined information from the merged datasets is also
displayed in Table III.

TABLE III
MERGED DATASETS

Dataset Name Merged Dataset

Dataset 1
Dataset 2
Dataset 3
Dataset 4
Dataset 5
Dataset 6

Alexa + Phishing Site URL
Crowdï¬‚ower + Phishtank
DMOZ + Malicious data URL
Benign set URL + ISCX-URL-2016 (Malicious)
Non-malicious URL + Phishstrom
ISCX-URL-2016 (Benign) + Malicious set URL

B. Statistical Characteristics of the Datasets

To better understand our data, we perform a statistical study
of legitimate and malicious advertisement URLs based on
lexical properties here. In this analysis, we discovered that the
length of malicious ad URLs has a broader range of dispersion
than benign URLs. The majority of benign URLs are between
25 and 50 characters long, with an average length of 44.28
characters. The average number of special characters in a
benign URL is 8.64, with a path length of 17.54 characters.
Fig. 1 shows the frequency distribution of benign URL lengths.

Fig. 1. Frequency Distribution of URL Length - Benign

The majority of malicious ad URLs are between 25 and 105
characters long, with an average length of 63.14 characters.
Malicious URLs have 13.98 special characters on average and
a path length of 42.60 characters. We also discovered that
less than 2 per cent of malicious ad URLs use IP as a domain
name. Fig. 2 presents the frequency distribution of malicious
URLs.

Fig. 2. Frequency Distribution of URL Length - Malicious

3

C. Preprocessing of Datasets

Our prototype platformâ€™s implementation accepts a speciï¬ed
shape of the input dataset. As a result,
to acquire more
precise outcomes, the dataset must be modiï¬ed and reshaped
to meet our relianceâ€™s required input format. We scale the data
using the interquartile range method during the preprocessing
stage. All redundant and raw valued cells were removed, and
repeated hostname URLs were excluded. The URL datasets
were then shufï¬‚ed, and samples were taken from the datasets
for further investigation.

D. Classiï¬cation Techniques

The Classiï¬cation method is a Supervised Learning tech-
nique that uses training data to identify the category of new
observations. Predictive models train from a given dataset or
collection of observations and afterwards categorize subse-
quent observations into one of many classes or groupings.
Classes are sometimes known as targets/labels or categories.
Boosting is an ensemble modelling approach that aims to con-
struct a robust classiï¬er from many weak classiï¬ers. This task
is performed by building a model by sequentially connecting
weak models. First, a model is constructed using the training
data. Then the second model is constructed to address the
faults in the previous model. The is repeated again and again
until the entire training data set is adequately predicted or the
maximum number of models added. Here, we discussed some
of the classiï¬cations and boosting techniques we used in our
research.

1) Random Forest: A Random Forest is a large collection
of decision trees that differ slightly from the others. Random
Forest is based on the premise that while every tree may
predict quite well,
it almost certainly overï¬ts some data.
Overï¬tting can be limited by averaging the outcomes of
numerous trees that all operate well and overï¬t in different
ways. This reduction in overï¬tting can also be demonstrated
while keeping the predictive power of the trees. The important
parameter to alter are n estimators, max features, and pre-
pruning settings such as max depth. For n estimators, larger
value is preferred. As more trees are averaged, an ensemble
becomes more robust as overï¬tting is reduced. However, more
trees require more memory and training time.

2) Gradient Boost: Gradient boosting is another ensemble
approach that combines numerous decision trees to generate
a more signiï¬cant model. Unlike the Random Forest method,
Gradient Boosting works by successively creating trees for
every tree, attempting to ï¬x the ï¬‚aws of the preceding one.
Randomization is not employed by default in Gradient Boost
regression trees; instead, severe pre-pruning is used. Gradient
Boost
trees usually employ extremely shallow trees with
depths ranging from one to ï¬ve, reducing memory needs and
speeding up the prediction. Gradient Boost tree models depend
on three primary parameters: n estimators, number of trees,
and learning rate, that deduce the extent by which new tree
corrects the errors of the previous one. It is common practice
to ï¬t n estimators for learning rates according to a time and
memory budget and then comparing.

3) AdaBoost: Another ensemble method in Machine
Learning, AdaBoost, or Adaptive Boosting, is a boosting algo-
rithm. During the data training period, it generates n decision
trees. When the ï¬rst decision tree/model is constructed, the
incorrectly classiï¬ed record in the ï¬rst model is prioritised.
Only these records are sent to the second model as input.
The process is repeated until we specify how many base
learners we want
to create. With all boosting techniques,
record repetition is permitted. The incorrectly classiï¬ed record
is used as input for the next model. This process is repeated
until the speciï¬ed condition is met.

4) XGBoost: XGBoost, or extreme Gradient Boosting,
enhances performance and speed aspects of Gradient Boost
decision trees implementation. To create a machine learning
algorithm, it used a Gradient Boost framework. The regu-
larisation term reduces over-ï¬tting by smoothing the ï¬nal
learned weights. Models using basic, predictive functions will
be favoured by the regularised objective. Here, the model is
taught additively instead of the traditional optimization method
for the tree ensemble model in the Euclidean space. Due to
its simultaneous and distributed processing, XGBoost is faster
than other algorithms.

E. Adversarial Attack

Adversarial machine learning technique aims to exploit
models by developing harmful attacks using accessible model
information [17]. The main reason for exploitation is to affect
machine learning and fail
it. Here, we will examine the
adversarial attack on our models. It has been discovered that
an intelligent malicious URL generating system can generate
URLs that can pass machine learning classiï¬ers at a low rate.
White-box, gray-box, and black-box attacks are the three main
types of adversarial attacks.

â€¢ White-Box Attack: In a white-box attack, the attackers
have complete access to the modelâ€™s architecture, pa-
rameters, weights. L-BFGS [18] black-box constrained
method was proposed to minimise the additive pertur-
bation based on classiï¬cation restrictions; however,
it
was inefï¬cient. The Fast Gradient Sign Method [19]
eventually conquered it, followed by the primary iterative
method of adding perturbations iteratively. Other white-
box adversarial attacks include JSMA, BIM & ILCM,
ATNs, and DeepFool.

â€¢ Black-Box Attack: In black-box attacks,

the attacker
have no access to the system. The systemâ€™s parameters
and weights cannot be obtained here, opposite to white-
box attack, which need the target neural networks to be
differentiable. Zeroth Order Optimization may directly
approximate the gradients of the target network using
zeroth order stochastic coordinate descent. Other exam-
ples of black-box adversarial attacks include One-pixel,
UPSET, and ANGRI.

â€¢ Grey-Box Attack: The grey-box attacks use only training
access to the target model to create adversarial samples.

Counter-Forensic Attack Model: Here we shall formulate
the universal adversarial paradigm for counter forensic attacks

4

in this text. An adversarial model is characterised by demon-
strating adversaryâ€™s goal, systemâ€™s knowledge, and capacity of
corrupting the system through data manipulation [20], [21].

â€¢ Attackerâ€™s goal: It describes the type of security violation
and the type of error the attacker seeks. Counter forensic
attacks are often either integrity violations or evasion
attacks. The adversaryâ€™s goal determines the loss function
that the adversary seeks to maximise.

â€¢ Attackerâ€™s knowledge: This deals with if the attack has a
limited amount of knowledge about the model or perfect
knowledge. The attacker is fully aware of the forensic
algorithm in a perfect knowledge scenario and aware of
a few details or settings relevant to the forensic algorithms
in a restricted knowledge scenario.

â€¢ Attackers capability: It refers to the adversaryâ€™s level
of control over training and testing data. The attackerâ€™s
capability in the exploratory attack paradigm is restricted
to modiï¬cations to test data, whereas modiï¬cations to
training examples are still not permissible. The attack
can interrupt the training process in a causative attack
scenario, referred to as a poisoning attack.

This article considers the exploratory attack scenario and
shall discuss the ZOO attack. The ZOO attack is a version
of the C&W attack [22] that employs ADAM coordinate
descent to perform numerical gradient estimates. As with any
tree attack, there is the risk of misclassiï¬cation of objects or
data. It can also involve picture captioning, voice recognition
misclassiï¬cation, and data regression effects. Because a white-
box attack relies on the modelâ€™s overall knowledge growth, this
black box attack has just a limited knowledge of the targeted
model. It has an unknown training technique as well as data. It
also includes unidentiï¬ed output classes and model conï¬dence.
Many research challenges are concerned with complex data
creation processes that, although analytically explainable, can
provide types of measurements such as measures from physi-
cal surroundings or predictions from deploying machine learn-
ing techniques. In black-box models, these kinds of challenges
are incorporated into Zeroth Order Optimization (ZOO).These
sorts of issues are put into Zeroth Order Optimization in black-
box models. The ZOO Attack, also known as Derivative-Free
Optimization, solves problems that do not have direct access
to gradients.

III. RELATED WORK

Signiï¬cant research has been conducted earlier to detect
malicious advertising and phishing websites in a variety of
ways. The traditional approach of blacklisting the malicious
ads related sites gives out as the list consists of only known
malicious URLs [23]. Although it is a powerful feature indica-
tion, it takes several hours for a malicious URL to be banned,
and its implementation is infeasible. As a result, the system
fails when a new malicious URL is encountered. Researchers
later proposed URL analysis based on lexical aspects [24],
statistical properties [25], host-based features [26], content
features [27], and popularity-based factors [28]. Thomas et
al. [29] developed a real-time URL spam ï¬ltering process that
involved based on IPs, lexical and HTML parameters. The

TABLE IV
LEXICAL FEATURE GROUP

5

Sr. No.
1

Feature Subgroup

Feature Name
URLLength

Data Type
Integer

2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49

CheckIPAsHostName
CheckEXE
DigitAlphabetRatio
SpecialcharAlphabetRatio
UppercaseLowercaseRatio
DomainURLRatio
NumericCharCount
EnglishLetterCount
SpecialCharCount
DotCount
SemiColCount
UnderscoreCount
QuesMarkCount
HashCharCount
EqualCount
PercentCharCount
AmpersandCount
DashCharCount
DelimiterCount
AtCharCount
TildeCharCount
DoubleSlashCount
IsHashed
TLD
DistDigitAlphabet
HttpsInUrl
FileExtension
TLDInSubdomain
TLDInPath
HttpsInHostName
HostNameLength
PathLength
QueryLength
DistWordBased
URLWithoutwww
FTPUsed
JSUsed
FilesInURL
CSSUsed
IsDomainEnglishWord
IsDomainMeaningful
IsDomainPronounceable
IsDomainRandom
Unigram
Bigram
Trigram
SensitiveWordCount
InSuspiciousList

Binary
Binary
Float
Float
Float
Float
Integer
Integer
Integer
Integer
Integer
Integer
Integer
Integer
Integer
Integer
Integer
Integer
Integer
Integer
Integer
Integer
Binary
String
Float
Binary
String
Binary
Binary
Binary
Integer
Integer
Integer
Binary
Binary
Binary
Binary
Binary
Binary
Binary
Binary
Binary
Binary
Float
Float
Float
Integer
Binary

Linguistic Features

Human-Engineered
Features

Feature Description
Compute length of the URL e.g. the URL length is 51 of
https://www.example.com/seo-tools/count-characters/
Check if IP address is used as hostname e.g. www.192.168.0.1
To look the presence of .exe in URL
To compute the ratio of number of digit to alphabets in URL
To compute the ratio of number of special characters to alphabets in URL
It computes ratio of uppercase characters to lowercase characters in URL
To compute the ratio of domain length to URL length
Number of numeric character viz. 0,1,2,...,9
Number of English letter viz. a,b,c,...,z and A,B,C,...,Z
Number of special character viz. !,$,â€,...etc.
Number of â€˜.â€™ characters
Number of â€˜;â€™ characters
Number of â€˜ â€™ characters
Number of â€˜?â€™ characters
Number of â€˜#â€™ characters
Number of â€˜=â€™ characters
Number of â€˜%â€™ characters
Number of â€˜&â€™ characters
Number of â€˜-â€™ characters
Number of the dilimeter characters in URL viz. (),{}[],,/*,*/,...etc.
Number of â€™@â€™ characters
Number of â€˜âˆ¼â€™ characters
Number of â€˜//â€™ characters in the link path
To check if URL is hashed (If any hash function is used to convert URL)
To look for top level domain of URL e.g. .com, .us, .org
Distance between number to alphabet
Check the presence of https in URL
To check the extension of the ï¬le in URL
Check whether subdomain have TLD or ccTLD as its part
Check whether subdomain have TLD or ccTLD in link of URL
Check for the disarrangement of https in URL e.g. â€˜www.wordforhttps.inâ€™
Hostname length of URL
Path length of URL
Length of the query In URL
Check if URL is contain anonymous words (personal, .bin, abuse etc.)
To check if www is present in the URL
Check if â€œftp://â€ is there in the URL
Check if â€œ.jsâ€ is there in the URL
Check if ï¬les is there in the URL
Check if â€œ.cssâ€ is used in the URL
Check if domain name is English language word as per US/UK dictionary
To check if domain name is English language word and meaningful
To check if domain name can be pronounced
To compute the randomness of the URL string
To calculate uni-gram probability
To calculate bi-gram probability
To calculate tri-gram probability
Sensitive words in URL (i.e., â€œsecureâ€, â€œaccountâ€, â€œwebscrâ€, â€œloginâ€ etc)
To check if URL is present in suspicious list from malicious dataset

popularity features are the details about the URLâ€™s position on
social media or its rating. Choi et al. [30] used URL lexical
analysis to identify multiple forms of malicious assaults. Xiang
et al. [31] employed machine learning algorithms with a large
collection of rich features. In Twitter streams, Lee and Kim
[32] discovered suspicious URLs by examining and analysing
associated redirect chains of URLs in several tweets. Further-
more, determining which features are valuable necessitates
specialist topic knowledge, yet our strategy of combining the
innovative combination of rich features proved to be thoughtful
exertion.

Based on the machine learning approaches, a number of
fraudulent advertisements URL detection systems were cre-
ated, including logistic regression [33], Nave Bayes [34], de-
cision trees, and ensembles [35]. Garera et al. [36] research is

based on logistic regression, with a few variables incorporated
in the extraction to categorise harmful URLs [16]. Fette et
al. [37] classify phishing emails using statistical approaches
from machine learning. The classiï¬ers examine the structure
and content of the email. Bergholz et al. improve on the
technique mentioned aboveâ€™s accuracy by incorporating text
classiï¬cation algorithms to examine email content [38]. Abu-
Nimeh et al. [39] compares multiple classiï¬ers on a database
of phishing emails, using the frequency of the corpusâ€™s top 43
keywords as attributes. Numerous online tools are available
on the web that can help detect malicious URLs, such as
URL Void, UnMask Parasites, Norton Safe Web, Google Safe
Browsing Diagnostic, SiteAdvisor, VirusTotal, and Browser
Defender. However, their effectiveness is limited due to their
signature-based nature. In this article, we will look at the most

popular ensemble strategies and compare the accuracy of all
the models.

Extensive research has been conducted on the adversarial
attack on deep learning models [22]. An investigation of
the robustness of deep neural networks was conducted when
they were exposed to small simulated perturbations [40]. In
this context, the adversarial robustness of machine learning
models was also investigated. Barreno et al. workâ€™s [41] is
part of a series of security evaluations of machine learning
algorithms that includes various attacks on machine learning
techniques and systems. Huan and Wardey-paper Farleyâ€™s [42]
laid the groundwork for such work using sophisticated model
architecture and parameters, including the use of adversarial
examples to improve the classiï¬erâ€™s robustness. A reliable
technique for identifying adversarial perturbations is required
to investigate and assess the robustness of different classiï¬ers
to adversarial perturbation.

IV. METHODOLOGY

In this section, we present our working mechanism with
feature extraction procedure in Section IV-A, empirical study
in Section IV-B, and adversarial attack on our detection models
in Section IV-C.

A. Feature Extraction

the URL string.

It entails a set of

This phase of research aims to gather important information
features with
about
distinguishing characteristics used to specify different dataset
categories. Since we wish to differentiate between fraudulent
and genuine advertisement URLs, we do this work using two
lexical and web-scrapped features.
key feature categories:
These are covered in the next section.

1) Lexical Features: We used the fundamental features
from the URL string for easy demonstration and some ad-
vanced aspects for an unconventional approach in this set of

Algorithm 1: Check domain is English language word

INPUT: domain name
OUTPUT: Meaningful, English word, Pronounceable,
Random string
break domain name in words = words[]
IF domain name belongs to wordnet.synsets

Return TRUE

ELSE

Return FALSE

IF words[] is not NULL

Check for parts of speech
IF words[] has Noun, Pronoun

Return Meaningful

ELIF words[] has Verb, Adjective

Return Pronounceable

ELSE

Rerurn Random string

END

6

features. These are further classiï¬ed into two types: linguistic
features and human-engineered features. Linguistic features
comprise essential URL string qualities such as length-based
features (length of the URL string, domain length, etc.),
presence of an object (.exe presence in the string, etc.), count-
based features (alphabet, special character count, etc.), and
TLDs. In this scenario, features such as the digits-to-alphabet
ratio are also relevant because most malicious algorithmically
created domains have considerably more digits than alphabets.
Aside from the bag-of-words features, statistical features help
signiï¬cantly in gaining a quick understanding of the path,
query, and URL length.
If the domain name has any credibility in terms of being a
meaningful, easy-to-pronounce, and random string, as proven
in Algorithm 1, Human-Engineered Features perform well
enough in this classiï¬cation task. We considered the UK/US
English dictionary to state the domain name as a meaningful,
pronounceable or random string in the identiï¬cation process.
We also collect â€n-gramâ€ data for both legitimate and non-
legitimate advertising URLs. We generate the bag-of-words by
extracting 2-gram and 3-gram tokens from the data mentioned
above sources. This allows us to break each input URL into
two or three token sequences and verify the presence of the
target token in the bag. The sensitive words contained domains
have a high chance of being malicious, and we created it as a
feature. We also check whether the domain name is present in
the list of suspected lists. Please see Table IV for a complete
list of lexical feature groups as well as an overview of the
features.

2) Web-scrapped Features: In this feature group, we would
like to extract the web information of the URLâ€™s domain
name and deal with the obfuscation problem. Some harmful
URLs overlap lexical features with benign URLs. As a result,
web scraping of URLs will offer us the required solution.
URL-segmentation, deep-web features, host-based features,
and content-based features are the four subgroups of our
web-scrapped feature group. We want to identify ways to
that spoof a domain name in URL segmentation. Whence,
with Python, the domain name is sent as a query request
in the Google search engine, and the ï¬rst 60 results are
collected for the process of hit counts. If the exact domain
name exists, it is recorded as a count. This approach takes a
little time, but it signiï¬cantly inï¬‚uences the straightforward
categorisation procedure. If similar name is found in netloc,
it
is an excellent chance to be a clean domain name. In
Deep-Web Features, we create a list of 11 distinct types
of typosquats of the searched domain name (see Table V)
and examine all registered domain names among them. We
also created a fuzzer for this step, which attempts to ï¬nd
typosquat domain names for each searched domain name. The
phishing domains can be identiï¬ed using above technique.
We also computed the Lavenshtein distance and Shannon
entropy with the most comparable query request results and
saved it as a feature using the same method. The Lavenshtein
distance between two words is the number of single-character
modiï¬cations necessary to transform one term into another.
In the Host-based Features subgroup, we included URL
host-name attributes such as WHOIS information, IP address,

7

Feature Subgroup

Deep-Web Features

URL Segmentation

Host-Based Features

Content-Based Features

Sr. No.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40

TABLE V
WEB-SCRAPPED FEATURE GROUP

Feature Name
LevenshteinDistance
Entropy
Hyphenstring
Homoglyph
Vowel
Bitsquatting
InsertionString
Omission
Repeatition
Replacement
Subdomain
Transposition
AdditionString
GoogleSearchFeature
IPAddress
ASNNumber
ASNCountryCode
ASN CIDR
ASNPostalCode
ASNCreationDate
ASNUpdationDate
DomainAgeInDays
ImgCount
TotalLinks
NumParameters
NumFragments
BodyTagCount
MetaTagCount
DivTagCount
FakeLinkInStatusBar
RightClickDisabled
PopUpWindow
CheckMailto
CheckFrametag
TitleCheck
SourceEvalCount
SourceEscapeCount
SourceExecCount
SourceSearchCount
ImageOnlyInForm

Data Type
Float
Float
String
String
String
String
String
String
String
String
String
String
String
Integer
Numeric
Numeric
Numeric
Numeric
Numeric
Numeric
Numeric
Numeric
Integer
Integer
Integer
Integer
Integer
Integer
Integer
Binary
Binary
Binary
Binary
Binary
Binary
Integer
Integer
Integer
Integer
Binary

Feature Description
To calculate Levenshtein distance
To calculate shannon entropy of the URL
To get hyphenated domain name of URL for typosquat
To get homoglyph string for typosquat
To get vowel swap string for typosquat
To get bitsquatting string for typosquat
To get insertion string for typosquat
To get omission string for typosquat
To get repitition string for typosquat
To get replaced string for typosquat
To get subdomain string for typosquat
To get transposition string for typosquat
To get addition string for typosquat
Array of top 60 results of URL querying the Google search engine
To get the IP address of the host name
To get the ASN number of the URL
To get ASN country code
To get the CIDR number of the host name
To get ASN postal code
To get the creation date of the domain name
To get the updation date of the domain name
The duration of a domainâ€™s registration
To count the images in the webpage
To count links in the webpage
Number of parameters of the URL
Number of fragments of the URL
Counting the body tag in webpageâ€™s html source code
Counting the meta tag in webpageâ€™s html source code
Counting the div tag in webpageâ€™s html source code
Check whether display of fake URL JS command on MouseOver
Check the presence of command to disable right click
Check the presence of command to start popup window
Whether â€mailtoâ€ is present in HTML source code
Whether frame or iframe used in HTML source code
In HTML source codes, see whether title tag is empty
Count of eval () functions in HTML source code
Count of escape () functions in HTML source code
Count of exec () functions in HTML source code
Number of search() functions HTML source code
Check whether only image are present in HTML source code

location details, and country code. These include registration
details, domain age, country code, location, and registrant
company. As these attributes have identity-related qualities,
they are recorded in numerical vectors with unique identities.
For malicious URLs, the time-to-live from domain registration
is nearly instantaneous. Many of them employed botnets for
hosting for themselves on machines spread across various
countries. As a result, host-based characteristics play an essen-
tial role in detecting malicious URLs. When the web page is
completely downloaded, Content-Based Features are gained.
Our research extracts HTML document-level information of
the web page i.e. total images, the total links, and different tags
from the source code. If malicious URLs remain undetected
by URL-based features, then these attributes will function
effectively in detecting threats by analysing the web page.

B. Empirical Study

This section describes our suggested supervised URL clas-
siï¬cation and unsupervised clustering approaches for detecting
fraudulent advertisement URLs. We intend to assess if a given
URL is benign or malicious by making binary classiï¬ca-
tion problem. Consider the following collection of ğ‘ URLs:

(ğ‘¢1, ğ‘¦1), ..., (ğ‘¢ğ‘›, ğ‘¦ğ‘›). Here, ğ‘› = 1, ...ğ‘ speciï¬es a URL, and
URL label is denoted by ğ‘¦ğ‘, with ğ‘¦ = 0 denoting the benign
URL and ğ‘¦ = 1 denoting the malicious URL. The ï¬rst step is
to represent the features ğ‘¢ğ‘› â†’ ğ‘ğ‘›, where ğ‘ğ‘› is ğ‘›-dimensional
feature vector corresponding to the URL ğ‘¢ğ‘›. The problem
can be expressed as a function ğ‘¦ğ‘› = ğ‘ ğ‘–ğ‘”ğ‘›(ğ¿ ğ‘“ (ğ‘ğ‘›)). We may
reduce the overall number of errors in the classiï¬cation process
by minimising the loss function. We retrieved 89 features
from each URL and processed them for the classiï¬cation
phase based on the previous section. A balanced dataset of
both legitimate and non-legitimate URLs is used to detect the
fraudulent URL. We used 1000 URLs from each of our six
balanced merged datasets to train our four classiï¬ers with
appropriate parameters. Depending on the simulation task,
we used a split size of around 0.7 for training and 0.3
for testing. These 89 features will be used by classiï¬ers to
differentiate between clean and malicious URLs. In contrast
to prior research that only considered a restricted element of
the feature categories, we created a unique set of these highly
inï¬‚uential feature categories and attempted to combine a good
combination. For supervised machine learning methods, we
used Random Forest, Gradient Boost, AdaBoost, and XGBoost

approaches. For each of our datasets, we examined the rela-
tive performance of all models. Then, to study the accuracy
behaviour, we trained our models on mismatched datasets,
training the complete one dataset and evaluating it on the other
ï¬ve. This procedure is carried out on all datasets with all model
selections. We continued our research by testing our models
on unlabeled datasets. We took all of the necessary criteria for
the categorisation stage, as discussed in the previous section.
The process of grouping data points such similar data points
are placed in same group and dissimilar from other data points
in different groups is known as clustering. We employed the K-
Means clustering method in this unsupervised learning strategy
to better visualise malicious and benign data. The method will
classify the objects into k groups of similarity, with an optimal
value of k equal to 2 expected for exact results. The euclidean
distance will be used as a measurement
to calculate that
similarity. The Elbow approach is used to do this assignment.
We cycle through the k values from 1 to 9 to calculate the
distortion for each k value in the deï¬ned range. To get the
optimal number of clusters, we must determine the value of k
at the elbow or the point where the distortion begins to drop
linearly.

C. ZOO - Adversarial Attack

This section will investigate our ensemblesâ€™ vulnerability to
adversarial attack. Unlike white-box attack approaches, which
in black-box
need the target network to be differentiable,
ZOO attack the gradients are estimated uning zeroth order
stochastic coordinate descent of the targeted network. Here,
for this reason, we will select a loss function that is only
dependent on the output of the targeted network in order to
compute the gradient by using the ï¬nite difference method. We
will use zeroth order optimization to solve the optimization
problem. Here, for the input vector ğ‘, the loss function ğ¿ ğ‘“
can be deï¬ned for output ğ‘‚ ğ‘“ as

ğ¿ ğ‘“ (ğ‘, ğ‘) = max{max
ğ‘—â‰ ğ‘

log[ğ‘‚ ğ‘“ (ğ‘)] ğ‘— âˆ’ log[ğ‘‚ ğ‘“ (ğ‘)] ğ‘, âˆ’ğœŒ}, (1)

where ğœŒ â‰¥ 0 and log ğ‘ â†’ âˆ’âˆ whenever ğ‘ â†’ 0. Because the
ğ‘™ğ‘œğ‘” function is a strictly monotonic function, ğ‘šğ‘ğ‘¥ = 0 follows.
As a result, ğ‘ has the greatest conï¬dence score for targeted
class label ğ‘. Strictly monotonic functions are those function
which for ğ‘¥ > ğ‘¦ satisfy ğ‘“ (ğ‘¥) > ğ‘“ (ğ‘¦). Here, the dominant
inï¬‚uence is decreased by the log operator and maintain the
conï¬dence order due to monotonicity. For untargeted attacks,
if ğ‘ is classiï¬ed as any different from original label ğ‘0, then
adversarial attack will be considered successful. For untargeted
attack , the most probable pridicted class after eliminating ğ‘
is

ğ¿ ğ‘“ (ğ‘¥) = max{log[ğ‘‚ ğ‘“ (ğ‘)] ğ‘0 âˆ’ max
ğ‘—â‰ ğ‘0

log[ğ‘‚ ğ‘“ (ğ‘)] ğ‘— , âˆ’ğœŒ},

(2)

label

for ğ‘ is denoted by ğ‘0,
where original class
and the most probable predicted class is represented by
ğ‘šğ‘ğ‘¥ ğ‘—â‰ ğ‘0 log[ğ‘‚ ğ‘“ (ğ‘)] ğ‘— other than ğ‘0. The attack employs the
optimization technique for the general ğ¿ ğ‘“ . If a functionâ€™s
symmetric derivative exists at point ğ‘, it is symmetrically

8

differentiable at that point. Therefore, the symmetric difference
quotient is:

Ë†ğ‘” ğ‘— :=

ğœ•ğ¿ ğ‘“ (ğ‘)
ğœ•ğ‘ ğ‘—

â‰ˆ

ğ¿ ğ‘“ (ğ‘ + ğ‘˜ğ‘’ ğ‘— ) âˆ’ ğ¿ ğ‘“ (ğ‘ âˆ’ ğ‘˜ğ‘’ ğ‘— )
2ğ‘˜

,

(3)

for gradient estimation. Here, we use ğ‘˜ as a very small constant
and standard basis vector is denoted by ğ‘’ ğ‘— where only the
ğ‘—th component have value 1 and all other components equal
to 0. Although numerical precision is important, predicting
the gradient precisely is typically not required for efï¬cient
adversarial attacks. In the coordinate descent approach, one
variable is chosen at random at each iteration and changed
by minimising the objective function along that coordinate.
We can obtain the estimated optimum delta by estimating the
gradient and Hessian for ğ‘ ğ‘— . Here, Hessian estimate is

Ë†â„ ğ‘— :=

ğœ•2ğ¿ ğ‘“ (ğ‘)
ğœ•2ğ‘2
ğ‘— ğ‘—

â‰ˆ

ğ¿ ğ‘“ (ğ‘ + ğ‘˜ğ‘’ ğ‘— ) âˆ’ 2ğ¿ ğ‘“ (ğ‘) + ğ¿ ğ‘“ (ğ‘ âˆ’ ğ‘˜ğ‘’ ğ‘— )
ğ‘˜ 2

,

(4)
The stochastic coordinate descent method in Algorithm 2 and
the ADAM optimizer in Algorithm 3 increased the speed of
the ZOO attack [43]. The ZOO attack is more dependable to
utilise than frequently used gradient-based techniques in this
context due to its computational efï¬ciency approximation and
ease of implementation with only minor modiï¬cations.

Algorithm 2: SCD - Stochastic Coordinate Descent

Initialise ğ‘™ â† 0;
WHILE ğ‘™ â‰¤ ğ¾ DO

Choose ğ‘— (ğ‘™) out of {1, ..., ğ‘š} with same probability
Evaluate and update ğœ‚âˆ—

ğ‘ğ‘Ÿğ‘” minğœ‚ ğ¿ ğ‘“ (ğ‘ + ğœ‚ğ‘’ ğ‘— )

Updating ğ‘ ğ‘— â† ğ‘ ğ‘— + ğœ‚âˆ—
ğ‘™ â† ğ‘™ + 1
END WHILE

Algorithm 3: Coordinate-wise ADAM Zeroth Order
SCD

Requirement: Set step size â„, ADAM hyper-parameters
ğ›¼1 = 0.9, ğ›¼2 = 0.99, ğœ– = 10âˆ’8, and set ADAM states
ğ‘, ğœ âˆˆ Râ„˜

Initialise ğ‘ â† 0, ğœ â† 0, ğ‘ˆ â† 0

WHILE diverges DO

Choose ğ‘— (ğ‘™) out of {1, ..., ğ‘š} with same probability
Evaluate ğ‘ˆ ğ‘— â† ğ‘ˆ ğ‘— + 1
Approximate ğ‘” ğ‘— by using equation (3)
Evaluate ğ‘ ğ‘— â† ğ›¼1ğ‘ ğ‘— + (1 âˆ’ ğ›¼1)ğ‘” ğ‘—
Evaluate ğœğ‘— â† ğ›¼2ğœğ‘— + (1 âˆ’ ğ›¼2)ğ‘”2
ğ‘—
Evaluate Ë†ğ‘ ğ‘— = ğ‘ ğ‘— /(1 âˆ’ ğ›¼ğ‘ˆ ğ‘—

), Ë†ğœ = ğœğ‘— /(1 âˆ’ ğ›¼ğ‘ˆ ğ‘—

)

1

2

ğœ‚âˆ— = âˆ’â„

Ë†ğ‘ ğ‘—âˆš
Ë†ğœ ğ‘— +ğœ–

Update ğ‘ ğ‘— â† ğ‘ ğ‘— + ğœ‚âˆ—

END WHILE

V. RESULTS AND DISCUSSION

Here, we will sum up and discuss our study results by
inspecting the effectiveness of several classiï¬ers, clustering
techniques, and the effects of adversarial attacks on ensembles.
To assess our suggested system, we run a set of rigorous
tests on a desktop computer. The systemâ€™s setup is Intel(R)
Core(TM) Intel Core i5-4300M 2.6GHz, Ubuntu 20.04 LTS
with 4GB RAM, and Python version 3.8.10.

TABLE VI
MATCH CASE DETECTION RESULT

Dataset

Dataset 1

Dataset 2

Dataset 3

Dataset 4

Dataset 5

Dataset 6

Dataset 1

Dataset 2

Dataset 3

Dataset 4

Dataset 5

Dataset 6

Dataset 1

Dataset 2

Dataset 3

Dataset 4

Dataset 5

Dataset 6

Dataset 1

Dataset 2

Dataset 3

Dataset 4

Dataset 5

Dataset 6

Folds
5
10
5
10
5
10
5
10
5
10
5
10

Random Forest

Accuracy
98.72
99.13
98.78
99.07
99.06
99.13
98.42
98.91
98.84
99.18
98.58
99.07

Precision
98.98
99.42
98.77
99.37
99.37
98.86
98.95
98.93
98.86
98.92
98.27
99.38

AdaBoost

5
10
5
10
5
10
5
10
5
10
5
10

5
10
5
10
5
10
5
10
5
10
5
10

5
10
5
10
5
10
5
10
5
10
5
10

98.97
98.97
99.54
99.47
98.58
99.53
99.53
99.52
99.53
99.07
99.53
99.48

98.98
99.23
99.10
99.45
99.13
99.56
99.01
99.27
99.04
99.35
99.14
99.46
Gradient Boost
99.11
99.31
99.14
99.46
99.19
99.60
99.04
99.39
99.11
99.38
99.29
99.54

99.12
99.55
99.56
99.38
99.57
99.60
99.14
99.59
99.55
99.15
99.53
99.55

XGBoost

99.26
99.59
99.24
99.47
99.27
99.63
99.15
99.58
99.35
99.42
99.45
99.63

99.25
99.59
99.25
99.63
99.25
99.63
99.14
99.58
99.15
99.24
99.25
99.63

FPR
0.0104
0.0059
0.0120
0.0062
0.0063
0.0116
0.0107
0.0112
0.0115
0.0112
0.0175
0.0061

0.0101
0.0101
0.0048
0.0052
0.0149
0.0048
0.0050
0.0050
0.0099
0.0091
0.0047
0.0051

0.0091
0.0045
0.0044
0.0041
0.0042
0.0041
0.0062
0.0043
0.0045
0.0083
0.0047
0.0047

0.0073
0.0041
0.0077
0.0036
0.0071
0.0037
0.0085
0.0041
0.0089
0.0078
0.0076
0.0037

FNR
0.0152
0.0115
0.0123
0.0125
0.0125
0.0057
0.0208
0.0107
0.0114
0.0057
0.0116
0.0123

0.0103
0.0052
0.0136
0.0053
0.0048
0.0047
0.0140
0.0095
0.0094
0.0047
0.0141
0.0052

0.0088
0.0090
0.0131
0.0085
0.0127
0.0081
0.0124
0.0043
0.0131
0.0043
0.0093
0.0045

0.0075
0.0041
0.0075
0.0073
0.0075
0.0037
0.0086
0.0042
0.0043
0.0038
0.0038
0.0037

A. Experimental Results

We pick 1000 URLs from each balanced dataset with an
equal number of malicious and benign advertisement URLs

9

for the experiment. The experiment is performed on each of
our four classiï¬ers with 5 and 10 folds. We also consider
the runtime complexity, which grows as the number of folds
increases. It is a problem throughout the training stage but
not during testing. Each of the six datasets took roughly
150 minutes to process. However, the modelâ€™s remarkable
accuracy is worth it in the end. We used Pythonâ€™s Sciket-learn
package and the GridSearchCV library function to cycle over
predeï¬ned hyperparameters, selecting 1, 100, 200, 500, 1000,
and 1500 n estimators to ï¬t on our training set. We got more
precise results as the number of trees increased. The sampled
datasets were examined using the Random Forest model, and
we noticed a gain in accuracy and precision as we moved to
AdaBoost, Gradient Boost, and XGBoost, as well as a drop
in FPR and FNR. We discovered that the ten folds of the
XGBoost classiï¬er had the best detection accuracy. We created
the evaluation matrix using the following formulas.
FPR: The false positive rate is calculated as the proportion of
malicious data that is mistakenly recognised as benign.
FNR: The false negative rate is the proportion of data that is
wrongly classiï¬ed as non-malicious but is, in fact, malicious.

ğ¹ğ‘ƒğ‘… =

ğ¹ğ‘ƒ
ğ¹ğ‘ƒ + ğ‘‡ ğ‘

,

ğ¹ ğ‘ ğ‘… =

ğ¹ ğ‘
ğ‘‡ ğ‘ƒ + ğ¹ ğ‘

Accuracy: Accuracy is calculated as the ratio of accurately
predicted examples to total examples.
Precision: The percentage of malicious data that was success-
fully categorised out of all malicious URLs labelled by the
classiï¬er.

ğ‘ƒğ‘Ÿ ğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘›& =

ğ‘‡ ğ‘ƒ
ğ‘‡ ğ‘ƒ + ğ¹ ğ‘ƒ

, ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿ ğ‘ğ‘ğ‘¦& =

ğ‘‡ ğ‘ƒ + ğ‘‡ ğ‘
ğ‘‡ ğ‘ƒ + ğ‘‡ ğ‘ + ğ¹ ğ‘ƒ + ğ¹ ğ‘

1) Detection Results: We have discussed the accuracy and
precision of our ensembles by using the confusion matrix in
this section with the discussed machine learning techniques.

â€¢ Matched Case

In the matched scenario, the classiï¬er is trained and tested
on a single dataset. The results for all classiï¬ers are
shown in Table VI.
â€¢ Mismatched Case

The classiï¬er is trained on one full dataset and evaluated
on the remaining ï¬ve datasets in the mismatched case.
Table VII shows the results tables for various classiï¬ers
for mismatched datasets.

2) Clustering Results: In this section of our research, we
choose cluster formation to distinguish between two types of
malicious and non-malicious URLs. We employ the K-Means
clustering technique for visual comprehension for this purpose.
We determine the number of clusters necessary to cluster the
dataset using the elbow technique of K-Means. We discover
a gap between the two groups and make a clear distinction.
This creation is seen in Fig. ??, where red represents benign
and blue represents malicious.

10

TABLE VII
MISMATCH CASE DETECTION RESULT

Trained

Dataset 1

Dataset 2

Dataset 3

Dataset 4

Dataset 5

Dataset 6

Trained

Dataset 1

Dataset 2

Dataset 3

Dataset 4

Dataset 5

Dataset 6

Tested
Dataset 2
Dataset 3
Dataset 4
Dataset 5
Dataset 6
Dataset 1
Dataset 3
Dataset 4
Dataset 5
Dataset 6
Dataset 1
Dataset 2
Dataset 4
Dataset 5
Dataset 6
Dataset 1
Dataset 2
Dataset 3
Dataset 5
Dataset 6
Dataset 1
Dataset 2
Dataset 3
Dataset 4
Dataset 6
Dataset 1
Dataset 2
Dataset 3
Dataset 4
Dataset 5

Tested
Dataset 2
Dataset 3
Dataset 4
Dataset 5
Dataset 6
Dataset 1
Dataset 3
Dataset 4
Dataset 5
Dataset 6
Dataset 1
Dataset 2
Dataset 4
Dataset 5
Dataset 6
Dataset 1
Dataset 2
Dataset 3
Dataset 5
Dataset 6
Dataset 1
Dataset 2
Dataset 3
Dataset 4
Dataset 6
Dataset 1
Dataset 2
Dataset 3
Dataset 4
Dataset 5

Random Forest
Accuracy
98.69
98.89
98.81
98.92
98.65
98.78
98.70
98.70
98.56
98.68
98.83
98.66
98.39
98.61
98.77
98.53
98.43
98.59
98.71
99.04
98.67
98.70
98.49
98.63
98.73
98.38
98.34
97.80
98.07
98.16

Precision
98.77
99.18
99.09
98.69
98.79
98.95
98.88
98.75
98.16
98.41
98.59
98.81
98.04
98.37
98.59
98.64
98.58
98.58
98.98
98.84
98.60
98.56
98.13
98.27
98.33
98.05
98.22
98.05
98.55
98.39

Gradient Boost
Accuracy
98.58
98.96
98.95
99.05
98.87
98.95
99.11
99.12
98.12
98.91
98.97
98.84
98.87
98.94
99.15
98.75
98.79
98.91
98.97
99.16
98.89
98.99
99.04
98.95
98.96
98.75
98.85
98.64
98.92
98.77

Precision
98.84
98.75
98.80
99.22
98.97
98.89
98.87
98.98
98.12
98.57
98.59
98.44
98.57
98.85
98.74
98.54
98.57
98.44
98.79
98.89
99.15
98.75
99.15
98.94
98.95
98.26
98.66
98.44
98.46
98.36

FPR
0.0121
0.0083
0.0091
0.0129
0.0119
0.0103
0.0111
0.0123
0.0181
0.0157
0.0138
0.0118
0.0194
0.0161
0.0140
0.0166
0.0174
0.0139
0.0099
0.0113
0.0137
0.0142
0.0184
0.0170
0.0164
0.0229
0.0209
0.0228
0.0170
0.0190

FPR
0.0118
0.0127
0.0122
0.0081
0.0100
0.0109
0.0100
0.0099
0.0102
0.0139
0.0138
0.0151
0.0140
0.0113
0.0123
0.0143
0.0140
0.0152
0.0118
0.0109
0.0083
0.0122
0.0083
0.0104
0.0103
0.0170
0.0131
0.0152
0.0150
0.0160

FNR
0.0143
0.0143
0.0150
0.0093
0.0154
0.0141
0.0150
0.0137
0.0106
0.0104
0.0094
0.0147
0.0128
0.0117
0.0106
0.0131
0.0143
0.0143
0.0160
0.0079
0.0128
0.0118
0.0118
0.0104
0.0090
0.0105
0.0129
0.0212
0.0212
0.0179

FNR
0.0129
0.0081
0.0089
0.0109
0.0123
0.0101
0.0080
0.0076
0.0117
0.0076
0.0066
0.0079
0.0086
0.0100
0.0046
0.0106
0.0103
0.0065
0.0087
0.0058
0.0139
0.0078
0.0110
0.0107
0.0106
0.0078
0.0099
0.0121
0.0065
0.0086

Trained

Dataset 1

Dataset 2

Dataset 3

Dataset 4

Dataset 5

Dataset 6

Trained

Dataset 1

Dataset 2

Dataset 3

Dataset 4

Dataset 5

Dataset 6

Tested
Dataset 2
Dataset 3
Dataset 4
Dataset 5
Dataset 6
Dataset 1
Dataset 3
Dataset 4
Dataset 5
Dataset 6
Dataset 1
Dataset 2
Dataset 4
Dataset 5
Dataset 6
Dataset 1
Dataset 2
Dataset 3
Dataset 5
Dataset 6
Dataset 1
Dataset 2
Dataset 3
Dataset 4
Dataset 6
Dataset 1
Dataset 2
Dataset 3
Dataset 4
Dataset 5

Tested
Dataset 2
Dataset 3
Dataset 4
Dataset 5
Dataset 6
Dataset 1
Dataset 3
Dataset 4
Dataset 5
Dataset 6
Dataset 1
Dataset 2
Dataset 4
Dataset 5
Dataset 6
Dataset 1
Dataset 2
Dataset 3
Dataset 5
Dataset 6
Dataset 1
Dataset 2
Dataset 3
Dataset 4
Dataset 6
Dataset 1
Dataset 2
Dataset 3
Dataset 4
Dataset 5

AdaBoost

Accuracy
98.70
98.93
98.84
98.99
98.77
98.86
98.92
98.96
98.87
98.76
98.88
98.68
98.59
98.70
98.95
98.64
98.59
98.89
98.80
98.04
98.70
98.90
98.66
98.78
98.79
98.52
98.71
98.45
98.68
98.58

Precision
98.89
98.81
98.81
98.83
98.89
99.06
99.12
99.29
99.25
98.92
99.20
99.00
98.99
99.19
98.71
99.11
99.31
99.14
99.37
99.23
98.44
98.64
98.39
98.59
98.79
97.99
98.20
98.12
98.19
98.39

XGBoost

Accuracy
98.91
99.10
99.07
99.13
99.01
99.02
99.15
99.16
99.06
99.03
99.08
98.98
98.95
99.02
99.21
98.92
98.85
99.01
99.10
99.20
99.05
99.14
99.15
99.07
99.03
98.85
98.93
98.82
99.05
98.90

Precision
98.81
99.14
98.85
98.93
98.97
99.29
99.26
99.05
98.86
99.01
98.98
99.08
99.03
99.15
99.10
98.74
98.65
98.65
98.94
99.38
99.03
99.04
98.74
99.01
98.82
98.62
98.77
98.94
98.74
98.88

FPR
0.0131
0.0140
0.0140
0.0142
0.0131
0.0111
0.0103
0.0084
0.0088
0.0127
0.0082
0.0103
0.0103
0.0082
0.0131
0.0090
0.0070
0.0085
0.0064
0.0078
0.0158
0.0135
0.0164
0.0143
0.0123
0.0293
0.0182
0.0191
0.0184
0.0164

FPR
0.0116
0.0084
0.0112
0.0104
0.0100
0.0070
0.0072
0.0092
0.0092
0.0096
0.0100
0.0090
0.0095
0.0083
0.0088
0.0123
0.0132
0.0131
0.0103
0.0060
0.0095
0.0093
0.0123
0.0097
0.0116
0.0134
0.0120
0.0103
0.0123
0.0109

FNR
0.0129
0.0079
0.0096
0.0068
0.0117
0.0117
0.0105
0.0122
0.0135
0.0121
0.0141
0.0161
0.0181
0.0177
0.0081
0.018
0.0211
0.0141
0.0174
0.0114
0.0103
0.0087
0.0101
0.0113
0.0118
0.0094
0.0075
0.0119
0.0081
0.0121

FNR
0.0102
0.0096
0.0073
0.0069
0.0097
0.0127
0.0096
0.0076
0.0076
0.0097
0.0083
0.0114
0.0115
0.0114
0.0069
0.0074
0.0097
0.0065
0.0077
0.0102
0.0095
0.0078
0.0045
0.0090
0.0078
0.0095
0.0094
0.0134
0.0065
0.0110

11

less vulnerable to adversarial examples. Due to a lack of
attack tools to test their resilience, studying robustness training
techniques for tree ensemble models has been challenging.
Our method can serve as a benchmark tool for robustness
evaluation, stimulating research in tree ensemble robustness.
The research on lowering time complexity and developing
appropriate defence strategies will beneï¬t our studies.

VI. CONCLUSION AND FUTURE WORK

In this paper, we developed a framework for identifying
fraudulent advertisement URLs using innovative feature ex-
traction, and we created a detection system with the highest
accuracy results. We also looked into the vulnerability of var-
ious ensembles for adversarial training. We investigated novel
feature extraction using an unconventional combination of six
feature classes, including various advanced features. Most of
the existing approaches were based on only the traditional
features set like a bag of words, which were insufï¬cient to
make the detection system sufï¬ciently efï¬cient. We focused on
handling the unseen features to test the URLâ€™s maliciousness.
Our classiï¬ers optimised the accuracy, which we can see in
the clustering visualisation. The machine learning approaches
we used are ideal for the purpose.

Although the web-scrapped features extraction process was
a little time-consuming due to a number of ample features,
we would take it to minimise with more resources and tactics
in the upcoming time. We will also deploy the state of the
art adversarial examples and compare the vulnerability and
defence approaches in our future work.

REFERENCES

[1] J. Hong, â€œThe state of phishing attacks,â€ Communications of the ACM,

vol. 55, no. 1, pp. 74â€“81, 2012.

[2] D. Sahoo, C. Liu, and S. C. Hoi, â€œMalicious url detection using machine

learning: A survey,â€ arXiv preprint arXiv:1701.07179, 2017.

[3] A. Blum, B. Wardman, T. Solorio, and G. Warner, â€œLexical feature based
phishing url detection using online learning,â€ in Proceedings of the 3rd
ACM Workshop on Artiï¬cial Intelligence and Security, 2010, pp. 54â€“60.
https://github.com/ehsannowroozi/Sec Classifying

[4] â€œGitHub Code,â€

URL Detection, accessed: 2022-04-07.

[5] â€œVirusTotal,â€ https://www.virustotal.com/gui/home/url, accessed: 2022-

03-24.

[6] â€œAlexa Dataset,â€ https://www.kaggle.com/datasets/cheedcheed/top1m,

accessed: 2021-08-24.

[7] â€œCrowdï¬‚ower

Dataset,â€

https://data.world/crowdï¬‚ower/

url-categorization, accessed: 2022-03-24.

[8] â€œDMOZ

Dataset,â€

https://www.kaggle.com/datasets/shawon10/

url-classiï¬cation-dataset-dmoz, accessed: 2022-03-24.

[9] â€œBenign and Malicious Set URL,â€ https://www.kaggle.com/datasets/
siddharthkumar25/malicious-and-benign-urls, accessed: 2022-03-24.

[10] â€œBenign and Malicious Data URL Dataset,â€ https://www.kaggle.com/

antonyj453/urldataset#data.csv, accessed: 2022-03-24.

[11] â€œISCX-URL-2016 Dataset,â€ https://www.unb.ca/cic/datasets/url-2016.

html, accessed: 2022-03-24.

[12] M. S. I. Mamun, M. A. Rathore, A. H. Lashkari, N. Stakhanova, and
A. A. Ghorbani, â€œDetecting malicious urls using lexical analysis,â€ in
International Conference on Network and System Security.
Springer,
2016, pp. 467â€“482.

[13] â€œPhishtank Dataset,â€ https://www.phishtank.com/developer info.php, ac-

cessed: 2022-03-24.

[14] â€œPhishstrom

Dataset,â€

https://research.aalto.ï¬/en/datasets/

phishstorm-phishing-legitimate-url-dataset, accessed: 2022-03-24.
[15] S. Marchal, J. FrancÂ¸ois, R. State, and T. Engel, â€œPhishstorm: Detecting
phishing with streaming analytics,â€ IEEE Transactions on Network and
Service Management, vol. 11, no. 4, pp. 458â€“471, 2014.

Fig. 3. Elbow method and K-Means result.

3) Adversarial Attack Results: Here, we conduct techni-
cal investigations on our model and investigate the impact of
adversarial training on our models. We used the ZOO attack
to evaluate the susceptibility of various models. We trained
our model ï¬rst and then used the ZOO attack in the testing
phase. The result for the ZOO attack is shown in Table VIII.

TABLE VIII
ZOO ATTACK RESULT

AdaBoost

Attack Accuracy Rate
Gradient
Boost
95.30
94.87
94.41
94.66
95.30
95.73
94.44
94.66
94.30
94.30
95.35
94.88

95.62
95.31
94.50
94.33
96.18
95.95
95.31
95.12
95.29
94.56
95.12
94.66

XGBoost

93.15
93.86
95.16
93.05
94.82
93.78
93.70
93.40
93.64
92.61
92.20
92.18

Random
Forest
95.85
94.33
95.18
93.80
96.05
96.00
96.67
96.50
95.74
94.60
95.20
95.05

Dataset Conï¬dence

Dataset 1

Dataset 2

Dataset 3

Dataset 4

Dataset 5

Dataset 6

50
100
50
100
50
100
50
100
50
100
50
100

B. Discussion

The combination of lexical and web-scrapped features we
collected is a good foundation for our analysis. Various ma-
chine learning techniques used for categorization give us light
and profound output. We found that the XGBoost classiï¬er
with a maximum depth of ten yields the best outcomes in
the classiï¬cation process. When compared to other classiï¬ers,
XGBoost has the highest accuracy and precision, followed by
Gradient Boost, AdaBoost, and Random Forest. If the number
of folds in the simulation work increases, the FPR and FNR
drop. The model grows more sophisticated and overï¬ts the
data as the maximum depth of the tree is increased. The
same thing occurs with the other classiï¬ers. Our ï¬ndings and
recommended techniques improve the accuracy of prediction
and detection. The accuracy we discovered is substantially
greater than prior efforts, and deploying machine learning
systems in the identiï¬cation of rogue advertisement URLs is a
good concept. The visual comprehension in the elbow method
cluster formation recommends the appropriate categories of
data and low overlaps of both classes. The results of the
adversarial attack indicate a comparison of the ensembleâ€™s
susceptibility. We discovered that better predictive models are

[16] â€œPhishing

Site URL Dataset,â€

https://www.kaggle.com/datasets/

taruntiwarihp/phishing-site-urls, accessed: 2022-03-24.

[17] E. Nowroozi, Y. Mekdad, M. H. Berenjestanaki, M. Conti, and
A. EL Fergougui, â€œDemystifying the transferability of adversarial attacks
in computer networks,â€ IEEE Transactions on Network and Service
Management, pp. 1â€“1, 2022.

[18] C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow,
and R. Fergus, â€œIntriguing properties of neural networks,â€ arXiv preprint
arXiv:1312.6199, 2013.

[19] I. J. Goodfellow, J. Shlens, and C. Szegedy, â€œExplaining and harnessing

adversarial examples,â€ arXiv preprint arXiv:1412.6572, 2014.

[20] E. Nowroozi, A. Dehghantanha, R. M. Parizi, and K.-K. R. Choo, â€œA
survey of machine learning techniques in adversarial image forensics,â€
Computers & Security, vol. 100, p. 102092, 2021.

[21] E. Nowroozi, M. Barni, and B. Tondi, â€œMachine learning techniques for
image forensics in adversarial setting,â€ Ph.D. dissertation, 2020.
[22] N. Carlini and D. Wagner, â€œAudio adversarial examples: Targeted attacks
on speech-to-text,â€ in IEEE Security and Privacy Workshops (SPW).
IEEE, 2018, pp. 1â€“7.

[23] P. Prakash, M. Kumar, R. R. Kompella, and M. Gupta, â€œPhishnet:
predictive blacklisting to detect phishing attacks,â€ in 2010 Proceedings
IEEE INFOCOM.

IEEE, 2010, pp. 1â€“5.

[24] Y. He, Z. Zhong, S. Krasser, and Y. Tang, â€œMining dns for malicious
domain registrations,â€ in 6th International Conference on Collaborative
Computing: Networking, Applications and Worksharing (Collaborate-
Com 2010).

IEEE, 2010, pp. 1â€“6.

[25] J. Ma, L. K. Saul, S. Savage, and G. M. Voelker, â€œBeyond blacklists:
learning to detect malicious web sites from suspicious urls,â€ in Proceed-
ings of the 15th ACM SIGKDD international conference on Knowledge
discovery and data mining, 2009, pp. 1245â€“1254.

[26] M. Antonakakis, R. Perdisci, D. Dagon, W. Lee, and N. Feamster,
â€œBuilding a dynamic reputation system for {DNS},â€ in 19th USENIX
Security Symposium (USENIX Security 10), 2010.

[27] W. Liu, X. Deng, G. Huang, and A. Y. Fu, â€œAn antiphishing strat-
egy based on visual similarity assessment,â€ IEEE Internet Computing,
vol. 10, no. 2, pp. 58â€“65, 2006.

[28] B. Eshete, A. Villaï¬orita, K. Weldemariam, and M. Zulkernine, â€œEin-
spect: Evolution-guided analysis and detection of malicious web pages,â€
in 2013 IEEE 37th Annual Computer Software and Applications Con-
ference.

IEEE Computer Society, 2013, pp. 375â€“380.
[29] K. Thomas, C. Grier, J. Ma, V. Paxson, and D. Song, â€œDesign and
evaluation of a real-time url spam ï¬ltering service,â€ in 2011 IEEE
symposium on security and privacy.

IEEE, 2011, pp. 447â€“462.

[30] H. Choi, B. B. Zhu, and H. Lee, â€œDetecting malicious web links and
identifying their attack types,â€ in 2nd USENIX Conference on Web
Application Development (WebApps 11), 2011.

[31] G. Xiang, J. Hong, C. P. Rose, and L. Cranor, â€œCantina+ a feature-rich
machine learning framework for detecting phishing web sites,â€ ACM
Transactions on Information and System Security (TISSEC), vol. 14,
no. 2, pp. 1â€“28, 2011.

[32] S. Lee and J. Kim, â€œWarningbird: Detecting suspicious urls in twitter

stream.â€ in Ndss, vol. 12, 2012, pp. 1â€“13.

[33] S. N. Bannur, L. K. Saul, and S. Savage, â€œJudging a site by its content:
learning the textual, structural, and visual features of malicious web
pages,â€ in Proceedings of the 4th ACM Workshop on Security and
Artiï¬cial Intelligence, 2011, pp. 1â€“10.

[34] A. Aggarwal, A. Rajadesingan, and P. Kumaraguru, â€œPhishari: Auto-
matic realtime phishing detection on twitter,â€ in eCrime Researchers
Summit.

IEEE, 2012, pp. 1â€“12.

[35] H. Choi, B. B. Zhu, and H. Lee, â€œDetecting malicious web links and
identifying their attack types,â€ in 2nd USENIX Conference on Web
Application Development (WebApps 11), 2011.

[36] S. Garera, N. Provos, M. Chew, and A. D. Rubin, â€œA framework for
detection and measurement of phishing attacks,â€ in Proceedings of the
2007 ACM workshop on Recurring malcode, 2007, pp. 1â€“8.

[37] I. Fette, N. Sadeh, and A. Tomasic, â€œLearning to detect phishing emails,â€
in Proceedings of the 16th international conference on World Wide Web,
2007, pp. 649â€“656.

[38] A. Bergholz, J. H. Chang, G. Paass, F. Reichartz, and S. Strobel,
â€œImproved phishing detection using model-based features.â€ in CEAS,
2008.

[39] S. Abu-Nimeh, D. Nappa, X. Wang, and S. Nair, â€œA comparison of
machine learning techniques for phishing detection,â€ in Proceedings
of the anti-phishing working groups 2nd annual eCrime researchers
summit, 2007, pp. 60â€“69.

12

[40] H. Chen, H. Zhang, P.-Y. Chen, J. Yi, and C.-J. Hsieh, â€œAttacking visual
language grounding with adversarial examples: A case study on neural
image captioning,â€ arXiv preprint arXiv:1712.02051, 2017.

[41] M. Barreno, B. Nelson, R. Sears, A. D. Joseph, and J. D. Tygar, â€œCan
machine learning be secure?â€ in Proceedings of the ACM Symposium on
Information, computer and communications security, 2006, pp. 16â€“25.
[42] D. Warde-Farley and I. Goodfellow, â€œ11 adversarial perturbations of
deep neural networks,â€ Perturbations, Optimization, and Statistics, vol.
311, p. 5, 2016.

[43] P.-Y. Chen, H. Zhang, Y. Sharma, J. Yi, and C.-J. Hsieh, â€œZoo: Zeroth
order optimization based black-box attacks to deep neural networks
without training substitute models,â€ in Proceedings of the 10th ACM
workshop on artiï¬cial intelligence and security, 2017, pp. 15â€“26.

Mauro Conti is Full Professor at the University of
Padua, Italy. He is also afï¬liated with TU Delft and
University of Washington, Seattle. He obtained his
Ph.D. from Sapienza University of Rome, Italy, in
2009. After his Ph.D., he was a Post-Doc Researcher
at Vrije Universiteit Amsterdam, The Netherlands.
In 2011 he joined as Assistant Professor at
the
University of Padua, where he became Associate
Professor in 2015, and Full Professor in 2018. He
has been Visiting Researcher at GMU, UCLA, UCI,
TU Darmstadt, UF, and FIU. He has been awarded
with a Marie Curie Fellowship (2012) by the European Commission, and with
a Fellowship by the German DAAD (2013). His research is also funded by
companies, including Cisco, Intel, and Huawei. His main research interest is
in the area of Security and Privacy. In this area, he published more than 450
papers in topmost international peer-reviewed journals and conferences. He is
Editor-in-Chief for IEEE Transactions on Information Forensics and Security,
Area Editor-in-Chief for IEEE Communications Surveys & Tutorials, and has
been Associate Editor for several journals, including IEEE Communications
Surveys & Tutorials, IEEE Transactions on Dependable and Secure Com-
puting, IEEE Transactions on Information Forensics and Security, and IEEE
Transactions on Network and Service Management. He was Program Chair
for TRUST 2015, ICISS 2016, WiSec 2017, ACNS 2020, CANS 2021, and
General Chair for SecureComm 2012, SACMAT 2013, NSS 2021 and ACNS
2022. He is Fellow of the IEEE, Senior Member of the ACM, and Fellow of
the Young Academy of Europe.

Ehsan Nowroozi received his Ph.D. from Siena
University in Italy. He is a research fellow at Sabanci
Universityâ€™s Faculty of Engineering and Natural Sci-
ences (FENS), Istanbul, Turkey 34956. Previously,
he was a Postdoctoral Fellow at Siena and Padua
Universities in Italy in 2020 and 2021, respectively.
His research interests include security and privacy,
with an emphasis on the use of image processing
methods to multimedia authentication, network and
Internet security.

Abhishek received the B.Sc. Degree in Honours
in Mathematics from University of Delhi, India,
M.Sc. Degree in Mathematics and Scientiï¬c Com-
puting from MNNIT Allahabad, India. He worked
in Artiï¬cial Intelligence and Digital Image Process-
ing. Moreover, his research interest cover Machine
Learning, Cryptography, Cyber-Security, Number
Theory etc. Currently, he conducted his new research
in applied machine learning in Cybersecurity with a
research group from Italy. He is a member of IEEE
Cybersecurity Community.

13

Mohammadreza Mohammadi
is a second-year
Master student of
ICT at University of Padua.
He received the bachelorâ€™s degree in computer
engineering(software-network)
from Bu-Ali Sina
University, Hamedan, Iran in 2019. His main re-
search interest is in the area of Machine Learning,
Cybersecurity, IoT and Computer Vision. He worked
in Industrial IoT security and AI, and Intrusion
detection systems(IDS) and Healthcare systems and
He is also a graduate student member of IEEE
institution.

