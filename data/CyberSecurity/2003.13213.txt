1
2
0
2

n
a
J

9
1

]

R
C
.
s
c
[

2
v
3
1
2
3
1
.
3
0
0
2
:
v
i
X
r
a

Deep Learning-Based Anomaly Detection in Cyber-Physical
Systems: Progress and Opportunities

YUAN LUO, Wuhan University
YA XIAO, Virginia Tech
LONG CHENG, Clemson University
GUOJUN PENG‚àó, Wuhan University
DANFENG (DAPHNE) YAO‚àó, Virginia Tech

Anomaly detection is crucial to ensure the security of cyber-physical systems (CPS). However, due to the
increasing complexity of CPSs and more sophisticated attacks, conventional anomaly detection methods,
which face the growing volume of data and need domain-specific knowledge, cannot be directly applied to
address these challenges. To this end, deep learning-based anomaly detection (DLAD) methods have been
proposed. In this paper, we review state-of-the-art DLAD methods in CPSs. We propose a taxonomy in terms of
the type of anomalies, strategies, implementation, and evaluation metrics to understand the essential properties
of current methods. Further, we utilize this taxonomy to identify and highlight new characteristics and designs
in each CPS domain. Also, we discuss the limitations and open problems of these methods. Moreover, to give
users insights into choosing proper DLAD methods in practice, we experimentally explore the characteristics
of typical neural models, the workflow of DLAD methods, and the running performance of DL models. Finally,
we discuss the deficiencies of DL approaches, our findings, and possible directions to improve DLAD methods
and motivate future research.

CCS Concepts: ‚Ä¢ Security and privacy ‚Üí Intrusion/anomaly detection and malware mitigation; ‚Ä¢
Computer systems organization ‚Üí Embedded and cyber-physical systems.

Additional Key Words and Phrases: Deep learning, Anomaly detection, Cyber-physical systems

ACM Reference Format:
Yuan Luo, Ya Xiao, Long Cheng, Guojun Peng, and Danfeng (Daphne) Yao. 2021. Deep Learning-Based Anomaly
Detection in Cyber-Physical Systems: Progress and Opportunities. ACM Comput. Surv. 1, 1 (January 2021),
37 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn

1 INTRODUCTION

Cyber-physical systems (CPS) are increasingly being deployed in critical infrastructures. The CPS
market is expected to expand by 9.7% each year, which will reach $9563 million by 2025 [82].
Prominent applications of CPS include industrial control systems (ICS), smart grid, intelligent
transportation systems (ITS), and aerial systems. CPSs have evolved to be complex, heterogeneous,

‚àóCorresponding authors

Authors‚Äô addresses: Yuan Luo, School of Cyber Science and Engineering, Wuhan University, Hubei, China, 430072,
leonnewton@whu.edu.cn; Ya Xiao, Department of Computer Science, Virginia Tech, Blacksburg, VA, 24060, yax99@vt.edu;
Long Cheng, School of Computing, Clemson University, Clemson, SC, 29634, lcheng2@clemson.edu; Guojun Peng, School
of Cyber Science and Engineering, Wuhan University, Hubei, China, 430072, guojpeng@whu.edu.cn; Danfeng (Daphne)
Yao, Department of Computer Science, Virginia Tech, Blacksburg, VA, 24060, danfeng@vt.edu.

Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee
provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and
the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored.
Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires
prior specific permission and/or a fee. Request permissions from permissions@acm.org.
¬© 2021 Association for Computing Machinery.
0360-0300/2021/1-ART $15.00
https://doi.org/10.1145/nnnnnnn.nnnnnnn

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

 
 
 
 
 
 
2

Yuan Luo, Ya Xiao, et al.

and integrated to provide rich functionalities. However, such characteristics also expose CPSs to
broader threats. In H1 2019, 41.6% of ICS computers that installed Kaspersky products detected
attacks [52]. According to FireEye‚Äôs report, insiders, ransomware, market manipulation, etc are
among the top attack types in ICS [33]. Recent incidents (e.g., Stuxnet [107], Ukraine power grid
outage [105], auto-driving crashes [106], robot malfunction [7]) have shown that sophisticated and
stealthy attacks (and faults) can result in catastrophic consequences to the economy, environment,
and even human lives. Thus, it is paramount important to ensure the security of CPSs.

To detect attacks and unexpected errors in CPSs, anomaly detection methods are proposed to
mitigate these threats. For example, rule, state estimation (e.g., Kalman filter), statistical model
(e.g., Gaussian model, histogram-based model) based methods are utilized to learn normal status
of CPSs [65]. However, these methods usually require expert knowledge (e.g., operators manually
extract certain rules), or need to know the underlying distribution of normal data. Machine learning
approaches do not rely on domain-specific knowledge [18]. But they usually require a large quantity
of labeled data (e.g., classification-based methods). Also, they cannot capture the unique attributes
of CPSs (e.g., spatial-temporal correlation) [88]. Intrusion detection methods are dedicated to
ensuring network communication security [70, 116]. Physical properties are captured to depict
the immutable nature of CPSs [36]. Program execution semantics are characterized to protect
control systems [19, 89, 112]. However, as CPSs become more complicated and attacks are more
stealthy (e.g., APT attacks), these methods are hard to ensure the overall status of CPSs (e.g., protect
multivariate physical measurement) and need more domain knowledge (e.g., more components and
correlation). Anomaly detection systems need to adapt to capture new characteristics of CPSs.

To this end, deep learning-based anomaly detection (DLAD) methods have been proposed to
identify anomalies in CPS. Current studies have explored different neural network architectures
(e.g., ConvLSTM) to mitigate various threats (e.g., false data injection attacks) in different CPS
domains (e.g., smart grid). However, since these studies are not introduced in a unified way, a
systematic survey is needed to review existing methods and provide guidance for future solutions.
Specifically, we need to answer the following four research questions:

‚Ä¢ What are the characteristics of existing approaches? How existing DLAD methods can be
categorized in terms of the threat model, detection strategies, implementation, and evaluation
metrics?

‚Ä¢ How a DL model can be applied to solve a problem? For example, what are the characteristics
of each neural model and how to use a neural model to build a DLAD method (i.e., the
workflow)?

‚Ä¢ What are the limitations and deficiencies of DL approaches when being applied to the anomaly

detection task in CPS?

‚Ä¢ How can researchers address the limitations and improve DLAD methods?

Answering these questions helps to understand the fundamentals of DLAD methods, evaluate
proposed DLAD models, and explore new solutions. This motivates our work to summarize and
identify progress, challenges, and future research directions of DLAD methods. Our contributions
are as follows.

‚Ä¢ We systematically review existing deep learning-based anomaly detection methods that
target at detecting faults and attacks in CPS. To this end, we propose a new taxonomy that
is based on i) type of anomalies (i.e., threat model), ii) detection strategies (i.e., input data,
neural network designs, anomaly scores), and iii) implementation and evaluation metrics.
Further, we explore and categorize peer-reviewed research papers from conferences and
journals under the setting of this taxonomy.

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

Deep Learning-Based Anomaly Detection in Cyber-Physical Systems: Progress and Opportunities

3

‚Ä¢ We identify and highlight characteristics that are essential to building a DLAD method. First,
we discuss existing methods in representative CPS domains (i.e., ICSs, smart grid, ITSs, and
aerial systems). Then, we report unique designs and trends in each domain. All these findings
are summarized according to our taxonomy. Meanwhile, we summarize and discuss the
limitations and open problems of current methods.

‚Ä¢ We experimentally explore typical neural models to capture different characteristics of CPSs.
We show the workflow to build a DLAD method and present the running performance of
neural models.

‚Ä¢ We identify the limitations and deficiencies of deep learning approaches when being applied
to the anomaly detection task in CPS. We present our findings and takeaways to improve
the design and evaluation of DLAD methods. Also, we discuss several promising research
directions and open problems that motivate future research efforts.

2 BACKGROUND

In this section, we introduce a generic architecture of cyber-physical systems and threats that
are typically studied in existing DLAD methods (Section 2.1), the workflow of DLAD methods
(Section 2.2). We discuss the key differences between our work and the existing survey papers in
CPS (Section 2.3).

2.1 Cyber-physical systems and threats

The generic definition of CPS. As illustrated in Figure 1, CPSs typically consist of five com-
ponents: The physical space contains physical components of CPSs, e.g., engines, tanks, wheels.
Actuators receive control commands (denoted as ùê¥2) from control systems and change the running
parameters of physical devices (ùê¥1). Sensors measure the running status of devices (ùëÜ1) and report
to the control systems (ùëÜ2). Control systems obtain sensor measurement (ùëÜ2) and send control
commands to actuators (ùê¥2), which follows the predefined control logic. Supervisory control and
data acquisition (SCADA) systems are used to gather data from control systems (ùê∑1) and monitor
the running status of CPSs for users.

We define communication between sensors (actuators) and control systems as level 0 commu-
nication (denoted as ùê∂0). The content of ùê∂0 communication traffic is sensor measurement (ùëÜ2)
and control commands (ùê¥2). Similarly, communication between control systems and SCADA is
defined as level 1 communication (ùê∂1). The content of ùê∂1 is ùê∑1. Specifically, our work focuses on
four representative types of CPSs, i.e., Industrial Control Systems (ICSs), smart grid, Intelligent
Transportation Systems (ITSs) and aerial systems. Actual devices may vary in these four CPSs (e.g.,
actuators can be pumps in ICS and brakes in ITS) but they share the same generic architecture.

Threat model. We then present threats that are studied by DLAD methods in our work. Threats
can be classified as attacks and faults. We observe that most existing studies usually do not obtain
data directly from physical space. Namely, these two data sources are not adopted: i) running status
data of physical components from physical devices to sensors (ùëÜ1), ii) control parameters from
actuators to physical devices (ùê¥1). Instead, ùëÜ2 (values sent to control systems) and ùê¥2 (commands
sent to actuators) are commonly utilized by existing work. We focus our investigation on:

‚Ä¢ Sensor and actuator anomalous values. Sensors and actuators either can be compromised
under attacks or failed due to various reasons (e.g., lack of maintenance). Attackers may
physically tamper with field sensors and actuators under this scenario. In Figure 1, ùëÜ2 and ùê¥2
are affected under this threat model (ùëÜ2 ‚â† ùëÜ1, ùê¥2 ‚â† ùê¥1).

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

4

Yuan Luo, Ya Xiao, et al.

Fig. 1. A generic CPS architecture. Deep anomaly detection methods mainly aim to protect sensors, actuators,
level 0 and level 1 communication, and control systems.

‚Ä¢ Manipulated level 0 and level 1 communication traffic. Attackers can manipulate two types
of communication signals: i) network traffic between sensors (actuators) and control systems
(ùê∂0), ii) traffic data between control systems and SCADA (ùê∂1).

‚Ä¢ Compromised control systems. Control systems are connected to field devices and central
operating centers, which makes it prone to remote attacks. For example, attackers can plant
malware and send false control signals. Also, internal faults (e.g., logic errors) can cause
wrong control commands. ùê¥2 and ùê∑1 are affected in this scenario.

2.2 The workflow of typical DLAD methods

Fig. 2. The workflow of a typical DLAD method. The input data is used to train or test DLAD models. The
anomaly score is used to optimize DLAD models. Trained DLAD models are applied to decide whether the
input data is an anomaly at the online detection phase.

Anomaly detection has developed for many different applications [18, 113], e.g., intrusion de-
tection, fraud detection. In this work, we focus on new research efforts that detect anomalies in
CPS with the help of emerging deep learning methods. As illustrated in Figure 2, we characterize
the generic workflow of DLAD methods. Typically, DLAD methods consist of training and testing
phases. At the training phase, a large quantity of input data is first collected. Sensor and actuator
data, level 0 and level 1 communication traffic, and control system logs are commonly used data

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

ActuatorsSensorsPhysical spaceA1S1Control system(e.g., PLCs)S2Sensor measurementA2Control commandSupervisory Control and Data Acquisition (SCADA)D1: Level 0 communication (C0): Level 1 communication (C1)Input dataS2A2Level 0 communication (C0)Level 1 communication (C1)Control system logsD1DLAD modelsRNNAutoencoder‚Ä¶CNNHybrid modelsAnomaly scorePrediction errorReconstruction errorLabelGround truthOutput layerLossfunctionUpdateInput dataTrained modelsAnomaly scoreNormal statusAnomalyorTraining:Testing orDetecting:Data processingDeep Learning-Based Anomaly Detection in Cyber-Physical Systems: Progress and Opportunities

5

sources. Various customized data processing approaches are applied to the input data, which is
then fed to neural network models. Then, the main contribution of new methods lies in different
DLAD models (e.g., RNN, autoencoders, CNN, and customized models) in different application
scenarios. Further, DLAD models utilize loss functions to compute differences between output data
from the output layer and ground truth data. We denote these differences as anomaly scores. There
are three types of anomaly scores: (1) Prediction error (2) Reconstruction error, and (3) Predicted
labels (details in Section 3.2). Anomaly scores are used to optimize and update DLAD models. At
the testing phase, collected or real-time input data is fed to trained models and determine whether
the input is an anomaly.

Table 1. Summary of techniques, applications, and scope covered by related surveys.
YES respectively.
detection respectively.

means NO and
means related but not fully covered. ‚ÄúDL‚Äù and ‚ÄúAD‚Äù denotes deep learning and anomaly

and

(cid:32)

(cid:35)

(cid:71)(cid:35)

Related
work

Techniques

DL?

Application

CPS?

Scope

AD?

Chandola et al. [18]

Celik et al. [16]
Giraldo et al. [36]

Classiflcation-Based, Clustering-Based,
Statistical, etcanomaly detection methods
Program Analysis
Physical properties

Chalapathy et al. [17]

Deep learning

Cherdantseva et al. [20]

Attack tree, model-based

Veith et al. [98]

Deep learning

Mitchell et al. [70]

Nazir et al. [77]

Knowledge-Based, Behavior-Based
Intrusion Detection system

Intrusion Detection system,
machine learning, honey pots

Heartfield et al. [45]

-

Lun et al. [65]

Mohammadi et al. [73]
Ours

Plant models, noise-based detection,
state estimation, etc

Deep learning
Deep learning

Cyber Intrusion Detection,
Fraud Detection, etc

Commodity IoT
CPS
Cyber Intrusion Detection,
Fraud Detection, etc

CPS (focus on SCADA)

CPS

CPS

CPS

Smart home IoT

CPS

IoT
CPS

(cid:35)

(cid:35)
(cid:35)

(cid:32)

(cid:35)

(cid:32)

(cid:35)

(cid:35)
-

(cid:35)

(cid:32)
(cid:32)

Anomaly detection

App security and privacy
Anomaly detection

Anomaly detection

Cyber risk assessment
Analyzing applications
of DL in CPS

Anomaly detection

Cyber security

Taxonomy of threats,
not detection methods

Anomaly detection

Data analytics
Anomaly detection

(cid:32)

(cid:35)
(cid:32)

(cid:32)

(cid:71)(cid:35)

(cid:35)

(cid:32)

(cid:71)(cid:35)

(cid:35)

(cid:32)

(cid:35)
(cid:32)

(cid:35)

(cid:71)(cid:35)
(cid:32)

(cid:35)

(cid:32)

(cid:32)

(cid:32)

(cid:32)

(cid:71)(cid:35)

(cid:32)

(cid:71)(cid:35)
(cid:32)

2.3 Related survey

There are a number of recent related surveys, which are different in focus and domain from our work.
As illustrated in Table 1, we summarize these papers in terms of techniques, applications, and scope.
Chandola et al. provided a comprehensive overview of anomaly detection methods [18]. As an early
effort to review anomaly detection methods, they did not consider deep learning-based methods and
did not include CPS. Commodity IoT systems have transformed the way people live. For example,
emerging smart home applications allow users to interact with home appliances automatically.
Program analysis methods are proposed to protect the privacy and discover vulnerabilities in
these applications [16]. Meanwhile, Giraldo et al. reviewed anomaly detection methods that utilize
the physical properties of CPSs (e.g., the evolution of the physical system under control) [36].
Studies in terms of network security of SCADA systems are summarized with a focus on risk
assessment techniques [20]. Mitchell et al. [70], Nazir et al. [77], Lun et al. [65] provided a review of
anomaly detection approaches in CPS. But the techniques did not include deep learning methods
and are conventional, e.g., state estimation, intrusion detection based methods. There is work that
studied deep learning-based anomaly detection methods but did not focus on CPS [17]. While
Veith et al. investigated applications of deep learning methods in CPS, it did not cover anomaly
detection [98]. Heartfield et al. examined the taxonomy of threats in smart home IoT, which did
not consider anomaly detection methods [45]. Finally, Mohammadi et al. studied data analysis

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

6

Yuan Luo, Ya Xiao, et al.

approaches that use deep learning methods in IoT [73]. To the best of our knowledge, our work is
the first work that studies deep learning-based anomaly detection methods in CPS, which differs
from the above existing surveys.

3 TAXONOMY

In this section, we present our taxonomy to classify existing work. In particular, our taxonomy
consists of three aspects: (1) Type of anomalies. DLAD methods first need to decide what type of
anomalies they intend to detect. (2) Detection strategies. Based on different anomalies, different
strategies (e.g., neural network design) are adopted. (3) Implementation and evaluation metrics.
Once a strategy is decided, appropriate implementation and evaluation metrics are selected to
assess the performance of methods. Our taxonomy is depicted in Figure 3 and we elaborate the
details as follows.

3.1 Type of anomalies

We elaborate anomalies described in Section 2.1. Anomalies can be broadly categorized as: (1)
attacks; (2) faults.

Fig. 3. Taxonomy of deep learning-based anomaly detection methods in cyber-physical systems.

Attacks. Since CPSs usually manage critical infrastructure (e.g., ICS, medical devices, and power
grid), they are always under the threat of various attacks. An attacker who has the motive (e.g.,
financial interest, privacy theft, and state operations) can conduct attacks. These attacks can target
different parts of CPSs:

(1) Network communication layer. Field devices (e.g., sensors and actuators) rely on communica-
tion networks to cooperate with each other. Also, sensor values, device status are reported to
data centers and control commands are sent by control systems through the network. In this
case, level 0 communication (ùê∂0) and level 1 communication (ùê∂1) can both be targeted. Note
that ùëÜ2, ùê¥2, ùê∑1 (contained in ùê∂0 and ùê∂1 traffic) can also be manipulated under these attacks.
We identify three types of attacks:
‚Ä¢ Denial-of-service (DoS) attacks. DoS attacks bring a significant threat to the functionalities
of real-time applications in CPSs. For example, it would cause a collision of aircraft or low
traffic utilization if the ADS-B system is out of service. Meanwhile, the broadcast feature
in some CPS communication protocols (e.g., the CAN protocol in smart car systems) makes
the network prone to DoS attacks.

‚Ä¢ Man-in-the-middle (MITM) attacks. CPSs adopt many newly designed protocols, which
may lack a well-designed authentication mechanism. Also, Ethernet used in CPS can be

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

Type of anomaliesAttacksNetwork communicationlayerControl systemFaultsSensor layerControl systemDetection strategiesInput dataNeural network designSensor and actuator dataNetwork traffic dataSystem calls and logsTime-series dataRNN CNN GAN, etcCustom modelsImplementationData from real-world systemsTestbedSimulationAnomaly scoresPrediction errorReconstruction errorPredicted labelEvaluationTP/FP/FN/TNPrecision/recall/F1/ROCCase studyImplementation &EvaluationDeep Learning-Based Anomaly Detection in Cyber-Physical Systems: Progress and Opportunities

7

exploited to conduct MITM attacks. Packet content may be manipulated and sensitive
information can be leaked through MITM attacks [31].

‚Ä¢ Packet injection. If attackers gain access to the network, they are able to inject an arbitrary
packet to send control command into the system. False control commands can cause severe
damage to running devices and even place human lives under risk. For example, a false
engine and brake control command could possibly induce a car crash [42].

(2) Control system. As the core of one CPS, control systems take sensor values as input and give
control signals to actuators or field devices. Due to harsh working environments or limited
hardware resources, the protection mechanism may not well-established in control systems.
Once control systems are compromised, data sent to SCADA systems (ùê∑1) and commands
sent to actuators (ùê¥2) can be altered. We find two types of attacks that target control systems:
‚Ä¢ Malware. For the long-term monitoring and information leakage, attackers would place
malware in the control system. Moreover, malware can be used to launch a stealthy
attack (e.g., APT attack) at a certain critical moment. Sensor readings can be manipulated
by malware. Under certain circumstances, malware may also cause physical damage to
devices [107].

‚Ä¢ False control signals. Devices operate deviating from regular working status when receiving
false control signals. Wrong operations shorten the working life of devices and can even
damage devices directly. Attackers usually conceal their unauthorized access to the system
and send false control commands at a critical time point.

Faults. The complexity of systems and heterogeneity of devices lead CPSs to generate unexpected
faults. For example, industrial control systems typically consist of multiple stages and a lot of
components in each stage. Many devices operate in a harsh environment (e.g., high humidity or
temperature). Also, mechanical parts are vulnerable to abrasion and vibration. ùëÜ2, ùê¥2, and ùê∑1 can
all be anomalous due to faults. We find that faults typically happen in two layers:

(1) Sensor layer. False sensor value is a common fault in the sensor layer. First, physical damage
or flaw lead sensors to report inaccurate and even wrong sensor values. Also, previously
unseen circumstances may cause sensors to work beyond their abilities. For example, sensors
on spacecraft may come across unexpected conditions [47, 93].

(2) Control system. CPSs typically hold the dynamic running characteristic, which means there
are always situations that may not be covered during the system design stage. For example,
different orders and timings of events in the PLC code can cause object collisions of an
assembly line in industrial plants [117].

3.2 Detection strategies

DLAD methods choose their detection strategies from three aspects:
Input data. DLAD methods first need to decide what type of data to take as input, which depends
on specific anomalies they tend to detect. Based on the layer and source where data is collected, we
conclude four types of input data: (1) Sensor and actuator data. (2) Network traffic data. (3) System
calls and logs. (4) Time-series data, which is preprocessed sensor, network, and log data in numeric
time-series form. DLAD methods adopt semi-supervised and unsupervised learning to resolve the
lack of labeled data (especially anomalous data).
Neural network design. DLAD methods adopt different neural network designs based on input
data and tasks. The deep network can be stacked models (e.g., LSTMs) or hybrid combinations of
models (e.g., the combination of LSTM and CNN). Although neural network designs can be in various
forms, we found several basic models used to build the neural network. (1) RNN. LSTM models (one
type of RNN) are often used to capture characteristics of time-series data [47]. (2) Autoencoder.

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

8

Yuan Luo, Ya Xiao, et al.

Autoencoders are applied to handle imbalanced data and achieve unsupervised learning [88]. (3)
CNN. CNN models can capture correlations and context information of multivariate measurement
data [15].
Anomaly scores. There exist three metrics to calculate the detection error: (1) Prediction error.
DLAD methods take past data as input to predict future sensor or actuator values. Then, the error
between predicted and real values is measured. Anomalous data usually deviate from predicted
values. (2) Reconstruction error. Input data is fed to the model and compressed to hidden layers,
which represents low dimensional space. The data is then reconstructed to the size of the original
dimension. Similarly, the error between reconstructed and origin values is calculated. A threshold
of error is usually selected to identify anomalous data. (3) Predicted label or class. If labeled data is
relatively sufficient in some domain (e.g., SWaT [50] testbed in ICS), DLAD models can be trained
to predict labels of input data. The assumption is that latent features learned from neural networks
can be used to identify anomalies. We observe very few methods to adopt this design since a large
quantity of labeled data needs profound manual effort.

3.3 Implementation and evaluation metrics

We summarize the implementation of existing work with a focus on platforms where data is
collected. Then, metrics that are used to evaluate the effectiveness and performance of DLAD
methods are identified.
Implementation. As data-driven techniques, DLAD methods consume a large quantity of data
to train and test models. We summarize three types of environments where data is collected: (1)
Data from real-world systems. (2) Testbed. Researchers build scaled-down yet entirely functional
testbeds, where experiments can be done without the risk of damaging real CPSs. (3) Simulation.
The advantage of data from real-world systems is that it reflects the intrinsic principle of real
systems, although the data is hard to harvest and the number of systems is limited. Simulation is
easy to operate but can not capture problems that only exist in real systems. A scaled-down testbed
could balance the data distortion and operability.

Similarly, anomalous data can be collected from real-world systems and manually created. There
can be insufficient real-world anomalous data since anomalies are hard to harvest. For example, in
smart cars and medical domain, anomalies in real devices may place human lives at risk. So existing
studies tackle this problem by manually creating three kinds of anomalies: (1) Point anomaly.
Through investigating anomalies that can possibly happen, several independent abnormal cases can
be injected into the normal data series. For instance, Taylor et al. [95] and Russo et al. [84] injected
several attack cases into the sequence of CAN bus packets. (2) Statistical anomaly. Anomalies that
follow certain statistical patterns are injected into normal data as an abnormal period [115]. (3)
Simulated attacks. Various attacks are simulated in the testbed, where sensor values and system
logs can be easily collected. Zhang et al. [119] created cyber attacks in transactive energy systems.
Evaluation metrics. Metrics are proposed to measure the effectiveness of DLAD methods. We
conclude that the most commonly used metrics are precision, recall, and ùêπ1 score. Given imbalanced
datasets, these metrics consider false positives and false negatives, which are better than metrics
such as accuracy. The precision is defined as ùëá ùëÉ/(ùëá ùëÉ + ùêπ ùëÉ), where ùëá ùëÉ stands for True Positives
and ùêπ ùëÉ means False Positives. The recall is defined as ùëá ùëÉ/(ùëá ùëÉ + ùêπ ùëÅ ), where ùêπ ùëÅ denotes False
Negatives. ùêπ1 is defined as 2*Precision*Recall/(Precision+Recall). Also, the Receiver Operating
Characteristic (ROC) curve is used to manage tradeoffs between ùêπ ùëÉ and ùëá ùëÉ. Meanwhile, methods
are often compared with baseline methods to examine the improvement. Some error-based metrics
are also applied to measure the prediction and reconstruction performance such as Mean Absolute
Error (MAE) and Relative Errors (ReErr) [3, 121].

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

Deep Learning-Based Anomaly Detection in Cyber-Physical Systems: Progress and Opportunities

9

Table 2. Summary of existing work on deep learning-based anomaly detection in Cyber Physical Systems.
‚Äú

‚Äù means ‚ÄúYes‚Äù, ‚ÄúNo‚Äù, ‚ÄúDoes not clear but inferred to be Yes‚Äù respectively. 1: GAN 2: DBN

‚Äù, ‚Äú-‚Äù, ‚Äú

(cid:32)

s

m
e
t
s
y
S
S
P
C

s

m
e
t
s
y
s

l
o
r
t
n
o
c

l
a
i
r
t
s
u
d
n
I

d
i
r
g
t
r
a
m
S

S
T

I

s

m
e
t
s
y
s

l
a
i
r
e
A

(cid:71)(cid:35)

k
r
o
w
g
n
i
t
s
i
x
E

Schneider et al. [88]
Kravchik et al. [58]
Zohrevand et al. [121]
Su et al. [92]
Eiteneuer et al. [25]
Goh et al. [39]
Feng et al. [31]
Inoue et al. [48]
Ferrari et al. [32]
Legrand et al. [59]
Wu et al. [108]
Li et al. [62]
Lindemann et al. [63]
Canizo et al. [15]
Khan et al. [53]
Xiao et al. [109]
Li et al. [60]
Tasfi et al. [94]
Zhang et al. [119]
Wang et al. [101]
Deng et al. [23]
Niu et al. [78]
Wang et al. [100]
Basumallik et al. [10]
Fan et al. [30]
Wang et al. [104]
Khanapuri et al. [54]
Wyk et al. [97]
Taylor et al. [95]
Russo et al. [84]
Kieu et al. [55]
Zhu et al. [120]
Jichici et al. [51]
Hundman et al. [47]
Tariq et al. [93]
Ezeme et al. [29]
Gunn et al. [41]
Nanduri et al. [75]
Habler et al. [42]
Ezeme et al. [28]

Type of anomalies

Attacks

Faults

Input data

Detection strategies
Neural network
design

Anomaly
score

Implementation & Metrics
Implemen
-tation

n
o
i
t
c
e
j
n
i

t
e
k
c
a
P

M
T
I
M

S
o
D

-
-
(cid:32) (cid:32) (cid:71)(cid:35)
-
-
-
(cid:32)
-
-
-
-
-
-
-
-

-
(cid:32)

-
(cid:32)
-
-
-
-
-
-
-

-
(cid:32)

-
(cid:32)
-
-
-
-
-
-

-
(cid:32)
-
-

-
(cid:32)
-
-
-
-
-
-
-
-
-
-

s
l
a
n
g
i
s

l
o
r
t
n
o
c

e
s
l
a
F

-

-
(cid:32)
-
-

(cid:32)
(cid:32)
-
(cid:32)
-
-
-
-
-

e
r
a
w
l
a
M

-
-
-
-
-
-
-
-
-
-
-
-
-
-

-
(cid:32) (cid:71)(cid:35)
-
(cid:32)
-

-
(cid:32)

(cid:32)
(cid:32)
(cid:32)
(cid:32)
-
(cid:32)

-
-
-
(cid:32) (cid:71)(cid:35) (cid:32) (cid:32) (cid:32)
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-

-
(cid:32)

-
(cid:32)
-
-

-
(cid:32)

(cid:32)
-
(cid:32)

-
(cid:32) (cid:32) (cid:32)
-
-
-
(cid:32) (cid:32)
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-

-
(cid:32)
-

-
(cid:32)
-
-

-
-
(cid:71)(cid:35) (cid:32)
-
-
-
-
-
-

-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-

r
e
y
a
l
k
r
o
w
t
e
N

r
e
y
a
l

r
o
s
n
e
S

m
e
t
s
y
s

l
o
r
t
n
o
C

-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-

-
-
-

(cid:32)
-
(cid:32)
-
-
-

(cid:32)
(cid:32)
(cid:32)
(cid:32)
-
(cid:32)
-
-
-
-
-
-
-
-
-

-
(cid:32)
-

-
(cid:32)
-

-
(cid:71)(cid:35)
-

(cid:32)
-
(cid:32)
-
-
-
-

-
-
-
-
-
-
-
-

-
(cid:32)
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-

-
(cid:32)
-
-

c

ffi
a
r
t
k
r
o
w
t
e
N

-
(cid:32)
-

a
t
a
d
r
o
s
n
e
S

-

-
(cid:32)

s
g
o
l
/
s
l
l
a
c
m
e
t
s
y
S

-
-
-

d
e
t
a
e
r
c
y
l
l
a
u
n
a
M

-
-

-
(cid:71)(cid:35)

-
(cid:32)

-
(cid:32)

-
(cid:32)
-
-
-
-
-
-
-
-
-
-
-

-
(cid:32) (cid:32)
-
-
(cid:32)
-
-
-
-

-
-
(cid:32) (cid:32) (cid:32)
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-

(cid:32)
(cid:32)
(cid:32) (cid:32)
(cid:32) (cid:32)
(cid:32) (cid:32)
(cid:32) (cid:32)
-
(cid:71)(cid:35) (cid:32)
(cid:32)
(cid:32) (cid:32)
(cid:32) (cid:32)
(cid:32) (cid:32)
(cid:32) (cid:32)
-
(cid:32) (cid:32) (cid:32)
-
(cid:32) (cid:32)
-
-
(cid:32) (cid:32)
-
(cid:32)
-
-
(cid:32) (cid:32)
-
(cid:32)
-
(cid:32) (cid:32)
-
(cid:32)
-
(cid:32)

-
(cid:32)
-
-

(cid:32)
-
(cid:32)

(cid:32)
(cid:32)
-
(cid:32)
-

(cid:32)
-
(cid:32)
-
-
-

-
(cid:32)
-
-
-
-

-
(cid:32)

-
(cid:32)

-
(cid:32)

-
(cid:32)

(cid:32)

-
(cid:32) (cid:32)
-
(cid:32)
(cid:32)

r
e
d
o
c
n
e
o
t
u
A

-
(cid:32)
-
-

-
(cid:32)
-
-
-

-
(cid:32)
-
-
-
-
-
-

(cid:32)
(cid:32)
-
(cid:32)
-
-
-

-
(cid:32)
-
-
-
-

N
N
C

-

-
(cid:32)
-
-
-
-
-
-
-

-
(cid:32)
-

-
(cid:32)
-
-
-
-
-
-

-
(cid:32)

-
(cid:32)
-

(cid:32)
-
(cid:32)
-

-
-
(cid:32) (cid:32)
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-

s
e
i
r
e
s
-
e
m
T

i

-
-

-
(cid:32)
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-

N
N
D

N
N
R

-
-
-
-
-
-
-

-
(cid:32)
-
-
-
-
-

-
(cid:32)
1
-
-
-
-
-
2
-
-
-
-
-
-
-
-
-

-
(cid:32)
-
-
-
-
-
-

-
-
-

-
(cid:32)

(cid:32)
-
(cid:32)

-
(cid:32)

-
(cid:32)
-

-
(cid:32)

-
(cid:32)
-
-
-

(cid:32)
-
(cid:32)
-
-

-
(cid:32)
-

(cid:32)
-
(cid:32)

-
(cid:32)

(cid:32)
(cid:32)
(cid:32)
(cid:32)
-
(cid:32)

(cid:32)

r
e
d
o
c
n
e
o
t
u
A
+
N
N
R

-
-

-
(cid:32)
-
-
-
-
-
-
-

r
o
r
r
e
n
o
i
t
c
i
d
e
r
P

-

-
(cid:32)
-
-

(cid:32)
(cid:32)
(cid:32)
-
(cid:32)
-

r
o
r
r
e
n
o
i
t
c
u
r
t
s
n
o
c
e
R

-
(cid:32)
-

(cid:32)
-
(cid:32)
-
-
-

-
(cid:32)
-

(cid:32)
(cid:32)
-
(cid:32)
-
-
-
-

-
(cid:32) (cid:32)
-
-
(cid:32)
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-

(cid:32)
-
(cid:32)
-
-

-
(cid:32)

-
(cid:32)
-
-
-
-

-
(cid:32)
-
-

(cid:32)
-
(cid:32) (cid:32)
-
(cid:32)
-
(cid:32)
-
(cid:32)

-
(cid:32)

(cid:32)

l
e
b
a
l
d
e
t
c
i
d
e
r
P

-
-
-
-
-
-
-
-
-
-

d
l
r
o
w

-
l
a
e
R

-
-

(cid:32)
(cid:32)
-
(cid:32) (cid:32)
-
(cid:32)
-
(cid:32)
-
(cid:32)
-
(cid:32)
-
(cid:32)

n
o
i
t
a
l
u
m
i
S

d
e
b
t
s
e
T

-
(cid:32) (cid:32)
-
-
(cid:32)
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-

-
(cid:32)
-

-
-
-
-
-
-
-
-
-
-
-
-
-
-
-

-
(cid:32)
-

(cid:32)
(cid:32)
-
(cid:32)
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-

-
(cid:32) (cid:71)(cid:35)
-
(cid:32)
-
(cid:32)
-
(cid:32)
-
(cid:32)
-
-
(cid:32)

-
(cid:32) (cid:32)
-
-
(cid:32)
-
-
-
-
-

-
(cid:32)
-

-
-
(cid:32) (cid:32)
-
-
-
-

-
(cid:32)
-

-
(cid:32)

(cid:32)

-
(cid:32)

-
(cid:32)

-
(cid:32)
-

(cid:32)
(cid:32)
-
(cid:32) (cid:32)
-
(cid:32)
-
(cid:32)
(cid:32)
-
(cid:32) (cid:32)
-
(cid:32)
-
-
-
-
-
-

(cid:32)
(cid:32)
(cid:32)
-
(cid:32)

-
(cid:32)

-
(cid:32)
-
-

(cid:32)
(cid:32)
-
(cid:32) (cid:32)
-
-

-
-
(cid:32) (cid:32)
-

(cid:32)
-
-
(cid:32) (cid:32)
-
-
-
-

-
-
(cid:32) (cid:32) (cid:32)
-
-
(cid:32)
-
-
-
(cid:32)
-
-
-
-
-
-
-
-

Evaluation
metric
C
O
R
/
1
F
/
l
l
a
c
e
r
/
n
o
i
s
i
c
e
r
P

y
d
u
t
s

e
s
a
C

/

N
T
N
F
/
P
F
/
P
T

-
-
-
-
-

-
(cid:32)
-

-
(cid:32)
-
-

-
(cid:32)
-
-
-

-
(cid:32)
-
-
-

-
(cid:32)
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-

(cid:32)
-
(cid:32)

(cid:32)
-
(cid:32)

(cid:32)
-
(cid:32)

(cid:32)
(cid:32)
-
(cid:32)

(cid:32)
-
(cid:32)

-
(cid:32)
-

(cid:32)
(cid:32)
-
(cid:32)

(cid:32)
-
(cid:32)

(cid:32)
(cid:32)
-
(cid:32)

(cid:32)
-
(cid:32)

(cid:32)
-
(cid:32)
-

-
(cid:32)
-

4 REVIEW OF DEEP LEARNING-BASED ANOMALY DETECTION METHODS

In this section, we present novel ideas and our findings in each domain of CPSs. We identified
that current research efforts mainly focus on four types of systems: (1) industrial control systems
(ICSs); (2) smart grid; (3) intelligent transportation systems (ITSs); and (4) aerial systems. Also, we
investigate general-purpose methods that analyze time-series data. We have summarized existing
work under our taxonomy in Table 2. The metrics of the taxonomy are listed in the column while
current methods that target different CPSs are presented in each row. We also provide a list of
public datasets used in DLAD methods1.

1https://github.com/leonnewton/DLAD-Survey

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

10

Yuan Luo, Ya Xiao, et al.

4.1 DLAD methods in ICSs

Characteristics of DLAD methods in ICSs. DLAD methods in ICS detect both attacks [31, 39, 48,
53, 58, 60, 88, 109] and faults [15, 25, 32, 59, 62, 63, 92, 108]. The attack types include injecting false
control commands, altering communicating traffic packets, and spoofing sensor values. On the other
hand, much of the research effort in ICS is on detecting faults, which have been less studied in other
applications of CPSs. The complexity of infrastructures and the harsh working conditions of field
devices can cause unexpected faults. The majority of existing work detects anomalies from sensor
and actuator values, which are easy to be obtained. Only several studies handle network traffic data
since there are inadequate real-world traffic data and proprietary communication protocols. Very
few studies target control systems (e.g., system logs) and thus we did not find such a dataset in
ICS. For neural network architectures, LSTMs and autoencoders (and their variations) are the most
commonly used. Typically, LSTMs are used to capture the temporal relation of sensor values and
unsupervised learning is achieved through autoencoders. Most solutions adopt the prediction error
to measure the deviation of an anomaly. Testbeds are usually used to evaluate proposed methods
and the SWaT testbed [38] is a popular platform to conduct the evaluation. Precision, recall, ùêπ1, and
ROC are de facto evaluation metrics. In addition to the above characteristics, we also find some
new techniques and explorations used by DLAD methods in ICS. As illustrated in Figure 4, in what
follows, we discuss representative new techniques in ICS. Note that these methods can also be
applied to other domains.

Fig. 4. An illustration of representative new techniques in ICS. These methods can also be applied to other
domains.

4.1.1 Representative new techniques. Applying filters before DLAD methods to improve ef-
ficiency. Applying DLAD methods in ICS, where running environments are usually resource-
constrained, must consider the efficiency factor. A lightweight and efficient conventional detecting
method could be utilized before DLAD methods to decrease data to be checked significantly. Feng et
al. [31] proposed a combined anomaly detection framework. The main idea is to first apply a Bloom
filter to traffic data and then pick suspicious packets to the follow-up LSTM-based detector. The
fast and lightweight filter reduces the burden of the LSTM detector, which enhances the detection
efficiency. This method aims to identify cyber attacks in the communication layer of a SCADA
system. The attack types include injecting malicious commands (e.g., state, parameter, and function
code) and DoS attacks. Also, the LSTM detector stacks two LSTM layers using signatures of previous

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

Input dataData filterFenget al. [31]FeaturerepresentationLi et al. [62]Schneider et al. [88]CNN layer to capture contextCanizoet al. [15] Kravchiket al. [58] Wu et al. [108]GAN-based methodsLi et al. [60]Multi-branch Deep NetworkZohrevandet al. [121]Neural network designEnsemble learningStatistical methodData processingDeep Learning-Based Anomaly Detection in Cyber-Physical Systems: Progress and Opportunities

11

packets to predict the signature of the next packet. Then, the predicted signature is checked to
examine whether it is in the normal signature database. The method is evaluated on a gas pipeline
system in a laboratory environment, which outperforms baseline methods (e.g., Bayesian Network,
Isolation Forest) in the recall, accuracy, and ùêπ1 score.

Open problems. Computing resources of CPS devices are limited. Utilizing filters to boost detecting
efficiency makes deploying DLAD methods in CPS more practical. However, there are two open
questions in terms of how to design the filter. First, the interrelationship between the filter and DL
models is not studied. Namely, the methodology to find a proper filter that works best with DLAD
methods can be further investigated. Second, the authors found that if the filter can remove noise,
the detection performance will be improved. Hence how to design a denoising filter can be studied.
Deep learning-based feature representation. We identify three types of feature representation
in DLAD methods: (1) raw data (directly fed to models) (2) data processing (e.g., inner products
of two sensor time series) (3) deep learning-based embedding. Data processing helps to identify
discriminative characteristics of data, which is also used in conventional detection methods. We find
that deep learning methods are utilized to integrate features and reduce dimensions of feature space.
For example, Li et al. [62] and Schneider et al. [88] proposed deep autoencoders to automatically
compress raw input to lower-dimension hidden layer representation, which further is utilized as
the input of the follow-up neural network. Despite both works [62, 88] utilizing the hidden layer to
represent features, the actual neural network detecting anomalies can be different. One [62] takes
sensor value and uses LSTM to generate prediction errors, while the other [88] takes traffic data
and uses autoencoder to generate reconstruction errors. Both methods are evaluated on data from
testbeds. When expert knowledge is limited (e.g., face a new network protocol), this can be very
useful.

Open problems. Using deep learning methods to automatically learn features is known as one type
of transfer learning [99]. When applied to anomaly detection task, DL-based feature representation
faces two challenges. First, the rules to choose the number of features and learning parameters
are not clear. Currently, it is quite subjective to decide the features and parameters to be selected.
Second, not all features are appropriate for the detection task. It is possible that some features fail
to capture the essential characteristics of data.
Capturing temporal and spatial relationships with different architectures. The value of
one sensor or actuator is one-dimension data (e.g., time-series), many LSTM-based DLAD methods
are proposed to learn temporal behaviors of the data. However, there exist correlations among
several different sensors and actuators, which reflect logical relations in the control system. In other
words, there are interdependent relationships among sensors and actuators. Hence one challenge
is to capture context (temporal, spatial, and logical) features in multi-dimensional (time-series of
multiple sensors and actuators) data. To this end, CNN can extract features of multi-dimensional
data jointly via convolution operations. Several approaches [15, 58, 108] adopt a convolutional
layer as the first layer of the neural network to obtain correlations of multiple sensors in a sliding
time window. Further, the extracted features are fed to subsequent layers to generate output scores.
These methods can be employed to detect both attacks and faults. All methods take sensor and
actuator value as input and generate prediction error or predicted labels. Meanwhile, Canizo et
al. [15] and Wu et al. [108] utilized RNN to take the output of the CNN layer and form the prediction
layer. Moreover, both methods use datasets from real industrial plants. Precision, recall, ùêπ1, and
ROC are evaluation metrics.

Open problems. CNN models are used to capture correlations of sensor readings. However, the
input to CNN models is still manually designed. A clear guideline to create the structure of input
data is needed. On the other hand, for time-series data, anomaly detection action is conducted

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

12

Yuan Luo, Ya Xiao, et al.

based on a time window. If the length of input time-series data is too short (shorter than a time
window), a suitable padding mechanism is needed to expand input data.
Exploration of GAN-based methods. Li et al. [60] proposed a GAN-based framework to capture
the spatial-temporal correlation in the multi-dimension data. Both the generator and discriminator
are utilized to detect anomalies by reconstruction and discrimination errors. Also, LSTM models
are used to build the generator and discriminator. The framework takes sensor and actuator values
as input and aims to detect false control signals. Compared to a GAN-based anomaly detection
method [114] that is not focused on ICS, this method finds that capturing temporal correlation is the
key to improve performance. The method outperforms baseline methods (e.g., Principal component
analysis, One-Class SVM, K-Nearest Neighbour, Feature Bagging) in precision, recall, and ùêπ1. This
is an interesting attempt to utilize GAN-based models. Also, a well-tuned generator can be used to
produce training data.

Current limitations. It is an interesting early effort to explore GAN-based DLAD methods. How-
ever, two questions remain unsolved. First, false positives are high. The precision of the SWaT
dataset is 70% and the WADI dataset is 53.75%. The cause of false positives is not fully investigated
and discussed. Second, the DL models for the generator and discriminator are empirically selected.
Other models can be examined to find the best choice.
Applying conventional and DLAD methods parallelly through ensemble learning. We
have introduced that conventional methods can be used as filters before applying DLAD methods.
However, to increase the accuracy, these two kinds of methods can be placed parallelly to learn
the characteristics of input data. Zohrevand et al. [121] proposed a framework named MBPF
that ensembles two components: (1) a statistical method named TBATS (Trigonometric Box-Cox
transform, ARMA errors, Trend, and Seasonal components) [22], and (2) Multi-branch Deep Network
Component. First, seasonality evaluation and outlier elimination are applied to remove noise. Then,
pre-processed data is fed to TBATS and deep learning models simultaneously to capture linear and
sequential relations. Finally, a Multi-Layer Perceptron (MLP) takes the output of TBATS and deep
learning models, which will vote between the two methods and predict the next value. The MBPF
framework can analyze any time-series data. The Mean Absolute Error (MAE) and Root Mean
Square (RMSE) are utilized to measure prediction errors. Evaluated on a real-world SCADA water
supply system, the method outperforms baseline methods (e.g., Multilayer Perceptron, Stacked
LSTM, Regularized LSTM) when measured by MAE, RMSE, Absolute deviation (AbsDev) and
Relative Errors (ReErr).

Open problems. The ensemble of parametric methods and DL-based methods makes DLAD
methods more reliable and less sensitive to stochastic data. However, there are two open questions
that MBPF can address in future work. First, MBPF prefers capturing seasonal patterns, which often
exist in systems such as water management systems. For systems that without seasonality, the
method may not work. Second, complex pre-processing techniques and multiple models may add
computational costs to CPSs. Thus it will limit the application of MBPF.

4.2 DLAD methods in smart grid

Characteristics of DLAD methods in smart grid. False data injection (FDI) attacks [64] usually
inject malicious packets (e.g., traffic of ùê∂0, ùê∂1) to create small measurement errors (e.g., alter ùëÜ2,
ùê∑1) to compromise the state estimation component of a smart grid. FDI attacks are stealthy and
difficult to detect, which have attracted most of the research efforts [10, 23, 78, 100, 101, 104].
Meanwhile, few studies detect faults [30] and injected anomalies [94]. Although FDI attacks are
accomplished via network packet injection, the majority of current work focuses on analyzing
sensor data (e.g., voltage magnitude, power flow, electricity consumption). We find one work [78]
to analyze network packet data. We did not find work protecting control systems and datasets

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

Deep Learning-Based Anomaly Detection in Cyber-Physical Systems: Progress and Opportunities

13

about system logs or traces in the smart grid published by DLAD methods. This is may partly
because real control systems are hard to obtain. Autoencoders and RNNs (and their variations)
are almost equally adopted architectures, which have been proven effective by existing works. So
reconstruction and prediction errors are both used to detect anomalies. Simulations are mainly
utilized to evaluate the performance of methods. Specifically, the IEEE X-bus [8] (e.g., 9-bus, 14-bus)
power test system is employed to simulate attacks and collect data. There are various evaluation
metrics, e.g., precision, recall, ùêπ1, and accuracy. As shown in Figure 5, we present representative
new techniques in smart grid.

Fig. 5. An illustration of representative new techniques in smart grid.

4.2.1 Representative new techniques. Deep learning aided state estimator. In the smart grid, a
state estimator is utilized to monitor the running state of the grid [74], which is a key component
to protect the power system. The input data of one state estimator is usually collected from
SCADA systems, which obtain measurements from sensors and field devices. A bad data detector or
filter [57] is connected to the state estimator to eliminate false or injected data, which usually utilizes
normalized residuals of measurements [46]. However, attacks such as false data injection (FDI) and
PMU data manipulation attack (PDMA) can evade the detection of conventional state estimators.
These attacks deliberately mimic legitimate state variables and thus evade the detection. To thwart
these attacks, several deep learning-based methods are proposed to improve state estimator, which
adopt three strategies:

(1) Remove false data before bad data detectors. Basumallik et al. [10] added a filter, which is based
on deep learning techniques, to eliminate false data, which then could transfer sanitized
data to the bad data detector. This filter contains two convolutional layers and takes voltage
values as input. The output is the probabilities of various attacks (e.g., FDI attack). If attacks
are detected, the false data is removed to protect the state estimator.

(2) Improve bad data detectors via joint detection. Wang et al. [101] utilized a deep autoencoder
with RBM layers to form a joint detection framework with the bad data detector. The input
of the autoencoder is extracted 108 features from PMU measurements, e.g., the three-phase
magnitude, angles, and voltages. If the reconstruction error is above a pre-defined threshold,
then attacks are detected from the raw data. Only attacks that are identified by both the
autoencoder and bad data detector will be flagged as alerts in the management system, which
significantly reduces false positives of conventional bad data detector.

(3) Improve state estimators via predicting precise state variables. Wang et al. [100] proposed a
DBN network with ten hidden layers to take generator and market time-series information
as input and predict electric load in real-time. The predicted electric load intervals are the

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

Power grid measurement dataCNN-based filterState estimatorBad data detectorDeep autoencoderPrecise state variablesData processingBasumalliket al. [10] Wang et al. [100] Joint detectionWang et al. [101]Network packets3-layer LSTM Measurement & traffic dataNiuet al. [78] Deep autoencoderZhang et al. [119] Market dataMeasurement & market data14

Yuan Luo, Ya Xiao, et al.

normal range of state variables. The method pinpoints precise state variables, thus attacks
that cause abnormal states are detected.

Current limitations. The major threat to the smart grid is false data injection (FDI) attacks.
Improving bad data detectors can thwart FDI attacks. However, current DL-aided detectors have
limitations. First, the sampling rate of PMU can be at a pretty high frequency. Using all the data
as an input needs massive computing resources. How to keep essential historical data and filter
out irrelevant data is a relevant challenge to DLAD methods. Second, current bad data detectors
are mainly evaluated on synthetic data, which are usually generated by simulation. The impact of
real-world FDI attacks is not studied.
Combining characteristics from sensors and network layers. Most existing studies adopt
the threat model that a limited number of data points (i.e., point anomalies) are manipulated by
FDI attacks. Niu et al. [78] indicated that sophisticated attackers can inject multivariate malicious
data points in a period (i.e., collective and contextual anomalies). Since such FDI attacks are more
stealthy, inspecting measurement data alone may fail to detect such stealthy attacks. They proposed
a mixed neural network architecture that combines sensor measurements and network packets.
First, the one-dimension convolutional layer is utilized to extract features from the source data.
Originally, raw data of the two sources are in different dimensions, which is further transformed
into the same dimension by the convolution operation. Then, the features of two sources from past
values are fully connected and fed to a 3-layer LSTM network to predict the next data point. Data
points that generate large prediction errors are classified as anomalies. The method is evaluated on
an IEEE 39-bus system. Overall, the accuracy of the method is above 0.8.

Open problems. Utilizing features from both sensors and network traffic can help to learn system
states precisely. But two issues need further investigation. First, two types of features are now
directly connected using a fully connected layer. Methods that not only integrate all features but
also provide interpretability have not been explored yet. Second, contributions of different features
to the detection performance are not compared. The performance of one type of feature (e.g., using
only sensor features) has not been explored.
Detecting anomalies both in the market and physical system. Most existing methods concen-
trate on ensuring the stability of the running status of physical systems in the smart grid. However,
considering merely sensor measurement and traffic packets data may fail to secure the robustness.
In modern transactive power systems, the market plays an important role in adjusting the state of
the system. Specifically, the electricity price and consumption also impact the grid by affecting the
workload. Indeed, FDI attacks have already targeted markets [102, 110]. We believe that it is closer
to reality to consider cyberattacks in the market utilities and networks. Zhang et al. [119] studied
measurements of both the electricity market and the physical system. In particular, price, voltage
magnitude, and power consumption are monitored. The proposed framework utilizes a stacked
autoencoder and generates reconstruction errors of the market and physical system separately. If
anomalies are detected in the market, network traffic and server logs are checked to locate the
error. The framework is evaluated on a 9 bus bulk system modeled in MATPOWER [68]. Results
show that 79% of outages and 96.9% of attacks can be detected.

Current limitations. Bid price and bid quantity (market information) are two important factors
that distinguish the smart grid from traditional electricity systems. These factors are the context of
electricity consumption. However, this also indicates that these two features can be impacted by
economic booms and busts. DLAD methods that use market information need to update models
frequently so as to capture the characteristics of changed market information. Another limitation
is that current detection schemes focus on securing the status of the whole grid. The specific
compromised component is not identified.

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

Deep Learning-Based Anomaly Detection in Cyber-Physical Systems: Progress and Opportunities

15

4.3 DLAD methods in ITSs

Characteristics of DLAD methods in ITSs. Most studies in ITS aim to detect attacks on the CAN
bus [51, 84, 95, 120], which is responsible for the communication between devices (e.g., airbags)
and Electronic Control Units (ECUs) [21]. Khanapuri et al. [54] targeted vehicle platoons to avoid
collisions among a sequence of cars. Kieu et al. [55] studied aggressive manners of drivers while
Wyk et al. [97] also considered anomalies caused by faulty sensor readings. Attacks on the CAN
bus include traffic drop, traffic sequence in reverse order, competing commands from two sources,
false packet injection, and traffic replay attack, etc. Given that most research efforts analyze CAN
bus network data, sensor data from LIDAR, RADAR, GPS speed, acceleration sensor, etc, are also
utilized. Few works directly analyze control systems. For network architectures, there are no
obvious dominant neural networks. Typically, LSTM models are used to capture temporal relations
and CNN models are utilized to learn context respectively. Most methods generate prediction errors
to detect anomalies while this work [55] uses the reconstruction error. Most CAN-bus datasets are
obtained from real-world vehicles. Precision, recall, accuracy, false positives, ùêπ1, ROC are typically
used to measure the performance. We present representative new techniques in ITS as summarized
in Figure 6.

Fig. 6. An illustration of representative new techniques in ITS.

4.3.1 Representative new techniques. The embedding of contextual information. Smart vehi-
cles interact with the surrounding environment constantly. Cameras, radars, speed sensors are
utilized to obtain the position, velocity, status of on-going vehicles. Existing studies use data from
the above sensors and devices to ensure that vehicles perform in normal behaviors. However, the
influence of environments is not captured if DLAD methods merely detect the condition of vehicles.
Indeed, the environment information (i.e., context) is also important to decide the status of vehicles.
For example, the same physical status can be classified as normal or anomalous depending on
different weather, road, and traffic information. Kieu et al. [55] utilized an embedding method to
encode context information into matrixes. Further, context embedding matrixes are concatenated
with feature-enriched time-series matrixes. Such enriched features contribute to higher precision
and recall. This work aims to detect anomalies in time-series data and validates it on a driving
behavior dataset. Thus, it can be used to identify reckless driving. The concatenated matrixes are
fed to 2D CNN and LSTM autoencoders, which produce reconstruction errors to recognize outliers.
The method outperforms two baseline methods (i.e., Local Outlier Factor [14], One-Class Support
Vector Machines [66]) in precision, recall, and ùêπ1 score.

Current limitations. We compare the performance of the advanced model (with contextual
information) and the basic model (without contextual information). We find that the advanced
model improves the recall but the precision is unchanged. This shows that contextual information

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

Input dataNeural network designEnvironment information embeddingKieuet al. [55]Study basic models on the CAN bus dataTaylor et al. [95]Jichiciet al. [51]Filters to improve robustnessWyket al. [97] Utilize mobile edge devicesZhu et al. [120]16

Yuan Luo, Ya Xiao, et al.

contributes to reducing false negatives. The advanced model can identify more anomalies than
the basic model. However, if the model incorrectly classifies normal data as anomalies, adding
contextual information cannot improve the model.
Utilizing mobile edge devices to boost computing. Control commands are sent from ECUs to
physical devices and mechanical parts of vehicles. With all these traffic transmitted on the CAN bus,
a short delay of messages could cause severe casualties when users respond to sudden incidents.
Meanwhile, DLAD methods typically consume a large number of computing resources. Restricted
computing power on vehicles could add delay to send out benign commands when conducting
the anomaly detection process. To this end, Zhu et al. [120] proposed the multi-dimension LSTM
framework to allow the parallel computing of certain LSTM layers, which can speed up the
computing process. Also, part of the computing is delegated to mobile edge devices. In particular,
two hidden layers are adopted to adjust the dimensions of input data, which are located at on-board
computers. Further, data-based and time-based features are fed separately and simultaneously
to two LSTM layers on edge devices. This work targets spoof, replay, flood, drop and tamper
attacks to CAN bus messages. The cross entropy of the predicted message and the next message is
calculated to detect the anomaly. With the accuracy reaching 90%, the detection only takes about
0.61 milliseconds.

Current limitations. Mobile edge devices and parallel computing significantly reduce the comput-
ing time, which is 100 times faster than OBU as illustrated in this work. However, the communication
costs between edge devices and control systems are not measured. DLAD methods have to balance
computing and communication costs. Another issue is that parallel computing and its communica-
tion channel may also be vulnerable. Attackers may attack the communication network among
edge devices instead of ITS.
Applying filters after DLAD methods to improve robustness. DLAD methods are used to
remove anomalous measurements so that control systems can generate correct responses to envi-
ronmental changes. Thus, DLAD methods on ITS systems must be robust and work in real-time.
To achieve robustness, Wyk et al. [97] adopted a mixed framework. This work applies a three-layer
CNN-based model first to eliminate false sensor readings. Then, scrutinized data is fed to Kalman
filters (KF) to further remove anomalies that are undetected by the CNN model. The authors find
that the CNN-KF model surpasses the KF-CNN model in general. Also, they observe that deploying
a Kalman filter as the last layer makes the detecting process more reliable [87]. This work aims to
detect and remove false sensor readings caused by both false injection attacks and failures. The
sensors include speed, acceleration, and GPS speed sensors. The CNN model consists of three CNN
layers and two fully connected layers. Benign sensor readings are transferred to the control system
from the CNN-KF model. The method is validated on a two-year real-world dataset obtained from
the Safety Pilot Model Deployment (SPMD) program [11]. Accuracy, precision, and ùêπ1 are used to
measure the performance, which outperforms two baseline (i.e., KF, CNN) methods.

Current limitations. Overall, the ùêπ1 score of the CNN-KF model is about 2% higher than the CNN
model. Hence if the computing resources are sufficient, the CNN-KF model can be adopted. If
computing resources on the vehicle are limited, the CNN model may be used. This method does not
distinguish between attacks and faults. Thus the root cause may not be identified. Also, since the
experiments are conducted on synthetic datasets, the performance in real-world sensor networks
are not measured.
Studying the performance of basic models on the CAN bus data. As an important part of the
communication system, the CAN bus has attracted most of the research efforts as we have shown
in this section. With various heterogeneous neural network models introduced, the performance
of basic neural networks is not clear. Serving as building blocks of sophisticated models, these
basic architectures of neural networks have to be fully explored to better build and tune complex

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

Deep Learning-Based Anomaly Detection in Cyber-Physical Systems: Progress and Opportunities

17

models. To this end, Taylor et al. [95] investigated the performance of a two-layer LSTM (with
two hidden layers) model on different types of anomalies. Five types of anomalies (e.g., packet
drop) are adopted to simulate attacks. Fifty million of traffic packets are captured from real-world
vehicles as training and test dataset. The area under curve (AUC) is measured under different loss
functions (e.g., maximum bit loss). Meanwhile, Jichici et al. [51] evaluated the performance of a
three-layer DNN with different settings of training, validation, and testing proportion of datasets.
The parameters of the gradient, epochs and Mean Squared Error (MSE) are reported. The replay of
traffic frames and the injection of data attacks are used to simulate the anomaly. True negatives,
false positives, true positives, and false negatives are calculated on a real-world dataset. Results
show that basic models can achieve high true positives and low false positives.

Current limitations. CAN bus is the core of the control system in a smart car. Despite impressive
detection performance, basic DL models also have problems. First, the false positives of basic models
are relatively high. The authors reported that the false positive rate can be between 2% to 10%.
It is not suitable to deploy such DLAD methods in practical smart car systems. Second, current
detection is based on individual ECU components. The correlations among ECUs have not been
studied, which can be used to reduce false positives.

4.4 DLAD methods in aerial systems

Characteristics of DLAD methods in aerial systems. There are methods studying faults in
aircraft [75] and spacecraft [41, 47, 93]. The faults consist of point and contextual anomalies
in sensor and communication data. Some research efforts are on attacks in unmanned aerial
vehicles (UAVs) [28, 29] and aircraft [42]. The attacks include malicious code in control systems,
eavesdropping, and spoofing in the communication network, etc. With network and sensor data
as conventional input data, two studies [28, 29] investigate attacks to control systems and utilize
kernel events and logs as input. Most approaches use LSTMs and variants to generate prediction
errors. Most aircraft and spacecraft data are collected from real airplanes and satellites. Although
running data is obtained from real UAVs, attacks are simulated and injected into normal traces. It is
hard to find a commonly used platform in aerial systems. Precision, recall, ùêπ1, true positives and
false positives are calculated to measure the performance. As shown in Figure 7, we present the
details of representative techniques in aerial systems as follows. We argue that these methods can
be used in other domains as well.

Fig. 7. An illustration of representative new techniques in aerial systems.

4.4.1 Representative new techniques. Automatic and dynamic threshold. For all DLAD methods,
whether to generate prediction or reconstruction errors, a threshold is expected to decide if a value
is normal or anomalous. Typically, this threshold is determined empirically via trying different

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

Automatic & dynamic thresholdInput dataData processingData sampling & reductionProtecting the control systemStochasticity& temporal dependenceProtect the ADS-B systemNeural network designADS-B messages System calls & kernel events Hundmanet al. [47]Tariqet al. [93]Ezeme et al. [28, 29] Su et al. [92] Hableret al. [42]18

Yuan Luo, Ya Xiao, et al.

values by an expert. To automate this process, an unsupervised yet accurate method is needed to
produce a threshold without the expert knowledge. Hundman et al. [47] proposed a dynamic and
automatic method to calculate the threshold. Firstly, smoothed prediction errors are generated. An
exponentially-weighted average (EWMA) is adopted to smooth a sequence of past prediction errors,
which usually contain spikes when there are sharp changes in raw values. Secondly, a formula
composed of the mean and standard deviations is utilized to dynamically adjust the threshold. The
key observation is that the filtration of max smoothed errors is used to eliminate false positives.
The unsupervised thresholding method outperforms Gaussian tail-based methods and can be used
in other DLAD methods as well. This work utilizes the LSTM model to detect faults in the telemetry
data of the spacecraft. Precision, recall, ùêπ0.5 scores are computed to measure the performance.

Current limitations. Automatic threshold tuning makes DLAD methods more practical in a
real-world deployment. However, EWMA and smoothed errors based dynamic thresholds can be
improved. Firstly, a large time window is needed to calculate errors. In a real-time system, attacks
or faults may already cause catastrophic disasters. Thus the time window may cause a delay in
detecting anomalies and prevent losses. Secondly, false positives are still high. Given the large
volume of telemetry data, even a small false positive rate will cost massive time and effort of users
to investigate these false alarms.
Input data sampling and reduction. Spacecrafts generate a large quantity of telemetry data
when operating at space. The size and noise of the data could reduce the efficiency and accuracy
of DLAD models. Conventional average sampling methods adopt a time window to compress a
sequence of data into a data point. But the disadvantage is that the anomalous data is also shifted
into the normal range. Tariq et al. [93] proposed an archive sampling method to reduce the data
amount while maintaining the characteristics of raw data. To this end, a list is used to record each
telemetry in one component. For each row data in the original dataset, different values are saved
in the new database. In other words, rows with the same value will not be saved. With archive
sampling, the characteristics have not been changed and remain the same with raw telemetry
data. The method utilizes ConvLSTM and Mixtures of Probabilistic PCA (MPPCA) jointly to detect
anomalies, where a higher error will be accepted as the final error score. The model is evaluated on
a real-world satellite dataset with 22 million telemetry data points. The precision and ùêπ1 score of
the method outperforms four baseline methods (e.g., One-Class Support Vector Machines, Isolation
Forest) to a large extent. But the recall is at a similar level with baseline methods.

Current limitations. Archive sampling significantly reduces the amount of data and keeps the
original characteristics. But two issues remain unsolved. First, due to the different sampling rates
of telemetry channels, the first rows of the dataset may not be stored. This may cause a loss of
data. Second, collective anomalies may not be detected. Because the temporal dependency among
different telemetry channels may be altered by archive sampling (although numeric values have
not changed).
Protecting the control system. Attacks targeting control systems are covert and devastating,
which do not necessarily change the values of sensors and network traffic. Detection methods rely
on sensor measurements and communication patterns may fail to identify such attacks. Typically,
malicious code that injected into control systems intentionally changes the running logic of con-
trollers (e.g., PLCs), hence it can potentially cause physical damage to CPSs. However, conventional
methods may fail to identify elaborate attacks that generate similar sequences of events to that
of normal code blocks. Ezeme et al. [28, 29] utilize system calls and kernel events to ensure the
running status of control systems. Concretely, through log preprocessing, features (e.g., events)
are extracted from raw log traces. Further, an LSTM model with an attention layer is adopted to
predict subsequent event sequences. The prediction error is measured to identify the anomaly. Four
scenarios (i.e., full-while, ffo-ls, hilRF-InFin, and sporadic) are used to simulate the status of a UAV,

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

Deep Learning-Based Anomaly Detection in Cyber-Physical Systems: Progress and Opportunities

19

where the data is retrieved. The method outperforms three approaches [26, 27, 86] by evaluating
true positives and false positives.

Open problems. The correlation of system calls and kernel events is captured through attention-
based LSTM neural networks. However, the number of system calls and kernel events in UAV
control systems are small compared to other CPSs (e.g., ICSs). Whether this method can effectively
handle enormous system calls needs to be measured. Moreover, the computational performance
is measured on a desktop computer. A real embedded device can be used to evaluate the running
performance.
Capture the stochasticity and temporal dependence. The multivariate time series data is
produced widely in CPSs (e.g., spacecraft, ICS), which contains both stochasticity and temporal
dependence. To better learn the patterns of normal data, capturing both characteristics can improve
the accuracy of the detection. To this end, Su et al. [92] adopts a deep Bayesian model (named
VAE) [56] to map input data into stochastic variables. Further, to learn temporal dependence,
these variables are connected to hidden Gated recurrent units (GRUs) representations. Finally,
planar NF [83] is used to learn non-Gaussian distributions of input data from hidden variables
of the previous step, the output of which is fed to consecutive layers to reconstruct the original
input data point. Reconstruction errors are utilized to detect anomalies in time-series data. The
method outperforms three baseline methods (LSTM-NDT[47], DAGMM[122], LSTM-VAE[79]) in
ùêπ1, precision, and recall when evaluated on three datasets.

Open problems. Applied to three different datasets, the recall of this work is much higher than
the precision (about 5%-20%). And the precision is similar to the three baseline methods. This may
be caused by the stochasticity of CPS data (this work intends to capture such stochasticity). If the
DL model is sensitive to random noise, small changes of noise (e.g., relatively large but normal
engine vibrations) could cause the model to generate a lot of false positives. This issue can be
further studied and experimentally investigated.
Detecting anomalies in the ADS-B system. As a key component of the air traffic control man-
agement, the Automatic dependent surveillance‚Äìbroadcast (ADS‚ÄìB) system is utilized to notify the
position of an airplane to ground stations and other aircraft. However, attackers could eavesdrop
messages to learn activities and position of aircraft or spoof messages to disturb the air traffic. Also,
DoS attacks can cause airplanes to fail to report and receive information. Existing countermea-
sures require additional sensors to send signals or modification of the ADS-B protocol to provide
authentication and encryption, which may not be possible due to the strict regulation. To detect
the above attacks, Habler et al. [42] used ADS-B messages as the data source to detect anomalies.
They utilized an LSTM autoencoder to reconstruct features of a window of messages. The input
features include speed, latitude, longitude, altitude and distance delta. Reconstruction errors are
used to detect the anomaly. The method is evaluated on a large-scale flight tracking dataset from
Flightradar24 [34], which outperforms five baseline methods (e.g., Hidden Markov model with
Gaussian mixture emissions (GMM-HMM) [43], one-class SVM, Isolation Forest, DBSTREAM [9])
when measured by true positives and false positives.

Open problems. The LSTM-based autoencoder is effective to detect injected anomalies as il-
lustrated in this work. However, two issues can be improved. First, the anomalies are manually
simulated and the types are simple. For example, random noise and sensor value drift are injected
into the origin data. However, sophisticated attacks such as replay attacks are not studied. Second,
contextual information could be extracted as features. For example, the flying states (parameters)
and current geolocations of airplanes can be combined as the context of a flight.
Summary of major categories of limitations. We briefly summarize five major categories of
limitations as discussed in this section. 1) A clear guideline is needed to create the input structure
of neural models. 2) The cause of false positives is not fully investigated. 3) The evaluation is on

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

20

Yuan Luo, Ya Xiao, et al.

synthetic anomalies. 4) Feature representation process requires a methodology. 5) Computational
performance is usually not measured.

5 EXPLORATION OF DEEP LEARNING-BASED ANOMALY DETECTION MODELS

In this section, we use and customize DL models in the existing work [58, 88, 115] to illustrate the
process to detect anomalies in an industrial control system. Note that the purpose of experiments
is not to provide sophisticated DLAD methods. Instead, with these experiments, we aim to show
the usage of DL models, the typical workflow of DLAD methods, and the running performance
of DL models. We hope these efforts can provide readers with some insights to develop DLAD
methods that are fit for their own research problems. The source code of these experiments has
been open-sourced2. Specifically, we conduct two series of experiments.

‚Ä¢ We explore LSTM-based DLAD methods to capture the temporal dependency of time-series

data [31, 47, 93]. Prediction errors are used as anomaly scores.

‚Ä¢ We explore CNN-based autoencoders to capture the correlation of different sensors [15, 97,

115]. Reconstruction errors are used as anomaly scores.

Testbed & Dataset. We utilize a scale-down and fully functional ICS testbed named the Secure
Water Treatment (SWaT) [50] to conduct experiments. The testbed is a water treatment plant with
six stages. Each stage is responsible for a specific treatment process (e.g., filtration). The testbed
consists of sensors, actuators, communication networks, and control systems. The testbed provides
a dataset, which consists of 7 days of normal data and 4 days of attack data. The normal data
contains 496,800 data points. The attack data contains 36 types of attacks and 449,917 data points.
The details of the testbed can be found at [67]. This testbed is widely used in the anomaly detection
research community in CPS.
Implementation. We conduct all experiments on a desktop computer (OS Linux x86_64, 3.7GHz
Intel i7 8700K CPU, 32 GB memory). The GPU is NVIDIA GeForce GTX 1080 Ti (12 GB memory).
All neural models are implemented using the Keras [96] development platform. The calculation
operations are performed with NumPy [1].

5.1 LSTM-based models

Time-series data are pervasive in CPS. Sensor values (usually with a sampling rate) are usually
utilized to record the physical properties of CPS. For example, the water level sensor can report a
water level value every second. Sensor values of different periods usually have dependencies. For
instance, the water level at present will impact the value in the future. Also, whether increasing or
decreasing, the changes of the water level should be continuous. To capture such dependencies and
correlations, LSTM-based neural models are used to build DLAD methods. Indeed, LSTMs have
been successfully applied to sequence learning tasks, e.g., time series prediction, speech recognition.
The key enabler of LSTM is its special design of internal vectors. A cell state vector is utilized to
obtain long-term "memories". Meanwhile, a forget vector named forget gate is used to selectively
ignore information that is kept in the cell state. The hidden state vector stores the information to
be fed to the next time step. Memorizing information of extensive time steps is useful to capture
the temporal dependency of time-series data.
The attack used in the experiments. We present a false data injection attack [71, 72] (which is
very common in attacks against CPS) in the SWaT dataset. As illustrated in Figure 8, Figure 8a is
the water level (sensor LIT-101) of a water tank in a normal period. The water level changes since
the system is treating water. However, as presented in Figure 8b, the false data injection attack
has manipulated the water level readings that far exceed the measurement range of sensors. Thus

2https://github.com/leonnewton/DLAD-Survey/tree/main/DLADexperiments

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

Deep Learning-Based Anomaly Detection in Cyber-Physical Systems: Progress and Opportunities

21

the temporal dependency of water level has been altered. The attack can be conducted through
spoofing attacks or MITM attacks.

(a) Water level values in a normal period,
which increase and decrease periodically as
the system treats the water.

(b) Water level values in an anomalous pe-
riod. A data injection attack has changed the
normal increasing process of water level.

Fig. 8. Water level values of a normal period and an anomalous period.

Design of LSTM-based models. We elaborate the design from three aspects: (1) Input data &
preprocessing. (2) Neural model architecture. (3) Anomaly scores.

Input data & preprocessing. The input data is unidimensional sensor time-series data. Data
preprocessing approaches are usually leveraged to transform input data into the format that can be
applied to neural networks. For example, we first apply a Min-Max [4] scaler to map raw data into
range 0 to 1.

Neural model architecture. We utilize LSTM models [58, 88] to predict future values from past
values. As illustrated in Figure 9, a time window of past values can be represented as ùëäùëùùëéùë†ùë° = (ùëÜùë° ,
ùëÜùë° +1, ¬∑ ¬∑ ¬∑ , ùëÜùë° +ùëò ), where ùëÜùë° is a sensor value at time ùë° and the size of time window is ùëò. Then, this
sequence can be used to predict future time-window sequence ùëäùëì ùë¢ùë°ùë¢ùëüùëí = (ùëÜùë° +ùëò+1, ùëÜùë° +ùëò+2, ¬∑ ¬∑ ¬∑ , ùëÜùë° +ùëò+ùëö),
where the size of time window is ùëö. In this experiment, we predict a single future value. Namely,
ùëäùëì ùë¢ùë°ùë¢ùëüùëí = (ùëÜùë° +ùëò+1), ùëö = 1. ùëò is set to be 60. A step (distance) can be set between ùëäùëùùëéùë†ùë° and ùëäùëùùëéùë†ùë° +1. If
the start of ùëäùëùùëéùë†ùë° is ùëÜùë° , the start of ùëäùëùùëéùë†ùë° +1 is ùëÜùë° +ùë†ùë°ùëíùëù . We set step to be 1. As illustrated in Figure 10,
for the neural model, we use one LSTM layer and a dense layer to build a basic model. The units of
the LSTM layer can be tuned to get optimized values. The units of the dense layer are set to the
size of ùëäùëì ùë¢ùë°ùë¢ùëüùëí (namely ùëö). The model will predict values in the future time window ÀÜùëäùëì ùë¢ùë°ùë¢ùëüùëí .

Anomaly scores. We adopt prediction errors as anomaly scores. Namely, the model will calculate
and minimize the Mean Squared Error (MSE) between ùëäùëì ùë¢ùë°ùë¢ùëüùëí and ÀÜùëäùëì ùë¢ùë°ùë¢ùëüùëí . At the training phase,
the model learns the characteristics of normal data. At the testing phase, if prediction errors are
above a pre-defined threshold, an anomaly is detected. We use 80% of the dataset to train the model
and 20% to validate the model.
Detection process. The hyperparameters of the neural model include the number of layers, batch
size, epochs, learning rate, the units of each layer (LSTM, Dense layer), etc. It depends on the
learning task and the characteristics of the data. Typically, researchers need to empirically obtain
optimized combinations of hyperparameters. We set the batch size to be 100, the learning rate to be
0.001, and the units of LSTM to be 30. We illustrate the real sensor values and predicted sensor
values in Figure 11. We can see that prediction errors are rather small in the normal period (real

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

050010001500200025003000Time (s)500550600650700750800Water level sensor values (mm)AttackNormal water level22

Yuan Luo, Ya Xiao, et al.

Fig. 9. The input to the LSTM model. We use a ùëäùëùùëéùë†ùë°
time window to predict a ùëäùëì ùë¢ùë°ùë¢ùëüùëí time window. The
distance between two ùëäùëùùëéùë†ùë° time windows is the size
of step.

Fig. 10. The architecture of the LSTM-based
model.

Fig. 11. Real sensor values and predicted sensor val-
ues in a normal period.

Fig. 12. The prediction errors of the false data injec-
tion attack period. Prediction errors are larger than
those in a normal period.

values and predicted values are close). However, we present the prediction errors (the difference
between real values and predicted values) in Figure 12 when there is a false data injection attack
(as illustrated in Figure 8b). We find that prediction errors are larger than those in a normal period.
Specifically, a threshold can be used to decide whether data are normal or anomalous. This threshold
is a hyperparameter and can be adjusted in terms of different purposes. A possible threshold is
marked in the green line in Figure 12. Generally, we aim to achieve a balance between false positives
and false negatives.
Performance evaluation. We evaluate and report the running performance for different layers of
LSTM models. As illustrated in Figure 13, with more training epochs, the training losses decrease
to a certain level. Also, adding more layers slightly reduces the losses. As illustrated in Figure 14,
the 2-layer model seems to have the best performance on unseen data. This indicates that simply
adding more layers may not necessarily improve the performance. Also, the performance of basic
models is not stable. As illustrated in Figure 15, more layers incur longer training time to optimize
the model. Also, the model size increases steadily with more layers as illustrated in Figure 16. In
CPS, given limited computing power, training time and model size need to be considered before
the deployment of DLAD methods.

5.2 CNN-based Autoencoders

Physical devices in CPS not only contain temporal dependencies but also logical dependencies.
For example, the water level of a tank (water level sensor) will impact the states of a pump (thus

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

WpastStSt+1St+k‚Ä¶St+k+1St+k+2St+k+m‚Ä¶WfutureWpast+1StepLSTM layerDense (units = m)Input data:Output data:ùëä"futureWpast025050075010001250150017502000Time (s)0.450.500.550.600.650.700.750.80Water level values (scaled)Real valuesPredicted valuesA possible thresholdAttack periodDeep Learning-Based Anomaly Detection in Cyber-Physical Systems: Progress and Opportunities

23

Fig. 13. The training losses of LSTM-based models
with different LSTM layers.

Fig. 14. The validation losses of LSTM-based models
with different LSTM layers.

Fig. 15. The training time for each epoch.

Fig. 16. Model size

affect the water flow sensor). Namely, there are correlations among different sensors. The running
status of a physical device has its context. To capture such context, CNN-based neural models
are explored to develop DLAD methods. Convolutional operations can represent correlations of
multivariate data [61]. We build CNN-based models in the form of autoencoders. Autoencoders can
learn essential features automatically and reduce the dimension of feature space [13, 40].
The attack used in the experiments. As illustrated in Figure 17, we present another false data
injection attack used in the experiments. This attack causes a longer duration of anomalous high
water level compared to the attack in Figure 8b. Thus, it impacts several sensors such as inflow,
outflow, water level sensors.
Design of CNN-based Autoencoders. The architecture of the CNN model in our experiments is
inspired by the work of Zhang et al. [115]. We elaborate the design from three aspects: (1) Input
data & preprocessing. (2) Neural model architecture. (3) Anomaly scores.

Input data & preprocessing. We first scale the input data to 0 to 1 with a Min-Max scaler. We
design a matrix ùëÄ to represent correlations of sensors. First, we define two time windows ùëäùëñ =
(ùëÜùë°
), which stands for a time window of size ùëò for
ùëñ
sensor ùëñ and ùëó respectively. ùëÜùë°
ùëñ denotes a value of sensor ùëñ at time ùë°. An element ùëö of matrix ùëÄ can

) and ùëäùëó = (ùëÜùë°

, ¬∑ ¬∑ ¬∑ , ùëÜùë° +ùëò

, ¬∑ ¬∑ ¬∑ , ùëÜùë° +ùëò

ùëñ , ùëÜùë° +1
ùëñ

ùëó, ùëÜùë° +1
ùëó

ùëó

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

02468101214Epochs0.00000.00010.00020.00030.00040.00050.00060.00070.0008Mean Squared Error (MSE)1 layer LSTM2 layers LSTM3 layers LSTM4 layers LSTM5 layers LSTM02468101214Epochs0.000.250.500.751.001.251.501.752.00Mean Squared Error (MSE)1e51 layer LSTM2 layers LSTM3 layers LSTM4 layers LSTM5 layers LSTM02468101214Epochs200300400500600700800900Time (seconds)1 layer LSTM2 layers LSTM3 layers LSTM4 layers LSTM5 layers LSTMLSTM_1LSTM_2LSTM_3LSTM_4LSTM_5Model type0100200300400Model size (KB)24

Yuan Luo, Ya Xiao, et al.

Fig. 17. A false data injection attack with a longer duration.

be defined as:

ùëöùë° +ùëò

ùëñ ùëó =

ùëäùëñ ‚àó ùëäùëó
ùëò

,ùëäùëñ ‚àó ùëäùëó =

ùëò
‚àëÔ∏Å

ùëõ=0

ùëÜùë° +ùëõ
ùëñ

ùëÜùë° +ùëõ
ùëó

(1)

Thus we get a matrix ùëÄ ‚àà Rùëô√óùëô at time ùë° + ùëò, where ùëô is the number of sensors. This matrix is the
input to the CNN neural model. We also set a time step ùëá between two matrixes.

Neural model architecture. The CNN-based model takes a matrix ùëÄ as input and tries to reconstruct
the matrix. As illustrated in Figure 18, the dimension of input is 20 ‚àó 20 ‚àó 1, since the number of
sensors is 20. Then, we use three convolutional layers to learn logical dependencies. MaxPooling is
used to reduce the spatial dimension and UpSampling is used to recover the dimension to the size
of the input.

Fig. 18. The architecture of the CNN-based model.

Anomaly scores. Reconstruction errors are utilized as anomaly scores. The Mean Squared Error is
calculated between matrix ùëÄ and the reconstructed matrix ÀÜùëÄ. At the testing phase if reconstruction
errors are above the threshold, anomalies are detected. We also use 80% of the dataset to train and
20% to validate the model.
Detection process. We use reconstruction errors of matrix ùëÄ to detect anomalies. As illustrated
in Figure 19, reconstruction errors are small in a normal period. However, we find that the false
data injection attack causes large errors as shown in Figure 20. Also, we can see the correlations
of sensors through the errors. For example, errors between sensor 8 and 11 are large, but errors
between sensor 8 and 14 are small.
Performance evaluation. We show the training and validation losses in Figures 21 and 22. Gen-
erally, using more CNN layers can reduce the validation errors of the model. In Figure 23, we report
the mean training epoch time of each CNN-based model. We find that CNN-based models can be

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

Attack periodInput (20*20*1)Conv1 32 kernels of 3*3MaxPooling(2*2)Conv2 32 kernels of 3*3UpSampling(2*2)Conv3 1 kernel of 3*3Output (20*20*1)Deep Learning-Based Anomaly Detection in Cyber-Physical Systems: Progress and Opportunities

25

Fig. 19. Reconstruction errors of Matrix ùëÄ in a nor-
mal period.

Fig. 20. Reconstruction errors of Matrix ùëÄ in a false
data injection attack period.

trained much faster than LSTM-based models. As illustrated in Figure 24, adding more layers will
also increase the size of CNN-based models.

Fig. 21. The training losses of CNN-based models
with different CNN layers.

Fig. 22. The validation losses of CNN-based models
with different CNN layers.

Summary of key observations. We summarize key observations from our experiments as

follows.

‚Ä¢ The typical workflow and essential procedure of a DLAD method include: (1) identify anom-
alies that intend to detect, (2) design the input layer, neural model, and anomaly scores, and
(3) define evaluation metrics to measure the performance. In fact, we present our taxonomy
in light of this workflow.

‚Ä¢ Typically, LSTM-based neural networks are capable of modeling the temporal dependency of
time-series sensor data. CNN-based neural networks can capture correlations of multivariate
sensor data.

‚Ä¢ A threshold is usually selected as the boundary of normal and anomalous data.
‚Ä¢ Adding more neural layers may not necessarily improve the performance. Namely, only

making models deep may not help.

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

The anomaly is caused by sensor No. 8 (LIT-301) and impacts multiple sensors. 02468101214Epochs0.0000.0050.0100.0150.0200.025Mean Squared Error (MSE)3 layers CNN4 layers CNN5 layers CNN6 layers CNN7 layers CNN02468101214Epochs0.0000.0010.0020.0030.0040.0050.006Mean Squared Error (MSE)3 layers CNN4 layers CNN5 layers CNN6 layers CNN7 layers CNN26

Yuan Luo, Ya Xiao, et al.

Fig. 23. The training time for one epoch (mean).

Fig. 24. Model size

‚Ä¢ Generally, adding more layers increases training time and model size.
‚Ä¢ Generally, CNN-based models can be trained faster than LSTM-based models.

6 LIMITATIONS OF DEEP LEARNING-BASED ANOMALY DETECTION METHODS

Despite the fast and exciting research advances on deep learning-based anomaly detection, there
are still many opportunities to improve the state-of-the-art solutions. In this section, we summarize
the current technical limitations and discuss the circumstances where DLAD methods may fail in
practice.
The lack of interpretability. We describe the interpretability of anomaly detection methods as
the cause of a detection result that users can understand [49]. Typically, conventional machine
learning methods have rather good interpretability. For example, we can check the decision path
of decision tree-based methods and examine the subset that the input sample belongs to. Current
DLAD methods focus on improving detection performance (e.g., precision and recall). Thus the
interpretability of the model is less discussed and studied [118]. However, the lack of interpretability
may impact the usage of DLAD from the following aspects.

‚Ä¢ Users may not trust the detection result. For tasks such as object detection in the computer
vision domain, the output of deep learning models is intuitive. For example, it is easy for a
human to check whether a cat in an image has been correctly identified. And users can know
whether the model works as expected. However, for an anomaly reported by DLAD methods,
users do not know the decision process of the model and what the anomaly represents is not
clear [37]. Namely, users do not have the "whole picture" as they have in the object detection
task. At least, users have to inspect system status (e.g., check system logs) to find out what
happened (e.g., unknown attacks or false positives). Thus, given a detection result, it is hard
for users to decide under which circumstances it can be trusted and adopted [6].

‚Ä¢ The root cause of the anomaly is not identified. Users utilize DLAD methods to detect anomalies
and protect CPSs. More importantly, users are more concerned with why and where (the
root cause) the result is generated [24]. However, CPSs consist of vast and heterogeneous
components such as communication networks and physical devices. For example, given an
anomalous chemical component level in a water treatment plant, the root cause could be
anomalous water inflow, anomalous water outflow, or a false chemical dosing process. In
particular, root cause analysis helps users to choose appropriate mitigation actions.

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

3 layers CNN4 layers CNN5 layers CNN6 layers CNN7 layers CNNModel type0.00.51.01.52.02.5Epoch time (second)CNN_3CNN_4CNN_5CNN_6CNN_7Model type0100200300400500600Model size (KB)Deep Learning-Based Anomaly Detection in Cyber-Physical Systems: Progress and Opportunities

27

Building and maintaining costs are high. The performance of DLAD methods comes at a price,
which is mainly from two aspects. First, the computing resources of devices in CPS usually cannot
directly run DL models. Dedicated computing devices (e.g., GPUs) are expensive. Second, developers
spend plenty of time on designing and maintaining neural network models. At the designing stage,
researchers have to create corresponding models based on certain CPS architectures and anomalies.
At the training stage, extensive efforts are needed to tune hyperparameters. At the maintaining
stage, the transmission of parameters adds a burden to the communication network of CPSs. We
elaborate the details as follows.

‚Ä¢ Computational costs. Challenges of computing costs are from several aspects. First, the
computing resources of devices in CPS are usually limited. Dedicated devices such as GPUs
are needed to run DL models. Another solution is known as edge computing [103], which is
used to support DL models with resource-constrained devices. Second, CPSs nowadays tend
to generate a large quantity of data (or big data) [12]. This will require huge computational
resources. Third, the scale of DL models also increases [5]. The growing depth and width of
models requests increasing computing power. Finally, an effective DLAD method regularly
updates models [85]. This process demands computations constantly (not a one-time effort).
‚Ä¢ Hyperparameter tuning costs. Hyperparameters include learning rate, batch size, epochs, etc.
Finding appropriate hyperparameters requires not only experience but also an in-depth
understanding of DL models [91]. With current large-scale models, it can be time-consuming
to determine the right hyperparameters.

‚Ä¢ Maintaining costs. Since sensor and traffic data keeps being generated, DLAD models need to
be updated regularly. Maintaining costs come from two aspects. First, users have to set up
a maintaining team (experts in DLAD) to update DLAD models, e.g., retrain and redeploy
models. Second, CPSs are distributed systems, and thus the deployment of models will impact
the communication networks of CPSs.

The lack of high-quality data. As a data-driven technique, DLAD methods require a large
volume and high-quality data. We summarize three challenges in terms of training data in CPS.
First, CPS environments are changing. Physical components are added or removed, and new attacks
may emerge. Second, the type of data (e.g., normal or attack types) is usually not labeled. Finally,
anomalous cases are manually created. The details are as follows.

‚Ä¢ CPS environments keep changing [81]. Physical devices in CPS can be added or removed after
the initial deployment. In this case, DLAD models trained on the old dataset may not learn
the characteristics of the new CPS system dynamics. Also, new attacks are developed to avoid
the detection of DLAD methods. Hence DLAD methods need to be trained on new attack
cases to identify them.

‚Ä¢ The lack of labeled data. Most datasets in CPS are data in a normal period [2]. Challenges
to obtain labeled data include: (1) Labor costs are needed. Developers have to be trained
before they can tag data. For example, they need to reach a consensus on the definition of a
certain type of attack. (2) Lack of anomalies. Attack cases are less than normal data. Also, it
is hard to extract and replay real-world attack cases, e.g., attacks to a smart car system may
cause devastating losses. (3) Data in CPS is of a wide variety. It means normal data exist in
multiple forms, e.g., time series, system logs, and network traffic. Also, it indicates that there
are plenty of attack types. It is difficult to identify and collect all types of attacks.

‚Ä¢ The lack of real-world anomalies or attack cases [76]. As we can see from Table 2, a large
portion of existing studies evaluate their methods on manually created anomalies. To date,
three strategies are utilized to generate anomalous samples. (1) Implementing attack or
fault cases and scenarios. (2) Changing simulation model parameters. (3) Injecting noising

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

28

Yuan Luo, Ya Xiao, et al.

measurements (e.g., Gaussian distributed noise). However, we argue that these synthetic
anomalies either may not happen in the real world or obey a certain statistical distribution,
which, unfortunately, may not represent the characteristics of threats in the real world. Hence,
a well-designed DLAD method may not detect attacks or faults well when deployed on real
CPSs. Moreover, based on different anomaly-creation methods, it is difficult to compare the
performance of different methods even they tend to solve the same problem.

Fig. 25. Different periods of a long-time attack. Period A denotes sudden changes to the original values.
Period B denotes anomalies with no or small changes.

Fail to detect anomalies that exist for a long-time period. We find that DLAD methods are
sensitive to point and contextual anomalies (e.g., sudden changes). But they may fail when there are
collective anomalies (e.g., anomalies exist for a long time). As illustrated in Figure 25, a false data
injection attack manipulated sensor values, which consist of period A and period B. For period A,
DLAD methods can detect these sudden changes. However, for period B, DLAD methods may not
raise prediction or reconstruction errors. Because anomalies exist for a long time, DLAD methods
(especially LSTM-based methods) may treat data before and after period B as normal data since
there is no sudden change. We argue that this is a challenge that future studies need to address.
DLAD methods can be compromised. DLAD methods need data from CPSs to update neural
models. Attackers could inject false data to contaminate DL models or avoid detection. Specifically,
there are two types of attacks: (1) Poisoning attack [111]. Attackers pollute training data to lead
models to produce wrong detection results. (2) Adversarial examples [69]. With subtle perturbations
to normal data, tampered data can avoid the detection of DLAD methods and still damage CPSs.
These attacks can either take black-box or white-box assumptions [44]. The details are as follows.
‚Ä¢ Poisoning attack. Instead of directly attacking CPS, attackers could inject manipulated sensor
or traffic data to attack DL models. Typically, after being deployed, DLAD methods require
data from CPSs to update models. During this process, attackers could deliberately inject
false training samples. So DLAD methods cannot learn the true characteristics of CPS and
deviate from the decision boundary. Thus DLAD models cannot identify anomalies.

‚Ä¢ Adversarial examples. Different from poisoning attacks, adversarial examples do not com-
promise the training process of DLAD models. Instead, adversarial examples add subtle
perturbations to normal data. The purpose is to deceive DLAD models to classify anomalous
data (e.g., manipulated sensor data or control commands) as normal data. Or if attackers want
to disable CPSs, they could trick DLAD methods to generate tremendous false positives (let
DL models classify normal data as anomalies).

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

AABDeep Learning-Based Anomaly Detection in Cyber-Physical Systems: Progress and Opportunities

29

No running performance evaluation. We observe that almost all studies have not evaluated the
running performance of DLAD models. To avoid catastrophic events, CPSs such as smart vehicles
and aerial systems operate in real-time and need to respond to attacks or faults immediately [80].
In this case, response time is an important factor to measure. For example, DLAD methods startup
time and prediction time can be calculated. Furthermore, the computing power of certain CPSs
is limited. Or, the computing resources that left to the DLAD methods are constrained at least.
Typically, RAM on a commodity UAV is about 2 GB. Hence running costs like RAM usage and CPU
overhead can be assessed.
No updating or online learning mechanism. Existing research efforts mainly focus on develop-
ing new models to improve detecting performance (e.g., reducing false positives and false negatives).
However, the deployment of these methods has not been studied yet. Specifically, there is no
updating mechanism of trained models to thwart new attacks. Meanwhile, time-series streaming
data keeps being generated all the time, which can be utilized to enhance the model constantly.
When design one DLAD method, we can consider how to update the model (e.g., updating frequency
and time) and keep learning from new data.
The threshold is empirically selected. As a key part of DLAD methods, the number of layers and
the sliding window size are hyperparameters that researchers have to decide. Such parameters can
be empirically selected to design the network. However, once the network architecture (e.g., layers)
is determined, the anomaly threshold needs to be resolved. Since it is the boundary of anomalies, the
threshold plays an important role in the performance of DLAD models. Currently, the threshold is
empirically set or selected in a brute force way [35]. The value may not be optimized due to various
reasons (e.g., weak validation process, the lack of experience), which could be time-consuming and
error-prone. Also, the threshold is fixed and not adaptive, which may not suitable for new data.

7 TAKEAWAYS & CONCLUSION

In this section, we highlight several future research directions to improve deep anomaly detection
methods. Based on our findings, these opportunities are proposed to solve the limitations of current
DLAD methods.

7.1 Our findings

(1) Most studies do not explicitly present a clear threat model. Although these methods usually
claim to target either attacks or faults, they do not provide types and details of specific threats
that they tend to detect. Also, in different CPSs, prevalent anomalies are usually different.
For example, most studies in the smart grid aim to detect the false data injection attack.
(2) Sensor measurements in time-series form are the most adopted training and testing data
source. First, almost all CPSs contain sensors, hence sensor readings can be easily obtained.
Furthermore, sensor values reflect the working status of CPSs reasonably well. Last, sensor
values can be accumulated in large quantities, which makes them perfect for deep learning-
based methods. Meanwhile, network traffic is the second utilized data source.

(3) RNNs (especially LSTMs) and autoencoders are the most commonly adopted architectures
in DLAD methods (and their variants). RNNs are leveraged to capture temporal relation
contained in univariate and even multivariate data. Autoencoders are employed to conduct
unsupervised learning, which overcomes the absence of labeled data. A mixture of RNN
and autoencoder is also adopted to exploit both advantages. In particular, RNN plus CNN
combined networks are usually utilized to capture both temporal and context relations.
(4) Prediction and reconstruction errors are equally employed to construct the loss function. All
autoencoder-based DLAD methods utilize reconstruction error to build loss functions, which
computes the difference between values reconstructed by the model and origin values. Other

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

30

Yuan Luo, Ya Xiao, et al.

architectures tend to use prediction error, which computes the difference between values
predicted by the model and real values. Prediction labels are typically adopted when labeled
data is sufficient.

(5) Depending on different CPSs, different implementation strategies are selected. For methods
that work on industrial control systems, scale-down yet fully functional testbeds are often
used to collect data. For example, SWaT is a popular water treatment testbed, which contains
sensors, actuators, control PLCs, and network traffic. For the smart grid, simulation is most
frequently used. In fact, the IEEE X-bus system is the de facto evaluation platform. Meanwhile,
for intelligent transportation systems, real-world datasets are applied. Typically, CAN bus
data is entirely obtained from real vehicles. In terms of aerial systems, real-world datasets
are also preferred. Satellite, UAV, ADS-B data are all collected from real devices.

(6) Precision, recall, ùêπ1 are the most used evaluation metrics. In some cases, baseline methods are
also presented to emphasize improvement. Note that these metrics are also commonly used
in conventional statistical and machine-learning based methods. In particular, false positives
and false negatives are balanced through the ùêπ1 score. However, there is no specialized metric
to measure the performance of DLAD methods. For example, training time and updating
frequency are not considered at present. The computing and storage overhead has not been
adequately evaluated.

7.2 Improving deep anomaly detection methods

Determine the anomaly threshold automatically and adaptively. We argue that the threshold
should be decided: (1) Automatically. The conventional threshold tuning process is not efficient
and error-prone. To this end, Su et al. [92] utilize the Extreme Value Theory (EVT) [90] to learn
the threshold automatically. The key idea is to use a generalized Pareto distribution (GPD) to fit
extreme values. Prediction errors of training datasets are used to optimize the threshold. No data
distribution assumption is needed. Another method is to test a series of threshold values at a fixed
interval and check the performance. Intuitively, the value that produces the best result can be
selected. (2) Adaptively. A threshold is decided and fixed when a model is trained on a known
dataset. However, with the development of CPSs, the boundary of anomalies is changing. The
threshold should evolve as new data comes. A naive strategy is to update the model regularly based
on newly collected data. Then, a threshold is generated according to the data. Moreover, online
learning could be adopted to let models learn from recent incremental data. Meanwhile, when each
time the model is updated, a new threshold is calculated to replace the old one.

Benchmarks with sufficient labeled and real-world anomalous data. To date, we have not
found many benchmarks in CPSs that can be used to compare different DLAD methods. Although
there exist some frequently used datasets (e.g., SWaT), different DLAD methods tend to tailor the
dataset and adopt the processed data on their own. We suppose that benchmarks in each CPS
domain (e.g., aerial systems) can help to improve the evaluation process. Different methods may
compare performances on the same benchmark. Specifically, we conclude several requirements for
benchmarks. (1) Cover enough data types. Ideally, sensor, actuator, network, and control system
logs data can be provided. DLAD methods can choose any type of data based on their design goals.
Also, some models tend to work better on specific data types (e.g., sensor time-series data), which
could be produced separately. (2) Include labeled anomalous data. One challenge to evaluate DLAD
methods is the lack of labeled anomalies. Researchers have to design and simulate attack or fault
cases. Standard and rich attack data and cases can improve detection performance and reduce
data-processing efforts. (3) Collect from the real world. Although simulation is widely adopted in
certain domains (e.g., smart grid) due to hardware constraints, real measurements and anomalies
can represent the status of systems better. For example, the sequential order and interval of packets

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

Deep Learning-Based Anomaly Detection in Cyber-Physical Systems: Progress and Opportunities

31

in CAN bus traffic in a smart vehicle can be utilized as factors to decide whether there is an anomaly.
Simulation may not fully contain and represent these important factors.

Enhance the running performance to a real-time level. We observe that many studies [15,
84, 97] in the smart vehicle domain discussed the running performance of DLAD methods. This
is because the response time is critical to avoid devastating accidents in smart cars. To make
DLAD methods more practical, we argue that running performance is important in other CPS
systems as well. Concretely, the design can be improved from two aspects. (1) Accept real-time
input measurements. Instead of using data from offline datasets, DLAD methods could obtain online
real-time measurements and traffic from host systems. The data amount, sampling rate and format
can be decided based on computing resources and network architectures. For example, DLAD
methods that run on edge devices can achieve a high detection speed, which is owing to powerful
computing ability. (2) Take real-time actions. While it is essential to detect anomalies, actions to
prevent catastrophic losses can also be adopted. In some sense, actions should be taken into account
when design and train DLAD models. For example, when designing the loss function, we could
study how to choose appropriate actions in terms of different anomalies.

Locate the anomalous device or root cause. The detection performance (e.g., true positives,
precision) is high in current DLAD methods. However, the location and the root cause of the
anomaly is usually not identified. Users still do not know where an anomaly is from and how
to handle the anomaly even DLAD methods detect anomalous status. Moreover, anomalies in
different parts of CPSs present different impacts. We argue that DLAD methods could improve
the detection granularity to component level. For example, Zhang et al. [115] adopt ConvLSTM to
detect anomalies in each sensor or actuator. Once an anomaly is identified, the compromised device
is also recognized. Then certain actions could be taken to prevent the loss. Further, this process can
be automatically conducted without the intervene of users.

For different CPSs and problems, different compatible neural network architectures
can be adopted. We observe that there exist typical data types and anomalies in different CPSs.
In ICS, sensor time-series measurement data is commonly collected. Gradual sensor and sudden
actuator change anomalies will break time relations in the data. LSTM-based models and variants
are utilized to capture such time relation. Meanwhile, FDI attacks are prevalent in the smart grid.
We find that DLAD methods are used to aid conventional state estimator methods. LSTM and
autoencoder can both be adopted. Moreover, attacks on the CAN bus system in ITS are mostly
seen. Thus LSTM and CNN are used to capture both time relation and context information (e.g.,
packet order and content). In aerial systems, most anomalies are injected. LSTM-based methods are
utilized to capture time relations. We suggest that researchers custom their models based on these
findings.

7.3 Conclusion

In this work, we systematically reviewed the current research efforts on deep learning-based
anomaly detection methods in cyber-physical systems. To this end, we first proposed a taxonomy
to characterize the key properties of DLAD methods. Further, we highlighted prevailing DLAD
methods and research findings based on our taxonomy. We also discussed the limitations and open
problems of current methods. Meanwhile, we conducted experiments to explore the characteristics
of typical neural models, the workflow of DLAD methods, and the running performance of DL
models. We presented deficiencies of DL approaches, our findings, and possible future directions to
improve DLAD methods. We hope that this survey ‚Äì systematizing state-of-the-art deep learning-
based CPS security solutions ‚Äì helps the community prioritize research efforts to address pressing
deployment issues in CPS anomaly detection.

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

32

REFERENCES

Yuan Luo, Ya Xiao, et al.

[1] 2020. NumPy. https://numpy.org/
[2] Chuadhry Mujeeb Ahmed, Gauthama Raman M R, and Aditya P. Mathur. 2020. Challenges in Machine Learning
Based Approaches for Real-Time Anomaly Detection in Industrial Control Systems. In Proceedings of the 6th ACM on
Cyber-Physical System Security Workshop (Taipei, Taiwan) (CPSS ‚Äô20). Association for Computing Machinery, New
York, NY, USA, 23‚Äì29. https://doi.org/10.1145/3384941.3409588

[3] Salman Ahmed, Ya Xiao, Kevin Z. Snow, Gang Tan, Fabian Monrose, and Danfeng (Daphne) Yao. 2020. Methodologies
for Quantifying (Re-)Randomization Security and Timing under JIT-ROP. In Proceedings of the 2020 ACM SIGSAC
Conference on Computer and Communications Security (Virtual Event, USA) (CCS ‚Äô20). Association for Computing
Machinery, New York, NY, USA, 1803‚Äì1820. https://doi.org/10.1145/3372297.3417248

[4] Luai Al Shalabi and Zyad Shaaban. 2006. Normalization as a preprocessing engine for data mining and the approach

of preference matrix. In 2006 International conference on dependability of computer systems. IEEE, 207‚Äì214.

[5] Mario Almeida, Stefanos Laskaridis, Ilias Leontiadis, Stylianos I Venieris, and Nicholas D Lane. 2019. EmBench: Quan-
tifying performance variations of deep neural networks across modern commodity devices. In The 3rd International
Workshop on Deep Learning for Mobile Systems and Applications. 1‚Äì6.

[6] Kasun Amarasinghe and Milos Manic. 2018. Improving user trust on deep neural networks based intrusion detection

systems. In IECON 2018-44th Annual Conference of the IEEE Industrial Electronics Society. IEEE, 3262‚Äì3268.

[7] Car assembly line robot kills worker in Germany. 2020. Retrieved Feb 14, 2020 from https://www.cnn.com/2015/07/

02/europe/germany-volkswagen-robot-kills-worker/index.html

[8] T Athay, R Podmore, and S Virmani. 1979. A practical method for the direct analysis of transient stability. IEEE

Transactions on Power Apparatus and Systems 2 (1979), 573‚Äì584.

[9] Arian B√§r, Alessandro Finamore, Pedro Casas, Lukasz Golab, and Marco Mellia. 2014. Large-scale network traffic
monitoring with DBStream, a system for rolling big data analysis. In 2014 IEEE International Conference on Big Data
(Big Data). IEEE, 165‚Äì170.

[10] Sagnik Basumallik, Rui Ma, and Sara Eftekharnejad. 2019. Packet-data anomaly detection in PMU-based state estimator
using convolutional neural network. International Journal of Electrical Power & Energy Systems 107 (2019), 690‚Äì702.
[11] Debby Bezzina and James Sayer. 2014. Safety pilot model deployment: Test conductor team report. Report No. DOT

HS 812 (2014), 171.

[12] Karl Biron, Wael Bazzaza, Khalid Yaqoob, Amjad Gawanmeh, and Claude Fachkha. 2020. A Big Data Fusion to Profile
CPS Security Threats Against Operational Technology. In 2020 IEEE 21st International Symposium on" A World of
Wireless, Mobile and Multimedia Networks"(WoWMoM). IEEE, 397‚Äì402.

[13] Andrea Borghesi, Andrea Bartolini, Michele Lombardi, Michela Milano, and Luca Benini. 2019. Anomaly detection
using autoencoders in high performance computing systems. In Proceedings of the AAAI Conference on Artificial
Intelligence, Vol. 33. 9428‚Äì9433.

[14] Markus M Breunig, Hans-Peter Kriegel, Raymond T Ng, and J√∂rg Sander. 2000. LOF: identifying density-based local

outliers. In Proceedings of the 2000 ACM SIGMOD international conference on Management of data. 93‚Äì104.

[15] Mikel Canizo, Isaac Triguero, Angel Conde, and Enrique Onieva. 2019. Multi-head CNN‚ÄìRNN for multi-time series

anomaly detection: An industrial case study. Neurocomputing 363 (2019), 246‚Äì260.

[16] Z Berkay Celik, Earlence Fernandes, Eric Pauley, Gang Tan, and Patrick McDaniel. 2019. Program analysis of
commodity IoT applications for security and privacy: Challenges and opportunities. ACM Computing Surveys (CSUR)
52, 4 (2019), 1‚Äì30.

[17] Raghavendra Chalapathy and Sanjay Chawla. 2019. Deep learning for anomaly detection: A survey. arXiv preprint

arXiv:1901.03407 (2019).

[18] Varun Chandola, Arindam Banerjee, and Vipin Kumar. 2009. Anomaly detection: A survey. ACM computing surveys

(CSUR) 41, 3 (2009), 15.

[19] Long Cheng, Ke Tian, and Danfeng Yao. 2017. Orpheus: Enforcing cyber-physical execution semantics to defend
against data-oriented attacks. In Proceedings of the 33rd Annual Computer Security Applications Conference. 315‚Äì326.
[20] Yulia Cherdantseva, Pete Burnap, Andrew Blyth, Peter Eden, Kevin Jones, Hugh Soulsby, and Kristan Stoddart. 2016.
A review of cyber security risk assessment methods for SCADA systems. Computers & security 56 (2016), 1‚Äì27.
[21] Kyong-Tak Cho and Kang G Shin. 2016. Fingerprinting electronic control units for vehicle intrusion detection. In

25th USENIX Security Symposium (USENIX Security 16). 911‚Äì927.

[22] Alysha M De Livera, Rob J Hyndman, and Ralph D Snyder. 2011. Forecasting time series with complex seasonal

patterns using exponential smoothing. J. Amer. Statist. Assoc. 106, 496 (2011), 1513‚Äì1527.

[23] Qingyu Deng and Jian Sun. 2018. False Data Injection Attack Detection in a Power Grid Using RNN. In IECON

2018-44th Annual Conference of the IEEE Industrial Electronics Society. IEEE, 5983‚Äì5988.

[24] Min Du, Feifei Li, Guineng Zheng, and Vivek Srikumar. 2017. Deeplog: Anomaly detection and diagnosis from system
logs through deep learning. In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

Deep Learning-Based Anomaly Detection in Cyber-Physical Systems: Progress and Opportunities

33

Security. 1285‚Äì1298.

[25] Benedikt Eiteneuer, Nemanja Hranisavljevic, and Oliver Niggemann. 2019. Dimensionality Reduction and Anomaly
Detection for CPPS Data using Autoencoder. (Feb. 2019), 1286‚Äì1292. https://doi.org/10.1109/ICIT.2019.8755116 ISSN:
2641-0184.

[26] Mellitus Ezeme, Akramul Azim, and Qusay H Mahmoud. 2017. An imputation-based augmented anomaly detection
from large traces of operating system events. In Proceedings of the Fourth IEEE/ACM International Conference on Big
Data Computing, Applications and Technologies. 43‚Äì52.

[27] Mellitus O Ezeme, Qusay H Mahmoud, and Akramul Azim. 2018. Hierarchical attention-based anomaly detection
model for embedded operating systems. In 2018 IEEE 24th International Conference on Embedded and Real-Time
Computing Systems and Applications (RTCSA). IEEE, 225‚Äì231.

[28] Okwudili M Ezeme, Michael Lescisin, Qusay H Mahmoud, and Akramul Azim. 2019. DeepAnom: An Ensemble Deep
Framework for Anomaly Detection in System Processes. In Canadian Conference on Artificial Intelligence. Springer,
549‚Äì555.

[29] Okwudili M Ezeme, Qusay H Mahmoud, and Akramul Azim. 2019. Dream: deep recursive attentive model for anomaly

detection in kernel events. IEEE Access 7 (2019), 18860‚Äì18870.

[30] Cheng Fan, Fu Xiao, Yang Zhao, and Jiayuan Wang. 2018. Analytical investigation of autoencoder-based methods for

unsupervised anomaly detection in building energy data. Applied energy 211 (2018), 1123‚Äì1135.

[31] Cheng Feng, Tingting Li, and Deeph Chana. 2017. Multi-level anomaly detection in industrial control systems via
package signatures and lstm networks. In 2017 47th Annual IEEE/IFIP International Conference on Dependable Systems
and Networks (DSN). IEEE, 261‚Äì272.

[32] P Ferrari, S Rinaldi, E Sisinni, F Colombo, F Ghelfi, D Maffei, and M Malara. 2019. Performance evaluation of full-cloud
and edge-cloud architectures for Industrial IoT anomaly detection based on deep learning. In 2019 II Workshop on
Metrology for Industry 4.0 and IoT (MetroInd4. 0&IoT). IEEE, 420‚Äì425.

[33] FireEye. 2020. A View Into The Top 20 Cyber Attacks on ICS Networks | FireEye. Retrieved Feb 18, 2020 from https:
//www.fireeye.com/solutions/industrial-systems-and-critical-infrastructure-security/wp-top-20-cyberattacks.html

[34] Flightradar24. [n.d.]. Live Flight Tracker - Real-Time Flight Tracker Map. https://www.flightradar24.com/
[35] Amin Ghafouri, Waseem Abbas, Aron Laszka, Yevgeniy Vorobeychik, and Xenofon Koutsoukos. 2016. Optimal
thresholds for anomaly-based intrusion detection in dynamical environments. In International Conference on Decision
and Game Theory for Security. Springer, 415‚Äì434.

[36] Jairo Giraldo, David Urbina, Alvaro Cardenas, Junia Valente, Mustafa Faisal, Justin Ruths, Nils Ole Tippenhauer,
Henrik Sandberg, and Richard Candell. 2018. A survey of physics-based attack detection in cyber-physical systems.
ACM Computing Surveys (CSUR) 51, 4 (2018), 1‚Äì36.

[37] Ioana Giurgiu and Anika Schumann. 2019. Additive Explanations for Anomalies Detected from Multivariate Temporal
Data. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management. 2245‚Äì2248.
[38] Jonathan Goh, Sridhar Adepu, Khurum Nazir Junejo, and Aditya Mathur. 2016. A dataset to support research in the
design of secure water treatment systems. In International Conference on Critical Information Infrastructures Security.
Springer, 88‚Äì99.

[39] Jonathan Goh, Sridhar Adepu, Marcus Tan, and Zi Shan Lee. 2017. Anomaly detection in cyber physical systems
using recurrent neural networks. In 2017 IEEE 18th International Symposium on High Assurance Systems Engineering
(HASE). IEEE, 140‚Äì145.

[40] Dong Gong, Lingqiao Liu, Vuong Le, Budhaditya Saha, Moussa Reda Mansour, Svetha Venkatesh, and Anton van den
Hengel. 2019. Memorizing normality to detect anomaly: Memory-augmented deep autoencoder for unsupervised
anomaly detection. In Proceedings of the IEEE International Conference on Computer Vision. 1705‚Äì1714.

[41] Lachlan Gunn, Peter Smet, Edward Arbon, and Mark D McDonnell. 2018. Anomaly Detection in Satellite Communica-
tions Systems using LSTM Networks. In 2018 Military Communications and Information Systems Conference (MilCIS).
IEEE, 1‚Äì6.

[42] Edan Habler and Asaf Shabtai. 2018. Using LSTM encoder-decoder algorithm for detecting anomalous ADS-B

messages. Computers & Security 78 (2018), 155‚Äì173.

[43] Waqas Haider, Jiankun Hu, Yi Xie, Xinghuo Yu, and Qianhong Wu. 2017. Detecting anomalous behavior in cloud
servers by nested arc hidden SEMI-Markov model with state summarization. IEEE Transactions on Big Data (2017).
[44] Y. He, G. Meng, K. Chen, X. Hu, and J. He. 2020. Towards Security Threats of Deep Learning Systems: A Survey. IEEE

Transactions on Software Engineering (nov 2020). https://doi.org/10.1109/TSE.2020.3034721

[45] Ryan Heartfield, George Loukas, Sanja Budimir, Anatolij Bezemskij, Johnny RJ Fontaine, Avgoustinos Filippoupolitis,
and Etienne Roesch. 2018. A taxonomy of cyber-physical threats and impact in the smart home. Computers & Security
78 (2018), 398‚Äì428.

[46] Yi Huang, Mohammad Esmalifalak, Huy Nguyen, Rong Zheng, Zhu Han, Husheng Li, and Lingyang Song. 2013. Bad

data injection in smart grid: attack and defense mechanisms. IEEE Communications Magazine 51, 1 (2013), 27‚Äì33.

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

34

Yuan Luo, Ya Xiao, et al.

[47] Kyle Hundman, Valentino Constantinou, Christopher Laporte, Ian Colwell, and Tom Soderstrom. 2018. Detecting
spacecraft anomalies using lstms and nonparametric dynamic thresholding. In Proceedings of the 24th ACM SIGKDD
International Conference on Knowledge Discovery & Data Mining. ACM, 387‚Äì395.

[48] Jun Inoue, Yoriyuki Yamagata, Yuqi Chen, Christopher M Poskitt, and Jun Sun. 2017. Anomaly detection for a
water treatment system using unsupervised machine learning. In 2017 IEEE International Conference on Data Mining
Workshops (ICDMW). IEEE, 1058‚Äì1065.

[49] Aya Abdelsalam Ismail, Mohamed Gunady, Hector Corrada Bravo, and Soheil Feizi. 2020. Benchmarking Deep

Learning Interpretability in Time Series Predictions. Advances in Neural Information Processing Systems 33 (2020).

[50] iTrust Labs. 2019.

iTrust Labs_Dataset Info. Retrieved Dec 09,2019 from https://itrust.sutd.edu.sg/itrust_labs_

datasets/dataset_info/#swat

[51] Camil Jichici, Bogdan Groza, and Pal-Stefan Murvay. 2018. Examining the Use of Neural Networks for Intrusion
Detection in Controller Area Networks. In International Conference on Security for Information Technology and
Communications. Springer, 109‚Äì125.

[52] Kaspersky. 2019. Threat landscape for industrial automation systems, H1 2019.

Retrieved Feb 18, 2020 from

https://ics-cert.kaspersky.com/reports/2019/09/30/threat-\landscape-for-industrial-automation-systems-h1-2019/

[53] Haider Adnan Khan, Nader Sehatbakhsh, Luong N Nguyen, Milos Prvulovic, and Alenka Zajiƒá. 2019. Malware
Detection in Embedded Systems Using Neural Network Model for Electromagnetic Side-Channel Signals. Journal of
Hardware and Systems Security (2019), 1‚Äì14.

[54] Eshaan Khanapuri, Tarun Chintalapati, Rajnikant Sharma, and Ryan Gerdes. 2019. Learning-based adversarial agent
detection and identification in cyber physical systems applied to autonomous vehicular platoon. In 2019 IEEE/ACM
5th International Workshop on Software Engineering for Smart Cyber-Physical Systems (SEsCPS). IEEE, 39‚Äì45.
[55] Tung Kieu, Bin Yang, and Christian S Jensen. 2018. Outlier detection for multidimensional time series using deep
neural networks. In 2018 19th IEEE International Conference on Mobile Data Management (MDM). IEEE, 125‚Äì134.

[56] Diederik P Kingma and Max Welling. 2013. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114 (2013).
[57] Oliver Kosut, Liyan Jia, Robert J Thomas, and Lang Tong. 2011. Malicious data attacks on the smart grid. IEEE

Transactions on Smart Grid 2, 4 (2011), 645‚Äì658.

[58] Moshe Kravchik and Asaf Shabtai. 2018. Detecting cyber attacks in industrial control systems using convolutional
neural networks. In Proceedings of the 2018 Workshop on Cyber-Physical Systems Security and PrivaCy. ACM, 72‚Äì83.
[59] Adrien Legrand, Brad Niepceron, Alain Cournier, and Harold Trannois. 2018. Study of Autoencoder Neural Networks
for Anomaly Detection in Connected Buildings. In 2018 IEEE Global Conference on Internet of Things (GCIoT). IEEE,
1‚Äì5.

[60] Dan Li, Dacheng Chen, Baihong Jin, Lei Shi, Jonathan Goh, and See-Kiong Ng. 2019. MAD-GAN: Multivariate
anomaly detection for time series data with generative adversarial networks. In International Conference on Artificial
Neural Networks. Springer, 703‚Äì716.

[61] Yidong Li, Li Zhang, Zhuo Lv, and Wei Wang. 2020. Detecting Anomalies in Intelligent Vehicle Charging and Station
Power Supply Systems With Multi-Head Attention Models. IEEE Transactions on Intelligent Transportation Systems
(2020).

[62] Zhe Li, Jingyue Li, Yi Wang, and Kesheng Wang. 2019. A deep learning approach for anomaly detection based on SAE
and LSTM in mechanical equipment. The International Journal of Advanced Manufacturing Technology (2019), 1‚Äì12.
[63] Benjamin Lindemann, Fabian Fesenmayr, Nasser Jazdi, and Michael Weyrich. 2019. Anomaly detection in discrete

manufacturing using self-learning approaches. Procedia CIRP 79 (2019), 313‚Äì318.

[64] Yao Liu, Peng Ning, and Michael K Reiter. 2011. False data injection attacks against state estimation in electric power

grids. ACM Transactions on Information and System Security (TISSEC) 14, 1 (2011), 13.

[65] Yuriy Zacchia Lun, Alessandro D‚ÄôInnocenzo, Francesco Smarra, Ivano Malavolta, and Maria Domenica Di Benedetto.
2019. State of the art of cyber-physical systems security: An automatic control perspective. Journal of Systems and
Software 149 (2019), 174‚Äì216.

[66] Larry M Manevitz and Malik Yousef. 2001. One-class SVMs for document classification. Journal of machine Learning

research 2, Dec (2001), 139‚Äì154.

[67] Aditya P Mathur and Nils Ole Tippenhauer. 2016. SWaT: a water treatment testbed for research and training on
ICS security. In 2016 International Workshop on Cyber-physical Systems for Smart Water Networks (CySWater). IEEE,
31‚Äì36.

[68] MATPOWER. 2019. Open-source tools for electric power system simulation and optimization. Retrieved Nov 15,

2019 from https://matpower.org/

[69] Dongyu Meng and Hao Chen. 2017. Magnet: a two-pronged defense against adversarial examples. In Proceedings of

the 2017 ACM SIGSAC conference on computer and communications security. 135‚Äì147.

[70] Robert Mitchell and Ing-Ray Chen. 2014. A survey of intrusion detection techniques for cyber-physical systems.

ACM Computing Surveys (CSUR) 46, 4 (2014), 1‚Äì29.

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

Deep Learning-Based Anomaly Detection in Cyber-Physical Systems: Progress and Opportunities

35

[71] Yilin Mo and Bruno Sinopoli. 2010. False data injection attacks in control systems. In Preprints of the 1st workshop on

Secure Control Systems. 1‚Äì6.

[72] Yilin Mo and Bruno Sinopoli. 2012. Integrity attacks on cyber-physical systems. In Proceedings of the 1st international

conference on High Confidence Networked Systems. 47‚Äì54.

[73] Mehdi Mohammadi, Ala Al-Fuqaha, Sameh Sorour, and Mohsen Guizani. 2018. Deep learning for IoT big data and

streaming analytics: A survey. IEEE Communications Surveys & Tutorials 20, 4 (2018), 2923‚Äì2960.

[74] Khosrow Moslehi and Ranjit Kumar. 2010. A Reliability Perspective of the Smart Grid. IEEE Transactions on Smart

Grid 1, 1 (2010), 57‚Äì64.

[75] Anvardh Nanduri and Lance Sherry. 2016. Anomaly detection in aircraft data using Recurrent Neural Networks

(RNN). In 2016 Integrated Communications Navigation and Surveillance (ICNS). IEEE, 5C2‚Äì1.

[76] Sandeep Nair Narayanan, Anupam Joshi, and Ranjan Bose. 2020. ABATe: Automatic Behavioral AbstractionTechnique
to Detect Anomalies in SmartCyber-Physical Systems. IEEE Transactions on Dependable and Secure Computing (2020).
[77] Sajid Nazir, Shushma Patel, and Dilip Patel. 2017. Assessing and augmenting SCADA cyber security: A survey of

techniques. Computers & Security 70 (2017), 436‚Äì454.

[78] Xiangyu Niu, Jiangnan Li, Jinyuan Sun, and Kevin Tomsovic. 2019. Dynamic detection of false data injection attack
in smart grid using deep learning. In 2019 IEEE Power & Energy Society Innovative Smart Grid Technologies Conference
(ISGT). IEEE, 1‚Äì6.

[79] Daehyung Park, Yuuna Hoshi, and Charles C Kemp. 2018. A multimodal anomaly detector for robot-assisted feeding

using an lstm-based variational autoencoder. IEEE Robotics and Automation Letters 3, 3 (2018), 1544‚Äì1551.

[80] Neehar Peri, Pirazh Khorramshahi, Sai Saketh Rambhatla, Vineet Shenoy, Saumya Rawat, Jun-Cheng Chen, and
Rama Chellappa. 2020. Towards real-time systems for vehicle re-identification, multi-camera tracking, and anomaly
detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops. 622‚Äì623.
[81] Eric Ras, Fridolin Wild, Christoph Stahl, and Alexandre Baudet. 2017. Bridging the skills gap of workers in Industry
4.0 by human performance augmentation tools: Challenges and roadmap. In Proceedings of the 10th International
Conference on PErvasive Technologies Related to Assistive Environments. 428‚Äì432.

[82] Orbis Research. 2020. Global Cyber Physical System Market 2020 by Company, Regions, Type and Application,
Forecast to 2025 | Orbis Research. Retrieved Feb 17, 2020 from https://www.orbisresearch.com/reports/index/global-
cyber-physical-system-market-2020-by-company-regions-type-and-application-forecast-to-2025

[83] Danilo Jimenez Rezende and Shakir Mohamed. 2015. Variational inference with normalizing flows. arXiv preprint

arXiv:1505.05770 (2015).

[84] Michele Russo, Maxime Labonne, Alexis Olivereau, and Mohammad Rmayti. 2018. Anomaly Detection in Vehicle-to-

Infrastructure Communications. In 2018 IEEE 87th Vehicular Technology Conference (VTC Spring). IEEE, 1‚Äì6.

[85] Ahmed Salem, Apratim Bhattacharya, Michael Backes, Mario Fritz, and Yang Zhang. 2020. Updates-leak: Data set
inference and reconstruction attacks in online learning. In 29th {USENIX} Security Symposium ({USENIX} Security
20). 1291‚Äì1308.

[86] Mahmoud Salem, Mark Crowley, and Sebastian Fischmeister. 2016. Anomaly detection using inter-arrival curves for

real-time systems. In 2016 28th Euromicro Conference on Real-Time Systems (ECRTS). IEEE, 97‚Äì106.

[87] J√ºrgen Schmidhuber. 2015. Deep learning in neural networks: An overview. Neural networks 61 (2015), 85‚Äì117.
[88] Peter Schneider and Konstantin B√∂ttinger. 2018. High-Performance Unsupervised Anomaly Detection for Cyber-
Physical System Networks. In Proceedings of the 2018 Workshop on Cyber-Physical Systems Security and PrivaCy. ACM,
1‚Äì12.

[89] Xiaokui Shu, Danfeng Yao, and Naren Ramakrishnan. 2015. Unearthing stealthy program attacks buried in extremely
long execution paths. In Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security.
401‚Äì413.

[90] Alban Siffer, Pierre-Alain Fouque, Alexandre Termier, and Christine Largouet. 2017. Anomaly detection in streams
with extreme value theory. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery
and Data Mining. ACM, 1067‚Äì1075.

[91] Prabhu Teja Sivaprasad, Florian Mai, Thijs Vogels, Martin Jaggi, and Francois Fleuret. 2020. Optimizer benchmarking

needs to account for hyperparameter tuning. In International Conference on Machine Learning. PMLR, 9036‚Äì9045.

[92] Ya Su, Youjian Zhao, Chenhao Niu, Rong Liu, Wei Sun, and Dan Pei. 2019. Robust Anomaly Detection for Multivariate
Time Series through Stochastic Recurrent Neural Network. In Proceedings of the 25th ACM SIGKDD International
Conference on Knowledge Discovery & Data Mining. ACM, 2828‚Äì2837.

[93] Shahroz Tariq, Sangyup Lee, Youjin Shin, Myeong Shin Lee, Okchul Jung, Daewon Chung, and Simon S Woo.
2019. Detecting Anomalies in Space using Multivariate Convolutional LSTM with Mixtures of Probabilistic PCA.
In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. ACM,
2123‚Äì2133.

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

36

Yuan Luo, Ya Xiao, et al.

[94] Norman L Tasfi, Wilson A Higashino, Katarina Grolinger, and Miriam AM Capretz. 2017. Deep neural networks
with confidence sampling for electrical anomaly detection. In 2017 IEEE International Conference on Internet of Things
(iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing
(CPSCom) and IEEE Smart Data (SmartData). IEEE, 1038‚Äì1045.

[95] Adrian Taylor, Sylvain Leblanc, and Nathalie Japkowicz. 2016. Anomaly detection in automobile control network
data with long short-term memory networks. In 2016 IEEE International Conference on Data Science and Advanced
Analytics (DSAA). IEEE, 130‚Äì139.

[96] Keras Team. [n.d.]. Keras documentation: About Keras. https://keras.io/about/ Library Catalog: keras.io.
[97] Franco van Wyk, Yiyang Wang, Anahita Khojandi, and Neda Masoud. 2019. Real-Time Sensor Anomaly Detection

and Identification in Automated Vehicles. IEEE Transactions on Intelligent Transportation Systems (2019).

[98] Eric Veith, Lars Fischer, Martin Tr√∂schel, and Astrid Nie√üe. 2019. Analyzing Cyber-Physical Systems from the

Perspective of Artificial Intelligence. arXiv preprint arXiv:1908.11779 (2019).

[99] Bolun Wang, Yuanshun Yao, Bimal Viswanath, Haitao Zheng, and Ben Y Zhao. 2018. With great training comes great
vulnerability: Practical attacks against transfer learning. In 27th {USENIX} Security Symposium ({USENIX} Security
18). 1281‚Äì1297.

[100] Huaizhi Wang, Jiaqi Ruan, Zhengwei Ma, Bin Zhou, Xueqian Fu, and Guangzhong Cao. 2019. Deep learning aided

interval state prediction for improving cyber security in energy internet. Energy 174 (2019), 1292‚Äì1304.

[101] Jingyu Wang, Dongyuan Shi, Yinhong Li, Jinfu Chen, Hongfa Ding, and Xianzhong Duan. 2018. Distributed framework
for detecting PMU data manipulation attacks with deep autoencoders. IEEE Transactions on Smart Grid (2018).
[102] Wenye Wang and Zhuo Lu. 2013. Cyber security in the smart grid: Survey and challenges. Computer networks 57, 5

(2013), 1344‚Äì1371.

[103] Xiaofei Wang, Yiwen Han, Chenyang Wang, Qiyang Zhao, Xu Chen, and Min Chen. 2019. In-edge ai: Intelligentizing

mobile edge computing, caching and communication by federated learning. IEEE Network 33, 5 (2019), 156‚Äì165.

[104] Yawei Wang, Donghui Chen, Cheng Zhang, Xi Chen, Baogui Huang, and Xiuzhen Cheng. 2019. Wide and Recurrent
Neural Networks for Detection of False Data Injection in Smart Grids. In International Conference on Wireless
Algorithms, Systems, and Applications. Springer, 335‚Äì345.

[105] Wikipedia. 2020. December 2015 Ukraine power grid cyberattack. Retrieved Feb 03, 2020 from https://en.wikipedia.

org/w/index.php?title=December_2015_Ukraine_power_grid_cyberattack&oldid=920905638

[106] Wikipedia. 2020. List of self-driving car fatalities. Retrieved Feb 03, 2020 from https://en.wikipedia.org/w/index.

php?title=List_of_self-driving_car_fatalities&oldid$=$928100815

[107] Wikipedia. 2020. Stuxnet. Retrieved Feb 14, 2020 from https://en.wikipedia.org/w/index.php?\title=Stuxnet&oldid=

939556423

[108] Zhenyu Wu, Yang Guo, Wenfang Lin, Shuyang Yu, and Yang Ji. 2018. A weighted deep representation learning model

for imbalanced fault diagnosis in cyber-physical systems. Sensors 18, 4 (2018), 1096.

[109] Yu-jun Xiao, Wen-yuan Xu, Zhen-hua Jia, Zhuo-ran Ma, and Dong-lian Qi. 2017. NIPAD: a non-invasive power-based
anomaly detection scheme for programmable logic controllers. Frontiers of Information Technology & Electronic
Engineering 18, 4 (2017), 519‚Äì534.

[110] Le Xie, Yilin Mo, and Bruno Sinopoli. 2010. False data injection attacks in electricity markets. In 2010 First IEEE

International Conference on Smart Grid Communications. IEEE, 226‚Äì231.

[111] Guowen Xu, Hongwei Li, Hao Ren, Kan Yang, and Robert H Deng. 2019. Data security issues in deep learning: attacks,

countermeasures, and opportunities. IEEE Communications Magazine 57, 11 (2019), 116‚Äì122.

[112] Kui Xu, Ke Tian, Danfeng Yao, and Barbara G Ryder. 2016. A sharper sense of self: Probabilistic reasoning of program
behaviors for anomaly detection with context sensitivity. In 2016 46th Annual IEEE/IFIP International Conference on
Dependable Systems and Networks (DSN). IEEE, 467‚Äì478.

[113] Danfeng Yao, Xiaokui Shu, Long Cheng, and Salvatore J Stolfo. 2017. Anomaly detection as a service: challenges,
advances, and opportunities. Synthesis Lectures on Information Security, Privacy, and Trust 9, 3 (2017), 1‚Äì173.
[114] Houssam Zenati, Chuan Sheng Foo, Bruno Lecouat, Gaurav Manek, and Vijay Ramaseshan Chandrasekhar. 2018.

Efficient gan-based anomaly detection. arXiv preprint arXiv:1802.06222 (2018).

[115] Chuxu Zhang, Dongjin Song, Yuncong Chen, Xinyang Feng, Cristian Lumezanu, Wei Cheng, Jingchao Ni, Bo Zong,
Haifeng Chen, and Nitesh V Chawla. 2019. A deep neural network for unsupervised anomaly detection and diagnosis
in multivariate time series data. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 1409‚Äì1416.
[116] Hao Zhang, Danfeng Daphne Yao, Naren Ramakrishnan, and Zhibin Zhang. 2016. Causality reasoning about network

events for detecting stealthy malware activities. computers & security 58 (2016), 180‚Äì198.

[117] Mu Zhang, Chien-Ying Chen, Bin-Chou Kao, Yassine Qamsane, Yuru Shao, Yikai Lin, Elaine Shi, Sibin Mohan, Kira
Barton, James Moyne, et al. 2019. Towards Automated Safety Vetting of PLC Code in Real-World Plants. In 2019 IEEE
Symposium on Security and Privacy (SP). IEEE, 522‚Äì538.

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

Deep Learning-Based Anomaly Detection in Cyber-Physical Systems: Progress and Opportunities

37

[118] Xinyang Zhang, Ningfei Wang, Hua Shen, Shouling Ji, Xiapu Luo, and Ting Wang. 2020. Interpretable deep learning

under fire. In 29th {USENIX} Security Symposium ({USENIX} Security 20).

[119] Y Zhang, VVG Krishnan, J Pi, K Kaur, A Srivastava, A Hahn, and S Suresh. 2019. Cyber physical security analytics for

transactive energy systems. IEEE Transactions on Smart Grid (2019).

[120] Konglin Zhu, Zhicheng Chen, Yuyang Peng, and Lin Zhang. 2019. Mobile Edge Assisted Literal Multi-Dimensional
Anomaly Detection of In-Vehicle Network Using LSTM. IEEE Transactions on Vehicular Technology 68, 5 (2019),
4275‚Äì4284.

[121] Zahra Zohrevand, Uwe Gl√§sser, Mohammad A Tayebi, Hamed Yaghoubi Shahir, Mehdi Shirmaleki, and Amir Yaghoubi
Shahir. 2017. Deep learning based forecasting of critical infrastructure data. In Proceedings of the 2017 ACM on
Conference on Information and Knowledge Management. ACM, 1129‚Äì1138.

[122] Bo Zong, Qi Song, Martin Renqiang Min, Wei Cheng, Cristian Lumezanu, Daeki Cho, and Haifeng Chen. 2018. Deep

autoencoding gaussian mixture model for unsupervised anomaly detection. (2018).

ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: January 2021.

