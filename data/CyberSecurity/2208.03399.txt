ACCEPTED AND TO APPEAR IN IEEE GLOBECOM 2022

1

LCCDE: A Decision-Based Ensemble Framework
for Intrusion Detection in The Internet of Vehicles
Li Yang∗, Abdallah Shami∗, Gary Stevens†, and Stephen de Rusett†
∗Western University, London, Ontario, Canada; e-mails: {lyang339, abdallah.shami}@uwo.ca
†S2E Technologies, St. Jacobs, Ontario, Canada; e-mails: {gstevens, sderusett}@s2etech.com

2
2
0
2

p
e
S
1

]

R
C
.
s
c
[

2
v
9
9
3
3
0
.
8
0
2
2
:
v
i
X
r
a

Abstract—Modern vehicles,

including autonomous vehicles
and connected vehicles, have adopted an increasing variety of
functionalities through connections and communications with
other vehicles, smart devices, and infrastructures. However,
the growing connectivity of the Internet of Vehicles (IoV) also
increases the vulnerabilities to network attacks. To protect IoV
systems against cyber threats, Intrusion Detection Systems (IDSs)
that can identify malicious cyber-attacks have been developed
using Machine Learning (ML) approaches. To accurately detect
various types of attacks in IoV networks, we propose a novel
ensemble IDS framework named Leader Class and Conﬁdence
Decision Ensemble (LCCDE). It is constructed by determining
the best-performing ML model among three advanced ML
algorithms (XGBoost, LightGBM, and CatBoost) for every class
or type of attack. The class leader models with their prediction
conﬁdence values are then utilized to make accurate decisions
regarding the detection of various types of cyber-attacks. Ex-
periments on two public IoV security datasets (Car-Hacking
and CICIDS2017 datasets) demonstrate the effectiveness of the
proposed LCCDE for intrusion detection on both intra-vehicle
and external networks.

Index Terms—Intrusion Detection System, Internet of Vehicles,

CAN Bus, LightGBM, XGBoost, Ensemble Learning

I. INTRODUCTION

With the fast development of the Internet of Things (IoT)
and the Internet of Vehicles (IoV) technologies, network-
controlled automobiles, such as Autonomous Vehicles (AVs)
and Connected Vehicles (CVs), have begun replacing con-
ventional vehicles [1]. IoV systems typically consist of intra-
vehicle networks (IVNs) and external networks. In IVNs, the
Controller Area Network (CAN) bus is the core infrastructure
enabling communication between Electronic Control Units
(ECUs) to implement various functionalities [2]. External
vehicular networks, on the other hand, utilizes Vehicle-To-
Everything (V2X) technology to enable the connection be-
tween smart cars and other IoV entities, such as roadside units,
infrastructures, and smart devices [3].

Due to the expanded network attack surfaces of IoV sys-
tems,
the growing connectivity of vehicular networks has
resulted in numerous security threats [4]. In addition, there
are not authentication or encryption mechanisms involved in
the processing of CAN packets owing to their short length [5].
In the absence of basic security mechanisms, cybercriminals
are able to insert malicious messages into IVNs and execute a
variety of attacks, such as Denial of Service (DoS), fuzzy, and
spooﬁng attacks [4]. On the other hand, the emergence of con-
nectivity between connected cars and external networks has

Fig. 1. The IDS-protected vehicle architecture.

made these vehicles vulnerable to a number of conventional
cyber-attacks.

Figure 1 depicts the IoV attack scenarios, including IVN
and external network attacks. Intrusion Detection Systems
(IDSs) have been developed as promising solutions for de-
tecting intrusions and defending Internet of Vehicles (IoV)
systems and smart automobiles from cyber-attacks [6]. The
potential deployment of IDSs in IoV systems is also shown
in Fig. 1. To protect IVNs, IDSs can be placed on top of
the CAN-bus to identify malicious CAN messages [5]. IDSs
can also be incorporated into the gateways to detect malicious
packets coming from external networks [1].

Due to the advancement of Machine Learning (ML) meth-
ods, ML-driven IDSs in IoV applications have recently drawn
the interest of researchers and automotive manufacturers [7].
Through network trafﬁc data analytics, ML approaches are
commonly employed to construct classiﬁer-based IDSs that
can differentiate between benign network events and various
cyber-attacks [8] [9].

To apply ML models to IDS systems, it is common to ob-
serve that the prediction performance of different ML models
varies signiﬁcantly for different types of cyber-attack detec-
tion. Thus, a novel ensemble approach named Leader Class
and Conﬁdence Decision Ensemble (LCCDE)1 is proposed in
this paper to obtain optimal performance on all types of attack
detection by integrating three advanced gradient-boosting ML
algorithms, including Extreme Gradient Boosting (XGBoost)
[10], Light Gradient Boosting Machine (LightGBM) [11],

1code

is

available

at: https://github.com/Western-OC2-Lab/Intrusion-

Detection-System-Using-Machine-Learning

 
 
 
 
 
 
ACCEPTED AND TO APPEAR IN IEEE GLOBECOM 2022

2

and Categorical Boosting (CatBoost) [12]. LCCDE aims to
achieve optimal model performance by identifying the best-
performing base ML model with the highest prediction con-
ﬁdence for each class.

This paper mainly makes the following contributions:
1) It proposes a novel ensemble framework, named LC-
CDE, for effective intrusion detection in IoVs using
class leader and conﬁdence decision strategies, as well
as gradient-boosting ML algorithms.

2) It evaluates the proposed framework using two pub-
lic IoV security datasets, Car-Hacking [13] and CI-
CIDS2017 [14] datasets, representing IVN and external
network data, respectively.

3) It compares the performance of the proposed model with

other state-of-the-art methods.

The remainder of the paper is organized as follows. Section
II introduces the related work about IoV intrusion detection
using ML and ensemble models. Section III presents the
proposed LCCDE framework in detail. Section IV presents
and discusses the experimental results. Finally, Section V
concludes the paper.

II. RELATED WORK

The recent surge in the number of intelligent cars has led
to an increase in the development of ML models as effective
solutions for IoV intrusion detection and security enhancement
[15]. Song et al. [16] proposed a deep convolutional neural
network model framework for intrusion detection in in-vehicle
networks. It shows high performance on the Car-Hacking
dataset. Zhao et al. [17] proposed an IDS framework for IoT
systems based on lightweight deep neural network models.
It also uses Principal Component Analysis (PCA) to reduce
feature dimensionality and computational cost.

Several existing works have focused on IDS development
using ensemble techniques. Yang et al. [18] proposed a
stacking ensemble framework for network intrusion detection
in IoV systems using tree-based ML models. The stacking
ensemble model shows high accuracy on the CAN-Intrusion
and CICIDS2017 datasets. Elmasry et al. [19] proposed an
ensemble model for network intrusion detection using three
deep learning models: Deep Neural Networks (DNN), Long
Short-Term Memory (LSTM), and Deep Belief Networks
(DBN). Chen et al. [20] proposed a novel ensemble IDS
framework, named All Predict Wisest Decides (APWD), to
detect intrusions and make decisions based on the wisest
model for each class. However, it only achieves an accuracy
of 79.7% on the NSL-KDD dataset.

Although many of the related works achieve high per-
formance in intrusion detection tasks of IoV systems, there
is still much room for performance improvement. Existing
IDS frameworks can be improved with the use of more
advanced ML algorithms and ensemble strategies. To the best
of our knowledge, our proposed LCCDE framework is the
ﬁrst technique that leverages both leader class and prediction
conﬁdence strategies to construct ensemble IDSs. The use of
three advanced gradient-boosting algorithms also improves the
effectiveness of intrusion detection.

III. PROPOSED FRAMEWORK

A. System Overview

The purpose of this work is to develop an ensemble
IDS framework that can effectively detect various types of
attacks on both IVN and external vehicular networks. Figure
2 demonstrates the overall framework of the proposed system,
consisting of two phases: model training and model prediction.
At the model training stage, three advanced ML algorithms,
XGBoost [10], LightGBM [11], and CatBoost [12], are trained
on the IoV trafﬁc dataset to obtain the leader models for all
classes/types of attacks. At the model prediction stage, the
class leader models and their prediction conﬁdences are used
to accurately detect attacks. The algorithm details are provided
in this section.

B. Base Machine Learning Models

A decision tree (DT) is a basic ML algorithm that uses
a tree structure to make decisions based on the divide and
conquer technique [18]. In DTs, the decision nodes represent
the decision tests, while the leaves indicate the result classes.
Gradient Boosting Decision Tree (GBDT) is an iterative DT
algorithm that constructs multiple DTs and aggregates their
prediction outputs. To improve the performance of basic GB-
DTs, three advanced gradient-boosting algorithms, XGBoost
[10], LightGBM [11], and CatBoost [12], have been developed
and widely used in many applications. These three gradient-
boosting algorithms are used in the proposed system to build
the LCCDE ensemble framework.

XGBoost

is a popular gradient-boosting DT algorithm
designed for the speed and performance improvement of
GBDTs [10]. XGBoost uses a regularization term and a
Second-Order Taylor Approximation for the summation of
the squared errors to minimize the loss function and reduce
over-ﬁtting. XGBoost has a low computational complexity of
O(Kd(cid:107)x(cid:107) log n), where K is the number of trees, d is the
maximum tree depth, (cid:107)x(cid:107) is the number and non-missing
samples, and n is the data size [10]. Additionally, XGBoost
support parallel execution to save model learning time.

LightGBM is a fast and robust ensemble ML model con-
structed by multiple DTs [11]. LightGBM’s key advantage
over other ML methods is its capacity to efﬁciently handle
large-scale and high-dimensional data. Gradient-based One-
Side Sampling (GOSS) and Exclusive Feature Bundling (EFB)
are the two core strategies of LightGBM [11]. GOSS is a
down-sampling method that only preserves data samples with
large gradients and randomly discards small gradient samples
to accelerate model training and reduce memory consumption.
EFB is a feature engineering method that regroups mutually
exclusive features into bundles as single features to mini-
mize feature size and improve model training efﬁciency. By
employing GOSS and EFB, the data size can be reduced
signiﬁcantly without the loss of critical information. The time
and space complexity of LightGBM has also been reduced
to O(N (cid:48)F (cid:48)), where N (cid:48) is the reduced number of samples
after using GOSS, F (cid:48) is the bundled number of features after
employing EFB [21].

ACCEPTED AND TO APPEAR IN IEEE GLOBECOM 2022

3

Fig. 2. The framework of the proposed LCCDE model.

CatBoost is another advanced gradient-boosting algorithm
designed to process categorical features more effectively [12].
CatBoost, in comparison to existing gradient-boosting models,
includes three signiﬁcant model enhancement components:
symmetric trees, ordered boosting, and native feature support.
In symmetric trees, leaves are split under the same condition
as in prior trees, and the pair of feature splits with the
lowest loss is applied to all nodes. Using symmetric trees can
improve model prediction speed and reduce over-ﬁtting. Or-
dered boosting is a permutation-driven technique that prevents
overﬁtting on small datasets by training a model on a subset
while calculating residuals on another subset. CatBoost’s
native feature support indicates that it can directly process all
types of features, such as numerical, textual, and categorical
features, without the need for extra pre-processing. CatBoost
is an ensemble model with low computational complexity of
O(SN ), where S is the number of permutations of the subsets
and N is the number of base DT models [12].

The primary reasons for selecting XGBoost, LightGBM,

and CatBoost as base learners are as follows [10] - [12]:

1) These three ML models are all robust ensemble models
that have had great success in a variety of data analytics
applications [22].

2) These three ML models can automatically generate

feature importance scores and select features during
their training process, which saves time and resources
by avoiding the need for extra feature engineering.
3) These three ML models are fast models with relatively
low computational complexity. Additionally,
they all
support parallelization and Graphics Processing Unit
(GPU) execution, which can further improve model
learning speed.

4) These three ML models include randomness in their
model construction process, enabling people to develop
a robust ensemble model with high diversity and gen-
eralizability.

C. LCCDE: Proposed Ensemble Algorithm

The performance of different ML models often varies on
different types of attack detection tasks. For example, when
applying multiple ML models on the same network trafﬁc
dataset, a ML model perform the best for detecting the ﬁrst
type of attack (e.g., DoS attacks), while another ML model
may outperform other models for detecting the second type
of attack (e.g., snifﬁng attacks). Therefore, this work aims
to propose an ensemble framework that can achieve optimal
model performance for the detection of every type of attack.
Ensemble learning is a technique that combines multiple base

ACCEPTED AND TO APPEAR IN IEEE GLOBECOM 2022

4

Algorithm 1: Leader Class and Conﬁdence Decision Ensemble (LCCDE) -
Model Training

Algorithm 2: Leader Class and Conﬁdence Decision Ensemble (LCCDE) -
Model Prediction

Input:

Dtrain: the training set,
M = {M1, M2, M3}: the base ML model list, including M1 =

LightGBM, M2 = XGBoost, M3 = CatBoost,

c = 1, 2, . . . , n: the class list for n different classes.

Output:

M = {M1, M2, M3}: the trained base model list,
LM = {LM1, LM2, . . . , LMn}: the leader model list for all classes.

1 M1 ← T raining(M1, Dtrain);
2 M2 ← T raining(M2, Dtrain);
3 M3 ← T raining(M3, Dtrain);
4

// Train the LightGBM model
// Train the XGBoost model
// Train the CatBoost model
// For each class (normal or a type of attack), ﬁnd

for c = 1, 2, . . . , n do

the leader model

5

6

7

8

9

M listc ← BestP erf orming(M1, M2, M3, c);

// Find the

best-performing model for each class (e.g., has the highest F1-score)
if Len(M listc) == 1 then // If only one model has the highest F1
// Save this model as the leader model for

LMc ← M listc[0];

the class c

else

// If multiple ML models have the same highest F1-score
LMc ← M ostEf f icient(M listc); // Save the fastest or most

efﬁcient model as the leader model for the class c

end
LM ← LM ∪ {LMc};

10

11
12 end

// Collect the leader model for each class

ML models to improve learning performance and generaliz-
ability [3]. The proposed ensemble model is constructed using
XGBoost, LightGBM, and CatBoost, three advanced gradient-
boosting ML methods introduced in Section III-B.

Figure 2 demonstrates the process of the proposed LCCDE
framework in two phases: model training and model predic-
tion. The detailed procedures of the training and prediction
phases are also described in Algorithms 1 & 2, respectively.
At the training stage, the LCCDE framework aims to obtain
leader models for all classes via the following steps:

1) Train three base learners. The three base ML models
(XGBoost, LightGBM, and CatBoost) are trained on the
training set to obtain base learners.

2) Evaluate base learners. The performance of the three
ML models for each class (normal or a type of attack)
is evaluated using cross-validation and F1-scores. F1-
scores are chosen because it is a comprehensive perfor-
mance metric and works well with imbalanced datasets.
3) Determine the leader model for each class. For each
class, the best-performing ML model with the highest
F1-score is selected as the leader model for each class.
If multiple top-performing ML models have identical
highest F1-scores, the most efﬁcient ML model with
the highest speed is chosen as the ﬁnal leader model.

After the training process, the trained leader models for
all classes are utilized for model prediction. At the model
prediction stage, the LCCDE framework predicts each test
sample based on the following steps:

1) Make initial predictions. The three trained base ML
models obtained from the training process are used to
make initial predictions. Their predicted classes and
the corresponding prediction conﬁdences are retained
for further analysis. Conﬁdence is a probability value
used to quantify how conﬁdent the model is about its
predictions.

2) Check if the three predicted classes are the same. If they
are the same, the predicted class agreed by all three base

Input:

Dtest: the test set,
M = {M1, M2, M3}: the trained base ML model list, including M1 =

LightGBM, M2 = XGBoost, M3 = CatBoost,

c = 1, 2, . . . , n: the class list for n different classes.

Output:

Ltest: the prediction classes for all test samples in Dtest.

for each data sample xi ∈ Dtest do

Li1, pi1 ← P rediction (M1, xi);

// For each test sample
// Use the trained LightGBM
model to predict the sample, and save the predicted class & conﬁdence
// Use XGBoost to predict
// Use CatBoost to predict
// If the predicted classes of all the

Li2, pi2 ← P rediction (M2, xi);
Li3, pi3 ← P rediction (M3, xi);
if Li1 == Li2 == Li3 then
three models are the same

Li ← Li1;

else if Li1! = Li2! = Li3 then

// Use this predicted class as the ﬁnal predicted class
// If the predicted classes of all the

three models are different
for j = 1, 2, 3 do

if Mj == LMLi,j then

// For each prediction model
// Check if the predicted class’s

original ML model is the same as its leader model

L listi ← L listi ∪ {Li,j };

// Save the predicted

class

p listi ← p listi ∪ {pi,j };

// Save the conﬁdence

end

end
if Len(L listi) == 1 then

// If only one pair of the original

model and the leader model for each predicted class is the same

Lj ← L listi[0];

// Use the predicted class of the leader

model as the ﬁnal prediction class

else // If no pair or multiple pairs of the original prediction model

and the leader model for each predicted class are the same

if Len(L listi) == 0 then

p listi ← {pi1, pi2, pi3}; // Avoid empty probability

list

end
p maxi ← max(p listi);
// Find the highest conﬁdence
if p maxi == pi1 then // Use the predicted class with the

highest conﬁdence as the ﬁnal prediction class

Li ← Li1;

else if p maxi == pi2 then

Li ← Li2;

Li ← Li3;

else

end

end

else // If two predicted classes are the same and the other one is different
// Find the predicted class with the

n ← mode(Li1, Li2, Li3);

majority vote

Li ← P rediction(Mn, xi);

// Use the predicted class of the

leader model as the ﬁnal prediction class

end
Ltest ← Ltest ∪ {Li};

samples;

// Save the predicted classes for all tested

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34 end

learners is used as the ﬁnal predicted class.

3) Check if the three predicted classes are different. If they
are all different, the corresponding leader model for each
predicted class is compared to the base learner that has
predicted this class. If only one pair of the leader and
base models match, their predicted class is used as the
ﬁnal predicted class; otherwise, the predicted class with
the highest prediction conﬁdence is used as the ﬁnal
predicted class.

4) Check if two predicted classes are the same and the
other one is different. If so, the corresponding leader
model of the same two predicted classes is used to make
the ﬁnal prediction.

In brief, LCCDE detects attacks based on the following

three principles:

1) It uses the trained ML models to generate initially

predicted classes.

ACCEPTED AND TO APPEAR IN IEEE GLOBECOM 2022

5

TABLE I
MODEL PERFORMANCE COMPARISON FOR EACH CLASS IN THE TWO DATASETS

Car-Hacking Dataset

Method

F1 (%)
of Class
1: Normal

F1 (%)
of Class
2: DoS

F1 (%)
of Class
3: Fuzzy

LightGBM [11]
XGBoost [10]
CatBoost [12]
Proposed
LCCDE

99.9998
99.9996
99.9996

99.9998

100.0
100.0
100.0

100.0

99.995
99.990
99.990

99.995

F1 (%)
of Class
4: Gear
Spooﬁng
100.0
100.0
100.0

F1 (%)
of Class
5: RPM
Spooﬁng
100.0
100.0
100.0

100.0

100.0

F1 (%)
of Class
1: Normal

F1 (%)
of Class
2: DoS

F1 (%)
of Class
3: Snifﬁng

99.863
99.863
99.794

99.876

100.0
100.0
99.754

100.0

99.889
99.889
99.557

99.889

CICIDS2017 Dataset
F1 (%)
of Class
4: Brute-
Force
99.222
99.351
99.094

F1 (%)
of Class
5: Web
Attack
99.354
99.137
99.354

99.351

99.354

F1 (%)
of Class
6: Botnets

100.0
100.0
100.0

100.0

F1 (%) of
Class 7:
Inﬁltra-
tion
85.714
85.714
85.714

85.714

2) It uses the leader models for each class to make the ﬁnal

predictions.

3) If there are multiple leader models for different classes,
it selects the leader model with the highest prediction
conﬁdence to make ﬁnal decisions.

The computational complexity of LCCDE is O(N CK),
where N is the data size, C is the number of classes,
K is the complexity of base models. Thus, its complexity
mainly depends on the complexity of all base ML models.
In the proposed framework, three fast gradient-boosting ML
algorithms are used to achieve low overall complexity. These
three algorithms can be replaced by other ML algorithms
using the same generic LCCDE strategy according to speciﬁc
tasks. LCCDE is designed to address the difﬁcult samples that
cannot be correctly predicted by individual ML models. By
using LCCDE, the ﬁnal ensemble model can achieve optimal
performance for detecting every type of attack.

IV. PERFORMANCE EVALUATION

A. Experimental Setup

To develop the proposed IDS, the models were implemented
using Scikit-learn, Xgboost [10], Lightgbm [11], and Catboost
[12] libraries in Python. The experiments were conducted on a
Dell Precision 3630 computer with an i7-8700 processor and
16 GB of memory, representing an IoV server machine.

The proposed LCCDE framework is evaluated on two
public benchmark IoV network security datasets, Car-Hacking
[13] and CICIDS2017 [14] datasets, representing the IVN and
external network data, respectively. The Car-Hacking dataset
[13] is created by transmitting CAN messages into a real vehi-
cle’s CAN bus. It has nine features (i.e., CAN ID and the eight
bits of the CAN message data ﬁeld) and four types of attacks
(i.e., DoS, fuzzy, gear spooﬁng, and Revolutions Per Minute
(RPM) spooﬁng attacks). The CICIDS2017 dataset [14] is
a state-of-the-art general cyber-security dataset including the
most updated types of attacks (i.e., DoS, snifﬁng, brute-force,
web-attacks, botnets, and inﬁltration attacks).

To evaluate the proposed LCCDE model, ﬁve-fold cross-
validation is used in the training process to select leader
class models, and 80%/20% hold-out validation is then used
in the testing process to evaluate the model on the unseen
test set. As network trafﬁc data is often highly imbalanced
and contains only a small proportion of attack samples, four
performance measures, including accuracy, precision, recall,
and F1-scores, are utilized to evaluate the model performance
[3]. The execution time, including the model training and test
time, is used to evaluate the efﬁciency of the model.

TABLE II
PERFORMANCE EVALUATION OF MODELS ON CAR-HACKING DATASET

Method

KNN [23]
SVM [23]
LSTM-AE [24]
DCNN [16]
LightGBM [11]
XGBoost [10]
CatBoost [12]
Proposed
LCCDE

Accuracy
(%)
97.4
96.5
99.0
99.93
99.9997
99.9994
99.9994
99.9997

Precision
(%)
96.3
95.7
99.0
99.84
99.9997
99.9994
99.9994
99.9997

Recall
(%)
98.2
98.3
99.9
99.84
99.9997
99.9994
99.9994
99.9997

F1 (%)

93.4
93.3
99.0
99.91
99.9997
99.9994
99.9994
99.9997

Execution
Time (s)
195.6
1345.3
-
-
10.7
45.3
88.6
185.1

TABLE III
PERFORMANCE EVALUATION OF MODELS ON CICIDS2017

Method

KNN [14]
RF [14]
DBN [19]
Stacking [18]
LightGBM [11]
XGBoost [10]
CatBoost [12]
Proposed
LCCDE

Accuracy
(%)
96.3
98.82
98.95
99.80
99.794
99.794
99.683
99.813

Precision
(%)
96.2
98.8
95.82
99.75
99.795
99.795
99.684
99.814

Recall
(%)
93.7
99.955
95.81
99.89
99.794
99.794
99.683
99.913

F1 (%)

96.3
98.8
95.81
99.70
99.792
99.792
99.680
99.811

Execution
Time (s)
1558.3
135.1
-
278.6
14.3
44.7
73.7
168.9

B. Experimental Results and Discussion

The experimental results of evaluating the three base ML
models (LightGBM, XGBoost, CatBoost) and the proposed
LCCDE model on the Car-Hacking and CICIDS2017 datasets
are shown in Tables I – III. Table I illustrates the performance
of the four models for detecting every type of attack in the
two datasets based on their F1-scores. It is noticeable that the
F1-scores of different base ML models vary for different types
of attack detection. For example, on the CICIDS2017 dataset,
LightGBM achieves the highest F1-score among the three
base learners for detecting normal samples, DoS, snifﬁng,
webattacks, botnets, and inﬁltration attacks, while XGBoost
outperforms LightGBM for the brute-force attack detection.
As shown in Table I, the proposed LCCDE ensemble model
can achieve the highest F1-score for every class. Thus, as
shown in Tables II and III,
the overall F1-scores of the
proposed model are also the highest among the four utilized
ML models on the two datasets. The proposed LCCDE model
achieves a near-perfect F1-score on the Car-Hacking dataset
(99.9997%), and improved its F1-score from 99.792% to
99.811% on the CICIDS2017 dataset. This demonstrates the
beneﬁts of identifying the best-performing base models for
each class to construct the LCCDE ensemble model.

Tables II and III also compare the performance of the

ACCEPTED AND TO APPEAR IN IEEE GLOBECOM 2022

6

[6] J. Jiang, F. Liu, W. W. Y. Ng, Q. Tang, W. Wang, and Q.-V. Pham,
“Dynamic Incremental Ensemble Fuzzy Classiﬁer for Data Streams in
Green Internet of Things,” IEEE Trans. Green Commun. Netw., pp. 1-14,
2022.

[7] M. Injadat, A. Moubayed, A. B. Nassif, and A. Shami, “Machine
learning towards intelligent systems: applications, challenges, and op-
portunities,” Artif. Intell. Rev., 2021.

[8] L. Yang, D. M. Manias, and A. Shami, “PWPAE: An Ensemble
Framework for Concept Drift Adaptation in IoT Data Streams,” in proc.
2021 IEEE Glob. Commun. Conf., pp. 1–6, 2021.

[9] L. Yang , A. Moubayed, A. Shami, P. Heidari, A. Boukhtouta, A. Larabi,
R. Brunner, S. Preda, and D. Migault, ”Multi-Perspective Content
Delivery Networks Security Framework Using Optimized Unsupervised
Anomaly Detection,” IEEE Trans. Netw. Serv. Manag., vol. 19, no. 1,
pp. 686-705, 2022.

[10] T. Chen and C. Guestrin, “XGBoost: A Scalable Tree Boosting System,”
in Proceedings of the 22nd ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, 2016, pp. 785–794.

[11] G. Ke et al., “LightGBM: A highly efﬁcient gradient boosting decision
tree,” Adv. Neural Inf. Process. Syst., vol. 2017-December, no. Nips, pp.
3147–3155, 2017.

[12] L. Prokhorenkova, G. Gusev, A. Vorobev, A. V. Dorogush, and A. Gulin,
“Catboost: Unbiased boosting with categorical features,” Adv. Neural
Inf. Process. Syst., vol. 2018-December, no. Section 4, pp. 6638–6648,
2018.

[13] E. Seo, H. M. Song, and H. K. Kim, “GIDS: GAN based Intrusion
Detection System for In-Vehicle Network,” 2018 16th Annu. Conf.
Privacy, Secur. Trust, pp. 1–6, 2018.

[14] I. Sharafaldin, A. Habibi Lashkari, and A. A. Ghorbani, “Toward
Generating a New Intrusion Detection Dataset and Intrusion Trafﬁc
Characterization,” in Proc. Int. Conf. Inf. Syst. Secur. Privacy, 2018,
pp. 108–116.

[15] M. Injadat, A. Moubayed, A. B. Nassif, and A. Shami, “Multi-Stage
Optimized Machine Learning Framework for Network Intrusion Detec-
tion,” IEEE Trans. Netw. Serv. Manag., vol. 4537, no. c, pp. 1–14, 2020.
[16] H. M. Song, J. Woo, and H. K. Kim, “In-vehicle network intrusion
detection using deep convolutional neural network,” Veh. Commun., vol.
21, p. 100198, 2020.

[17] R. Zhao et al., “A Novel Intrusion Detection Method Based on
Lightweight Neural Network for Internet of Things,” IEEE Internet
Things J., vol. 9, no. 12, pp. 9960-9972, 2022.

[18] L. Yang, A. Moubayed, I. Hamieh, and A. Shami, “Tree-Based Intelli-
gent Intrusion Detection System in Internet of Vehicles,” in proc. 2019
IEEE Glob. Commun. Conf., pp. 1–6, 2019.

[19] W. Elmasry, A. Akbulut, and A. H. Zaim, “Evolving deep learning
architectures for network intrusion detection using a double PSO
metaheuristic,” Comput. Networks, vol. 168, 2020.

[20] Z. Chen, M. Simsek, B. Kantarci, and P. Djukic, “All Predict Wisest
Decides: A Novel Ensemble Method to Detect Intrusive Trafﬁc in IoT
Networks,” in proc. 2021 IEEE Glob. Commun. Conf., pp. 1–6, 2021.
[21] L. Yang and A. Shami, “A Lightweight Concept Drift Detection and
Adaptation Framework for IoT Data Streams,” IEEE Internet Things
Mag., vol. 4, no. 2, pp. 96–101, 2021.

[22] L. Yang and A. Shami, “On hyperparameter optimization of machine
learning algorithms: Theory and practice,” Neurocomputing, vol. 415,
pp. 295–316, 2020.

[23] A. Alshammari, M. A. Zohdy, D. Debnath, and G. Corser, “Classiﬁca-
tion Approach for Intrusion Detection in Vehicle Systems,” Wirel. Eng.
Technol., vol. 09, no. 04, pp. 79–94, 2018.

[24] J. Ashraf, A. D. Bakhshi, N. Moustafa, H. Khurshid, A. Javed, and A.
Beheshti, “Novel Deep Learning-Enabled LSTM Autoencoder Architec-
ture for Discovering Anomalous Events From Intelligent Transportation
Systems,” IEEE Trans. Intell. Transp. Syst., pp. 1–12, 2020.

proposed technique with existing state-of-the-art methods [14]
[16] [18] [19] [23] [24] on the two datasets. The proposed
LCCDE model outperforms other methods by at least 0.09%
and 0.11% F1-score improvements on the Car-Hacking and
CICIDS2017 datasets, respectively. As an ensemble approach,
the proposed LCCDE model has a longer execution time than
the other three base gradient-boosting models, but it is still
faster than many other ML algorithms, such as K-Nearest
Neighbors (KNN) and Support Vector Machine (SVM). This
is because the proposed ensemble model is built using low
complexity ML models with parallel execution and GPU
support. To summarize,
the proposed model can achieve
the highest F1-scores among the compared methods with
relatively low execution time on the two benchmark datasets.

V. CONCLUSION

For the purpose of enhancing IoV security, Machine Learn-
ing (ML) algorithms have been used as promising solutions
to detect various types of cyber-attacks. However, ML models
often perform differently for different types of attack detec-
tion. To achieve optimal performance on all types of attack
detection in IoV networks, a novel ensemble method, namely
Leader Class and Conﬁdence Decision Ensemble (LCCDE),
is proposed in this paper. It identiﬁes the best-performing ML
models for each type of attack detection as the leader class
models to construct a robust ensemble model. Additionally,
the prediction conﬁdence information is utilized to help de-
termine the ﬁnal prediction classes. Three advanced gradient-
boosting ML algorithms, XGBoost, LightGBM, and CatBoost,
are utilized to construct the proposed LCCDE ensemble model
due to their high effectiveness and efﬁciency. Through the
experiments, the proposed IDS framework achieves high F1-
scores of 99.9997% and 99.811% on the Car-Hacking and
CICIDS2017 datasets, representing intra-vehicle and external
vehicular network data, respectively. Moreover, the proposed
model’s F1-scores are higher than other compared ML meth-
ods for detecting every type of attack. This illustrates the
beneﬁts of the proposed leader class-based strategy.

VI. ACKNOWLEDGEMENT

This work is partially supported by The Canadian Urban

Transit Research & Innovation Consortium (CUTRIC).

REFERENCES

[1] H. Bangui and B. Buhnova, “Recent Advances in Machine-Learning
Driven Intrusion Detection in Transportation: Survey,” Procedia Com-
put. Sci., vol. 184, pp. 877–886, 2021.

[2] O. Y. Al-Jarrah, C. Maple, M. Dianati, D. Oxtoby, and A. Mouzakitis,
“Intrusion Detection Systems for Intra-Vehicle Networks: A Review,”
IEEE Access, vol. 7, pp. 21266–21289, 2019.

[3] L. Yang and A. Shami, “A Transfer Learning and Optimized CNN Based
Intrusion Detection System for Internet of Vehicles,” in 2022 IEEE Int.
Conf. Commun. (ICC), 2022, pp. 1–6.

[4] K. Kim, J. S. Kim, S. Jeong, J.-H. Park, and H. K. Kim, “Cybersecurity
for autonomous vehicles: Review of attacks and defense,” Comput.
Secur., vol. 103, p. 102150, 2021.

[5] L. Yang, A. Moubayed, and A. Shami, “MTH-IDS: A Multitiered
Hybrid Intrusion Detection System for Internet of Vehicles,” IEEE
Internet Things J., vol. 9, no. 1, pp. 616–632, 2022.

