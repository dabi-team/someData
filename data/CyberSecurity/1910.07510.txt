9
1
0
2

t
c
O
9
1

]

Y
S
.
s
s
e
e
[

3
v
0
1
5
7
0
.
0
1
9
1
:
v
i
X
r
a

ARXIV, OCTOBER 2019

1

Dynamic Games for Secure and Resilient Control System Design

Yunhan Huang1, Juntao Chen1, Linan Huang1, and Quanyan Zhu1,
1Department of Electrical and Computer Engineering, New York University, Brooklyn, NY 11220 USA

Modern control systems are featured by their hierarchical structure composing of cyber, physical, and human layers. The intricate
dependencies among multiple layers and units of modern control systems require an integrated framework to address cross-layer
design issues related to security and resilience challenges. To this end, game theory provides a bottom-up modeling paradigm to
capture the strategic interactions among multiple components of the complex system and enables a holistic view to understand and
design cyber-physical-human control systems. In this review, we ﬁrst provide a multi-layer perspective toward increasingly complex
and integrated control systems and then introduce several variants of dynamic games for modeling different layers of control
systems. We present game-theoretic methods for understanding the fundamental tradeoffs of robustness, security, and resilience and
developing a cross-layer approach to enhance the system performance in various adversarial environments. This review also includes
three quintessential research problems that represent three research directions where dynamic game approaches can bridge between
multiple research areas and make signiﬁcant contributions to the design of modern control systems. The paper is concluded with a
discussion on emerging areas of research that crosscut dynamic games and control systems.

Index Terms—Game Theory, Dynamic Games, Robustness, Security, Resilience, Cyber-Physical System, Cross-Layer Design,

Complex Systems, Sociotechnical Systems.

I. INTRODUCTION

R ECENT advances in information and communications

technologies (ICTs) such as the Internet of Things (IoT)
and 5G high-speed networks have witnessed increasing con-
nectivity between control systems and cyber networks. The
integration between the cyber and physical worlds has made
signiﬁcant advances in many industrial sectors and critical
infrastructures, including electric power, manufacturing, and
transportation, heralding the fourth industrial revolution that
transforms the operation of industrial control systems. To
understand and design such systems would require a global
and hierarchical perspective toward modern control systems
as shown in Fig. 1. The classical view toward control systems
consists of sensing, control, and plant dynamics integrated in
a feedback loop.

A multitude of control design methods including robust
control, adaptive control, and stochastic control have focused
on how to deal with uncertainties and physical disturbances
[1]. Modern control systems, due to its exposure to open
networks and integration with complex software, require new
methodologies that go beyond the classical ones that have
focused on the interface between the control layer and the plant
at the physical layer. The classical control system is extended
by interconnecting it with the cyber and human layers. The
cyber layer consists of the communication and networking
issues that arise from the communications between sensors
and actuators as well as the connectivity among multiple
distributed agents. The human layer consists of the supervisory
and the management layers that deal with the issues that
include coordination, operation, planning, and investment.

As the modern control system design beneﬁts from the
growing connectivity, the innate vulnerabilities at the cyber
layer and the human layer in modern control systems can
bring concomitant threats and hazards from adversaries [2].

Manuscript completed October 16, 2019; submitted October 17, 2019.

Corresponding author: Yunhan Huang (email: yh.huang@nyu.edu).

Many incidents have been reported as a result of attacker’s
exploitation of these vulnerabilities [3], [4]. Stuxnet, reported
in [5], [6], is one of the well-known Advanced Persistent
Threats (APTs) to control systems that can persist for a long
period, behave stealthily, and speciﬁcally target industrial con-
trol systems by taking advantage of the Supervisory Control
And Data Acquisition (SCADA) systems. This type of attacks
can also be launched by an insider. One example is the
Maroochy water breach incident launched by a disgruntled
former employee. The attack surface of control systems is
exponentially growing. Adversaries can exploit multiple zero-
day vulnerabilities and launch unanticipated attacks. One ex-
ample is the recent hacking of the self-driving vehicles, where
the attacker has remotely manipulated, through the cellular
connection of the vehicle, various electronic control units,
from wiper to brake and engine system [7]. Apart from self-
driving vehicles, many other autonomous systems can face
similar threats. Failure to defend against such threats can inﬂict
huge ﬁnancial losses and fatal damages.

The adversarial behaviors at

the human and the cyber
layers are often hard to anticipate and prepare for. They
can cause a signiﬁcant amount of catastrophic damage to
control systems in terms of their high impact and low effort.
The classical approach that regards abnormal behaviors as a
result of uncertainties and perturbations to physical plants is
insufﬁcient to address these emerging threats. To this end,
a new design paradigm is needed to develop frameworks to
safeguard the control systems from cyber threats and mitigate
the damage that can be caused by attacks. In other words, it
is indispensable to consider system properties beyond stability
and establish a holistic framework to incorporate the study of
robustness, security, and resilience of control systems.

This review aims to present an extensive overview of
recent research directions on using game-theoretic approaches
to address robust, secure, and resilient design problems of
modern control systems. The ﬁrst objective of this review
is to provide a layering perspective toward modern control

 
 
 
 
 
 
ARXIV, OCTOBER 2019

2

systems that consist of cyber, physical, and human components
across the layers. Game-theoretic methods play an important
role in interconnecting different aspects of a control system
and providing a holistic and integrated framework to address
the cross-layer design of robust, secure, and resilient systems.
The second objective of this review is to bridge the classical
system design approaches and the modern system design
through game-theoretic methods. We can view the secure
and resilient control design as an extension of the classical
robust control design by integrating multiple game-theoretic
frameworks. Last but not least, the third objective of this
work is to introduce the emerging research topics related
to game-theoretic methods for secure and resilient control
system design. Namely, we present three major application
areas including secure and resilient control of heterogeneous
autonomous systems, defensive deception game for industrial
control systems, and risk management of cyber-physical net-
works.

Game theory is not a panacea for all secure and resilient
problems in modern control systems. A large number of meth-
ods, including event-triggered control, cryptography, detection
methods, etc., have provided numerous secure and resilient
mechanisms for modern control system design. For those
methods, one can refer to [8]. Game theory have also been
applied to many other application scenarios in control systems
including multi-agent distributed control [9], [10], consensus
[11], robust estimation [12], control of complex systems [13].
In this review, we focus on game-theoretic methods for robust,
secure, and resilient control system design with an emphasis
on dynamic games. For game-theoretic security surveys in
general Cyber-Physical Systems (CPSs), one can refer to [14]–
[18].

A. The Triplet: Robustness, Security, and Resilience

Robustness, security, and resilience are three major control
system properties for modern control systems. The notion
of robustness describes a system’s ability to maintain its
performance in the presence of regular and singular pertur-
bations [12], whereas security refers to the system’s ability
to withstand and be protected from malicious behaviors and
unanticipated events [1]. Robustness and security are two
system properties that are achieved ofﬂine by foreseeing the
perturbations and the attacks before they happen. Thus, these
two system properties are classiﬁed as pre-event concepts.
Despite many endeavors toward designing robust and secure
systems, it is impractical and economically inefﬁcient, if it is
possible, to achieve perfect robustness and security against all
possible perturbations, attacks, and events. This concern calls
for the notion of resilience, a post-event concept referring to
the system’s ability to recover online after adversarial events
occur. Hence, resilient control systems have performance guar-
antees so that even when robustness and security fail under
unanticipated attacks and failures, the systems can self-recover
from deterioration.

Fig. 1. The hierarchical structure of modern control systems is composed
of six layers. The physical layer consists of a physical plant with actuators
and sensors embedded in it. The control system receives orders, observations,
and sends controls to actuators for achieving desired system performance.
The communication layer provides wired or wireless data communications
that enable advanced monitoring and intelligent control. The network layer
allocates network resources for routing and provides interconnections between
system units. The supervisory layer serves as the executive brain of the entire
system, provides human-machine interactions, and coordinates and manages
lower layers through centralized command and control. The management layer
resides at the highest echelon. It deals with social and economic issues, such
as market regulation, pricing, incentive, and environmental affairs.

control systems. Since a robust control system can withstand
a certain range of uncertain parameters and disturbances, the
system stays safe under the malicious attacks if the design of
security can limit the impact of the malicious attacks within an
acceptable range. Additionally, the design of resilient control
systems pivots on the fundamental system tradeoffs between
robustness, security, and resilience. Perfect security could be
attained by making the system unusable, and likewise, perfect
robustness could be reached by considerably degenerating the
control performance. The fact that no desirable control systems
exhibit perfect robustness or security creates a serious need for
resilience. Hence, the three system properties should be jointly
designed. It is of vital importance to know, on the one hand,
what type of uncertainties or adversarial events need to be
considered for enhancing robustness and security, and on the
other hand, what uncertainties or malicious events need to be
considered for post-event resilience.

It is imperative to be aware that robustness, security, re-
silience are three interdependent concepts. These three system
properties should be jointly considered in the design of modern

Metrics for robustness in control systems have been well
established in the literature [12], [19]. A game-theoretic
approach has been introduced to obtain the H ∞ optimal,

ARXIV, OCTOBER 2019

3

objectives of the players, games can be divided into two
categories: zero-sum games and nonzero-sum games.

A zero-sum game refers to a two-player game where the
sum of the two players’ objective functions is zero or can be
made zero by appropriate positive scaling and/or translation
that do not depend on the decision variables of the player.
Zero-sum games are often used to describe conﬂicting ob-
jectives between two players where one player’s gain is the
other player’s loss. Security games often take the form of zero-
sum games as in Blotto games [29] and adversarial machine
learning problems [30]. A non-cooperative game is nonzero-
sum if the sum of the players’ objective functions cannot
be made zero. If each player in a game has only a ﬁnite
number of alternatives, this game is ﬁnite, or a matrix game;
otherwise, it is an inﬁnite game. A continuous-kernel game
is an inﬁnite game where the action sets of the players are
subsets of ﬁnite-dimensional vector spaces, and the players’
objective functions are continuous with respect
to action
variables of all players. A game is dynamic when players
interact multiple rounds sequentially. A game is of complete
information if the structure of the game being played is of
common information to all players, including the number of
players, the objective functions of the players, the underlying
dynamics, the information structure, etc.; it is of incomplete
information, otherwise.

The concepts of equilibrium play a vital role in game theory
which refers to a joint strategy proﬁle from which no player
has a unilateral incentive to change his strategy within the rules
of the game. Based on the types of game, we have various
notions of equilibrium including, Nash equilibrium, Stackel-
berg equilibrium, saddle-point equilibrium (SPE), Bayesian
equilibrium, etc. They are useful to describe outcomes of
different types of interactions among players. For a detailed
exposition of basic concepts of equilibrium solutions, we refer
the reader to [27], [28]; and for a review of game-theoretic
applications to cyber security, we refer readers to [20], [31]–
[33].

Dynamic games are useful to model multi-layer interactions
in control systems as the system dynamics evolve, and dif-
ferent components across the players contribute to the path
of the dynamics. For example, the adversary who disrupts
the communication channels can create a denial-of-service
attack that makes sensor data unavailable and hence leads the
plant dynamics toward an unstable trajectory. The negligence
of a human operator can expose the control system network
to malware, which aims to disrupt the normal operations of
a nuclear power plant. In dynamic games, the information
structure of the game, the form of dynamical systems, and the
constraints on the strategy space determine different classes of
dynamic game models that are useful to describe a rich class
of scenarios of interactions for control systems. For example,
the design of robust control systems has been successfully
formulated as a continuous-time differential game between
disturbance and controller, which are regarded as two players
[12], [19], [23], [28]. The controller seeks to minimize the
control cost criterion by choosing a controller that adapts to
a given information structure while the disturbance aims to
maximize it.

Fig. 2. System functionality evolves over time as different events happen.
Solid line represents system S1; dash line represents system S2. Before t1, a
known small range of disturbances w hits the systems. At t2, an attack or rare
event a happens. At t3, system S1 ﬁnishes full recovery; later at t4, system
S2 ﬁnishes recovery. System S2 fails to accomplish full recovery and suffer
from a steady-state functionality degradation D. The maximum functionality
degradation of system S1(or resp. S2) induced by the event is denoted by
M1(or resp. M2).

disturbance-attenuating minimax controllers by viewing the
controller as the cost minimizer and the disturbance as the
maximizer. Likewise, game-theoretic frameworks have been
established to capture the conﬂict of goals between an attacker
who seeks to escalate the damage inﬂicted on the system
and a defender who aims to mitigate it [20]. There is a rich
literature on deﬁning metrics for the security [8], [20], [21].
However, metrics for security, unlike those for robustness,
are problem dependent as the attack model varies and the
security design parameters depend on the defense mechanisms
such as cryptography, detection, network architecture, and
communication protocols. Examples of recent security metrics
can be found in [22]–[26]. Metrics for resilience naturally
require a comparison between the pre-event and the post-
event performance as resilience is a system property deﬁned as
the ability to recover from severe stresses induced by natural
disasters or malicious attacks. Fig. 2 illustrates the notion of
resilience with respect to an attack that is launched at time
t1. Shortly after the attack, the system performance starts to
degrade to its maximum degree M1 and M2 for the high-
resiliency system (S2) and the low-resiliency system (S1),
respectively. Recovery mechanisms are used to restore the
system to its original performance or a steady-state degraded
performance for system S2 and S1, respectively. A system is
said to be more resilient if the system is capable of recovering
after an attack with a lower loss of performance and a faster
recovery time.

B. Game-Theoretic Methods

Game theory [27], [28], in a nutshell, studies the strategic
interaction between two or multiple decision-makers, called
players, where each player aims to optimize his respective
objective function, which depends on the choices of other
players in the game. Hence,
the optimal decisions of the
players are coupled when they aim to achieve the best for
themselves. Game theory provides a powerful modeling tool
to describe strategic interactions among players. Based on

ARXIV, OCTOBER 2019

4

The design of security mechanisms against APT attacks can
be viewed as a multi-stage game where an attacker aims to
ﬁnd a path toward the control system network from its initial
entry point while the network defender aims to detect and
deter the attack from reaching the targeted asset [34]–[36].
If the attacker is prevented from reaching the objective or
removed from the system, the system is successfully defended.
However, when the network defender fails to safeguard the
control system from the attack, the resilience strategies need to
be planned to restore the attacked control system to its original
operation. Resiliency should be built on the robustness and the
security of the system as the post-event resiliency relies on the
pre-event designs [37]–[41].

Hence,

the pre-event secure strategy and the post-event
resilient strategy are designed as a result of the game between
the defender and the attacker. Despite the fact that security
games are structurally different from robust control games
and may take different forms depending on attack models
[1], [20], [26], [29], [42]–[52], both security/resilience and
robustness of control systems can be studied using dynamic
game frameworks. Thus, dynamic games provide a holistic
approach to create an integrated framework to design robust,
secure, and resilient control systems by composing different
types of games together, as shown in recent literature such as
[1], [22]–[26], [43], [53], [54].

II. DYNAMIC GAMES FOR ROBUSTNESS, SECURITY AND
RESILIENCE
Modern control systems primarily consist of six layers:
physical, control, communication, network, supervisory, and
management, as illustrated in Fig. 1. Sitting at the bottom
is the physical world of the system which serves as a foun-
dation for modern control systems. The physical world of
the system can be viewed as an integration of the physical
plant to be controlled and the control layer providing control
signals based on the feedback. On top of these two layers are
the communication layer which establishes wired or wireless
communications, and the network layer that allocates resources
and manages routing. The communication and network layers
constitute the cyber world of the system. Note that in remote
control systems, the control layer can be sitting above the
cyber layer. Systems containing mainly the cyber layer and
the physical layer are called cyber-physical systems. Serving
as the brain of the system, the supervisory layer coordinates
the cyber and physical layers by designing and sending ap-
propriate commands. Together with the supervisory layer, the
management layer interfaces with humans and makes high-
level decisions, creating a human-in-the-loop cyber-physical
control system.

The design of cyber-physical control system used to be a
compartmentalized process, where the cyber system engineers
design network protocols and security policies independent
from the engineers who design control laws for the underlying
physical or chemical processes. This practice, however, is not
sufﬁcient to meet the integrated system requirements when the
two systems are tightly coupled and strongly interdependent.
It is imperative to take into account cyber security when de-
signing control laws for the physical systems, and be aware of

the physical impact when designing communications protocols
and conﬁguring network devices.

A. The Cyber-Physical Human System Framework

The baseline security-aware resilient control systems is
illustrated in Fig. 3, and can be mathematically described using
the following dynamical system model:

˙x(t) = f (t, x, u, w; θ(t, a, l)), x(t0) = x0,
y(t) = h(t, x, w; θ(t, a, l)),

(1)

(2)

where f, g are continuous functions in (t, x, u, w); x(t) ∈
Rn is the state of the physical system; y(t) ∈ Rm is the
sensor measurement; x0 is a ﬁxed (known) initial state of the
physical plant at starting time t0; u(t) ∈ Rr is the control
input; w(t) models the combined disturbances on the plant
and the sensors. The effect of higher layers on the physical
layer is encoded in θ which could be a function of time. The
space that θ lies in is problem-dependent. The evolution of θ
depends on the cyber defense action l and the attacker’s action
a, which could also be functions of time. We use θ(t) as a
shorthand notation in place of θ(t, a, l) if the pair of actions
(a, l) is ﬁxed.

1) Cyber Attack and Defense
For example, given pair (a, l), θ(t), t ∈ [0, tf ], could be a
Markov jump process with right-continuous sample paths, with
initial distribution π0, and with rate matrix λ = {λij}i,j∈S ,
where S := {1, 2, · · · , s} is the state space; λij ∈ R+ are
the transition rates such that for i (cid:54)= j, λij ≥ 0, and λii =
1 − (cid:80)

j(cid:54)=i λij for i ∈ S.

The framework can be used to capture different types of
attacks on control systems, such as the the replay attack [55],
[56], the false data injection attack [57], and the sensor attack
[58].

1) In the replay attack,

the attacker can record sensor
measurements, choose the replay window size TR > 0,
and decide whether to send the original or modiﬁed
sensor outputs at each time step. Let θ = θ1 denote the
state of the cyber state where there is no attack, and
the control system is in a healthy state. Let θ = θ2
denote the state where an attack has been successfully
launched in the cyber layer, and the control system
is compromised. The replay attack can be captured by
letting h(t, x, w; θ2) = y(t − TR) in (2), stating that the
past measurements y(t − TR) are taken as the current
ones y(t).

2) In the false data injection attack where the attacker
injects data to a subset of sensors, the model (2) can
be used to capture the attack by letting h(t, x, w; θ2) =
h(t, x, w; θ1) + ya(t), where ya(t) is the data value
injected by the attacker. In cases where an attacker can
cause disruptions to the system operation, for example,
by opening a valve in water distribution systems [59],
or turning on a circuit breaker in electric power systems
[60], the dynamics of the control system will be changed,
and they can be captured in (1) by specifying the changed
post-attack dynamics. Fig. 4 illustrates the vulnerabilities
of control systems to multiple potential attacks, where

ARXIV, OCTOBER 2019

5

Fig. 3.

Illustration of the security-aware resilient control systems.

Fig. 4. The attacker can compromise various components in a control
system, including the sensors, communications, controllers, and actuators.

controller-actuator (C-A) channel and sensor-controller
(S-C) channel are vulnerable to cyber attacks. A5 rep-
resents direct sensor attacks which can disable a set of
sensors. A3 and A1 represent the DoS attacks that prevent
controllers from receiving sensor measurements or actua-
tors from receiving control signals. A4 and A2 represent
data injections attacks, where the false information ˜y (cid:54)= y
and ˜u (cid:54)= u is sent from sensors and controllers.

3) In sensor attacks, θ(t) can describe the set of sensors
whose signals cannot be received by the control center
due to network failure or sensor failure cased by denial
of service (DoS) attacks. Each sensor has two states: func-
tioning normally or not. If the number of sensors in the
physical plant is N , then θ(t) ∈ S and S = {1, ..., 2N }.
At time t, the cyber attack action a(t) will be to choose
a set of sensors to attack and the cyber defense move
l(t) will be to recover a chosen set of sensors. Then,
{θ(t)}t∈[0,tf ] becomes a controlled Markov jump process
with transition rate λi,j(a, l), i, j ∈ S. In this case, the
system dynamics is considered to be independent from θ,
i.e., f (t, x, u, w; θ(t, a, l)) = f (t, x, u, w). The output y
is captured by (2). For linear system models, we have
y = C(θ(t, a, l))x where matrix C is a function of θ(t)
decided by the set of sensors that function normally. With
different θ, the system designer needs to adapt different
schemes to do ﬁltering and control.

The costs of launching attacks and executing defenses are
captured by CA(a, l) and CD(a, l), respectively. The attacker
aims to minimize the cost of attacking and deteriorating system
performance. Adversely, the system operator aims to minimize
the cost of defending and maintaining system performance. If
CA(a, l) + CD(a, l) = 0, the attack-and-defense problem is a
zero-sum stochastic game [61] with a Markov decision process
sitting behind. In general, we have CA(a, l) + CD(a, l) (cid:54)=
0. The costs CA and CD depend on the attacker’s and the
system’s actions and the system performance encoded in x
while the evolution of x is dependent on u and θ. Thus, the
security and resilience design in the cyber layer is coupled
with the system dynamics in the physical plant which should
be jointly considered.

2) Robustness and Resilience in the Physical Layer
Given the cyber security strategy pair (a, l), the goal of
is to design a controller that
robust and resilient control
minimizes the performance loss due to the attack, which is

measured by the shaded area in Fig. 5. This design problem
can be captured by an H ∞ control problem with the perfor-
mance index given by the expected cost over the statistics of
θ:

inf
u

sup
w

JP (u, w) :=Eθ{qf (x(tf ); θ(tf ))+

(cid:90) tf

g(t, x(t), u(t), w(t); θ(t))dt},

t0

(3)
where qf is continuous in x, and g is jointly continuous in
(t, x, u, w). In the inﬁnite-horizon case, qf is dropped out,
and tf → ∞. The H ∞-optimal control problem in the time
domain is in fact a minimax optimization problem, and hence
a zero-sum differential game, where the controller u can be
viewed as the minimizing player and the disturbance w as
the maximizing player [12], [28]. The game (3) is referred
to as the physical system game (PSG), and its solution is
characterized by SPE. This framework enables the design
of robustness and resilience within the same model, and
takes into account the security vulnerabilities from the cyber
systems. A large number of papers [24], [29], [44]–[48],
[53] has adopted the idea of deploying dynamic games for
the security and resilience of modern control systems with
interdependent cyber and physical layers.

3) Cyber-Physical Co-Design and Tradeoffs among Ro-

bustness, Security and Resilience

The cyber-physical nature of modern control systems re-
quires a cross-layer approach for designing secure and resilient
systems. Independent designs of the cyber and the physical
layers of the system without knowing their interdependencies
often lead to unintended performance degradation. Thus, a co-
design process that coordinates between cyber and physical
layers of the system is pivotal for the control system. As
illustrated in Fig. 3, the two design processes can be composed
together and reach an iterative process for cyber-physical co-
design. The resilient control design pair (u, w) will be used by
the cyber system for the design of defense strategy pair (a, l),
and likewise, the strategy pair (a, l) is also used by the physical
system for the design of the control pair (u, w). The coupled
system leads to a holistic design framework that enables
robust, secure and resilient design of infrastructural systems.
The fundamental tradeoffs between robustness, security, and
resilience can be quantitatively analyzed and designed:

ARXIV, OCTOBER 2019

6

• Tradeoff between Robustness and Resilience: Perfect ro-
bustness of control systems is not achievable for all types
of disturbances and events. However, resilience can be
used as a post-event measure to recover the system from
the impact of the disturbances and events that are not
accounted for in the model. This tradeoff is captured by
PSG for the security-aware resilient system design.

• Tradeoff between Security and Resilience: Perfect security
that is capable of defending against all types of attacks
is not realistic for control systems. However, the resilient
cyber systems can be designed to quickly bring a com-
promised state to their normal operations. This tradeoff is
captured by the cyber system game (CSG) for the impact-
aware proactive cyber defense.

• Tradeoff between Robustness and Security: The two trade-
offs above lead to a relation between the robustness of
the physical system and the security of the cyber system.
The high demand for robustness requires a strong level of
security. Given limited resources, they cannot be achieved
at the same time. This tradeoff is captured by the coupled
PSG and CSG frameworks.

4) Human Factors of Control Systems
The human factors arise from the interactions between the
control systems with the supervisory layer and the manage-
ment layer. The supervisory layer provides human-machine
interactions and coordinates and manages lower layers through
centralized command and control as illustrated in Fig.1. The
behaviors of human designers and human operators are often
less predictable and difﬁcult to describe. They are often viewed
as the weakest
link in the control system. Attackers can
leverage human vulnerabilities to enter and penetrate the multi-
layer control system network.

For example, in the Stuxnet attack [5], [6], the maintenance
engineer connected an infected USB to his maintenance laptop
from which the malware comes into the private network and
causes SCADA infection. And in the Maroochy breach [62],
a former employee installed a SCADA conﬁguration program
on his own laptop and took control of 150 sewage pumping
stations resulting in severe environmental damage.

The human factors have been studied extensively in the
game theory literature with the objective to describe the cog-
nitive, memory, computational, and psychological aspects of
the human decision-making process [63], [64]. One important
area of research is the bounded rationality which captures the
behavioral and imperfect decision-making of humans. Several
elements in the game-theoretic framework in CSG and PSG
can be revised to capture human errors in decision making due
to limited memory, attention, or reasoning power. For example,
by leveraging the concept of hyperbolic discounting, we can
model the time-inconsistent human preferences, which have
been demonstrated [65] to show that human makes irrational
choices at different times. Prospect theory [66], [67] incorpo-
rates loss-aversion in human decisions and differentiates the
perception of losses from the utility of the gains. It can be used
to extend the risk-neutral decision-making in CSG and PSG
to their risk-averse counterparts to understand the consequence
of the cognitive bias in the decision-making.

Attention is another important human factor that can be
incorporated in the decision making to capture the limited
cognition of the human when they make online decisions
[68]. Authors in [69] have presented an attention-constrained
risk analysis model to assess risks over interdependent risk
networks. The management layer at the highest echelon deals
with social and economic issues, such as market regulation,
pricing, and incentives. Players in this layer deal with socio-
economic issues involving many stakeholders related to the
control systems and make service-level contracts to reduce
cyber-physical risks. For example, cyber insurance is an ex-
ample of ﬁnancial products to transfer the risk from the control
system and mitigate the losses due to cyber threats. Authors
in [70], [71] have designed incentive-compatible attack-aware
cyber insurance policies to maximize the social welfare and
alleviate the impact of moral hazard. In [72], the authors have
designed service contracts for security services in the cloud-
enabled autonomous systems.

As modern control system scales to billions of connected
devices and is increasingly complex, it is not always possible
for an entity to own and manage all cyber and physical
components of the control system. For example, in cloud-
enabled systems [39], [73], [74], smart homeowners use the
services provided by the cloud service provider (SP) who fuses
data and optimizes control decisions for real-time systems.
Small business owners may not own the sensors but subscribe
to service providers (SPs) who collect data that allow users to
develop control system applications instead of making a costly
investment in their own sensing infrastructure [75].

The decentralized ownership and the provision of control
system services provide an effective sharing and utilization of
the resources of computational, communication, and sensing
infrastructures. In this paradigm, the SP owns the cyber infras-
tructure and determines defense strategy l while the user owns
the physical infrastructure and designs control u. However, a
user cannot directly control or manage the security risk. If the
SP is negligent in assuring cybersecurity, then users who rely
on these services will be subject to high-security risks. It is
essential to develop appropriate incentive-compatible service
mechanisms for the SPs to offer high quality of services (QoS)
while making efforts to mitigate security risks at the service
level of control systems. SPs should be incentivized to deploy
adequate security mechanisms to ensure the reliability and the
dependability of the services for control system users. It not
only enables the implementation and investment of security
but also prevents the cyber risks from further propagating at
the socio-economic scale.

Challenges in the design of the cyber-physical contract
come from incomplete information and adversarial behaviors.
The incomplete information can arise from the hidden type
and the hidden action of the SP. In [74], [76], the authors
have used contract design principles to develop a holistic
incentive-compatible and cost-efﬁcient security-aware service
mechanism for real-time operation of cloud-enabled Internet
of Controlled Things (IoCTs) under APTs.

ARXIV, OCTOBER 2019

7

III. RECENT ADVANCES

With the hierarchical perspective toward robust, secure,
and resilient control systems, this section aims to introduce
several recent dynamic applications to cross-layer control de-
sign in adversarial environments. Game-theoretic approaches
have been natural frameworks to model conﬂicts between an
attacker and a defender in various scenarios at the commu-
nication and networking layers including intrusion detection
[48], [77]–[81], jamming and eavesdropping [82]–[85], and
honeypot/deception [86]–[90]. These approaches use different
game models [27], [28] such as zero-sum game, stochastic
game, repeated game, differential game, Stackelberg game,
etc., to handle different type of attacks including jamming
attack [82]–[84], eavesdropping [84], DoS attack [25], [51],
replay attack [55], [56], zero dynamics attack [21], [91], data
injection attack [57], [79], covert attack [91], [92] and cyber
epidemic attack [93] etc.
Apart from those at

the cyber layers, game theory has
also successfully addressed risk management [70], [94] and
security investment problems [69], [95] at the human layers
and the problem of adversarial consensus [11], [96], [97] and
resilient infrastructures [98]–[103] at the control layers.

This section presents three quintessential research problems
that represent three distinct directions where dynamic game
approaches can be useful to bridge between multiple research
areas and make signiﬁcant contributions to the design of
modern control systems. The ﬁrst one leverages a moving-
horizon dynamic game technique to secure the heterogeneous
autonomous vehicles and enable self-healing after attacks. The
second research direction investigates an impact-aware multi-
stage cyber deception game where the defender proactively
deters the stealthy APT attacks from reaching the critical
asset of industrial control systems. Adversarial and defensive
deceptions across the entire intrusion process introduce the
thus both players need
games of incomplete information,
to make judicious actions under persistent uncertainty. The
third direction focuses on the risk management of networked
systems by incentivizing agents to comply with security guide-
lines with maximum effort.

A. Games for Secure Control of Heterogeneous Autonomous

Systems

Multi-layer networks or network-of-networks have been
seen in a number of critical applications, such as energy
and water networks [104], power and transportation networks
[105], and multi-layer robotic systems [53]. Traditional de-
fensive mechanisms for single networked systems are no
longer sufﬁcient for this network-of-networks paradigm. To
design secure and resilient control strategies for the multi-
layer autonomous systems, it is imperative to analyze three
types of games resulting from the strategic interactions: i)
interactions among agents in individual network layers, ii)
interactions between agents from different
layers, and iii)
interactions between agents and adversaries. To address this
challenge, the authors in [43], [106] have proposed a games-
in-games model which is able to understand the network

Fig. 5. Games-in-games framework for secure and resilient control of multi-
layer multi-agent systems. The control of each agent considers the behaviors
of the agents at the same layer and the ones at the other layer. Furthermore,
the agents also learn and respond to the unanticipated events, such as natural
disruptions and adversarial attacks, at each step of decision making.

performance, heterogeneous agents’ functionalities, and the
network operators’ decisions holistically.

For clarity, a pictorial illustration of the games-in-games
framework is shown in Fig. 5. The system composes two layers
of networks. In each sub-layer, agents make decisions based on
not only the behaviors of the agents at the same layer but the
ones at the other layer. At each step of decision making, the
agents also learn and respond to the unanticipated events in
an agile fashion, such as natural disruptions and adversarial
attacks. Leveraging the framework, one can compose the
distinct games together to obtain the Gestalt Nash equilibrium
(GNE) [69], [73]. The GNE describes an equilibrium solution
concept at which no agent has incentives to deviate away from
not only each modular game, which captures the local agent-
agent level interactions, but also the integrated game, which
considers the global system-system level interactions.

Based on [106], we next present an example of controlling
two-layer mobile autonomous systems in the adversarial en-
vironment. There are three players in the game: two network
operators and an attacker. The focused objective in [106] is the
algebraic connectivity of the global network. The attacker’s
problem at time k is formulated as follows:

Qk

A : min

e

λ2(e, x(k)),

(4)

where λ2(e, x(k)) is the connectivity of the global network,
with e representing the attacker’s strategy and x(k)
:=
[x1(k); x2(k)] the network conﬁguration at time k. On the
other hand, the network operator γ’s problem is, for γ ∈
{1, 2}:

Qk

γ :

max
xγ (k+cγ )

min
e

λ2(e, x(k + cγ))

s.t. physical dynamics of autonomous systems,

(5)

where xγ(k + cγ) is the conﬁguration of the mobile network
controlled by operator γ at time k + cγ, and cγ is a positive
integer indicating update frequency. Note that the network
operator’s problem falls into the general framework formulated
in Section II, where the dynamics of autonomous systems can
be captured by (1) and (2). Furthermore, each network operator
needs to prepare for the worst case attacks (Stackelberg game)
as well as the action taken by the other operator (Nash game)
during the network reconﬁguration.

ARXIV, OCTOBER 2019

8

(a) Secure conﬁguration of robotic networks

(b) Network connectivity

Fig. 6.
steps. (b) shows the corresponding network connectivity.

(a) shows the dynamic and secure conﬁguration of a two-layer robotic network. The GPS spooﬁng attack introduced at time step 9 and lasted for 5

This games-in-games framework has been corroborated to
be effective in obtaining the self-adaptability, self-healing, and
agile resilience of heterogeneous autonomous systems. In the
Internet of battleﬁeld things, the unmanned ground vehicle
network coordinates its actions with the unmanned aerial
vehicle network and the soldier network to achieve a highly
connected global network [107]. The designed decentralized
algorithm in [106] yields an intelligent control of each agent to
respond to others to optimize real-time network connectivity
under adversaries. Fig. 6 shows the results of a two-layer
autonomous system on the battleﬁeld where two operators
prepare for potential jamming attacks. Furthermore, the agents
can respond to the spooﬁng attack quickly which shows the
agile resilience of the control strategy. The developed games-
in-games model can be further extended to address the mosaic
control design as the framework provides built-in security and
resilience for each component in the system which guarantees
the performance of the integrated system.

B. Multi-stage Bayesian Games: Security under Adversarial

and Defensive Deception

APT attacks originated from a cyber network (the middle
layer of Fig. 1) can stealthily escalate privilege, move laterally,
and lead to damage in the physical control system (the bottom
layer of Fig. 1). The entire intrusion process can be divided
into multiple phases in sequence, as denoted by the black
boxes in the middle layer of Fig. 7.

Each phase serves as a stepping stone for the next phase
and plays an indispensable role in the success of APTs. Based
on the multi-stage and stealthy characteristics of APTs, [108]
has suggested a Defense-in-Depth (DiD) paradigm to counter
them proactively. DiD as the ﬁrst aspect means that a control
system defender should adopt defensive countermeasures at
all phases of APTs and holistically consider interconnections
and interdependencies among these stages. For example, a
privilege restriction at the escalation phase can result in a
failure or an additional cost for the APT attacker to take
control of the targeted sensor at the ﬁnal stage. Proactive
actions and precautions as the second aspect mean that the

defender needs to act before an attack is revealed. On one
hand, these precautions can mitigate the loss induced by the
APT attack at the ﬁnal phase and deter attacks at their early
stages. On the other hand,
they can also impair the user
experience and reduce the utility of legitimate users. Hence,
the defender has to take judicious actions at each stage to
balance usability versus security.

The lower and upper layers of Fig. 7 illustrate a K-stage
strategic interaction between the proactive defender and the
user in blue and red, respectively. The type of a user can
be either adversarial or legitimate. Since an APT attacker can
pretend to be a legitimate user throughout stages, the defender
does not know the user’s type. The defender can observe
suspicious user actions at each stage. However, these suspi-
cious actions do not directly reveal the user’s type because a
legitimate user may also take them. For example, both the Tor
network connection [109] and the code obfuscation [77] can be
used legitimately or illegally. Similarly, a defender can also be
classiﬁed into different types based on factors such as her level
of security awareness, detection techniques she have adopted,
and the completeness of her virus signature database. To tilt
the information asymmetry that the user has a private type,
the defender can also introduce defensive deception and make
her type unknown to the user. The defender takes proactive
actions at each stage and the user can observe them at the
next stage. Therefore, each stage describes a local interaction
between the attacker and the defender (two-layer game) where
the outcome leads to the next stage of interactions. Participants
receive different stage utilities from each local interaction (the
discrete counterpart of (3)) and each player aims to ﬁnd a
behavioral strategy of this dynamic game to maximize his
expected utility accumulated over K stages. The behavioral
strategy means that each player needs to decide which action
to take or take an action with what probability based on
the available information. Each player introduces a belief to
quantify the uncertainty of the opponent’s type and adopts
the Bayesian update to correlate the information revealed
at each stage and reduce the type uncertainty. The solution
concept of Perfect Bayesian Nash Equilibrium (PBNE) is

ARXIV, OCTOBER 2019

9

Fig. 7. A block diagram of the proposed proactive defense-in-depth paradigm against multi-stage stealthy APTs. As denoted in black, each stage describes a
local interaction between the user and the defender where the outcome leads to the next stage of interactions. Dash arrows represent the information available
to each player, which can be used to update the belief and decide the cross-stage behavioral strategy based on the PBNE. Then, each player takes an action
at each stage according to the strategy, as denoted in solid arrows.

introduced where ‘perfect’ captures the cross-stage cumulative
utility, ‘Bayesian’ captures the type uncertainty, and ‘Nash
Equilibrium’ captures the strategic interaction between two
players. The PBNE provides a creditable predication of both
players’ behaviors over K stages because no players beneﬁt
from unilateral deviations at the equilibrium. To solve the
coupling between the forward belief update and the backward
equilibrium computation, [108] has proposed a sequence of
nested algorithms. The authors in [108] have also provided an
elaborate case study of APT attacks on the Tennessee Eastman
process (a speciﬁc example of (1) and (2)) and obtained the
following insights.

First, one ounce of proactive actions when the attack
remains “under the radar” is worth a pound of post-attack
response. Second, the online learning capability of the de-
fender reveals hidden information from observable behaviors
and threatens the stealthy attacker to take more conservative
actions. Third, defensive deception introduces uncertainty to
attackers, increase their learning costs, and hence reduces the
probability of successful attacks.

C. Dynamic Games for Risk Management of Networked

Systems

Game theory is widely adopted in the risk management of
complex engineering systems [69], [70]. Mitigating the risk of
multi-agent systems is critical for their secure and efﬁcient op-
erations. However, due to complex interdependencies between
nodes and the fast-evolving nature of threats, controlling the
risks of multi-agent systems is not a trivial task and requires
expert knowledge. Hence, one approach for the system owners
is to delegate tasks of risk mitigation to security professionals,
creating security as a service paradigm [76].

As shown in Fig. 8, the owner can be seen as a principal
who employs a security professional to fulﬁll risk management

Fig. 8. Risk management of a networked system through dynamic contracts.
The asset owner (principal) delegates the risk management tasks to security
professional (agent) by designing a contract which speciﬁes the dynamic
remuneration schemes. The agent’s effort is hidden to the principal. The
amount of remuneration depends on the observed risk of the system. The
contract mechanism design can be formulated as a stochastic Stackelberg
differential game under nonstandard information.

tasks, and the security professional (risk manager) can be re-
garded as an agent whose efforts are dynamically compensated
by the principal. This type of two-sided service relationship
can be captured by a principal-agent framework. One unique
feature of the framework is that the principal cannot directly
observe the efforts adopted by the agent. Thus, the principal
needs to design a contract that speciﬁes the compensation
rules only based on observable risk outcomes. Speciﬁcally,
the cyber risk evolution can be described by the following
dynamic systems (which belongs to the general dynamics (1)):

dx(t) = f (x(t), u(t), t)dt + Σ(x(t), t)db(t),
x(0) = x0,

(6)

where f : RN × RN
+ × [0, T ] → RN , Σ : RN × [0, T ] → RN
with x(t) ∈ RN represents the risk of nodes in the system,
u(t) ∈ RN
+ the hidden effort of the agent, b(t) is an N -

Privilege EscalationLateral MovementMission CompletenessData Exfiltration Physical Damage Initial CompromisePhysical AccessWeb PhishingSocial EngineeringReconnaissance Insider ThreatsOSINTUserAdminRootKernelStage 0Stage 1Stage kStage k+1Stage KUser’s	ActionDefender’s	ActionSophisticatedPrimitiveDefender’s	TypeorLegitimateAdversarialUser’s	TypeorPBNE:	Belief	Update	and	Decision	Making	PBNE:	Belief	Update	and	Decision	Making	User’s	ObservationDefender’s	ObservationPrivate	InformationPrivate	InformationARXIV, OCTOBER 2019

10

dimensional standard Brownian motion, and x0 is a known
N -dimensional constant vector indicating the initial risk. The
dynamic contract designed by the principal is p(t), t ∈ [0, T ],
reﬂecting the payment delivered to the agent at time t. First,
the principal’s goal is to minimize the risk x(t) by providing
an appropriate amount of incentives p(t) over the time horizon.
Second, the contract should capture the agent’s behavior
including the incentive compatibility (IC) and the individual
rationality (IR). The principal’s cost function is

JP ({p(t)}0≤t≤T ) = E

(cid:90) T

0

and the agent’s cost function is

fP (t, x(t), p(t))dt,

(7)

JA ({u(t)}0≤t≤T ; {p(t)}0≤t≤T )

=E

(cid:90) T

0

fA(t, p(t), u(t))dt,

(8)

the

running costs of

where E is the expectation operator, and fP and fA
two players. Furthermore,
are
is JA ({u(t)∗}0≤t≤T ; {p(t)}0≤t≤T ) ≤
the IC constraint
JA ({u(t)}0≤t≤T ; {p(t)}0≤t≤T ) , ∀u(t), t ∈ [0, T ], and the
is inf u(t) JA ({u(t)}0≤t≤T ; {p(t)}0≤t≤T ) ≤
IR constraint
J A, where J A is a predetermined non-positive constant.

This contract design for risk management problem can be
formulated as a stochastic Stackelberg differential game under
nonstandard information. To design the optimal contract, the
authors in [94], [110] have developed a three-step approach in-
cluding the estimation, veriﬁcation and control phases, which
transformed the principal’s nonclassical control problem into
a standard stochastic control program. For example, when
the dynamics in (6) admit a linear form and the players’
cost functions are quadratic, then the optimal contract can
be obtained through solving a matrix Riccati equation [94].
Under mild conditions on the structure of cost functions of two
players, the authors have revealed a separation principle where
the estimation and control phases can be addressed separately.
The authors have also discovered a certainty equivalence
principle for a class of dynamic mechanism design problems
where the contracts designed under incomplete case and full
information scenario (the principal can directly observe the
agent’s action) coincide. The contract mechanism has been
corroborated effective in mitigating the risks.

The developed framework for risk management can be
applied broadly, such as industrial control systems, enterprise
networks, and critical infrastructures. Furthermore, the dy-
namic mechanism design problem can be extended extensively,
which is of great
to the control community. For
example, the underlying system could have jump parameters,
the risk could be governed by mean-ﬁeld dynamics in large
networks, the risk cannot be directly observable to the players,
and the risk observation is intermittent, etc.

interest

holistic view of control systems that leads to an integrated
dynamic game framework. The dynamic games approach has
successfully captured the multi-layer cyber, physical, and hu-
man interactions in control systems as well as their behaviors
in adversarial environments. The game-theoretic modeling has
provided a fundamental understanding of the tradeoffs among
robustness, security, and robustness, leading to a new system
science and design paradigm.

The application of dynamic games to control systems is
still
in its infancy despite a rich literature in game and
control theory. The bridging between these two ﬁelds would
require addressing many research challenges. Computational
complexity is one important research direction. Analysis of
large-scale game-theoretic models is often difﬁcult. It would
be essential to develop efﬁcient algorithms to compose distinct
models, compute equilibrium solutions, and solve mechanism
design problems. These tools would lead to the core of the
next-generation control system technologies that have the
capabilities of automated defense, self-organizing, and fast
recovery.

Another key challenge arises from dealing with human
factors at the supervisory and management layers. It has been
observed that many security breaches are due to human cog-
nitive errors, limited reasoning capabilities, and mismatched
perception of risk. Integrating human modeling into control
systems is critical to enable a scientiﬁc framework for human-
centered design. Recent advances in behavioral game theory
and epistemic game theory have laid necessary theoretical
foundations for the modeling of bounded rationality and hu-
man behaviors. Hence game theory provides an unprecedented
opportunity to understand human factors in control systems by
bridging game theory and control system theory.

ACKNOWLEDGMENT
This research is partially supported by award 2015-ST-061-
CIRC01, U. S. Department of Homeland Security, awards
ECCS-1847056, CNS-1544782, and SES-1541164 from Na-
tional Science of Foundation (NSF), and grant W911NF-19-
1-0041 from Army Research Ofﬁce (ARO).

REFERENCES

[1] Q. Zhu and T. Bas¸ar, “Game-theoretic methods for robustness, security,
and resilience of cyberphysical control systems: games-in-games prin-
ciple for optimal cross-layer resilient control systems,” IEEE Control
Systems Magazine, vol. 35, no. 1, pp. 46–65, 2015.

[2] F. Pasqualetti, F. D¨orﬂer, and F. Bullo, “Attack detection and identi-
ﬁcation in cyber-physical systems,” IEEE Transactions on Automatic
Control, vol. 58, no. 11, pp. 2715–2729, 2013.

and

security

released

directive

“Presidential

policy
resilience,”

[3] T. W. House,
infrastructure
12-February-2013].
[Online;
https://obamawhitehouse.archives.gov/the-press-ofﬁce/2013/02/12/
presidential-policy-directive-critical-infrastructure-security-and-resil
[4] R. Smith and R. Barry, “Americas electric grid has a vulnerable back
door – and russia walked through it,” Jan 2019, [Online; posted 11-
January-2019].

critical
2013,
Available:

–
February

[Online].

IV. CONCLUSION AND FUTURE DEVELOPMENT

In this review, we have discussed recent advances and appli-
cations of dynamic games to the robust, secure, and resilient
design of modern control systems. We have introduced the
hierarchical structure of modern control systems, offering a

[5] S. Greengard, “The new face of war,” Communications of the ACM,

vol. 53, no. 12, pp. 20–22, 2010.

[6] R. McMillan, “Siemens: Stuxnet worm hit industrial systems,” Com-

puterworld, vol. 14, 2010.

[7] A. Greenberg, “Hackers remotely kill a jeep on the highway – with me
in it,” July 2015, [Online; posted 21-July-2015]. [Online]. Available:
https://www.wired.com/2015/07/hackers-remotely-kill-jeep-highway/

ARXIV, OCTOBER 2019

11

[8] A. M. Annaswamy, A. R. Malekpour, and S. Baros, “Emerging research
topics in control for smart infrastructures,” Annual Reviews in Control,
vol. 42, pp. 259–270, 2016.

[9] J. R. Marden and J. S. Shamma, “Game theory and control,” Annual
Review of Control, Robotics, and Autonomous Systems, vol. 1, pp. 105–
134, 2018.

[10] R. M. Murray, “Recent research in cooperative control of multivehicle
systems,” Journal of Dynamic Systems, Measurement, and Control, vol.
129, no. 5, pp. 571–583, 2007.

[11] D. Bauso, L. Giarre, and R. Pesenti, “Mechanism design for optimal
consensus problems,” in IEEE Conference on Decision and Control,
2006, pp. 3381–3386.

[12] T. Bas¸ar and P. Bernhard, H-inﬁnity optimal control and related
minimax design problems: a dynamic game approach. Springer, 2008.
[13] R.-R. Zhang and L. Guo, “Controllability of nash equilibrium in game-
based control systems,” IEEE Transactions on Automatic Control,
2019.

[14] X. Liang and Y. Xiao, “Game theory for network security,” IEEE
Communications Surveys & Tutorials, vol. 15, no. 1, pp. 472–486,
2012.

[15] K. Ramachandran and Z. Stefanova, “Dynamic game theories in cyber
security,” Proceedings of dynamic systems and applications, vol. 7, pp.
303–310, 2016.

[16] S. Roy, C. Ellis, S. Shiva, D. Dasgupta, V. Shandilya, and Q. Wu, “A
survey of game theory as applied to network security,” in 2010 43rd
Hawaii International Conference on System Sciences.
IEEE, 2010,
pp. 1–10.

[17] Y. Wang, Y. Wang, J. Liu, Z. Huang, and P. Xie, “A survey of game
theoretic methods for cyber security,” in 2016 IEEE First International
Conference on Data Science in Cyberspace (DSC).
IEEE, 2016, pp.
631–636.

[18] S. R. Etesami and T. Bas¸ar, “Dynamic games in cyber-physical security:
An overview,” Dynamic Games and Applications, pp. 1–30, 2019.
[19] K. Zhou and J. C. Doyle, Essentials of robust control. Prentice hall

Upper Saddle River, NJ, 1998, vol. 104.

[20] M. H. Manshaei, Q. Zhu, T. Alpcan, T. Bacs¸ar, and J.-P. Hubaux,
“Game theory meets network security and privacy,” ACM Computing
Surveys (CSUR), vol. 45, no. 3, p. 25, 2013.

[21] A. Teixeira, I. Shames, H. Sandberg, and K. H. Johansson, “A se-
cure control framework for resource-limited adversaries,” Automatica,
vol. 51, pp. 135–148, 2015.

[22] D. Wei and K. Ji, “Resilient industrial control system (rics): Concepts,
formulation, metrics, and insights,” in International symposium on
resilient control systems, 2010, pp. 15–22.

[23] Q. Zhu and T. Bas¸ar, “Robust and resilient control design for cyber-
physical systems with an application to power systems,” in IEEE Con-
ference on Decision and Control and European Control Conference,
2011, pp. 4066–4071.

[24] Q. Zhu, L. Bushnell, and T. Bas¸ar, “Resilient distributed control
of multi-agent cyber-physical systems,” in Control of Cyber-Physical
Systems. Springer, 2013, pp. 301–316.

[25] Y. Yuan, H. Yuan, L. Guo, H. Yang, and S. Sun, “Resilient control of
networked control system under dos attacks: A uniﬁed game approach,”
IEEE Transactions on Industrial Informatics, vol. 12, no. 5, pp. 1786–
1794, 2016.

[26] S. M. Dibaji, M. Pirani, D. B. Flamholz, A. M. Annaswamy, K. H.
Johansson, and A. Chakrabortty, “A systems and control perspective of
cps security,” Annual Reviews in Control, 2019.

[27] D. Fudenberg and J. Tirole, “Game theory, 1991,” Cambridge, Mas-

sachusetts, vol. 393, no. 12, p. 80, 1991.

[28] T. Bas¸ar and G. J. Olsder, Dynamic noncooperative game theory.

SIAM, 1999, vol. 23.

[29] A. Ferdowsi, W. Saad, and N. B. Mandayam, “Colonel blotto game for
secure state estimation in interdependent critical infrastructure,” arXiv
preprint arXiv:1709.09768, 2017.

[30] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley,
S. Ozair, A. Courville, and Y. Bengio, “Generative adversarial nets,” in
Advances in neural information processing systems, 2014, pp. 2672–
2680.

[31] Q. Zhu, “Game theory for cyber deception: a tutorial,” in Proceedings
of the 6th Annual Symposium on Hot Topics in the Science of Security.
ACM, 2019, p. 8.

[32] Q. Zhu and S. Rass, “Game theory meets network security: A tutorial,”
in Proceedings of the 2018 ACM SIGSAC Conference on Computer and
Communications Security. ACM, 2018, pp. 2163–2165.

[33] J. Pawlick, E. Colbert, and Q. Zhu, “A game-theoretic taxonomy and
survey of defensive deception for cybersecurity and privacy,” ACM
Computing Surveys (CSUR), vol. 52, no. 4, p. 82, 2019.

[34] Q. Zhu and S. Rass, “On multi-phase and multi-stage game-theoretic
modeling of advanced persistent threats,” IEEE Access, vol. 6, pp.
13 958–13 971, 2018.

[35] S. Rass, A. Alshawish, M. A. Abid, S. Schauer, Q. Zhu, and
H. De Meer, “Physical
intrusion gamesoptimizing surveillance by
simulation and game theory,” IEEE Access, vol. 5, pp. 8394–8407,
2017.

[36] L. Huang and Q. Zhu, “Adaptive strategic cyber defense for advanced
persistent threats in critical infrastructure networks,” ACM SIGMET-
RICS Performance Evaluation Review, vol. 46, no. 2, pp. 52–56, 2019.
[37] Z. Xu and Q. Zhu, “Cross-layer secure cyber-physical control system
design for networked 3d printers,” in 2016 American Control Confer-
ence (ACC).

IEEE, 2016, pp. 1191–1196.

[38] ——, “Cross-layer secure and resilient control of delay-sensitive net-
worked robot operating systems,” in 2018 IEEE Conference on Control
Technology and Applications (CCTA).
IEEE, 2018, pp. 1712–1717.
[39] ——, “Secure and resilient control design for cloud enabled networked
control systems,” in Proceedings of the First ACM Workshop on Cyber-
Physical Systems-Security and/or PrivaCy. ACM, 2015, pp. 31–42.
[40] ——, “Secure and practical output feedback control for cloud-enabled
cyber-physical systems,” in 2017 IEEE Conference on Communications
and Network Security (CNS).

IEEE, 2017, pp. 416–420.

[41] ——, “A game-theoretic approach to secure control of communication-
based train control systems under jamming attacks,” in Proceedings
of the 1st International Workshop on Safe Control of Connected and
Autonomous Vehicles. ACM, 2017, pp. 27–34.

[42] M. Pirani, E. Nekouei, H. Sandberg, and K. H. Johansson, “A game-
theoretic framework for security-aware sensor placement problem in
networked control systems,” in American Control Conference (ACC),
2019, pp. 114–119.

[43] J. Chen and Q. Zhu, “A games-in-games approach to mosaic command
and control design of dynamic network-of-networks for secure and
resilient multi-domain operations,” in Sensors and Systems for Space
Applications XII, vol. 11017, International Society for Optics and
Photonics. SPIE, 2019, pp. 189 – 195.

[44] S. Amin, G. A. Schwartz, and S. S. Sastry, “Security of interdependent
and identical networked control systems,” Automatica, vol. 49, no. 1,
pp. 186–192, 2013.

[45] A. Clark, Q. Zhu, R. Poovendran, and T. Bas¸ar, “An impact-aware
defense against stuxnet,” in American Control Conference (ACC), 2013,
pp. 4140–4147.

[46] R. J. La, “Estimation of externalities in interdependent security: A case
study of large systems,” in IEEE Conference on Decision and Control
(CDC), 2017, pp. 3961–3966.

[47] A. Sanjab and W. Saad, “On bounded rationality in cyber-physical sys-
tems security: Game-theoretic analysis with application to smart grid
protection,” in Workshop on Cyber-Physical Security and Resilience in
Smart Grids (CPSR-SG), 2016, pp. 1–6.

[48] Q. Zhu, H. Tembine, and T. Bas¸ar, “Network security conﬁgurations:
A nonzero-sum stochastic game approach,” in American Control Con-
ference (ACC), 2010, pp. 1059–1064.

[49] F. Miao, Q. Zhu, M. Pajic, and G. J. Pappas, “A hybrid stochastic game
for secure control of cyber-physical systems,” Automatica, vol. 93, pp.
55–63, 2018.

[50] V. Ugrinovskii and C. Langbort, “Controller–jammer game models of
denial of service in control systems operating over packet-dropping
links,” Automatica, vol. 84, pp. 128–141, 2017.

[51] Y. Wu, Y. Li, and L. Shi, “A game-theoretic approach to remote state
estimation in presence of a dos attacker,” IFAC-PapersOnLine, vol. 50,
no. 1, pp. 2595–2600, 2017.

[52] X. Gao, E. Akyol, and T. Bas¸ar, “Communication scheduling and
remote estimation with adversarial intervention,” IEEE/CAA Journal
of Automatica Sinica, vol. 6, no. 1, pp. 32–44, 2019.

[53] J. Chen and Q. Zhu, “Resilient and decentralized control of multi-level
cooperative mobile networks to maintain connectivity under adversarial
environment,” in IEEE Conference on Decision and Control (CDC),
2016, pp. 5183–5188.

[54] M. Pajic, P. Tabuada, I. Lee, and G. J. Pappas, “Attack-resilient state
estimation in the presence of noise,” in IEEE Conference on Decision
and Control (CDC), 2015, pp. 5827–5832.

[55] T. Aura, “Strategies against replay attacks,” in Proceedings 10th
IEEE, 1997, pp. 59–68.

Computer Security Foundations Workshop.

ARXIV, OCTOBER 2019

12

[56] F. Miao, M. Pajic, and G. J. Pappas, “Stochastic game approach for
replay attack detection,” in IEEE conference on Decision and Control,
2013, pp. 1854–1859.

[57] R. B. Bobba, K. M. Rogers, Q. Wang, H. Khurana, K. Nahrstedt,
and T. J. Overbye, “Detecting false data injection attacks on dc state
estimation,” in First Workshop on Secure Control Systems, CPSWEEK,
2010.

[58] A. Mitra and S. Sundaram, “Byzantine-resilient distributed observers

for lti systems,” Automatica, vol. 108, p. 108487, 2019.

[59] T. U. D. of Homeland Security, Roadmap to Secure Control System in

the Water Sector, March 2008.

[60] ——, “Roadmap to achieve energy delivery systems cybersecurity,”

September 2011.

[61] L. S. Shapley, “Stochastic games,” Proceedings of the national academy

of sciences, vol. 39, no. 10, pp. 1095–1100, 1953.

[62] J. Slay and M. Miller, “Lessons learned from the maroochy water
breach,” in International Conference on Critical Infrastructure Pro-
tection. Springer, 2007, pp. 73–82.

[63] S. Dhami, The foundations of behavioral economic analysis. Oxford

University Press, 2016.

[64] M. S. Sanders and E. J. McCormick, “Human factors in engineering
and design,” Industrial Robot: An International Journal, 1998.
[65] R. Thaler, “Some empirical evidence on dynamic inconsistency,” Eco-

nomics letters, vol. 8, no. 3, pp. 201–207, 1981.

[66] A. Tversky and D. Kahneman, “Advances in prospect theory: Cumu-
lative representation of uncertainty,” Journal of Risk and uncertainty,
vol. 5, no. 4, pp. 297–323, 1992.

[67] D. Kahneman and A. Tversky, “Prospect

theory: An analysis of
decision under risk,” in Handbook of the fundamentals of ﬁnancial
decision making: Part I. World Scientiﬁc, 2013, pp. 99–127.
[68] C. A. Sims, “Rational inattention and monetary economics,” in Hand-

book of monetary economics. Elsevier, 2010, vol. 3, pp. 155–181.

[69] J. Chen and Q. Zhu, “Interdependent strategic security risk management
with bounded rationality in the Internet of things,” IEEE Transactions
on Information Forensics and Security, vol. 14, no. 11, pp. 2958 –
2971, 2019.

[70] R. Zhang, Q. Zhu, and Y. Hayel, “A bi-level game approach to
attack-aware cyber insurance of computer networks,” IEEE Journal on
Selected Areas in Communications, vol. 35, no. 3, pp. 779–794, 2017.
[71] Y. Hayel and Q. Zhu, “Attack-aware cyber insurance for risk sharing
in computer networks,” in International Conference on Decision and
Game Theory for Security. Springer, 2015, pp. 22–34.

[72] J. Chen and Q. Zhu, “Security as a service for cloud-enabled internet of
controlled things under advanced persistent threats: a contract design
approach,” IEEE Transactions on Information Forensics and Security,
vol. 12, no. 11, pp. 2736–2750, 2017.

[73] J. Pawlick, J. Chen, and Q. Zhu, “iSTRICT: An interdependent strategic
trust mechanism for the cloud-enabled Internet of controlled things,”
IEEE Transactions on Information Forensics and Security, vol. 14,
no. 6, pp. 1654–1669, 2018.

[74] J. Chen and Q. Zhu, “Optimal contract design under asymmetric infor-
mation for cloud-enabled internet of controlled things,” in International
Conference on Decision and Game Theory for Security.
Springer,
2016, pp. 329–348.

[75] S. S. Craciunas, A. Haas, C. M. Kirsch, H. Payer, H. R¨ock,
A. Rottmann, A. Sokolova, R. Trummer, J. Love, and R. Sengupta,
“Information-acquisition-as-a-service for cyber-physical cloud comput-
ing,” in Proceedings of the 2nd USENIX conference on Hot topics in
cloud computing. USENIX Association, 2010, pp. 14–14.

[76] J. Chen and Q. Zhu, “Security as a service for cloud-enabled internet of
controlled things under advanced persistent threats: a contract design
approach,” IEEE Transactions on Information Forensics and Security,
vol. 12, no. 11, pp. 2736–2750, 2017.

[77] N. Nissim, A. Cohen, C. Glezer, and Y. Elovici, “Detection of malicious
pdf ﬁles and directions for enhancements: A state-of-the art survey,”
Computers & Security, vol. 48, pp. 246–266, 2015.

[78] S. Farhang, M. H. Manshaei, M. N. Esfahani, and Q. Zhu, “A dynamic
bayesian security game framework for strategic defense mechanism
design,” in International conference on decision and game theory for
security. Springer, 2014, pp. 319–328.

[79] A. Ghafouri, W. Abbas, A. Laszka, Y. Vorobeychik, and X. Koutsoukos,
“Optimal thresholds for anomaly-based intrusion detection in dynami-
cal environments,” in International Conference on Decision and Game
Theory for Security. Springer, 2016, pp. 415–434.

[80] M. O. Sayin, H. Hosseini, R. Poovendran, and T. Bas¸ar, “A game theo-
retical framework for inter-process adversarial intervention detection,”

in International Conference on Decision and Game Theory for Security.
Springer, 2018, pp. 486–507.

[81] Q. Zhu, H. Tembine, and T. Bas¸ar, “Heterogeneous learning in zero-
sum stochastic games with incomplete information,” in IEEE confer-
ence on decision and control (CDC), 2010, pp. 219–224.

[82] A. Gupta, C. Langbort, and T. Bas¸ar, “Optimal control in the presence
of an intelligent jammer with limited actions,” in IEEE Conference on
Decision and Control (CDC), 2010, pp. 1096–1101.

[83] Y. Li, L. Shi, P. Cheng, J. Chen, and D. E. Quevedo, “Jamming attacks
on remote state estimation in cyber-physical systems: A game-theoretic
approach,” IEEE Transactions on Automatic Control, vol. 60, no. 10,
pp. 2831–2836, 2015.

[84] R. K. Mallik, R. A. Scholtz, and G. P. Papavassilopoulos, “Analysis of
an on-off jamming situation as a dynamic game,” IEEE Transactions
on Communications, vol. 48, no. 8, pp. 1360–1373, 2000.

[85] A. Mukherjee and A. L. Swindlehurst, “Jamming games in the mimo
wiretap channel with an active eavesdropper,” IEEE Transactions on
Signal Processing, vol. 61, no. 1, pp. 82–91, 2012.

[86] J. Pawlick, E. Colbert, and Q. Zhu, “Modeling and analysis of leaky
deception using signaling games with evidence,” IEEE Transactions
on Information Forensics and Security, vol. 14, no. 7, pp. 1871–1886,
2018.

[87] Y. Huang and Q. Zhu, “Deceptive reinforcement learning under ad-
versarial manipulations on cost signals,” 2019 Conference on Decision
and Game Theory for Security, 2019.

[88] J. Zheng and D. A. Casta˜n´on, “Dynamic network interdiction games
with imperfect information and deception,” in IEEE Conference on
Decision and Control (CDC), 2012, pp. 7758–7763.

[89] Q. Zhu, A. Clark, R. Poovendran, and T. Bas¸ar, “Deceptive routing
games,” in IEEE Conference on Decision and Control (CDC), 2012,
pp. 2704–2711.

[90] L. Huang and Q. Zhu, “Adaptive honeypot engagement through rein-
forcement learning of semi-markov decision processes,” International
Conference on Decision and Game Theory for Security, 2019.
[91] A. Hoehn and P. Zhang, “Detection of covert attacks and zero dynamics
attacks in cyber-physical systems,” in American Control Conference
(ACC), 2016, pp. 302–307.

[92] A. Laszka, B. Johnson, and J. Grossklags, “Mitigation of targeted
and non-targeted covert attacks as a timing game,” in International
Conference on Decision and Game Theory for Security.
Springer,
2013, pp. 175–191.

[93] Y. Huang and Q. Zhu, “A differential game approach to decentralized
virus-resistant weight adaptation policy over complex networks,” IEEE
Transactions on Control of Network Systems, to appear, 2019.
[94] J. Chen, Q. Zhu, and T. Bas¸ar, “Dynamic contract design for systemic
cyber risk management of interdependent enterprise networks,” arXiv
preprint arXiv:1908.04431, 2019.

[95] H. Cavusoglu, S. Raghunathan, and W. T. Yue, “Decision-theoretic
and game-theoretic approaches to it security investment,” Journal of
Management Information Systems, vol. 25, no. 2, pp. 281–304, 2008.
[96] M. El Chamie and T. Bas¸ar, “A zero-sum game between the network
designer and an adversary in consensus protocols,” in Advances in
dynamic and evolutionary games. Springer, 2016, pp. 117–137.
[97] M. Pirani, E. Nekouei, S. M. Dibaji, H. Sandberg, and K. H. Johansson,
“Design of attack-resilient consensus dynamics: A game-theoretic
approach,” in European Control Conference (ECC), 2019, pp. 2227–
2232.

[98] J. Chen and Q. Zhu, A Game-and Decision-Theoretic Approach to
Springer,

Resilient Interdependent Network Analysis and Design.
2020.

[99] J. Chen, C. Touati, and Q. Zhu, “A dynamic game approach to
strategic design of secure and resilient infrastructure network,” IEEE
Transactions on Information Forensics and Security, vol. 15, pp. 462–
474, 2020.

[100] L. Huang, J. Chen, and Q. Zhu, “A large-scale markov game approach
to dynamic protection of interdependent infrastructure networks,” in
International Conference on Decision and Game Theory for Security.
Springer, 2017, pp. 357–376.

[101] ——, “Factored markov game theory for secure interdependent infras-
tructure networks,” in Game Theory for Security and Risk Management.
Springer, 2018, pp. 99–126.

[102] J. Chen and Q. Zhu, “A game-theoretic framework for resilient and
distributed generation control of renewable energies in microgrids,”
IEEE Transactions on Smart Grid, vol. 8, no. 1, pp. 285–295, 2016.
[103] Y. Zhao, L. Huang, C. Smidts, and Q. Zhu, “Finite-horizon semi-
markov game for time-sensitive attack response and probabilistic

ARXIV, OCTOBER 2019

13

risk assessment in nuclear power plants (under review),” Reliability
Engineering and System Safety, 2019.

[104] V. Kurian, J. Chen, and Q. Zhu, “Electric power dependent dynamic
tariffs for water distribution systems,” in Proceedings of
the 3rd
International Workshop on Cyber-Physical Systems for Smart Water
Networks. ACM, 2017, pp. 35–38.

[105] L. Huang, J. Chen, and Q. Zhu, “A large-scale markov game approach
to dynamic protection of interdependent infrastructure networks,” in
International Conference on Decision and Game Theory for Security.
Springer, 2017, pp. 357–376.

[106] J. Chen and Q. Zhu, “Control of multi-layer mobile autonomous
systems in adversarial environments: A games-in-games approach,”
IEEE Transactions on Control of Network Systems, submitted, 2019.

[107] J. Chen, C. Touati, and Q. Zhu, “Optimal secure two-layer IoT network
design,” IEEE Transactions on Control of Network Systems, to appear,
2019.

[108] L. Huang and Q. Zhu, “A dynamic games approach to proactive
defense strategies against advanced persistent threats in cyber-physical
systems,” 2019. [Online]. Available: http://arxiv.org/abs/1906.09687

[109] S. M. Milajerdi and M. Kharrazi, “A composite-metric based path
selection technique for the tor anonymity network,” Journal of Systems
and Software, vol. 103, pp. 53–61, 2015.

[110] J. Chen and Q. Zhu, “A linear quadratic differential game approach
to dynamic contract design for systemic cyber risk management under
asymmetric information,” in Annual Allerton Conference on Commu-
nication, Control, and Computing (Allerton), 2018, pp. 575–582.

