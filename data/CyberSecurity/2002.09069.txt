0
2
0
2

b
e
F
1
2

]

R
C
.
s
c
[

1
v
9
6
0
9
0
.
2
0
0
2
:
v
i
X
r
a

Optimizing Vulnerability-Driven Honey Trafﬁc Using Game Theory

Iffat Anjum1, Mohammad Sujan Miah2, Mu Zhu1, Nazia Sharmin2,
Christopher Kiekintveld2, William Enck1, Munindar P Singh1
1 North Carolina State University,
Raleigh, NC 27695
{mzhu5, ianjum, mpsingh, whenck}@ncsu.edu
2 The University of Texas at El Paso,
El Paso, TX 79968
{msmiah@miners., nsharmin@miners., cdkiekintveld@}utep.edu

Abstract

Enterprises are increasingly concerned about adver-
saries that slowly and deliberately exploit resources over
the course of months or even years. A key step in this
kill chain is network reconnaissance, which has his-
torically been active (e.g., network scans) and there-
fore detectable. However, new networking technology
increases the possibility of passive network reconnais-
sance, which will be largely undetectable by defend-
ers. In this paper, we propose Snaz, a technique that
uses deceptively crafted honey trafﬁc to confound the
knowledge gained through passive network reconnais-
sance. We present a two-player non-zero-sum Stack-
elberg game model that characterizes how a defender
should deploy honey trafﬁc in the presence of an adver-
sary who is aware of Snaz. In doing so, we demonstrate
the existence of optimal defender strategies that will ei-
ther dissuade an adversary from acting on the existence
of real vulnerabilities observed within network trafﬁc, or
reveal the adversary’s presence when it attempts to un-
knowingly attack an intrusion detection node.

1

Introduction
Advanced Persistent Threats (APTs) are a signiﬁcant
concern for enterprises. In such scenarios, advanced ad-
versaries take slow and deliberate steps over months and
even years to compromise critical resources (e.g., work-
stations and servers) in a network. A key step in the kill
chain of APTs is reconnaissance. Historically, recon-
naissance is largely active, for example using network
port scanning to identify which hosts are running which
services. In response, many enterprises closely monitor
their networks for scanning attacks.

Simultaneously, Software Deﬁned Networking
(SDN) technology is emerging as a powerful primitive
for enterprise network security. SDN offers a global
perspective on network communications between
hosts. It can be used as an enhanced tool to identify
network scanning, provide ﬂexible access control to
mitigate attackers bypassing defenses such as ﬁrewalls,
the increased
and even prevent spooﬁng. However,

Copyright c(cid:13) 2020, Association for the Advancement of Arti-
ﬁcial Intelligence (www.aaai.org). All rights reserved.

functionality within network elements (e.g., switches)
makes them a target for attack. A compromised SDN
switch is particularly dangerous, because it can perform
reconnaissance passively. As a result, defenders may
have little to no signal that an APT is in process.

We propose Snaz (”snag and zap”) to address the
threat of passive network reconnaissance. Snaz uses
honey trafﬁc: fake ﬂows deceptively crafted to make a
passive attacker think speciﬁc resources (e.g., worksta-
tions and servers) exist and have speciﬁc un-patched,
vulnerable software. Snaz assumes the adversary knows
about the possibility of honey trafﬁc and uses game the-
ory to characterize how best to send honey trafﬁc. For
doing so, we demonstrate how a defender can either
successfully deﬂect or deplete an adversary using op-
timal amount of honey trafﬁc.

Snaz models this defender-attacker interaction as
a two-player non-zero-sum Stackelberg game. In this
game, the defender sends honey trafﬁc to confound the
adversary’s knowledge. However, if the defender sends
too much honey trafﬁc, the network may become over-
loaded. In contrast, the adversary wishes to act on in-
formation obtained using passive reconnaissance (e.g.,
a banner string indicating a server is running a vulner-
able version of Apache). However, if the adversary acts
on information in the honey trafﬁc, it will unknowingly
attack an intrusion detection node and be discovered.
Thus, the game presents an opportunity to design an op-
timal strategy for defense. We make the following pri-
mary contributions:
• We propose Snaz, a technique of using honey trafﬁc
to mitigate the threat of passive network reconnais-
sance. This honey trafﬁc has the potential to dissuade
an adversary from acting on evidence of real vulner-
abilities or more quickly reveal its existence within
the network.

• We model Snaz’s deceptive defense using a two-
player non-zero-sum Stackelberg game. We present
an algorithm for ﬁnding the optimal strategy for de-
ploying honey ﬂows that is fast enough to be used for
realistic networks.

• We present an empirical evaluation of the perfor-

1

 
 
 
 
 
 
Table 1: Example of types of information used for attacks

Target Type
Fingerprinting OS

Server software, version,
service type
Network topology,
forwarding logic
Employee Credentials,
personal information

Analysis Space
TTL, Packet Size, DF Flag, SackOk,
NOP Flag, Time Stamp
Default banners

Flow-rule update frequency, controller-
switch communication
Server-client trafﬁc header and data

Examples
Windows 2003 and XP

Apache HTTP 2.2,
Windows Server 2003
Lack of TLS adoption, modiﬁed
ﬂow rules
HTTP trafﬁc, HTTPS trafﬁc
with weak TLS/SSL

mance of our game model solutions under different
conditions, as well as the scalability of the algorithm
and some useful properties of the optimal solutions.

• We emulate Snaz in Mininet(De Oliveira et al. 2014),
also showing the network overhead that results from
honey trafﬁc.

2 Background and Related Work
Enterprise network administrators are increasingly
concerned with Advanced Persistent Threats (APTs)
where adversaries ﬁrst obtain a small foothold within
the network and then stealthily expand their penetra-
tion over the course of months, sometimes years. The
past decade has provided numerous examples of such
targeted attacks, e.g., Carbanak (Group-IB and Fox-IT
2014), OperationAurora (Matthews 2019). Such attacks
require signiﬁcant planning. Initially, adversaries iden-
tify attack vectors including 1) vulnerable servers or
hosts, 2) poorly conﬁgured security protocols, 3) unpro-
tected credentials, and 4) vulnerable network conﬁgu-
rations. To do so, they leverage network protocol ban-
ner grabbing, active port scanning, and passive monitor-
ing (Kondo and Mselle 2014; Bartlett, Heidemann, and
Papadopoulos 2007). Examples of different types of de-
sired information and corresponding attacks are shown
in Table 1.

Software Deﬁned Networking (SDN) has the po-
tential to address operational and security challenges
large enterprise networks (Levin et al. 2014). They pro-
vide ﬂexibility to programmatically and dynamically re-
conﬁguring trafﬁc forwarding within a network (McK-
eown et al. 2008) and provide opportunities for granu-
lar policy enforcement (Kim and Feamster 2013). How-
ever, these more functional network switches form a
large target for attackers as they can provide a foothold
to perform data plane attacks using advanced recon-
naissance and data manipulation and redirection (An-
tikainen, Aura, and S¨arel¨a 2014). Using one or more
compromised switches, an adversary can learn critical
information to mount attacks, including network topol-
ogy and software and hardware vulnerabilities (Benton,
Camp, and Small 2013; Jero et al. 2017).

Deception is an important tactic against adversary re-
connaissance, and there have been a variety of different
approaches that apply game-theoretic analysis to cyber

deception (Pawlick, Colbert, and Zhu 2019). Many of
these previous works have focused on how to effectively
use honeypots (fake systems) as part of a network de-
fense (Carroll and Grosu 2011; Wagener et al. 2009;
P´ıbil et al. 2012; Kiekintveld, Lis`y, and P´ıbil 2015).
This has included work on signaling games where the
goal is to make real and fake systems hard to dis-
tinguish (Miah et al. 2020). Work on security games
(including games modeling both physical and cyber-
security) focuses on deception to manipulate the be-
liefs of an attacker (Yin et al. 2013; An et al. 2011;
Hor´ak, Zhu, and Boˇsansk`y 2017; Thakoor et al. 2019).
Another research (Schlenker et al. 2018) proposes a
game model of deception in the reconnaissance phase
of an attack, though they do not consider honey ﬂows.
Stackelberg game models have been used to ﬁnd opti-
mal strategies for cyber-physical systems (Feng et al.
2017).

3 Overview
This paper proposes Snaz, a deception system de-
signed to mislead or delay the passive reconnaissance
by an adversary. Snaz provides this deception using
honey trafﬁc that is precisely controlled by the defender.
We now give a high level overview of the system and
threat model.

3.1 Snaz

Snaz uses honey trafﬁc to mislead adversaries using
passive network reconnaissance. This deception con-
sists of network ﬂows with fake information, which we
call honey ﬂows. Traditionally, a network ﬂow is deﬁned
as a 5-tuple: source IP, source port, destination IP, des-
tination port, and protocol (e.g., TCP). For simplicity,
we assume honey ﬂows include network ﬂows in both
directions to simulate real network communication.

Honey ﬂows can fake information in network ﬂow
identiﬁers. For example, a honey ﬂow can attempt to
make the adversary believe a non-existent host has a
speciﬁc IP address, or a host is running a server on a
speciﬁc port. Due to the ﬂexible packet forwarding ca-
pabilities of SDN, the defender can route honey ﬂows
through any path it chooses, e.g., to tempt an adversary
that has compromised a switch on a non-standard path.
Honey ﬂows can fake information in the packet pay-
load itself. For example, network servers often respond

2

mised switches. In doing so, it can learn (1) network
topology and which ports servers are listening to by ob-
serving network ﬂow identiﬁers, (2) about the installed
software versions by observing server and client banner
strings. We assume the adversary can map between ban-
ner strings and known vulnerabilities and their corre-
sponding exploits. We conservatively assume this map-
ping can occur on the switch, or can be done without the
knowledge of the defender. The adversary also has the
capability to initiate new network ﬂows from the switch
while forging the source IP address, as response traf-
ﬁc will ﬂow back through the compromised switch and
terminate as if it was delivered to the real host. Finally,
we assume the adversary is rational and is aware of the
existence of Snaz and that honey trafﬁc may be sent to
fake hosts. However, the adversary does not know the
speciﬁc conﬁguration of Snaz, such as the distribution
of honey trafﬁc.

We assume the defender’s network contains real hosts
with exploitable vulnerabilities. The defender is aware
of some, but not all of these vulnerabilities. For exam-
ple, the defender’s inventory system may indicate the
existence of an unpatched and vulnerable server, but
due to production requirements, the server is not yet
patched. We further assume the defender can identify
valuations of each network asset and approximate the
valuation of the assets to the attacker (e.g., domain con-
trollers that authenticate users are valuable targets). We
assume that the SDN controller and the applications
running on the controller are part of the trusted com-
puting base (TCB). We further assume that the com-
munication between the SDN controller and uncompro-
mised switches is protected and not observable to the
adversary (e.g., via SSL or an out-of-band control net-
work). As a result, the adversary cannot alter the con-
troller conﬁguration or forwarding logic of uncompro-
mised switches. Finally, we assume that the network uti-
lization is not near maximum capacity during normal
operation. However, exceeding honey trafﬁc may cause
congestion and cause network degradation.

4 Game Model
An important question we must answer to deploy
Snaz effectively is how to optimize the honey trafﬁc
created by the system, including how much trafﬁc to
create of different types. This decision must balance
many factors, including the severity of different types
of vulnerabilities, their prevalence on the network, and
the costs of generating different types of honey ﬂows
(e.g., the added network congestion). In addition, a so-
phisticated APT attacker may be aware of the possi-
ble use of this deception technique, so the decisions
should robust against optimal responses to honey traf-
ﬁc by such attackers. Finally, we note that many aspects
of the environment can change frequently; for example,
new zero day vulnerabilities may be discovered that re-
quire an immediate response, or the characteristics of
the real network trafﬁc may change. Therefore, we re-
quire a method for making fast autonomous decisions

Figure 1: Snaz uses honey trafﬁc to mislead adversaries.

with a banner string indicating the version of the soft-
ware, and sometimes even the OS version of the host.
Attackers often use this banner information to identify
unpatched vulnerabilities on the network. Honey ﬂows
can simulate servers with known vulnerabilities, mak-
ing it appear as if there are easy targets. If at any point
the adversary acts on this information (i.e., connects to
a fake IP address), Snaz will redirect the trafﬁc to an
intrusion detection node. Since the intrusion detection
node does not normally receive network connections,
the existence of any trafﬁc directed towards it indicates
the presence of an adversary on the network.

Figure 1 shows a simpliﬁed example of honey ﬂows
causing an adversary to update its belief. The ﬁgure
shows two real hosts: Host 1 with vulnerability type
V 1, and Host 2 is with vulnerability type V 2. The ad-
versary has compromised Switch 2 and observes all
packets passing through it. Without honey trafﬁc, the
adversary can easily identify the vulnerabilities on the
hosts (e.g., via banner strings) and attack them. In the
ﬁgure, Snaz simulates the existence of two fake hosts
(Host 3 and Host 4) using honey trafﬁc. If the adver-
sary is unaware of Snaz, it will probabilistically attack
either Host 3 or Host 4 and be quickly detected. How-
ever, if the adversary is aware of Snaz (the scenario we
consider in this paper), it must keep track of what it be-
lieves is real verses fake information. How the defender
and attacker act is the crux of our game-theoretic model
in Section 4.

3.2 Threat Model and Assumptions

The adversary’s goal is to compromise networked
resources, e.g., workstations and servers, without de-
tection. The adversary does not know what hosts are
on the network or which hosts have vulnerabilities. It
must discover vulnerable hosts using network recon-
naissance. The adversary assumes the defender has de-
ployed state-of-the-art intrusion detection systems that
can identify active network reconnaissance such as net-
work port scanning. However, we assume the adver-
sary has gained a foothold on one or more network
switches (an upper-bound of which is deﬁned by the
model). Using this vantage point, the adversary is able
to inspect all packets that ﬂow through the compro-

3

that can be adjusted quickly.

We propose a game theoretic model to optimize the
honey ﬂow strategy for Snaz. Our model captures sev-
eral of the important factors that determine how ﬂows
should be deployed against a sophisticated adversary,
but it remains simple enough that we can solve it for re-
alistic problems in seconds (see Section 5 for details)
allowing us to rapidly adapt to changing conditions.
Speciﬁcally, we model the interaction as a two-player
non-zero-sum Stackelberg game between the defender
(leader) and an attacker (follower) where the defender
(Snaz) plays a mixed strategy and the attacker plays
pure strategy. This builds on a large body of previous
work that uses Stackelberg models for security (Tambe
2011), including cyber deception using honeypots (P´ıbil
et al. 2012).

d
a
Vi ∈ V

Ri
Hi

Φij

Φ

Ci

υa,r
i

υa,h
i

υd,r
i

υd,h
i

ai

Table 2: Game Notation

defender
attacker
set of i types of vulnerabilities in the net-
work
number of real ﬂows indicating Vi
upper bound on the number of honey
ﬂows indicating Vi
action of selecting j ∈ [0, Hi] honey
ﬂows for Vi
defender’s mixed strategy as the marginal
probabilities over {Φi0, . . . , ΦiHi}
cost of creating each honey ﬂow that indi-
cates Vi
the value the attacker gains from attacking
a real or fake ﬂow of type Vi
the value the defender loses from an at-
tack against a real or fake ﬂow of type Vi
denotes the action of attacking a ﬂow of
type Vi where a0 is the no-attack action,
yielding 0 payoff

that can be created of each type as Ri. The attacker’s
pure strategy ai represents choosing to attack a ﬂow of
type Vi, or not to attack. We assume the attacker cannot
reliably distinguish real ﬂow and honey ﬂow, so an at-
tack on a speciﬁc type corresponds to drawing a random
ﬂow from the set of all real and fake ﬂows of this type.
The utilities for the players depend on which vulnera-
bility type the attacker chooses, as well as on how many
real and honey ﬂows of that type are on the network.
An attack on a real ﬂow will result in a higher value for
the attacker than on a honey ﬂow of the same type, and
vice versa for the defender. Speciﬁcally, if the attacker
chooses type Vi, it gains a utility υa,r
, which is greater
than or equal to the value for attacking a honey ﬂow
of the same type υa,h
(which may be negative or 0).
We assume that this component of the utility function
i = −υa,r
is zero-sum, so the defender’s values are υd,r
and υd,h
. The defender’s utility function in-
cludes a cost term Ci that models the marginal cost of
adding each additional ﬂow of type Vi (for example, the
additional network congestion which can vary depend-
ing on the type of ﬂow). If the defender plays strategy Φ
and the attacker attacks the Vi, the defender’s expected
utility is deﬁned as follows:

i = −υa,h

i

i

i

i

i υd,r

U d(Φ, i) = P r

i + (1 − P r

Here, P r

(1)
i denotes the probability of attacking a vul-
nerability of type Vi which can be calculated as follows:
(cid:88)

i − C h

i )υd,h

RSM N (mc, P ) =

Φij(Ri/(j + Ri))

j∈{0,...,Hi}
The overall cost C h for playing Φ is given by Equa-

tion 1:

(cid:88)

(cid:88)

C h =

(Φij × j × Ci)

i∈V

j∈{0,...,Hi}

Analogously, for the attacker the expected utility is

given by:

U a(Φ, i) = P r

i υa,r

i + (1 − P r

i )υa,h

i

(2)

We now formally deﬁne the strategies and utilities of
the players using the notation listed in Table 2. We as-
sume that the defender is using Snaz as a mitigation for
a speciﬁc set of i vulnerabilities that we label Vi. Every
ﬂow on the network indicates the presence of at most
one of these types of vulnerabilities in a speciﬁc host.
The real network trafﬁc is characterized by the num-
ber of real ﬂows Ri that indicate vulnerability type Vi.
The pure strategies for Snaz are vectors that represent
the number of honey ﬂows that are created that indicate
each type of vulnerability Vi; we write Φij to represent
the marginal pure action of creating j ﬂows of type Vi.
These fake ﬂows do not need to interact with real hosts;
they can advertise the existence of fake network assets
(i.e., honeypots). The defender can play a mixed strat-
egy that randomizes the number of ﬂows of each type
that are created, which we denote by Φ. To keep the
game ﬁnite we deﬁne the maximum number of ﬂows

4.1 Snaz Game Example

Consider a network with two types of vulnera-
the values be υa,r = (10, 20), and
bilities. Let
υa,h = (−5, −10), and the cost of creating honey ﬂow
indicating each type of vulnerability is C = (1, 0.5).
The total number real ﬂows indicating each type of real
vulnerability is R = (5, 5), and the upper bound on
honey ﬂows is H = (2, 3). Thus at most two honey
ﬂows of 1st vulnerability type and three honey ﬂows of
2nd vulnerability type can be created. Now, consider if
the defender plays the following strategy Φ:

In Φ the defender creates one honey ﬂow 50% of the
time and two honey ﬂows 50% of the time with type
1 vulnerability. The defender also creates three honey
ﬂows 100% of the time type 2 vulnerability. The at-
tacker’s best response is to attack vulnerability type 2
with expected utility Ua(Φ, 2) = 8.75, and the defender
utility is Ud(Φ, 2) = −11.75.

4

4.2 Optimal Defender’s Linear Program

Our objective is to compute a Stackelberg equilib-
rium that maximizes the defender’s expected utility, as-
suming that the attacker will also play the best response.
To determine the equilibrium of the game, we formulate
a linear program (LP) where the attacker’s pure strat-
egy a is a binary variable. We create a variable for each
defender’s pure strategy Φi,j, the action of creating j
honey ﬂows for Vi. The following LP computes the de-
fender’s optimal mixed strategy for each type of vul-
nerability under the constraint that the attacker plays a
pure-strategy best response:

max
i∈V

U d(Φ, i) ai

s.t. ai ∈ {0, 1}, Φij ∈ [0, 1]
U a(Φ, i) ai ≥ Ua(Φ, i(cid:48)) ai ∀ i, i(cid:48) ∈ V

(cid:88)

j∈{0,...,Hi}

Φij = 1 ∀Φi ∈ Φ

(cid:88)

i∈V

ai = 1

(3)

(4)

(5)

(6)

In the above formulation the unknown variables
are the defender’s strategy {Φi0, . . . , ΦiHi } for each
Φi ∈ Φ and the attacker’s action ai. Equation 3 is
the objective function of the LP that maximizes the de-
fender’s expected utility. The inequality in Equation 4
ensures that the attacker plays a best response. Finally,
Equation 5 forces the defender strategy to be a valid
probability distribution.

5 Simulations and Model Analysis
We now present some results of simulations based on
our game-theoretic model, as well as with an initial im-
plementation of honey ﬂow generation in an emulated
network environment. We show that the game theory
model can produce solutions that improve over simple
baselines, and can be calculated fast enough to provide
solutions for realistic networks. We also examine how
the optimal solutions change based on the parameters
of the model to better understand the structure of the
solutions and the sensitivity to key parameters of the
decision problem.

5.1 Preliminary Testbed Evaluation

We have constructed a preliminary honey ﬂow sys-
tem in the emulated environment of Mininet (Mininet
2018). We want to show the possibility of generating
plausible honey trafﬁc in an emulated network. And also
want to evaluate the effects of the deception in a more

realistic context. We work on a small topology shown in
Figure 2. As shown in the ﬁgure, we consider four real
and two fake hosts. Some additional parameters:
• Client 1 connects with Server 1, while Client 2 con-
nects with Server 2. In the simulation, each of these
two clients send 500 packets to the servers and re-
ceive corresponding replies.

• The fake clients are connected with the system and
can send packets with fake vulnerabilities to each
other.

• All the links in our simulation are 1 MBit/s band-

width, 10ms delay and 2% probability loss.

• The values assigned to the servers are 2 and real
clients have a value of 1 for both of attacker and de-
fender.

Figure 2: Simple Network Topology used for Mininet
Simulation

We visualize the simulation results with two types
of vulnerabilities in Figure 3. In this test, we increase
the amount of honey ﬂows from the fake clients from
0 to 500 packets. The honey ﬂows from fake client 1
are with vulnerabilities type 1, while fake client 2 sends
honey ﬂows with vulnerabilities type 2. Besides, we ex-
periment with different costs of honey ﬂow generation.
The dashed lines in Figure 3 shows the expected utilities
when generate 1 honey ﬂow with cost 0.001 and solid
lines represent that defender has to endure cost 0.0001
to generate each honey ﬂow.

Figure 3: Defender and attacker utility.

This simulation does not use the game theoretic opti-
mization. However, we can still get the idea that increas-
ing the number of honey ﬂows remarkably reduces the

5

effectiveness of adversarial efforts. Meanwhile, we can
also see that the cost of honey ﬂow generation signiﬁ-
cantly affects the defender utility.

5.2 Snaz Game Theory Solution Quality

Our next set of experiments focuses on evaluating
the solution quality of the proposed Stackelberg game
model for optimizing Snaz honey ﬂows compared to
some plausible baselines, 1) not generating honey ﬂows
at all, 2) using a uniform random policy for generating
honey ﬂows. We average the results over 100 randomly
generated games, each with 5 types of vulnerabilities.
We set the number of real ﬂows for each type to 500 and
the upper bound on the number of honey ﬂows for each
type is uniform randomly generated from [500,1000].
Values are described in the caption, and we vary the
costs of creating ﬂows as shown in the Figure 4.

ate costs the value of the strategic optimization is high-
est, which is the most likely scenario in real applica-
tions.

In our second experiment we consider vulnerabilities
with different values and examine the variation in the
optimal solution as we vary the number of real ﬂows.
We use 5 vulnerabilities with the values of the real sys-
tems (0.8, 0.5, 0.9, 0.6, 1.0) and attacking any fake sys-
tem gives 0. The cost is 0.0005 for all types. The results
in Figure 5 show that the defender’s strategy is to create
more honey ﬂows for the high valued vulnerabilities.
As the number of real ﬂows increases the cost of adding
ﬂows to create a high ratio is substantial and the overall
number created drops for all types.

Figure 5: Defender’s optimal strategy as number of real
ﬂows varies.

5.3 Solution Analysis

We now analyze how the ratio of honey ﬂows to real
ﬂows changes in the optimal solution as we change the
number of real ﬂows. In Figure 6, the network setup
consists of four vulnerabilities with values of (10, 20,
30, 40) and fake ﬂows with values of (9, 18, 27, 32).
The cost of generating each honey ﬂow is 0.1. We show
the defender’s expected utility as we increase the ratio
of honey ﬂows to real ﬂows. Each line represents a dif-
ferent number of real ﬂows in the original game. We
see that the defender utility increases as we add honey
ﬂows, but only up to a point; when the marginal value is
less than the cost the optimal solution is to stop adding
additional ﬂows. We see this in the shape of the curves.
We note that the point where these curves ﬂatten out
is similar across all of the different numbers of real
ﬂows. We can also see this more clearly in Figure 7.
This suggests that the optimal strategy is relatively in-
sensitive to the number of real ﬂows if we consider the
ratio between honey and real ﬂows as the solution. This
means that our solutions are robust to changes in the
number of real ﬂows, and that we can approximate a
solution very quickly without recomputing the full so-
lution as the number of real ﬂows changes.

5.4 Scalability Evaluation

In a practical application of Snaz we would need to
be able to calculate the optimal strategy quickly, since
the network may change frequently leading to different

Figure 4: Comparison of defender utility when the de-
fender uses different values: a) the value of attacking a
fake vulnerability is zero and a real is 1 b) the value of
attacking a fake vulnerability is the same as real value
and the values are randomly generated from [0.5, 1.0].

The results in Figure 4 show that the game theoretic
solution signiﬁcantly outperforms the two baselines in
most settings, demonstrating the value of optimizing the
honey ﬂow generation based on the speciﬁc scenario.
We also note that the cost has a signiﬁcant impact on
the overall result; with a high cost the game theories so-
lution is similar to not generating ﬂows at all (since they
are not very cost effective). Random honey ﬂow gener-
ation can be detrimental for the defender. With a low
cost, the performance of the game theoretic solution is
similar to the uniform random policy; since ﬂows are
so cheap it is effective to create a very large number of
them without much regard to strategy. With intermedi-

6

Figure 6: Utility with varying honey ﬂow ratios

Figure 7: Optimal ratios with varying real ﬂow

game parameters. For example, the number of real ﬂows
will change over time, as will the hosts in the network.
The values of trafﬁc and vulnerabilities, and the speciﬁc
vulnerabilities we are most interested in can change also
(e.g., due to the discovery of new vulnerabilities). We
evaluate the scalability of the basic LP solution for this
game as we increase the size of the game in two key
dimensions: 1) increasing the number of vulnerability
types, and 2) increasing the number of ﬂows.

We randomly generate games holding the other pa-
rameters constant to evaluate the solution time. The re-
sults are shown in Figure 8. Though the solution time
increases signiﬁcantly as we increase the complexity of
the game, we were able to solve realistic size games
with a large number of ﬂows and vulnerability types of
interest within just a couple of seconds using this solu-
tion algorithm. This signiﬁes that we can apply this to
optimize honey ﬂows in realistic size networks with a
fast response rate; with further optimization we expect
that the scalability could be improved signiﬁcantly be-
yond this basic algorithm.

6 Conclusion
We introduced Snaz, a technique that uses decep-
tively crafted honey trafﬁc to confound the knowledge
gained by adversary through passive network reconnais-
sance. We deﬁned a Stackelberg game model for opti-
mizing one of the key elements of Snaz, the quantity and
type of honey ﬂows to create. This model balances cost
and value trade-offs in the presence of a sophisticated
attacker, but can still be solved fast enough to be used

Figure 8: Comparison of computational time when a)
varying the number of vulnerabilities; b) varying the
number of honey ﬂows

in a dynamic network environment. We have evaluated
this model in both a preliminary emulation, as well as
in simulations that explore the properties of the game
theory solutions.

There are a number of ways that this model could
be improved, including incorporating network structure
and variable host values into the analysis, and allow-
ing for more overlap between vulnerabilities and ﬂows
(e.g., ﬂows with more than one vulnerability). We can
consider additional types of honey trafﬁc, such as modi-
fying real ﬂows in deceptive ways. However, these may
come with signiﬁcantly increased computational costs
for ﬁnding solutions, so we will need to develop faster
algorithms to make solving these more complex models
practical for a real implementation.

7 Acknowledgement

This work was supported by the Army Research Of-

ﬁce under award W911NF-17-1-0370.

References

[An et al. 2011] An, B.; Tambe, M.; Ordonez, F.; Shieh,
E.; and Kiekintveld, C. 2011. Reﬁnement of strong
In Twenty-
stackelberg equilibria in security games.
Fifth AAAI Conference on Artiﬁcial Intelligence.
[Antikainen, Aura, and S¨arel¨a 2014] Antikainen, M.;
Aura, T.; and S¨arel¨a, M. 2014. Spook in your network:
Attacking an sdn with a compromised openﬂow switch.
In Bernsmed, K., and Fischer-H¨ubner, S., eds., Secure

7

IT Systems, 229–244. Cham: Springer International
Publishing.
[Bartlett, Heidemann, and Papadopoulos 2007] Bartlett,
G.; Heidemann, J.; and Papadopoulos, C.
2007.
Understanding passive and active service discovery. In
Proceedings of the 7th ACM SIGCOMM Conference on
Internet Measurement (IMC), 57–70. ACM.
[Benton, Camp, and Small 2013] Benton, K.; Camp,
L. J.; and Small, C. 2013. Openﬂow vulnerability
In Proceedings of the Second ACM SIG-
assessment.
COMM Workshop on Hot Topics in Software Deﬁned
Networking, HotSDN ’13, 151–152. New York, NY,
USA: ACM.
[Carroll and Grosu 2011] Carroll, T. E., and Grosu, D.
2011. A game theoretic investigation of deception in
network security. Security and Communication Net-
works 4(10):1162–1172.
S.;
[De Oliveira et al. 2014] De Oliveira, R. L.
Schweitzer, C. M.; Shinoda, A. A.; and Prete, L. R.
2014. Using mininet for emulation and prototyping
In 2014 IEEE Colom-
software-deﬁned networks.
bian Conference on Communications and Computing
(COLCOM), 1–6. IEEE.
[Feng et al. 2017] Feng, X.; Zheng, Z.; Mohapatra, P.;
and Cansever, D. 2017. A stackelberg game and markov
In International
modeling of moving target defense.
Conference on Decision and Game Theory for Security,
315–335. Springer.
[Group-IB and Fox-IT 2014] Group-IB,
2014.
Anunak: Apt against ﬁnancial
https://www.group-ib.com/resources/threat-research/
Anunak APT against ﬁnancial institutions.pdf.
[Hor´ak, Zhu, and Boˇsansk`y 2017] Hor´ak, K.; Zhu, Q.;
and Boˇsansk`y, B. 2017. Manipulating adversary’s be-
lief: A dynamic game approach to deception by design
for proactive network security. In International Confer-
ence on Decision and Game Theory for Security, 273–
294. Springer.
[Jero et al. 2017] Jero, S.; Bu, X.; Nita-Rotaru, C.;
2017.
Okhravi, H.; Skowyra, R.; and Fahmy, S.
BEADS: Automated attack discovery in OpenFlow-
based SDN systems. In Proceedings of the International
Symposium on Research in Attacks, Intrusions, and De-
fenses (RAID), volume 10453 of LNCS, 311–333.
[Kiekintveld, Lis`y, and P´ıbil 2015] Kiekintveld,
C.;
Lis`y, V.; and P´ıbil, R. 2015. Game-theoretic foun-
dations for the strategic use of honeypots in network
security. In Cyber Warfare. Springer. 81–101.
[Kim and Feamster 2013] Kim, H., and Feamster, N.
2013.
Improving network management with software
deﬁned networking. IEEE Communications Magazine
51(2):114–119.
[Kondo and Mselle 2014] Kondo, T. S., and Mselle, L. J.
2014. Penetration testing with banner grabbers and
packet sniffers. Journal of Emerging Trends in com-
puting and information sciences 5(4).

and Fox-IT.
institutions.

8

2019.

[Levin et al. 2014] Levin, D.; Canini, M.; Schmid, S.;
Schaffert, F.; and Feldmann, A. 2014. Panopticon:
Reaping the beneﬁts of incremental SDN deployment in
enterprise networks. In 2014 USENIX Annual Technical
Conference (USENIX ATC 14), 333–345. Philadelphia,
PA: USENIX Association.
[Matthews 2019] Matthews, T.
Operation
Aurora – 2010’s major breach by Chinese hack-
ers.
https://www.exabeam.com/information-security/
operation-aurora/.
[McKeown et al. 2008] McKeown, N.; Anderson, T.;
Balakrishnan, H.; Parulkar, G.; Peterson, L.; Rexford,
J.; Shenker, S.; and Turner, J. 2008. Openﬂow: Enabling
innovation in campus networks. SIGCOMM Comput.
Commun. Rev. 38(2):69–74.
[Miah et al. 2020] Miah, M. S.; Gutierrez, M.; Veliz, O.;
Thakoor, O.; and Kiekintveld, C. 2020. Concealing
cyber-decoys using two-sided feature deception games.
In Proceedings of the 53rd Hawaii International Con-
ference on System Sciences.
[Mininet 2018] Mininet. 2018. Mininet an instant vir-
tual network on your laptop (or other pc). http://mininet.
org/.
[Pawlick, Colbert, and Zhu 2019] Pawlick, J.; Colbert,
E.; and Zhu, Q. 2019. A game-theoretic taxonomy and
survey of defensive deception for cybersecurity and pri-
vacy. ACM Computing Surveys (CSUR) 52(4):82.
[P´ıbil et al. 2012] P´ıbil, R.; Lis`y, V.; Kiekintveld, C.;
Boˇsansk`y, B.; and Pˇechouˇcek, M. 2012. Game theo-
retic model of strategic honeypot selection in computer
networks. In International Conference on Decision and
Game Theory for Security, 201–220. Springer.
[Schlenker et al. 2018] Schlenker, A.; Thakoor, O.; Xu,
H.; Fang, F.; Tambe, M.; Tran-Thanh, L.; Vayanos, P.;
and Vorobeychik, Y. 2018. Deceiving cyber adver-
In Proceedings
saries: A game theoretic approach.
of the 17th International Conference on Autonomous
Agents and MultiAgent Systems, 892–900.
Interna-
tional Foundation for Autonomous Agents and Multi-
agent Systems.
[Tambe 2011] Tambe, M. 2011. Security and game
theory: algorithms, deployed systems, lessons learned.
Cambridge university press.
[Thakoor et al. 2019] Thakoor, O.; Tambe, M.; Vayanos,
P.; Xu, H.; and Kiekintveld, C. 2019. General-sum cy-
ber deception games under partial attacker valuation in-
formation. In AAMAS, 2215–2217.
[Wagener et al. 2009] Wagener, G.; Dulaunoy, A.; En-
gel, T.; et al. 2009. Self adaptive high interaction hon-
eypots driven by game theory. In Symposium on Self-
Stabilizing Systems, 741–755. Springer.
[Yin et al. 2013] Yin, Y.; An, B.; Vorobeychik, Y.; and
Zhuang, J. 2013. Optimal deceptive strategies in secu-
rity games: A preliminary study. In Proc. of AAAI.

