9
1
0
2

l
u
J

0
2

]

R
C
.
s
c
[

2
v
8
5
9
9
0
.
5
0
9
1
:
v
i
X
r
a

CHARACTERIZING CERTAIN DNS DDOS ATTACKS

A PREPRINT

Renée Burton
Cyber Intelligence
Infoblox
rburton@infoblox.com

July 23, 2019

ABSTRACT

This paper details data science research in the area of Cyber Threat Intelligence applied to a speciﬁc
type of Distributed Denial of Service (DDoS) attack. We study a DDoS technique prevalent in the
Domain Name System (DNS) for which little malware have been recovered. Using data from a
globally distributed set of a passive collectors (pDNS), we create a statistical classiﬁer to identify
these attacks and then use unsupervised learning to investigate the attack events and the malware that
generates them. The ﬁrst known major study of this technique, we discovered that current attacks
have little resemblance to published descriptions and identify several previously unpublished features
of the attacks. Through a combination of text and time series features, we are able to characterize the
dominant malware and demonstrate that the number of global-scale attack systems is relatively small.

1

Introduction

In the ﬁeld of Cyber Security, there is a rich history of characterizing malicious actors, their mechanisms and victims,
through the analysis of recovered malware1 and related event data. Reverse engineers and threat analysts take advantage
of the fact that malware developers often unwittingly leave ﬁngerprints in their code through the choice of libraries,
variables, infection mechanisms, and other observables. In some cases, the Cyber Security Industry is able to correlate
seemingly disparate pieces of information together and attribute malware to speciﬁc malicious actors. Identifying a
speciﬁc technique or actor involved in an attack, allows the Industry to better understand the magnitude of the threat and
protect against it. The study of cyber actors, their motives and mechanisms, falls within Cyber Threat Intelligence, an
area traditionally dominated by security analysts utilizing deep domain expertise, but increasingly open to data science
methodologies. The malware itself is critical to the vast majority of work of this type.

In this paper, we address a class of Distributed Denial of Service (DDoS) attacks for which malware is rarely obtained,
but which remains a persistent presence on the Internet. Motivated by the need to help threat analysts more easily
identify and characterize threats, the results of this research demonstrate a dramatic change in these attacks in recent
years, made visible through statistical analysis and unsupervised machine learning. Leveraging over six months of real
data, we identify a number of features that allow us to cluster the majority of attacks into a handful of families and in
some cases completely reverse the algorithm for generating the attack. Data analysis shows that actors have changed
their modus operandi, making detection and correction more difﬁcult for Internet providers. We developed a highly
accurate statistical classiﬁer to identify the attacks and engineered features not previously mentioned in the literature,
some of which may apply to other cyber problems.

The attack, known as a Slow Drip, Random Subdomain, and Water Torture Attack, among other names, targets the
Domain Name System (DNS), a globally distributed database that provides critical functionality for the Internet. First
observed in 2009 [17], the attacks emerged with tremendous strength in early 2014. While their scale has varied
tremendously, they remain a daily ﬁxture of the cyber landscape today. The DNS community has focused primarily
on mitigation of ongoing attacks, largely through scaling the ability of systems to handle additional load. Research

1We use the term malware here to mean the software used for malicious means, not limited to such software on compromised

devices.

 
 
 
 
 
 
that attempted to address detection based on attack characteristics was hindered by the limited reporting available or
focused on single systems. This large-scale study, utilizing current, real data, is the ﬁrst of its kind.

We sought to understand the attack technique, and related malware, as it appears on the Internet today. Speciﬁcally, we
looked to address common threat intelligence questions:

A PREPRINT - JULY 23, 2019

• how many such malware systems exist?
• how can we attribute two attacks to the same malware?
• has the threat landscape evolved over time, and how?
• can we characterize the attack generation algorithms?

Throughout the remainder of this Section, we introduce DNS and the Slow Drip attack technique, discuss prior work,
and provide an overview of our data and methodologies. In Section 3 we review our method for detecting attacks in
passive data and provide a cursory analysis of the attack landscape over a six month period. Section 5 discusses feature
engineering and includes details of a number of novel features of the attacks. Those features are used to cluster attacks
in Section 6, demonstrating that the features are both meaningful and stand over time. The results are examined in the
context of our goals in Section 7. Finally, we discuss ideas for future research.

1.1 The Domain Name System (DNS)

The Domain Name System (DNS) is a global, hierarchical, distributed database which serves, among other things, to
map domain names to Internet Protocol (IP) addresses. While relatively straight forward in concept, in practice the
global DNS is complex to the point of being arcane [10]. For the purpose of this paper, we introduce a limited scope
and vocabulary; the interested reader can ﬁnd more depth in the operation and security of DNS in [15] and [13].

The domain name system operates as a query-response protocol, in which a query for a fully qualiﬁed domain name
(FQDN) is made by a client, or endpoint, and is answered via an iterative process known as resolution. An FQDN is
made up of a series of text labels separated by periods. For example, the FQDN www.google.com has three labels
[’www’, ’google’, ’com’].

From a hierarchical perspective, the right-most label in an FQDN is the top-level-domain (TLD) and the each subsequent
label represents a subdomain of the FQDN created from all the prior labels. For instance www.google.com is a
subdomain of google.com, which in turn is a subdomain of com. The term domain is often used to refer to both an
FQDN and the scope of its possible subdomains. Thus www.google.com, mail.google.com, inbox.google.com,
and photo.google.com are all subdomains of the domain google.com. The TLD is a single label and is considered
public in the sense that its subdomains are available for registration and not controlled by the TLD. The TLDs are
limited in number and controlled by the Internet Corporation for Assigned Names and Numbers (ICANN). In some
cases, subdomains of a TLD are also managed as public domains, most notably domains like co.uk, and are considered
public sufﬁxes and create extended TLDs (eTLD).2 A second-level-domain (SLD) is privately owned and the direct
subdomain of a public sufﬁx, or eTLD. Examples of second-level-domains include google.com and google.co.uk.
The SLD is sometimes referred to as the base domain.

Within the Domain Name System, authoritative name servers are servers which hold authoritative, or deﬁnitive, answers
for a certain portion of the database, generally a speciﬁc domain. If these authoritative servers are not functioning
properly, Internet trafﬁc to the domains for which they are authoritative may be interrupted or completely disrupted. For
this reason, companies often have multiple authoritative name servers for their domains.

While it is possible for an endpoint to resolve DNS queries themselves, in practice, most devices rely on large
recursive resolvers to perform resolution on their behalf. Internet Service Providers provide recursive resolvers for
their customers, for example. Many recursive resolvers are conﬁgured to answer queries only for devices in their
network, thereby limiting the resource demands on those network appliances. There are public resolvers, such as
those operated by Google, openDNS, and Cloudﬂare, designed to handle recursion for any endpoint selecting their
service.3 On the other hand, there are also a large number of devices on the Internet that, through misconﬁguration or
otherwise, will act as recursive resolvers for any client but are not announced as public resolvers. These are known as
open resolvers and are frequently leveraged by cyber actors to anonymize and amplify DDoS trafﬁc.

In another effort to ensure efﬁciency, the Domain Name System employs caching of records at the recursive resolvers.
Caching of records prevents unnecessary Internet trafﬁc by caching the records for popular domain names, such as
www.google.com. For security purposes, many recursive resolvers also employ negative caching, in which they

2A list of public sufﬁxes is maintained by Mozilla and found at publicsufﬁx.org
3Endpoints are typically conﬁgured with at least one recursive resolver to which they forward their queries.

2

A PREPRINT - JULY 23, 2019

Figure 1: Slow Drip Attack Mechanisms

remember, for some short period of time, that a given FQDN has no answer in the DNS. Queries for non-existent
domains typically return what is referred to as an NXDOMAIN response which triggers this form of caching.

1.2 Slow Drip DDoS Attacks

Given the fundamental role the DNS plays in the functioning of the Internet, attackers are known to abuse it. In the
technique considered in this paper, malicious actors generate a massive number of queries for non-existent domains.
Through the resolution process, these queries are forwarded to the authoritative name servers which may become
overwhelmed with the unexpected volume. The attack generates non-existent subdomains of a common SLD, with little
to no repetition in the queries. This serves to counter caching at recursive resolvers and force as much trafﬁc as possible
to the authoritative name servers. All of the queries within an attack will be subdomains of a common SLD, which we
refer to as the attack domain. Authoritative servers may attempt to mitigate an attack in a number of ways, including
dropping requests from recursive resolvers that transmit too many requests.4 In a counter play, attackers may utilize
open resolvers to diffuse their trafﬁc over a large IP space, maximizing transmission paths and reducing the likelihood
of blocked trafﬁc. Some attackers utilize spoofed5 IP addresses in the request packets, which help both anonymize and
diffuse trafﬁc, hindering mitigation.

This attack technique was ﬁrst recorded in 2009 in China [17], and again in a large attack against AFNIC in October
2013 [2]. Beyond these two attacks, there is no indication the technique was actively used until February 2014 when
it became a daily phenomena that disrupted the global DNS and had particularly damaging collateral damage on
Internet Service Provider (ISP) infrastructure [23]. During the early years, the attack used queries for pseudo-random
subdomains of primarily Chinese-owned domains. The terms Random Subdomain attack and Slow Drip, or Water
Torture, attack were derived from these characteristics. While targeted at authoritative name servers, these attacks are
often more damaging to the Internet’s middle infrastructure [20], including recursive resolvers within ISPs, as they
were not provisioned for unusually high trafﬁc volumes. Solutions like response-rate-limiting were designed for use at
the authoritative server, and are less effective at recursive resolvers where the distribution of client IPs may not trigger
such protections even if they were implemented. For practical reasons, most previous analysis of these attacks focused
on mitigation.

While the common domain for an attack is considered the attack domain, the nature of the attack creates a resource
exhaustion of the authoritative name servers, not the attack domain or its Internet resources, such as web pages. Beyond
potentially disabling the authoritative name server from answering legitimate queries, e.g, for their website, the attacked

4This is known as Response Rate Limiting (RRL).
5IP Spooﬁng is the creation of Internet trafﬁc with fake IP addresses.

3

Authoritative  Name Servers open resolvers recursive resolvers Actor-controlledServer FarmConsumer Botnet GloballydistributedresolversﬂoodauthoritativenameserversQueries forseeminglyrandomsubdomainsA PREPRINT - JULY 23, 2019

domain suffers no direct denial of service trafﬁc from these particular attacks. From this perspective, the attack domain
itself does not play a signiﬁcant role in the attack, only the authoritative name server. It is also possible for the attack
domain to be operated by the attacker as a mechanism to target a particular name server.

If a name server’s resources become exhausted, it may be unable to serve any of its customers, regardless of the
requested domain. In reality, many different types of cyber attacks may occur simultaneously, including ones that target
the web servers of the attack domain, for example. In the famous Mirai attacks of 2016, a wide range of attacks were
deployed simultaneously, and in series, against Dyn authoritative name servers, effectively crippling a large number of
popular websites [4]. One of the types of attacks used was Slow Drip. In other cases, malware has been discovered that
contains different DDoS mechanisms for domains known to be attacked via Slow Drip; it seems plausible that these
attacks were used in conjunction with one another [14].

More precisely, an attack consists of queries for a very large number of non-existent FQDNs within a common attack
domain. Queries that are part of the attack will have one or more subdomain labels. If we consider the attack domain
as an SLD, attack_domain, then queries that are part of the attack trafﬁc will have the form:

labeln.labeln−1...label1.attack_domain
The string labeln is referred to as the preﬁx. The attack domain is an SLD, most often containing two labels. The
sufﬁx of an FQDN is the parent domain of that FQDN, determined by removing the preﬁx, and thus of the form
labeln−1...label1.attack_domain. Slow Drip attacks are described in the literature as a set of pseudo-random preﬁxes
of a single sufﬁx [5] [7]. Previous published examples of conﬁrmed attack domains include 111f.com [5] and
www.dafa888.com [2], each of which contained a single pseudo-random label.

(1)

1.3 Prior Work

The vast majority of literature on this speciﬁc type of DDoS attack has focused on detection and mitigation. This
includes methods of determining an ongoing attack from the rate of queries [1] and the randomness of the FQDNs
[22]. In [1] the authors propose an algorithm for identifying ongoing attacks within a recursive resolver or name server
which leverages a ﬁxed size cache to identify domains that are seen frequently and, for the case of Slow Drip attacks,
suddenly frequently. Their solution for inline detection promises to require less resources and afford more timely
identiﬁcation than traditional approaches. In [22], they propose a means to detect attacks based on the queried FQDN
alone and introduce a set of text-based features for this purpose. Unfortunately, this approach made assumptions about
the randomness in the trafﬁc not found in real data and therefore is of limited use operationally.

Only a small percentage of the literature contains analysis of the attack mechanisms and their victims, and none has
undertaken a global study over a long period of time. An early expository [12] studied several months of trafﬁc from
a personal network in 2014. The author found distinct signatures in the IP packets of an attack and demonstrated
large-scale IP spooﬁng.6 They augmented statistics about the attacks with some investigation of the attack domains,
showing that the majority of these were Chinese owned. Patterns within the characters of attacks were described in
blogpost [7] in 2014.7

In work that considered a several DDoS techniques, Qihoo360 [16] used unsupervised learning to study trafﬁc observed
at honeypot8 sensors in order to understand "who is being attacked by what botnet families under which c2 controllers
with what set of attack parameters". They began tracking DDoS botnet families in 2014 and covered different forms of
DDoS attacks, including two that are DNS-based. Their approach used clustering on packet-level features. One of these
clusters, which they call dns_cls1 is a random subdomain attack. The examples they provide are consistent with those
found by [12] and conﬁrmed by [5] as part of a single attack system.9

In [5], a single DDoS attack system is studied in depth. First documented by [12], this attack system, dubbed
ExploderBot by the authors, was initially seen in February 2014. These attacks were observed almost continuously
through mid-2016, after which their activity was interrupted by multiple long periods of silence. The analysis of [5]
concluded that:

• the attacks contained a single pseudo-random alphabetic label of length 1-16 which followed a precise pattern,
• the trafﬁc was not generated by a consumer-device botnet,
• the packets utilized very-large scale IP spooﬁng,

6The primary source for this analysis was ICMP error messages, which allowed the author to make inferences about the attack

over time.

7We are able to verify that the attacks discussed in the blog are all related to the actor discussed in [5].
8A honeypot is a server set up as a decoy to lure cyber actors and to detect, deﬂect or study cyber attacks.
9In [16], they also claim that these preﬁxes are consistent with the Elknot/BillGates malware.

4

A PREPRINT - JULY 23, 2019

• the attacks did not appear to favor open resolvers to diffuse trafﬁc, and
• the attacks were the work of a single actor.

The vast majority of domains either had Chinese-operated authoritative names servers or were registered in China [5] [12].
We independently conﬁrmed the pseudo-random attack pattern and the attack tempo seen in [5], [12], and [7] using
historic data from 2016-2017.

In the vast majority of reporting on Slow Drip DDoS attacks, the examples cited to demonstrate the attacks can be tied
back to the ExploderBot system. The Mirai malware is also known to contain this technique, as documented in [4], and
uses a twelve-character alphanumeric label. However, the Mirai malware does not transit the DNS normally, instead
sending trafﬁc directly to IP addresses conﬁgured in the malware, and we have not observed this trafﬁc in our data.
Beyond these two systems, little is known about the malware and actors that generate these attacks.

2 Data and Methodologies

By early 2018, threat analysts noted that it was increasingly difﬁcult to determine whether high volume trafﬁc was part
of a Slow Drip attack or due to some other errant Internet phenomena.10 One analyst provided examples of spikes
in AirBnB-related domains that appeared suspicious in terms of their volume and variety, but in which many of the
subdomains could be interpreted as locations in China. In other examples, the subdomains contained a hodgepodge of
unusual, but not random, words. Another analyst highlighted attacks that leveraged domains known to be associated
to the hacker group MageCart. They wondered whether MageCart was branching from credit card theft into the area
of DDoS, or whether some other actor was attacking these domains. Were these attacks related to those seen on the
AirBnB domains, they asked, and were they Slow Drip attacks at all? The extraordinarily large volume and variety of
data makes human analysis time consuming and faulty.

Motivated to reduce the burden on threat analysts in identifying and characterizing the threat of these attacks, we set out
to understand what Slow Drip systems were active and how their techniques, tactics, and protocols (TTP) differed from
those of ExploderBot and Mirai.

2.1 Data Sources

This research relied on two independent accesses to passive DNS (pDNS) records, obtained by recording DNS query-
response events at recursive resolvers and including over twelve billion passively observed records per day. The majority
of the data was collected between large recursive resolvers and authoritative name servers. A smaller source included
data from several open resolvers.11 The data sources included recursive resolvers present on four continents. The
smaller open resolver sources collected approximately 10 million records daily. The data used was obtained over seven
months, from June through November 2018, and again in the month of January 2019.

In order to build a data set for analysis, we developed a statistical classiﬁer, described in Section 3, to identify attacks
within normal trafﬁc. Attacks are detected using events comprised of query-response pairs, aggregated by the SLD. For
each detected attack, we extract the following ﬁelds from all events related to the domain for that day, regardless of
their resolution:

• UTC timestamp of observation,
• fully qualiﬁed domain name (FQDN, qname),
• query type (qtype),
• response code (rcode)

While [5] and [12] used other elements of the IP and UDP header, such as the time-to-live and port ﬁelds, these were
not available to us.12

2.2 Collection Bias and Noise

Collection bias, also called observation bias, is a potential source of problems for this type of research. Without access
to the actual malware, we infer information based on observable data, which is inherently limited. While our data

10Personal conversations between this author and professional cyber threat analysts.
11These are recursive resolvers which will resolve queries for any client but are not publicly advertised.
12UDP is the User Datagram Protocol used most often to encode DNS queries for transmission.

5

A PREPRINT - JULY 23, 2019

collectors are globally distributed and cover a range of network types, it is possible that large scale attacks still do not
pass our sensors, or occur at volumes too low for our detector threshold. As we attempt to study attacks over time, our
collection is also susceptible to changes in the underlying trafﬁc due to variability in Internet routing, among other
reasons.

We also have to contend with a wide range of noise in the data. DNS trafﬁc is naturally prone to noisy data, as queries
are passed through the resolution process largely unchecked until they reach the authoritative server. The multitude
of applications running on endpoints can create illegitimate queries.13 Moreover, users can accidentally drive trafﬁc
through the DNS.14 In addition, while we expect a single attack query to create a single event in the data, recursive
resolvers and other devices in the path of the query may replicate the query or even initiate new queries. In some
portions of this analysis, successful resolution of a domain is considered noise in the sense that it further skews the data
and makes analysis more difﬁcult. The impact of noise on our analysis is largely dependent on the popularity of the
domain, as more popular domains are more likely to produce noisy data. The problem of noise was addressed through
normalization and considering only non-resolved queries.

2.3 Methodologies

Attack data was obtained through the creation of a statistical classiﬁer, as described in Section 3, that identiﬁed
anomalies in trafﬁc within and across days. The classiﬁer was tested on previously published attacks that occurred
between January 1st, 2017 and May 31st, 2018 to ensure it’s reliability and the results of newly identiﬁed attacks
manually analyzed. From the resulting detection data, events were summarized into a small set of ﬁelds for the purpose
of analysis and feature engineering.

As detailed in Section 5, exploratory analysis of the resulting attack records led to a number of strong features that
segregated attacks into several distinct groups. While a wide array of potential features were analyzed for their ability to
distinguish attack algorithms from one another, the most promising were derived from lexical and time series analysis,
along with the variety of query types used during an attack. Anomalies in the attack trafﬁc were discovered by measuring
the attack events against a baseline of global DNS trafﬁc over time. Character distributions proved to be particularly
useful in separating attacks. To take advantage of this, archetypal attacks were identiﬁed through unsupervised machine
learning and then used to create a distance measure used in more comprehensive clustering later.

Features were derived using three months of data and clustered as described in Section 6. Finally, to address the
potential of transient features derived from the Summer 2018 data, the same features and cluster analysis was applied to
January 2019 data and the results compared for consistency.

3 Attack Detection

Large-scale Slow Drip attacks are easily detected at the authoritative name server and can sometimes be detected in live
trafﬁc at recursive resolvers with methods like those described in [1]. However, our research is based on passive DNS
analysis. Detecting attacks in passive DNS collection is made difﬁcult by the scale and variety of global DNS trafﬁc,
as well as the nature of the attack. Trafﬁc created by anti-virus products and content delivery networks (CDNs) has
patterns that resemble a number of cyber attacks, including Slow Drip DDoS attacks. Attempts to identify attacks using
simple measures on the FQDN, as in [22] will fail in this environment, creating a large number of false positives, as will
approaches based on measurements of trafﬁc volumes within a day. To overcome these issues, we use both current and
historical data in the detection algorithm.

The detector is a statistical classiﬁer that identiﬁes potential attacks within daily trafﬁc. It contains two stages that
identify anomalous domain activity within a day of pDNS records which is also anomalous in comparison to the
domain’s prior history. To trigger the detector a domain (SLD) must have an unusually high number of unresolved
queries within a day and, additionally, the number of unique subdomains must be abnormal in comparison to the
domain’s recent past.15 To test performance, the classiﬁer was run on historical data covering ten days in 2017 and 2018
for which Slow Drip attacks were reported in [5] and which the openDNS Twitter feed DNSStream contained alerts
for Resource Exhaustion Attacks, generally synonymous for Slow Drip attacks in DNS. The results were manually
reviewed for accuracy.

13Google Chrome is known to create unresolvable pseudo-random queries, for example.
14For example, a user might mistype a website name in their browser.
15We have also observed these attacks against so-called wildcard domains, in which every subdomain is resolved, however, we do

not consider that variation in this study.

6

A PREPRINT - JULY 23, 2019

The detector ﬁrst groups all of the events for a given data source by domain, or SLD, and counts the number of distinct
unresolved queries.16 In the larger data source, the initial twelve billion records is reduced to approximately 225 million
domains. Given the distribution of unresolved query counts across this entire set of domains, we determine the quartiles,
Q1 and Q3, that represent the number of events below which the bottom 25% of domains, and above which the top
25%, lie, respectively. The Inter-Quartile Range (IQR) is deﬁned as Q3 − Q1, and outliers are those domains, d, for
which the number of unresolved queries, N (d), satisﬁes

N (d) > 1.5 ∗ IQR + Q3.

(2)

This formulation identiﬁes a set of domains which have an unusually high number of unresolved queries, with respect
to all other domains on a given day. As concrete examples, on August 1st, 2018, the detector found unusually high
query volumes for uberinternal.com and icelandairlabs.com. When compared to previous day’s volumes,
uberinternal.com had a 5600-fold increase in activity and icelandairlabs.com showed no queries on the prior
day.

Unfortunately, determining statistical outliers in this way is not sufﬁcient for identifying Slow Drip attacks in passive
DNS collection. Used alone, this will lead a number of false positives, particularly resulting from anti-virus product
and content delivery networks. To address this issue, we also compare the trafﬁc with the recent past. Attacks often
cross a date boundary, and detection will be missed if the comparison is only made with the previous day. On the other
hand, it is important to compare recent activity to ensure that the large number of queries represents a true change. For
this reason, we use a two day separation for detection. The second stage of the detector looks for a dramatic increase
in the number of subdomains observed for domains raised during the ﬁrst stage. This is accomplished by computing
the change in the number of unique subdomains between the two dates for all second-level-domains, calculating the
quartiles for the resulting distribution, and determining the outlier threshold analogous to that in Equation 2. Domains
raised in the ﬁrst stage, which are also anomalous in the second stage, are considered likely Slow Drip attacks. As a
concrete example, uberinternal.com showed a 214k-fold increase in the number of subdomains queried between
days.

These two stages create thresholds above which unresolved queries for a domain are considered a Slow Drip attack. The
thresholds for an attack vary for each data source and are dependent on the normal volume observed in that source. The
combination of anomaly detection with historical perspective serves to weed out false positives. In evaluating nearly
two thousand attacks over a six month period, across multiple data sources, no false positives were found. On the other
hand, this approach can have false negatives, that is, it might miss attacks for which we do not observe enough trafﬁc.

In mid-January 2019, the amount of Slow Drip trafﬁc increased dramatically over the previous year. While having
the same characteristics as Slow Drip DDoS attacks, the volume of the activity was much lower than necessary for an
effective denial of service. The domain characteristics were quite similar, however, to others studied in this research.
This activity was noted by top-level-domain administrators, as in [21].17 Unlike large-scale attacks, this activity is much
harder to detect at the authoritative name servers. It is, however, consistently detected by the algorithm discussed here.

4 Attack Landscape

To understand the overall attack landscape, meaning the tempo and general characteristics of Slow Drip attacks, we
analyzed attacks discovered with the detector described in Section 3 over a six month period (June - November 2018),
where an attack was identiﬁed by a domain and a date. During this time, there were 1949 separate attacks detected,
covering 1418 domains, with a median of seven attacks daily and eight days with over twenty-ﬁve targeted domains.
On days with a large number of attacks, the attacks often contained groups of related domains. For example, we found
ten attacks on August 12, 2018 targeting domains related to Western Union. On other days, the relationship between
domains was not readily apparent. The volume of attacks in the open resolver set is, as expected, much smaller, and
with more variance. It includes 221 attacks cover 143 unique domains over the same time period.

We were particularly interested in ﬁnding attacks observable in independent data sources, including data from open
resolvers. The use of open resolvers by attackers makes both detection and source identiﬁcation of attacks more difﬁcult
by distributing the attack.18 Discovering the same attack across sources lends support to the accuracy of our detector
and indicates the likely breadth of an attack. Nearly 100 attacks and a total of 48 domains were observed in multiple
data sources that included at least one open resolver. The inclusion in both sets signiﬁes an actor tactic to leverage open

16We consider all unresolved queries, not just NXDOMAIN responses.
17In a follow on email discussion, the author noted that they had observed this activity at lower levels for approximately one year,

and found it hard to detect.

18These resolvers are not publicly announced as recursive resolvers, but are easily detected by daily scanning of the Internet by

organizations such as Censys.

7

A PREPRINT - JULY 23, 2019

resolvers. The domains in the intersection are both unsurprising, such as airbnb.com, and curious, such as a series of
domains beginning with sc- seen in June 2018 that appear to have no legitimate purpose or common relationship.

In spite of a very strong signature for ExploderBot Slow Drip trafﬁc, we found no attacks of this kind during the
evaluation period. We detect this actor consistently through historical data and so while it remains possible that our data
sources are simply not observing the attacks, it appears more plausible that the actor has remained quiet through the
latter half of 2018.

This research focused on the malware, speciﬁcally the generation of subdomains used in the attacks, and we did not
do an in-depth analysis of the victims. We did ﬁnd a prevalence of high proﬁle domains, such as those owned by
AirBnB, Sony, DotDash, and Toyota present in the attacks. In the ﬁnal clusters, described in Section 6, we see groups
of well-known domains such as these, as well as clusters containing Pharmaceutical and Banking Industry domains. At
the same time, almost 38% of the domains were not in the top one million most commonly observed domains within
our datasets and many showed little sign of normal trafﬁc. Some examples of these domains include nspk.ru and
verimi.de. In these cases, the motivation for a DDoS attack is particularly unclear. In contrast to observations of Slow
Drip attacks in 2014-2015, we did not ﬁnd a preponderance of Chinese domains and name servers.

5 Attack Features

Slow Drip attack trafﬁc is most often described as random subdomains of an attack domain, that is, queries for
non-existent FQDNs of the form

random.attack_domain,

(3)

where random is a single pseudo-random label and attack_domain is an SLD. In some cases, as described in [7], a
second label was observed, leaving queries of the form

random.f ixed_label.attack_domain

(4)

The random label, or preﬁx, is generated by a portion of the malware we call the attack generator. Without a copy
of the malware, it might be impossible to fully determine how speciﬁc attack trafﬁc is generated. Given that attack
generators are software written by individuals, the hope is that the trafﬁc carries the ﬁngerprints of the designer and is
distinct enough that it can be correlated across attacks.19

A feature in machine learning is a measurable characteristic of the data. In clustering, we want to identify features
that are useful for grouping subsets of data and for isolating groups from one another. This is a unsupervised learning
approach, as we don’t know in advance the true nature of the groups, or clusters, and the algorithm learns these
from the data itself. A feature in the data is considered a strong feature if it can reliably separate groups of data,
and a weak feature if it demonstrates a measurable characteristic for separating data, but can’t be used alone to so.
A number of weak features might be combined to reliably separate data. These terms are subjective, but useful in
understanding how features help in the machine learning process. Feature Engineering is the iterative process of
identifying, evaluating, and selecting features. Successful use of machine learning to solve problems is highly reliant on
proper feature engineering, much more so than the choice of the machine learning algorithm itself. Feature engineering
also a laborious process, and researchers often rely on previous work to obtain features for their experiments.

In the case of Slow Drip attacks, little insight into the attack features exist in the literature and that which does was
speciﬁc to certain systems. As a result, we undertook the feature engineering process from scratch. In doing so, we
sought to ﬁnd features of the data that would allow us to group attacks that were likely created by the same algorithm,
that is, the process for creating the attack queries, and that could separate these from unrelated attacks. This process
begins with exploratory data analysis (EDA), in which large random samples of the attack data are analyzed in-depth.
After initial exploratory data analysis, we validated and reﬁned the feature set using the event records from 435 attacks
identiﬁed between June and August 2018. These features were then applied to cluster attacks into related groups.

5.1 Exploratory Data Analysis

During the initial review of the data, it was readily apparent that the structure of these attacks was quite different than
that previously reported, as described in Equations 3 and 4. In this section we provide a brief overview of the results of
Exploratory Data Analsysis (EDA) performed on a sample of attacks, and then dive into the resulting features more
deeply in the sections that follow. The Appendix includes further visualizations and detailed discussion of the feature
engineering process.

19Two different pieces of malware may share the same generator, particularly if it is simplistic, and two different cyber actors may

utilize the same malware for different attacks.

8

A PREPRINT - JULY 23, 2019

Figure 2: The distribution of ﬁrst characters seen in
an attack on hfax.com shows that preﬁxes most often
started with digits.

Figure 3: The distribution of ﬁrst characters seen in
an attack on dollarshaveclub.com shows that pre-
ﬁxes started with letters.

Perhaps most evident in the differences was the use of what appeared to be dictionary terms, rather than, or in addition
to, pseudo-random values in the subdomain labels. Additionally, many of the attacks contained FQDNs with several
labels, in stark contrast to the single pseudo-random label noted in the literature. Here are a few examples:

• ent254.sharepoint.hp.com
• passyourdrugtest.airbnb.com
• ltrefgt.byairbnb.com
• rtx.bjbgp.bjbgp.bjbgp.91y.com
• godoid-028.prod.ap-northeast-1.int.vidible.tv
• www.diskgas.api.csd.bitwala.com

Even this limited set of samples reveals the problems experienced by threat analysts in evaluating suspected Slow Drip
trafﬁc. The preﬁxes can hardly be described as pseudo-random.

When considered in aggregate, the preﬁxes in the sample data had strong characteristics that distinguished one attack
from another, and were unlike pseudo-randomly generated data. This feature was quantiﬁed by creating unigram
character distributions for each attack. This is accomplished by converting all of the preﬁxes observed in an attack to
a set of individual characters, called a unigram, and counting the number of times each character is present in the set,
creating a distribution. The resulting count distributions can be compared, both visually and statistically, for similarity.
As an example, two sample character distributions are shown in Figures 2 and 3. These distributions, derived from
millions of observations, are very clearly distinct.

In the sample data, only a handful of distinct unigram character distributions were present, meaning that attacks used
characters in the preﬁxes proportional to a select few and could be used to separate groups of attacks by the characters
used in their preﬁxes.20 The process of generating unigram character features for use in clustering attacks was a
multi-stage process and is detailed in Section 5.2.

Also notable was the large number of labels commonly seen in normal DNS trafﬁc, such as prod or cloud. A single
attack often included both common terms and a strange assortment of uncommon labels. This exempliﬁed another
challenge for threat analysts in reviewing attack queries. In an effort to determine whether these attacks utilized the
same generators, we extracted very long labels that were present across multiple attacks. Doing so led to a handful
of surprising labels, e.g., 007dapotianmuweijiaomenduchang, common to several seemingly independent attacks.
This led to the hypothesis that an unusual dictionary was used in the construction of some attacks; the resulting features
are described in Section 5.3.

Time series analysis, that is, the analysis of attack events considered in time order, proved one of the most fruitful
approaches to explore features within the sample data. Visualization of various summary statistics of the events

20While we used a single character, or unigram, here, it is common in text-based machine learning problems to create features
based on longer sub-strings, such as bigrams or trigrams. These were not used because the unigram character distribution provided a
strong feature and required less computational resources.

9

A PREPRINT - JULY 23, 2019

illuminated distinguishing characteristics between attacks. As an example, some attacks contained FQDNs with
a wide range of preﬁx lengths and the proportion of each length remained relatively ﬁxed over time, while other
attacks contained only preﬁxes of a ﬁxed length at any given time, as seen in Figure 9. Most prevalent among these
characteristics was the lexicographic ordering of the FQDNs, when considered as a series of strings ordered in time,
in many attacks. Although deriving a quantiﬁable measurement of that feature proved challenging, as discussed in
Section 5.4.

A number of other statistical features were apparent in the data and differed signiﬁcantly from that which would occur
if the attack trafﬁc was similar to Equation 3. For each of our ﬁndings in the exploratory data analysis phase, we
engineered and evaluated features in Spark across a data set including 435 attacks, comprised of over a billion event
records. In the sections that follow, we describe the features in depth and discuss their promise for clustering attacks
into common attack generators.

5.2 Unigram Character Features

To take advantage of the similarity, and differences, observed in character distributions between attacks, we designed a
process that allowed us to measure the difference between unigram character distributions for the preﬁxes in each
attack against a set of ﬁxed distributions, creating a feature that could be computed reliably over time. Given two
distributions, the Jensen-Shannon (J-S) distance [8] is a distance measure with a real number value in the interval
[0, 1], where smaller values indicate that the two distributions are more similar.21 To create a feature to be used in the
ﬁnal clustering of attacks, we ﬁrst used the Jensen-Shannon distance alone to identify a set of archetype attacks. The
distance between two attacks is deﬁned as the J-S distance between their respective distributions. For each of the 435
attacks, unigram character distributions were computed and the pairwise Jensen-Shannon (J-S) distance between these
distributions calculated. We hypothesized that attacks created by the same malware, or attack generator, would have
similar character distributions and therefore small J-S distances. Computing the pairwise distance between all attacks
over time, however, is unwieldy, at best and not an effective feature. Instead we clustered the initial attacks using only
this distance measures and identiﬁed a small set of attacks that represented large clusters. The speciﬁc process for this
feature engineering is described in detail below. This approach does not attempt to represent all attack generators, but
instead provide a statistical feature that measures the distance from a given attack to a handful of other ﬁxed attacks. We
have not seen this approach of converting distribution similarities into a distance metric and then utilized as a clustering
feature described elsewhere in the literature. This section elaborates on the process used to select archetype attacks.

We considered two different unigram distributions for each attack. The ﬁrst was the overall unigram character
distribution of the set of unique preﬁxes, or labeln, over all FQDNs observed in an attack. We refer to this as the
overall character distribution. We also considered the distributions of only the ﬁrst character of each preﬁx within an
attack. We refer to these distributions as char0 distributions. We then consider the underlying dictionary of characters
observed across all the attacks. A total of sixty-six distinct characters were present in the labels across all attacks.22

DBSCAN [9] was used to cluster the attacks via pairwise distances. This algorithm was chosen for clustering attacks by
character distribution because it does not require the number of clusters to be selected apriori and it identiﬁes outliers.
Each cluster is comprised of core points and boundary points. The algorithm has two parameters, eps, which speciﬁes
the distance the algorithm searches for additional cluster members from core points, and min_points, the number of
points that must exist within epsilon range for a point in the cluster to be considered a core point. Any point which is
further than eps away from all others is an outlier. In the application of DBSCAN to the unigram character distributions,
the distance between two attacks is the J-S distance between the associated character distributions.

The goal was to identify tight clusters that might represent attacks created by the same attack generator. For this reason,
we did not attempt to account for all of our data and were unconcerned about outliers.23 The most central distribution
within a cluster became the representative, or archetype. The feature for use in more comprehensive clustering was the
distance of each attack from a small set of archetype attacks.

This approach proved very successful. While the clustering was based on attacks, uniquely identiﬁed by a date
and domain pairing, the clusters effectively represented domains, meaning that a given domain, even if attacked
on several days, was usually found in only one cluster. This is consistent with attacks being created by the same
generator, or set of generators, for a given domain over time. In other words, if we observe attacks against a domain

21The Jensen-Shannon distance between two probability distributions is the square root of the Jensen-Shannon divergence of the

distributions.

22Many of these characters are not valid in DNS, however, the queries will still transit the DNS for resolution.
23Outliers in clustering algorithms are subjective and a result of thresholds applied to deﬁne cluster boundaries. An outlier is any
point that lies outside of all cluster boundaries and can be thought of as points that are dissimilar, according to the features used,
from all others.

10

A PREPRINT - JULY 23, 2019

Figure 4: Clusters of attacks based on the J-S Distance between the char0 distributions.

like uberinternal.com or airbnb.com over several distinct days, the preﬁxes generated have similar character
distributions.

The overall unigram distributions led to four clusters, and using the char0 distributions we found eight clusters containing
more than ten attacks. A visualization of the attacks, clusters, and the points that weren’t labeled, is found in Figure 4.
Attacks that could not be clustered are labeled in the Figure as cluster −1. For each cluster, the archetype attack domain
is noted.

These clusters also picked up sets of related domains, which again is consistent with a single attack generator. As an
example, seen in Figure 6, one cluster includes numerous domains owned by the company AirBnB, e.g., atairbnb.com
and withairbnb.com, but also includes the AirBnB content-delivery-network (CDN), muscache.com. This same
cluster contains numerous domains owned by the media company DotDash24. Another cluster is dominated by a
combination of Pharmaceutical Industry domains and domains registered in Iceland. Each of these clusters represent
attacks over numerous days within the approximately sixty days represented by the data sample. Two clusters contained
domains owned by AirBnB, but that did not overlap; see Figures 5 and 6.

There are a few obvious downsides to this approach of feature engineering. First, we made an assumption that while the
volume of data we observe may vary widely between attacks, our collection perspective relative to the attack generators
is unchanged, and therefore the character distributions from the same attack generator will be relatively consistent over
time. This is a useful but ﬂawed assumption that could lead us to separate attacks that are created by the same generator.
Second, we treat each set of distributions as derived from a single generator. If multiple generators are used during an
attack, each generator will contribute to a mixed character distribution. The expected result is that, in that case, we
observe more clusters than attack generators that truly exist.

24Formerly about.com, DotDash domains include thoughtco.com and lifewire.com, among many others.

11

A PREPRINT - JULY 23, 2019

Figure 5: Sample Cluster derived from the char0 distri-
butions. This cluster contains a distinct set of domains
owned by AirBnB. These attacks have low overlap
with the DNS enumeration list.

Figure 6: Sample Cluster derived from the char0 distri-
butions. This cluster contains a distinct set of domains
owned by AirBnB. These attacks have very high over-
lap with the DNS enumeration list.

Considering character distributions at-scale conﬁrmed our suspicion that most attacks in our dataset do not use a
pseudo-random preﬁx generator. In nearly 450 attacks, only eight of the attacks had distributions similar to a uniform
random distribution. Even in those cases, it wasn’t apparent that the preﬁxes were pseudo-randomly generated.
Attacks on the domain nspk.ru proved to be constructed from incrementally adding sorted characters. For example,
a.nspk.ru, b.nspk.ru,...aa.nspk.ru, ab.nspk.ru, etc. So, while the distribution was the same as a pseudo-
random generator, the attack was not. An attack on the domain verimi.de observed on July 6, 2018 exhibited a nearly
uniform random distribution and was used for a archetype attack for clustering.

Having identiﬁed promising clusters, the most central attack within each of these clusters is determined by the shortest
distance to each other attack within the cluster. The associated distribution for this central attack is the representative
for the cluster and the attack is the archetype for that cluster. In the ﬁnal clustering, one feature is generated for each of
these archetype representatives: the Jensen-Shannon distance between an attack and the archetype. We also included the
distance to the verimi.de attack as a uniform random representative. The distance between cluster centers is shown in
Appendix Figure 14.

5.3 DNS Enumeration

During exploratory data analysis, there was a surprising combination of relatively common labels and seemingly
unrelated and uncommon labels within the same attack. We isolated long labels, greater than twenty characters, which
were present in multiple attacks. These included a strange mix of dictionary-type labels, composite terms, and multiple
languages, such as

• mobilebusinessapplicationdevelopment,

• 007dapotianmuweijiaomenduchang, and

• caracepatmembuatwebsitegratis

Surprisingly, a Google search for one of these terms led to a GitHub repository [19] containing a list of over 420,000
terms culled from DNS, a so-called DNS enumeration list. This kind of list is generated by cyber actors to assist in
reconnaissance and formulating attacks, but the use has not been previously reported in Slow Drip attacks.

We hypothesized one of the attack generators utilized a DNS enumeration list as a dictionary, creating FQDNs during an
attack by picking words from the dictionary and continually appending them as labels. For each attack the intersection
of its labels and the GitHub list was computed. Over 15% of them drew 80% or more of their labels from this dictionary,
all but conﬁrming that some kind of DNS enumeration list was used as a dictionary for an attack generator, given
the volume of unique labels found in attacks. A signiﬁcant number of attacks contained 30-60% overlap, as seen in
Figure 7, which could be consistent with either multiple attack generators in use for those attacks or a larger underlying
dictionary.

Manual inspection of the domains found in each grouping showed correlation with the clustering based on character
distributions. In particular, the two clusters generated by the Jensen-Shannon distance between character distributions
containing AirBnB domains correlated to a high and low inclusion of the DNS enumeration terms in their labels, as
noted in Figures 5 and 6.

12

A PREPRINT - JULY 23, 2019

Figure 7: Percentage of labels per attack that overlap with GitHub DNS enumeration list.

The overlap with the DNS enumeration dictionary is not notable in any of the attacks found in data from open resolvers.
It’s possible that actors using a DNS enumeration dictionary are not leveraging open resolvers in their attacks.

5.4 Time Series Features

We found during the exploratory data analysis phase that when considered as strings in time order, the FQDNs used in
an attack were often in lexicographical order, that is, a query for aa-dev.airbnb.com would be transmitted prior
to one for ab-dev.airbnb.com. However, capturing this observation into a numerically accurate feature is difﬁcult.
For example, an attack that is generated by drawing preﬁxes from a sorted dictionary and create trafﬁc from multiple
locations will be observed as an interleaved set when aggregated in time. The more complex the generator and the more
sources of trafﬁc, the more obscured the original ordering becomes. A number of factors could inﬂuence ordering, in
particular:

• Observations are not directly from the attack generators and may contain the interleaving of the attack trafﬁc

of several devices.

• Internet routing may effect the timing of events at sensors and result in observations that are out of order from

their original creation.

• The sensors themselves are often part of load balanced systems which further diffuse arriving trafﬁc.
• Additional queries may be created by Internet appliances along the routing path, adding noise to the data.
• A large number of events occur every second, the smallest granularity of our observation period, and we are

unable to determine the order in which those are generated.

• It is extremely unlikely all events are observed.

To address these challenges, we approximate the lexicographic ordering by drawing a single event for each sufﬁx25
per second, creating a time series for each sufﬁx. The sufﬁx is ﬁxed because exploratory analysis led to the hypothesis
that subdomains may be created incrementally by increasing the number of labels in the FQDN. Given a ﬁxed sufﬁx,
and a sample for each second, we calculate the percentage of these that are in order. For each attack, the average of
this percentage over all sufﬁxes is an approximate measure of the lexigraphic ordering. We represent this as a ratio of
events in the interval [0, 1], as shown in Figure 8. Somewhat surprisingly, almost no attacks contain randomly ordered

25Recall, the sufﬁx of an FQDN is found by removing the preﬁx, labeln.

13

A PREPRINT - JULY 23, 2019

Figure 8: An approximation of the lexicographic or-
dering of events within attacks estimated by consider-
ing a single FQDN per sufﬁx per second.

Figure 9: Preﬁx lengths observed over time for an
attack against hfax.com. For a ﬁxed sufﬁx, the preﬁx
lengths are initially quite variable, but transition to
length three, and then length four, for extensive time
periods.

preﬁxes. A majority of attacks have strong tendency toward lexicographic ordering, while twenty-seven of the attacks
demonstrate reverse ordering.

Another feature drawn from the exploratory data analysis was the length of each attack. While most attacks were
relatively short, lasting under ﬁfteen minutes, several attacks lasted hours and some nearly a full day. Obtaining an
accurate measure of the attack length was hindered by noise in the trafﬁc and skew in the distribution of events per
minute for each domain. Popular domains are likely to have a constant stream of unresolvable queries, due to factors
such as user typos and the use of content delivery services. Measuring an attack by the number of minutes for which
there were more unresolvable queries than the mean, a common benchmark statistic, led to inaccurate results given
these factors. We found the number of minutes in which attack events exceeded the median number of non-existent
subdomains (NXDOMAIN events) measured over the full day more accurate. This value was used as the attack length
feature in clustering.

Time series analysis indicated there was a reasonable likelihood that multiple attack generators were used in some
attacks. The number of labels and variety of preﬁx lengths observed per second were illuminating. In a small subset of
attacks there were distinct periods of variable behavior. An example of this shown in Figure 9, in which a period of
widely varying preﬁx lengths is followed by long periods, with far greater activity, containing a single preﬁx length
and a smooth transition between lengths. Quantifying these behaviors over all attacks, however, would be extremely
difﬁcult, and these observations were not used in the ﬁnal clustering algorithms.

5.5 Qtype Features

Another striking observation from exploratory data analysis was the use of multiple DNS query types (qtype) during
an attack. This has not been reported previously. As mentioned in Section 1.1, while DNS is most recognized for its
translation of domain names to IP addresses, it can deliver a multitude of other types of information. The type of data
sought is included in the query. For example, a query for type "MX" would request the mail server domain, rather than
the IP address of a domain. While IPv4 address requests, called "A" records, are by far the most common request seen
in DNS trafﬁc, the protocol allows for 65536 different data types. Other commonly seen query types includes the IPv6
address, type "AAAA", and the authoritative name server, type "NS". Slow Drip attacks are known to request IPv4 (A)
records [5].

Many attacks included queries for less common query types, and these occurred in distinct combinations. Six record
types were often simultaneously utilized, though some variations existed. These six record types were query types: 1
(IPv4 address), 5 (CNAME), 12 (PTR), 16 (TXT), 28 (IPv6 address), and 33 (SRV). Of these, PTR, CNAME, and SRV
are the most unusual. We generated qtype features for each of these six by computing the percentage of events in an
attack of each type.

We also observed large queries for a handful of other unexpected qtypes. A comparison of attacks using multiple qtypes
to those with only "A" record queries is shown in Appendix Figure 15. Both the combination of query types and the
subdomains found within each type were rare within normal DNS trafﬁc. From an attacker’s perspective, this variety of
query types serves to further diffuse the attack and ensure that the majority of requests are forwarded to the authoritative
name server.

14

A PREPRINT - JULY 23, 2019

Count Name
1
1
6
1

label_ratio
overlap_ratio
qtype = n
active_min

1
9

lex_ratio
unigram_distn

Description
percentage of unique labels in attack
percentage of label overlap with DNS enumeration dictionary
percentage of query type n records in attack, n in [1, 5, 12, 15, 16, 28, 33, 43]
number of minutes where NXDOMAIN events greater than median of all events per
minute
estimated percentage of lexicographically ascending subdomains
J-S Distance from Unigram Char0 Distribution for these attacks as (date,
attack_domain): (2018-08-13, shave.io), (2018-08-19, informatica.com),
(2018-
(2018-07-24,
08-07,
(2018-08-09,
norwichpharma.com), (2018-08-02, ruckuslbs.com)

centralnic.com),

ecooltra.com),

toyota.com),

(2018-07-31,

(2018-07-12,

verimi.de),

Table 1: Features Used for Clustering Attacks

6 Final Cluster Analysis

An unsupervised learning technique, Hierarchichal Density-based spatial clustering of applications with noise (HDB-
SCAN) [6], an extension of DBSCAN [9], was used to cluster attacks.26 None of the features considers either the date
of the attack or the attacked domain itself, which are the two components used to uniquely label an attack. Thus the
clusters describe attacks that have generative features in common and represent attacks that are likely created by the
same attack generator. This clustering was performed on the set of 435 attacks found from June-August 2018 from
the larger data source and independently applied to the attacks found in the open resolver set for source comparison.
Finally, the same features were used to cluster data from January 2019 to ensure continued relevance of the features and
clusters.

6.1 Feature Set

We used a set of twenty features based on the initial analysis in Section 5. These considered the uniqueness of the domain
labels, their overlap with the DNS enumeration dictionary27, the distance between unigram character distributions and
nine established distributions (including one uniform random distribution), the length of the attack, the variety of query
types (qtype), and an estimate of the lexicographic ordering of the queries. The features are detailed in Table 1. The
correlation of the features is shown in Figure 10. We can also use Uniform Manifold Approximation and Projection
(UMAP) [18] [3] to reduce the features into two-dimensional space for the purpose of visualization. This projection
allows us to visualize how similar attacks are with one another, as seen in Figure 11.

6.2 Results

The clustering revealed nine large groups of attacks, accounting for 279 of the 435 attacks. These clusters and their
dominant features are described in Table 2. A visualization of the clusters is found in Figure 11.28 Attacks that could
not be clustered automatically are in cluster −1 indicated as pale blue points. From the plot we can see that although
the clustering algorithm was unable to include these points into a speciﬁc cluster, in most cases they appear likely to
belong to one of the named clusters. Were the attack generators highly variable, we would observed unclustered, or
outlier, points scattered across Figure 11.

These clusters are similar, but not identical, to those found using only Jensen-Shannon distance between unigram
character distributions, as evidenced by two of the unigram attacks falling into the same cluster, and two others as
outliers. Each cluster crosses a range of dates, but often contains obviously related attack domains. Several smaller
clusters were also apparent, and if we allow clusters as small as ﬁve attacks, the clusters represent 293 of the attacks.
We suspect that a large number of attacks are created by a single system, but also that two generators are in use at the
same time, hindering easy identiﬁcation.

The clustering of attacks found within open resolver data is also illuminating. If we consider attacks that are observed at
both multiple data sources, we ﬁnd that they almost entirely fall within a single cluster, cluster 6 in Table 2, represented

26A minimum cluster size of ten was used.
27Here we mean the list found on GitHub discussed earlier.
28This visualization, and other similar ones in this paper, are generated with Uniform Manifold Approximation and Projection

(UMAP) [18], a means to project high-dimensional data into a smaller space.

15

A PREPRINT - JULY 23, 2019

Figure 10: Correlation of twenty features used for clustering.

by playcanvas.com. Broadening the scope to include common attack domains, and not speciﬁc attacks, the open
resolver attacks primarily fall into two clusters, cluster 6 and cluster 4.

6.3 Resilience to Model Drift

A signiﬁcant potential Achilles heel for machine learning is known as model drift, in which the underlying data
landscape changes and a model that previously performed well begins to fail. In the context of Slow Drip attacks, this
would be the case for any detection based on the assumption of pseudo-random subdomains, for example, as the threat
landscape has evolved. For this reason, models need to be regularly checked for continued relevance to the environment.
The original feature engineering and clustering was computed from data for attacks that occurred in June-August 2018.
We extracted these same features from nine days of attacks in January 2019 to determine whether they remained valid.
During this time there were 106 attacks detected on 83 domains. Far more attacks in this new data set overlapped with
the DNS enumeration list [19], with over 25% of the attacks drawing more than 80% of their labels from the list.

To evaluate the relevance of the features in Table 1 to the new attacks, HDBSCAN was used to cluster the new attacks,
as well as the union of the two datasets. When considered alone, 93 of the new 106 attacks fall into two clusters,
indicating that the features remained relevant for clustering the new data. When combined with the earlier data set,
64 fell into previously deﬁned clusters, indicating stability in the clusters over six months. Most of the attacks in the
January 2019 data fall into cluster 0 in Table 2, while the others fall into cluster 6 and cluster 4.

7 Conclusions

The results of this research and development support both threat analysts and data scientists. An anomaly based statistical
classiﬁer provides a means to detect these attacks with high reliability in both very large-scale and moderate-scale data
environments. Feature engineering led to the discovery of notable characteristics of several generators, including the
use of DNS enumeration dictionaries and unusual query type combinations, that can help analysts recognize patterns in
putative attacks. It further conﬁrmed their concerns that the threat landscape had changed, making the attacks harder to
recognize. Unsupervised machine learning identiﬁed nine major clusters and the associated important features for each
cluster. Moreover, the features remained relevant after six months.

16

A PREPRINT - JULY 23, 2019

Figure 11: Clusters in a sample of 435 attacks using features from Table 1 and labeled with sample domains. Visualiza-
tion via UMAP [3] projection.

No.
0

1

2

3

4
5

6

7

8

11

28

46

47
10

27

55

11

5

5

28

19
9

8

6

Size Days Sample Attack Domains
20

AirBnB-related, Ruckus Wireless

6

DotDash-related

Pharmaceutical Industry and Icelandic

Indonesian domains, universities, pay-
ment sites, Tinder
Toyota, Starbucks, Paypal
dollarshaveclub.com, shave.io

Dominant Features
high DNS overlap, ﬁve qtypes, lex-ascending, moder-
ate attack lengths
redundant labels, one qtype, high DNS enumeration
overlap, short attacks
unique labels, lex-descending, ﬁve qtypes, moderate
length attacks
very lex-ascending, ﬁve qtypes

high label reuse, high DNS overlap, one qtype
no DNS enumeration overlap, one qtype, strong uni-
gram pattern, shorter attacks

12 Western Union, Harrys

starting sc-, AirBnB-related, PlayCanvas moderately duplicated labels, one qtype, no DNS enu-
meration overlap, lex-ascending, strong unigram pat-
tern
~50% label reuse, one qtype, short attacks, high lex-
ascending
one qtype, high lex-ascending, far from unigram mod-
els

crowdshield.com, coupa.com

Table 2: Clusters of at least ten attacks within a dataset of 435 attacks selected over 60 days using twenty features in
Table 1.

17

A PREPRINT - JULY 23, 2019

For data scientists working in Cyber Security, the features described here are markedly different from those commonly
described in the application of machine learning to problems leveraging DNS data. The approaches provide alternate
tools that may apply to a wide range of problems. In particular, while text-based features are frequently used in
the literature, we have not seen the similarity of distributions included. Similarly, the use of query types and the
lexicographical ordering were not seen elsewhere.

In the remainder of this Section we summarize the ﬁndings and our conclusions, organized by the associated threat
intelligence questions.

How is attack trafﬁc generated?

The current threat landscape does not resemble previously described attacks, and, in particular, pseudo-random
subdomains are not prevalent. Only eight of the attacks contained nearly uniformly random character distributions.
Even those attacks didn’t all show signs of pseudo-random generators. There was no evidence of the particular
pseudo-random generator used in the ExploderBot system.

In contrast, many of the attacks appear to be dictionary generated. Over 15% of the attacks appear to be generated
through the use of a DNS enumeration dictionary. That generator appears to traverse the list in lexicographic order and
continually append new labels. While we don’t have the underlying dictionary used, the list includes almost every term
of a 420,000 word list located in a GitHub repository [19]. Other attacks similarly had signiﬁcant overlap with Unix
dictionaries.

When considered as events in time, over 80% of the attacks consisted of FQDNs that were ordered lexicographically, or
alphabetically, rather than randomly. However, we also discovered one cluster of twenty-eight attacks that demonstrated
descending order, shown in Table 2. These ﬁndings are consistent with the use of sorted dictionaries as a source for
generators.

Further, attackers have broadened from the original attack scenario to incorporate multiple query types. This approach
allows them to use the same set of FQDNs with variable query types, assuring the queries are forwarded to the
authoritative server while minimizing the dictionary they might maintain. In doing so, they created a signature in the
choice of qtypes used within an attack.

How many systems are active?

Clustering results indicate that attack generators are limited to a relatively small number of algorithms. Multiple clusters
shown in Table 2 indicate the use of several query types, moreover they contain a combination of uncommon query
types. We suspect that there are commonalities in these generators, even where their subdomain features are distinct,
based on this query type pattern. Combining the clustering results with subject matter expertise, there are likely four to
eight attack generators in use that are able to create global-scale attacks on repeated days. The projection of the twenty
features into two-dimensional space, Figure 11 is consistent with this conclusion.

Some attacks appear to be a composite of multiple generators. Figures 9 and 17 show two examples where we see
abrupt changes in statistical features of the attack. In addition some of the attacks appear to be a composite of a DNS
enumeration dictionary generator and another dictionary source. In addition, rapid changes in the characteristics of the
FQDNs, such as the preﬁx changes seen in Figure 22 were fairly common and often overlapping. Further, the projection
of clusters in Figure 11 shows that many of the attacks that were not clusters lie in between those that were, indicating
they might be a mix of the two cluster generators.

8 Future Work

There are numerous avenues for further research into this area the results of which can help us understand cyber actors
better and may lead to techniques that can be applied to a broader set of problems. In our research, we did not study the
victims, for example, which may further reﬁne our understanding of both the generators and the actors operating these
attacks. One could take a number of graph approaches to these problems, including a study of how the labels form
tightly connected clusters among attacks. Similarly, one could study the qtype distribution across attacks as a bipartite
graph. The projection of the attacks into two dimensions as shown in Figure 4 raises additional questions about the
underlying cause for linear patterns in the projected points.

The incorporation of open resolvers to diffuse an attack as part of an actor’s Techniques, Tactics, and Procedures (TTP)
can help ﬁngerprint their activity. While we looked at global-scale attacks also observed at open resolvers, an in-depth

18

A PREPRINT - JULY 23, 2019

study of focused on attacks observed in open resolvers could shed light on the breadth of actor’s incorporating this
tactic in their attacks.

Finally, techniques to separate multiple generators used during a single attack could help reﬁne our understanding of
both the generator techniques and the actors. Our analysis appeared to indicate multiple generators might be used in
sequence, demonstrated by abrupt changes in the generator over time, as well as concurrently, demonstrated by a mix of
dictionary and crafted labels.

We have not seen distribution distance measures used as a clustering feature in the manner used here. The approach
of comparing character distributions, particularly when combined with reference distributions, scales well and can
be applied to other problems where we have large samples of strings generated through different mechanisms. One
alternate application is in the application to malware utilizing Domain Generation Algorithms (DGA).

The clusters, and respective data, found in Table 2 can be used to create classiﬁers for detected attacks. This would
allow attacks to be labeled and associated with other attacks, while reserving analytic resources to attacks that are not
able to classiﬁed automatically.

Acknowledgments

I’d like to thank the Infoblox Threat Analysts and Cyber Intelligence Director, Sean Tierney, for their insights into the
Slow Drip problem from a threat analyst perspective and help focusing this work for security applications. Nathan
Toporek, an Infoblox Threat Analyst, also helped in early feature engineering. Mike Last provided statistical advice that
helped guide the direction of this research. Laura da Rocha, Chris Heckman, Mike Last, and Cameron Switzer all proved
dedicated reviewers, making the paper clearer and more relevant. This work heavily relied on Open Source Software
and Python libraries, without which research of this complexity would be extraordinarily difﬁcult to accomplish.

19

A PREPRINT - JULY 23, 2019

A APPENDIX: Supporting Visualizations and Additional Features

We’ve included visualizations and further details in the Appendix that might appeal to certain readers interested in the
feature engineering performed. In addition, this appendix includes a number of features we evaluated in the course of
our research but did not use in the ﬁnal clustering.

A.1 Unigram Distributions as Features

Visualizing the similarity, or J-S distance, between distributions, with a heat map, conﬁrms that this distance measure
can be used to separate attacks. The distance between attacks is the J-S distance between the respective character
distributions for each attack, and is in the range [0, 1]. Figure 12 shows a heat map of pairwise distances, with smaller
distances represented by darker pixels. In this random sample of 150 attacks, subsets of similar attacks are seen as
dark groupings along the diagonal.29 Attacks that have dissimilar char0 distributions will have light-colored pixels.
Considering this, in Figure 12 we see a few outlier attacks in the top left, some smaller groups of similar attacks, and a
larger set that shows core similarity with broader distribution.

Figure 12: Pairwise Jensen-Shannon distances be-
tween char0 distributions of preﬁxes in 150 randomly
selected attacks, sorted to clustering of similar distri-
butions.

Figure 13: Relative pairwise Jensen-Shannon distance
between overall unigram distributions of preﬁxes in
150 randomly selected attacks. While clusters exist,
they are far less distinct than those found using the
char0 distributions.

If we compare the char0 distribution similarities with the overall distribution similarities, we see a dramatic difference.
The distance matrix for overall unigram distributions of the same set of 150 attacks is illustrated in Figure 13. Here we
observe much less variance in the distributions.

Recall from Section 5.2 that the attacks were clustered via their char0 distributions and eight clusters identiﬁed, the
centers of which were considered archetype distributions. The distances between these archetype distributions is shown
below in Figure 14. This allows the reader to see that the clusters are reasonably separated, though a few are closer
and are possibly related distributions. As these distributions are later used in clustering all of the attacks, we want to
observe some separation in the data. Our distributions include a nearly uniform random one, generated by an attack on
verimini.de, that is furthest from all other distributions.

A.2 Query Types as Features

Most attacks contained either a single query type, qtype 1, or a speciﬁc, surprising combination of ﬁve query types. In
Figure 15 a scatter plot shows the proportion of qtype 1 queries in attacks. Notice that there are two large groupings,
but also a small set of attacks with a wide degree of variance.

Another observation of the exploratory data analysis, was the transition in some attacks between the use of several
query types to a single query type over time. This phenomena, shown in Figure 17, serves to hinder using the query
type alone as a strong feature. In this case, six query types are used simultaneously for part of the attack, ﬁve in even
proportions, and then a transition occurs to a single query type. This type of phenomena occurs in a small, but notable,
portion of the attacks.

Nearly half of the attacks contained a substantial number of qtype 12 (PTR) records requests. This is particularly
surprising, as PTR records are primarily used to locate a hostname from an IP address in a specially formatted FQDN.

29This visualization also uses agglomerative clustering of the results to sort the attacks.

20

A PREPRINT - JULY 23, 2019

Figure 14: The Jensen-Shannon distances between char0 cluster centers indicates good separation between the clusters.

Figure 15: The relative type distribution between type
1 ("A") record queries and other types over 444 at-
tacks, including small jitter to the x- and y- coordi-
nates to visually separate attack points.

Figure 16: Domains attacked using PTR queries sized
by the number of PTR records observed.

An example of the domains attacked using PTR records are shown in Figure 16. Notably, none of the AirBnB-related
attacks contain PTR records, whereas attacks against universities, e.g., rit.edu, all contain PTR records.

A.3 DNS Enumeration as a Feature

Those attacks containing a very large portion of GitHub DNS Enumeration dictionary [19], contained domains that were
notably different than seen in other features. While byairbnb.com is present, most of the domains are less recognizable,
and quite a few of the larger attacks are against Russian or Chinese domains. Figure 18 shows a word cloud containing
the attacked domains sized by the percentage of overlap between attack preﬁxes and the DNS enumeration dictionary.

While the overlap with this speciﬁc list was present in a substantial number of domains, the true dictionary is unknown.
We attempted to ’bootstrap’ from the attack labels to the underlying dictionary by taking the union of all labels from

21

A PREPRINT - JULY 23, 2019

Figure 17: An example of the distribution of query
types transitioning over time during an attack from six
types to a single type.

Figure 18: Attacked domains, sized by their overlap
with the percentage of preﬁxes found in the DNS
enumeration dictionary.

attacks with greater than an 80% overlap to the GitHub list. This did increase the dictionary size, but not substantially.
More importantly, it didn’t impact the overall distribution of the overlap statistic.

A.4 Attack Length as a Feature

As seen in Figure 19, most attacks are quite short. This is consistent with other studies of DDoS attacks writ large [11].
Accurately estimating the length of an attack using a single computation across domains is difﬁcult due to the variance
in baseline trafﬁc for each domain which creates noise. The common approach of using a mean will be inaccurate due
to the skew within the distribution of events per minute for various types of domains. We evaluated multiple measures,
and ultimately used the number of minutes for which NXDOMAIN responses for a domain were above the median level
for that domain during the day. This measure tends to underestimate attack lengths for rare domains, e.g., hfax.com,
and overestimate lengths of popularly domains, e.g., airbnb.com, but creates a reasonable relative measure. The vast
majority of long-lived attacks are unpopular domains, as measured by global DNS requests over time.

Figure 19: Distribution of attack lengths as measured
by the number of minutes in which nxdomain events
exceeded the median for the attack domain.

Figure 20: Maximum depth of labels observed during
attacks.

A.5 Other Potential Features

We evaluated a wide range of features, many of which had promising characteristics, before settling on those used
in this paper. In this Section, we provide an overview of some of the other features we considered and that might be
relevant for understanding actors and attack generators.

A.5.1 Open Resolvers Usage

While we did not utilize the presence of an attack as an explicit feature in our clustering, the use of open resolvers by an
attacker to diffuse their packets is a tactic that may serve to ﬁngerprint the attack generator. Our results found that the
attacks observed at an open resolver were all within one cluster in Table 2.

22

A PREPRINT - JULY 23, 2019

For attacks created through consumer-based botnets, there is little advantage to using open resolvers and there are
evident risks.30 In many commercial environments, DNS requests to external IP addresses will be blocked, thereby
thwarting an attack emanating from these networks. Additionally, the space of open resolvers changes and the bot
members need to be regularly updated. A simpler solution is to have bot members transmit requests through their
normal recursive resolver. On the other hand, attacks generated from an actor-controlled infrastructure, such as cloud
services provider, beneﬁt from scattering the initial DNS requests across open resolvers without much risk.

Our focus in this research was on global-scale attacks, from which it is relatively difﬁcult to discern how widely open
resolvers are utilized given the natural transit of trafﬁc through the Internet; most of our observations occur at a point
where the connection with the initial request to an open resolver would be lost. A more in-depth look at all attacks
found at various open resolvers may shed further light on generators.

A.5.2 Label Depth

While the Slow Drip is typically characterized as a single random label on a ﬁxed attack domain, as shown in 1, we
found that current attack systems frequently used more labels. The depth of an FQDN is the number of labels it contains.
If we remove the attack domain from each FQDN within an attack, we can consider how many labels, in terms of depth,
were used in the attack. Instead of a single random label, we ﬁnd the most attacks contain more depth, and that eight
labels is particularly common; see Figure 20. The variance seen here indicates that this feature can be used to separate
some of the attacks, however overall it is a weak feature. We also considered averaging the unique levels per minute to
incorporate time, and alternate descriptive statistics such as the variance over time. As seen later in Figure 21, however,
this simple descriptive statistic can obscure strong time series features.

A.5.3 Preﬁx Lengths

Another natural set of features to investigate surround the label or preﬁx lengths. The distribution of these lengths
appears to vary with some consistency across attacks. We examined various descriptive statistics for the preﬁx lengths,
including the standard deviation and co-variance per attack, but ultimately did not use these in our clustering.

A.5.4 Time Series Features

During our data exploration and feature engineering, time series analysis again and again revealed characteristics in the
data not otherwise visible. Some of these features are seen in the main paper, including the lexicographic ordering in
attacks. There were a number of time-related features that we did not capture in our clustering, but found particularly
compelling. Some generators appear to use a ﬁxed number of labels at any time, which changes over the attack, as
seen in Figure 21, presumably from building attack queries by continually appending, or removing, labels. In this
particular example, the number of labels descends in time, but in many other examples it is seen to ascend. This would
be consistent with the use of a dictionary, which is used to select a label, and creating queries by continually appending
labels.

In the same attack shown in Figure 21 on airbnb.com, we ﬁnd that the relative distribution of preﬁx lengths remains
relatively constant over time, even as the number of labels changes. In Figure 22 we see a condensed view of this effect;
for space, we have limited the preﬁx length to twenty. In reality, the longest preﬁx is ﬁfty-ﬁve characters, the maximum
length permissible. This is consistent with with the use of an underlying dictionary.

Features considered to incorporate time series elements of the attacks included averaging descriptive statistics such as
minimum or maximum of different components, e.g., labels or preﬁx lengths, per minute over an attack, as well as
variance and co-variance measures. While promising, these features proved more difﬁcult to assess and scale given the
volume of data and were not used in the ﬁnal clustering. Given the strong time elements in DDoS attacks, improved
approaches to leveraging time series features at scale would likely prove valuable to understanding the malware and
actors.

30By consumer-based botnets, we mean botnets of compromised devices found in a home consumer environment, such as laptops,

phones, and home routers, as well as Internet of Things devices like alarm and lighting systems.

23

A PREPRINT - JULY 23, 2019

Figure 21: The number of labels over time for one
attack on airbnb.com.

Figure 22: Preﬁx lengths over time during one attack
on airbnb.com. The proportion of lengths remains
relatively constant although the volume changes.

References

[1] Yehuda Afek et al. “Efﬁcient Distinct Heavy Hitters for DNS DDoS Attack Detection”. In: arXiv e-prints,

arXiv:1612.02636 (Dec. 2016), arXiv:1612.02636. arXiv: 1612.02636 [cs.CR].

[2] AFNIC. Random qnames - dafa888 DoS attack, presentation on October 2013 attack on AFNIC. DNS-OARC
Brieﬁng on October 2013 attack against AFNIC. 2014. URL: https://indico.dns-oarc.net/event/20/
contributions/278/attachments/242/452/dafa888-DosAttack.pdf.

[3] McInnes et al. “UMAP: Uniform Manifold Approximation and Projection.” In: 3 (2018). DOI: 10.21105/joss.

0086. URL: https://doi.org/10.21105/joss.0086.

[4] Manos Antonakakis et al. “Understanding the Mirai Botnet”. In: USENIX Security Symposium. USENIX

Association, 2017, pp. 1093–1110.

[5] Renée Burton and Cameron Switzer. ExploderBot: A Slow Drip Attack System. National Security Agency
Technical Report. Fort Meade, MD: National Security Agency, Mar. 2018. DOI: 10.13140/RG.2.2.32214.
29760.

[6] Ricardo J. G. B. Campello, Davoud Moulavi, and Joerg Sander. “Density-Based Clustering Based on Hierarchical
Density Estimates”. In: Advances in Knowledge Discovery and Data Mining. Ed. by Jian Pei et al. Berlin,
Heidelberg: Springer Berlin Heidelberg, 2013, pp. 160–172. ISBN: 978-3-642-37456-2.

[7] Emmet Cassidy. A DNS Cache-Busting Technique for DDoS-style Attacks Against Authoritative Name Servers.
character analysis of slow drip attacks. Oct. 2014. URL: https://blog.cloudmark.com/2014/10/07/.
[8] D.M. Endres and J.E. Schindelin. “A New Metric for Probability Distributions”. In: IEEE Transactions on

Information Theory (2003). ISSN: 0018-9448. DOI: 10.1109/TIT.2003.813506.

[9] Martin Ester et al. “A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise”.

In: Proceedings of SIG-KDD (1996).

[10] Bert Hulbert. Herding the DNS Camel. Nov. 2018. URL: https://www.ietf.org/blog/herding- dns-

camel/.

[11] Mattijs Jonker et al. “Millions of Targets Under Attack: A Macroscopic Characterization of the DoS Ecosystem”.
In: Proceedings of the 2017 Internet Measurement Conference. IMC ’17. London, United Kingdom: ACM, 2017,
pp. 100–113. ISBN: 978-1-4503-5118-8. DOI: 10.1145/3131365.3131383. URL: http://doi.acm.org/10.
1145/3131365.3131383.

[12] Michael Joost. About DNS Attacks and Destination Unreachable Reports. access denied errors after September

2017. seminal study of these attacks. Sept. 2014. URL: https://michael-joost.de/dnsterror.html.
[13] Anestis Karasaridis. DNS Security: In-depth Vulnerability Analysis and Mitigation Solutions. 2012. ISBN:

978-0387765457.

[14] Antiy Labs. “A description of Magic Ferret, a.k.a. Weasel, DDOS malware”. In: (Aug. 2017). URL: www.antiy.

com/response/weasel.html.

[15] Cricket Liu and Paul Albitz. DNS and BIND. O’Reilly, 2006. ISBN: 978-0596100575.
[16] Ya Liu. Improve DDoS Botnet Tracking with Honeypots. honeypots are used to get trafﬁc; signatures lead to four

clusters. two are dns. Nov. 2016. URL: https://www.botconf.eu/botconf-2016/.

[17] Ziqian Liu. Lessons Learned from May 19 China’s DNS Collapse. this is the ﬁrst known attack, reported at the
DNS-OARC meeting. 2009. URL: https://www.dns-oarc.net/files/workshop-200911/Ziqian_Liu.
pdf.

24

A PREPRINT - JULY 23, 2019

[18] Leland McInnes, John Healy, and James Melville. “UMAP: Uniform Manifold Approximation and Projection
for Dimension Reduction”. In: arXiv e-prints, arXiv:1802.03426v2 (Dec. 2018). dimensionality reduction for
visualization of data. arXiv: 1802.03426v2. URL: https://arxiv.org/abs/1802.03426v2.

[19] n00py. all wordlists for every dns enumeration tool... ever. forked from haccer/all.txt. July 2018. URL: https:

//gist.github.com/n00py/2cba6990e4dacc52c5536346338f6f1e.

[20] Kei Nishida. Water Torture: A Slow Drip DNS DDoS Attack on QTNet. collateral damage on load balancers
and other infrastructure. 2015. URL: https://www.slideshare.net/apnic/dnswatertortureonqtnet-
1425130417-1425507043.

[21] Random Subdomain Strangeness (DNS-OARC Mailing List). Apr. 2019. URL: https://lists.dns-oarc.

net/pipermail/dns-operations/2019-April/018649.html.

[22] Yuya Takeuchi et al. “Detection of the DNS Water Torture Attack by Analyzing Features of the Subdomain
Name”. In: Journal of Information Processing 24.5 (2016). this paper just detects random strings. it has no
applied experiments to real data., pp. 793–801. DOI: 10.2197/ipsjjip.24.793.

[23] Ralf Weber. Latest Internet Plague: Random Subdomain Attacks. video of talk at UKNOF29. an additional talk

occured at UKNOF31. Sept. 2014. URL: https://www.youtube.com/watch?v=BDa2akVgbLg.

25

