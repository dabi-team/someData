Detecting CAN Masquerade Attacks with Signal
Clustering Similarity

Pablo Moriano∗, Robert A. Bridges†, Michael D. Iannacone†
∗Computer Science and Mathematics Division, †Cyber Resilience and Intelligence Division
Oak Ridge National Laboratory

moriano, bridgesra, iannaconemd
}
{

@ornl.gov

2
2
0
2

r
a

M
1
1

]

R
C
.
s
c
[

2
v
5
6
6
2
0
.
1
0
2
2
:
v
i
X
r
a

Abstract— Vehicular Controller Area Networks (CANs) are
susceptible to cyber attacks of different levels of sophistication.
Fabrication attacks are the easiest to administer—an adversary
simply sends (extra) frames on a CAN—but also the easiest to
detect because they disrupt frame frequency. To overcome time-
based detection methods, adversaries must administer masquer-
ade attacks by sending frames in lieu of (and therefore at the
expected time of) benign frames but with malicious payloads.
Research efforts have proven that CAN attacks, and masquerade
attacks in particular, can affect vehicle functionality. Examples
include causing unintended acceleration, deactivation of vehicle’s
brakes, as well as steering the vehicle. We hypothesize that
masquerade attacks modify the nuanced correlations of CAN
signal time series and how they cluster together. Therefore,
changes in cluster assignments should indicate anomalous be-
havior. We conﬁrm this hypothesis by leveraging our previ-
ously developed capability for reverse engineering CAN signals
(i.e., CAN-D [Controller Area Network Decoder]) and focus
on advancing the state of the art for detecting masquerade
attacks by analyzing time series extracted from raw CAN frames.
Speciﬁcally, we demonstrate that masquerade attacks can be
detected by computing time series clustering similarity using
hierarchical clustering on the vehicle’s CAN signals (time series)
and comparing the clustering similarity across CAN captures
with and without attacks. We test our approach in a previously
collected CAN dataset with masquerade attacks (i.e., the ROAD
dataset) and develop a forensic tool as a proof of concept to
demonstrate the potential of the proposed approach for detecting
CAN masquerade attacks.

I. INTRODUCTION

Modern vehicles are complex cyber-physical systems con-
taining up to hundreds of electronic control units (ECUs).
ECUs are embedded computers that communicate over a (few)
Controller Area Networks (CANs) to help control vehicle
functionality,
including acceleration, braking, steering, and
engine status, among others. CANs are vulnerable to cyber
exploitation, both by adversaries with direct physical access
through the standard on-board diagnostic [OBD] II
(e.g.,

This manuscript has been co-authored by UT-Battelle, LLC, under contract DE-
AC05-00OR22725 with the US Department of Energy (DOE). The US government
retains and the publisher, by accepting the article for publication, acknowledges that
the US government retains a nonexclusive, paid-up, irrevocable, worldwide license to
publish or reproduce the published form of this manuscript, or allow others to do
so, for US government purposes. DOE will provide public access to these results
of federally sponsored research in accordance with the DOE Public Access Plan
(http://energy.gov/downloads/doe-public-access-plan).

Workshop on Automotive and Autonomous Vehicle Security (AutoSec) 2022
24 April 2022, San Diego, CA, USA
ISBN 1-891562-75-4
https://dx.doi.org/10.14722/autosec.2022.23028
www.ndss-symposium.org

port) and remote access (e.g., Bluetooth, 5G). This increasing
connectivity enables more advanced vehicle features at the
expense of expanding the attack surface. By hijacking ECUs,
attackers may stealthily manipulate CAN frames resulting
in life threatening incidents. For example, malicious frame
injection through cellular networks has resulted in unintended
acceleration, vehicle brake deactivation, and rogue steering
wheel turning [1], [2].

CAN attacks are commonly classiﬁed using a three-tiered
taxonomy that includes fabrication, suspension, and masquer-
ade attacks [3], [4]. Fabrication attacks inject extra frames,
whereas suspension attacks remove benign frames; conse-
quently, both categories usually disturb regular frame timing
on the bus and can be accurately detected using time-based
methods [5], [6], [7]. Masquerade attacks require the adversary
to send frames in lieu of (and therefore at the expected time
of) benign frames but with malicious payloads. In masquerade
attacks, adversaries ﬁrst suspend frames of a speciﬁc ID and
then inject spoofed frames that modify the content of the
frames instead of their timing patterns. Hence, masquerade
attacks are the stealthiest CAN attacks.

Masquerade attacks can still be detected because they alter
the regular relationships of a vehicle’s subsystems. Using an
example attack from the ROAD [4] dataset, an adversary that
gains control of the ECU(s) that communicate the wheel speed
signals (four nearly identical signals) can modify the frames to
break the near perfect correlation, which will stop the vehicle
(regardless of the driver’s actions). By understating the regular
relationships of the vehicle’s CAN signals, this condition can
be ﬂagged as anomalous, even if the modiﬁed signals are not
abnormal when considered individually.

The widespread dependence of modern vehicles on CANs,
combined with the security vulnerabilities has been meet with
a push to develop intrusion detection systems (IDSs) for CAN.
Generally, there are two types of IDSs methods: signature and
machine learning (ML). Signature-based methods rely on a
predeﬁned set of rules for attack conditions. Behavior that
matches the expected signature is regarded as an attack [8], [9],
[10]. However, given the heterogeneous nature of the CAN bus
in terms of transmission rates and broadcasting, effective rules
for detecting attacks are difﬁcult to design, which contributes
to high rates of false negatives [11]. In contrast, ML-based
methods proﬁle benign behavior to identify anomalies or
generalized attack patterns when the trafﬁc does not behave

 
 
 
 
 
 
as expected.

In doing this, many ML-based methods leverage the CAN’s
frame payloads [12], [13]. Note that in passenger vehicles,
signals (sensor values communicated in CAN frames) are
encoded into the frame payloads via proprietary (nonpublic,
original equipment manufacturer-speciﬁed) mappings. Some
IDSs operate on the binary payload (raw bits) [12], whereas
others operate on the time series of signal values [13]. Process-
ing the binary payload has a set of associated challenges. First,
there is a semantic gap with respect to the signals encoded in
the payload. This means that a single CAN frame’s payload
usually contains several signals encoded in different formats,
including byte ordering, signedness, label and units, and scale
and offset [14]. Second, detecting subtle masquerade attacks
requires analyzing the payload content because the correlation
between certain signals may change when the frame content is
modiﬁed during an attack; hence, analyzing translated signals
is a promising avenue. Thus, considering the relationship
between signals is important for achieving a more effective
defense against advanced masquerade attacks.

In this work, we propose a forensic framework to decide if
recorded CAN trafﬁc contains masquerade attacks. The pro-
posed framework works at the signal-level and leverages time
series clustering similarity to arrive at statistical conclusions.
In doing so, we use available and readable signal-level CAN
trafﬁc in benign and attack conditions to test our framework.
The results obtained from our evaluation demonstrate the
capability of the proposed framework to detect masquerade
attacks in previously recorded CAN trafﬁc with high accuracy.
Our contributions in this paper are summarized as follows:
• We detail a CAN forensic framework based on time series
clustering similarity for detecting masquerade attacks. The
proposed framework is based on (1) clustering time series
using agglomerative hierarchical clustering (AHC); (2) com-
puting a clustering similarity; and (3) performing hypothesis
testing using the clustering similarity distributions to decide
between benign and attack conditions.

• We perform a sensitivity analysis of detection capabilities
with respect to the type of AHC used. We report our results
and offer possible explanations.

• We evaluate the proposed framework on masquerade attacks
from the ROAD dataset [4]. Evaluation results show very
high effectiveness of detecting attacks of different levels
of sophistication. Our results indicate that
the proposed
forensic framework can be built upon to yield a viable real-
time IDS, but using these results to craft a short-time-to-
detection IDS is future work.

II. RELATED WORK

Our research is informed by past work leveraging time
series signal correlations for context characterization of cyber-
physical systems. Here, we provide an overview of related
work in this area.

Ganesan et al. [15] introduced the notion of using pair-
wise correlations of vehicular sensor readings (e.g., speed,
acceleration, steering) to characterize behavioral context. They

2

used it for cluster analysis to identify distinct driver behaviors
and detect potential attacks. Li et al. [16] leveraged correla-
tions from multiple sensors to train a regression model that
estimates a targeted sensor value. They used the difference
between the estimated and observed sensor values as an
anomaly signature. Sharma et al. [17] proposed to compute
Pearson correlation matrices of geolocation-related signals
(e.g., latitude, longitude, elevation, speed, heading) to estimate
the state of neighboring vehicles and detect location forging
misbehavior based on correlation matrices’ distance. Guo et
al. [18] proposed Edge Computing Based Vehicle Anomaly
Detection, which focuses on analyzing the time and frequency
domains of sensor data to detect anomalies. In the ﬁrst step,
they ﬂag abrupt changes in the correlations of sensor readings
in the time domain as an indication of anomalies. For more
accurate anomaly detection in the second step, they further
analyze the sudden change in sensor readings by computing
the change in power spectral density (PSD) of sensor data in
the frequency domain. Under anomalous circumstances, the
PSD is expected to be higher in the high-frequency band. He
at al. [19] explored using correlations between heterogeneous
sensors to identify consistency among sensor data (e.g., accel-
eration, engine RPM, vehicle speed, GPS) and then utilize the
data to detect anomalous sensor measurements. They accom-
plished this by embedding the relationship of multiple sensors
into an autoencoder and pinpointing anomalies based on the
magnitude of the reconstruction loss. Leslie [20] developed
an unsupervised learning method to detect malicious trafﬁc
over J1939 data. This method converts categorical features to
numerical features with a one-hot encoding scheme and uses
an ensemble AHC algorithm that integrates multiple linkage
options.

Compared with the studies mentioned above, the present
paper is unique in that we model temporal and signal-wise
dependencies between CAN signals using time series cluster-
ing [21]. Speciﬁcally, we use AHC to generate a hierarchical
relationship between signals known as a dendrogram [22].
Using a hypothesis test, we show that masquerade attacks
are detectable by the resultant distribution of clustering sim-
ilarities. In addition, our method is tested on real CAN
data containing hundreds of signals, as opposed to previous
methods that used a dozen signals at most.

III. METHODS

S

=

X 1, X 2, . . . , X N
{

Our focus is on processing a set of N signals (i.e., time
series,
) obtained from a CAN log
}
captured during a vehicle’s drive. The subsections below ex-
plain the mathematical details of each step of our method and
the data source used to perform this research. The proposed
framework applies AHC (see § III-A) to produce a dendrogram
of clusters of
. Given two captures, each producing its
corresponding dendrogram, we compute a similarity between
the dendrograms using the CluSim method (see § III-B) [23].
Finally,
the pairwise similarities from each capture’s den-
drograms are used to create a hypothesis test to distinguish
between a benign CAN capture and an attack CAN capture.

S

A. Hierarchical Clustering

Hierarchical clustering is a method that outputs a hierarchy
of clusters (i.e., a set of nested clusters that are organized
in a tree-like diagram known as dendrogram). It works by
transforming a proximity matrix into a sequence of nested
partitions. Figure 1 depicts the details of a hierarchical clus-
tering and its subsequent dendrogram using the agglomera-
tive approach. The mathematical formulation of hierarchical
clustering can be found in the Appendix A. Agglomerative

−

by this method exists in the range [0, 1], where 0 implies
maximally dissimilar clusters, and 1 corresponds to identical
clusterings. We parametrized the clustering similarity method
by letting r =
5.0 and α = 0.9. Figure 2 shows a
comparison between similarity scores of three dendrograms.
The key advantage of CluSim is that it does not suffer from
critical biases found in previous methods (e.g., normalized
mutual information) and works for hierarchical clusterings,
including in conditions of skew cluster sizes and a different
number of clusters. We detail the main steps of CluSim in the
Appendix B.

Fig. 1. A hierarchical clustering using the agglomerative approach. (a) An
example of a hierarchical clustering: here, {X 1, X 2, X 3, X 4} is a set of time
series to be clustered. They are grouped in a hierarchy of clusters by color
(i.e., aquamarine, orange, purple). The thickness of the clusters represents how
the hierarchy is built: close time series (aquamarine), more distant time series
(orange), and most distant time series (purple). (b) Corresponding dendrogram
of the hierarchical clustering depicted in (a). Time series are placed in the
x-axis, and their relative distance is shown in the y-axis. Cluster colors
correspond with the ones in (a). (c) Different clusters at each level of the
hierarchy written explicitly. Note that cutting the dendrogram horizontally
creates clusterings.

algorithms1 require a deﬁnition of dissimilarity between clus-
ters called a linkage. The most popular linkages are the
(a) single linkage, which is the smallest dissimilarity between
two points in opposite clusters; (b) complete linkage, which
is the largest dissimilarity between two points in opposite
clusters; (c) average linkage, which is the average dissimilarity
over all points in opposite groups; and (d) Ward’s linkage,
which focuses on how the sum of squares will increase when
opposite groups are merged (or on the analysis of cluster
variance). Ward’s linkage tends to produce similar clusters as
the k-means method [21].

Given a CAN capture that has been translated into its
, we
constituent signal time series,
}
wish to cluster these time series to produce a dendrogram that
represents their hierarchical structure. Each linkage choice (a)–
(d) produces a potentially different dendrogram. Understand-
ing the most effective choice is a research question we address.

X 1, X 2, . . . , X N
{

=

S

B. Clustering Similarity

,
Given two hierarchical clusterings (dendrograms) of a set
S
a clustering similarity quantiﬁes a distance between them. We
computed the similarity between dendrograms using the open-
source CluSim method [25]. The similarity value provided

1There are two main categories of hierarchical clustering: agglomerative and
divisive. Agglomerative places each object in its own cluster and gradually
merges these atomic clusters into larger ones until all objects belong to a single
cluster. Divisive reverses the process starting with all objects belonging to a
single cluster and dividing them into smaller pieces [24]. Here, we used the
agglomerative approach by virtue of its simplicity.

3

Fig. 2. Hierarchical clustering similarity comparison using the CluSim
method [23]. Both (a) and (c) depict slightly modiﬁed dendrograms from
that of (b). The similarity between (a) and (b) dendrograms is 0.82, whereas
the similarity between (b) and (c) dendrograms is 0.76. This reﬂects that (a)
and (b) are more similar than (b) and (c).

C. Dataset

We used the ROAD dataset [4] to test our proposed forensic
framework. The ROAD dataset is an open set of CAN data
collected from a real vehicle with fabrication attacks and a
few advanced attacks (e.g., masquerade attacks). All of these
attacks are physically veriﬁed (i.e., the effect of the CAN ma-
nipulation is observed and documented). Notably, masquerade
attacks are also included but are simulated from the targeted ID
fabrication attacks by removing the benign frames of the target
ID. The ROAD dataset provides translated CAN time series
following a similar schema used by Hanselmann et al. [13].
The fundamental advantage of using the ROAD dataset over
prior released datasets is that it contains realistic, veriﬁed, and
labeled attacks as opposed to synthetic ones. This opens the
possibility for the evaluation, comparison, and validation of
CAN signal-based IDS methods in realistic conditions.

We tested our forensic framework on the subset of masquer-
ade attacks within the ROAD dataset. Each masquerade attack
ﬁle in the ROAD dataset contains time series from hundreds of
IDs that have a few to dozens of signals each. Table I shows
the ﬁles we used from the ROAD dataset. Speciﬁcally, we
tested the following attacks (in increasing order of detection
difﬁculty): correlated signal, max speedometer, max engine
coolant temperature, reverse light on, and reverse light off. In
the correlated signal attack, the correlation of the four wheel
speed values is altered by manipulating their individual values.
In the max speedometer and max engine coolant attacks, the
speedometer and coolant temperature values are modiﬁed to
their maximum. In the reverse light attacks, the state of the
reverse lights is altered to not match what gear the car is using

<latexit sha1_base64="76yJpN9sto+vxFA0O6hXKkWatRs=">AAAB7HicbVBNS8NAEJ34WetX1aOXxSJ4KokU9Vjw4rGCaQttLJvtpl262YTdiVBCf4MXD4p49Qd589+4bXPQ1gcDj/dmmJkXplIYdN1vZ219Y3Nru7RT3t3bPzisHB23TJJpxn2WyER3Qmq4FIr7KFDyTqo5jUPJ2+H4dua3n7g2IlEPOEl5ENOhEpFgFK3kdx5zb9qvVN2aOwdZJV5BqlCg2a989QYJy2KukElqTNdzUwxyqlEwyaflXmZ4StmYDnnXUkVjboJ8fuyUnFtlQKJE21JI5urviZzGxkzi0HbGFEdm2ZuJ/3ndDKObIBcqzZArtlgUZZJgQmafk4HQnKGcWEKZFvZWwkZUU4Y2n7INwVt+eZW0LmveVa1+X6826kUcJTiFM7gAD66hAXfQBB8YCHiGV3hzlPPivDsfi9Y1p5g5gT9wPn8AnHeOhg==</latexit>X1<latexit sha1_base64="buNJnrc6wr1cnqVqdrv8EfK/G8k=">AAAB7HicbVBNS8NAEJ34WetX1aOXxSJ4KokU9Vjw4rGCaQttLJvtpl262YTdiVBCf4MXD4p49Qd589+4bXPQ1gcDj/dmmJkXplIYdN1vZ219Y3Nru7RT3t3bPzisHB23TJJpxn2WyER3Qmq4FIr7KFDyTqo5jUPJ2+H4dua3n7g2IlEPOEl5ENOhEpFgFK3kdx7z+rRfqbo1dw6ySryCVKFAs1/56g0SlsVcIZPUmK7nphjkVKNgkk/LvczwlLIxHfKupYrG3AT5/NgpObfKgESJtqWQzNXfEzmNjZnEoe2MKY7MsjcT//O6GUY3QS5UmiFXbLEoyiTBhMw+JwOhOUM5sYQyLeythI2opgxtPmUbgrf88ippXda8q1r9vl5t1Is4SnAKZ3ABHlxDA+6gCT4wEPAMr/DmKOfFeXc+Fq1rTjFzAn/gfP4AoQaOiQ==</latexit>X4<latexit sha1_base64="+cpSzqyrAVZ25KC2lJhMslHPYUk=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0m0qMeCF48VTFtoY9lsp+3SzSbsboQS+hu8eFDEqz/Im//GbZuDtj4YeLw3w8y8MBFcG9f9dgpr6xubW8Xt0s7u3v5B+fCoqeNUMfRZLGLVDqlGwSX6hhuB7UQhjUKBrXB8O/NbT6g0j+WDmSQYRHQo+YAzaqzktx+zy2mvXHGr7hxklXg5qUCORq/81e3HLI1QGiao1h3PTUyQUWU4EzgtdVONCWVjOsSOpZJGqINsfuyUnFmlTwaxsiUNmau/JzIaaT2JQtsZUTPSy95M/M/rpGZwE2RcJqlByRaLBqkgJiazz0mfK2RGTCyhTHF7K2EjqigzNp+SDcFbfnmVNC+q3lW1dl+r1Gt5HEU4gVM4Bw+uoQ530AAfGHB4hld4c6Tz4rw7H4vWgpPPHMMfOJ8/n4GOiA==</latexit>X3<latexit sha1_base64="rRmNyVlC88pSJpvD9EBst9Lbs+8=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lKUY8FLx4rmLbQxrLZbtulm03YnQgl9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YSKFQdf9dgobm1vbO8Xd0t7+weFR+fikZeJUM+6zWMa6E1LDpVDcR4GSdxLNaRRK3g4nt3O//cS1EbF6wGnCg4iOlBgKRtFKfucxq8365YpbdRcg68TLSQVyNPvlr94gZmnEFTJJjel6boJBRjUKJvms1EsNTyib0BHvWqpoxE2QLY6dkQurDMgw1rYUkoX6eyKjkTHTKLSdEcWxWfXm4n9eN8XhTZAJlaTIFVsuGqaSYEzmn5OB0JyhnFpCmRb2VsLGVFOGNp+SDcFbfXmdtGpV76pav69XGvU8jiKcwTlcggfX0IA7aIIPDAQ8wyu8Ocp5cd6dj2VrwclnTuEPnM8fnfyOhw==</latexit>X2<latexit sha1_base64="76yJpN9sto+vxFA0O6hXKkWatRs=">AAAB7HicbVBNS8NAEJ34WetX1aOXxSJ4KokU9Vjw4rGCaQttLJvtpl262YTdiVBCf4MXD4p49Qd589+4bXPQ1gcDj/dmmJkXplIYdN1vZ219Y3Nru7RT3t3bPzisHB23TJJpxn2WyER3Qmq4FIr7KFDyTqo5jUPJ2+H4dua3n7g2IlEPOEl5ENOhEpFgFK3kdx5zb9qvVN2aOwdZJV5BqlCg2a989QYJy2KukElqTNdzUwxyqlEwyaflXmZ4StmYDnnXUkVjboJ8fuyUnFtlQKJE21JI5urviZzGxkzi0HbGFEdm2ZuJ/3ndDKObIBcqzZArtlgUZZJgQmafk4HQnKGcWEKZFvZWwkZUU4Y2n7INwVt+eZW0LmveVa1+X6826kUcJTiFM7gAD66hAXfQBB8YCHiGV3hzlPPivDsfi9Y1p5g5gT9wPn8AnHeOhg==</latexit>X1<latexit sha1_base64="buNJnrc6wr1cnqVqdrv8EfK/G8k=">AAAB7HicbVBNS8NAEJ34WetX1aOXxSJ4KokU9Vjw4rGCaQttLJvtpl262YTdiVBCf4MXD4p49Qd589+4bXPQ1gcDj/dmmJkXplIYdN1vZ219Y3Nru7RT3t3bPzisHB23TJJpxn2WyER3Qmq4FIr7KFDyTqo5jUPJ2+H4dua3n7g2IlEPOEl5ENOhEpFgFK3kdx7z+rRfqbo1dw6ySryCVKFAs1/56g0SlsVcIZPUmK7nphjkVKNgkk/LvczwlLIxHfKupYrG3AT5/NgpObfKgESJtqWQzNXfEzmNjZnEoe2MKY7MsjcT//O6GUY3QS5UmiFXbLEoyiTBhMw+JwOhOUM5sYQyLeythI2opgxtPmUbgrf88ippXda8q1r9vl5t1Is4SnAKZ3ABHlxDA+6gCT4wEPAMr/DmKOfFeXc+Fq1rTjFzAn/gfP4AoQaOiQ==</latexit>X4<latexit sha1_base64="rRmNyVlC88pSJpvD9EBst9Lbs+8=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lKUY8FLx4rmLbQxrLZbtulm03YnQgl9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YSKFQdf9dgobm1vbO8Xd0t7+weFR+fikZeJUM+6zWMa6E1LDpVDcR4GSdxLNaRRK3g4nt3O//cS1EbF6wGnCg4iOlBgKRtFKfucxq8365YpbdRcg68TLSQVyNPvlr94gZmnEFTJJjel6boJBRjUKJvms1EsNTyib0BHvWqpoxE2QLY6dkQurDMgw1rYUkoX6eyKjkTHTKLSdEcWxWfXm4n9eN8XhTZAJlaTIFVsuGqaSYEzmn5OB0JyhnFpCmRb2VsLGVFOGNp+SDcFbfXmdtGpV76pav69XGvU8jiKcwTlcggfX0IA7aIIPDAQ8wyu8Ocp5cd6dj2VrwclnTuEPnM8fnfyOhw==</latexit>X2<latexit sha1_base64="+cpSzqyrAVZ25KC2lJhMslHPYUk=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0m0qMeCF48VTFtoY9lsp+3SzSbsboQS+hu8eFDEqz/Im//GbZuDtj4YeLw3w8y8MBFcG9f9dgpr6xubW8Xt0s7u3v5B+fCoqeNUMfRZLGLVDqlGwSX6hhuB7UQhjUKBrXB8O/NbT6g0j+WDmSQYRHQo+YAzaqzktx+zy2mvXHGr7hxklXg5qUCORq/81e3HLI1QGiao1h3PTUyQUWU4EzgtdVONCWVjOsSOpZJGqINsfuyUnFmlTwaxsiUNmau/JzIaaT2JQtsZUTPSy95M/M/rpGZwE2RcJqlByRaLBqkgJiazz0mfK2RGTCyhTHF7K2EjqigzNp+SDcFbfnmVNC+q3lW1dl+r1Gt5HEU4gVM4Bw+uoQ530AAfGHB4hld4c6Tz4rw7H4vWgpPPHMMfOJ8/n4GOiA==</latexit>X3<latexit sha1_base64="pw5LD79KoXv6qexSC9opI02A02g=">AAAB+3icbVDLSgNBEJyNrxhfazx6GQyCp7ArQT0GvHiMkBckS5iddJIhsw9meiVh2V/x4kERr/6IN//GSbIHTSxoKKq66e7yYyk0Os63Vdja3tndK+6XDg6Pjk/s03JbR4ni0OKRjFTXZxqkCKGFAiV0YwUs8CV0/On9wu88gdIiCps4j8EL2DgUI8EZGmlgl/sIM0ybIgCqQQnQ2cCuOFVnCbpJ3JxUSI7GwP7qDyOeBBAil0zrnuvE6KVMoeASslI/0RAzPmVj6BkasgC0ly5vz+ilUYZ0FClTIdKl+nsiZYHW88A3nQHDiV73FuJ/Xi/B0Z2XijBOEEK+WjRKJMWILoKgQ6GAo5wbwrgS5lbKJ0wxjiaukgnBXX95k7Svq+5NtfZYq9RreRxFck4uyBVxyS2pkwfSIC3CyYw8k1fyZmXWi/VufaxaC1Y+c0b+wPr8AXPylK0=</latexit>Timeseries<latexit sha1_base64="e1gCTqy9Q3csip6NEZtqM4PlqD0=">AAAB+HicbVBNS8NAEN3Ur1o/GvXoJVgETyWRoh4LevBYwX5AG8pmO2mXbjZhdyLW0F/ixYMiXv0p3vw3btsctPXBwOO9GWbmBYngGl332yqsrW9sbhW3Szu7e/tl++CwpeNUMWiyWMSqE1ANgktoIkcBnUQBjQIB7WB8PfPbD6A0j+U9ThLwIzqUPOSMopH6drmH8IjZjdlEJYNp3664VXcOZ5V4OamQHI2+/dUbxCyNQCITVOuu5yboZ1QhZwKmpV6qIaFsTIfQNVTSCLSfzQ+fOqdGGThhrExJdObq74mMRlpPosB0RhRHetmbif953RTDKz/jMkkRJFssClPhYOzMUnAGXAFDMTGEMsXNrQ4bUUUZmqxKJgRv+eVV0jqvehfV2l2tUq/lcRTJMTkhZ8Qjl6RObkmDNAkjKXkmr+TNerJerHfrY9FasPKZI/IH1ucPV1GTgA==</latexit>Distance<latexit sha1_base64="PO0NqngryUnjKe32h7rSS1UGwRM=">AAAB+3icbVBNS8NAEN3Ur1q/Yj16CRbBU0mkqMdCLx4r2A9oQ9lsJ+3SzSbsTqQl9K948aCIV/+IN/+N2zYHbX0w8Hhvhpl5QSK4Rtf9tgpb2zu7e8X90sHh0fGJfVpu6zhVDFosFrHqBlSD4BJayFFAN1FAo0BAJ5g0Fn7nCZTmsXzEWQJ+REeSh5xRNNLALvcRppg1RKoRFJcjPR/YFbfqLuFsEi8nFZKjObC/+sOYpRFIZIJq3fPcBP2MKuRMwLzUTzUklE3oCHqGShqB9rPl7XPn0ihDJ4yVKYnOUv09kdFI61kUmM6I4livewvxP6+XYnjnZ1wmKYJkq0VhKhyMnUUQzpArYChmhlCmuLnVYWOqKDM56JIJwVt/eZO0r6veTbX2UKvUa3kcRXJOLsgV8cgtqZN70iQtwsiUPJNX8mbNrRfr3fpYtRasfOaM/IH1+QP9GZUG</latexit>Clusterings<latexit sha1_base64="tHtQS5nNUb+jjgkoA5NlxTAuHLY=">AAACq3icbVFLbxMxEHaWVwmvFLhxsaiQOCzReklJcqvgAMfySBuRDdGsM5ta9T5ke1Ejy3+FX8MV7vwbnN2CSMpIo/k8841n9E1aSaFNFP3qBNeu37h5a+92987de/cf9PYfnuiyVhwnvJSlmqagUYoCJ0YYidNKIeSpxNP0/M2mfvoVlRZl8cmsK5znsCpEJjgYn1r0RolNDF6Y5idb1aqS6KxN7PSLZS6kPgzaELfhpUuc877oHUT9qDF6FbBLcHD0OGvseLHfmSXLktc5FoZL0HrGosrMLSgjuB/aTWqNFfBzWOHMwwJy1HPbLOboM59Z0qxU3gtDm+y/HRZyrdd56pk5mDO9W9sk/1eb1SYbza0oqtpgwdtBWS2pKelGL7oUCrmRaw+AK+F3pfwMFHDjVd2actGu2u0mS8z8OVpJYVVDDsq/nf3w9rWz8TBkh6OQsbHbZpYKitVfFhuG48Mw3uH8OVDDYZ7DWByy4XhzDrYr/lVwEvfZq/7gvb/LgLS2R56Qp+Q5YWRIjsg7ckwmhJNv5Dv5QX4GL4KPwecgaalB57LnEdmyAH8DpmfVWQ==</latexit>{{X1,X4,X2,X3}}<latexit sha1_base64="dsosNUe8GowCTi+iaKqoXwEi+mc=">AAACrnicbVFNb9NAEN2YAsV8pdBbLysqJA5W5DUpacSlag9wLBVJI8UmGm/WyarrtbW7RkQr/xh+Dddy5N+wcVKUpIx2pPdm3mhmZ9JScG3C8E/Le7D38NHj/Sf+02fPX7xsH7wa6qJSlA1oIQo1SkEzwSUbGG4EG5WKQZ4Kdp3eXCzz19+Z0ryQX82iZEkOM8kzTsG40KT9MbbYvdE3S2oc18GadDdJtEneLwl27vuT9nHYCRvD9wFZg+Ozw6yxy8lBaxxPC1rlTBoqQOsxCUuTWFCGU8FqP640K4HewIyNHZSQM53Y5pc1fusiU5wVyrk0uIluVljItV7kqVPmYOZ6N7cM/i83rkx2mlguy8owSVeNskpgU+DlyvCUK0aNWDgAVHE3K6ZzUECNW+xWlx+rUX0/nrLMXaShFmYV5KAcr+3Vp/PaRr2AnJwGhPTrbWWhQM7+qUgv6J8E0Y6mrFQp7jTEaQiJAtLr1+4cZHf598Ew6pAPne4Xd5cuWtk+OkJv0DtEUA+doc/oEg0QRT/RL3SLfnuhN/QSb7KSeq11zWu0Zd78LzJT0js=</latexit>{{X1},{X4},{X2},{X3}}<latexit sha1_base64="4dxjUewpABYhO8aiZT32T2TitzA=">AAAC53ichZFLbxMxEMe9Wx7t8koLNy4WFRKHVbTepqS5VXCAY0GkjZQN0azjTa16vSvbixpZ/gzcEFc+FnwanE1BJEEwkuW/Zn7z0ExeC65NknwPwp1bt+/c3d2L7t1/8PBRZ//gXFeNomxIK1GpUQ6aCS7Z0HAj2KhWDMpcsIv86vUyfvGJKc0r+cEsajYpYS55wSkY75p2TGYzw65NW8nCvIESlK/lbGZHHy1xMfZfz2XOq3+R6f+RoyWSuSiadg6TbtIa3hbkRhyePilaO5vuB+NsVtGmZNJQAVqPSVKbiQVlOBXMRVmjWQ30CuZs7KWEkumJbedw+Ln3zHBRKf+kwa33zwwLpdaLMvdkCeZSb8aWzr/Fxo0pTiaWy7oxTNJVo6IR2FR4uWs844pRIxZeAFXcz4rpJSigxl9krcv1atQoymas8Bvb3uD7N6+cTfsxOT6JCRm4dbJSIOe/KdKPB8dxusHUjarFL4Z4hpA0Jv2B8+cgm8vfFudpl7zs9t75u/TQynbRU/QMvUAE9dEpeovO0BBR9CNAwV4QhTz8HH4Jv67QMLjJeYzWLPz2E6t27UY=</latexit>{{X1,X4},{X2},{X3}}<latexit sha1_base64="nDdZAjrAeZjuo545xhGZsNfjglk=">AAACyXicbZFNbxMxEIadLR9l+UoLNy4WFRKHVbReUtLcKjhQiUtBJI2UDdGs402tej+wvSjB8om/xR/hypX+CJzdRmoSRrL8auaxZ/ROUgqudBj+bnl7d+7eu7//wH/46PGTp+2Dw6EqKknZgBaikKMEFBM8ZwPNtWCjUjLIEsEukqv3q/rFdyYVL/IvelmySQbznKecgnapaXsYGxxrttD1VwbmFWQg3WfWxGb01RAbYHd1bWydukUWEvL5mooa6s2Kwji2/rR9FHbCOvCuIDfi6PR5Wsf59KA1jmcFrTKWaypAqTEJSz0xIDWnglk/rhQrgV7BnI2dzCFjamLqWSx+5TIznBbSnVzjOnv7hYFMqWWWODIDfam2a6vk/2rjSqcnE8PzstIsp02jtBJYF3jlJp5xyagWSyeASu5mxfQSJFDtPN/osmhG9f14xlLn767fnz+8sybqBeT4JCCkbzfJtd8NRXpB/ziItpiykqVYM8QxhEQB6fWtWwfZNn9XDKMOedvpfnJ76aIm9tEL9BK9RgT10Ck6Q+dogCj6hf6gv+ja++h98xbejwb1WjdvnqGN8H7+A5Yh4dU=</latexit>{{X1,X4},{X2,X3}}<latexit sha1_base64="lh15BHjErcxaseqYjOIG8rS4yCs=">AAACfnicbVFNT9tAEJ24tID7BYVbL1ZRKyq5qTeCJrmh9lCOtGoAKbHQeDMOK9Zrs7uuiCz/Dq7tz+LfsHGgIqFPWunNmzea0dukkMLYKLppeU9Wnj5bXVv3n794+er1xuabY5OXmtOA5zLXpwkakkLRwAor6bTQhFki6SS5+Dbrn/wmbUSuftlpQXGGEyVSwdE6KR5ZurJJWu3ix9o/29iJ2lGD4DFhd2TnYDttcHS22RqOxjkvM1KWSzRmyKLCxhVqK7ik2h+VhgrkFzihoaMKMzJx1VxdB++dMg7SXLunbNCoDycqzIyZZolzZmjPzXJvJv6vNyxt2osroYrSkuLzRWkpA5sHswiCsdDErZw6glwLd2vAz1Ejty6ohS1X81N9fzSm1CXclBVOSsxQu7qufn7/Wledbsj2eyFj/XrRmWtUk38u1g37+2FnyVOUupD3HuY8jHVC1u3X7jvYcviPyXGnzb609364f9mDOdbgLbyDXWDQhQM4hCMYAIdLuIY/8NcD74P3yfs8t3qtu5ktWIDXuwW8B8KR</latexit>(a)<latexit sha1_base64="yc6rs5zDFq7J5h+bSPd5R7Sqb9k=">AAACfnicbVFNT9tAEJ24tID7BYVbL1ZRKyq5qTeCJrmh9lCOtGoAKbHQeDMOK9Zrs7uuiCz/Dq7tz+LfsHGgIqFPWunNmzea0dukkMLYKLppeU9Wnj5bXVv3n794+er1xuabY5OXmtOA5zLXpwkakkLRwAor6bTQhFki6SS5+Dbrn/wmbUSuftlpQXGGEyVSwdE6KR5ZurJJWu0mH2v/bGMnakcNgseE3ZGdg+20wdHZZms4Gue8zEhZLtGYIYsKG1eoreCSan9UGiqQX+CEho4qzMjEVXN1Hbx3yjhIc+2eskGjPpyoMDNmmiXOmaE9N8u9mfi/3rC0aS+uhCpKS4rPF6WlDGwezCIIxkITt3LqCHIt3K0BP0eN3LqgFrZczU/1/dGYUpdwU1Y4KTFD7eq6+vn9a111uiHb74WM9etFZ65RTf65WDfs74edJU9R6kLee5jzMNYJWbdfu+9gy+E/JsedNvvS3vvh/mUP5liDt/AOdoFBFw7gEI5gABwu4Rr+wF8PvA/eJ+/z3Oq17ma2YAFe7xa+GMKS</latexit>(b)<latexit sha1_base64="jNoJxxHFmZLNoi5fQ44jZY/YFjg=">AAACfnicbVFNT9tAEJ24tID7BYVbL1ZRKyq5qTeCJrmh9lCOtGoAKbHQeDMOK9Zrs7uuiCz/Dq7tz+LfsHGgIqFPWunNmzea0dukkMLYKLppeU9Wnj5bXVv3n794+er1xuabY5OXmtOA5zLXpwkakkLRwAor6bTQhFki6SS5+Dbrn/wmbUSuftlpQXGGEyVSwdE6KR5ZurJJWu3yj7V/trETtaMGwWPC7sjOwXba4OhsszUcjXNeZqQsl2jMkEWFjSvUVnBJtT8qDRXIL3BCQ0cVZmTiqrm6Dt47ZRykuXZP2aBRH05UmBkzzRLnzNCem+XeTPxfb1jatBdXQhWlJcXni9JSBjYPZhEEY6GJWzl1BLkW7taAn6NGbl1QC1uu5qf6/mhMqUu4KSuclJihdnVd/fz+ta463ZDt90LG+vWiM9eoJv9crBv298POkqcodSHvPcx5GOuErNuv3Xew5fAfk+NOm31p7/1w/7IHc6zBW3gHu8CgCwdwCEcwAA6XcA1/4K8H3gfvk/d5bvVadzNbsACvdwvAKcKT</latexit>(c)<latexit sha1_base64="76yJpN9sto+vxFA0O6hXKkWatRs=">AAAB7HicbVBNS8NAEJ34WetX1aOXxSJ4KokU9Vjw4rGCaQttLJvtpl262YTdiVBCf4MXD4p49Qd589+4bXPQ1gcDj/dmmJkXplIYdN1vZ219Y3Nru7RT3t3bPzisHB23TJJpxn2WyER3Qmq4FIr7KFDyTqo5jUPJ2+H4dua3n7g2IlEPOEl5ENOhEpFgFK3kdx5zb9qvVN2aOwdZJV5BqlCg2a989QYJy2KukElqTNdzUwxyqlEwyaflXmZ4StmYDnnXUkVjboJ8fuyUnFtlQKJE21JI5urviZzGxkzi0HbGFEdm2ZuJ/3ndDKObIBcqzZArtlgUZZJgQmafk4HQnKGcWEKZFvZWwkZUU4Y2n7INwVt+eZW0LmveVa1+X6826kUcJTiFM7gAD66hAXfQBB8YCHiGV3hzlPPivDsfi9Y1p5g5gT9wPn8AnHeOhg==</latexit>X1<latexit sha1_base64="buNJnrc6wr1cnqVqdrv8EfK/G8k=">AAAB7HicbVBNS8NAEJ34WetX1aOXxSJ4KokU9Vjw4rGCaQttLJvtpl262YTdiVBCf4MXD4p49Qd589+4bXPQ1gcDj/dmmJkXplIYdN1vZ219Y3Nru7RT3t3bPzisHB23TJJpxn2WyER3Qmq4FIr7KFDyTqo5jUPJ2+H4dua3n7g2IlEPOEl5ENOhEpFgFK3kdx7z+rRfqbo1dw6ySryCVKFAs1/56g0SlsVcIZPUmK7nphjkVKNgkk/LvczwlLIxHfKupYrG3AT5/NgpObfKgESJtqWQzNXfEzmNjZnEoe2MKY7MsjcT//O6GUY3QS5UmiFXbLEoyiTBhMw+JwOhOUM5sYQyLeythI2opgxtPmUbgrf88ippXda8q1r9vl5t1Is4SnAKZ3ABHlxDA+6gCT4wEPAMr/DmKOfFeXc+Fq1rTjFzAn/gfP4AoQaOiQ==</latexit>X4<latexit sha1_base64="rRmNyVlC88pSJpvD9EBst9Lbs+8=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lKUY8FLx4rmLbQxrLZbtulm03YnQgl9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YSKFQdf9dgobm1vbO8Xd0t7+weFR+fikZeJUM+6zWMa6E1LDpVDcR4GSdxLNaRRK3g4nt3O//cS1EbF6wGnCg4iOlBgKRtFKfucxq8365YpbdRcg68TLSQVyNPvlr94gZmnEFTJJjel6boJBRjUKJvms1EsNTyib0BHvWqpoxE2QLY6dkQurDMgw1rYUkoX6eyKjkTHTKLSdEcWxWfXm4n9eN8XhTZAJlaTIFVsuGqaSYEzmn5OB0JyhnFpCmRb2VsLGVFOGNp+SDcFbfXmdtGpV76pav69XGvU8jiKcwTlcggfX0IA7aIIPDAQ8wyu8Ocp5cd6dj2VrwclnTuEPnM8fnfyOhw==</latexit>X2<latexit sha1_base64="+cpSzqyrAVZ25KC2lJhMslHPYUk=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0m0qMeCF48VTFtoY9lsp+3SzSbsboQS+hu8eFDEqz/Im//GbZuDtj4YeLw3w8y8MBFcG9f9dgpr6xubW8Xt0s7u3v5B+fCoqeNUMfRZLGLVDqlGwSX6hhuB7UQhjUKBrXB8O/NbT6g0j+WDmSQYRHQo+YAzaqzktx+zy2mvXHGr7hxklXg5qUCORq/81e3HLI1QGiao1h3PTUyQUWU4EzgtdVONCWVjOsSOpZJGqINsfuyUnFmlTwaxsiUNmau/JzIaaT2JQtsZUTPSy95M/M/rpGZwE2RcJqlByRaLBqkgJiazz0mfK2RGTCyhTHF7K2EjqigzNp+SDcFbfnmVNC+q3lW1dl+r1Gt5HEU4gVM4Bw+uoQ530AAfGHB4hld4c6Tz4rw7H4vWgpPPHMMfOJ8/n4GOiA==</latexit>X3<latexit sha1_base64="pw5LD79KoXv6qexSC9opI02A02g=">AAAB+3icbVDLSgNBEJyNrxhfazx6GQyCp7ArQT0GvHiMkBckS5iddJIhsw9meiVh2V/x4kERr/6IN//GSbIHTSxoKKq66e7yYyk0Os63Vdja3tndK+6XDg6Pjk/s03JbR4ni0OKRjFTXZxqkCKGFAiV0YwUs8CV0/On9wu88gdIiCps4j8EL2DgUI8EZGmlgl/sIM0ybIgCqQQnQ2cCuOFVnCbpJ3JxUSI7GwP7qDyOeBBAil0zrnuvE6KVMoeASslI/0RAzPmVj6BkasgC0ly5vz+ilUYZ0FClTIdKl+nsiZYHW88A3nQHDiV73FuJ/Xi/B0Z2XijBOEEK+WjRKJMWILoKgQ6GAo5wbwrgS5lbKJ0wxjiaukgnBXX95k7Svq+5NtfZYq9RreRxFck4uyBVxyS2pkwfSIC3CyYw8k1fyZmXWi/VufaxaC1Y+c0b+wPr8AXPylK0=</latexit>Timeseries<latexit sha1_base64="76yJpN9sto+vxFA0O6hXKkWatRs=">AAAB7HicbVBNS8NAEJ34WetX1aOXxSJ4KokU9Vjw4rGCaQttLJvtpl262YTdiVBCf4MXD4p49Qd589+4bXPQ1gcDj/dmmJkXplIYdN1vZ219Y3Nru7RT3t3bPzisHB23TJJpxn2WyER3Qmq4FIr7KFDyTqo5jUPJ2+H4dua3n7g2IlEPOEl5ENOhEpFgFK3kdx5zb9qvVN2aOwdZJV5BqlCg2a989QYJy2KukElqTNdzUwxyqlEwyaflXmZ4StmYDnnXUkVjboJ8fuyUnFtlQKJE21JI5urviZzGxkzi0HbGFEdm2ZuJ/3ndDKObIBcqzZArtlgUZZJgQmafk4HQnKGcWEKZFvZWwkZUU4Y2n7INwVt+eZW0LmveVa1+X6826kUcJTiFM7gAD66hAXfQBB8YCHiGV3hzlPPivDsfi9Y1p5g5gT9wPn8AnHeOhg==</latexit>X1<latexit sha1_base64="buNJnrc6wr1cnqVqdrv8EfK/G8k=">AAAB7HicbVBNS8NAEJ34WetX1aOXxSJ4KokU9Vjw4rGCaQttLJvtpl262YTdiVBCf4MXD4p49Qd589+4bXPQ1gcDj/dmmJkXplIYdN1vZ219Y3Nru7RT3t3bPzisHB23TJJpxn2WyER3Qmq4FIr7KFDyTqo5jUPJ2+H4dua3n7g2IlEPOEl5ENOhEpFgFK3kdx7z+rRfqbo1dw6ySryCVKFAs1/56g0SlsVcIZPUmK7nphjkVKNgkk/LvczwlLIxHfKupYrG3AT5/NgpObfKgESJtqWQzNXfEzmNjZnEoe2MKY7MsjcT//O6GUY3QS5UmiFXbLEoyiTBhMw+JwOhOUM5sYQyLeythI2opgxtPmUbgrf88ippXda8q1r9vl5t1Is4SnAKZ3ABHlxDA+6gCT4wEPAMr/DmKOfFeXc+Fq1rTjFzAn/gfP4AoQaOiQ==</latexit>X4<latexit sha1_base64="rRmNyVlC88pSJpvD9EBst9Lbs+8=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lKUY8FLx4rmLbQxrLZbtulm03YnQgl9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YSKFQdf9dgobm1vbO8Xd0t7+weFR+fikZeJUM+6zWMa6E1LDpVDcR4GSdxLNaRRK3g4nt3O//cS1EbF6wGnCg4iOlBgKRtFKfucxq8365YpbdRcg68TLSQVyNPvlr94gZmnEFTJJjel6boJBRjUKJvms1EsNTyib0BHvWqpoxE2QLY6dkQurDMgw1rYUkoX6eyKjkTHTKLSdEcWxWfXm4n9eN8XhTZAJlaTIFVsuGqaSYEzmn5OB0JyhnFpCmRb2VsLGVFOGNp+SDcFbfXmdtGpV76pav69XGvU8jiKcwTlcggfX0IA7aIIPDAQ8wyu8Ocp5cd6dj2VrwclnTuEPnM8fnfyOhw==</latexit>X2<latexit sha1_base64="+cpSzqyrAVZ25KC2lJhMslHPYUk=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0m0qMeCF48VTFtoY9lsp+3SzSbsboQS+hu8eFDEqz/Im//GbZuDtj4YeLw3w8y8MBFcG9f9dgpr6xubW8Xt0s7u3v5B+fCoqeNUMfRZLGLVDqlGwSX6hhuB7UQhjUKBrXB8O/NbT6g0j+WDmSQYRHQo+YAzaqzktx+zy2mvXHGr7hxklXg5qUCORq/81e3HLI1QGiao1h3PTUyQUWU4EzgtdVONCWVjOsSOpZJGqINsfuyUnFmlTwaxsiUNmau/JzIaaT2JQtsZUTPSy95M/M/rpGZwE2RcJqlByRaLBqkgJiazz0mfK2RGTCyhTHF7K2EjqigzNp+SDcFbfnmVNC+q3lW1dl+r1Gt5HEU4gVM4Bw+uoQ530AAfGHB4hld4c6Tz4rw7H4vWgpPPHMMfOJ8/n4GOiA==</latexit>X3<latexit sha1_base64="e1gCTqy9Q3csip6NEZtqM4PlqD0=">AAAB+HicbVBNS8NAEN3Ur1o/GvXoJVgETyWRoh4LevBYwX5AG8pmO2mXbjZhdyLW0F/ixYMiXv0p3vw3btsctPXBwOO9GWbmBYngGl332yqsrW9sbhW3Szu7e/tl++CwpeNUMWiyWMSqE1ANgktoIkcBnUQBjQIB7WB8PfPbD6A0j+U9ThLwIzqUPOSMopH6drmH8IjZjdlEJYNp3664VXcOZ5V4OamQHI2+/dUbxCyNQCITVOuu5yboZ1QhZwKmpV6qIaFsTIfQNVTSCLSfzQ+fOqdGGThhrExJdObq74mMRlpPosB0RhRHetmbif953RTDKz/jMkkRJFssClPhYOzMUnAGXAFDMTGEMsXNrQ4bUUUZmqxKJgRv+eVV0jqvehfV2l2tUq/lcRTJMTkhZ8Qjl6RObkmDNAkjKXkmr+TNerJerHfrY9FasPKZI/IH1ucPV1GTgA==</latexit>Distance<latexit sha1_base64="76yJpN9sto+vxFA0O6hXKkWatRs=">AAAB7HicbVBNS8NAEJ34WetX1aOXxSJ4KokU9Vjw4rGCaQttLJvtpl262YTdiVBCf4MXD4p49Qd589+4bXPQ1gcDj/dmmJkXplIYdN1vZ219Y3Nru7RT3t3bPzisHB23TJJpxn2WyER3Qmq4FIr7KFDyTqo5jUPJ2+H4dua3n7g2IlEPOEl5ENOhEpFgFK3kdx5zb9qvVN2aOwdZJV5BqlCg2a989QYJy2KukElqTNdzUwxyqlEwyaflXmZ4StmYDnnXUkVjboJ8fuyUnFtlQKJE21JI5urviZzGxkzi0HbGFEdm2ZuJ/3ndDKObIBcqzZArtlgUZZJgQmafk4HQnKGcWEKZFvZWwkZUU4Y2n7INwVt+eZW0LmveVa1+X6826kUcJTiFM7gAD66hAXfQBB8YCHiGV3hzlPPivDsfi9Y1p5g5gT9wPn8AnHeOhg==</latexit>X1<latexit sha1_base64="buNJnrc6wr1cnqVqdrv8EfK/G8k=">AAAB7HicbVBNS8NAEJ34WetX1aOXxSJ4KokU9Vjw4rGCaQttLJvtpl262YTdiVBCf4MXD4p49Qd589+4bXPQ1gcDj/dmmJkXplIYdN1vZ219Y3Nru7RT3t3bPzisHB23TJJpxn2WyER3Qmq4FIr7KFDyTqo5jUPJ2+H4dua3n7g2IlEPOEl5ENOhEpFgFK3kdx7z+rRfqbo1dw6ySryCVKFAs1/56g0SlsVcIZPUmK7nphjkVKNgkk/LvczwlLIxHfKupYrG3AT5/NgpObfKgESJtqWQzNXfEzmNjZnEoe2MKY7MsjcT//O6GUY3QS5UmiFXbLEoyiTBhMw+JwOhOUM5sYQyLeythI2opgxtPmUbgrf88ippXda8q1r9vl5t1Is4SnAKZ3ABHlxDA+6gCT4wEPAMr/DmKOfFeXc+Fq1rTjFzAn/gfP4AoQaOiQ==</latexit>X4<latexit sha1_base64="rRmNyVlC88pSJpvD9EBst9Lbs+8=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lKUY8FLx4rmLbQxrLZbtulm03YnQgl9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YSKFQdf9dgobm1vbO8Xd0t7+weFR+fikZeJUM+6zWMa6E1LDpVDcR4GSdxLNaRRK3g4nt3O//cS1EbF6wGnCg4iOlBgKRtFKfucxq8365YpbdRcg68TLSQVyNPvlr94gZmnEFTJJjel6boJBRjUKJvms1EsNTyib0BHvWqpoxE2QLY6dkQurDMgw1rYUkoX6eyKjkTHTKLSdEcWxWfXm4n9eN8XhTZAJlaTIFVsuGqaSYEzmn5OB0JyhnFpCmRb2VsLGVFOGNp+SDcFbfXmdtGpV76pav69XGvU8jiKcwTlcggfX0IA7aIIPDAQ8wyu8Ocp5cd6dj2VrwclnTuEPnM8fnfyOhw==</latexit>X2<latexit sha1_base64="+cpSzqyrAVZ25KC2lJhMslHPYUk=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0m0qMeCF48VTFtoY9lsp+3SzSbsboQS+hu8eFDEqz/Im//GbZuDtj4YeLw3w8y8MBFcG9f9dgpr6xubW8Xt0s7u3v5B+fCoqeNUMfRZLGLVDqlGwSX6hhuB7UQhjUKBrXB8O/NbT6g0j+WDmSQYRHQo+YAzaqzktx+zy2mvXHGr7hxklXg5qUCORq/81e3HLI1QGiao1h3PTUyQUWU4EzgtdVONCWVjOsSOpZJGqINsfuyUnFmlTwaxsiUNmau/JzIaaT2JQtsZUTPSy95M/M/rpGZwE2RcJqlByRaLBqkgJiazz0mfK2RGTCyhTHF7K2EjqigzNp+SDcFbfnmVNC+q3lW1dl+r1Gt5HEU4gVM4Bw+uoQ530AAfGHB4hld4c6Tz4rw7H4vWgpPPHMMfOJ8/n4GOiA==</latexit>X3<latexit sha1_base64="lh15BHjErcxaseqYjOIG8rS4yCs=">AAACfnicbVFNT9tAEJ24tID7BYVbL1ZRKyq5qTeCJrmh9lCOtGoAKbHQeDMOK9Zrs7uuiCz/Dq7tz+LfsHGgIqFPWunNmzea0dukkMLYKLppeU9Wnj5bXVv3n794+er1xuabY5OXmtOA5zLXpwkakkLRwAor6bTQhFki6SS5+Dbrn/wmbUSuftlpQXGGEyVSwdE6KR5ZurJJWu3ix9o/29iJ2lGD4DFhd2TnYDttcHS22RqOxjkvM1KWSzRmyKLCxhVqK7ik2h+VhgrkFzihoaMKMzJx1VxdB++dMg7SXLunbNCoDycqzIyZZolzZmjPzXJvJv6vNyxt2osroYrSkuLzRWkpA5sHswiCsdDErZw6glwLd2vAz1Ejty6ohS1X81N9fzSm1CXclBVOSsxQu7qufn7/Wledbsj2eyFj/XrRmWtUk38u1g37+2FnyVOUupD3HuY8jHVC1u3X7jvYcviPyXGnzb609364f9mDOdbgLbyDXWDQhQM4hCMYAIdLuIY/8NcD74P3yfs8t3qtu5ktWIDXuwW8B8KR</latexit>(a)<latexit sha1_base64="yc6rs5zDFq7J5h+bSPd5R7Sqb9k=">AAACfnicbVFNT9tAEJ24tID7BYVbL1ZRKyq5qTeCJrmh9lCOtGoAKbHQeDMOK9Zrs7uuiCz/Dq7tz+LfsHGgIqFPWunNmzea0dukkMLYKLppeU9Wnj5bXVv3n794+er1xuabY5OXmtOA5zLXpwkakkLRwAor6bTQhFki6SS5+Dbrn/wmbUSuftlpQXGGEyVSwdE6KR5ZurJJWu0mH2v/bGMnakcNgseE3ZGdg+20wdHZZms4Gue8zEhZLtGYIYsKG1eoreCSan9UGiqQX+CEho4qzMjEVXN1Hbx3yjhIc+2eskGjPpyoMDNmmiXOmaE9N8u9mfi/3rC0aS+uhCpKS4rPF6WlDGwezCIIxkITt3LqCHIt3K0BP0eN3LqgFrZczU/1/dGYUpdwU1Y4KTFD7eq6+vn9a111uiHb74WM9etFZ65RTf65WDfs74edJU9R6kLee5jzMNYJWbdfu+9gy+E/JsedNvvS3vvh/mUP5liDt/AOdoFBFw7gEI5gABwu4Rr+wF8PvA/eJ+/z3Oq17ma2YAFe7xa+GMKS</latexit>(b)<latexit sha1_base64="jNoJxxHFmZLNoi5fQ44jZY/YFjg=">AAACfnicbVFNT9tAEJ24tID7BYVbL1ZRKyq5qTeCJrmh9lCOtGoAKbHQeDMOK9Zrs7uuiCz/Dq7tz+LfsHGgIqFPWunNmzea0dukkMLYKLppeU9Wnj5bXVv3n794+er1xuabY5OXmtOA5zLXpwkakkLRwAor6bTQhFki6SS5+Dbrn/wmbUSuftlpQXGGEyVSwdE6KR5ZurJJWu3yj7V/trETtaMGwWPC7sjOwXba4OhsszUcjXNeZqQsl2jMkEWFjSvUVnBJtT8qDRXIL3BCQ0cVZmTiqrm6Dt47ZRykuXZP2aBRH05UmBkzzRLnzNCem+XeTPxfb1jatBdXQhWlJcXni9JSBjYPZhEEY6GJWzl1BLkW7taAn6NGbl1QC1uu5qf6/mhMqUu4KSuclJihdnVd/fz+ta463ZDt90LG+vWiM9eoJv9crBv298POkqcodSHvPcx5GOuErNuv3Xew5fAfk+NOm31p7/1w/7IHc6zBW3gHu8CgCwdwCEcwAA6XcA1/4K8H3gfvk/d5bvVadzNbsACvdwvAKcKT</latexit>(c)<latexit sha1_base64="ORpKQ/9xAsYZw1oBTpa4tcbORvA=">AAACj3icbVFNaxsxEJU3aZtuv+ykt+QgGgo2LGa1JFn7kGKaQ9tbWuokYBszK2sdEUm7SNoQs+ylv6bX9t/031Rep6V2+kDwZuYNM3qT5IIbG4a/Gt7W9qPHT3ae+s+ev3j5qtnavTBZoSkb0kxk+ioBwwRXbGi5Fewq1wxkIthlcnO2rF/eMm14pr7aRc4mEuaKp5yCdalp82Bs2Z0tDZdVuw2dALeTTgef4rDbi/xp8zDshjXwQ0LuyeHgdVrjfNpqjMazjBaSKUsFGDMiYW4nJWjLqWCVPy4My4HewJyNHFUgmZmU9Tcq/NZlZjjNtHvK4jr7b0cJ0piFTJxSgr02m7Vl8n+1UWHT3qTkKi8sU3Q1KC0EthleeoJnXDNqxcIRoJq7XTG9Bg3UOufWptytVvX98YylzvI6LGFegATt4qr88uF9VUZxQI57ASH9al2ZaVDzvyoSB/3jINrQ5IXOxR8NcRpCooDE/cqdg2ya/5BcRF1y0j367O5yhFbYQfvoDWojgmI0QB/RORoiir6h7+gH+um1vNh75w1WUq9x37OH1uB9+g0yZcZu</latexit>sim((a),(b))=0.82<latexit sha1_base64="kPtqeFbkxWGq/kxGNvMMkGoDLQ8=">AAACj3icbVFNTxsxEHWWltLtB0nprT1YRZUSaRWtI2DJARS1h5YbrRpASqJo1vEGC9u7sr2IaLUXfg1X+Df8mzobWpHAkyy9mXmjGb+JM8GNDcP7mrf24uX6q43X/pu3795v1hsfTkyaa8r6NBWpPovBMMEV61tuBTvLNAMZC3YaX3yf108vmTY8VX/sLGMjCVPFE07ButS4/nlo2ZUtDJdlsxm3AtykrRY+wGE72vPH9e2wHVbATwl5INu9j0mF43GjNhhOUppLpiwVYMyAhJkdFaAtp4KV/jA3LAN6AVM2cFSBZGZUVN8o8VeXmeAk1e4pi6vs444CpDEzGTulBHtuVmvz5HO1QW6T/VHBVZZbpuhiUJILbFM89wRPuGbUipkjQDV3u2J6Dhqodc4tTblarOr7wwlLnOVVWMA0BwnaxWXx+8e3suhEAdndDwjplsvKVIOa/leRKOjuBp0VTZbrTPzTEKchpBOQqFu6c5BV85+Sk06b7LV3frm77KAFNtAn9AU1EUER6qGf6Bj1EUXX6Abdojuv4UXeoddbSL3aQ88WWoJ39Bc8xsZz</latexit>sim((b),(c))=0.76TABLE I
CAN CAPTURES USED FROM THE ROAD DATASET [4].

Description

g Dynamometer Various Ambient
n
i
n
i
a
r
T

Road Various Ambient
Total
Correlated Signal Fabrication Attack
Correlated Signal Masquerade Attack
Fuzzing Fabrication Attack
Max Engine Coolant Temp Fabrication Attack
Max Engine Coolant Temp Masquerade Attack
Max Speedometer Fabrication Attack
Max Speedometer Masquerade Attack
Reverse Light Off Fabrication Attack
Reverse Light Off Masquerade Attack
Reverse Light On Fabrication Attack
Reverse Light On Masquerade Attack
Accelerator Attack (In Drive)
Accelerator Attack (In Reverse)
Total

g
n
i
t
s
e
T

# Files Used Duration (min)
108.2
70.6
178.8
1.3
1.3
0.7
0.4
0.4
3.9
3.9
2.1
2.1
3.2
3.2
2.7
3.2
10.9

(cid:51)
(cid:51)
12
(cid:55)
(cid:51)
(cid:55)
(cid:55)
(cid:51)
(cid:55)
(cid:51)
(cid:55)
(cid:51)
(cid:55)
(cid:51)
(cid:55)
(cid:55)
13

10
2
12
3
3
3
1
1
3
3
3
3
3
3
2
2
33

(i.e., the reverse light is on when the vehicle is not in reverse,
and the reverse light is off when the vehicle is in reverse).

≈

We used the complete set of 12 ﬁles to characterize the
3 hours of data). We used
behavior in benign conditions (
each of the ﬁles in the masquerade attack category: 3 ﬁles
in the correlated attack (
1.3 minutes), 3 ﬁles for the max
3.9 minutes), 1 ﬁle for the max engine
speedometer attack (
0.4 minutes), 3 ﬁles for the reverse light on
coolant attack (
attack (
3.2 minutes), 3 ﬁles for the reverse light off attack
(
≈
D. Pipeline Detailed Steps

2.1 minutes) to characterize the attack conditions.

≈

≈

≈

≈

|

,

∈ S

X i
|

X i
∀

The following steps are performed to arrive at the results.
1) Same Length Time Series Transformation: Each ID has
a characteristic frequency that is unique in most cases. We
modiﬁed the time series to have the same frequency by linearly
interpolating them in common timestamps. We chose a base-
line frequency of 10 Hz because it is the lowest frequency in
the IDs in this dataset. This ensures that
= T .
Time series of the same length enable easier computation of
similarity. After this, we also discarded any constant time
series and normalized each remaining series to the unit norm.
2) Time Series Correlation Computation: We computed
pairwise Pearson correlations [26] among time series. Time
series that have a positive correlation are expected to move in
tandem (i.e., when one measurement increases or decreases,
the other measurement also increases or decreases). Pearson
correlation values that are close to
1.0 indicate strong
positive or negative correlation. As vehicle subsystems are
dependent, we expect (1) clusters of correlated signals (e.g.,
increasing speed of the vehicle matches increases in the
speedometer reading and the speed of all four wheels), and
(2) such relationships to be broken or signiﬁcantly changed
upon a cyber attack.

±

3) Hierarchical Clustering Computation: These pairwise
correlations populate a correlation matrix, which is used as
the input for AHC. The output is a dendrogram depicting
hierarchies between clusters. We explored the effect of linkage
selection (i.e., single, complete, average, Ward) in our detec-
tion framework.

4

4) Similarity Distribution Computation: Once each dendro-
gram has been computed for each ﬁle, we compute empirical
distributions of similarity between pairs of dendrograms using
the method described in § III-B. We focus on two distinct
groups. The ﬁrst group is composed of all dendrograms
derived from ﬁles in benign conditions (i.e., 12 ﬁles). In doing
so, we computed pairwise similarities of dendrograms in this
group, that is (cid:0)12
(cid:1) = 66 possible combinations. The second
group comes from the similarity between dendrograms in each
category of attack (i.e., correlated, max speedometer, max
engine coolant, reverse light on, reverse light off) and each of
the ﬁles in benign conditions. This produces a varying number
of combinations based on the number of ﬁles in each of the
attack categories.

2

5) Hypothesis Testing: We used the Mann-Whitney U
test [27] and set the signiﬁcance level to 0.05 to test the null
hypothesis that the distribution underlying benign conditions
is the same as the distribution underlying attack conditions.
The Mann-Whitney U test is a nonparametric test often used
as a test of difference in location between distributions.

E. Motivational Preliminary Data Analysis

As a ﬁrst step to investigate our hypothesis that masquerade
attacks will disrupt clustering based on correlation of the
CAN signals, we compute and visualize the CluSim similarity
(§ III-B) between every pair of ﬁles in the dataset discussed
above (12 benign ﬁles and 13 masquerade attack ﬁles of ﬁve
different attack scenarios, all in their signal time series format).
More speciﬁcally, we follow the steps describe in § III-D1
to interpolate time series to identical time steps, § III-D2 to
compute Pearson correlation for each pair of signals in a CAN
ﬁle, and § III-D3 to produce a dendrogram for the signals in
each ﬁle. We then apply CluSim, and visualize the pairwise
similarity results in Figure 3.

To see if the benign ﬁles signal cluster dendrograms do
indeed “look” similar to each other but different than signal
cluster dendrograms from masquerade attacks, we apply AHC
to all the ﬁles based on their CluSim similarities to each other.
Figure 3 shows the resulting dendrogram revealing four main
clusters. Notably the ﬁrst two (from left to right) contain all
but one benign ﬁle (11/12), and only two (of 13) attack ﬁles.
This provides strong empirical motivation to pursue a more
formal detection experiment based on hierarchical clustering
of signals.

IV. RESULTS

Here we present our results on the efﬁcacy of the proposed
forensic framework for detecting masquerade attacks in the
CAN bus. We focus on analyzing the detection capabilities
for each of the attacks described in § III-C. Figure 4 plots the
probability density functions in the correlated attack (in benign
and attack conditions) using the Gaussian kernel density
estimate implementation from seaborn [28] with a default
bandwidth. We study the effect of the linkage selection (in the
hierarchical clustering) for distinguishing between benign and
attack conditions: (a) single, (b) complete, (c) average, and

TABLE II
STATISTICAL HYPOTHESIS TEST RESULTS (p-VALUES).

Attack Scenario

Single

Complete

Average Ward

Correlated
Max Speedometer
Max Engine Coolant
Reverse Light On
Reverse Light Off

0.005
0.003
0.251
0.378
0.039

0.002
0.017
0.065
0.007
0.004

0.123
0.007
0.006
0.057
0.004

0.000
0.000
0.008
0.004
0.000

Statistically signiﬁcant values are printed in bold.

A. Correlated Attack

Figure 4 shows the comparison of similarity distributions
in the correlated attack. Among these, we found that
the
framework that used the average linkage (i.e., [c]) is not
able to differentiate between benign and attack conditions. We
also noticed that the Ward’s method has the most distinctive
difference (i.e., smaller p-value).

Fig. 4. Empirical distribution comparison of the correlated attack for each
linkage selection: (a) single, (b) complete, (c) average, and (d) Ward. Results
from these distributions appear in the ﬁrst row of Table II.

B. Max Speedometer Attack

Table II shows that for the max speedometer attack, each
linkage option produces statistically signiﬁcant differences.
We notice again that the Ward linkage produces the most
distinctive results. We believe that speedometer readings cor-
relate closely with wheel speed and engine readings, so when
the speedometer value is manipulated (via attack) to appear
maximally, correlations broken with these signals should be
captured by the similarity distributions.

C. Max Engine Coolant Attack

Table II shows the results of the max engine coolant
temperature attack. We notice that only average and Ward
linkages detect signiﬁcant differences. In this attack, the engine
coolant signal value is set to maximum, which may cause
correlations with other engine signals to differ.

5

Fig. 3. CluSim cluster similarity heatmap for each pair of ﬁles from the ROAD
dataset (12 benign ﬁles, 13 masquerade attack ﬁles of ﬁve attack scenario
types) depicted. For each ﬁle, a hierarchical clustering dendrogram is produced
based on similarity of the ﬁle’s CAN signals. For each pair of ﬁles, CluSim
produces a similarity measure between the two ﬁle’s dendrograms using
Ward’s linkage, r = −5.0, and α = 0.9, which is visualized by colors in the
heatmap. Atop the heatmap is a dendrogram showing hierarchical clustering
of all ﬁles based on their the CluSim similarities. We used Euclidean distance
on these similarities with Ward linkage. Notably, there are four main clusters.
From left to right, the ﬁrst and second contain all benign ﬁles except Benign
dyno reverse ﬁle, and only two attack ﬁles, i.e., Attack correlated
masquerade 3 and Attack reverse light on 3, while the ﬁnal
two clusters contain all remaining attack ﬁles and the aforementioned benign
ﬁle. As a preliminary analysis, this heatmap and clustering give positive
results for masquerade attack detection by comparing Pearson correlation
signal clusters.

(d) Ward. We also report the p-value, using three decimals,
of the associated Mann-Whitney U test to compare the two
distributions in the inset; statistically signiﬁcant values (i.e.,
p-value < 0.05) are printed in bold. Recall that we ﬁxed
the scaling parameter r =
5 for comparing hierarchical
−
clusterings. This is because we want to capture differences
at higher levels of the dendrograms, in which the focus is on
coarser groups of multiple correlated signals, instead of more
ﬁne-grained groupings of individual to a few signals, in which
not much emphasis is on their correlations.

Overall, we ﬁnd that detecting attacks depends heavily on
(1) the linkage function used to compute the hierarchical
clusterings and (2) the severity of the attack in terms of
the number of correlations perturbed. Speciﬁcally, out of the
the method based on Ward’s linkage
ﬁve attacks studied,
detected all of them (5 of 5), followed by complete linkage
(4 of 5). Both single and average linkage methods detected
fewer attacks (3 of 5). We report the p-values resulting from
running the forensic framework for the remaining attacks (i.e.,
max speedometer, max engine coolant, reverse light on, and
reverse light off) for each linkage in Table II. We elaborate on
each attack scenario below.

0.80.9024681012BenignAttack0.800.850.900.950510152025300.70.80.90.02.55.07.510.012.515.00.800.850.900.950510152025(a)p=0.005(b)p=0.002(c)p=0.123(d)p=0.000SimilarityDensityD. Reverse Light On Attack

Table II shows the comparison of similarity distributions
in the reverse light on attack. Note that only the complete
and Ward linkages produce statistically signiﬁcant differences
(i.e., [b] and [d]). We also note that, although statistically
signiﬁcant, these p-values are not as small as in the correlated
attack, which is a consequence of having an attack that is more
difﬁcult to detect. This suggests that fewer correlated signals
are affected under this attack, (i.e., only a binary [1 bit] signal
was targeted).

E. Reverse Light Off Attack

Table II shows that for the reverse light off attack, each
linkage method produces statistically signiﬁcant differences.
Among these, Ward’s linkage produces the most signiﬁcant
difference, followed by average and complete linkages. The
single linkage produces the least signiﬁcant result, but it still
meets the threshold.

F. Detection Evaluation

We compute and compare the performance of the proposed
framework for classifying benign and attack ﬁles. Recall that
we use 12 benign ﬁles. To do so, we implement a cross-
validation as follows: We set apart three benign ﬁles to be
used for testing purposes (along with all attack ﬁles) and use
the remaining nine ﬁles for training, that is, for computing
the similarity distribution from benign ﬁles. We chose to
hold out three benign ﬁles for testing to be consistent with
the maximum number of attack ﬁles found in the attack
dataset (i.e., correlated, max speedometer, reverse light on,
and reverse light off attacks each have three attack ﬁles). We
implement the above train-test split of our benign ﬁles for each
of the (cid:0)12
(cid:1) = 220 possible combinations. This experimental
design allows us to decide if the difference between similarity
distributions in benign and attack scenarios is statistically
signiﬁcant and further count the number of true positives (TP),
false positives (FP), false negatives (FN), and true negatives
(TN).

9

−

We use the best set of parameter values derived from our
previous experiments, i.e., Ward linkage, r =
5.0, α = 0.9,
and a signiﬁcance level for the statistical hypothesis test of
0.05. We report the following micro-averaged classiﬁcation
T P
metrics based on these numbers: Precision, deﬁned as
T P +F P ,
gives the likelihood that the computed similarity distribution
difference can be attributed to an attack; Recall, deﬁned as
T P +F N , gives the likelihood that attack ﬁles are detected.
Since higher precision often comes at the price of lower recall
(and vice versa), it is important to consider a balance of both
metrics, and the standard balanced metric is the F1 score,
precision×recall
precision+recall . Table III summarizes these
deﬁned as 2
ﬁndings.

×

T P

Because our method is unsupervised, the training set is
deﬁned by the benign ﬁles in a given fold not the attack ﬁles;
hence, the false positive counts and rate are independent of
the attack scenarios. In our experiment, the overall FPR is
13.64%, with per-ﬁle FPR depicted in Figure 5.

6

TABLE III
CLASSIFICATION RESULTS (%).

Attack Scenario

Precision

Recall

F1 score

Correlated
Max Speedometer
Max Engine Coolant
Reverse Light On
Reverse Light Off

88.00
88.00
87.18
87.23
88.00

100.00
100.00
92.73
93.18
100.00

93.62
93.62
89.87
90.11
93.62

False positive rate (FPR), deﬁned as
F P +T N equals to
13.64%. Because this method is unsupervised, the training set
is deﬁned by the benign ﬁles in a given fold not the attack
ﬁles; hence, the false positive counts and rate are independent
of the attack scenarios.

F P

Fig. 5. False positive rates for each benign ﬁle. All are at or below 20%,
except Benign dyno drive benign anomaly at 27%. Comparing
with Figure 3, we see the lone benign ﬁle to cluster with attack ﬁles in
preliminary analysis (i.e., Benign dyno reverse) has FPR = 20%.

Unlike the false positive and true negative counts, the true
positive and false negative results will vary across different
attack scenarios. For correlated, max speedometer, and reverse
light off attacks, our results are identical. In these attack
scenarios, recall is 100.00% meaning that all the attack con-
ﬁgurations are detected even when changing the set of benign
ﬁles used in training. In these attack scenarios, precision is
88% meaning that from the detected conﬁgurations, there are
a few that come from the set of benign ﬁles or false positives.
We obtain different results for the max engine coolant and
reverse light on attacks. In particular, the lower results for the
max engine coolant attack suggests that this attack was more
difﬁcult to detect when varying the set of benign ﬁles.

V. DISCUSSION

This work proposes a statistical forensic framework to detect
masquerade attacks in the CAN bus. We quantify the empirical
distribution of similarities of time series captures in benign
and attack conditions. To accomplish this, we cluster time
series using AHC and compute the similarity between their
corresponding dendrograms. We ﬁnd that masquerade attacks
can be detected effectively using the proposed framework, and
its discriminatory power depends on the linkage function being
used in the AHC as well as the the impact of the attacks on
correlated signals.

These results suggest that the proposed framework is a
viable approach for detecting masquerade attacks in a forensic
setting. We assume that the time series signal translation (or
at least a high-ﬁdelity translation) is readily available for use.
This seems feasible with current and upcoming work in reverse
engineering CAN bus signals, such as CAN-D [14].

The proposed framework detects all masquerade attacks in
the ROAD dataset when the Ward linkage is used. Note that
Ward’s linkage (d) is an appropriate choice in this context
because it tends to produce dense-enough clusters and enables
the capture of meaningful changes in clustering assignations
when attacks occur. In contrast, for the single linkage (a),
clusters of signals tend to be spread out and often not compact
enough with clusters having disparate elements. In the com-
plete linkage (b), clusters of signals tend to be compact, but
not far enough apart, with clusters having similar members.
Additionally, for the average linkage (c), clusters tend to be
relatively compact and relatively far apart, which strikes a
balance between single and complete linkages.

We note that the detection performance may also depend
on speciﬁc attack features. Here, the detection difﬁculty is
based on the potential number of correlated signals that are
affected by the attack. Thus, an attack scenario in which wheel
speed signals are modiﬁed, such as in the correlated attack,
has a more noticeable effect of disrupting correlation with
other signals than an attack that modiﬁes the reverse lights
because the wheel speed correlation attack manipulates four
highly correlated signals (and seemingly strong correlations to
many other signals), whereas the reverse light attacks modify
a single signal that has correlation with gear selection but not
many other signals.

Detection metrics are also affected by the number of ﬁles
used to compute the similarity distribution. It other words,
augmenting the number of ﬁles to estimate the similarity
distribution helps to have better deﬁned distributions that are
later used for comparison purposes. This explains the lower
results on the max engine coolant attack that contains a single
ﬁle.

To the best of our knowledge, the results from this research
are the ﬁrst to show systemic evidence of a forensic framework
successfully detecting masquerade attacks based on time series
clustering using a dataset of realistic and veriﬁed masquerade
attacks. The following are some limitations of our work.
ROAD dataset conditions. The ROAD dataset was collected
on a single vehicle while being exercised mostly on a dy-
namometer. We acknowledge that more comprehensive data
collection using different vehicles may be necessary to gener-
alize our ﬁndings. We also are aware that driving conditions
may affect correlations of CAN signals, and the dynamometer
conditions may be restrictive.
Parameter tuning. The proposed framework allows for ﬂex-
ible election of linkage functions (e.g., single, complete,
average, Ward) for computing the hierarchical clusterings and
the scaling parameter r and α to control the inﬂuence of
hierarchical clusterings with shared lineages. Here, we ﬁxed
the values of r and α to focus on differences at higher levels of

the dendrograms or in groups of correlated signals. However,
we acknowledge that the optimal selection of these parameters
may depend on the type of attack and driving conditions. We
did not explore those variables in this research.
Not real-time detection. As is currently presented, this is not
a real-time detector.
Baseline comparison. We did not compare our proposed
forensic framework with other methods.

VI. CONCLUSION

In this research, we proposed a forensics framework for the
detection of masquerade attacks in the CAN bus. To ascertain
this fact in experiments, we compute time series clustering
similarity. We show that the similarity of time series clusters
under benign conditions exhibits statistically signiﬁcant dif-
ferences from the the similarity of time series clusters under
attack conditions. We demonstrated these differences under
different attack scenarios with different levels of sophistication
using data from the ROAD dataset. This work shows that it
is possible to detect masquerade attacks by effectively using
the time series clustering representation of signals in the CAN
bus and appropriate choices of parameters to group them.

Future work in this area includes the development of a
real-time IDS that uses the principles described in this work.
Additional work includes the translation of such developments
to edge computing devices that can be integrated with real-
world vehicle conditions.

VII. ACKNOWLEDGMENTS

This research was sponsored in part by Oak Ridge National
Laboratory’s (ORNL’s) Laboratory Directed Research and
Development Program. This research used resources of the
Compute and Data Environment for Science (CADES) at
ORNL, which is supported by the Ofﬁce of Science of the
U.S. Department of Energy under Contract No. DE-AC05-
00OR22725.

REFERENCES

[1] C. Miller and C. Valasek, “Remote exploitation of an unaltered passenger

vehicle,” Black Hat USA, vol. 2015, p. 91, 2015.

[2] ——, “CAN message injection: OG dynamite edition,” Tech. Rep., 2016.
[3] K.-T. Cho and K. G. Shin, “Fingerprinting electronic control units for
vehicle intrusion detection,” in Proceedings of the 25th USENIX Security
Symposium, 2016, pp. 911–927.

[4] M. E. Verma, M. D. Iannacone, R. A. Bridges, S. C. Holliﬁeld, P. Mori-
ano, B. Kay, and F. L. Combs, “Addressing the Lack of Comparability &
Testing in CAN Intrusion Detection Research: A Comprehensive Guide
to CAN IDS Data & Introduction of the ROAD Dataset,” 2022, arXiv
preprint arXiv:2012.14600, January 2022.

[5] H. M. Song, H. R. Kim, and H. K. Kim, “Intrusion detection system
based on the analysis of time intervals of CAN messages for in-vehicle
network,” in Proceedings of the International Conference on Information
Networking (ICOIN), 2016, pp. 63–68.

[6] M. R. Moore, R. A. Bridges, F. L. Combs, M. S. Starr, and S. J. Prowell,
“Modeling inter-signal arrival times for accurate detection of CAN bus
signal injection attacks: a data-driven approach to in-vehicle intrusion
detection,” in Proceedings of the 12th Annual Conference on Cyber and
Information Security Research, 2017, pp. 1–4.

[7] D. H. Blevins, P. Moriano, R. A. Bridges, M. E. Verma, M. D. Iannacone,
and S. C. Holliﬁeld, “Time-based can intrusion detection benchmark,”
in Proceedings of the Workshop on Automotive and Autonomous Vehicle
Security (AutoSec), 2021, pp. 1–6.

7

A. Hierarchical Clustering Deﬁnition

APPENDIX

Here we mathematically deﬁne hierarchical clustering. A partition
P, of S breaks S into non-overlapping subsets {C 1, C 2, . . . , Cm},
i.e., S = (cid:83)
i∈{1,2,...,m} C i. A clustering is a partition, so the elements
of the partition are called clusters. A partition B of S is nested in a
partition A of S if every subset of B is a subset of a subset of A,
i.e., ∀C i ∈ B ∃j : C i ⊆ C j ∈ A. A hierarchical clustering is then a
sequence of partitions in which each partition is nested into the next
partition in the sequence.

B. Brief CluSim Overview

Here we describe how CluSim works in brevity. See Gates et
al. [23] for full details. Given S = {X 1, X 2 . . . , X N } and a
clustering A = {C 1, C 2, . . . , Cm}, ﬁrst make the bipartite graph
with elements of S on the left, clustering assignments from A on
the right, and edges denoting containment (i.e., (X i, C j) is an edge
if and only if X i is in cluster C j). Note that this can be naturally
extended to a dendrogram representing a hierarchical clustering A
by using a weighted bipartite graph, where the weight of the edges
is given by a hierarchy weighting function based on the level of
the cluster assignation within the hierarchical clustering. Next, the
bipartite graph is projected into the S elements producing a weighted,
directed graph that captures the inter-element relationships induced
by common cluster memberships. Now equipped with a weighted,
directed graph on S, the CluSim method captures high-order co-
occurrences of elements by taking into account their paths to obtain
an equilibrium distribution of a personalized diffusion process on
the graph, or personalized PageRank (PPR) [29], i.e., for each X i
in S, a PageRank version with restart to X i given by probability
1 − α is used to produced stationary distribution pi. The element-
wise similarity of an element X i in two different clusterings A and B
is found by comparing the stationary distributions pA
i using
a variation of the (cid:96)1 metric for probability distributions. Finally, the
similarity score of two clusterings A, B is the average of element-
wise similarities. CluSim is parametrized by specifying r and α.
Here, r is a scaling parameter that deﬁnes the relative importance of
memberships at different levels of the hierarchy. That is, the larger
r, the more emphasis on comparing lower levels of the dendrogram
(zoom in). In addition, α is a parameter that controls the inﬂuence of
hierarchical clusterings with shared lineages. That is, the larger α, the
further the process will explore from the focus data element, so more
of the cluster structure is taken into account into the comparison. We
used r = 5.0 and α = 0.9 in Figure 2.

i and pB

[8] U. E. Larson, D. K. Nilsson, and E. Jonsson, “An approach to
speciﬁcation-based attack detection for in-vehicle networks,” in Proceed-
ings of the IEEE Intelligent Vehicles Symposium, 2008, pp. 220–225.
[9] M. Bresch and N. Salman, “Design and implementation of an intrusion
detection system (ids) for in-vehicle networks,” Master’s thesis, Univer-
sity of Gothenburg, 2017.

[10] H. Olufowobi, C. Young, J. Zambreno, and G. Bloom, “SAIDuCANT:
Speciﬁcation-Based Automotive Intrusion Detection Using Controller
Area Network (CAN) Timing,” IEEE Transactions on Vehicular Tech-
nology, vol. 69, no. 2, pp. 1484–1494, 2019.

[11] W. Wu, R. Li, G. Xie, J. An, Y. Bai, J. Zhou, and K. Li, “A survey
of intrusion detection for in-vehicle networks,” IEEE Transactions on
Intelligent Transportation Systems, vol. 21, no. 3, pp. 919–933, 2019.

[12] A. Taylor, S. Leblanc, and N. Japkowicz, “Anomaly detection in auto-
mobile control network data with long short-term memory networks,”
in Proceedings of the IEEE International Conference on Data Science
and Advanced Analytics (DSAA), 2016, pp. 130–139.

[13] M. Hanselmann, T. Strauss, K. Dormann, and H. Ulmer, “CANet: An
unsupervised intrusion detection system for high dimensional CAN bus
data,” IEEE Access, vol. 8, pp. 58 194–58 205, 2020.

[14] M. E. Verma, R. A. Bridges, J. J. Sosnowski, S. C. Holliﬁeld, and M. D.
Iannacone, “CAN-D: A Modular Four-Step Pipeline for Comprehen-
sively Decoding Controller Area Network Data,” IEEE Transactions on
Vehicular Technology, vol. 70, no. 10, pp. 9685–9700, 2021.

[15] A. Ganesan, J. Rao, and K. Shin, “Exploiting consistency among
heterogeneous sensors for vehicle anomaly detection,” SAE Technical
Paper, Tech. Rep., 2017.

[16] H. Li, L. Zhao, M. Juliato, S. Ahmed, M. R. Sastry, and L. L.
Yang, “Poster: Intrusion detection system for in-vehicle networks using
sensor correlation and integration,” in Proceedings of the 2017 ACM
SIGSAC Conference on Computer and Communications Security, 2017,
pp. 2531–2533.

[17] P. Sharma, J. Petit, and H. Liu, “Pearson correlation analysis to detect
misbehavior in vanet,” in Proceedings of the 88th Vehicular Technology
Conference (VTC-Fall), 2018, pp. 1–5.

[18] F. Guo, Z. Wang, S. Du, H. Li, H. Zhu, Q. Pei, Z. Cao, and J. Zhao,
“Detecting vehicle anomaly in the edge via sensor consistency and
frequency characteristic,” IEEE Transactions on Vehicular Technology,
vol. 68, no. 6, pp. 5618–5628, 2019.

[19] T. He, L. Zhang, F. Kong, and A. Salekin, “Exploring inherent sensor
redundancy for automotive anomaly detection,” in Proceedings of the
57th ACM/IEEE Design Automation Conference (DAC), 2020, pp. 1–6.
[20] N. Leslie, “An unsupervised learning approach for in-vehicle network
intrusion detection,” in Proceedings of the 55th Annual Conference on
Information Sciences and Systems (CISS), 2021, pp. 1–4.

[21] A. Javed, B. S. Lee, and D. M. Rizzo, “A benchmark study on time series
clustering,” Machine Learning with Applications, vol. 1, p. 100001,
2020.

[22] L. Kaufman and P. J. Rousseeuw, Finding Groups in Data: An Intro-

duction to Cluster Analysis.

John Wiley & Sons, 2009, vol. 344.

[23] A. J. Gates, I. B. Wood, W. P. Hetrick, and Y.-Y. Ahn, “Element-centric
clustering comparison uniﬁes overlaps and hierarchy,” Scientiﬁc Reports,
vol. 9, no. 1, pp. 1–13, 2019.

[24] G. N. Lance and W. T. Williams, “A general theory of classiﬁcatory
sorting strategies: 1. hierarchical systems,” The Computer Journal,
vol. 9, no. 4, pp. 373–380, 1967.

[25] A. J. Gates and Y.-Y. Ahn, “CluSim: A Python package for calculating
clustering similarity,” Journal of Open Source Software, vol. 4, no. 35,
p. 1264, 2019.

[26] K. Pearson, “Notes on regression and inheritance in the case of two
parents,” Proceedings of the Royal Society of London, vol. 58, pp. 240–
242, 1895.

[27] H. B. Mann and D. R. Whitney, “On a test of whether one of two
random variables is stochastically larger than the other,” The Annals of
Mathematical Statistics, pp. 50–60, 1947.

[28] M. L. Waskom, “seaborn: statistical data visualization,” Journal of Open

Source Software, vol. 6, no. 60, p. 3021, 2021.

[29] T. H. Haveliwala, “Topic-sensitive PageRank: A context-sensitive rank-
ing algorithm for web search,” IEEE Transactions on Knowledge and
Data Engineering, vol. 15, no. 4, pp. 784–796, 2003.

8

