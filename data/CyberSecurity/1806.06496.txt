9
1
0
2

n
u
J

3
2

]

R
C
.
s
c
[

3
v
6
9
4
6
0
.
6
0
8
1
:
v
i
X
r
a

The 18th IEEE International Conference on Trust, Security and Privacy in Computing and
Communications (TrustCom’19)

Power-Grid Controller Anomaly Detection with
Enhanced Temporal Deep Learning

Zecheng He
Princeton University
Princeton, NJ
zechengh@princeton.edu

Aswin Raghavan
SRI International
Princeton, NJ
aswin.raghavan@sri.com

Guangyuan Hu
Princeton University
Princeton, NJ
gh9@princeton.edu

Sek Chai
SRI International
Princeton, NJ
sek.chai@sri.com

Ruby Lee
Princeton University
Princeton, NJ
rblee@princeton.edu

Abstract—Controllers of security-critical cyber-physical sys-
tems, like the power grid, are a very important class of computer
systems. Attacks against the control code of a power-grid system,
especially zero-day attacks, can be catastrophic. Earlier detection
of the anomalies can prevent further damage. However, detecting
zero-day attacks is extremely challenging because they have no
known code and have unknown behavior. Furthermore, if data
collected from the controller is transferred to a server through
networks for analysis and detection of anomalous behavior, this
creates a very large attack surface and also delays detection.

In order to address this problem, we propose Reconstruction
Error Distribution (RED) of Hardware Performance Counters
(HPCs), and a data-driven defense system based on it. Speciﬁ-
cally, we ﬁrst train a temporal deep learning model, using only
normal HPC readings from legitimate processes that run daily
in these power-grid systems, to model the normal behavior of the
power-grid controller. Then, we run this model using real-time
data from commonly available HPCs. We use the proposed RED
to enhance the temporal deep learning detection of anomalous
behavior, by estimating distribution deviations from the normal
behavior with an effective statistical test. Experimental results on
a real power-grid controller show that we can detect anomalous
behavior with high accuracy (>99.9%), nearly zero false positives
and short (<360ms) latency.

I. INTRODUCTION

The power-grid is a critical infrastructure, and attacks on
it can cripple society, affecting national security, economic
competitiveness and societal interactions. In 2015, Ukraine
experienced cyber attacks against its power-grid system [2].
During this attack, 30 substations were switched off and
230 thousand people were left without electricity. The U.S.
Government Accountability Ofﬁce (GAO) questioned the cur-
rent adequacy of defenses against power-grid attacks, and
the North American Electric Reliability Corporation (NERC)
has recognized these concerns [24]. With power-grid substa-
tions controllable through cyberspace transactions, the concern
about cyber attacks on the physical power-grid systems is a
real and serious threat, which is the focus of our paper.

There have been detection approaches proposed to protect
the power-grid system by examining the physical sensors

[18], [26]. However, the approaches examining sensors only
consider the physical part but
ignored the cyber attacker.
Furthermore, they focused on the algorithms but neglected
the system design. Previous work on the cyber-security of
power-grid systems focused on protecting the networks and
data transmission [27], [22]. Each of these solved a speciﬁc
loophole of secure communication in the power-grid system,
but did not protect controllers and cannot detect new attacks.
Besides the physical sensors and network, protecting the
control code running on the industrial programmable logic
controllers (PLCs) is an essential and fundamental task in
protecting the power-grid systems. No matter how the adver-
sary spreads the malware or bad programs through system
vulnerabilities, his ultimate goal is taking control of the power-
grid infrastructures, destroying them or turning them off, and
thus inducing huge physical impact. This attack strategy on
the industrial controller has been shown in the Stuxnet [14]
and BlackEnergy [2] attacks. Therefore, rather than physical
attacks on the physical power-grid system, we consider cyber
attacks that hijack the controller code that controls the actua-
tors of the physical system.

The problem of protecting the controllers in the power-
grid system is a critical unsolved problem. It is challenging
because (cid:172) there is no prior-knowledge about
the attacks,
especially in ”zero-day” attacks. (cid:173) Various controllers, e.g.
ABB, Siemens and Wago, and OS, e.g. Windows, Unix and
proprietary OS (SIMATIC WinCC), are widely used in modern
power-grid systems, exposing a large attack surface. (cid:174) The
power-grid systems usually implement weak anti-virus and
integrity checking mechanisms on both executed code and
transferred data, due to the computation capacity and hard-
realtime constraints [12]. (cid:175) Many concurrent threads are run-
ning on the controller simultaneously. Stealthy attack programs
that have infected the controller can hide within these threads.
In this paper, we propose a new method, Reconstruction
Error Distribution (RED) of Hardware Performance Coun-
ters (HPCs), to detect anomalies in power-grid controllers.

 
 
 
 
 
 
Our proposed defense provides comprehensive and reliable
protection against unknown attacks. It does not
look for
speciﬁc attacks or triggers, but rather takes a holistic view of
controller operation. Speciﬁcally, our proposed approach ﬁrst
automatically learns the normal behavior of the controller, and
generates a corresponding behavioral model and a RED proﬁle
of the controller. Then we use the generated model, enhanced
by an effective statistical test, to detect the RED deviation
from the controller’s normal behavior.

Our main contributions in this paper are:
• We propose Reconstruction Error Distribution (RED) of
Hardware Performance Counters (HPCs) as a proﬁle of
the controller’s normal behavior, and show it is effective
in detecting anomalies in power-grid controllers.

• We

implement

learning-based,
a new data-driven,
statistically-enhanced system based on RED for detect-
ing anomalies in the power-grid controllers. No prior-
knowledge of attacks is needed in either the training or
inference, thus it can be used to detect zero-day attacks.
• We evaluate our proposed defense on real power-grid
controllers in multiple dimensions. We simulate publicly
reported attack functionalities [14], [5] and other attacks,
and show the superiority of our proposed solution, com-
pared to other machine learning approaches.

Fig. 1: A diagram of a power-grid system. Attacks can happen
in (cid:172) sensors (cid:173) actuators (cid:174) controllers and (cid:175) networks.

controller in a power-grid subsystem. Figure 2 shows the
block diagram of a PLC [1]. A PLC is composed of several
subsystems, e.g. CPU, internal memories and communication
interface. A PLC can take physical sensor (and other) inputs
from the target industrial devices, make decisions and send
commands to control a large range of devices and actuators.

In Section II, we provide background material. In Section
III, we articulate our threat model. In Section IV, we present
our approach in detail. In Section V, we present the accuracy
and performance evaluation, respectively. We discuss related
work in Section VI and conclude in Section VII.

II. BACKGROUND

A. Power-Grid System Architecture and Vulnerability

Figure 1 shows a SCADA (Supervisory Control And Data
Acquisition) system controlling a power-grid [3]. While the
rest of the SCADA network and components are similar
to general information processing systems, the power-plant
substations are the cyber-physical systems we focus on. The
key components in these substations are physical sensors
(e.g. voltage, current), actuators (e.g. relays, valves) and pro-
grammable logic controllers (PLCs). The PLC obtains inputs
from the sensors, and outputs control signals to the actuators
according to its control logic or control code. The substations
are connected through local networks.

Attacks against the power-grid system can happen in sen-
sors, actuators, controllers and the interconnected networks
illustrated in Figure 1. Attacks against the physical actuators
or sensors usually require physical accesses to the devices,
and are not in the scope of this paper. The ultimate goal
of the network attacks against the power-grid is launching
the malware, compromising the controller to induce physical
damage. Hence, we focus on the detection of the controller’s
abnormal behavior on the power-grid.

B. Programmable Logic Controller (PLC)

A programmable logic controller (PLC) is a digital device,
equipped with microprocessors, which is widely used as the

Fig. 2: Programmable logic controller block diagram [1]

The PLC used in our experiments is a Wago PLC with an
ARM Cortex A8 processor. A custom real-time Linux OS runs
on this PLC. This PLC is widely used as the controller in a
power-grid system.

C. Hardware Performance Counters

Controller hardware events, such as the number of executed
instructions, cache operations and misses, are automatically
and securely counted and stored in Hardware Performance
Counters (HPC) – a set of special-purpose registers. HPCs
are now widely available in commodity processors, e.g., Intel,
ARM and PowerPC.

In this work, we use low-level hardware events to mon-
itor the controller behavior. Hardware performance counters
provide a high tamper-resistant and low-cost way to monitor
the controller behavior. First, unlike anti-virus software, HPCs
are hardware that cannot be directly accessed and modiﬁed
by malware [28]. This characteristic of HPCs signiﬁcantly
increases the tamper-resistant property. Second, HPCs au-
tomatically record the hardware events, requiring no extra
logging or recording. Reading from HPCs is more efﬁcient

2

PLCPLCPower-Plant SubstationPower-PlantSubstationVoltage SensorsCurrent SensorsRelayTurbines TemperatureVoltage SensorsValvesSCADANetworkData ServerApplication ServerEngineering StationFirewallOutside WorldCurrent Sensors(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:2)(cid:2)(cid:2)(cid:3)(cid:3)(cid:4)(cid:4)CPUHPCRAMROMEAPROMProgrammable PortDigital I/OInterfaceAnalog I/OInterfacePulse Counter and TimerAdditionalDigital I/O InterfaceCommunication InterfaceInternal BusPLCProgramming ConsoleComputerHand-held TerminalDC InputRelay OutputTransistor OutputTriacOutputAC InputAC OutputOther Devicesthan hashing the whole control code, making it low-cost with
negligible overhead.

III. THREAT MODEL

We consider cyber attacks that hijack the controller code
that controls the actuators of the physical system, making the
controller behave abnormally. We do not explicitly consider
the attacks against networks in power-grid systems, because
the ultimate goal of the network attacks is corrupting the
controller, which has been shown in the Stuxnet [14] and
BlackEnergy [2] attacks. Thus these attacks can be detected
if we can detect
the controller’s anomalous behavior. We
highlight the key points of our threat model in detail:
Our threat model speciﬁcally includes zero-day attacks.
We assume that there is no prior-knowledge of attack code, and
the way the adversary hijacks the controller. We only assume
the goal of the attacker is to hijack the controller and run
unauthorized code on the hijacked controller. Note that we
do not make any assumptions about the type of unauthorized
code, i.e., it can be malicious control logic, worms, trojans
or spyware, etc. Therefore,
though not explicitly targeted,
availability and conﬁdentiality breaches are also included in
our threat model. Furthermore, we assume the normal behavior
of the controller can be collected in a clean environment and
used for training a deep learning model.
Attacker Capabilities. We consider an active attacker who
can hijack the controller code, add to, delete or modify the pro-
grams running on the controller. Consequences of the attacks
include controller failures, incorrect outputs to the controlled
physical actuators and other subsystems. The attacker is able to
bypass the ﬁrewall through system vulnerabilities or client-side
attacks, e.g the misuse of unauthorized USB drive in Stuxnet.
The attacker can either access the victim system remotely (e.g.
via network or Botnet) or physically (e.g. USB). The attack
code can be polymorphic and stealthy.
Target Systems. We consider a power-grid system in our
threat model, especially the cyber-physical power substation
with a PLC. We assume the power-grid substation implements
weak anti-virus and integrity checking mechanisms on both
executed code and transferred data, due to the computation
capacity and hard-realtime constraints [12]. We assume the
low-level hardware performance counters are accessible and
trusted. This assumption is reasonable because hardware regis-
ters are harder to tamper with than software. The target system
is relatively stable, i.e. the code running on the controller
changes infrequently. This assumption is reasonable because
the control processes, once downloaded to the controller,
usually are not updated very often [15].

IV. DETECTION METHODOLOGY

A. Overview

We consider the attack scenario in which the attacker
breaches the integrity of the control code and causes the
controller to function incorrectly in the power-grid system.
Our key idea is, the normal behavior of the controller in

a power-grid system is predictable using a temporal deep
learning model and low-cost HPC features. We deﬁne RED,
Reconstruction Error Distribution, of hardware performance
counters, as a robust way to detect controller anomalies. The
deviation of the real monitored behavior from the predicted
behavior indicates the anomalies. We further use a statistical
test to emphasize such deviations. We show our proposed
architecture in Figure 3.

There are two phases, i.e. ofﬂine training and proﬁling and
online detection and mitigation, and ﬁve steps in the power-
grid controller anomaly detection. The ofﬂine phase consists
of two main steps:

1) Training a deep learning sequence predictor to pre-
dict future normal controller behavior. The sequence
predictors we explore are Long Short-Term Memory
(LSTM) and Conditional Restricted Boltzmann Machine
(CRBM).

2) Calculating the baseline RED D1 as the reference dis-
tribution. In our experiments, we use the squared error
of the predicted behavior v1 and the observed behavior
v2, i.e. |v1 − v2|2, as the reconstruction error.
The online detection phase consists of three main steps:

1) Using the sequence predictor online to predict the future
behavior using the historical behavior. Calculating the
RED D2 of the observed (testing) behavior which can
be normal or abnormal.

2) Applying the statistical test on D1 and D2 to determine

if they are from the same distribution.

3) If an anomaly is detected, the anomaly response module
is triggered. One action is to switch to a ”safe but not
updated” version of the control code, and send out an
alarm.

Next, we highlight some challenges and concerns in design-

it

ing an effective protection for power-grid controllers.
Availability of only normal data. Since attack data is very
is very hard to obtain. Furthermore, zero-day
sensitive,
attacks have no attack code nor known behavior. To address
this challenge, our proposed approach only needs normal data.
Speciﬁcally, it predicts the future behavior of the controller
through a deep temporal model, and investigates the deviation
between the prediction and observation error distributions.
Capturing high-level controller behavior with low-level
HPC features. Although using HPC measurements beneﬁts
from the low-cost and high tamper-resistant properties, it is
challenging to appropriately capture and characterize high-
level controller behavior from the low-level hardware events.
Conventional machine learning or clustering based anomaly
detection approaches require carefully designed heuristic fea-
tures, however, high-level semantic features are typically hard
to handcraft from low-level measurements.
Comprehensive protection. To provide comprehensive pro-
tection, we monitor all threads running on the controller. HPCs
automatically record the hardware events, requiring no extra
logging or recording. Reading from HPCs is more efﬁcient
than hashing the whole control code, making it low-cost with

3

RBM which considers historical information, i.e., Conditional-
RBM (CRBM). We compare LSTM and CRBM used as the
controller behavior predictors in our evaluation.
Model training. A temporal deep learning model is trained,
illustrated as (cid:172) in Figure 3, to predict the controller’s future
behavior based on its historical behavior.

In the training, we ﬁrst collect a set of sequences of
the controller behavior measurement {Si}N
i=1, which are HPC
measurements in our scenario, in a clean environment. N is
the number of total sequences. Each sequence Si consists of
i , ..., ST
T continuous behavior measurements, i.e. Si = [S1
i ]. In
our experiments, each behavior measurement St
i is a vector
consisting of 4 HPC readings for 23 threads, i.e. a vector
of dimension 4*23=92. At time t, the deep learning model
predicts St+1
i , ..., St
i]. We denote
i
this prediction as Pt+1
. The loss function is deﬁned as the
accumulated prediction errors, i.e.

using behavior history [S1

i

loss =

1
N

1
T − 1

N
∑
i=1

T
∑
t=2

(St

i − Pt

i )2

(1)

Intuitively, since {Si}N
i=1 are normal behavior collected
in the clean environment,
the loss penalizes the incorrect
prediction of normal behavior. We train this model to minimize
the loss function with Stochastic Gradient Descent (SGD).
Reconstruction error distribution proﬁling. After training
the model, we proﬁle the normal behavior in terms of recon-
struction error distribution (RED), illustrated as (cid:173) in Figure
3. First, a longer reference sequence of controller behavior
measurement, R = [R1, ..., RT (cid:48)
], is collected in the clean en-
vironment. Note that R is another sequence rather than the
previous Si, consisting of T (cid:48) time frames. Each time frame Ri
is a vector of dimension 4*23=92 in our experiment. Second,
at time frame t, we use the trained model to predict time
frame t + 1,..., t + L using the corresponding history behavior.
We denote the prediction as Pt+1, ..., Pt+L respectively. The
reconstruction error is deﬁned as:

E(t) =

(Ri − Pi)2

(2)

t+L
∑
i=t+1

We deﬁne the distribution of {E(1), E(2), E(3)...} as the
Reconstruction Error Distribution (RED). Using the RED
as the proﬁle has several advantages. (cid:172) It is more robust to
the noise in the measurement, because noise makes a single
prediction error vary signiﬁcantly but the distribution remains
stable. (cid:173) It simpliﬁes the model learning process. Since we
proﬁle the error distributions, we no longer need to train a
”perfect” predictor. (cid:174) It broadens the scope of target systems
by decreasing the required level of predictability. By using
RED, we allow imprecisions in the prediction, reducing the
required predictability of the system to a mild level.

In the proﬁling, collections of the reference RED are
required to be gathered in a clean environment. This can be
done by collecting the HPC sequences immediately after a
trusted version of the control code is uploaded. The gathered
HPC sequences are sent to the trained model to calculate

4

Fig. 3: Overview of our proposed deep temporal model and
test based method. Ofﬂine proﬁling: (cid:172) Train a
statistical
deep learning model with only normal data, to predict the
normal behavior of the controller. (cid:173) Collect the reference
reconstruction error distribution (RED) D1 of the baseline
behavior. Online detecting: (cid:174) Monitor the real behavior of
the controller and compute the observed reconstruction error
distribution (RED) D2. (cid:175) Statistically test if D1 and D2 are
the same distribution. If not, trigger the (cid:176) response and attack
mitigation module.

negligible overhead to monitor all running processes. There are
fewer threads (10-100) running on the power-grid controller
than a general- purpose system, making it possible to monitor
all threads.
Polymorphic and stealthy attacks. To bypass any static
malware analysis, the adversary can write code variants that
are functionally equivalent (polymorphic codes), or hide by
prolonging the time-span, or mimicking the normal behavior.
Our detection algorithm must characterize the program by its
functionality and behavior.

B. Ofﬂine Training and Reconstruction Error Proﬁling

Model selection. Among the deep learning models, Recurrent
Neural Network (RNN) and its variation, Long Short-Term
Memory (LSTM), [11] have become the most powerful ones
in modeling sequential data. An LSTM cell has three gates
that control information ﬂow: the forget gate, the input gate
and the output gate. The forget gate controls the amount
of previous information remaining in the cell memory. The
input gate controls the amount of new information ﬂowing to
the cell memory, and the output gate controls the amount of
information ﬂowing to the output. Thus, LSTM automatically
determines what information to ”remember” and ”forget”.

We also explore the Conditional Restricted Boltzmann
Machine (CRBM). RBM is a shallow, two-layer stochastic
neural network. Each node in the visible layer takes a low-
level feature (e.g. HPC values), each node in the invisible
layer represents a high-level learned feature (e.g. controller
behavior). However, the vanilla RBM does not capture the tem-
poral information, therefore in this work, we use a variant of

ProgrammableLogicController(PLC)Process 1HPCProcess MHPCProcess 2HPC…Training Module(cid:1)BehaviorModelProgrammableLogicController(PLC)Process 1HPCProcess MHPCProcess 2HPC…Anomaly DetectorOffline Trainingand ProfilingOnline Detection and MitigationObservedREDD2StatisticalTest ModuleBehaviorPredictorReferenceREDD1Normal/AbnormalCode Version ControllerMitigation ModuleAlarmAbnormal(cid:2)(cid:3)(cid:4)(cid:5)“OK” lightNormalReferenceREDD1the reference RED. These REDs are then stored in secure
memory, and used as the references in the online detection. To
better represent the RED by the empirical samples, multiple
reference REDs can be generated and compared with the
observed RED in the online detection phase.
Model evolution. To accommodate legitimate controller be-
havior drift, e.g. an update of the control code, the deep
learning model needs to be retrained or ﬁne-tuned online. Note
that either in the initial training or online ﬁne-tuning, the deep
learning model must be trained with HPC measurements from
a clean (no attack) environment. Otherwise, the trained model
cannot predict the normal behavior correctly.

C. Online Hijack Detection and Mitigation

The online hijacking detection is illustrated as steps (cid:174) and
(cid:175) in Figure 3. The controller behavior, in terms of HPCs,
is dynamically monitored at runtime. Similar to the ofﬂine
proﬁling phase, the runtime gathered HPC sequences are sent
to the deep learning module for prediction. The same form
(Eq. 2) of reconstruction errors are calculated and sent to
the Kolmogorov-Smirnov (KS) test module, along with the
reference reconstruction errors gathered in the ofﬂine phase.
All the computations are performed outside the controller, on
the attached trusted anomaly detector module, because if the
controller is hijacked, the results computed by it cannot be
trusted.

Our detection system can be integrated with different mit-
igation approaches. For example, after a controller hijacking
attack is detected, an alarm is sent out. Another mitigation
response is switching to a ”safe version” of controller code in
a ROM, which may not be up-to-date but is free from attack.
Other responses are possible, such as controlling the actuator
settings, while checking that an attack has actually occurred
rather than a false alarm.

D. Anomaly Detection through RED

We now address the problem: how to effectively determine

anomalies from the reconstruction error distribution (RED)?

A simple way to detect anomaly is using a hard threshold on
each individual error point, based on Gaussian assumption [17]
mean + 3 * std on the validation set. However, the Gaussian
assumption is not true, because the reconstruction errors are
non-negative and “long-tail” (Figure 4). Besides, the threshold
value signiﬁcantly affects the accuracy and relies highly on the
selection of the validation set, making it not stable nor reliable.
Hence, we enhance the detection by using the assumption-
free Kolmogorov-Smirnov (KS) test to determine if the ob-
served RED is the same distribution as the reference RED,
without Gaussian assumptions. The KS test is a nonparametric
test of one-dimensional probability distributions. It can be
used to distinguish if two sets of samples are from the same
distribution. The Kolmogorov-Smirnov statistic for two sets
with n and m samples is:

Dn,m = supx|Fn(x) − Fm(x)|

(3)

where Fn and Fm are the empirical distribution functions of
two sets of samples respectively, i.e. Fn(t) = 1
i=1 1xi≤t , and
sup is the supremum function. The null hypothesis that the two
sets of samples are i.i.d. sampled from the same distribution,
is rejected at level α if:

n ∑n

Dn,m > c(α)

(cid:114) n + m
nm

(4)

where c(α) is a pre-calculated value and can be found in the
standard KS test lookup table.

Suppose the reference and questioned RED are D1 and
D2. We draw m and n independent samples from the two
distributions, respectively. We calculate the KS test statistic,
i.e., Dn,m in Eq 3. Then we deﬁne a signiﬁcance level α, i.e. the
probability of detecting a difference under the null hypothesis
that samples are drawn from the same distribution. We reject
the null hypothesis, i.e., recognize the samples as anomalies,
if the inequality in Eq (4) holds.

We show that our enhanced deep learning approach is
effective in amplifying small changes of control logic code in
the PLC to large KS statistics D. We show three representative
examples, Testing Normal (row 1), Attack 1 (row 2) and
Attack 2 (row 3), in Figure 4. (cid:172) The left column shows the
reconstruction errors in the time domain. We observe that,
in general, the reconstruction errors of Attacks (red in the
2nd and 3rd row) are slightly larger than the testing normal
scenario (green in the 1st row). (cid:173) The middle column shows
the histograms of the REDs. We observe that the RED of
testing normals (green, row 1 middle) is more similar to the
reference RED (blue, row 1 middle), than the RED of attacks
(red, rows 2 and 3). (cid:174) The right column shows the KS test
statistics D. We ﬁnd that D is signiﬁcantly larger under the
attacks (rows 2 and 3) than testing normal (row 1). This gives
us assurance that our enhanced deep learning method (LSTM
+ RED) can indeed detect attacks which materialize as only
small code changes in the PLC in power-grid systems. We
show the quantitative comparison results in Section V-C.

Fig. 4: Effectiveness in detecting attacks. Left: REDs in the
time domain. Middle: Histograms of REDs. Right: KS statistic
D. The KS statistic ampliﬁes the differences in the time
domain in cases of attacks (rows 2 and 3), while remaining
small in the case of normal behavior (row 1).

5

ReferenceTesting NormalHistogramofREDDDReferenceAttack1ReferenceAttack 2RED inTimeDomainKSTestStatisticsDV. EVALUATION

A. System Conﬁguration

We implement a prototype of our proposed detection sys-
tem. Our target system is a real power-grid controller sub-
system, running the real deployed power-grid controlling code.
The control codes are written in Structured Text (IEC 61131-
3 standard), and run on the PLC as a multi-threaded program
(e.g., 23 threads as I/O, controls, etc.). The 23 threads in the
Wago PLC process being monitored correspond to the main
thread and 22 threads. When the PLC powers on, 7 threads
are created. When an application is loaded, another 15 threads
will be killed and re-spawned with a different thread ID (TID).
The last thread (PLC Task) is the one speciﬁcally running the
loaded application (utilizing the other threads to do various
tasks). We list the threads and their start phase in Table I.

TABLE I: Threads running on Programmable Logic Controller

Start Time
PLC powers on
(7)

Application
loaded (15)

Main thread (1)

Thread(s)
spi1, codesys3, com DBUS worker, 0ms Watch Thread,
CAAEventTast, SchedExeption, Schedule
WagoAsyncRtHigh, WagoAsyncRtMed, WagoAsyncRtLow,
WagoAsyncHigh, WagoAsyncMed, WagoAsyncLow,
WagoAsyncBusCyc, WagoAsyncBusEvt, WagoAsyncBusEvt,
WagoAsyncBusEvt, WagoAsyncBusEvt, ProcessorLoadWa,
KBUS CYCLE TASK, ModbusSlaveTCP, PLC Task
Main

The HPCs are monitored on a real PLC with an ARM
Cortex A8 processor and a custom real-time Linux distribu-
tion. Data from 4 HPCs was collected for each thread: (cid:172) the
number of cycles and (cid:173) the number of instructions executed,
to provide the overall running status of the thread. (cid:174) The
number of L1 cache misses, to reﬂect the locality and temporal
properties of data usage. (cid:175) The number of branch instructions,
to show the changes in the control ﬂow of the threads. The
total number of HPCs monitored is 4N if there are N threads.
The HPCs are sampled at 1 kHz for each of the 23 threads.
We sample 300,000 samples for each attack running. The data
is relatively stable during our collection.

B. Attack coverage

We evaluate the system with six representative real attacks
in Table II, which are known to cause damage to the power
grid. The evaluated attacks are comprehensive enough to
represent unknown attacks because we consider attacks against
different components of PLCs, i.e. inputs (attack1), control
ﬂow (attacks 2,5), outputs (attack 4,6) and disabling the
whole PLC (attack 3). The attacks include simulating the
publicly reported malicious functionalities of Stuxnet [14]
and BlackEnergy [2], i.e., halting the controller and replaying
prerecorded inputs to the legitimate code.

C. Detection Evaluation

We use 6 performance metrics: accuracy, false positive rate,
false negative rate, precision, recall and F1 score. Precision
measures the ratio of true positives among all predicted pos-
itives. Recall measures the ratio of detected positives among

Fig. 5: (a) Detection results of using LSTM and CRBM as
the predicting module. LSTM performs better than CRBM. (b)
Training mechanism for LSTM and CRBM. LSTM converges
faster and achieves higher ultimate accuracy than CRBM.

all real positives. F1 score is the harmonic mean of Precision
and Recall, which balances these two metrics.
Anomaly Detection Comparison. We show the detection re-
sults of our proposed approach, and compare with conventional
anomaly detection algorithms in Table III. For fair comparison,
we set the accumulated length of gathering RED (250) as
the window size of conventional approaches. Note that all
conventional approaches require heuristic features, while our
approach takes raw data. We ﬁne-tune the hyper-parameters
and report the highest F1 score for the conventional methods.
Our proposed LSTM+RED detection methods (last row)
achieve as high as 99.97% accuracy and 0.9997 F1 score
with no false negatives (all anomalies are detected). Our
proposed LSTM+RED approach performs better than all eval-
uated methods, because conventional methods are not able to
automatically extract inherent but complex features which can
be used to model the normal behaviors of the target power-
grid controller. In addition, our proposed RED provides a more
robust way to detect anomalies by comparing distributions.
Temporal Learning Models Comparison. We investigate
how the types and architectures of the deep learning models
affect
the detection results. We use LSTM with different
hidden nodes and an alternative CRBM model as the predictor
in the experiment. In Figure 5 (a), we observe that the LSTMs
perform better than the CRBM, because the LSTM automati-
cally adjusts the “memory window size” while CRBM uses a
ﬁxed size. In Figure 5 (b), We ﬁnd that LSTM convergences
faster than CRBM, and achieves better ﬁnal detection results.
LSTM also becomes stable at the end of the training, however,
CRBM continues to oscillate as we continue to train it.

By comparing different LSTM architectures in Table IV, we
observe that an LSTM with a medium number (128) of nodes
in the hidden layer performs better than an LSTM with a small
(5) or large (256) number of nodes in the hidden layer. Too
few nodes in the hidden layer signiﬁcantly limit the capability
to represent the controller behavior, while too many nodes in
the hidden layer cause over-ﬁtting.
Ablation Experiment of RED. We evaluate the effectiveness
and necessity of our proposed RED. In Table IV, we compare
the detection results with and without RED. The ﬁrst 4 rows

6

0.90.910.920.930.940.950.960.970.980.991CRBM + KS TestLSTM (5) + KS TestLSTM (64) + KS TestLSTM (128) + KS TestLSTM (256) + KS TestPrecisionRecallF1123456789101.00.90.80.70.60.50.40.30.20.10.0EpochsLSTM accuracyCRBM accuracyLSTM FPCRBM FP(a) Deep learning models (b) Training MechanismTABLE II: Baseline and attacks against a power-grid PLC

Baseline (Testing Normal)
Attack 1
Attack 2
Attack 3
Attack 4
Attack 5
Attack 6

Description
Baseline (a Proportional Integral Derivative (PID) controller)
Overwrite the input (an additional line of code to overwrite the value of the input)
Saturate the input (2 additional lines of code with IF condition on input value)
Disable the PID control code (the entire PID block is commented out)
PID in ”manual” mode (output is ﬁxed)
2 PIDs Cascaded (input of a PID controller is sent through a second PID controller)
Overwrite the output (an additional line of code to overwrite the value of the output)

Attack Type
None
Input hijack
Control ﬂow hijack
Entire Code hijack
Output hijack
Control ﬂow hijack
Output hijack

TABLE III: Anomaly detection methods on detecting zero-day attacks against a real ARM Cortex A8 PLC controlling a real
power-grid. Our proposed LSTM+RED approach performs better than all evaluated methods.

Anomaly Detection Method
One-Class SVM
KNN
PCA
Exponential Moving Average
Elliptic Envelope Estimation [21]
Robust Elliptic Envelope Estimation [23]
Local Outlier Factor [4]
Isolation Forrest [16]
Bitmap Encoding [31]
HBOS [7]
ABOS [13]
CRBM + RED (Explored)
LSTM + RED (Proposed)

Key Hyper-parameters
RBF Kernel, γ =

1
N f eatures

Nneighbors = 5
Ncomponents = 10
Smoothing Factor = 0.2, Smooth Window = 20
Support Fraction = 1.0

Support Fraction =

Nsamples+N f eatures+1
2

Nneighbors = 20
Ntrees = 100
Sections = 4
Nbins = 10, regularizer α = 0.1
Nneighbors = 5
Nhidden = 50
Nhidden = 256

Accuracy
0.849
0.930
0.841
0.911
0.867
0.928
0.929
0.949
0.911
0.899
0.929
0.957
0.9997

False Positive
0.104
0.000
0.161
0.000
0.146
0.079
0.000
0.056
0.001
0.111
0.000
0.062
0.0005

False Negative
0.621
0.766
0.141
0.982
0.000
0.000
0.783
0.000
0.968
0.001
0.784
0.023
0.000

Precision
0.267
1.000
0.347
0.994
0.406
0.559
1.000
0.640
0.799
0.473
1.000
0.934
0.9995

Recall
0.379
0.235
0.859
0.018
1.000
1.000
0.218
1.000
0.032
0.999
0.216
0.977
1.000

F1
0.313
0.380
0.495
0.127
0.578
0.717
0.357
0.780
0.061
0.642
0.355
0.958
0.9997

show the detection results of different LSTMs using hard
thresholds, while the next 4 rows show the corresponding
LSTM + RED for comparison. We observe that the RED im-
proves all evaluated LSTM models and it provides insensitivity
to the deep learning architectures (last 4 rows).

TABLE IV: Effectiveness of enhancing DL with KS test

LSTM(5)
LSTM(128)
LSTM(256)
LSTM(512)
LSTM(5) + RED
LSTM(128) + RED
LSTM(256) + RED
LSTM(512) + RED

Accuracy
0.935
0.977
0.976
0.976
0.998
0.9998
0.9997
0.9997

False Positive
0.028
0.028
0.041
0.041
0.004
0.0004
0.0005
0.0005

False Negative
0.103
0.017
0.007
0.007
0.000
0.000
0.000
0.000

Precision
0.970
0.972
0.960
0.960
0.996
0.9996
0.9995
0.9995

Recall
0.897
0.983
0.993
0.993
1.000
1.000
1.000
1.000

F1
0.932
0.977
0.976
0.976
0.999
1.000
1.000
1.000

D. Latency Evaluation

We list the components that contribute to the overall latency:
(cid:172) LSTM Prediction Time tpredict . This is the inference time
for the LSTM model to predict the controller behavior, in
terms of one HPC reading.
(cid:173) Sampling Interval tsample. This is the interval between two
HPC readings.
(cid:174) Error Accumulation (EA) Time tEA. This is the time to
gather one point of the reconstruction error. Note that in Eq
(2), one point of the reconstruction error is accumulated among
L time frames. Therefore, tEA = max{tpredict ,tsample} × L.
(cid:175) RED Collection Time tRED. This is the time to collect
the testing reconstruction error distribution. This distribution
is represented by NEA independent reconstruction errors in (cid:174).
(cid:176) KS-Test Time tKS. This is the time to compute the KS
statistic and determine if an anomaly has occurred.

The detection latency tdetection, i.e. the time interval between
the occurrence of the attack and the detection of the anomaly:

tdetection = max{tpredict ,tsample} × L × NEA + tKS

(5)

We observe that Eq (5) is dominated by the ﬁrst term. Thus
we look for the minimal L × NEA that maintains false positives
rate (FPR) < 10−4. We observe a signiﬁcant FPR increase
(∼10.4%) after L × NEA = 250, thus we choose L = 10 and
NEA = 25 in our implementation.

TABLE V: Execution time for model training and inferencing,
and KS testing, for detecting controller anomalous behavior.

GPU

Training
21.1 min

tnetwork
100 ms

tsample
1 ms

tpredict
0.53 ms

tEA
25 ms

tRED
250 ms

tKS
8.6 ms (cid:63)

Detection
358.6 ms

(cid:63) KS test is implemented on the CPU.

Table V shows the latency evaluated in our system. The
total detection latency (386.5ms) is much shorter than human
response and reaction time, i.e. a few seconds. Thus, our
proposed method signiﬁcantly reduces the response time and
provides a quick mitigation mechanism.

E. Security Discussion

All the evaluated attacks were successfully detected. We
discuss further potential attack strategies and how they are
defended by our proposed solution.
Case 1: The attacker hides and waits for a speciﬁc time to
launch an attack. Our proposed method provides continuous
and holistic protection of the controller. If the attack code
keeps silent, it does not do any harm to the system. When
the attack becomes active and inﬂuences the behavior of the
controller, our experiments show that we can quickly detect it
and reduce the damage to the system.
Case 2: The attacker tampers with the computation. It
is harder for the attacker to tamper with the prediction and
KS test because the deep learning prediction and KS test are

7

not computed by software on the controller, but done in a
protected module in our design.
Case 3: Adversarial examples [8] against the learning
model. Generating adversarial examples against our system
is generally hard, because the RED is generated from HPCs
which are hard to mimic.

VI. RELATED AND FUTURE WORK

Previous work has shown the feasibility of using HPCs
for detecting malware [19], [6], ﬁrmware-modiﬁcation [30]
and kernel root-kits [29]. To the best of our knowledge, we
are the ﬁrst to use HPCs to detect anomalies in the critical
power-grid controllers. Furthermore, we are the ﬁrst to propose
reconstruction error distribution of HPCs as a proﬁle of normal
behavior, while previous work only use conventional machine
learning and hard thresholds. Previous work on using deep
learning for improving security [25], [20], [10] and protecting
deep learning systems [9], [32] have been proposed.

We detect anomalous behavior in this paper, which may be
attacks or benign. Further situation dependent testing needs to
be done to determine if it is a known or zero-day attack – a
topic for future work. Our proposed defense cannot detect an
attack when the HPCs are not available, e.g. the PLC is shut
down, the PLC does not provide HPC readings, or the HPCs
reading process is terminated by a malicous process.

VII. CONCLUSION

We propose a new data-driven approach to detect anomalous
behavior in power-grid controllers. Our method leverages
a temporal deep learning model, and is enhanced by our
proposed reconstruction error distribution (RED) of low-cost
hardware performance counters (HPCs). A key advantage of
our approach is that only normal data is used, and no prior-
knowledge about the attack data is needed, thus enabling de-
tection of zero-day attacks. We evaluate our detection system
on a real programmable logic controller used in power-grid
substations. We show the signiﬁcant improvement of using
enhanced deep learning compared to 11 conventional anomaly
detection approaches. Experiments show that our proposed
system achieves nearly zero false positives and low latency.
Acknowledgment. We thank Prashanth Krishnamurthy, Far-
shad Khorrami and Ramesh Karri from NYU for giving us
access to the raw data on the baseline behavior of the PLC.

REFERENCES

[1] Programmable logic controller block diagram.

https://www.youtube.

com/watch?v=oOCW5muXNyo, 2010.

[2] December 2015 ukraine power grid cyberattack. https://en.wikipedia.
org/wiki/December 2015 Ukraine power grid cyberattack, 2015.

[3] The

efﬁcacy

integration.
challenges-of-scada-and-smart-grid-integration/, 2016.

and

challenges

grid
https://www.csiac.org/journal-article/the-efﬁcacy-and-\

smart

scada

and

of

[4] Markus M Breunig, Hans-Peter Kriegel, Raymond T Ng, and J¨org
Sander. Lof: identifying density-based local outliers. In ACM sigmod
record, volume 29, pages 93–104. ACM, 2000.

[5] Defense Use Case. Analysis of the cyber attack on the ukrainian power
grid. Electricity Information Sharing and Analysis Center (E-ISAC),
2016.

8

[6] John Demme, Matthew Maycock, Jared Schmitz, Adrian Tang, Adam
Waksman, Simha Sethumadhavan, and Salvatore Stolfo. On the feasi-
bility of online malware detection with performance counters. In ACM
SIGARCH Computer Architecture News, volume 41, pages 559–570.
ACM, 2013.

[7] Markus Goldstein and Andreas Dengel. Histogram-based outlier score
(hbos): A fast unsupervised anomaly detection algorithm. KI-2012:
Poster and Demo Track, pages 59–63, 2012.

[8] Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining
and harnessing adversarial examples. arXiv preprint arXiv:1412.6572,
2014.

[9] Zecheng He, Tianwei Zhang, and Ruby Lee. Sensitive-sample ﬁnger-
In IEEE Conference on Computer

printing of deep neural networks.
Vision and Pattern Recognition (CVPR), 2019.

[10] Zecheng He, Tianwei Zhang, and Ruby B Lee. Machine learning
based ddos attack detection from source side in cloud. In 2017 IEEE
International Conference on Cyber Security and Cloud Computing.
[11] Sepp Hochreiter and J¨urgen Schmidhuber. Long short-term memory.

Neural computation, 9(8):1735–1780, 1997.

[12] Abdulmalik Humayed, Jingqiang Lin, Fengjun Li, and Bo Luo. Cyber-
IEEE Internet of Things Journal,

physical systems securitya survey.
4(6):1802–1831, 2017.

[13] Hans-Peter Kriegel, Arthur Zimek, et al. Angle-based outlier detection
In Proceedings of the 14th ACM SIGKDD
in high-dimensional data.
international conference on Knowledge discovery and data mining,
pages 444–452. ACM, 2008.

[14] Ralph Langner. Stuxnet: Dissecting a cyberwarfare weapon.

IEEE

Security & Privacy, 9(3):49–51, 2011.

[15] Edward A Lee. The past, present and future of cyber-physical systems:

A focus on models. Sensors, 15(3):4837–4869, 2015.

[16] Fei Tony Liu, Kai Ming Ting, and Zhi-Hua Zhou. Isolation forest. In
Data Mining, 2008. ICDM’08. Eighth IEEE International Conference
on, pages 413–422. IEEE, 2008.

[17] Pankaj Malhotra, Lovekesh Vig, Gautam Shroff, and Puneet Agarwal.
Long short term memory networks for anomaly detection in time series.
In Proceedings, page 89. Presses universitaires de Louvain, 2015.
[18] Kebina Manandhar, Xiaojun Cao, Fei Hu, and Yao Liu. Detection of
faults and attacks including false data injection attack in smart grid
using kalman ﬁlter. IEEE transactions on control of network systems,
1(4):370–379, 2014.

[19] Meltem Ozsoy, Khaled N Khasawneh, Caleb Donovick, Iakov Gorelik,
Nael Abu-Ghazaleh, and Dmitry Ponomarev. Hardware-based malware
detection using low-level architectural features. IEEE Transactions on
Computers, 65(11):3332–3344, 2016.

[20] Razvan Pascanu, Jack W Stokes, Hermineh Sanossian, Mady Marinescu,
and Anil Thomas. Malware classiﬁcation with recurrent networks. In
2015 IEEE International Conference on Acoustics, Speech and Signal
Processing (ICASSP), pages 1916–1920. IEEE, 2015.

[21] Peter J Rousseeuw and Katrien Van Driessen. A fast algorithm for the
minimum covariance determinant estimator. Technometrics, 41(3):212–
223, 1999.

[22] Biplab Sikdar and Joe H Chow. Defending synchrophasor data networks
IEEE Transactions on Smart Grid,

against trafﬁc analysis attacks.
2(4):819–826, 2011.

[23] DG Simpson. Introduction to rousseeuw (1984) least median of squares

regression. In Breakthroughs in Statistics. Springer, 1997.

[24] Siddharth Sridhar, Adam Hahn, and Manimaran Govindarasu. Cyber–
physical system security for the electric power grid. Proceedings of the
IEEE, 100(1):210–224, 2012.

[25] Tuan A Tang, Lotﬁ Mhamdi, Des McLernon, Syed Ali Raza Zaidi,
and Mounir Ghogho. Deep learning approach for network intrusion
In Wireless Networks and
detection in software deﬁned networking.
Mobile Communications (WINCOM), 2016 International Conference on,
pages 258–263. IEEE, 2016.

[26] Jorge Valenzuela, Jianhui Wang, and Nancy Bissinger. Real-time
intrusion detection in power system operations. IEEE Transactions on
Power Systems, 28(2):1052–1062, 2013.

[27] Xudong Wang and Ping Yi. Security framework for wireless commu-
nications in smart distribution grid. IEEE Transactions on Smart Grid,
2(4):809–818, 2011.

[28] Xueyang Wang, Sek Chai, Michael Isnardi, Sehoon Lim, and Ramesh
Karri. Hardware performance counter-based malware identiﬁcation and
detection with adaptive compressive sensing. ACM Transactions on
Architecture and Code Optimization (TACO), 13(1):3, 2016.

[29] Xueyang Wang and Ramesh Karri. Numchecker: Detecting kernel
control-ﬂow modifying rootkits by using hardware performance coun-
ters. In Proceedings of the 50th Annual Design Automation Conference,
page 79. ACM, 2013.

[30] Xueyang Wang, Charalambos Konstantinou, Michail Maniatakos, and
Ramesh Karri. Conﬁrm: Detecting ﬁrmware modiﬁcations in embedded
In Proceedings of the
systems using hardware performance counters.
IEEE/ACM International Conference on Computer-Aided Design, pages
544–551. IEEE Press, 2015.

[31] Li Wei, Nitin Kumar, Venkata Nishanth Lolla, Eamonn J Keogh, Stefano
Lonardi, and Chotirat (Ann) Ratanamahatana. Assumption-free anomaly
detection in time series. In SSDBM, volume 5, pages 237–242, 2005.

[32] Tianwei Zhang, Zecheng He, and Ruby Lee. Privacy-preserving machine

learning through data obfuscation. arXiv preprint arXiv:1807.01860.

9

