2
2
0
2

t
c
O
9
1

]

R
C
.
s
c
[

2
v
0
8
7
2
0
.
1
0
1
2
:
v
i
X
r
a

1

SHARKS: Smart Hacking Approaches for RisK
Scanning in Internet-of-Things and
Cyber-Physical Systems based on Machine
Learning

Tanujay Saha, Najwa Aaraj, Neel Ajjarapu and Niraj K. Jha (Fellow, IEEE)

Abstract—Cyber-physical systems (CPS) and Internet-of-Things (IoT) devices are increasingly being deployed across multiple
functionalities, ranging from healthcare devices and wearables to critical infrastructures, e.g., nuclear power plants, autonomous
vehicles, smart cities, and smart homes. These devices are inherently not secure across their comprehensive software, hardware, and
network stacks, thus presenting a large attack surface that can be exploited by hackers. In this article, we present an innovative
technique for detecting unknown system vulnerabilities, managing these vulnerabilities, and improving incident response when such
vulnerabilities are exploited. The novelty of this approach lies in extracting intelligence from known real-world CPS/IoT attacks,
representing them in the form of regular expressions, and employing machine learning (ML) techniques on this ensemble of regular
expressions to generate new attack vectors and security vulnerabilities. Our results show that 10 new attack vectors and 122 new
vulnerability exploits can be successfully generated that have the potential to exploit a CPS or an IoT ecosystem. The ML methodology
achieves an accuracy of 97.4% and enables us to predict these attacks efﬁciently with an 87.2% reduction in the search space. We
demonstrate the application of our method to the hacking of the in-vehicle network of a connected car. To defend against the known
attacks and possible novel exploits, we discuss a defense-in-depth mechanism for various classes of attacks and the classiﬁcation of
data targeted by such attacks. This defense mechanism optimizes the cost of security measures based on the sensitivity of the
protected resource, thus incentivizing its adoption in real-world CPS/IoT by cybersecurity practitioners.

Index Terms—Artiﬁcial Intelligence; Attack Graphs; Cyber-Physical Systems; Cybersecurity; Embedded Systems; Internet-of-Things;
Machine Learning.

(cid:70)

1 INTRODUCTION

C YBER-PHYSICAL systems (CPS) use sensors to feed

data to computing elements that monitor and control
physical systems and use actuators to elicit desired changes
in the environment. Internet-of-Things (IoT) enables di-
verse, uniquely identiﬁable, and resource-constrained de-
vices (sensors, processing elements, actuators) to exchange
data through the Internet and optimize desired processes.
CPS/IoT have a plethora of applications, like smart cities [1],
smart healthcare [2], smart homes, nuclear plants, smart
grids [3], autonomous vehicles [4], and in various other
domains. With recent advances in CPS/IoT-facilitating tech-
nologies like machine learning (ML), cloud computing, and
5G communication systems [5], CPS/IoT are likely to have
an even more widespread impact in the near future.

An unfortunate consequence of integrating multiple
devices in an ecosystem is the dramatic increase in its
attack surface. Most of the CPS/IoT devices are energy-
constrained, which makes them unable to implement exist-
ing elaborate cryptographic protocols and primitives as well
as other conventional security measures across the software,
hardware, and network stacks [6, 7]. The diverse range of
embedded devices in the network and inherent vulnera-

• T. Saha, N. Ajjarapu and N. K. Jha are with the Department of
Electrical Engineering, Princeton University, New Jersey, NJ, 08544
({tsaha,najjarapu,jha}@princeton.edu. N. Aaraj is with Technology In-
novation Institute, UAE (najwa@tii.ae).

bilities in the design and implementation, coupled with an
absence of standard cryptographic primitives and network
security protocols, make CPS/IoT a favorable playground
for malicious attackers. Although lightweight cryptographic
protocols [8, 9] and hardware-based (lightweight) authen-
tication protocols [10, 11, 12] mitigate some threats, most
of the vulnerabilities remain unaddressed. Another chal-
lenge in securing CPS/IoT is the large amount of accessible
data generated by the numerous communication channels
among devices. Such data, in the absence of adequate cryp-
tographic technologies, pose a threat to the CPS/IoT device
and consequently impact user privacy, data conﬁdential-
ity, and integrity. Moreover, CPS/IoT are vulnerable to a
plethora of attacks [6, 13], e.g., buffer overﬂow exploits, race
conditions, XSS attacks that target known vulnerabilities,
and new (undiscovered) vulnerabilities, the exploit of which
is referred to as a zero-day attack.

In this article, we propose an ML-based approach to
systematically generate new exploits in a CPS/IoT frame-
work. We call this approach SHARKS, which is an acronym
for Smart Hacking Approaches for RisK Scanning. ML has
already found use in CPS/IoT cybersecurity [14, 15, 16],
primarily in network intrusion and anomaly detection sys-
tems [17, 18]. These systems execute ML algorithms on data
generated by network logs and communication channels. In
the methodology that we propose, ML instead operates at
both system and user levels to predict unknown exploits

 
 
 
 
 
 
against CPS/IoT.

SHARKS is based on developments along two important
directions. Recognizing the need to depart from the tradi-
tional approaches to cybersecurity, we observe that the main
objective of many security attacks on CPS/IoT is to modify
the behavior of the end-system to cause unsafe operations.
Based on this insight, we propose to model the behavior
of CPS/IoT under attack, at the system and network levels,
use ML to discover a more exhaustive potential attack space,
and then map it to a defense space. Our approach enables a
preemptive analysis of vulnerabilities across a large variety
of devices by detecting new attacks and deploying patches
ahead of time.

We analyze an exhaustive set of real-world CPS/IoT
attacks that have been documented and represent them
as regular expressions. An ML algorithm is then trained
with these regular expressions. The trained ML model can
predict the feasibility of a new attack. The vulnerability
exploits predicted to be highly feasible by the ML algorithm
are reported as novel exploits. This approach successfully
generated 122 novel exploits and 10 unexploited attack
vectors. To demonstrate the applicability of our approach,
we evaluate the trained model on the in-vehicle network of
a connected car. The model was successful in discovering 67
vulnerability exploits in the car network.

The novelty of the proposed methodology lies in:

• Representation of real-world CPS/IoT attacks in the
form of regular expressions and control-data ﬂow
graphs (CDFGs), where both control ﬂow and data
invariants are instrumented at the system level.
• Creation of an aggregated attack directed acyclic
graph (DAG) with an ensemble of such regular ex-
pressions.

• Use of an ML model trained with these regular
expressions to generate novel exploits in a given
CPS/IoT framework.

The article is organized as follows. Section 2 provides
a summary of the work that has been done in the appli-
cation of ML and automation to cybersecurity. Section 3
discusses background material. Section 4 gives details of
our methodology and the results obtained with it. Section 5
describes the application of our algorithm to a connected
vehicle. Section 6 proposes a tiered-security framework,
composed of defense DAGs, for protection against security
vulnerabilities. Section 7 concludes the article.

2 RELATED WORK

In this section, we discuss some of the major works that
have been done to automate security for real-world threat
mitigation. Many major classes of security vulnerabilities,
like memory corruption bugs and network intrusion vul-
nerabilities, can be detected using automation techniques.
The domain of cybersecurity and embedded security that
has been highly inﬂuenced by the popularity of ML is intru-
sion detection systems (IDSs), in particular an IDS targeted
at network-level attacks. Prior to the rapid advancements
in ML, IDSs consisted of signature-based methods and
anomaly-based techniques to detect intrusions in the net-
work or the host systems. Proposed IDSs perform quite well

but have their drawbacks. Signature-based methods require
regular updates of the software and are unable to detect
zero-day vulnerabilities. Anomaly-based methods can de-
tect zero-day vulnerabilities but have a very high false alarm
rate (FAR). The advent of ML alleviated some of these draw-
backs and thus ML was widely adopted in IDSs. Researchers
have used a wide variety of ML methodologies to tackle this
problem, such as unsupervised learning [19], artiﬁcial neu-
ral networks [20, 21], Bayesian networks [22, 23], clustering
methods [24, 25, 26], decision trees [27, 28], ensemble learn-
ing like random forests [29, 30], hidden Markov models [31],
and support vector machines (SVMs) [32, 33, 34]. More
advanced deep learning based IDSs use generative adver-
sarial networks [35] and autoencoders [36]. These methods
provide a reactive security mechanism for detecting ongoing
attacks. They also require signiﬁcant computational over-
head because the models need to be continuously trained
on recent data and all incoming trafﬁc must be processed
by the ML model before it can be catered to by the system.
Our method differs from these methods in that it provides
proactive security and requires zero run-time overhead.

ML has recently been used for malware and rootkit
detection on mobile devices [37, 38, 39, 40]. These meth-
ods analyze the application programming interface (API)
call logs to detect malicious behavior. Another ML-based
malware detection method analyzes the hardware perfor-
mance counters (HPCs) to detect malware execution at run-
time [41]. A drawback of ML systems that are trained on
API call logs, HPCs, and network logs, is that they are only
able to detect the types of malware they have been trained
on. A novel malware with completely different behavior and
signature will go undetected by these detectors. They would
also face difﬁculties in detecting the same malware running
on a different platform and operating system. Our method,
on the other hand, trains on application-independent repre-
sentations of system-level attacks, which makes it platform-
independent and equips it with the intelligence to detect a
much broader class of security breaches.

Attack graphs have been widely used for analyzing
the security of systems and networks [42, 43]. Generating
attack graphs has been a longstanding challenge due to
the state explosion problem. Various automation techniques,
like model checking [44], rule-based artiﬁcial intelligence,
and ML [45, 46], have been used to tackle this challenge.
Analysis of the attack graphs is also a challenge due to the
enormous size and complexity of the graphs. Graph-based
neural networks [47] and reinforcement learning [48] have
been used to analyze attack graphs to detect vulnerabilities.
This article uses attack graphs at a higher granularity to
detect vulnerabilities and the exploits thereof across the
entire hardware, software, and network stacks of CPS/IoT.
In previous works, system-speciﬁc attack graphs have been
used for vulnerability analysis. In this article, we propose
a generalized attack graph that can be applied to detect
vulnerabilities (and exploits thereof) in any CPS/IoT. We
buttress this claim by applying our approach to detect
vulnerabilities in the in-vehicle network of a connected car.
Memory corruption bugs have been a longstanding vul-
nerability in computer systems. A detailed analysis of this
problem is provided in [49]. Automation attempts have also
been made for detecting such bugs. In [50], static analysis is

used to detect memory corruption vulnerabilities.

The discovery of hardware vulnerabilities like Spec-
tre [51] and Meltdown [52] in 2018 opened the door to
new classes of side-channel attacks on device microarchi-
tecture. An automated side-channel vulnerability detection
technique for microarchitectures is proposed in [53]. Our
method aims to achieve a similar goal, but across the entire
hardware, software, and network stacks.

3 BACKGROUND

We model existing CPS/IoT attacks as regular expressions
and CDFGs. We train a popular ML model, namely SVM,
with these CDFGs to predict new vulnerability exploits.
This section provides an introduction to regular expressions,
CDFGs, and SVM models that is required for ease of com-
prehending the rest of the article.

3.1 Regular Expressions

A regular expression is used to denote a set of string
patterns. We use regular expressions to represent known
CPS/IoT attacks in a compact and coherent manner.

The set of all possible characters permissible in a regular
expression is referred to as its alphabet Σ. The basic opera-
tions permitted in regular expressions are [54]:

• Set union: This represents the set union of two regu-
lar expressions. For example, if expression A denotes
{xy, z} and B denotes {xy, r, pq}, then expression
A + B denotes {xy, z, r, pq}.

• Concatenation: This operation represents the set of
strings obtained by attaching any string in the ﬁrst
expression with any string in the second expression.
For example, if A = {xy, z} and B = {r, pq}, then,
AB = {xyr, xypq, zr, zpq}.

• Kleene star: A∗ denotes the set of strings obtained
by concatenating the strings in A any number of
times. A∗ also includes the null string λ. For ex-
ample, if A = {xy, z} then, A∗ = {λ, xy, z, xyz,
zxy, xyxy, zz, xyxyxy, xyzxy, ...}.

In this article, we deﬁne regular expressions at a higher
granularity for the sake of generality. The symbols of the
Alphabet Σ of our regular expressions are generic sys-
tem operations. Σ = {”Access port 1234 of the system,”
”Overwrite pointer address during memory overﬂow,” ...,
”Download unwhitelisted malware”}. All the symbols used
in our regular expressions can be found in the nodes of the
attack graph presented later. These symbols constitute the
regular expression alphabet Σ.

3.2 Control-data Flow Graph

The CDFG of a program is a graphical representation of
all possible control paths and data dependencies that the
program might encounter during its execution. The basic
blocks of the program constitute the nodes of the CDFG. A
basic block is a block of sequential statements that satisfy
the following properties:

• The control ﬂow enters only at the beginning of the

block.

• The control ﬂow leaves only at the end of the block.
• A block contains a data invariant or a low-level

system call.

Basic blocks are widely used in areas like compiler
construction and ﬁnite automata. Generally, basic blocks
denote low-level computer instructions. For the sake of
this article, we use basic blocks to represent higher-level
instructions. We construct the CDFGs at the level of human-
executable instructions rather than assembly-level instruc-
tions, as shown in Fig. 1. We do this to ensure generalizabil-
ity of our method to a wide spectrum of applications and
systems.

Fig. 1: Example of a CDFG

In Fig. 1, bb1 denotes the action of requesting access
to a device. Access can be requested through various
ports and protocols like ftp, ssh or http. The port num-
bers and protocols to be targeted are system-dependent.
We encapsulate these details into a single basic block to
ensure generalizability of our method to all IoT systems
and CPS. Similarly, in Fig. 1, bb3 denotes the action of
accessing the unencrypted key from the device key chain
of a compromised, rooted or jailbroken device. The ex-
act implementation is application-dependent because ev-
ery application stores its keys at different locations. For
example, WhatsApp (for both Android and iOS) stores its
keys in the ﬁle /data/data/com.whatsapp/ﬁles/key. The
assembly-level instructions for accessing the keys are not
generalizable since they are application-dependent. Hence,
we encapsulate all such instructions in a single basic block
to facilitate generalization of our approach.

3.3 Support Vector Machine

We employ ML at the system level. Our training dataset
does not have enough training examples to train a robust
neural network. Thus, we use traditional ML approaches, in-
stead of deep learning, for classiﬁcation. Among traditional
ML classiﬁcation algorithms, SVM is one of the most robust
classiﬁers that generalizes quite well.

SVM is a class of supervised ML algorithms that an-
alyzes a labeled training dataset to perform either classi-
ﬁcation or regression [55]. It is capable of predicting the
label of a new example with high accuracy. It is inherently
designed to be a linear binary classiﬁer. However, kernel

AccessrequestedNo mutualauthenticationEncryption key readin unencrypted formbb1bb2bb3transformations can be used to perform nonlinear classiﬁ-
cation as well. For a dataset with an n-dimensional feature
space, a trained SVM model learns an (n − 1)-dimensional
hyperplane that serves as the decision boundary, also referred
to as the separating hyperplane.

Many contemporary ML algorithms, e.g., k-nearest-
neighbor classiﬁcation, use a greedy search approach. How-
ever, SVM uses a quadratic optimization algorithm to out-
put an optimal decision boundary. The two main limitations
of SVM are its natural binding to binary classiﬁcation and
the need to specify (rather than learn) a kernel function.

4 METHODOLOGY
In our methodology, we extract intelligence from an ensem-
ble of known CPS/IoT attacks and use this system-level
adversarial intelligence to predict other possible exploits in
a given CPS/IoT framework. The automated derivation of
novel exploits and defenses broadly comprises extracting
intelligence, discovering unexploited attack vectors, apply-
ing ML, and taking measures to secure the system. These
processes are depicted in the ﬂowchart of Fig. 2.

4.1.1 Data Collection
Next, we discuss how to extract knowledge from known
attack patterns. To achieve this objective, we create a list of
known CPS/IoT attacks. Then we classify these attacks into
various categories based on the type of vulnerability being
exploited. This list consists of 41 different attacks [6, 56, 57].
The most popular attacks among these and their regular
expressions are shown in Table 1.

4.1.2 Data Transformation
In this phase, we decompose each attack into its basic
system-level operations. We express these sequences of op-
erations as regular expressions that are then represented as
CDFGs. Each attack is now transformed into a CDFG with
system-level operations as its basic blocks. The methodol-
ogy of decomposing an attack into a CDFG is similar to the
method used in [58].

An example of the data transformation procedure for
a buffer overﬂow attack is given next. A buffer overﬂow
attack can be expressed as a sequence of following actions:

1) dynamic memory allocation,
2) overﬂow of memory, and
3) frame pointer with overwritten memory.

Let bbi denote the ith basic block of the sequence. Then

the corresponding regular expression is given by:
bbi(Dynamic memory allocation)∗.bbj(Overﬂow of memory).
bbk(Frame pointer with overwritten memory)

Fig. 2: Flowchart of the overall methodology

4.1 Extracting Intelligence

We document existing CPS/IoT attacks and decompose
them into their constituent system-level actions and used
data invariants. We use regular expressions to represent
these constituent system-level operations. Then we com-
bine the regular expressions of all the attacks to form an
ensemble of interconnected system-level operations. This
ensemble is represented as a DAG. This DAG is henceforth
referred to as the aggregated attack DAG.

Fig. 3: CDFG of buffer overﬂow attacks

Here, bbi denotes the dynamic memory allocation that
occurs in the memory stack before a buffer overﬂow oc-
curs. The Kleene star operation suggests that bbi might
be executed multiple times before bbj is executed. Basic
blocks bbj and bbk are similarly deﬁned. Every basic block
of the regular expression forms a node of the CDFG. The
concatenation operation (represented by the dot operator)
is represented by a branch from the preceding node of the
concatenation operator to its succeeding node. The CDFG
of a buffer overﬂow attack is shown in Fig. 3. In Fig. 3,
we can see that the concatenation between bbi and bbj is
represented by a directed branch from bbi to bbj. The Kleene
star operator should ideally be represented by a self-loop on
the basic block. However, we ignore self-loops in our CDFG
representation. This is because we combine these CDFGs
into a DAG. The acyclic property of a DAG facilitates our
further analysis, but the presence of self-loops violates this
property.

List of known IoT/CPSattacksExpress attacksas regular expressionsVulnerability detectionExhaustively search attack DAGNew attack                    vectorsfound?Data preparationConstruct the training datasetTrain machine learning modelApply machine learning model to test datasetConstruct defense DAGsReport new  attack vectorsReport  novel exploitsYesNoInputOutputOutputExtracting IntelligenceMachineLearningDiscoveringUnexploitedAttack VectorsSecurityMeasuresConstruct attack DAGDynamic memoryallocationMemory overﬂowFrame pointer tooverwritten memorybbibbjbbkTABLE 1: Real-world CPS/IoT attacks and regular expressions

Attack

Therac-25 Radiation Poisoning

Ariane 5 Rocket Explosion
Worcester Airport Control
Tower Communication Hack
Bellingham, Washington,
Pipeline Rupture

Maroochy Shire Wastewater
Plant Compromised

Davis-Besse Nuclear Power
Plant Worm
Worm Cripples CSX Transport
System
Worm Cripples Industrial
Plants

Browns Ferry Nuclear Plant

LA Trafﬁc System Attack
Aurora Generator Test
Internet Attack on Epileptics

Turkish Oil Pipeline Rupture

Stuxnet Attack on Iranian
Nuclear Power Facility

Tests of Insulin Pumps

Houston, Texas, Water
Distribution System Hack
Researcher Defeats Key Card
Locks

Vulnerability category
Race condition /
TOCTOU vulnerability
Integer overﬂow

Buffer overﬂow

Buffer overﬂow

Access
control/Privilege
escalation
Malware/Privilege
escalation
Malware/Privilege
escalation
Malware/Privilege
escalation
Distributed Denial of
Service (DDoS) attack
DDoS attack
Protocol vulnerability
SQL injection
Privilege escalation/
DDoS

Malware through USB

No authentication + No
encryption
Replay attacks
Weak access
management

No authentication

Test of Trafﬁc Vulnerabilities

Weak cryptographic
measures

German Steel Mill Attack

Fatal Military Aircraft Crash
Linked to Software fault
Test of Smart Riﬂes

Black Energy Ukrainian Power
Grid Attack

Mirai Botnet Attack

Unidentiﬁed Water
Distribution Facility Hack
“WannaCry” Ransomware
Attacks

Malware/Privilege
escalation

Software fault

Weak password

Weak authentication

Weak authentication +
DDoS

Web vulnerabilities

Buffer overﬂow

Cryptographic key
management

Regular expression

bbi(access system call)*. bbj (open system call)*

bbi(data invariant > max integer)*
bbi(dynamic memory allocation)*.bbj (overﬂow of memory).bbk(frame pointer
with overwritten memory)
bbi(dynamic memory allocation)*.bbj (overﬂow of memory).bbk(frame pointer
with overwritten memory)

bbi(critical component with one-factor or one-man authentication)*

bbi(critical component with one-factor or one-man authentication)*

bbi(critical component with one-factor or one-man authentication)*

bbi(critical component with one-factor or one-man authentication)*

bbi(port trafﬁc per second > threshold)

bbi(data invariant > threshold)
bbi(access requested)*.bbj (no mutual authentication)*
bbi(user input)*.bbj (user input not compliant with database format)
bbi(critical component with one-factor or one-man authentication)* + bbj (data
invariant > threshold)
bbi(executive ﬁle of new executable at kernel level)*.bbj (sending data through
port to external C2)
bbi(transaction requested)*.bbj (no time stamp check)*.bbk(no mutual
authentication)*.bbl(no hash check)*
bbi(data in transit not encrypted)*
bbi(access requested)*.bbj (no strong authentication, e.g., no public key
infrastructure based authentication or two-factor authentication)*
bbi(access requested)*.bbj (no mutual authentication)*.bbk(encryption key read
from memory in unencrypted format)*
bbi(no encryption of data/commands)*+(bbj (no digital signature on sensor
ﬁrmware)*. bbk(illegal access through unobstructed port)*. (bbl(reconﬁgure the
system specs)* + (bbm(access memory buffer). bbn(overwrite allocated
memory))*))
bbh(open downloaded ﬁle from spear-phishing email)*.bbi(executive
downloaded ﬁle from email)*.bbj (critical component with one-factor or
one-man authentication)*.bbk(access business network)*.bbl(access ports of
entry to production network)*.bbm(manipulate commands to the system)*
bbi(access system ﬁles)*.bbj (rewrite code for updates)*.bbk(delete/modify
important system ﬁles)*
bbi(weak WiFi password)*.(bbj (alter state variables)*+bbk(gain root access))
bbi(spear phishing emails to access business network)*.bbj (maneuver into the
production network)*.(bbk(erased critical ﬁles on disk) + bbm(took control over
important network nodes)*)

bbi(weak password)*.bbj (port trafﬁc per second > threshold)

(bbi(phishing emails to access credentials)*+bbj (SQL injection attacks to get
credentials)*).bbk(weak storage of credentials on front-end server)
bbi(dynamic memory allocation)*.bbj (overﬂow of memory)*.bbk(frame pointer
with overwritten memory in SMBv1 buffer)*
bbi(process starts encrypting data)*.bbj (process new to the system and not
whitelisted)*

4.1.3 Attack DAG

4.2 Applying Machine Learning

Every attack in our list is represented by its correspond-
ing CDFG. All the CDFGs are combined to form a single
DAG. This DAG, shown in Fig. 4, is our aggregated attack
DAG. The attack DAG is a concise representation of the
system and network-level operations of known categories of
CPS/IoT attacks. Every path from a head node to a leaf node
in the attack DAG corresponds to a unique attack vector.

We observe that certain basic blocks appear in multiple
attacks. These basic blocks are represented as a single node
in the attack DAG with in-degree and/or out-degree greater
than 1. Our attack DAG has 37 nodes, represents 41 different
attacks, and has a maximum depth of 6.

Once we have represented the known attacks in the attack
DAG, we observe that some of its unconnected nodes can
be linked together. Every new feasible link that is predicted
by the ML model is considered to be a novel exploit of
vulnerabilities. A link or branch is considered to be feasible
if the control/data ﬂow represented by that branch can be
implemented in a real-world system. We use ML models
to predict if directed branches between various pairs of
nodes of the attack DAG are feasible. Manual veriﬁcation
of the feasibility of all possible branches in the attack DAG
is too time-consuming. Let n be the number of nodes in
the attack DAG and c be the number of examples in the

Fig. 4: The aggregated attack DAG

training dataset. Then the size of the search space of possible
branches is

(cid:33)

(cid:32)

n
2

2

− c = n(n − 1) − c

= n2 − n − c
= Θ(n2)

This quadratic dependence makes it very expensive to per-
form manual checks to exhaustively examine the feasibility
of all the possible branches. In our experiments, we show
that using ML can reduce the search space by 87.2%.

We train the ML model using the attack DAG of known
attack vectors. Once trained, it can predict the feasibility of
new branches in the attack DAG. We derive an SVM model
for this purpose. Since the dataset is very small, consisting
of just 140 datapoints, it prevented us from being able to
adequately train a neural network [59]. However, when our
methodology is applied to a larger scope of cyberattacks, a
neural network model might be an effective tool [60].

4.2.1 Data Preparation

We assign various attributes (features) to the basic blocks of
the attack DAG depending on the type of impact the attack
would have on the system and network. The exhaustive
set of attributes that we used is composed of memory,
data/database, security vulnerability, port/gateway, sensor,
malware, authentication vulnerability, head node, leaf node,
and mean depth of the node. Each node has a binary value (0
or 1) associated with every feature except the mean depth.

The mean depth of a node denotes the average depth of
the node in the attack DAG. For example, nodes ”Certiﬁcate
proxying” and ”SQL query with format -F” have the attributes
shown in Table 2.

TABLE 2: Node attributes

(1)

Attribute

Memory
Data/Database
Security vulnerability
Port/Gateway
Sensor
Malware
Authentication vulnerability
Head node
Leaf node
Mean depth

Certiﬁcate
proxying
0
0
1
0
0
0
1
0
1
1

SQL query with
format -F
0
1
0
0
0
0
0
0
1
3.75

We represent a branch in the attack DAG by an ordered
pair of nodes, i.e., (origin node, destination node). The features
of the branches of the attack DAG are required to train
the ML model. The concatenation of the attributes of the
origin and destination nodes represents the feature vector
of a branch. For example, from Table 2, it can be observed
that the feature vector for the node ”Certiﬁcate proxying” is
[0, 0, 1, 0, 0, 0, 1, 0, 1, 1] and that of node ”SQL query with
format -F” is [0, 1, 0, 0, 0, 0, 0, 0, 1, 3.75]. A plausible branch
from node ”Certiﬁcate proxying” to node ”SQL query with
format -F” will be represented by the ordered concatenation
of the feature vectors of the individual nodes, which is
[0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 3.75]. This vec-

DynamicmemoryallocationMemoryoverﬂowFrame pointerwithoverwrittenmemoryRead downloadedﬁle from emailDownloadunwhiltelistedmalwareExploit vulnerablesoftware to accesssystem as rootCriticalcomponentwith 1-factorauthenticationAccessrequestedInsecure unencryptedstorage of credentialsNo strongauthenticationNo mutualauthenticationEncryption keyread inunencryptedformNo check fortime-stampMissing hash-basedintegrity checkInvariantsunencryptedAccess network address;production/businessaddressAccessdatabase/system ﬁlesEncrypt data anddestruct key1.Access BIOS image2. Decompress kernel image3. Modify BIOS image4. Pass execution to kernelCache poisoningAccess ports ofnetworkNo digital sign onsensor ﬁrmwareSensortamperingAccess memorybufferOverwrite memorybufferManipulatecommands to systemReconﬁgure systemspeciﬁcationsSQL query withformat -FRewrite code forupdatesRemove/modifycritical ﬁles on diskWeak Wi-FipasswordRead statevariable ataddress AWrite statevariable ataddress ABackdoorbypassing ofﬁrewallNo SSL pinning forauthentication sessionsMan-in-the-middleattacksCertiﬁcatesproxyingtor represents the attributes of a plausible branch and serves
as a datapoint for our ML model. The label of this particular
datapoint is −1 because a certiﬁcate proxying vulnerability
cannot be exploited to launch an SQL injection attack. This
process of datapoint construction is illustrated in Fig. 5.

Fig. 5: Representing a plausible branch as a datapoint of the
training or test dataset

4.2.2 Training Dataset

Our SVM model learns from the underlying patterns that
exist in known CPS/IoT attacks, some of which are shown
in Table 1. This knowledge is encoded in the attack DAG.
Thus, the training dataset is composed of all the existing
branches (positive examples) and some infeasible branches
(negative examples) of the attack DAG. The labels of the
training dataset are:

1, if the branch exists in the attack DAG.

•
• −1, if a branch from the origin to the destination

node is not feasible.

A negatively labeled branch denotes an impossible con-
trol/data ﬂow. The detailed procedure for generating neg-
ative examples for the training set is discussed in Sec-
tion 4.2.3.

Our training dataset consists of 140 examples, 39 of
which have positive labels and the remaining have negative
labels.

4) Weak cryptographic and authentication measures; mal-

ware with social engineering
Most of the nodes of the mutually independent cate-
gories will not have feasible branches between them. Such
infeasible branches are added to the set of negative training
examples. However, there may exist some exceptions in
which branches between nodes of independent categories
are feasible. For example, the nodes ”Overwrite allocated
memory” and ”Access ports of network” belong to the mutually
independent attack categories, namely Memory vulnerability
and Network protocol vulnerability, respectively. However,
there exist attack vectors in which the buffer overﬂow
vulnerability can be exploited to obtain the device port
assignments for the TCP protocol or to listen to network
ports on the device. We carefully exclude such branches
from our set of negative examples. Similarly, there exist a
few infeasible branches between nodes of non-independent
categories as well as between nodes of the same category.
To include such negative branches into our training set, we
experimentally observe certain statistical properties of the
existing negative examples. Then we use these properties to
ﬁlter out more negative examples. The observations are:

• Most branches from head nodes to the leaf nodes are

infeasible.

• Most branches among leaf nodes are infeasible.
• The difference between the mean depths of the
source and destination nodes of an infeasible branch
is either smaller than −0.09 or greater than 2.0.
• Most infeasible branches have a high Hamming dis-
tance (HD) between the feature vectors of the source
and destination nodes. The mean HD of feasible and
infeasible branches were observed to be 2.93 and
4.30, respectively.

Filtering out the probable negative examples with these
observations reduces our search space. Then we manually
select the negative examples from this reduced search space.

4.2.3 Negative Training Examples

4.2.4 Training

Creating the set of negative training examples is more com-
plicated than creating the set of positive training examples.
This is because the absence of a branch in the DAG does
not imply that the branch is infeasible. It implies that the
branch was not exploited in any real-world IoT/CPS hack
so far. We describe the process of ﬁnding negative examples
next.

First, we classify the nodes of the DAG into broader

vulnerability categories. These categories are:

• Memory vulnerability
• Network protocol vulnerability
• Weak cryptographic and authentication measures
• Malware
•

Social engineering

We observe that some of these vulnerability classes are
independent of each other. The pairs of independent cate-
gories are listed next:

1) Memory vulnerability; network protocol vulnerability
2) Memory vulnerability; social engineering
3) Network protocol vulnerability; social engineering

The ML model has multiple parameters that can be tuned
to achieve optimal performance [61]. The parameters of the
SVM model that we experimentally tuned during training
are mentioned below.

1) Regularization parameter (C): Regularization is used
in ML models to prevent overﬁtting of the model to the
training data. Overﬁtting causes the model to perform
well on the training dataset but poorly on the test
dataset. This parameter needs to be ﬁne-tuned to obtain
optimal performance of the model. The value of C is
inversely proportional to the strength of regularization.
2) Kernel: The kernel function transforms the input vector
xi to a higher-dimensional vector space φ(xi), such that
separability of inputs with different labels increases.
We use the radial basis function (RBF) as our kernel
function. The RBF kernel is deﬁned as:

k(xi, xj) = exp(−γ||(xi − xj)||2)

(2)

3) γ: Parameter γ deﬁnes how strong the inﬂuence of
each training example is on the separating hyperplane.

Node BNode A-1Features of Node AFeatures of Node BLabel0, 0, 1,  ...  , 0, 1, 1,   0,1,0,  ... ,0,1,3.75 Higher (lower) values of γ denote a smaller (larger)
circle of inﬂuence.

4) Shrinking heuristic: The shrinking heuristic is used to
train the model faster. The performance of our model
does not change in the absence of this heuristic.

5) Tolerance: The tolerance value determines the error
margin that is tolerable during training. A higher tol-
erance value causes early stopping of the optimization
process, resulting in a higher training error. A higher
tolerance value also helps prevent overﬁtting.

The parameters of the SVM model are chosen such that
we get zero false negatives (FNs). The parameters that have
the greatest inﬂuence on accuracy are the regularization
parameter (C), kernel of SVM, and γ. We performed a
parameter search over various combinations of these pa-
rameters and plotted the number of FNs against them. The
results of our parameter search experiments are shown in
Fig. 6. In Fig. 6a, we observe that the RBF kernel yields the
lowest number of FNs. We also observe that the number of
FNs increases with an increase in the value of γ. It is very
important that we obtain zero FN in order to regard all the
negative predictions of the model as infeasible exploits. In
Fig. 6b, we observe that only one combination of parameter
values in our parameter search space gives us zero FNs. We
choose these parameters for our SVM model, as shown in
Table 3.

TABLE 3: SVM parameters

Parameter
C
Kernel
γ
Shrinking heuristic
Tolerance for stopping

Value
1.0
RBF
0.0556
Used
10−3

(a)

(b)

4.2.5 Veriﬁcation

A test example is positive if the sequence of two basic
blocks is a permissible control/data ﬂow in a given system.
Determining the control/data ﬂow in a program is generally
a hard task. However, in this article, we deﬁne the basic
blocks at a human-interpretive level. This makes it easier
for a human expert to determine if the sequence of basic
blocks in the test example is feasible or not.

The SVM model predicts 153 positive labels out of 1192
test datapoints. A positive label indicates that the test dat-
apoint is a potential novel exploit. Manual veriﬁcation of
all the 1192 datapoints in the test dataset revealed that 1161
predictions by the SVM model are accurate, resulting in a
test accuracy of 97.4%.

The parameters of SHARKS were chosen to achieve
zero FN. However, our SVM model outputs a few false
positives (FPs). To eliminate these FPs, manual veriﬁcation
is necessary. In the absence of SHARKS, a human expert
would have to verify all 1192 potential vulnerability exploits
manually. With the assistance of SHARKS, it is sufﬁcient to
verify only the 153 positive predictions of the SVM model.
Thus, SHARKS helps reduce the search space of possible
novel exploits from 1192 to 153, which is an 87.2% reduction
in manual checks.

Fig. 6: Parameter search: (a) 3D scatter plot showing the
number of FNs for various combinations of parameters
(Kernels 1, 2, and 3 refer to the RBF, polynomial, and
sigmoid kernels, respectively), and (b) histogram of FN
frequencies

4.3 Experimental Results

In this section, we present the experimental results. We
begin by demonstrating why we chose an SVM model
for novel exploit detection. In addition to SVM, we eval-
uated the following models: k-nearest neighbors (k-NN),
naive Bayes, decision tree, and stochastic gradient descent
(SGD) based linear SVM. We compare their accuracies,
precision/recall values, false positive rates (FPR), and F1
scores in Table 4. It is clear that SVM (with C=1) performs
the best.

We use the SVM model to predict the feasibility of
all plausible branches of the attack DAG. The test dataset
contains all plausible branches except the branches present
in the training dataset. The branches are converted into test
vectors by the method depicted in Fig. 5. The attack DAG
has 37 nodes and the training set has 140 examples. Putting
n = 37 and c = 140 in Eq. (1), we observe that the test
dataset contains 1192 test vectors. The SVM model success-

Kernel1.01.52.02.53.0Gamma0.00.20.40.60.8C0.51.01.52.02.53.0020406080100120020406080100120False Negatives012345678FrequencyTABLE 4: Performance of ML models

Model
Decision Tree
k-NN (k=2)
k-NN (k=3)
k-NN (k=4)
k-NN (k=5)
Naive Bayes
SVM (C=1)
Linear SVM
with SGD
SVM (C=2)
SVM (C=3)

Accuracy Precision Recall
0.40
86.8%
0.60
92.8%
0.54
92.0%
0.70
94.5%
0.58
93.0%
0.46
90.5%
0.80
97.4%

0.89
0.62
0.88
0.70
0.86
0.26
1.0

90.6%

93.8%
92.8%

0.49

0.60
0.56

0.75

0.97
0.96

FPR
0.14
0.04
0.08
0.03
0.06
0.03
0.03

0.08

0.06
0.08

F1
0.55
0.61
0.67
0.70
0.69
0.34
0.89

0.59

0.76
0.71

fully predicts the existence of 122 new feasible branches in
the attack DAG. Each new branch corresponds to a unique
novel exploit.

Some of the 122 feasible branches of the attack DAG
that were predicted by ML are listed in Table 5. These
attacks have been chosen to represent the most popular
vulnerability categories.

TABLE 5: Novel exploits discovered

Branch discovered

Read downloaded ﬁle from email −→
Overﬂow of memory
Access network ports −→ Encrypt data
and destroy key
Access system ﬁles and databases −→
Reconﬁgure system speciﬁcations
Download unwhitelisted malware −→
Bypass ﬁrewall using backdoor
Access network address −→
Encryption key read from memory in
unencrypted form
Critical component with 1-factor
authentication −→ Access Basic
Input/Output System (BIOS) image
Exploit malware to access system as
root −→ Cache poisoning

Vulnerability
category

Buffer overﬂow

Privilege escalation

Access control

Malware

Cryptographic ﬂaw

BIOS boot level
attack

Cache poisoning

The confusion matrix in Table 6 shows the number of
true negatives (TNs), FPs, FNs, and true positives (TPs).
The SVM model achieves zero FNs, which indicates that
a negative prediction is always correct.

TABLE 6: Confusion matrix

N=1192
Predicted = No
Predicted = Yes

Actual = No Actual = Yes
TNs = 1039
FPs = 31
1070

FNs = 0
TPs = 122
122

1039
153

In Fig. 7, we categorize the novel exploits into six
categories. We can see that access control vulnerabilities
(including privilege escalation), weak cryptographic prim-
itives, and network security ﬂaws are most common vul-
nerabilities with high likelihood of exploit. We also observe
that vulnerabilities with lower exploit likelihood are BIOS
vulnerabilities and cache poisoning attacks. This is expected
because a successful BIOS attack or a cache poisoning attack
involves one or more of the following: boot-stage execution,
shared resources with adversary, side-channel access, kernel
code execution, and close proximity to the CPS/IoT devices

at very speciﬁc time instances. These operations involve
higher complexity in building the exploit chains across
various system elements.

Fig. 7: Histogram depicting the number of novel exploits
discovered in each category

Training accuracy refers to the accuracy of the SVM
model when evaluated on the training dataset. Only four
of the 140 training datapoints were incorrectly classiﬁed by
the SVM model, yielding an accuracy of 97.2%. The test
accuracy is manually determined by evaluating the feasi-
bility of all the 1192 possible branches in the attack DAG.
We observed that 31 of the 153 positive predictions were
incorrect. On the other hand, all the negative predictions
were accurate. Thus, 1161 of the 1192 datapoints of the test
dataset were classiﬁed correctly by the SVM model, yielding
a test accuracy of 97.4%.

4.3.1 Constraint Satisfaction Problem (CSP) Formulation

In this section, we use a CSP formulation to analyze the
feasibility of DAG branches. Constraint-based reasoning
requires the creation of a set of constraints over the features
of the branches, such that any branch satisfying all the
constraints is deemed to be a feasible branch. CSP is widely
used in program analysis techniques. Unlike traditional
CSP-addressable problems, there are no deterministic rules
governing the feasibility of a branch in our attack DAG.
Thus, generating mathematical constraints that deﬁne the
feasibility of a branch is not easy.

We use heuristics derived from the statistics of the
training set to generate constraints. The constraints used
to detect infeasible branches are inspired by the thresholds
derived to construct the negative examples in Section 4.2.3.
The variables and symbols are deﬁned next:

• Hamming distance - hd (integer value)
• Height difference of nodes - htdif f (ﬂoat value)
• Head-leaf connection - hl (Boolean value)
• Leaf-leaf connection - ll (Boolean value)

Experimentally, the following results were observed on

the training set.

1) Mean Hamming distance between feature vectors of

nodes of feasible branches = 2.93.

2) Mean Hamming distance between feature vectors of

nodes of infeasible branches = 4.30.

3) Height difference between nodes of feasible branches:

Minimum = -0.08; Mean = 0.997; Maximum = 2.

4) Height difference between nodes of infeasible branches:
Minimum = -3.33; Mean = 0.071; Maximum = 3.33.
5) (Number of infeasible head-leaf or leaf-leaf branches/
Number of feasible head-leaf or leaf-leaf branches) = 4.
These observations are used to generate the following
heuristic constraints. A branch is deemed to be infeasible if:

1) htdif f ≤ −0.09 or htdif f > 2
2) hd > 5
3) if (4 ≤ hd ≤ 5) and ((hl == True)or(ll == True))

When the above constraints are applied to the test
dataset, they yield 60 FNs. Comparing this to the results
in Fig. 6b, we observe that CSP analysis performs better
than many SVM models. However, the best SVM model
yields zero FNs, thus performing signiﬁcantly better than
CSP. Since our primary objective is to minimize the number
of FNs, we prefer SVM over CSP.

4.4 Discovering Unexploited Attack Vectors

An unexploited attack vector is one that exists in the DAG
but has not yet been exploited in any documented real-
world attack on IoT/CPS. This is unusual because the
DAG was constructed from real-world attacks on IoT/CPS.
The unexploited attack vectors embedded in the DAG can
be discovered through linear search on the DAG. Every
path from a head node to a leaf node corresponds to a
unique attack vector. The attack DAG has 51 such paths.
However, only 41 known attack vectors were considered
while constructing the attack DAG. Thus, 10 unexploited
attack vectors are obtained through a linear search of all the
attack paths, a subset of which is shown in Fig. 8. These 10
unexploited attack vectors represent 10 additional ways to
compromise an IoT/CPS.

New attack vectors emerge due to the convergence of
multiple attack paths at common basic block(s). Such an
occurrence is illustrated in Fig. 8. Fig. 8a and Fig. 8b rep-
resent two subgraphs of the attack DAG in Fig. 4. Fig. 8c
shows the graph obtained by combining Fig. 8a and Fig. 8b
at the common node titled “Access ports of network.” Fig. 8d
depicts the new paths obtained from the combination of the
two graphs. The ﬁve new paths thus discovered correspond
to ﬁve attack vectors that have not yet been exploited in
real-world CPS/IoT attacks.

5 IOT CASE STUDY: CONNECTED CAR

The connected car is a complicated IoT system comprising
various sensors, electronic control units (ECUs), system
buses, and embedded software packages. It possesses a vast
range of capabilities that includes Internet access, communi-
cation with multiple devices, and collection of real-time data
from the surroundings. While these functionalities enhance
user convenience, they also expand the attack surface of the
system. The attack surface of a connected car includes the
networks of vehicle-to-vehicle communication, in-vehicular

(a)

(b)

(c)

(d)

Fig. 8: Generating new exploits with linear search: (a) CDFG
for Attack1, (b) CDFG for Attack2, (c) combined CDFG
of both attacks, and (d) new attacks that emerge from a
combination of the two CDFGs

communication, and exposed software and sensors, to name
a few [62]. We analyze the security of in-vehicular networks
with the SHARKS framework. The most common entry
points into the in-vehicular network are the ECUs, on-
board diagnostics (OBD) port, WiFi, and GSM and bluetooth
networks of the vehicle. Some of these are shown in Fig. 9.

Spoof sensorOverwriteallocated memoryReconﬁgure systemspeciﬁcationsAccess ports ofnetworkCommon	NodeRead downloadedﬁle from emailExploit component with 1-factorauthenticationManipulate commandsto systemCommon	NodeAccess ports ofnetworkRead downloadedﬁle from emailExploitcomponent with1-factorauthenticationManipulatecommands tosystemAccess ports ofnetworkCommon	NodeSpoof sensorOverwriteallocated memoryReconﬁgure systemspeciﬁcationsRead downloadedﬁle from emailExploitcomponent with1-factorauthenticationAccess ports ofnetworkOverwriteallocated memoryReconﬁgure systemspeciﬁcationsManipulatecommands to systemAccess ports ofnetworkSpoof sensormakes it easier to analyze the collected frames. The
range of valid messages on the CAN bus is small
enough to be exhaustively analyzed. Fuzzing tech-
niques can be used to decode the functionalities of
various ECUs from the log of sniffed frames [69]. This is
a breach of conﬁdentiality of the system. Frame snifﬁng
is often the precursor of more complex attacks.

2) Frame spooﬁng: Frame spooﬁng involves snifﬁng and
reverse engineering of the data frames of the CAN
bus. Using the details of the data frames, the adversary
can broadcast malicious frames on the bus by spooﬁng
a particular node. Absence of authentication schemes
compromises the integrity of messages on the CAN
bus. Spooﬁng attacks may result in incorrect speedome-
ter readings, arbitrary acceleration of the vehicle, er-
roneous fuel level readings, and conveying malicious
messages to the driver [70]. This poses grave safety con-
cerns as the adversary can gain access to safety-critical
ECUs like the braking system and engine management
system.

3) Denial of Service (DoS): The CAN protocol imple-
ments a priority-based broadcasting communication
scheme. For example, messages from the anti-lock brak-
ing system, which are critical to the safety of the pas-
sengers, are given higher priority for transmission on
the bus than messages from climate control sensors.
The priority of a frame is determined by a parameter
id (PID). Lower values of PID signify higher priority
messages. To launch a DoS attack, the adversary needs
to decode the smallest acceptable value of PID from the
history of CAN messages (obtained by frame snifﬁng).
Then he can continually broadcast messages with the
highest priority on the bus, thus preventing any other
message from being transmitted on it [69]. This com-
promises the availability of the CAN bus to legitimate
messages, thus denying service to these messages.
4) Replay attack: Replay attacks involve snifﬁng the
frames on the CAN bus prior to launching the at-
tack. Snifﬁng and analyzing the frame packets using
fuzzing techniques reveal knowledge about the frame
functionalities. Since the CAN protocol is bereft of au-
thentication schemes and time-stamp veriﬁcation, the
recorded frame packets can be sent on the CAN bus at
inconvenient time instances to launch various attacks.
For example, the frame packet to unlock the car door
can be replayed by a thief when the owner is not
around. Replay attacks on cars have been demonstrated
both in simulations [71] and real cars [69].
The other vulnerabilities that we consider in our experi-
ments are ECU buffer overﬂows [72] and malware injection
through ECU ﬁrmware updates [73]. These attack vectors
involve sending malicious packets to the ECUs over the
CAN bus but do not involve exploiting any vulnerability
of the CAN bus itself.

5.2 Application of SHARKS

Fig. 9: Examples of hacker entry points into the connected
car

The connected car has numerous ECUs that are respon-
sible for different functionalities like anti-lock braking, lane
departure warning, and engine management. All commu-
nications between ECUs occur over the network bus that
connects all the ECUs to one another. There exist multiple
networks for in-vehicle communications. Some of them are
local interconnect network [63], FlexRay network [64], and
media-oriented systems transport network [65]. One of the
most popular in-vehicle networks is the Controller Area
Network (CAN) [66]. CAN ensures real-time handling of
all in-vehicle communications, including safety-critical data.
This makes the security of the CAN bus critical to the safety
and security of the smart vehicle. However, the CAN bus
has been shown to be intrinsically not secure [67, 68]. Cryp-
tographic techniques like encryption and message authen-
tication cannot be applied to the data traversing the CAN
bus. These operations increase the latency of processing the
packets that leads to an increased ECU response time. This
overhead is not permissible in the case of safety-critical,
time-sensitive, and real-time applications. Cryptographic
measures also prevent car mechanics from analyzing CAN
trafﬁc during troubleshooting. This is a major inconvenience
for them because they generally use the CAN bus as a
diagnostic tool during repair.

5.1 CAN Bus Vulnerabilities

Although CAN is the de-facto in-vehicle network in con-
nected vehicles, it is not secure by design. The CAN protocol
uses a broadcast mechanism for communication. Due to the
absence of sender and receiver addresses in the data frames,
every ECU can freely publish and receive messages from
the bus. While this enables easier addition of new ECUs to
the network, it poses a grave security threat to the system.
We next discuss the popular vulnerabilities on the CAN bus
that were detected by our approach.

1) Frame snifﬁng: The CAN protocol uses a broadcasting
mechanism for ECU communications. This allows a
malicious node on the CAN bus to receive all the
data frames through snifﬁng. The absence of encryption

In this section, we describe how we use our SHARKS
approach to detect the aforementioned vulnerabilities in
the given IoT system, namely the CAN bus. An adversary
can gain access to the CAN bus through multiple entry

,points like the OBD port, WiFi, bluetooth, radio or the
GPS system of the car [74]. In our simulations, we use the
OBD-II port to gain access to the CAN bus. We simulate
the CAN bus with OpenGarages ICSim simulator [74] on
our workstation with LibSDL and Socket-CAN CAN-utils
libraries. The simulation results can then be executed on
a connected car, with the help of ScanTools software, by
connecting the workstation (laptop) to the car through the
OBD-II port.

5.3 Results

We ran a pre-trained SVM model on the CAN attack DAG
shown in Fig. 10. The SVM model was trained on the attack
DAG in Fig. 4, and not on the CAN attack DAG. While
testing the model’s performance on the CAN attack DAG,
we observed that it is able to discover 67 CAN vulnerability
exploits that were initially absent in the CAN attack DAG.
This indicates that our approach is generic enough to be
deployed on any CPS/IoT system for vulnerability exploit
detection. We classify the detected CAN bus vulnerabilities
into the vulnerability categories mentioned in Section 5.1.
Some of the attack branches predicted by the model and
their corresponding categories are shown in Table 7.

TABLE 7: Novel exploits discovered

Branch discovered

Invariants unencrypted −→ Read state
variable at address A
No mutual authentication −→
Man-in-the-middle attacks
No check for time-stamp −→
Manipulate commands to system
Access memory buffer −→ Write state
variable at address A

Rewrite code for updates −→
Download unwhitelisted software

Vulnerability
category

Frame snifﬁng

Frame spooﬁng

Replay attack

ECU buffer
overﬂow
Malware injection
through ECU
updates

The CAN attack DAG has 29 nodes and 27 branches.
Putting n = 29 and c = 27 in Eq. (1), we observe that there
are 785 datapoints in the test set. The SVM model predicts 88
of these to be feasible novel exploits and eliminates the rest.
Manually examining the feasibility of the 88 positive predic-
tions, we ﬁnd that 67 of them are TPs. All the branches that
were predicted to be negative are infeasible control/data
ﬂows. Hence, the SVM model reduced our search space
from 785 to 88, which represents an 88.8% reduction in
human effort. The confusion matrix of the predictions made
by the model is shown in Table 8.

TABLE 8: Confusion matrix of SHARKS on CAN vulnera-
bilities

N=785
Predicted = No
Predicted = Yes

Actual = No Actual = Yes

TN = 697
FP = 21
718

FN = 0
TP = 67
67

697
88

Fig. 10: The attack DAG for the CAN bus of the connected
vehicle

6 SECURITY MEASURES

To apply SHARKS to a speciﬁc CPS/IoT system, we have
to design the attack DAG for it. The attack DAG shown in
Fig. 4 is designed for a generic CPS/IoT system. The CAN
bus has fewer functionalities than those considered during
the design of the attack DAG in Fig. 4. This makes some
of the nodes in the DAG in Fig. 4 redundant with respect
to the CAN bus IoT system. We remove those nodes and
obtain a subgraph of Fig. 4 that is relevant to the CAN bus.
This subgraph, shown in Fig. 10, is referred to as the CAN
attack DAG. It has 29 nodes, 27 branches, and represents 24
high-level attack vectors relevant to the CAN bus.

In this section, the primary endeavor is to show how to de-
fend CPS/IoT against the known attacks and novel exploits
predicted by SHARKS at an optimal cost. Defense-in-depth
and multi-level security (MLS) [75, 76] are the most appro-
priate schemes to adopt in such a scenario. Defense-in-depth
refers to employing multiple defense strategies against a
single weakness and is one of the seven properties of highly
secure devices [77]. MLS categorizes data/resources into
one of the following security levels: Top Secret, Secret, Re-
stricted, and Unclassiﬁed. The ﬁrst three levels have classiﬁed
resources and require different levels of protection. Security

AccessrequestedExploitcomponentwith 1-factorauthenticationExploit weakauthenticationparametersExploit absenceof mutualauthenticationRead encryptionkey inunencryptedformExploitabsence oftime-stampExploitabsence ofhash checkReadunencryptedinvariantsAccess networkaddress;production/businessaddressAccess database /system ﬁlesAccess ports ofnetworkSpoof sensorAccess memorybufferOverwrite allocatedmemoryManipulatecommands to systemReconﬁguresystemspeciﬁcationsRewrite code forupdatesRemove/modifycritical ﬁles on diskRead statevariable ataddress AWrite statevariable ataddress AMan-in-the-middleattacksRead encryptedstorage ofcredentialsTamper withsensor physicallyExploit weakgatewayauthenticationExploit absence of SSLpinning for authentication Proxy certiﬁcatesOverﬂowmemoryOverwrite framepointerExploit vulnerablesoftware to accesssystem as rootmeasures become stricter as we move from Restricted to
Top Secret. Many different policies can be employed to im-
plement MLS in an organization. Some of the most popular
policies are based on the Bell-La Padula (BLP) model [78]
and the Biba model [79]. The BLP model prioritizes data
conﬁdentiality whereas the Biba model gives more impor-
tance to integrity.

The aggregated attack DAG is composed of multiple
categories of attacks that are weaved together. Defense
mechanisms can be systematically developed for each of
these vulnerability categories in the form of defense DAGs.
Defense DAGs mirror the corresponding attack subgraphs
and make execution of the key basic blocks of the attack
sequence infeasible. This ensures that no path from a head
node to a leaf node in the attack DAG can be traversed in
the presence of the suggested defense measures.

Many attacks have multiple defense strategies that can
protect against them. The cost of our overall defense strat-
egy increases with the complexity and number of defense
measures that we enforce. Defense-in-depth helps us opti-
mize this cost. The less sensitive resources (those belonging
to the Restricted level) have basic defense measures against
all attacks. As we move up the hierarchy to the Secret and
Top Secret levels, we have more layers of security. Next,
we demonstrate our defense strategies against access control
and boot-stage attacks.

6.1 Defense against Access Control Attacks

Access control and privilege escalation attacks are the most
common amongst real-world CPS/IoT attacks, as shown in
Fig. 7. Access control attacks involve an unauthorized entity
gaining access to a classiﬁed resource, thus compromising
its conﬁdentiality and/or integrity. Privilege escalation at-
tacks involve an entity exploiting a vulnerability to gain
elevated access to resources that it is not permitted to
access. Implementation of strict policies can protect against
such attacks. These security policies include multi-factor
authentication, access control lists, and role-based access
control. More layers of authentication, authorization, and
network masking can be added for more sensitive resources.
An example of a defense DAG is shown in Fig. 11.

In Fig. 11, we demonstrate the security measures de-
ployed in a resource that is classiﬁed as Top Secret. A Top
Secret resource is generally a computing device with more
computing resources, the exploit of which can lead to a high-
impact damage like the compromise of data conﬁdentiality
and integrity in a Top Secret data storage server. Hence, we
should have multiple layers of authentication and network
address masking, as shown in Fig. 11. In a resource classiﬁed
as Restricted, there can be only one layer of authentication.
More layers of authentication may be added for a Secret-
level resource depending on the resources it has.

Fig. 11: Defense at the Top Secret level against access
control and privilege escalation exploits. The DAG on the
left depicts the attack DAG and the DAG on the right depicts
the defense DAG. The arrows indicate the basic blocks of the
defense DAG making the corresponding basic blocks of the
attack DAG non-operational.

module (TPM) or a hardware security module. These are
generally present at a level
lower than the kernel and
sometimes referred to as the trusted computing base (TCB).
In Fig. 12, the BOOTROM serves as the TCB. Defense
against boot-stage attacks involves a series of hierarchical
and chained hash checks of binary ﬁles and secret keys
stored in the Platform Conﬁguration Register (PCR) of the
TPM. The PCR is inaccessible to all entities except the TPM.
The detection of an incorrect hash value at any stage of the
boot sequence causes the boot sequence to halt due to the
detection of an illegal modiﬁcation of the binary boot ﬁles
and/or the secret(s). Fig. 12 gives an overview of the hash
checks and execution of binary ﬁles at various levels.

6.2 Defense against Boot-stage Attacks

Fig. 12: Defensive measures against Boot-stage attacks

This category of attacks is the most complicated among all
the categories. While other attacks can be launched at the
application level, these attacks typically require root access
and have to be launched at the system level.

To defend against such attacks, a core root of trust for
measurement is required along with a trusted platform

7 CONCLUSION
The rapid advancement of CPS/IoT-enabling technologies,
increases the
like 5G communication systems and ML,
scope of their applications manifold. Unfortunately, this

Criticalcomponent with1-factorauthenticationAccessdatabase/system ﬁlesSQL query withformat -FRewrite code forupdatesRemove/modifycritical ﬁles on diskAccess network address;production/businessaddressMulti-factorauthenticationRole-basedauthenticationMutual authenticationof system ﬁlesSQL query inputvalidationAuthentication beforemodifying/removingcode or ﬁlesAttack DAGDefense DAGMask networkaddressFirmwareOSKernelBOOTROM -CRTMTPM Firmware CodeStorageExecuteExecuteExecuteMeasure and ExtendMeasure and ExtendMeasure and ExtendUnsealExecute and Check Signatureto Ensure Integrityalso increases the attack surface of such systems that can
often result in catastrophic effects. We have demonstrated
how ML can be used at the system and network levels to
detect possible vulnerability exploits across the hardware,
software, and network stacks of CPS/IoT. We discovered 10
unexploited attack vectors and 122 novel exploits using the
proposed methodology and suggested appropriate defense
measures to implement a tiered-security mechanism. We
hope that this methodology will prove to be helpful for
proactive threat detection and incident response in different
types of CPS/IoT frameworks.

ACKNOWLEDGMENTS

This work was supported by NSF under Grant No. CNS-
1617628.

REFERENCES

[1] H. Arasteh, V. Hosseinnezhad, V. Loia, A. Tommasetti,
O. Troisi, M. Shaﬁe-Khah, and P. Siano, “IoT-based
smart cities: A survey,” in Proc. IEEE Int. Conf. Envi-
ronment and Electrical Engineering, 2016, pp. 1–6.

[2] A. O. Akmandor and N. K. Jha, “Smart health care:
An edge-side computing perspective,” IEEE Consumer
Electronics Magazine, vol. 7, no. 1, pp. 29–37, 2018.
[3] M. Yun and B. Yuxin, “Research on the architecture and
key technology of Internet of Things (IoT) applied on
smart grid,” in Proc. IEEE Int. Conf. Advances in Energy
Engineering, 2010, pp. 69–72.

[4] S. K. Datta, R. P. F. Da Costa, J. H¨arri, and C. Bonnet,
“Integrating connected vehicles in Internet of Things
ecosystems: Challenges and solutions,” in Proc. IEEE
Int. Symp. A World of Wireless, Mobile and Multimedia
Networks, 2016, pp. 1–6.

[5] X. Huang, P. Craig, H. Lin, and Z. Yan, “SecIoT: A
security framework for the Internet of Things,” Security
and Communication Networks, vol. 9, no. 16, pp. 3083–
3094, 2016.

[6] A. Mosenia and N. K. Jha, “A comprehensive study
of security of Internet-of-Things,” IEEE Trans. Emerging
Topics in Computing, vol. 5, no. 4, pp. 586–602, 2017.
[7] T. Xu, J. B. Wendt, and M. Potkonjak, “Security of IoT
systems: Design challenges and opportunities,” in Proc.
IEEE/ACM Int. Conf. Computer-Aided Design, 2014, pp.
417–423.

[8] M. Katagi and S. Moriai, “Lightweight cryptography
for the Internet of Things,” Sony Corporation, pp. 7–10,
2008.
J. Lee, W. Lin, and Y. Huang, “A lightweight authen-
tication protocol for Internet of Things,” in Proc. Int.
Symp. Next-Generation Electronics, 2014, pp. 1–2.

[9]

[10] T. Saha and V. Sehwag, “TV-PUF: A fast lightweight
threshold voltage PUF,” Cryptology

aging-resistant
ePrint Archive, 2016.

[11] G. E. Suh and S. Devadas, “Physical unclonable func-
tions for device authentication and secret key genera-
tion,” in Proc. Design Automation Conference, 2007, pp.
9–14.

[12] V. Sehwag and T. Saha, “TV-PUF: A fast lightweight
analog physical unclonable function,” in Proc. IEEE Int.

Symp. Nanoelectronic and Information Systems, Dec. 2016,
pp. 182–186.

[13] H. Suo, J. Wan, C. Zou, and J. Liu, “Security in the In-
ternet of Things: A review,” in Proc. Int. Conf. Computer
Science and Electronics Engineering, vol. 3, Mar. 2012, pp.
648–651.

[14] T. Saha, N. Aaraj, N. Ajjarapu, and N. K. Jha, “Sharks:
Smart hacking approaches for risk scanning in internet-
of-things and cyber-physical systems based on machine
learning,” IEEE Transactions on Emerging Topics in Com-
puting, 2021.

[15] L. Xiao, X. Wan, X. Lu, Y. Zhang, and D. Wu, “IoT
security techniques based on machine learning: How
do IoT devices use AI to enhance security?” IEEE Signal
Processing Magazine, vol. 35, no. 5, pp. 41–49, Sep. 2018.
[16] F. Copty, A. Kassis, S. Keidar-Barner, and D. Murik,
“Deep ahead-of-threat virtual patching,” in Proc. Int.
Wkshp. Information and Operational Technology Security
Systems, 2018, pp. 99–109.

[17] C. Zhang, J. Jiang, and M. Kamel, “Intrusion detection
using hierarchical neural networks,” Pattern Recognition
Letters, vol. 26, no. 6, pp. 779–791, 2005.

[18] J. Brown, T. Saha, and N. K. Jha, “Gravitas: Graphical
reticulated attack vectors for internet-of-things aggre-
gate security,” IEEE Transactions on Emerging Topics in
Computing, 2021.

[19] L. Sacramento, I. Medeiros, J. Bota, and M. Correia,
“FlowHacker: Detecting unknown network attacks in
big trafﬁc data using network ﬂows,” in Proc. IEEE Int.
Conf. on Big Data Science And Engineering, 2018, pp. 567–
572.

[20] J. Cannady, “Artiﬁcial neural networks for misuse de-
tection,” in Proc. Nat. Inf. Syst. Secur. Conf., 1998, pp.
443–456.

[21] A. Bivens, C. Palagiri, R. Smith, B. Szymanski, and
M. Embrechts, “Network-based intrusion detection us-
ing neural networks,” Intelligent Engineering Systems
through Artiﬁcial Neural Networks, vol. 12, no. 1, pp. 579–
584, 2002.

[22] C. Livadas, R. Walsh, D. Lapsley, and W. T. Strayer,
“Using machine learning techniques to identify botnet
trafﬁc,” in Proc. IEEE Conf. Local Computer Networks,
2006, pp. 967–974.

[23] S. Benferhat, T. Kenaza, and A. Mokhtari, “A naive
Bayes approach for detecting coordinated attacks,” in
Proc. Annual IEEE Int. Computer Software and Applica-
tions Conference, 2008, pp. 704–709.

[24] G. R. Hendry and S. J. Yang, “Intrusion signature
creation via clustering anomalies,” in Proc. Data Min-
ing, Intrusion Detection, Information Assurance, and Data
Networks Security, vol. 6973, 2008, p. 69730C.

[25] M. Blowers and J. Williams, “Machine learning applied
to cyber operations,” in Network Science and Cybersecu-
rity, 2014, pp. 155–175.

[26] K. Sequeira and M. Zaki, “Admit: Anomaly-based data
mining for intrusions,” in Proc. ACM SIGKDD Int. Conf.
Knowledge Discovery and Data Mining, 2002, pp. 386–395.
[27] L. Bilge, E. Kirda, C. Kruegel, and M. Balduzzi, “EXPO-
SURE: Finding malicious domains using passive DNS
analysis,” in Proc. Symp. Network and Distributed Systems
Security, 2011, pp. 1–17.

[28] C. Kruegel and T. Toth, “Using decision trees to im-
prove signature-based intrusion detection,” in Proc. Int.
Wkshp. Recent Advances in Intrusion Detection, 2003, pp.
173–191.

[29] L. Bilge, D. Balzarotti, W. Robertson, E. Kirda, and
C. Kruegel, “Disclosure: Detecting botnet command
and control servers through large-scale netﬂow analy-
sis,” in Proc. ACM Annual Computer Security Applications
Conference, 2012, pp. 129–138.

[30] F. Gharibian and A. A. Ghorbani, “Comparative study
of supervised machine learning techniques for intru-
sion detection,” in Proc. IEEE Annual Conference on
Communication Networks and Services Research, 2007, pp.
350–358.

[31] A.

˚Arnes, F. Valeur, G. Vigna, and R. A. Kemmerer,
“Using hidden Markov models to evaluate the risks
of intrusions,” in Proc. Int. Wkshp. on Recent Advances in
Intrusion Detection, 2006, pp. 145–164.

[32] F. Amiri, M. M. R. Youseﬁ, C. Lucas, A. Shakery, and
N. Yazdani, “Mutual information-based feature selec-
tion for intrusion detection systems,” Journal of Network
and Computer Applications, vol. 34, no. 4, pp. 1184–1199,
2011.

[33] Y. Li, J. Xia, S. Zhang, J. Yan, X. Ai, and K. Dai,
“An efﬁcient intrusion detection system based on sup-
port vector machines and gradually feature removal
method,” Expert Systems with Applications, vol. 39, no. 1,
pp. 424–430, 2012.

[34] T. Saha, N. Aaraj, and N. K. Jha, “System and method
for security in internet-of-things and cyber-physical
systems based on machine learning,” Jun. 23 2022, uS
Patent App. 17/603,453.

[35] H. Chen and L. Jiang, “GAN-based method for cyber-
intrusion detection,” CoRR, vol. abs/1904.02426, 2019.
[Online]. Available: http://arxiv.org/abs/1904.02426

[36] Y. Meidan, M. Bohadana, Y. Mathov, Y. Mirsky,
A. Shabtai, D. Breitenbacher, and Y. Elovici, “N-BaIoT:
Network-based detection of IoT botnet attacks using
deep autoencoders,” IEEE Pervasive Computing, vol. 17,
no. 3, pp. 12–22, 2018.

[37] N. Islam, S. Das, and Y. Chen, “On-device mobile
phone security exploits machine learning,” IEEE Per-
vasive Computing, Apr. 2017.

[38] J. Bickford, H. A. Lagar-Cavilla, A. Varshavsky,
V. Ganapathy, and L. Iftode, “Security versus energy
tradeoffs in host-based mobile malware detection,” in
Proc. Int. Conf. on Mobile Systems, Applications, and Ser-
vices, 2011, pp. 225–238.

[39] J. Brown, T. Saha, and N. K. Jha, “Gravitas: Graphical
reticulated attack vectors for internet-of-things aggre-
gate security,” arXiv preprint arXiv:2106.00073, 2021.
[40] T. Saha, “Machine learning-based efﬁcient and general-

izable cybersecurity frameworks,” 2022.

[41] H. Sayadi, H. M. Makrani, O. Randive, S. M. P.D.,
S. Rafatirad, and H. Homayoun, “Customized machine
learning-based hardware-assisted malware detection in
embedded devices,” in Proc. IEEE Int. Conf. on Trust,
Security and Privacy in Computing and Communications,
2018, pp. 1685–1688.

[42] V. Shandilya, C. B. Simmons, and S. Shiva, “Use of
attack graphs in security systems,” Journal of Computer

Networks and Communications, 2014.

[43] T. Saha, N. Aaraj, and N. K. Jha, “Machine learn-
ing assisted security analysis of 5G-network-connected
systems,” IEEE Transactions on Emerging Topics in Com-
puting, 2022.

[44] S. Jha, O. Sheyner, and J. M. Wing, “Two formal anal-
yses of attack graphs,” in Proc. IEEE Computer Security
Foundations Wkshp., June 2002, pp. 49–63.

[45] M. U. Aksu, K. Bicakci, M. H. Dilek, A. M. Ozbayoglu,
and E. I. Tatli, “Automated generation of attack graphs
using NVD,” in Proc. ACM Conf. Data and Application
Security and Privacy, 2018, pp. 135–142.

[46] T. Saha, N. Aaraj, and N. K. Jha, “Machine learn-
ing assisted security analysis of 5G-network-connected
systems,” arXiv preprint arXiv:2108.03514, 2021.

[47] L. Lu, R. Safavi-Naini, M. Hagenbuchner, W. Susilo,
J. Horton, S. L. Yong, and A. C. Tsoi, “Ranking attack
graphs with graph neural networks,” in Proc. Int. Conf.
Information Security Practice and Experience, 2009, pp.
345–359.

[48] M. Youseﬁ, N. Mtetwa, Y. Zhang, and H. Tianﬁeld,
“A reinforcement learning approach for attack graph
analysis,” in Proc. IEEE Int. Conf. Trust, Security and
Privacy in Computing and Communications, Aug. 2018,
pp. 212–217.

[49] L. Szekeres, M. Payer, T. Wei, and D. Song, “SoK:
Eternal war in memory,” in Proc. IEEE Symp. Security
and Privacy, 2013, pp. 48–62.

[50] Y. Gao, L. Chen, G. Shi, and F. Zhang, “A comprehen-
sive detection of memory corruption vulnerabilities for
C/C++ programs,” in Proc. IEEE Int. Symp. Parallel &
Distributed Processing with Applications, 2018, pp. 354–
360.

[51] P. Kocher, J. Horn, A. Fogh, D. Genkin, D. Gruss,
W. Haas, M. Hamburg, M. Lipp, S. Mangard,
T. Prescher, M. Schwarz, and Y. Yarom, “Spectre attacks:
Exploiting speculative execution,” in Proc. IEEE Symp.
Security and Privacy, 2019, pp. 1–19.

[52] M. Lipp, M. Schwarz, D. Gruss, T. Prescher,
W. Haas, S. Mangard, P. Kocher, D. Genkin,
Y. Yarom, and M. Hamburg, “Meltdown,” arXiv
preprint arXiv:1801.01207, 2018.

[53] C. Trippel, D. Lustig, and M. Martonosi, “Checkmate:
Automated synthesis of hardware exploits and security
litmus tests,” in Proc. IEEE/ACM Int. Symp. Microarchi-
tecture, 2018, pp. 947–960.

[54] Z. Kohavi and N. K. Jha, Switching and Finite Automata

Theory, 3rd ed. Cambridge University Press, 2009.

[55] C. Cortes and V. Vapnik, “Support-vector networks,”
Machine Learning, vol. 20, no. 3, pp. 273–297, 1995.
[56] R. Langner, “Stuxnet: Dissecting a cyberwarfare
weapon,” IEEE Security & Privacy, vol. 9, no. 3, pp. 49–
51, 2011.

[57] A. Humayed, J. Lin, F. Li, and B. Luo, “Cyber-physical
systems security: A survey,” IEEE Internet of Things
Journal, vol. 4, no. 6, pp. 1802–1831, Dec. 2017.

[58] N. Aaraj, A. Raghunathan, and N. K. Jha, “Dynamic
binary instrumentation-based framework for malware
defense,” in Proc. Int. Conf. Detection of Intrusions and
Malware, and Vulnerability Assessment, 2008, pp. 64–87.

[59] F. Ghasemi, A. Mehridehnavi, A. Perez-Garrido, and

H. Perez-Sanchez, “Neural network and deep-learning
algorithms used in QSAR studies: Merits and draw-
backs,” Drug Discovery Today, 2018.

[75] D. of Defense: Washington DC, “Security requirements
for automatic data processing (ADP) systems,” DoD
Directive 5200.28, Dec. 1972.

[60] S. Hassantabar, Z. Wang, and N. K. Jha, “SCANN:
Synthesis of compact and accurate neural networks,”
arXiv preprint arXiv:1904.09090, 2019.

[61] C. Chang and C. Lin, “LIBSVM: A library for support
vector machines,” ACM Trans. Intelligent Systems and
Technology, vol. 2, pp. 27:1–27:27, 2011.

[62] A. Lima, F. Rocha, M. V ¨olp, and P. Esteves-Ver´ıssimo,
“Towards safe and secure autonomous and cooperative
vehicle ecosystems,” in Proc. ACM Wkshp. on Cyber-
Physical Systems Security and Privacy, 2016, pp. 59–70.

[63] M. Ruff, “Evolution of local interconnect network (LIN)
solutions,” in Proc. IEEE Vehicular Technology Conference,
vol. 5, 2003, pp. 3382–3389.

[64] R. Makowitz and C. Temple, “FlexRay: A communica-
tion network for automotive control systems,” in Proc.
IEEE Int. Wkshp. Factory Communication Systems, 2006,
pp. 207–212.

[65] B. T. Fijalkowski, “Media oriented system transport
(MOST) networking,” in Automotive Mechatronics: Op-
erational and Practical Issues, 2011, pp. 73–74.

[66] S. Tuohy, M. Glavin, C. Hughes, E. Jones, M. Trivedi,
and L. Kilmartin, “Intra-vehicle networks: A review,”
IEEE Trans. Intelligent Transportation Systems, vol. 16,
no. 2, pp. 534–545, 2014.

[67] O. Avateﬁpour, A. Hafeez, M. Tayyab, and H. Malik,
“Linking received packet to the transmitter through
physical-ﬁngerprinting of controller area network,” in
Proc. IEEE Wkshp. on Information Forensics and Security
(WIFS), 2017, pp. 1–6.

[68] W. Choi, H. J. Jo, S. Woo, J. Y. Chun, J. Park, and D. H.
Lee, “Identifying ECUs using inimitable characteristics
of signals in controller area networks,” IEEE Trans.
Vehicular Technology, vol. 67, no. 6, pp. 4757–4770, 2018.
[69] K. Koscher, A. Czeskis, F. Roesner, S. Patel, T. Kohno,
S. Checkoway, D. McCoy, B. Kantor, D. Anderson,
H. Shacham, and S. Savage, “Experimental security
analysis of a modern automobile,” in Proc. IEEE Symp.
Security and Privacy, 2010, pp. 447–462.

[70] J. Liu, S. Zhang, W. Sun, and Y. Shi, “In-vehicle network
attacks and countermeasures: Challenges and future
directions,” IEEE Network, vol. 31, no. 5, pp. 50–58,
2017.

[71] T. Hoppe and J. Dittman, “Snifﬁng/replay attacks on
CAN buses: A simulated attack on the electric window
lift classiﬁed using an adapted CERT taxonomy,” in
Proc. Wkshp. Embedded Systems Security, 2007, pp. 1–6.

[72] S. Checkoway, D. McCoy, B. Kantor, D. Anderson,
H. Shacham, S. Savage, K. Koscher, A. Czeskis, F. Roes-
ner, and T. Kohno, “Comprehensive experimental anal-
yses of automotive attack surfaces,” in Proc. USENIX
Security, 2011, pp. 1–16.

[73] D. K. Nilsson and U. E. Larson, “Conducting forensic
investigations of cyber attacks on automobile in-vehicle
networks,” Int. Journal of Digital Crime and Forensics,
vol. 1, no. 2, pp. 28–41, 2009.

[74] B. R. Payne, “Car hacking: Accessing and exploiting the
CAN bus protocol,” Journal of Cybersecurity Education,
Research and Practice, vol. 2019, no. 1, p. 5, 2019.

[76] ——, “Techniques and procedures for implementing
deactivating testing and evaluating secure resource-
sharing ADP systems,” DoD 5200.28-M, Jan. 1973.
[77] G. Hunt, G. Letey, and E. Nightingale, “The seven
properties of highly secure devices,” Tech. Rep. MSR-
TR-2017-16, Microsoft Research, 2017.

[78] J. Rushby, “The Bell and La Padula security model,”
Computer Science Laboratory, SRI International, Menlo
Park, CA, 1986.

[79] K. J. Biba, “Integrity considerations for secure com-
puter systems,” MITRE Corp., Bedford, MA, Tech.
Rep., 1977.

Tanujay Saha Tanujay Saha is currently pur-
suing his Ph.D. degree at Princeton University,
NJ, USA. He received his Master’s Degree in
Electrical Engineering from Princeton University
and Bachelors in Technology in Electronics and
Electrical Communications Engineering from In-
dian Institute of Technology, Kharagpur, India in
2017. He has held research positions in vari-
ous organizations and institutes like Intel Corp.,
KU Leuven, and Indian Statistical Institute. His
research interests lie at the intersection of IoT,
cybersecurity, machine learning, embedded systems, and cryptography.

Najwa Aaraj Najwa Aaraj is a Chief Research
Ofﬁcer at the UAE Technology Innovation Insti-
tute. She holds a Ph.D. in Electrical Engineer-
ing from Princeton University and a Bachelor’s
in Computer and Communications Engineering
from the American University in Beirut. Her ex-
pertise lies in applied cryptography, trusted plat-
forms, secure embedded systems, software ex-
ploit detection/prevention, and biometrics. She
has over 15 years of experience working in the
United States, Australia, Middle East, Africa, and
Asia with global ﬁrms. She has two patents and 15 academic publica-
tions. She has worked in a cybersecurity start-up (DarkMatter). Prior
to joining DarkMatter, she worked at Booz & Company, where she led
consulting engagements in the communication and technology industry
for clients across four continents. She has also held research positions
at IBM T. J. Watson Center, New York, Intel Security Research Group,
Portland, Oregon, and NEC Laboratories, Princeton, New Jersey.

Neel Ajjarapu Neel Ajjarapu is currently pur-
suing his B.S.E in the Department of Electrical
Engineering at Princeton University, with a con-
centration in security and privacy as well as a
certiﬁcate in technology and society from the
Center for Information Technology Policy and
Keller Center for Entrepreneurship. He has held
intern positions at Microsoft Corp. and One Mil-
lion Metrics Corp. (Kinetic) in product manage-
ment and hardware engineering. His current re-
search interests focus on automotive security,

embedded systems, and cybersecurity.

Niraj K. Jha Niraj K. Jha received the B.Tech.
degree in electronics and electrical communica-
tion engineering from I.I.T., Kharagpur, India, in
1981, and the Ph.D. degree in electrical engi-
neering from the University of Illinois at Urbana-
Champaign, Illinois, in 1985. He has been a
faculty member of the Department of Electrical
Engineering, Princeton University, since 1987.
He was given the Distinguished Alumnus Award
by I.I.T., Kharagpur. He has also received the
Princeton Graduate Mentoring Award. He has
served as the editor-in-chief of the IEEE Transactions on VLSI Systems
and as an associate editor of several other journals. He has co-authored
ﬁve books that are widely used. His research has won 20 best paper
awards or nominations. His research interests include smart health-
care, cybersecurity, machine learning, and monolithic 3D IC design.
He has given several keynote speeches in the area of nanoelectronic
design/test and smart healthcare. He is a fellow of the IEEE and ACM.

