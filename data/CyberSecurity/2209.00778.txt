Detection of False Data Injection Attacks in Smart
Grid: A Secure Federated Deep Learning Approach

Yang Li, Senior Member, IEEE, Xinhao Wei, Yuanzheng Li, Member, IEEE,
Zhaoyang Dong, Fellow, IEEE, and Mohammad Shahidehpour, Life Fellow, IEEE

1

2
2
0
2

p
e
S
6

]

R
C
.
s
c
[

2
v
8
7
7
0
0
.
9
0
2
2
:
v
i
X
r
a

Abstract—As an important cyber-physical system (CPS), smart
grid is highly vulnerable to cyber attacks. Amongst various types
of attacks, false data injection attack (FDIA) proves to be one of
the top-priority cyber-related issues and has received increasing
attention in recent years. However, so far little attention has been
paid to privacy preservation issues in the detection of FDIAs in
smart grids. Inspired by federated learning, a FDIA detection
method based on secure federated deep learning is proposed in
this paper by combining Transformer, federated learning and
Paillier cryptosystem. The Transformer, as a detector deployed
in edge nodes, delves deep into the connection between individual
electrical quantities by using its multi-head self-attention mech-
anism. By using federated learning framework, our approach
utilizes the data from all nodes to collaboratively train a detection
model while preserving data privacy by keeping the data locally
during training. To improve the security of federated learning,
a secure federated learning scheme is designed by combing
Paillier cryptosystem with federated learning. Through extensive
experiments on the IEEE 14-bus and 118-bus test systems, the
effectiveness and superiority of the proposed method are veriﬁed.

Index Terms—Secure federated learning, Transformer, false
data injection attack, smart grid, privacy preservation, Paillier
cryptosystem.

ABBREVIATION

cyber-physical system
independent system operator

FDIA false data injection attack
CPS
ISO
BDD bad data detection
direct current
DC
alternating current
AC
CNN convolutional neural network
GAN generative adversarial network

This work is supported by National Natural Science Foundation of China
under Grant U2066208, the Natural Science Foundation of Jilin Province,
China under Grant YDZJ202101ZYTS149, and Open Project of Key Labora-
tory of Modern Power System Simulation and Control and Renewable Energy
Technology, Ministry of Education, Northeast Electric Power University under
Grant MPSS2022-04. (Corresponding author: Yuanzheng Li.)

Y. Li, X. Wei are with the Key Laboratory of Modern Power System
Simulation and Control and Renewable Energy Technology, Ministry of
Education, Northeast Electric Power University, Jilin 132012, China (e-mail:
liyang@neepu.edu.cn; 779058643@qq.com)

Y. Z. Li is with the School of Artifcial Intelligence and Automation,
Huazhong University of Science and Technology, Wuhan 430074, China (e-
mail: Yuanzheng Li@hust.edu.cn).

Z. Y. Dong is with the School of Electrical and Electronic Engi-
neering, Nanyang Technological University, Singapore 639798 (e-mail:
zy.dong@ntu.edu.sg).

Mohammad Shahidehpour is with the Electrical and Computer Engineering
Department, Illinois Institute of Technology, Chicago, IL, 60616, USA. He
is also a Research Professor in the ECE Department at the King Abdulaziz
University in Saudi Arabia (e-mail: ms@iit.edu).

LSTM
SecFed
EMS
GRU
LSGAN
SCADA
WLS
AMCNN attention mechanism-based convolutional

long short-term memory
secure federated learning
energy management system
gate recurrent unit
least square generative adversarial networks
supervisory control and data acquisition
weighted least square

DG
MTD

neural network
distributed generation
moving target defense

I. INTRODUCTION

A S power system is a critical infrastructure of a country,

its safe operation is vital to national security. The au-
tomation of the entire power system is an important feature
of the development of the electrical industry [1]. To achieve
this goal, a modern power system is developing into a type
of CPSs that is deeply integrated by sensing, communication,
computing, decision-making, and control [2]. Due to the
open communication environment and increasingly complex
information-physical coupling of smart grid, cyber security
has become an important factor affecting the secure operation
of smart grids [3]. In December 2015, Ukrainian power grid
suffered catastrophic consequences due to a massive blackout
caused by a hacker attack [4]. As a new type of cyber attacks,
FDIA seriously threatens the secure operation of smart grids,
so it is crucial to establish an effective and efﬁcient FDIA
detection mechanism.

Up to date, many researchers have conducted research
from the perspective of FDIA detection and achieved certain
results [5], [6]. The study in [7] is one of the seminal studies
investigating the vulnerability of DC state estimators about
FDIA. And many studies on methods for DC state estimation
have subsequently emerged, such as DC FDIA detetion by
Kalman ﬁltering [8], network theory [9], [10], and machine
learning [11]. In [12], a CNN-based method is proposed for de-
tecting and locating FDIA in DC-model power system. In [13],
Deng et al. put forward a countermeasure, named moving
target defense, against FDIAs with limited meter information.
In [14], Deng et al. analyze MTD against FDIAs on electrical
grids. These methods show satisfactory performance in the
detection of DC FDIA, but the DC model makes a large
number of simpliﬁcations compared to the AC model, making
it different from the AC model used in real life. Therefore
some studies on AC state estimation of FDIA emerge [15]–
[17]. In [18], graph theory is introduced into FDIA detection

 
 
 
 
 
 
work, based on that an FDIA detection method is proposed. J.
J. Q. Yu et al. [19] use GRU and wavelet transform to detect
FDIA in power system. Y. Zhang et al. [20] combine GAN
with self-encoder for FDIA detection. X. Luo et al. [21] detect
and locate FDIA in smart grid by interval observer. All these
traditional methods are centralized detection methods. With
the development of smart grids, power systems are becoming
larger and larger and generating more and more data, the
traditional centralized processing methods cannot cope with
the explosive growth of data volume in smart grid. The above
methods require all data from each node in the grid to be
transmitted to a data center for inspection. Such centralized
detection methods have the following problems: 1) these meth-
ods are reliant on a central work station which has powerful
calculation and storage capabilities; 2) limited communication
and storage resources make the grid less capable of processing
data in real time, which can result in some critical operations
of the grid not being executed in a timely manner; 3) the way
that data is stored at the central workstation can easily lead
to data breaches and cyber attacks; 4) most importantly, since
one independent system operator (ISO) typically only has a
limited number of attack samples and these samples are always
related to highly-sensitive information, the owners are usually
reluctant to share such attack instances considering privacy
preservation. These issues make it a very challenging problem
to train a data-driven FDIA detection model with desirable
performance in a privacy-preserving manner for smart grids.
To solve the above problems, distributed detection methods
emerges, and there are very few studies on distributed FDIA
detection in the existing literature. Speciﬁcally, reference [22]
proposes a FDIA detection method based on sub-grid-oriented
microservice framework. Reference [23] proposes a distributed
detection with adaptive sampling sequence, which can reduce
communication overhead and improve detection efﬁciency
while ensuring robustness; however, data fusion between
neighboring sub-areas must be performed to train a wide-area
cyber-attack detector in this approach.

As a representative of distributed machine learning methods,
federated learning has been successfully applied in industrial
internet of things. For instance, reference [24] combines fed-
erated learning and AMCNN-LSTM to detect anomalies using
data from time series. Reference [25] integrates federated
learning and CNN-GRU and used it to detect cyber attacks
internet of things. Reference [26] combines
in industrial
federated learning with LSGAN together and used to model
renewable energy sources. Reference [27] integrates federated
learning and attentive aggregation to do FDIA detection in
industry 4.0. Unfortunately, federated learning has so far rarely
been used for detecting stealthy FDIA in smart grids.

In order to bridge this gap, based on our existing work
in [26], a federated learning-based FDIA detection method is
proposed in this paper by setting up a edge node detector at
each node of power system to collect, store and detect data di-
rectly instead of an original central workstation, transforming
traditional centralized detection methods into a distributed de-
tection approach. By building a detector based on Transformer
model, the proposed approach can fully extract data features
via self-attention mechanism. The main contributions of this

2

paper are as follows:

1) We propose a federated learning-based FDIA detection
approach. By keeping the data locally during training,
this approach protects the data privacy of each node in
a power system while utilizing the data from all nodes
to collaboratively train a detection model. Moreover, as
the detection model is deployed on each node locally,
the communication delays caused by transferring data
between each node and dispatch center are avoided during
online detection, thus enabling efﬁcient data detection.
2) We build a new Transformer-based FDIA detection
model. By using its unique multi-head self-attention
mechanism, the Transformer is able to delve deep into
the connection between individual electrical quantities,
thus effectively detecting FDIA with various intensities.
3) We combine the Paillier cryptosystem with federated
learning to build SecFed scheme. The cryptosystem en-
crypts the data exchanged by federated learning, pre-
venting hackers from using the weights generated during
training to deduce the original data information, which
greatly improves the security of federated learning. To our
knowledge, ours is the ﬁrst report on leveraging secure
federated learning for FDIA detection in smart grids.
4) We perform extensive experiments to examine the effec-
tiveness and superiority of the presented secure federated
deep learning-based FDIA detection method. In addition,
we also add noises on the measurement data to test the
robustness of our method.

II. PRELIMINARY

A. Bad Data Detection

Since measurement data in the power grid usually suffers
from data incompleteness and data anomalies, state estimation
is necessary to accurately and efﬁciently monitor state infor-
mation to offer support for system security evaluation [28].
Existing bad data detection mechanisms for detecting state
information in the EMS have the ability to resist some
common less stealthy cyber attacks. However, there are still
serious vulnerabilities in the bad data detection mechanism.
Liu’s team found that by following certain conditions, it is
possible to construct spurious measurement data to be injected
into SCADA without increasing the estimate residuals, which
is stealthy to BDD mechanisms [7].

As one of the basic analysis tools for EMS to achieve
reliable monitoring of the power system, state estimation
provides feedback to the system on the operating status of the
network based on measurement data and network information.
Currently, AC state estimation is commonly used in smart
grids, which uses a nonlinear function between the measure-
ment values and the system states. The corresponding model
for state estimation is described as follows:

z = h(x) + e,

(1)

where z = {z1, z2, · · · , zI } is the measurement vector, which
represents the power injection of each bus and the power
ﬂow of each branch; x = {x1, x2, · · · , xJ } is the state

vector, which represents the voltage amplitude and phase angle
of each bus; h(x) denotes the measurement function of x;
e = {e1, e2, · · · , eI } stands for the measurement noises; I
and J denote the number of measurement variables and the
number of state variables, respectively.

Multiple approaches for solving the system state vectors
x have been proposed in [29]. The most commonly used
state estimate method in power systems is WLS. WLS solves
for the estimate with the smallest objective function value as
the optimal state result by using the sum of the squares of
the differences between the measurement vector z and the
estimated state vector x as the objective function, and the
value of the estimated system state vector x(cid:48) can be solved by

x(cid:48) = arg min

[z − h(x)]T Y[z − h(x)],

(2)

x

where Y is a diagonal matrix, and each of its elements is
equal to the inverse of the respective measurement accuracy.
During the whole process of remote terminal measurement
data from being collected in the ﬁeld to being transmitted to
the database of the power control center, each step may be
subject to random disturbances and generate errors, such as
sensor offset, interference in the communication process, and
human error. These errors can cause some measurement data to
deviate from the real value and make it signiﬁcantly different
from the normal data. This kind of measurement data is called
bad data. Bad data with large errors, when subjected to the
state estimation process, can cause the calculated deviations
between the calculated state estimate and the real condition,
which seriously affects the control center operator’s judgment
of the system state. Researchers have adopted a series of
methods to detect, process, and eliminate bad data. Most of
the commonly used methods are based on the residual test
principle. The residual r is deﬁned as

(cid:107)r(cid:107)2 = (cid:107)z − h(x(cid:48))(cid:107)2.

(3)

Assuming that all state vectors are independent mutually
and the random measurement error vectors obey the Gaussian
2
distribution with zero mean, therefore it is attested that (cid:107)r(cid:107)2
obeys the chi-square distribution. In order to detect whether
there is bad data in the measurements, we compare euclidean
norm of residual with the threshold value τ [30]. The speciﬁc
inequality is shown as below:

(cid:107)r(cid:107)2 > τ.

(4)

B. False Data Injection Attack

Changing some state vectors by manipulating a set of
measurement vectors is the basic principle of constructing a
FDIA on an AC power system [18]. For instance, if an attacker
intends to change the real power on bus i, he ought to make a
series of attack vectors so that the estimated state vectors do
not differ from the actual state values. Due to the subjection
to the power ﬂow equations, all the measurement vectors of
the system have to follow the change of the state vectors. The
power ﬂow equations are as follows:

3

ViVj(Gij cos θij+Bij sin θij),

(5)

ViVj(Gij sin θij−Bij cos θij),

Pi =

Qi =

Ni(cid:88)

j=1

Ni(cid:88)

j=1

(6)

(7)

(8)

Pij = V 2

i (gsi + gij) − ViVj(gij cos θij + bij sin θij),

Qij = −V 2

i (bsi + bij) − ViVj(gij sin θij − bij cos θij),

where Pi represents the real power injections at bus i, Qi
denotes reactive power injections at bus i. Pij stands for the
real power ﬂow from bus i to bus j, Qij represents the reactive
power ﬂow from bus i to bus j. Vi(Vj) is the voltage magnitude
at bus i (j), θi(θj) represents the phase angle at bus i (j).
Gij + jBij is the ijth element of the bus admittance matrix,
gij + jbij is the admittance of the branch between buses i and
j, gsi + jbsi is the admittance of the shunt branch connected
at bus i, Ni indicates the number of buses connected to bus i,
and θij = θi − θj.

From (5)-(8), we can see that any change in the state value
affects the change in the measurement values correlating to
it. For creating a stealthy FDIA in power system, a set of
measurements needs to be changed.

A. Abur et al. [29] state that in order to make attack vectors

stealthy, an attack vector α could be constructed by

α = h(x(cid:48) + l) − h(x(cid:48)),

(9)

where l denotes the vector of deviations of state quantities
after being attacked. By adding the attack vector α to the real
measurement vector, the measurement vector of the attack will
change to zα = z + α, and accordingly the state vector of the
attacked system will become x(cid:48)
α = x + l. When the attack
vector is constructed using the above method, the residuals
after being attacked will become as shown below:

(cid:107)rα(cid:107)2 = (cid:107)zα − h(x(cid:48)

α)(cid:107)2 = (cid:107)z + α − h(x(cid:48) + l)(cid:107)2

= (cid:107)z + h(x(cid:48) + l) − h(x(cid:48)) − h(x(cid:48) + l)(cid:107)2
= (cid:107)r(cid:107)2.

(10)

From (10), it can be clearly seen that the residual values
do not change and therefore the bad data detector can not
detect the attack. In this way, a stealthy FDIA is built on the
vulnerability of conventional bad data detection. Note that,
this attack is able to modify the original measurements while
bypassing the bad data detection in power systems, as it keeps
the 2-norm of the compromised data unchanged in such cases.

III. PROPOSED METHOD

Firstly, the workﬂow of the proposed SecFed scheme is
described. Then, the developed transformer-based FDIA detec-
tion model is presented. Finally, the federated learning-based
framework is demonstrated.

A. Proposed SecFed Scheme

The key idea of the SecFed scheme is that multi-clients
co-train a FDIA detection model while keeping the data
locally. This scheme is a combination of the federated learning
and the Paillier cryptosystem. Fig. 1 and Algorithm 1 show
the ﬂowchart of the SecFed-Transformer and the details of
the scheme, respectively. To be speciﬁc, the SecFed scheme
consists of the following ﬁve steps:

1) Initialization: After all clients are enumerated by the
trustee, the model parameters are initialized for each client,
such as the number of encoder blocks Nenc, the number of
communication rounds R, the number of local epochs E,
size of minibatch B, learn rate lr, loss function L, initial
weight w0, the communication round index r, the time step
e, the ﬁrst moment vector f , the second moment vector s,
exponential decay rates for moment estimates α1 and α2, a
small constant used for numerical stabilization ε. Generate
public key P K = (n, g) and private key CK(λ, µ) based
on the Paillier cryptosystem through KeyGeneration (see
Appendix for the details).

2) Training of local models deployed on each client: After
initialization, each client locally trains a Transformer-based
FDIA detection model using their respective local data.

3) Encryption of model weights: When the training of
each client’s local Transformer model
is completed, each
client extracts and encrypts the respective model weights by
Encryption(w, P K), and then uploads the encrypted model
weights to the cloud.

4) Aggregation of model weights: According to the received
encrypted model weights from each client, the cloud server
aggregates them through Aggregation(ctd), and then the
aggregated ciphertext is sent back to each client.

5) Update of

local models: By using the method of
Decryption(ad, CK), the ciphertext c is decrypted, and each
client obtains the updated model weights. And then, the local
deep learning model is updated.

Fig. 1. Flow Chart of the SecFed-Transformer.

To facilitate the analysis, we make the following three as-
sumptions: i) all clients use the same initial global framework
to train their Transformer models; ii) all local models have the

4

same hyperparameters and the same optimization algorithms;
iii) the computing power of each client is similar. It should
be noted that this paper does not consider dropped packets
in the communication process, while realistic situations need
to consider these issues. Referring to our previous study [26],
we set the federated learning related parameters. It is noted
that the cloud server itself does not train the model, and the
knowledge of the weights of the global model is derived by
aggregating the weights of each local model.

B. Distributed Detector Based on Transformer

As a cutting-edge deep learning model, Transformer ﬁrstly
proposed in 2017 has shown great success in the area of
language recognition in recent years [31]. Unlike most of the
current major sequence transduction models that are based on
complex neural networks recursion or convolution of neural
networks, Transformer eschews recursion and convolution and
forms its network structure through attention mechanisms and
neural networks. In addition, traditional deep learning models
perform feature extraction based on the sequential ordering of
data [32], while Transformer focuses more on the global data
feature relationships, which makes it more suitable for dealing
with FDIA detection issues. In this section, a deep learning
model based on Transformer is presented to detect stealthy
FDIA in smart grid, and a diagram of the proposed detector
is depicted in Fig. 2.

1) The input and output of the detector: In this work, active
and reactive power injections of nodes and power ﬂows of
branches are adopted as the input of the detection model, while
the judgment of whether a FDIA occurs as the output. We
formulate the problem for detecting stealthy FDIA represented
by the attack vector α as a binary classiﬁcation problem with
the detection indicator β.

(cid:40)

β =

0, Normal data
1, Compromised data.

(11)

In the Transformer-based detection model, the measurement
vector z, comprising power injections and power ﬂows, is
gathered as the inputs of Transformer, which is labeled with
β = 1 or β = 0 . In comparison to the traditional WLS
detection approach, our detection method is totally data-driven
and does not need the model and parameters of the analyzed
i.e., h(x). In addition, we train the Transformer
system,
model
to deeply extract attack features from normal and
compromised data, and thereby detect the presence of stealthy
FDIAs.

2) Transformer architecture: A Transformer model mainly
consists of a positional encoding, encoder blocks and a sig-
moid layer, where a encoder block includes a multi-head self-
attention module, Add&Norm layers and feedforward neural
networks.

a) Positional encoding: In order to learn the intrinsic laws
obeyed by the feature quantities of different positions under
normal and compromised conditions, the Transformer must
record the position information of each feature quantity in
sample sets. The data is ﬁrst processed for recording the

Initial global modelDeploy parame-ters to clientsDataProcessingAverage weights Multi-HeadSelf-AttentionAdd&NormAdd&NormFeedForwardClientsFederated Learning Frameworklocal Transformer ModelIn a ClientGlobal epochLocalepochLocalepoch...Nenc×LocalepochClientsAlgorithm 1 Secure Federated Learning(SecFed).

1: Input: The data resources of each client {Dt | t ∈ T },
the number of communication rounds R, the number of
local epochs E, the size of minibatch B, learning rate lr,
loss function L.

5

2: Output: The SecFed-Transformer model.
3: Initialization:
4:

a). The trustee generates private key and public key
{CK, P K} by KeyGeneration and sends them to each
client.
b). Initialize the w0.
c). Initialize the r = 0.

5:
6:
7: Procedure:
8: for r ≤ R do
9:
10:
11:
12:
13:
14:

(I). For each client:
Initialize e = 1
for each round e ≤ E do

B ← (split Dt into minibatch of size B)
for each minibatch of data resource do

Initialize f = 0, s = 0, α1 = 0.9, α2 = 0.999,
ε = 10−8, respectively;
a). Compute the gradient by g ← ∇wt,rL.
b). Renew the biased ﬁrst moment estimation by
f ← α1f + (1 − α1)g.
c). Renew the biased second raw moment estimation
by s ← α2s + (1 − α2)g2.
d). Calculate the bias-corrected ﬁrst moment estimat-
ion by ˆf ← f
e). Calculate the bias-corrected second raw moment
estimation by ˆs ← s
.
f). Renew the model weights by
wt,r ← wt,r − lr

1−αe
2

1−αe
1

ˆf√

.

.

ˆs+ε

end
returnwt,r
for each ciphertext ctd do

Compute the ciphertext by
ctd ← Encryption(wt,r, P K);

end
(II). For cloud server:
for each ciphertext ctd do

Aggregate the ciphertext by
ad ← Aggregation(ctd);

end
The cloud server distributes the aggregated ciphertext
ad to all clients.
(III). For each client:
If r < R

for each aggregated ciphertext ad do

Decrypt the ciphertext by
wt,r ← Decryption(ad, CK);

end
Each client upload its local model using the renewed
weights wi,r+1
r ← r + 1

15:
16:

17:

18:

19:

20:

21:
22:

23:
24:
25:
26:
27:
28:

29:
30:
31:
32:

33:
34:
35:
36:
37:
38:

39:

Else

40:
41:
42:
43: end
44: return The comprehensive deep learning model.

Break

Fig. 2. Proposed Transformer-based FDIA detector.

position information of each feature quantity in a data sample
by positional encoding, which can be described as

PE(φ,2k) = sin(φ/100002k/d),

PE(φ,2k+1) = cos(φ/100002k/d),

(12)

(13)

where PE(·) is the function of positional encoding operations,
φ denotes the position of each sample in sample sets, d
represents the dimension, 2k denotes the even dimension,
and 2k+1 denotes the odd dimension (k is a natural number,
2k ≤ d, 2k + 1 ≤ d).

b) Multi-head self-attention module: This module uses the
self-attention mechanism to dig out the potential relationships
in the electrical quantities of the power system to distinguish
the true values from the false ones. The multi-head self-
attention module consists of several self-attention modules.

Self-attention uses matrices Q(query), K(key), and V(value)
in its calculation. In this study, the self-attention receives the
output of positional encoding or the output of the previous
encoder block as its input. Q, K, V are obtained by multiplying
the input of self-attention by the linear matrix WQ, WK, WV,
respectively. After obtaining the matrices Q, K, V, the output
of self-attention can be calculated as the following formula:

Attention(Q, K, V) = softmax(

QKT
√
dk

)V,

(14)

where dk is the number of columns of matrices Q and K. The
obtained self-attention matrix reﬂects the degree of correlation
between each electrical quantity.

c) Add&Norm layer: This layer is set after the multi-head
self-attention module or feedforward neural network module.
The calculation of Add&Norm layer consists of two opera-
tions: Add and Norm. Here, Add stands for residual connection
to prevent network degradation, and Norm represents layer

Power SystemMeasuementsPower NetworkKnowledgeBad DataDetectorStateEstimatorBad Data DetectedTransformerNetwork TrainingHistorical SystemMeasuementsMulti-HeadSelf-AttentionAdd&NormAdd&NormFeedForwardStealthyAttackNo AttackTransformerZh (·)xZOffline TrainingOnline Detection×NencThe BDD testThe proposed learning-based methodNo bad datanormalization to normalize the activation values of each layer.
The speciﬁc operations in this layer are given as follows:

LayerNorm(X + MultiHeadAttention(X)),

(15)

LayerNorm(X + FeedForward(X)),

(16)

where X is the input of multi-head self-attention module or
feedforward neural network module. The Add operation refers
to X + MultiHeadAttention(X) or X + FeedForward(X),
which is used to solve the problem of multi-layer network
training such as gradient dispersion and gradient explosion;
while the Norm operation refers to layer normalization, which
can speed up the convergence process by converting the input
of each layer to have the same mean-variance.

d) Feedforward neural network module: This module con-
sists of two parts, a fully connected layer in the front as well
as a dropout layer in the back. The fully connected layer
corresponds to the following equation:

max(0, XW1 + b1)W2 + b2,

(17)

where X is the input, and FeedForward ends up with an output
matrix whose dimensions are consistent with X.

And then, we apply dropout to the output of feedforward
neural network module. The role of the dropout layer is to
prevent overﬁtting of the model.

e) Sigmoid layer: This layer consists of two fully connected
layers in series, and sigmoid function is used as the activation
function of the last fully connected layer. The Sigmoid layer
is used to map the output of the Transformer to a classiﬁcation
result.

C. Proposed Framework Based on Federated Learning

Federated learning, initially studied and proposed by the
Google team [33],
is a machine learning framework that
accomplishes multi-client collaboratively modeling without
data sharing. This paper assumes that there are T clients (e.g.,
edge devices) and each client has a separate piece of data. A
traditional centralized training approach builds a large dataset
by collecting data from all clients in a central workstation,
which trains the large dataset to obtain a global model. With
the centralized approach, each client exposes its data to each
workstation and other clients, which makes it very vulnerable
to data leakage. In contrast, federated learning simply uploads
the weights of each client to a central server for aggregation,
with the original data for each client stored locally and not
exchanged or transferred, and the weights are aggregated and
updated to achieve learning goals. Although federated learning
does not require original data in data sharing, participants
still need to upload model weights to construct a federated
model, which are essentially a mapping of raw data, and cloud
servers or hackers can invert the data of each client through
model weights. To address this problem, we introduce the
Paillier cryptosystem [34], a homomorphic encryption method,
to protect the weights of the models in federated learning.

6

Fig. 3. The structure of server-client-trustee in SecFed

The speciﬁc steps of the Paillier cryptosystem are shown in
Appendix.

Combining the Paillier cryptosystem with traditional feder-
ated learning, we propose a secure federated learning approach
for communication over multiple edge devices for collabora-
tive training of multiple models. As shown in Fig. 3, it is
generally composed of the following components:

• Cloud server: A cloud server is usually a cloud aggregator
which has powerful computing power and abundant com-
puting resources. The main functions of cloud aggregator
are as follows: (1) initializes the global model before the
ﬁrst run of the global model; (2) sends the global model to
all clients after each communication round; (3) aggregates
the weights which are uploaded by the clients until the
model converges.
• Clients: Each client

is responsible for modeling a
Transformer-based local FDIA detector, which is based
on its own gathered measurement data (time-section
electrical data collected by SCADA at each node) on
behalf of each client, and helps to update the weights
of the detector by repeatedly interoperating with the
cloud server until the detector converges. Note that, the
presented method is also suitable for WAMS data or
mixed measurement data of WAMS and SCADA, besides
SCADA data.

• Trustee: Based on the Pillier cryptosystem, trustee gen-
erates public keys as well as private keys, and uses them
to encrypt the weights which are uploaded by each client
to the server, and decrypt the weights distributed by the
server to each client.

IV. EXAMPLE ANALYSIS
In this section, we conduct a large number of experiments
to evaluate the performance of SecFed-Transformer method.
In Section IV-A, we describe the data generation. In Sec-
tion IV-B, we introduce the implementation details and hy-
perparameter settings. In Section IV-C, we conduct numerous

...Client 1Client 2Client TTrusteeCloud Serverof experiments for comparing SecFed-Transformer with some
common deep learning detection models including the CNN
and LSTM, under our SecFed scheme, and use different
metrics to compare the proposed approach with traditional
algorithms in detail. Finally, in Section IV-D, the robustness
of the proposed model is illustrated by observing the accuracy
under different noises.

A. Data Generation

1) Normal data: Following the approach in [12], we ﬁrstly
generate uncompromised data which is based on the IEEE
14-bus system and IEEE 118-bus system. Speciﬁcally, we
generate a set of data that has a mean equal to the base load
and a variance of one-tenth of the base load.

2) Compromised data: Since unstealthy FDIAs can be
detected by the BDD, we only construct stealthy FDIAs. We
generate compromised data under strong and weak attacks
which is performed on the IEEE 14-bus system and IEEE
118-bus system.

it

According to [19],

is stated that all generated FDIA
samples are classiﬁed into 3 categories based on the “strength”
of attacks: a) Weak attacks: The ratio of the mean of the
power injection deviations in c to x is smaller than 10%, or
the ratio of the mean of the voltage magnitude deviations
to nominal value is smaller than 5%, or the mean of the
voltage angle deviations is smaller than 2◦; b) Strong attacks:
The means of the deviations of the above-mentioned variables
are respectively greater than 30%, 10%, and 5◦; c) Medium
attacks: FDIA samples not belonging to the above two attacks.
3) Training and test datasets settings: In each attack case, we
generate a training set containing 10,000 samples of normal
data and 10,000 samples of compromised data, and a test set
containing 1,000 samples of normal data and 1,000 samples
of compromised data. In addition, it should be noted that we
choose horizontal federated learning, which requires the data
features of each client to be consistent, so we choose the bus
data of each node and a branch data connected to the bus for
each client data. Therefore, each data set consists of power
injections of all buses, as well as power ﬂow of the selected
branch.

7

B. Experiment Settings

1) Environmental setup: All simulations are performed on
a machine with Intel i9-10900k CPU, GTX3090 GPU, and
32 GB RAM. Data generation is performed in Matlab using
MATPOWER [35], and the federated deep learning component
is run in Python based on Tensorﬂow 2.5.

2) Hyperparameter settings: Regarding Transformer,
the
learning rate is selected as 0.0001, the number of encoder
blocks is 3, the number of local epochs under strong attacks is
set to 400, and the number of local epochs under weak attacks
is 1000, the minibatch is set to 128, the Adam optimizer is
selected as the optimizer, and the Binary Cross-Entropy is
chosen as the loss function. As for federated learning, the
maximum number of communication rounds is 9.

C. Detection Results

1) Performance evaluation metrics: In our experiments, we
calculate the True Positive, False Positive, True Negative, and
False Negative, where True Positive stands for the compro-
mised measurement value is detected as the compromised data.
Then we choose accuracy, precision, recall, and F1-score as the
evaluation metrics for our output results. The speciﬁc formulas
for each indicator can be found in the relevant literatures [12]
and [20].

2) The IEEE 14-bus system: Table I and Table II show
the various evaluation metrics of the CNN, LSTM, and the
proposed method in this paper for the IEEE 14-bus system
under weak and strong attacks, respectively. We take bus 2
and bus 3 as examples to show the change of their metrics in
different communication rounds (R). Fig. 4a and Fig. 4b show
the change of accuracy with the number of communication
rounds for the IEEE 14-bus system under weak and strong
attacks, respectively, for the CNN, LSTM, and the proposed
method in this paper, taking bus 3 as an example.

Under weak attacks, when R=6, accuracy, precision, recall,
and F1-score are 0.9965, 0.9995, 0.9938, 0.9966 for bus 2, and
accuracy, precision, recall, and F1-score are 0.9230, 0.9855,
0.8883, 0.9344 for bus 3, respectively. From the experimental
results, it is clear that the proposed method is notably superior
to the CNN and LSTM. As the communication round increases
from 0 to 9 (R=0 means the model is trained locally without

TABLE I
DATA COMPARISON OF TWO DIFFERENT NODES OF THE IEEE 14-BUS SYSTEM
WITH DIFFERENT NUMBER OF COMMUNICATION ROUNDS (UNDER WEAK ATTACKS)

Bus R

CNN

LSTM

The Proposed Method

Precision

Recall

F1-score

Precision

Recall

F1-score

Precision

Recall

F1-score

2

3

0

2

4

6

0

2

4

6

0.9841

0.9991

0.9991

0.9991

0.5537

0.5467

0.5539

0.5577

0.9783

0.9816

0.9834

0.9841

0.4380

0.5091

0.5019

0.5180

0.9812

0.9903

0.9912

0.9915

0.4891

0.5272

0.5019

0.5371

0.9964

0.9962

0.9977

0.9976

0.5919

0.5893

0.5826

0.6336

0.9888

0.9894

0.9887

0.9886

0.4947

0.4611

0.5149

0.6088

0.9926

0.9928

0.9932

0.9931

0.5389

0.5174

0.5467

0.6210

0.9991

0.9985

0.9995

0.9995

0.9932

0.9830

0.9850

0.9855

0.9940

0.9944

0.9936

0.9938

0.8188

0.8725

0.8779

0.8883

0.9965

0.9964

0.9966

0.9966

0.8976

0.9245

0.9255

0.9344

8

TABLE II
DATA COMPARISON OF TWO DIFFERENT NODES OF THE IEEE 14-BUS SYSTEM
WITH DIFFERENT NUMBER OF COMMUNICATION ROUNDS (UNDER STRONG ATTACKS)

Bus R

CNN

LSTM

The Proposed Method

Precision

Recall

F1-score

Precision

Recall

F1-score

Precision

Recall

F1-score

2

3

0

2

4

6

0

2

4

6

1.0000

1.0000

1.0000

1.0000

0.7547

0.7741

0.7779

0.7703

1.0000

1.0000

1.0000

1.0000

0.6859

0.7044

0.7096

0.7054

1.0000

1.0000

1.0000

1.0000

0.7210

0.7376

0.7422

0.7364

1.0000

1.0000

0.9997

1.0000

0.8591

0.9329

0.9837

0.9768

0.9766

0.9952

1.000

1.0000

0.6913

0.8199

0.8642

0.9019

0.9981

0.9976

0.9999

1.0000

0.7661

0.8727

0.9200

0.9379

1.0000

1.0000

1.0000

1.0000

1.0000

1.0000

0.9999

1.0000

1.0000

1.0000

1.0000

1.0000

0.9257

0.9998

0.9999

1.0000

1.0000

1.0000

0.9990

1.0000

0.9614

0.9999

0.9990

1.0000

TABLE III
DATA COMPARISON OF TWO DIFFERENT NODES OF THE IEEE 118-BUS SYSTEM
WITH DIFFERENT NUMBER OF COMMUNICATION ROUNDS (UNDER WEAK ATTACKS)

Bus R

CNN

LSTM

The Proposed Method

Precision

Recall

F1-score

Precision

Recall

F1-score

Precision

Recall

F1-score

55

87

0

2

4

6

0

2

4

6

0.6071

0.8586

0.8617

0.8556

0.5845

0.5826

0.5824

0.5826

0.6578

0.7387

0.7415

0.7342

0.5526

0.5695

0.5669

0.5679

0.6314

0.7941

0.7971

0.7903

0.5681

0.5758

0.5745

0.5752

0.6157

0.7341

0.9201

0.9492

0.7828

0.9394

0.9402

0.9418

0.6392

0.6926

0.7716

0.7698

0.6718

0.7903

0.8047

0.8247

0.6273

0.7127

0.8393

0.8501

0.7231

0.8584

0.8672

0.8794

0.8257

0.9944

0.9997

0.9997

0.8276

0.9844

1.0000

1.0000

0.8206

0.9279

0.9355

0.9355

0.7032

0.8358

0.9834

0.9806

0.8231

0.9600

0.9666

0.9666

0.7603

0.9037

0.9916

0.9902

TABLE IV
DATA COMPARISON OF TWO DIFFERENT NODES OF THE IEEE 118-BUS SYSTEM
WITH DIFFERENT NUMBER OF COMMUNICATION ROUNDS (UNDER STRONG ATTACKS)

Bus R

CNN

LSTM

The Proposed Method

Precision

Recall

F1-score

Precision

Recall

F1-score

Precision

Recall

F1-score

55

87

0

2

4

6

0

2

4

6

0.7602

0.9065

0.9379

0.9426

0.7981

0.7983

0.8656

0.8671

0.8475

0.8883

0.9086

0.9120

0.7813

0.7813

0.7973

0.7962

0.8015

0.8973

0.9230

0.9271

0.7896

0.7897

0.8300

0.8302

0.8776

0.9962

0.9991

0.9978

0.9590

0.9684

0.9675

0.9730

0.8061

0.8916

0.9554

0.9779

0.8582

0.9232

0.9393

0.9434

0.8403

0.9410

0.9767

0.9877

0.9058

0.9453

0.9530

0.9584

1.0000

1.0000

1.0000

1.0000

1.0000

1.0000

1.0000

1.0000

0.9042

1.0000

1.0000

1.0000

1.0000

1.0000

1.0000

1.0000

0.9497

1.0000

1.0000

1.0000

1.0000

1.0000

1.0000

1.0000

federated learning), the performance of each detection model is
gradually enhanced and eventually stabilized; and the detection
accuracy of the proposed method can reach more than 90% for
both strong and weak attacks. Furthermore, the accuracy of the
proposed method always exceeds that of the CNN and LSTM.
In addition,
the proposed approach performs better under
strong attacks than under weak attacks because strong attacks
make the difference between normal data and compromised
data more pronounced compared to weak attacks.

To test

the effectiveness of federated learning, we also
conduct experiments about local model and ideal model, where
local model means that each node uses only local data to

train its own model without any communication with other
nodes, and the ideal model means that the data of all nodes
are pooled together and trained with a centralized model.
Fig. 5 shows the data differences between the above mentioned
local model, federated model, and ideal model under weak
and strong attacks. As seen in the ﬁgures,
the accuracy,
precision, recall, and F1-score of the local model are 0.9625,
1.0000, 0.9257, and 0.9614, respectively, while the accuracy,
precision, recall, and F1-score of our proposed model are
1.0000, 1.0000, 0.9998, and 0.9999. It is obvious that the
local model does not perform satisfactorily, while our method
has a satisfactory performance. The performance of ours is

9

(a)

(b)

(a)

(b)

Fig. 4. Comparison of Accuracy of considered FDIA detection models with
varying communication rounds in IEEE 14-bus system, bus 3. (a) Weak
attacks. (b) Strong attacks.

Fig. 6. Comparison of the accuracy of considered FDIA detection models
with varying communication rounds in IEEE 118-bus system, bus 55. (a)
Weak attacks. (b) Strong attacks.

118-bus system are roughly similar to those on the IEEE 14-
bus system, and the detection accuracy of the proposed model
is signiﬁcantly better than that of the CNN and LSTM.

(a)

(b)

Fig. 5. Performance comparison of the local, ideal, and SecFed at bus 3 in
the IEEE 14-bus system. (a) Weak attacks. (b) Strong attacks.

approximately equivalent to that of the ideal model, but the
SecFed scheme solves the problems existing in the ideal
model, such as communication delay, and privacy leakage.
Therefore, compared with other deep learning methods, our
model has the best performance in solving the FDIA detection
problem in this study.

3) The IEEE 118-bus system: Table III and Table IV show
the evaluation metrics of the CNN, LSTM and the proposed
method in this paper for the IEEE 118-bus system under weak
attacks and strong attacks, respectively. We take bus 55 and bus
87 as examples to show the change of the metrics of different
models in different communication rounds. Fig. 6 shows the
change of accuracy with the number of communication rounds
for the IEEE 118-bus system under weak and strong attacks,
for the CNN and LSTM, and the proposed method with bus
55 as an example. Similarly, we also conduct experiments
concerning the local model and the ideal model. Fig. 7 shows
the comparison of the results of each experiment.

From the results, it can be seen that the results on the IEEE

(a)

(b)

Fig. 7. Performance comparison of the local, ideal, and SecFed at bus 55 in
the IEEE 118-bus system. (a) Weak attacks. (b) Strong attacks.

D. The Effect of Measurement Noises

Due to the presence of noises in real power system measure-
ment equipments [36], we design various levels of measure-
ment noises and observe the impact of measurement noises.
We add Gaussian noises to individual client data to represent
the noises in the power system. In this experiment, we set the
measurement noises to range from 1% to 4% of the true value.
We take the accuracy of bus 4 as an example and compare
the proposed method with the CNN and LSTM in this paper.
The speciﬁc results are displayed in Fig. 8. From the ﬁgure,
it is easy to see that the accuracys of all models decrease as
the noise level increases. This is because with the increasing
noise levels, normal data and compromised data become more
difﬁcult to distinguish as the unnoised data is more likely

        & R P P X Q L F D W L R Q  5 R X Q G  U R X Q G V  R I  X S O R D G                    $ F F X U D F \ 7 U D Q V I R U P H U / 6 7 0 & 1 1        & R P P X Q L F D W L R Q  5 R X Q G  U R X Q G V  R I  X S O R D G                              $ F F X U D F \ 7 U D Q V I R U P H U / 6 7 0 & 1 1 $ F F X U D F \ 3 U H F L V L R Q 5 H F D O O )   V R U H 0 H W U L F V                   3 H U I R U P D Q F H / R F D O 6 H F ) H G , G H D O $ F F X U D F \ 3 U H F L V L R Q 5 H F D O O )   V R U H 0 H W U L F V                   3 H U I R U P D Q F H / R F D O 6 H F ) H G , G H D O        & R P P X Q L F D W L R Q  5 R X Q G  U R X Q G V  R I  X S O R D G                    $ F F X U D F \ 7 U D Q V I R U P H U / 6 7 0 & 1 1        & R P P X Q L F D W L R Q  5 R X Q G  U R X Q G V  R I  X S O R D G                              $ F F X U D F \ 7 U D Q V I R U P H U / 6 7 0 & 1 1 $ F F X U D F \ 3 U H F L V L R Q 5 H F D O O )   V R U H 0 H W U L F V                   3 H U I R U P D Q F H / R F D O 6 H F ) H G , G H D O $ F F X U D F \ 3 U H F L V L R Q 5 H F D O O )   V R U H 0 H W U L F V                   3 H U I R U P D Q F H / R F D O 6 H F ) H G , G H D Odrowned in the noises. Moreover, it is obvious from the ﬁgure
that our proposed method performs signiﬁcantly better than
the CNN and LSTM under the inﬂuence of noises, therefore
it can be concluded that our model has better robustness than
other alternatives..

1. KeyGeneration: Trustee randomly chooses two large
prime numbers p and q and calculates their product n as well
as λ (λ is the least common multiple of p - 1 and q - 1). Then,
pick a random integer g ∈ Z ∗

n2 ,and g must satisfy

gcd(L(gλ mod n2), n) = 1.

(18)

10

The ﬁnal calculation is made µ = (L(gλ mod n2))−1,
where the function L(x) = (x − 1)/n, and the function gcd(·)
is used to calculate the maximum common divisor of two
numbers. Zn2 is the set of integers less than n2, and Z ∗
n2
is the set of integers that are mutually exclusive with n2 in
Zn2 . We choose (n, g) as the public key(P K), and (λ, µ)
as the private key (CK) of each client and trustee distributes
them to each client.

2. Encryption(w, P K): To ensure that the encrypted num-
ber is a positive integer, we preprocess the weights. Deﬁne
a function ˆx = f (x) = 108 × (x + s), where s is greater
than the absolute value of the minimum value of the weights.
The weights of the local client can be transformed to positive
integer ˆwtd ∈ Zn by calculation ˆwtd = f (wtd) . After
randomly selecting a positive integer r ∈ Z ∗
n, we encrypt the
model weights as follows:

ctd = gf (wtd) · rn mod n2,

(19)

where t ∈ {1, 2, · · · , T }, d ∈ {1, 2, · · · , N }. T represents the
number of clients, and N denotes the number of weights in
each client.

3. Aggregation(ctd): Each client uploads the encrypted
weight ctd to server, then the cloud server aggregates the
received parameters by

ad = c1d · c2d · · · · · cKd =

K
(cid:89)

t=1

ctd.

(20)

4. Decryption((ad, CK): The server distributes the aggre-
gated weights to each client, and each client decrypts the
received ciphertext by

md = L(ad mod n2) · µ mod n

= L(aλ

d mod n2) · L(gλ mod n2)−1 mod n.

(21)

Afterwards, the average value of the decrypted parameters
with respect to the client will be calculated ¯md = md/K. The
weights which are updated are calculated by

w(cid:48)

td = f −1( ¯md) = 10−8 · ¯md − s.

(22)

REFERENCES

[1] V. C. Gungor, D. Sahin, T. Kocak, S. Ergut, C. Buccella, C. Cecati, and
G. P. Hancke, “Smart grid technologies: Communication technologies
and standards,” IEEE Trans. Ind. Informat., vol. 7, no. 4, pp. 529–539,
2011.

[2] K. Dehghanpour, Z. Wang, J. Wang, Y. Yuan, and F. Bu, “A survey on
state estimation techniques and challenges in smart distribution systems,”
IEEE Trans. Smart Grid, vol. 10, no. 2, pp. 2312–2322, 2019.

[3] X. Yu and Y. Xue, “Smart grids: A cyber–physical systems perspective,”

Proc. IEEE, vol. 104, no. 5, pp. 1058–1070, 2016.

[4] “Analysis of the cyber attack on the Ukrainian power grid,” Elect. Inf.
Sharing Anal. Center, vol. 388, pp. 1–29, Washington, DC, USA, 2016.
[5] A. S. Musleh, G. Chen, and Z. Y. Dong, “A survey on the detection
algorithms for false data injection attacks in smart grids,” IEEE Trans.
Smart Grid, vol. 11, no. 3, pp. 2218–2234, 2019.

Fig. 8. Performance of CNN, LSTM, Transformer under different noise levels.

V. CONCLUSION

Aiming at false data injection attacks faced by smart grids, a
FDIA detection method combining secure federated learning
with Transformer is proposed in this paper. To the authors’
knowledge, this is the ﬁrst work to leverage secure federated
learning for detecting FDIA in smart grid. First, we build a
Transformer-based FDIA detection model for local training of
each node. Then, we introduce a federated learning framework
to enable all nodes collaboratively train a detection model
while preserving the privacy of all the local training data. In
addition, we combine the Paillier cryptosystem with the feder-
ated learning framework to construct secure federated learning,
which effectively protects the privacy of federated learning
during training. Extensive experimental results indicate that
our Transformer-based detection model signiﬁcantly outper-
forms conventional deep learning algorithms and the proposed
secure federated learning approach has unique advantages in
protecting data privacy and reducing communication overhead
than centralized detection methods.

In the future, we will extend our method to handle the
detection of multi-cyber attacks, including but not limited
to denial-of-service attacks and replay attacks. This work
assumes that an attacker has all system information during
attacks, while more realistic scenarios should consider cyber
attacks with incomplete information. It’s also interesting to
determine the hyper-parameters of the presented approach by
using automated machine learning [37].

APPENDIX

Paillier cryptosystem is an additive homomorphic key cryp-
tosystem for securing federated learning data, and its key
mechanism consists of the following four parts:

                                    1 R L V H  / H Y H O                             $ F F X U D F \ 7 U D Q V I R U P H U / 6 7 0 & 1 111

[29] A. Abur and A. G. Exposito, Power system state estimation: theory and

implementation. Boca Raton, FL, USA: CRC press, 2004.

[30] T. Wu, C. Y. Chung, and I. Kamwa, “A fast state estimator for systems
including limited number of PMUs,” IEEE Trans. Power Syst., vol. 32,
no. 6, pp. 4329–4339, 2017.

[31] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
Ł. Kaiser, and I. Polosukhin, “Attention is all you need,” Proc. Adv.
Neural Inf. Process. Syst., vol. 30, pp. 5998–6004, 2017.

[32] Y. Li, M. Zhang, and C. Chen, “A deep-learning intelligent system incor-
porating data augmentation for short-term voltage stability assessment
of power systems,” Appl. Energy, vol. 308, p. 118347, 2022.

[33] B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas,
“Communication-efﬁcient learning of deep networks from decentralized
data,” in Proc. 20th Int. Conf. Artif. Intell. Stat.
PMLR, 2017, pp.
1273–1282.

[34] P. Paillier, “Public-key cryptosystems based on composite degree resid-
uosity classes,” in Proc. 17th Int’l Conf. Theory and Application of
Cryptographic Techniques. Springer, 1999, pp. 223–238.

[35] R. D. Zimmerman, C. E. Murillo-S´anchez, and R. J. Thomas, “Mat-
power: Steady-state operations, planning, and analysis tools for power
systems research and education,” IEEE Trans. Power Syst., vol. 26, no. 1,
pp. 12–19, 2011.

[36] Y. Li, J. Li, J. Qi, and L. Chen, “Robust cubature Kalman ﬁlter for
dynamic state estimation of synchronous machines under unknown
measurement noise statistics,” IEEE Access, vol. 7, pp. 29 139–29 148,
2019.

[37] Y. Li, R. Wang, and Z. Yang, “Optimal scheduling of isolated microgrids
using automated reinforcement learning-based multi-period forecasting,”
IEEE Trans. Sustain. Energy, vol. 13, no. 1, pp. 159–169, 2022.

[6] R. Deng, G. Xiao, R. Lu, H. Liang, and A. V. Vasilakos, “False data
injection on state estimation in power systems—attacks, impacts, and
defense: A survey,” IEEE Trans. Ind. Informat, vol. 13, no. 2, pp. 411–
423, 2016.

[7] Y. Liu, P. Ning, and M. K. Reiter, “False data injection attacks against
state estimation in electric power grids,” ACM Trans. Inf. Syst. Security,
vol. 14, no. 1, pp. 1–33, 2011.

[8] K. Manandhar, X. Cao, F. Hu, and Y. Liu, “Detection of faults and
attacks including false data injection attack in smart grid using Kalman
ﬁlter,” IEEE Trans. Control. Netw. Syst., vol. 1, no. 4, pp. 370–379,
2014.

[9] Y. Guan and X. Ge, “Distributed attack detection and secure estimation
of networked cyber-physical systems against false data injection attacks
and jamming attacks,” Trans. Signal Inf. Process. Netw., vol. 4, no. 1,
pp. 48–59, 2017.

[10] S. Bi and Y. J. Zhang, “Using covert topological information for defense
against malicious attacks on DC state estimation,” IEEE J. Sel. Areas
Commun., vol. 32, no. 7, pp. 1471–1485, 2014.

[11] Y. He, G. J. Mendis, and J. Wei, “Real-time detection of false data injec-
tion attacks in smart grid: A deep learning-based intelligent mechanism,”
IEEE Trans. Smart Grid, vol. 8, no. 5, pp. 2505–2516, 2017.

[12] S. Wang, S. Bi, and Y.-J. A. Zhang, “Locational detection of the
false data injection attack in a smart grid: A multilabel classiﬁcation
approach,” IEEE Internet Things J., vol. 7, no. 9, pp. 8218–8227, 2020.
[13] R. Deng and H. Liang, “False data injection attacks with limited
susceptance information and new countermeasures in smart grid,” IEEE
Trans. Ind. Informat., vol. 15, no. 3, pp. 1619–1628, 2018.

[14] Z. Zhang, R. Deng, D. K. Yau, P. Cheng, and J. Chen, “Analysis of
moving target defense against false data injection attacks on power grid,”
IEEE Trans. Inf. Forensics Security, vol. 15, pp. 2320–2335, 2019.
[15] M. Jin, J. Lavaei, and K. H. Johansson, “Power grid AC-based state
estimation: Vulnerability analysis against cyber attacks,” IEEE Trans.
Autom. Control, vol. 64, no. 5, pp. 1784–1799, 2018.

[16] X. Liu and Z. Li, “False data attacks against AC state estimation with
incomplete network information,” IEEE Trans. Smart Grid, vol. 8, no. 5,
pp. 2239–2248, 2016.

[17] J. Zhao, L. Mili, and M. Wang, “A generalized false data injection attacks
against power system nonlinear state estimator and countermeasures,”
IEEE Trans. Power Syst., vol. 33, no. 5, pp. 4868–4877, 2018.

[18] M. Jorjani, H. Seiﬁ, and A. Y. Varjani, “A graph theory-based approach
to detect false data injection attacks in power system AC state estima-
tion,” IEEE Trans. Ind. Informat., vol. 17, no. 4, pp. 2465–2475, 2020.
[19] J. James, Y. Hou, and V. O. Li, “Online false data injection attack
transform and deep neural networks,” IEEE

detection with wavelet
Trans. Ind. Informat., vol. 14, no. 7, pp. 3271–3280, 2018.

[20] Y. Zhang, J. Wang, and B. Chen, “Detecting false data injection attacks
in smart grids: A semi-supervised deep learning approach,” IEEE Trans.
Smart Grid, vol. 12, no. 1, pp. 623–634, 2020.

[21] X. Luo, Y. Li, X. Wang, and X. Guan, “Interval observer-based detection
and localization against false data injection attack in smart grids,” IEEE
Internet Things J., vol. 8, no. 2, pp. 657–671, 2020.

[22] X. Yin, Y. Zhu, and J. Hu, “A subgrid-oriented privacy-preserving
microservice framework based on deep neural network for false data
injection attack detection in smart grids,” IEEE Trans. Ind. Informat.,
vol. 18, no. 3, pp. 1957–1967, 2021.

[23] S. Li, Y. Yılmaz, and X. Wang, “Quickest detection of false data
injection attack in wide-area smart grids,” IEEE Trans. Smart Grid,
vol. 6, no. 6, pp. 2725–2735, 2014.

[24] Y. Liu, S. Garg, J. Nie, Y. Zhang, Z. Xiong, J. Kang, and M. S.
Hossain, “Deep anomaly detection for time-series data in industrial
IoT: A communication-efﬁcient on-device federated learning approach,”
Internet Things J., vol. 8, no. 8, pp. 6348–6358, 2020.

[25] B. Li, Y. Wu, J. Song, R. Lu, T. Li, and L. Zhao, “Deepfed: Feder-
ated deep learning for intrusion detection in industrial cyber–physical
systems,” IEEE Trans. Ind. Informat., vol. 17, no. 8, pp. 5615–5624,
2020.

[26] Y. Li, J. Li, and Y. Wang, “Privacy-preserving spatiotemporal scenario
generation of renewable energies: A federated deep generative learning
approach,” IEEE Trans. Ind. Informat., vol. 18, no. 4, pp. 2310–2320,
2021.

[27] B. Tahir, A. Jolfaei, and M. Tariq, “Experience driven attack design
and federated learning based intrusion detection in industry 4.0,” IEEE
Trans. Ind. Informat., vol. 18, no. 9, pp. 6398–6405, 2022.

[28] M. Ghosal and V. Rao, “Fusion of multirate measurements for nonlinear
dynamic state estimation of the power systems,” IEEE Trans. Smart
Grid, vol. 10, no. 1, pp. 216–226, 2017.

