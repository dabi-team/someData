5
1
0
2

r
a

M
7
2

]
T
G
.
s
c
[

1
v
5
8
0
8
0
.
3
0
5
1
:
v
i
X
r
a

Evolutionary Poisson Games for Controlling Large

1

Population Behaviors
Yezekael Hayel1,2 and Quanyan Zhu2

1LIA/CERI, University of Avignon, Avignon, France, Email: yezekael.hayel@univ-avignon.fr

2Department of Electrical and Computer Engineering, New York University, USA. E-mail:

{yezekael.hayel,quanyan.zhu}@nyu.edu.

Abstract

Emerging applications in engineering such as crowd-sourcing and (mis)information propagation

involve a large population of heterogeneous users or agents in a complex network who strategically make

dynamic decisions. In this work, we establish an evolutionary Poisson game framework to capture the

random, dynamic and heterogeneous interactions of agents in a holistic fashion, and design mechanisms

to control their behaviors to achieve a system-wide objective. We use the antivirus protection challenge

in cyber security to motivate the framework, where each user in the network can choose whether or

not to adopt the software. We introduce the notion of evolutionary Poisson stable equilibrium for the

game, and show its existence and uniqueness. Online algorithms are developed using the techniques of

stochastic approximation coupled with the population dynamics, and they are shown to converge to the

optimal solution of the controller problem. Numerical examples are used to illustrate and corroborate

our results.

I. INTRODUCTION

Emerging engineering applications such as social networks [1], crowdsourcing [2], [3] and the

Internet of Things (IoTs) [4] involve a large population of heterogeneous devices or users. These

agents interact with each other in a complex environment, in which each agent makes strategic

and dynamic decisions in response to the group of agents it interacts with. The group of agents

can be random and changing over time. One illustrative example is 5G wireless communication

networks [5]. Each mobile can communicate with a number of heterogeneous devices at different

times, and makes an investment decision on antivirus software. This situation is also analogous

to the epidemic spread of inﬂuenza in which individual person makes a decision on vaccination.

March 22, 2022

DRAFT

 
 
 
 
 
 
2

The objective from the perspective of the system designer or government agency is to control the

large population behaviors, and induce desirable outcome that is conducive for the sustainable

growth of the population. In order to address this issue, the ﬁrst step of this research is to establish

an integrated system framework that allows capturing the random, dynamic and heterogeneous

features of the population.

One useful tool to describe the dynamic evolution of population is evolutionary game theory

[6], [7], which often assumes homogeneous and pairwise interactions between agents. This under-

lying assumption makes the classical framework insufﬁcient to capture the network properties

of the agents, and the heterogeneous local interactions among the players. In this paper, we

develop an evolutionary Poisson game framework which bridges the gap between the evolutionary

game theory with the heterogeneity of the population. We enrich the game-theoretic model by

incorporating network topology, the size of the population, and the epidemic process to establish

a holistic framework that can be used to address the engineering applications of interest. These

unique aspects of the model lead to a customized evolutionary stability equilibrium concept, and

its corresponding replicator dynamics for describing the evolution of the population.

Fig. 1. Feedback system between controller and the evolutionary Poisson game model. Each circle represents a group of agents

who interact through a network. Each agent is denoted by its type. The controller observes the population states and controls

the population to achieve a global objective.

March 22, 2022

DRAFT

CONTROLLER	  TYPES	  Random	  number	  of	  individuals	  in	  each	  interac4on	  control	  equilibrium	  3

The overarching goal of this work is to control the behaviors of the large population to

achieve a system-wide objective. Building on the evolutionary Poisson game framework, we

leverage the techniques of stochastic approximation to develop an online learning algorithm.

Fig. 1 illustrates the interdependencies between the game-theoretic model and the controller.

The controller observes the population states and inputs a control to drive the system to a global

optimum.

The convergence analysis of the controller involves the understanding of the coupled dynamics

between the population and the learning algorithm. We show that the convergence is guaranteed

under time scale separation and mild conditions on the step sizes. In addition, we use virus

protection over a large-scale network as a motivating application to illustrate the link between

the game-theoretic model and the application. We fully characterize the global control of the virus

protection problem in network systems, and corroborate the results with numerical examples.

We observe a phenomenon of heterogeneity induced conﬁdence in which the protection rate

decreases as heterogeneity of the population exceeds a certain threshold.

A. Related Work

Large population behaviors have been investigated using models from evolutionary games

[6]–[9], Poisson games [10], [11], mean-ﬁeld games [12]–[14]. These models have successfully

captured different aspects of the large population. The evolutionary Poisson game developed

in this work integrates the features of evolutionary games and Poisson games to form a more

powerful framework to analyze and control systems with a large population of agents.

From the perspective of applications, the optimal protection problem and epidemics spreading

over networks has been recently investigated in [15]–[18]. The existing models are not sufﬁcient

yet to incorporate the topological information into a holistic epidemic and game model simul-

taneously. In this work, we aim to address this issue by proposing an integrated framework that

can be used to broaden the scope of the applications and capture more pertinent features of the

problem.

B. Organization of the Paper

The paper is organized as follows: In section II, we describe the system model, and we develop

in section III the evolutionary stable equilibrium concept and its associated replicator dynamics.

March 22, 2022

DRAFT

4

In Section IV, we present a global control problem, and we provide in section V explicit results

that completely characterize a class of virus protection problem. Finally, we conclude the paper

in section VI and discuses future work. Due to the page limit of the paper, we remove the proofs

of the results. The details of the proofs can be found in [19].

II. SYSTEM MODEL

In this section, we introduce the large population game model, and discuss an application of

epidemic protection in an heterogeneous population.

A. Random player game

Large scale interacting systems often involve a random number of interacting players. Poisson

game is a natural framework to capture this phenomenon [10], [11], which has been successfully

used to study decentralized resource allocation in networks [20], [21]. A Poisson Game Γ is

mathematically deﬁned by a ﬁve-tuple (λ, τ, r,C , u) where:

• λ corresponds to the mean number of players, typically λ >> 1,

• T is the set of types of players and each one belongs to one type t ∈ T ,

• The probability of a player being of type t is given by r(t), and the number of players of

type t is a Poisson random variable with parameter λr(t),

• C is the set of all pure actions available to all players,

• The utility of a player of type t is ut(a, x) with a is the pure action, and x is a vector of

size |C | where x(b) is the number of players who choose action b in C .

The expected utility of a player of type t who plays action a while the rest of the players are

expected to play using strategy σ is:

Ut(a, σ) = ∑
x∈Z(C )

P(x|σ)ut(a, x),

where Z(C ) denotes the set of elements w ∈ IRC such that w(c) is a non-negative integer for all
c ∈ C . The decomposition property of the Poisson distribution yield:

P(x|σ) = ∏
b∈C

e−λτ(b) (λτ(b))x(b)

x(b)!

,

τ(b) = ∑
t∈T

r(t)σt(b).

and

March 22, 2022

DRAFT

If players play according to the strategy σ, σt(c) is the probability that a player of type t chooses

the pure action c. Finally, the expected utility whether a player chooses action θ ∈ ∆(C ) is:

5

Deﬁnition 1: The strategy σ∗ is a pure Nash equilibrium if

Ut(θ, σ) = ∑
a∈C

θ(a)Ut(a, σ).

∀t ∈ T, σ∗ ∈ Bt(σ∗),

with

Bt(σ) = {b ∈ C : b ∈ arg min
a∈C

Ut(a, σ)}.

We can also extend this framework to the mixed-strategy Nash equilibrium by considering the

set of mixed best responses ∆(Bt(σ)).

B. Application to epidemic protection in heterogeneous population

Having deﬁned the non-cooperative game in the context of heterogeneous interacting randomly

individuals, we describe one application related to virus protection. Many recent work works have

ignored the topology of the interaction, the heterogeneity of the individuals or the selﬁshness

of their decision in their models. In this work, we develop a holistic framework that can

incorporate these features. We start by introducing the Susceptible-Infected-Susceptible (SIS)

epidemic model, which has been well-studied in the literature [22] and recently has gained lots

of interests for modeling computer viruses propagation [23], [24].

Consider an SIS epidemics over a graph, there exists a limiting spreading factor rate, denoted

by the critical epidemic threshold, below which the infection vanishes exponentially fast in time,

and above which the critical threshold the network stays infected. In an in-homogeneous SIS

epidemics, we can express the epidemic threshold of an individual effective spreading rate τi of

each node i. Indeed, it is has been shown in [25] that by using a mean-ﬁeld approximation of

the Markov process model for the epidemic, for the complete graph structure with N nodes, the

critical threshold thus satisﬁes the following relation:

1
1 + τc
i
The contamination process of our SIS epidemic is a Poisson variable with rate β but our spreading

= N − 1.

N
∑
i=1

framework is in-homogeneous as we consider that each node of type t has a recovery process

with rate δt.

March 22, 2022

DRAFT

6

Our framework is enough generic such that its can be applied to the control of large complex

systems, such as virus spreading [23] and information cascading [26]. In order to illustrate our

framework, we describe in the next section, our model for the controlled of an in-homogeneous

SIS over a large population in which the interaction structure is stochastic.

We consider an individual protection strategic game where each player has a type, or private

information which determines his recovery capability (e.g. the rate of recovery), and incomplete
information (e.g. nodes are not aware of the number of players they interact with 1).

The set of pure actions of the players is C = {OFF, ON}, and the set Z(C ) = IN2. Players
are characterized by their recovery rate δt which depends on their type t. Then, the effective
spreading rate for each type t player is τt = β
δt
threshold for the heterogeneous SIS in a complete graph, we obtain a following necessary and

. Based on the expression of the critical epidemic

sufﬁcient condition over the effective spreading rates τt and the number of nodes xt of type t

that do not invest, in order for the infection to propagate in a complete graph:

This inequality is equivalent to the linear constraint:

T
∑
t=1

xt
1 + τt

≤

T
∑
t

xt − 1.

T
∑
t=1

xtτt
1 + τt

≥ 1.

(1)

(2)

Depending on the decision of each player, if the infection is propagated over the entire network,

then the cost for a player that does not protect itself is K, otherwise its cost is 0. This cost

may represent the restoring cost when a node is contaminated, or also this cost can be a penalty

proposed by the system designer in order to control self-protection behavior. Then, the utility

of a player of type t is given by:

ut(OFF, (x1, . . . , xT )) =




K if ∑T

t=1

xt τt
1+τt

≥ 1,



0

otherwise.

In our framework, the type-t utility function is not deﬁned over the set Z(C ) as in [11] but as

follows:

ut : C × Z(C ) × . . . × Z(C )
(cid:125)

(cid:124)

(cid:123)(cid:122)
×T

→ IR.

1Each local interaction has a random number of players which follows a Poisson process with an average population equal

to λ(λ >> 1), i.e., most of the interactions that occur in the population involve a large number of interacting users.

March 22, 2022

DRAFT

7

In fact, the utility function in a Poisson game should depend on the total number of players

choosing the same action over different types. In the model, we do not have such aggregative

assumption in the utility, and the type as an impact on the utility function. For the same number

of individuals that do not invest, i.e., take the action OFF, the utility of a player depends on

the number of such individuals of each type. We then use the concept of random player game

model proposed in [27], which is a generalization of Poisson games. In fact, games with a

random number of players are a natural extension of Bayesian games, which are a class of

incomplete information games [28].

We denote by Xt the random variable which determines the number of players of type t that

do not invest. Based on the decomposition property of the Poisson distribution, Xt is a Poisson

distribution with parameter λr(t)σt(OFF). Then, the total number of players that do not invest

is a Poisson distribution with parameter λ ∑t r(t)σt(OFF). If a node decides to be protected, he
pays a cost C, i.e.,

ut(ON, (x1, . . . , xT )) = C.

Note that the utility functions do not depend on the type t of the user 2. We consider a

symmetric Nash Equilibrium. Denote by p the probability that a player (of any type) chooses

action OFF, i.e., for all types t = 1, . . . , T , σt(OFF) = p and σt(ON) = 1 − p. The expected

utility of a player who plays pure action OFF while all other players are expected to play

according to a mixed strategy p depends on the realization vector x = (x1, x2, . . . , xT ) of the

random vector X = (X1, . . . , XT ) by:

Ut(OFF, p) = ∑
x∈INT

P(X = x|p)ut(OFF, x) := U(OFF, p).

Based on the decomposition and aggregation properties of the Poisson distribution, we arrive at

P(X = x|p) =

T
∏
t=1

P(Xt = xt|p) =

T
∏
t=1

(λr(t)p)xt
xt!

e−λr(t)p.

Then, the expected utility of a player that does not invest in protection, in face of a population

2A similar analysis can be done for the case of type-dependent equilibrium ( [29]).

March 22, 2022

DRAFT

proﬁle p is given by:

8

P(X = x|p)u(OFF, x)

U(OFF, p) = ∑
x∈INT

 ∑
x:∑T

= K

xt τt
1+τt

t=1



P(X = x|p)



≥1

= K

= K

= K


1 − ∑
x:∑T

t=1

xt τt
1+τt


1 − ∑
x:∑T

t=1

xt τt
1+τt



P(X = x|p)



<1

T
∏
t=1

<1



P(Xt = xt |p)




1 − e−λp ∑

x:∑T

t=1

xt τt
1+τt

(λp)∑T

t=1 xt

<1



 .

T
∏
t=1

r(t)xt
xt !

Finally, the expected utility from playing action q ∈ ∆(C ) is given by:

U(q, p) = qU(OFF, p) + (1 − q)C.

Based on Deﬁnition 1, a (symmetric) mixed Nash Equilibrium p∗ for the protection game with

a random number of player satisﬁes:

∀q (cid:54)= p∗, U(p∗, p∗) ≤ U(q, p∗).

Lemma 1: If C ≥ K, then the pure Nash equilibrium is p∗ = 1.

Proof: The proof of this lemma follows the intuition that if the cost for being protected C

is higher than the cost of being infected K, then every user will take the risk to be infected.

Indeed, if it is, the cost injured is less or equal to the cost if it was protected. Mathematically

speaking, for any population proﬁle p the utility of an individual to be protected is C and we

have that:

U(OFF, p) = K

Then if we have C ≥ K, then:


 ∑
x:∑T

t=1

xt τt
1+τt



P(X = x|p)

 < K.

≥1

∀p, U(OFF, p) < U(ON, p).

Thus the strategy OFF is a dominant strategy and all individuals play this action at equilibrium.

March 22, 2022

DRAFT

We next state the proposition that describes the mixed equilibrium.

Proposition 1 (Existence and Uniqueness): If the parameters of the system λ, C, K (with

C < K), T , the type distribution r(·) and the effective spreading rates τt satisfy the following

9

condition:

T
∏
t=1

∑
x

(λr(t))xt
xt!

< (1 −

C
K

)eλ.

Then, there exists one unique mixed Nash equilibrium.
Proof: A mixed Nash equilibrium p∗ satisﬁes:

∀q (cid:54)= p∗, U(p∗, p∗) ≤ U(q, p∗),

which is equivalent to:

p∗ ∈ arg max

p

U(p, p∗) = arg max

p

(pU(OFF, p∗) + (1 − p)C).

Then, we study the solution ˜p of the equation:

K

which is equivalent to:


1 − e−λp ∑

x:∑T

t=1

xt τt
1+τt

(λp)∑T

t=1 xt

<1



 = C,

T
∏
t=1

r(t)xt
xt!

F(p) := ∑

x:∑T

t=1

xt τt
1+τt

(λp)∑T

t=1 xt

<1

T
∏
t=1

r(t)xt
xt!

= (1 −

C
K

)eλp := G(p).

(3)

Note that both functions are continuous, strictly increasing over the interval [0, 1] and also we

have:

G(0) = (1 −

C
K

) < 1 = F(0).

The function G(.) is strictly convex over the interval [0, 1]. Also the same for the function F(.)

which is a ﬁnite sum of strictly convex functions and then it is a strictly convex function over the

interval [0, 1]. Then, if we assume that F(1) < G(1) there exists almost one solution of equation

(3) inside the interval ]0, 1[. More as the left-hand side function is a polynom and the right-hand

side an exponential, this equation, if it has a solution over [0, 1], this solution is unique.

We have proved the existence and uniqueness of the equilibrium depending on the parameters

of the problem. Based on simple geometric argument, as function F and G are continuous over
the interval [0, 1], we can show that the equilibrium p∗ is strictly decreasing in C (i.e., more

expensive is the protection, less individuals will adapt the strategy OFF.), and it also is strictly

March 22, 2022

DRAFT

10

decreasing with λ (i.e., the average number of individuals in each local interaction). Indeed,

having more people in average at each interaction makes individuals more vulnerable, and then

the protection rate (i.e., proportion of individuals protected) becomes higher at the equilibrium. A

last important remark from the previous proposition is that the strategy ON cannot be a dominant

strategy for any values of the parameters of the model. In fact, F(0) > G(0), and there is always

a proportion of individuals that are not protected.

III. EVOLUTIONARY STABILITY AND DYNAMICS

Another equilibrium concept, which is more robust than the Nash equilibrium and well

adapted to large population games is called Evolutionary Stable Strategies (ESS). It is based

on evolutionary principles that have been originally deﬁned in [30] in biology, and recently

applied to engineering and systems [9]. In this section, we will introduce the concept of ESS

and its associated dynamics.

A. Evolutionary stability concept

ESS is a strategy such that, if adopted by all the players, is robust against deviations of a

(possibly small) fraction of the population. From a biological point of view, it can be seen as a

generalization of Darwin’s idea of survival of the ﬁttest, while from a game theory perspective,

it is a reﬁnement of the Nash Equilibrium, which satisﬁes a stability property.

It is important to note that a mixed strategy p can be also interpreted as the set of distributions

of pure strategies among the players [6]. In our setting, the mixed strategy p can describe,

assuming that each player plays a pure action in C , the proportion of players that choose the

action OFF. This is also called the strategy proﬁle of the population. Having this equivalent

point of view of the game in mind, an ESS, if adopted by the whole population, is resistant

against mutations of a small fraction of individuals in the population. Suppose that the whole

population adopts a strategy q, and that a fraction ε of mutants deviate to strategy p. Strategy q

is an ESS if ∀p (cid:54)= q, there exists some εp > 0 such that ∀ε ∈ (0, εp):

U(q, εp + (1 − ε)q) < U(p, εp + (1 − ε)q).

(4)

In other words, this strict inequality says that an ESS defeats any small mutations (relative to ε)

of the population proﬁle. In that sense, the equilibrium concept of ESS is said to be more robust

March 22, 2022

DRAFT

11

than the Nash Equilibrium, because it is robust against the deviation of a fraction of players,

and not only one.

Another approach to study the evolutionary stability of an equilibrium is to consider the

dynamics of the strategies inside the population. When the utility function is bilinear, this strict

inequality condition can be replaced by two simple conditions: Nash condition and stability

conditions. This type of analysis which makes the game as a standard evolutionary game that has

been proposed in [9] to analyze the evolutionary stability with a random number of individuals

at each interaction. But in our setting, the utility function is clearly not bilinear and then we

cannot use the Nash and stability conditions instead of equation (4).

B. Dynamics

Another way to describe how a population reaches a stable situation is through the replicator

dynamics, which serves to highlight the role of selection from a dynamic perspective. It is

formalized by a system of ordinary differential equations, and it establishes that the evolution

of the size of the populations depends on the ﬁtness they achieve during interactions. A strategy

will sustain if its ﬁtness is higher than the ﬁtness averaged over all the strategies used in the

whole population. The folk theorem of evolutionary games allows to establish a strict connection

between the stable points of the Replicator Dynamics and the Nash Equilibria [8].

In our context, the RD equation can be formalized as follows:

˙p(t) = p(t) [U(p(t), p(t)) −U(OFF, p(t))] ,

= p(t)(1 − p(t))[U(ON, p(t)) −U(OFF, p(t))],

= p(t)(1 − p(t))[C −U(OFF, p(t))].

(5)

We have the results from the folk theorem of the replicator dynamics in population games

that an interior rest point of the dynamics is a Nash equilibrium of our game. Then, we have

another method to describe the equilibrium, as a rest point of a dynamical system. This provides

a very important insight for a global control of the system. We will see in the next section, that

this approach gives us the possibility to determine a two time-scale process to optimize a global

performance of the system without computing explicitly the Nash equilibrium. Moreover, we

prove in the next proposition that any rest point of our dynamics is not only a Nash equilibrium

but also an ESS. In our setting, we have the following result.

March 22, 2022

DRAFT

12

Proposition 2: If our game has a unique mixed equilibrium p∗, then it is an ESS and it

corresponds to the unique interior rest point of the ODE (5).

Proof: Based on proposition (1), we ﬁrst assume that the parameters of the system are such
that there exists a mixed nash equiliiubrm p∗ and we have proved that then it is unique. More,

this equilibrium is the unique exterior rest point of the replicator dynamics:

˙p(t) = p(t)(1 − p(t))[C −U(OFF, p(t))].

We have that U(OFF, p∗) = C. In order to prove that p∗ is an ESS, we choose another mixed
strategy q adopted by a proportion ε of individuals. Then, based on equation (4), p∗ is an ESS

if the exists an εq such that ∀ε ∈ (0, εq), we have:

U(p∗, εq + (1 − ε)p∗) < U(q, εq + (1 − ε)p∗).

In fact, we prove this inequality for εq = 1. Let ﬁrst assume w.l.o.g. that 0 < q < p∗. A similar
analysis can be done for the case when 1 > q > p∗. We ﬁxed ε ∈ (0, 1) and we denote pε =
εq + (1 − ε)p∗. Note that q ≤ pε < p∗ (if ε = 0 there is no mutant, so it is not an interesting
case). After some simple algebraic decompositions, we have the following equivalence:

U(p∗, εq + (1 − ε)p∗) < U(q, εq + (1 − ε)p∗),

rewriting as:

is equivalent to

U(p∗, pε) < U(q, pε),

(p∗ − q)(U(OFF, pε) −C) < 0.

As the mixed equilibrium p∗ is unique and is the unique interior rest point of the replicator
dynamics, for all p < p∗ (resp. p > p∗) we have that ˙p(t) > 0 (resp. ˙p(t) < 0). We have that
pε < p∗ and then ˙pε(t) > 0 which, based on the replicator dynamics o.d.e. (5), means that for
any time t:

C −U(OFF, pε(t)) > 0 ⇐⇒ C > U(OFF, pε(t)).

Finally, as it is try for any time t, it is also true for any value pε such that q ≤ pε < p∗ and then:

(p∗ − q)(U(OFF, pε) −C) < 0,

which proves that p∗ is an ESS.

March 22, 2022

DRAFT

The discrete-time version of the replicator dynamics is described as follows:

pn+1 = pn + b(n)pn(1 − pn)[C −U(OFF, pn)].

Let timescale parameter b(n) be

13

(6)

∑
n

b(n) = ∞ and ∑
n

b(n)2 < ∞,

then, as n tends to inﬁnity, the discrete-time iteration (6) is an approximation of the replicator

dynamics ODE given by (5).

IV. ONLINE GLOBAL CONTROL

The overarching goal of this work is to design a global control for the entire heterogeneous,

stochastic interacting population. As an example of global objective function for the controller

(see Fig. 1), we consider in this section the global revenue. Moreover, we propose an online

learning process as we assume that the infected cost K is not known by the controller. This

parameter is highly related to how individuals evaluate the cost of being infected, or by deﬁnition,

it is difﬁcult to estimate it correctly. We then propose an online learning algorithm so that a

controller can optimize a global function of the equilibrium population without knowing this

parameter. We use the average revenue as a global function given by

R(C) = λ(1 − p∗(C))C,

where p∗(C) is the equilibrium considering the control parameter C. Its goal is to maximize this
function depending on the price C. Based on simulations, we observe that the equilibrium p∗

depends on the cost C as an S-shaped function, concave and strictly convex. Particularly, for
C high enough, i.e., C > K
2 , the equilibrium is strictly convex in C. Then, there exists a price
C0 such that for all C > C0, the function p∗(C) is strictly convex. Then, we have the following

lemma.

Lemma 2: The revenue R(C) of the provider is strictly concave for C ∈ [C0, K].

Proof: We have that R(C) = λ(1 − p∗(C))C. We take the two time derivatives and then:

R(cid:48)(C) = −λp∗(C) − λC

d p∗
dC

(C),

R(cid:48)(cid:48)(C) = −2λ

d p∗
dC

(C) − λC

d2 p∗
dC2 (C) < 0,

and

March 22, 2022

DRAFT

14

because the equilibrium is strictly increasing with C and it is strictly convex over the interval

[C0,C]. Then the revenue of the provider is strictly concave over the interval [C0,C].

Based on this result, a gradient algorithm can be used to converge to then optimal price C∗ that

maximized the revenue of the provider. In fact, we have existence and uniqueness of an optimal

price. Designing a gradient algorithm in our context needs to estimate the gradient function of

the revenue because there is no closed form expression of the equilibrium function. We then

propose to use the following Simultaneous Perturbation Stochastic Approximation (SPSA) [31]:
(cid:18)R(C + δ∆) − R(C)
δ∆

dR
dC

(C) ∼

(7)

(cid:19)

,

where ∆ is a random variable such that IP(∆ = 1) = IP(∆ = −1) = 1

2 , and δ is a small constant.
One sample form of this approximation is proposed in [32]. However, it has been observed that

this single form introduces signiﬁcant bias, so that in general the two-sample form, given by

equation (7), is considered.

Since the equilibrium of the population game is characterized by the rest-point of the replicator

dynamic given by equation (5), the controller can set a new price (C +δ∆) to optimize his revenue,

and wait for convergence of the replicator dynamics to the equilibrium. Therefore, by observing

the equilibrium, the controller has an estimation of its new revenue and also of the gradient of

his revenue.

Given that for a ﬁxed price C the replicator dynamics has a global asymptotically stable
equilibrium p∗(C), our algorithm converges to the optimal price. Considering a starting price

C0, we then consider the following approximate gradient descent algorithm:
(cid:18) ˜R(Cn + δ∆n) − ˜R(Cn)
δ∆n

∀n = 0, 1, . . . , Cn+1 = Cn + a(n)

(cid:19)

,

= Cn + a(n) f (Cn, ∆n),

where a(n) is the update step size, a discrete random variable ∆n at each step n such that
IP(∆n = 1) = IP(∆n = −1) = 1

2, and

˜R(Cn) = λ(1 − ˜p(Cn))Cn.

We can then deﬁne for all n the following functions:

h(Cn) := IE[ f (Cn, ∆1)],

March 22, 2022

DRAFT

15

and

Mn+1 := f (Cn, ∆n+1) − h(Cn).

Then, the approximate stochastic gradient descent can be written as:

Cn+1 = Cn + a(n)[h(Cn) + Mn+1],

where Mn is a martingale difference sequence. The update step-size parameter a(n) has to

be efﬁciently designed in order to guarantee the convergence to the global optimal solution.

Indeed, the control update has to wait for the convergence of the replicator dynamics to the

equilibrium. Therefore, there is a relation between the speeds of the two dynamical processes.
For a ﬁxed C, the equilibrium p∗(C) is a global attractor, which is also a global asymptotically

stable equilibrium of the replicator dynamics. Indeed, the SPSA is coupled with the replicator

dynamics.Let ε be a positive constant, and the replicator equation is rewritten as

˙p(t) =

1
ε

p(t)(1 − p(t))[C −U(OFF, p(t))].

(8)

By having ε small enough, the SPSA views the replicator dynamics as quasi-equilibrated while

the replicator dynamics views the SPSA as quasi-static. Then, we can prove the convergence

of our SPSA by viewing the underlying replicator dynamics as a two timescale dynamical

system. For a sufﬁcient relative speed of convergence of the replicator dynamics compared to

the stochastic gradient descent, we can prove that our algorithm converges to the price that

optimizes the global objective function. The step size of strategy update of the population is

1
n in discrete time. Then, we have the following proposition that yields the conditions on the
step-size update of the gradient algorithm for reaching the optimal solution.

Proposition 3: If we have the following conditions:

∑
n

a(n) = ∞, ∑
n

a(n)2 < ∞ and

1
na(n)

→ 0,

then Cn → C∗, a.s.

Proof: On one side, the approximate gradient descent algorithm follows:

∀n = 0, 1, 2, . . . , Cn+1 = Cn + a(n)(

˜R(Cn + δ∆n) − ˜R(Cn)
δ∆n

),

where the reward depends on the equilibrium as ˜R(Cn) = λ(1 − ˜p(Cn))Cn and a(n) is the step

size of the updating rule. On the other side, the replicator dynamics given by equation (5) is

March 22, 2022

DRAFT

16

the limit of a discrete time iteration with an update stepsize 1/n. Then, the two discrete time

iterations are coupled like in [33]. Then, in order to have the convergence of the coupled iteration

processes, we need the following conditions:

1) supn(||Cn||) < ∞, a.s.,

2) for ﬁxed C, the replicator dynamics o.d.e has a globally asymptotically stable equilibrium

p∗(C),

3) the o.d.e limit of the approximate gradient algorithm has a globally asymptotically stable

equilibrium when replacing the equilibrium by p∗(C),

4)

∑
n

a(n) = ∞, ∑
n

a(n)2 < ∞ and

1
na(n)

→ 0,

The ﬁrst point is veriﬁed as if C > K then p∗ = 1, thus we have that for all n, ||Cn|| < K and

then ||R(Cn)|| < λK. Thus we have:

||Cn+1|| = ||Cn +

1
n

(

˜R(Cn + δ∆n) − ˜R(Cn)
δ∆n

)||,

< ||Cn|| + ||

< ||Cn|| +

(

˜R(Cn + δ∆n) − ˜R(Cn)
1
n
δ∆n
|| ˜R(Cn + δ∆n)|| + || ˜R(Cn)||
δ

,

)||,

< K(1 +

2λ
δ

) < ∞

and then supn(||Cn||) < ∞. The second point is veriﬁed as the replicator dynamics rest point,

for a ﬁxed C, is an interior ESS in our case and then a global globally asymptotically stable

equilibrium (see [7]-Theorem 7). Based on the strict concavity of the revenue function proved in

lemma 2, this function has a unique maximizer, and then the o.d.e limit of the stochastic gradient

has a global globally asymptotically stable equilibrium. This proves the third point. Finally, we

assume that

∑
n

a(n) = ∞, ∑
n

a(n)2 < ∞ and

1
na(n)

→ 0,

which implies that the gradient update moves on the slower timescale than the replicator dynam-

ics. Thus we have the convergence almost surely of our approximate gradient descent algorithm
given by equation (8) to the optimal price, i.e. Cn → C∗

a.s..

The last proposition provides conditions on the time scale of the gradient algorithm to ensure

that the coupled algorithm converges to the optimal solution of the global control problem.

March 22, 2022

DRAFT

17

V. COMPLETE CHARACTERIZATION OF THE VIRUS PROTECTION GLOBAL CONTROL

PROBLEM

In this section, we ﬁrst provide a complete characterization of the solutions to the global control

problem for the population of one single type. Second, we show the impact of heterogeneity

and randomness of our system on the equilibrium results and the global control problem.

A. Population with Single Type

Consider a fully connected network of size N, and all the players are of the same type. Hence

τi = τ and the value of the epidemic threshold τc is exactly equal to inverse of the largest

eigenvalue, i.e. the spectral radius, λ1 of the adjacency matrix [18]. In particular, we arrive at

τc(x) =

1
x − 1

,

where x > 1 is the number of nodes that do not invest. The special cases where x = 1 and x = 0

are not representative of our problem since there is no propagation effects in these two cases.

The utility function for a node that does not invest can be simpliﬁed into

ut(OFF, x) =




K if

x ≥ 1 + 1
τ ,



0

otherwise.

The value x is not known by every node, but it follows a Poisson distribution with rate λ. We

denote by ˜p the solution to the following equation

(cid:98) δ
β (cid:99)
∑
k=0

(λ ˜p)k
k!

(cid:18)

=

1 −

(cid:19)

C
K

eλ ˜p.

The strategy OFF is dominant if K ≤ C as stated in Lemma (1). Next, we investigate the case
where K > C. Note that if the effective spreading rate is sufﬁciently large, i.e., τ = β

δ > 1, then,

we can ﬁnd the equilibrium given by:

p∗ =

1
λ

log

(cid:18) K

K −C

(cid:19)

.

This solution is not 0 since there is a very small probability that an individual is not infected.

However, this value becomes close to 0 as λ increases.

Proposition 4: If the effective spreading rate is high enough but not too much, i.e. 1/2 < τ ≤ 1,

then we have the unique equilibrium given by:
(cid:18)

(cid:20)

p∗ = −

1 +W

−e−1

1
λ

(cid:18)

1 −

C
K

(cid:19)(cid:19)(cid:21)

,

March 22, 2022

DRAFT

with W (x) is known as the Lambert W function and deﬁned such that x = W (x)eW (x).

Proof: Assuming that 1/2 < τ ≤ 1 implies that (cid:98) δ

β(cid:99) = 1 and then the mixed equilibrium is

solution bet ween the interval [0, 1] of the following equation:

18

This equation is equivalent to:

1 + λp = (1 −

C
K

)eλp.

eλp =

λ
1 − C
K

(p +

1
λ

).

This equation is the following transcendental algebraic equation:

e−cp = a0(p − r),

with the following constants:

c = −λ,

a0 =

λ
1 − C
K

,

and r = −

1
λ

.

Then the solution is given by:

which gives:

p∗ = r +

1
c

LambertW (

ce−cr
a0

),

p∗ = −

= −

1
λ
1
λ

−

1
λ

LambertW (

−λe−1(1 − C
K )
λ

),

[1 + LambertW (−e−1(1 −

C
K

))].

In the case where τ ≤ 1/2, we have the following description of the equilibrium p∗:

p∗ =




˜p



1

if (1 − C

K )eλ ≤ ∑

(cid:98) δ
β (cid:99)
k=0

(λ)k
k! ,

(9)

otherwise.

The solution ˜p is in fact the solution of the so-called Generalized Lambert W function [34]:

e−cx =

PN(x)
QM(x)

,

where c > 0 is a constant and PN(x) and QM(x) are polynomials in x of respectively orders N

and M. Though this equation cannot be solved in its general form (approximations are possible

for simple cases [35]), it embodies an interesting link between gravity theory and quantum

mechanics [36].

March 22, 2022

DRAFT

19

B. Population with Multiple Types

We consider 2 types of individuals in a population, i.e., T = 2. We then have r(1) := r (i.e.,

the proportion of type-1 individuals in the population) and r(2) := 1 − r (i.e., the proportion of

type-2 individuals). Individuals from each type differ in their capacity (e.g. recovery rate τ) to

recover from the virus. We let τ1 < τ2, which means that δ1 > δ2, i.e., type-1 individuals are

more resilient to the virus and it takes generally less time for them to react and then to recover.

Fig. 2.

Proportion of individuals protected inside the population at equilibrium depending on the average number of nodes

λ in the graph and two types of individuals with varying the heterogeneity of the population. The parameters are: τ1 = 0.05,

τ2 = 0.2, C = 4 and K = 5.

1) Equilibrium Paradox: When r is close to 0 (resp. 1), i.e., only type-2 (resp. type-1)

individuals form the population, we observe in Fig. 2 the impact of both heterogeneity parameters

λ and the type distribution r(·) on the equilibrium. Speciﬁcally, for the reason of convenience, we

show the percentage of people protecting themselves (i.e., the protection rate) which corresponds
to 1 − p∗. We can observe that the average number of interacting individuals, which is equal to

λ, has a positive impact on the protection rate inside the population. For the same heterogeneity

type given by a distribution r(·), the protection rate is strictly increasing with λ. It is obvious

that, when each individual interacts with more individuals in average, it makes individuals more

March 22, 2022

DRAFT

0.10.20.30.40.50.60.70.80.91−0.100.10.20.30.40.50.60.70.80.9rprotection rate  λ=2λ=10λ=20λ=30λ=50fully type−2 fully type−1 20

Fig. 3. Proportion of individuals protected inside the population at equilibrium depending on the proportion r of the two types

of individuals varying the heterogeneity of the population. The parameters are: λ = 30, τ2 = 0.2, C = 4 and K = 5.

Fig. 4. Convergence of the replicator dynamics to the Nash equilibrium with 2 types of individuals and the following parameters:

τ1 = 0.05, τ2 = 0.2, C = 4, r = 0.1 and K = 5.. We consider two initial points: p(0) = 0.3 and p(0) = 0.7.

March 22, 2022

DRAFT

0.10.20.30.40.50.60.70.80.910.20.30.40.50.60.70.8rprotection rate in the population  τ1=0.1τ1=0.0501234567800.20.40.60.81timeequilibriumλ=2, p*=1λ=10, p*=0.87λ=20, p*=0.4421

Fig. 5. Revenue of the provider depending on the price C with the following parameters τ1 = 0.5, τ2 = 0.98, K = 10, r(1) = 0.3

and λ = 10.

vulnerable to the contagion, and then requires a higher level of protection. Comparing λ = 2 (e.g.

a population with mostly pairwise interactions as in standard evolutionary game framework) and

λ = 10, we can observe that the protection rate is strictly higher only when the proportion of type-

2 individuals is higher than around 80%. This means that under this threshold type proportion,

individuals do not feel in a risky environment even if the number of interacting individuals is

large (i.e., λ = 10). When λ becomes even larger another interesting property arises. From Fig. 2,

we can observe that, for parameter λ = 20, the impact of the heterogeneity type is signiﬁcant. By

increasing the heterogeneity from r = 0 (only type-2 individuals), the protection rate decreases.

In fact, increasing the heterogeneity in our scenario means that we reduce the proportion of

type-2 individuals meanwhile increasing the proportion of type-1 individuals.

As we further increase the value r, the phenomenon of heterogeneity induced conﬁdence

principle arises. A highly heterogeneous population leads to a decreasing the protection rate as

the heterogeneity reaches the percentage value around 20 % of type-2. Moreover, this threshold

seems be independent of the average number of individuals in each local interaction.

We can explain this counter-intuitive outcome by considering the particular case with λ = 30

March 22, 2022

DRAFT

01234567891005101520253035404550CRevenueC*22

and with two different effective spreading rate for type-1 individuals. This scenario is depicted

on Fig. 3. Here, we can observe that the behavior of the protection rate is as expected, always

decreasing when increasing the proportion of type-2 individuals. This is obtained when the effec-

tive spreading rate of type-1 individuals is equals to 0.1. In the other case, when τ1 = 0.05 even

if more type-2 individuals are in the population, the global protection rate is decreasing as more

heterogeneity is introduced. Individuals behave more conﬁdently and protect less themselves.

2) Convergence of the Replicator Dynamics: In Fig. 4, the replicator dynamics equation is

illustrated for two different starting points and also for different values of the average interaction

size λ. This result conﬁrms the convergence of the ODE to the equilibrium and also that the

equilibrium is decreasing with the parameter λ. In fact, the protection rate is by deﬁnition the
proportion of individuals that are protected, i.e., 1 − p∗. Then, we can observe on Fig. 2 that

for r = 0.1 and λ = 10, the protection rate of the population is 0.13, which corresponds to the

rest point of the replicator dynamics in long dashed line. This result is corroborated for the

case where λ = 20 and the protection rate is then 0.56, we obtain that the replicator dynamics

converge to 0.44.

3) Global optimization and learning algorithm: Finally, we illustrate the global control design

problem. We ﬁrst describe in Fig. 5 the global revenue for the controller as a function of his

control parameter, and observe the strict concavity property.

We show in Fig. 6 the result of our learning mechanism for several control updates with step

1

size a(n) =

n2 , respectively. The ﬁrst control update satisﬁes the
conditions in Proposition 3. We can observe that for this control update, our learning algorithm

1+n log(n), a(n) = 1

n and a(n) = 1

converges to the optimal control, whereas the two other control updates do not. The last control
update a(n) = 1

n2 gives a too fast update of the control and ﬁnally converges to the control value
which is far from the optimal one, and therefore, the revenue at this value is far from the optimal

revenue.

VI. CONCLUSION

In this paper, we have ﬁrst described a framework of large population game with heteroge-

neous types of individuals, in which local interactions involve a random number of individuals

of different types. We have developed the concept of evolutionary stability equilibrium as a

solution that characterizes the game behavior. A decentralized virus protection problem has

March 22, 2022

DRAFT

23

Fig. 6. Convergence of our learning algorithm with the SPSA to the optimal price with δ1 = 10, δ2 = 5.1, β = 5, K = 10,

r(1) = 0.3 and λ = 10.

been used to motivate and illustrate this framework. In order to achieve desirable outcome of

the game, we have developed methodologies to design a global controller for this dynamic

heterogeneous population game. In particular, the interdependency between the global control

and the population behaviors has been analyzed using coupled dynamics between approximate

stochastic gradient algorithms with the replicator dynamics. We have shown the convergence of

our learning algorithm, and provided numerical illustrations to demonstrate the impact of the

heterogeneity on the outcome of the system. As a future work, we would lift the assumption

of Poisson distribution on the population, and investigate the data-driven reinforcement learning

type of algorithms for as a global controller.

REFERENCES

[1] M. O. Jackson et al., Social and economic networks, vol. 3. Princeton University Press Princeton, 2008.

[2] A. Kittur, E. H. Chi, and B. Suh, “Crowdsourcing user studies with mechanical turk,” in Proceedings of the SIGCHI

conference on human factors in computing systems, pp. 453–456, ACM, 2008.

[3] J. Howe, “The rise of crowdsourcing,” Wired magazine, vol. 14, no. 6, pp. 1–4, 2006.

[4] L. Atzori, A. Iera, and G. Morabito, “The internet of things: A survey,” Computer networks, vol. 54, no. 15, pp. 2787–2805,

2010.

March 22, 2022

DRAFT

2040608010012014055.566.577.58iterationsC  5101520253035407.47.57.67.77.87.98iterationsCC*=7.8527a(n)=1/(nlog(n))a(n)=1/na(n)=1/n224

[5] S. Ohmori, Y. Yamao, and N. Nakajima, “The future generations of mobile communications based on broadband access

technologies,” Communications Magazine, IEEE, vol. 38, no. 12, pp. 134–142, 2000.

[6] J. Hofbauer and K. Sigmund, Evolutionary games and population dynamics. Cambridge University Press, 1998.

[7] J. Hofbauer and K. Sigmund, “Evolutionary game dynamics,” Bulletin of the American Mathematical Society, vol. 40,

no. 4, pp. 479–519, 2003.

[8] J. Hofbauer, P. Schuster, and K. Sigmund, “A note on evolutionary stable strategies and game dynamics,” Journal of

Theoretical Biology, vol. 81, no. 3, pp. 609–612, 1979.

[9] H. Tembine, E. Altman, R. El-Azouzi, and Y. Hayel, “Evolutionary games with random number of interacting players

applied to access control,” in Modeling and Optimization in Mobile, Ad Hoc, and Wireless Networks and Workshops, 2008.

WiOPT 2008. 6th International Symposium on, pp. 344–351, IEEE, 2008.

[10] R. B. Myerson, “Large poisson games,” Journal of Economic Theory, vol. 94, no. 1, pp. 7–45, 2000.

[11] R. B. Myerson, “Population uncertainty and poisson games,” International Journal of Game Theory, vol. 27, no. 3,

pp. 375–392, 1998.

[12] J.-M. Lasry and P.-L. Lions, “Mean ﬁeld games,” Japanese Journal of Mathematics, vol. 2, no. 1, pp. 229–260, 2007.

[13] H. Tembine, Q. Zhu, and T. Bas¸ar, “Risk-sensitive mean-ﬁeld games,” Automatic Control, IEEE Transactions on, 2013.

[14] Q. Zhu, H. Tembine, and T. Bas¸ar, “Hybrid risk-sensitive mean-ﬁeld stochastic differential games with application to

molecular biology,” in Proc. of 50th IEEE Conference on Decision and Control and European Control Conference (CDC-

ECC), pp. 4491–4497, Dec 2011.

[15] L. Jiang, V. Anantharam, and J. Walrand, “How bad are selﬁsh investments in network security?,” Networking, IEEE/ACM

Transactions on, vol. 19, no. 2, pp. 549–560, 2011.

[16] S. Saha, A. Adiga, and A. K. S. Vullikanti, “Equilibria in epidemic containment games,” in Twenty-Eighth AAAI Conference

on Artiﬁcial Intelligence, 2014.

[17] G. Theodorakopoulos, J.-Y. Le Boudec, and J. S. Baras, “Selﬁsh response to epidemic propagation,” Automatic Control,

IEEE Transactions on, vol. 58, no. 2, pp. 363–376, 2013.

[18] P. Van Mieghem, J. Omic, and R. Kooij, “Virus spread in networks,” Networking, IEEE/ACM Transactions on, vol. 17,

no. 1, pp. 1–14, 2009.

[19] Y. Hayel and Q. Zhu, “Evolutionary poisson games for controlling large population behaviors,” CoRR, 2015.

[20] O. Filio-Rodriguez, S. Primak, V. Kontorovich, and A. Shami, “A game theory interpretation for multiple access in cognitive

radio networks with random number of secondary users,” CoRR, vol. abs/1305.5222, 2013.

[21] E. Simhon and D. Starobinski, “Advance reservation games and the price of conservatism,” ACM SIGMETRICS Performance

Evaluation Review, vol. 42, no. 3, pp. 33–33, 2014.

[22] N. T. Bailey et al., The mathematical theory of infectious diseases and its applications. Charles Grifﬁn & Company Ltd,

5a Crendon Street, High Wycombe, Bucks HP13 6LE., 1975.

[23] B. A. Prakash, H. Tong, N. Valler, M. Faloutsos, and C. Faloutsos, “Virus propagation on time-varying networks: Theory

and immunization algorithms,” in Machine Learning and Knowledge Discovery in Databases, pp. 99–114, Springer, 2010.

[24] J. O. Kephart and S. R. White, “Directed-graph epidemiological models of computer viruses,” in Research in Security and

Privacy, 1991. Proceedings., 1991 IEEE Computer Society Symposium on, pp. 343–359, IEEE, 1991.

[25] P. Van Mieghem and J. Omic, “In-homogeneous virus spread in networks,” arXiv preprint arXiv:1306.2588, 2013.

[26] D. J. Watts, “A simple model of global cascades on random networks,” Proceedings of the National Academy of Sciences,

vol. 99, no. 9, pp. 5766–5771, 2002.

March 22, 2022

DRAFT

25

[27]

I. Milchtaich, “Random-player games,” Games and Economic Behavior, vol. 47, no. 2, pp. 353–388, 2004.

[28] J. C. Harsanyi, “Games with incomplete information played by “bayesian” players, i–iii: Part i. the basic model&,”

Management science, vol. 50, no. 12 supplement, pp. 1804–1817, 2004.

[29] D. Fudenberg and J. Tirole, “Game theory. 1991,” Cambridge, Massachusetts, vol. 393, 1991.

[30] J. M. Smith and G. Price, “lhe logic of animal conﬂict,” Nature, vol. 246, p. 15, 1973.

[31] J. C. Spall, “Multivariate stochastic approximation using a simultaneous perturbation gradient approximation,” Automatic

Control, IEEE Transactions on, vol. 37, no. 3, pp. 332–341, 1992.

[32] J. C. Spall and J. A. Cristion, “Model-free control of nonlinear stochastic systems with discrete-time measurements,”

Automatic Control, IEEE Transactions on, vol. 43, no. 9, pp. 1198–1210, 1998.

[33] V. S. Borkar, “Stochastic approximation with two time scales,” Systems & Control Letters, vol. 29, no. 5, pp. 291–294,

1997.

[34] T. C. Scott, R. Mann, and R. E. Martinez Ii, “General relativity and quantum mechanics: towards a generalization of the

Lambert W function a generalization of the lambert w function,” Applicable Algebra in Engineering, Communication and

Computing, vol. 17, no. 1, pp. 41–47, 2006.

[35] T. C. Scott, G. Fee, and J. Grotendorst, “Asymptotic series of generalized Lambert W function,” ACM Communications

in Computer Algebra, vol. 47, no. 3/4, pp. 75–83, 2014.

[36] P. Farrugia, R. Mann, and T. Scott, “N-body gravity and the schr¨odinger equation,” Classical and Quantum Gravity, vol. 24,

no. 18, p. 4647, 2007.

March 22, 2022

DRAFT

