Meta-analysis of mid-p-values: some new results based on the
convex order

Patrick Rubin-Delanchy1,3, Nicholas A Heard2,3, and Daniel J Lawson4

1Department of Statistics, University of Oxford, UK
2Department of Mathematics, Imperial College London, UK
3Heilbronn Institute for Mathematical Research, University of Bristol, UK
4School of Social and Community Medicine, University of Bristol, UK

Abstract

The mid-p-value is a proposed improvement on the ordinary p-value for the case where
the test statistic is partially or completely discrete.
In this case, the ordinary p-value is
conservative, meaning that its null distribution is larger than a uniform distribution on the
unit interval, in the usual stochastic order. The mid-p-value is not conservative. However, its
null distribution is dominated by the uniform distribution in a diﬀerent stochastic order, called
the convex order. The property leads us to discover some new ﬁnite-sample and asymptotic
bounds on functions of mid-p-values, which can be used to combine results from diﬀerent
hypothesis tests conservatively, yet more powerfully, using mid-p-values rather than p-values.
Our methodology is demonstrated on real data from a cyber-security application.

Keywords: conservative test; convex order; hypothesis testing; meta-analysis; signiﬁcance level;
stochastic order

7
1
0
2

y
a
M
1
3

]
T
S
.
h
t
a
m

[

4
v
8
6
0
5
0
.
5
0
5
1
:
v
i
X
r
a

1

 
 
 
 
 
 
1 Introduction

Let T be a real-valued test statistic, with probability measure P0 under the null hypothesis, denoted
H0. Let X be a uniform random variable on the unit interval that is independent of T under P0.
X is a randomisation device which is in practice usually generated by a computer.

We consider the (one-sided) p-value,

the mid-p-value (Lancaster, 1952),

P = P0(T ∗ ≥ T ),

Q =

1
2

P0(T ∗ ≥ T ) +

1
2

P0(T ∗ > T ),

and the randomised p-value,

R = XP0(T ∗ ≥ T ) + (1 − X)P0(T ∗ > T ),

(1)

(2)

(3)

where T ∗ is a hypothetical independent replicate of T under P0.
If T is absolutely continuous
under H0, then the three quantities are equal and distributed uniformly on the unit interval. More
generally, that is, if discrete components are possible, the three are diﬀerent. Two main factors,
one obvious and one more subtle, make this a very common occurrence. First, T is discrete if it is
a function of discrete data, e.g. a contingency table, categorical data or a presence/absence event.
Second, discrete test statistics often occur as a result of conditioning, as in the permutation test
or Kendall’s tau test (Sheskin, 2003). Partially discrete tests occur, for example, as a result of
censoring.

When P , Q and R are not equal, it is a question which to choose. The ordinary p-value is
often preferred in relatively strict hypothesis testing conditions, e.g.
in clinical trials, where the
probability of rejecting the null hypothesis must not exceed the nominal level (often 5%). The
randomised p-value has some theoretical advantages, e.g.
the nominal level of the test is met
exactly. However, to quote one of its earliest proponents, “most people will ﬁnd repugnant the
idea of adding yet another random element to a result which is already subject to the errors of
random sampling” (Stevens, 1950). Randomised p-values also fail Birnbaum’s admissibility crite-
rion (Birnbaum, 1954). Note that we can also work with an unrealised version of the randomised
p-value, known as the fuzzy or abstract p-value (Geyer and Meeden, 2005), and either stop there —
leaving interpretation to the decision-maker — or propagate uncertainty through to any post-hoc
analysis, e.g. multiple-testing (Kulinskaya and Lewin, 2009; Habiger, 2015).

Although it can allow breaches of the nominal level, the mid-p-value is often deemed to better
represent the evidence against the null hypothesis than the ordinary or randomised p-values. Justi-
ﬁcations are not just heuristic as, for example, the mid-p-value can arise as a Rao-Blackwellisation
of the randomised p-value corresponding to the uniformly most powerful test (Wells, 2010), as an
optimal estimate of the H0 versus H1 truth indicator under squared loss (Hwang and Yang, 2001),
or from asymptotic Bayesian arguments (Routledge, 1994). Performance has also been demon-
strated in applications, e.g. in the context of healthcare monitoring (Spiegelhalter et al., 2012) (a
paper read before the Royal Statistical Society), genetics (Graﬀelman and Moreno, 2013), a wealth
of examples involving contingency tables (Lydersen et al., 2009), and more. Our own interest stems
from cyber-security applications, and a motivating example is given in Section 3. Most arguments
for using the mid-p-value in hypothesis testing scenarios also work for conﬁdence intervals. Here,
using the mid-p-value over the p-value can result in a smaller interval, with a closer-to-nominal
coverage probability (Berry and Armitage, 1995; Fagerland et al., 2015).

In this article, we are able to make further mathematical progress on the mid-p-value by using
a stochastic order known as the convex order. The problem we focus on is meta-analysis, that
is, combining evidence from diﬀerent hypothesis tests into one, global measure of signiﬁcance. In
some of the scenarios analysed, the use of the ordinary p-value leads to sub-optimal, and even
spurious results. New bounds for some commonly-used methods for combining ordinary p-values
are derived for mid-p-values. This allows large gains in power over using ordinary p-values, while,
unlike any previous study based on mid-p-values, the false positive rate is still controlled exactly
(albeit conservatively).

2

The remainder of this article is structured as follows. In Section 2, we summarise our main
results. Section 3 gives a cyber-security application where, using mid-p-values, we are able to
detect a cyber-attack that would likely fall under the radar if only ordinary p-values were used.
Section 4 elaborates on the results of Section 3, with improved (although more complicated) bounds,
simulations and discussion. Section 5 concludes. All proofs are relegated to the Appendix.

2 Main results

This section summarises the main ideas and ﬁndings of the paper. Let U denote a uniform random
variable on the unit interval, with expectation operator E, and let E0 denote expectation with
respect to P0. Under the null hypothesis, it is well known, see e.g. Casella and Berger (2002), that
P dominates U in the usual stochastic order, denoted P ≥st U . One way to write this is

E0{f (P )} ≥ E{f (U )},

(4)

for any non-decreasing function f , whenever the expectations exist (Shaked and Shanthikumar,
2007). It is also well known, and in fact true by design, that R is uniformly distributed under the
null hypothesis, denoted R =st U . On the other hand, it is not widely known that, under the null
hypothesis, Q is dominated by U in the convex order, denoted Q ≤cx U . One way to write this is
(Shaked and Shanthikumar, 2007, Chapter 3)

E0{h(Q)} ≤ E{h(U )},

(5)

for any convex function h, whenever the expectations exist. We have used the qualiﬁer ‘widely’,
because an eﬀective equivalent of equation (5) can be found in Hwang and Yang (2001). However,
even there, equation (5) is not recognised as a major stochastic order, meaning that some of its
importance is missed.

In particular, we now present three concrete, new results, made possible by the literature on
the convex order. Each provides a method for combining mid-p-values conservatively, the ﬁrst
two in ﬁnite samples and the last asymptotically. Details and improved (but more complicated)
bounds are given in Section 4. In what follows, Q1, . . . , Qn denote independent (but not necessarily
identically distributed) mid-p-values, with an implied joint probability measure ˜P0 under the null
hypothesis.

Let ¯Qn = n−1 (cid:80)n

i=1 Qi denote the average mid-p-value. For t ≥ 0,

˜P0

(cid:0)1/2 − ¯Qn ≥ t(cid:1) ≤ exp(−6nt2).

(6)

Note that, ﬁrst, no knowledge of the individual mid-p-value distributions is required. Second,
Hoeﬀding’s inequality (Hoeﬀding, 1963), which would be available more generally, gives the larger
bound exp(−2nt2) (the cubic root).

Let Fn = −2 (cid:80)n

i=1 log(Qi), known as Fisher’s statistic (Fisher, 1934) and the most popular
method for combining p-values (in the continuous case, it is well-known that Fn has a chi-square
distribution with 2n degrees of freedom under H0). For t ≥ 2n,

˜P0(Fn ≥ t) ≤ exp{n − t/2 − n log(2n/t)}.

(7)

Finally, assume additionally that Q1, . . . , Qn are identically distributed. Then applying Fisher’s
method as usual, i.e. treating the mid-p-values as if they were ordinary p-values and using the
chi-square tail, is asymptotically conservative as n → ∞.

3 Example: network intrusion detection

The perceived importance of cyber-security research has risen dramatically in recent years, partic-
ularly after several well-publicised events in 2016 and 2017. In this area, anomaly detection over
very high volumes and rates of network data is a key statistical problem (Adams and Heard, 2016).
In our experience of the ﬁeld, discrete data, whether they be presence/absence events, counts or

3

Figure 1: Authentication data: full network of connections comprising ∼ 18, 000 nodes and ∼
400, 000 directed edges. Edges are coloured by authentication type. On the left, nodes are shown
as black points, with node ID “C17693” highlighted in red (and larger). On the right, the points
are hidden to better see the connections made by node ID “C17693”, which are now highlighted
in pink.

categorical data, are absolutely the norm rather than the exception. We will demonstrate the value
of our paper’s contributions in a network intrusion detection problem.

Figure 1 shows publically available authentication data covering 58 days on the Los Alamos
National Laboratory computer network (Kent, 2016). Nodes in the graph are computers, and an
edge indicates that there was at least one connection from one computer to the other, resulting
in a graph with m ≈ 18, 000 nodes and ∼ 400, 000 directed edges. An exciting opportunity
oﬀered by this data resource is that it contains an actual cyber-attack: or, to be precise, records
of penetration testing activity conducted by a ‘red-team’. One of the four computers used for
the attack (the highest degree of the four, ID “C17693”, with 296 out of 534 edges labelled as
nefarious) is highlighted in red on the left, with its connections highlighted in pink on the right.

Earlier work on network intrusion has suggested that the occurrence of new edges on the net-
work can be indicative of nefarious behaviour (Neil et al., 2013; Neil, 2015). Looking at the outward
connections from a given computer, in particular, those which involve a computer otherwise re-
ceiving relatively few new connections present special interest. Because the ﬁrst day of data has no
red-team activity, we use this day to learn a rate λj, j = 1, . . . , m at which each computer receives
new connections, treating the times as right-censored independent and identically distributed expo-
nential random variables. For every computer on the network, the set of outward new connections
made over the remainder of the observation period [1, 58] is scored according to this model. The
test-statistic

Tij =

(cid:40)

57
τ − 1

if no connection occurs from i to j,
if a new connection from i to j occurs at time τ ,

is considered for every directed pair (i, j) not occurring as an edge on the ﬁrst day, so that each
node i has associated with it a collection of test statistics Ti·, which are partially discrete, with a
point mass at 57.

For regularisation purposes, the rates λj, j = 1, . . . , m are assumed a priori to follow a Gamma
distribution matching the mean and variance of the empirical rates computed for each j = 1, . . . , m
over the full period of 58 days. The use of this prior implies that before censoring Tij has a Gamma-
Exponential (also called Lomax) predictive distribution, which is used to compute the collection
of ordinary, mid, and randomised p-values Pi·, Qi·, Ri· corresponding to the outward connections
of each node i = 1, . . . , m.

As we are interested in the ranking of computer ID “C17693” among the other ∼ 18, 000
computers, as well as its p-value, it makes sense to extend the ranges of the bounds (6) and (7) as

4

follows:

˜P0

(cid:0)1/2 − ¯Qn ≥ t(cid:1) ≤ exp{−6 sgn(t)nt2},

˜P0(Fn ≥ t) ≤ exp[sgn(t − 2n){n − t/2 − n log(2n/t)}],

t ∈ R,

t > 0,

(8)

(9)

which preserves the shape and monotonicity of the curves, and remains valid because larger values
than unity are returned outside the old ranges. Our options are:

1. to compute the average ordinary, mid, and randomised p-values, and obtain a global sig-
niﬁcance level using bound (8). Computer ID “C17693” then ranks as 8th (p-value ≈ 1),
8th (p-value ≈ 10−7) and 9th (p-value ≈ 10−7) most anomalous of the ∼ 18, 000 computers
respectively.

2. to compute Fisher’s statistic for the ordinary, mid, and randomised p-values, and obtain a
global signiﬁcance level using bound (9) for the second case, and the chi-square tail otherwise.
Computer ID “C17693” now ranks joint 8118th (p-value ≈ 1), 2nd (p-value ≈ 1) and 9th
(p-value ≈ 10−43) respectively.

3. to assume an asymptotic regime and use the chi-square tail for the Fisher-with-mid-p-values

statistic instead. Computer ID “C17693” then ranks 8th (p-value ≈ 1).

As rankings go, therefore, the mid-p-value is never beaten, with computer ID “C17693” coming
in the top ten every time and coming second once. The most obvious approach of using Fisher’s
method with ordinary p-values fails completely. As for the other three red-team computers: using
the best performing method, i.e. Fisher’s statistic with mid-p-values and bound (9), where Com-
puter ID “C17693” comes second, their ranks are 384th (ID “C18025”), 550th (ID “C19932”) and
1079th (ID “C22409”).

4 Meta-analysis of mid-p-values: further details

This section elaborates on the results of Section 2. We say that a random variable (and its measure
and distribution function) is sub-uniform if it is less variable than a uniform random variable, U ,
in the convex order.

To see why the mid-p-value is sub-uniform, notice that Q = E0(R | T ). By Jensen’s inequality,

for any convex function h,

E0{h(Q)} = E0[h{E0(R | T )}] ≤ E0[E0{h(R) | T }] = E0{h(R)} = E{h(U )},

(10)

whenever the expectations exist, since R =st U . Remember that we do not claim this result is
new, see e.g. Hwang and Yang (2001), but rather the idea to exploit the literature on the convex
order.

0

To formalise the meta-analysis framework, let T1, . . . , Tn be a sequence of independent test
statistics. We consider a joint null hypothesis, ˜H0, under which T1, . . . , Tn have probability measure
0 , . . . , P(n)
P(1)
respectively. The p-values, Pi, mid-p-values, Qi, and randomised p-values, Ri, are
obtained by replacing P0 with P(i)
in (1), (2) and (3) respectively. In the case of the randomised
0
p-value, an independent uniform variable, Xi, is generated each time. ˜P0 denotes the implied joint
probability measure of the statistics under ˜H0. The focus of this section is on testing the joint null
hypothesis ˜H0. Probability bounds that follow often have the form ˜P0{f (Q1, . . . , Qn) ≥ t} ≤ bn(t).
If the observed mid-p-values are q1, . . . , qn and level of the test is α (e.g. 5%), then a procedure
that rejects when bn{f (q1, . . . , qn)} ≤ α is conservative: the probability of rejecting ˜H0 if ˜H0 is
true does not exceed α.

4.1 Sums of mid-p-values

An early advocate of mid-p-values, Barnard (1989, 1990) proposed to combine test results from
diﬀerent contingency tables by taking the sum of standardised mid-p-values. His exposition relies
on some approximations. Our results make exact inference possible.

5

We begin with a bound on the sum of independent mid-p-values. This bound bears an in-
teresting resemblance to Hoeﬀding’s inequality (Hoeﬀding, 1963). It will later be extended to be
relevant to Barnard’s analysis.

Theorem 1. Let X1, . . . , Xn denote n independent sub-uniform random variables with mean ¯Xn =
n−1 (cid:80)n

i=1 Xi. Then, for 0 ≤ t ≤ 1/2,

P (cid:0)1/2 − ¯Xn ≥ t(cid:1) ≤ min

h≥0

(cid:8)2e−ht sinh(h/2)/h(cid:9)n

,

≤ exp(−12nt2) {sinh(6t)/(6t)}n ,
≤ exp(−6nt2).

(11)

(12)

(13)

A sub-uniform random variable has expectation 1/2 and is bounded between 0 and 1. Ho-
eﬀding’s inequality would therefore give us P (cid:0)1/2 − ¯Xn ≥ t(cid:1) ≤ exp(−2nt2), the cubic root. Our
improvement is substantial, for example, suppose we observe an average of 0.4 from n = 100 mid-
(cid:0)1/2 − ¯Qn ≥ 0.1(cid:1) ≤ 0.0025 using (13). However, we would
p-values. This is very signiﬁcant: ˜P0
only ﬁnd ˜P0

(cid:0)1/2 − ¯Qn ≥ 0.1(cid:1) ≤ 0.14 using Hoeﬀding’s inequality.

Instead of summing the mid-p-values directly, Barnard (1990) actually considers sums of the

standardised statistics

Di = (1/2 − Qi)/σi,
where σi is the standard deviation of Qi under ˜H0. The upper tail probability of the sum is
then estimated by Gaussian approximation.
In the purely discrete case, Barnard shows that
σi = {(1 − si)/12}1/2 where

si =

(cid:88)

t∈Si

(cid:110)

P(i)

0 (Ti = t)

(cid:111)3

,

and Si is the (countable) support of Qi. Instead of appealing to the Gaussian approximation, the
convex order allows us to ﬁnd an exact bound.

Lemma 1. Let X1, . . . , Xn denote n independent sub-uniform random variables with standard
deviations σ1, . . . , σn respectively, and let

¯Yn =

1
n

n
(cid:88)

i=1

(1/2 − Xi)/σi.

Then, for t ≥ 0,

P( ¯Yn ≥ t) ≤ min
h≥0

(cid:32) n
(cid:89)

exp[−h{t + 1/(2σi)}]

i=1
≤ exp{−6n(¯σt)2},

(cid:26) eh/σi − 1
h/σi

+ h2

(cid:18) 1
2

−

1
24σ2
i

(cid:19)(cid:27)(cid:33)

,

(14)

(15)

where ¯σ = ((cid:81) σi)1/n is the geometric mean of the standard deviations.

In practice, the bound (14), which is an important improvement over (15), is found numerically
by minimising over h. Of course, even if the optimum cannot be determined exactly the obtained
bound still holds, because the tail area is simply over-estimated.

To illustrate how the bound (14) performs in practice, we now re-visit Barnard’s example
(Barnard, 1990, p.606). The ﬁrst experiment he considers yields Q1 = 1/7, s1 = 9002/423, D1 =
2 is almost
1.32. The second yields Q2 = 1/9, s2 = 141/729, D2 = 1.5. Since the sum divided by
two, i.e. two standard deviations away, he ﬁnds “serious evidence” against the null hypothesis.
Lemma 1 ﬁnds ˜P0(D1 + D2 ≥ 1.32 + 1.5) ≤ 0.12, providing some evidence in favour of the
alternative, but not signiﬁcant at, say, the 5% level. On the other hand, evidence would start to
become compelling if we were to observe the second result again, Q3 = 1/9, s3 = 141/729, D3 = 1.5;
Lemma 1 then ﬁnds ˜P0(D1 + D2 + D3 ≥ 1.32 + 1.5 + 1.5) ≤ 0.036.

√

6

Figure 2: Comparison of the probability bounds given by Theorem 2 for Fisher’s method using
mid-p-values. Theorem 2 gives explicit formulae for 2α, Cantelli and MGF, in that order. Both
axes are on the logarithmic scale.

4.2 Products of mid-p-values (Fisher’s method)

Fisher’s method (Fisher, 1934) is the most popular way of combining p-values. As is well-
known, under ˜H0, the statistic −2 (cid:80)n
i=1 log(Pi) has a chi-square distribution with 2n degrees
of freedom if Pi are absolutely continuous. Therefore, the p-value of the combined test is P † =
S2n{−2 (cid:80)n
i=1 log(Pi)}, where Sk is the survival function of a chi-square distribution with k de-
grees of freedom. This results in an exact procedure when Pi are absolutely continuous, and a
conservative one otherwise, i.e. P † ≥st U under ˜H0.

Our next result allows us to use the mid-p-values Q1, . . . , Qn in place of P1, . . . , Pn while
retaining a conservative procedure. We were able to derive three probability bounds. None beats
the other two uniformly for all n and all signiﬁcance levels (see Figure 2), but the last is often the
winner, hence the simpler statement of Section 2.

Theorem 2. Let X1, . . . , Xn be a sequence of independent sub-uniform random variables. Then
for x ≥ 2n,

(cid:32)

P

−2

n
(cid:88)

i=1

(cid:33)

log(Xi) ≥ x

≤ min

(cid:104)

S2m(x − 2n log 2),

(cid:105)
n (cid:14)(cid:2)n + {(x − 2n)/2}2(cid:3) , exp{n − x/2 − n log(2n/x)}

= un(x).

The ﬁrst uses P(Xi ≤ α) ≤ 2α for α ≥ 0, which would be obvious if Xi was a mid-p-value,
but is actually true for any sub-uniform random variable (Meng, 1994). The second uses bounds
on the mean and variance of − log(Xi) (given in Lemma 2, in the Appendix) and then applies the
Chebyshev-Cantelli inequality. The third is based on a bound on the moment generating function
of − log(Xi). Derivation details are in the Appendix.

For a given n and α ∈ (0, 1], let tα,n denote the critical value of Fisher’s statistic, i.e., tα,n
satisﬁes S2n(tα,n) = α. Figure 2 presents the behaviour of the diﬀerent bounds for diﬀerent n (20
on the left and 1 billion on the right) and α. The curves show the bound given by each formula at
diﬀerent α (which can be interpreted as ‘canonical levels’), i.e. inputting x = tα,n in Theorem 2,
as α ranges from 10−5 to 0.1. For low α, the bound based on the moment generating function,
marked MGF, is by far the best.

Let Q† = un{−2 (cid:80)n

i=1 log(Qi)}. Then Q† is again conservative, i.e., Q† ≥st U under ˜H0. Both
P † and Q† are valid p-values. Clearly, if the underlying p-values are continuous then the standard
P † is superior (in fact, deterministically smaller). However, Q† seems to be substantially more
powerful in a wide range of discrete cases. This is demonstrated by simulation in Section 4.3.

7

aProbability bound: n = 2010-510-410-310-210-110-510-410-310-210-11CantelliMGF2ay=aaProbability bound: n =10910-510-410-310-210-110-510-410-310-210-11CantelliMGF2ay=aFinally, we ﬁnd this interesting asymptotic result.

Theorem 3 (Fisher’s method is asymptotically conservative). Let X1, . . . , Xn denote n indepen-
dent and identically distributed sub-uniform random variables. For any α ∈ (0, 1], there exists
N ∈ N such that

(cid:32)

n
(cid:88)

P

−2

log(Xi) ≥ tα,n

≤ α,

(cid:33)

for any n ≥ N .

i=1

Hence, we can dispense with any correction entirely if n is large enough and the Qi are identically
distributed. A formal proof is given in the Appendix. Since E{− log(Xi)} ≤ E{− log(U )}, from
the deﬁnition of the convex order, a direct application of the law of large numbers gets us most of
way, except for the possibility E{− log(Xi)} = E{− log(U )}. In fact, this exception is no problem
because, perhaps surprisingly, it implies that the Xi are uniform, using Shaked and Shanthikumar
(2007, Theorem 3.A.43).

4.3 Simulations

To illustrate the potential improvement of employing Fisher’s method with mid-p-values, using
the bound (7), over the traditional approach of using ordinary p-values and the chi-square tail,
we considered p-values from three types of support. In the ﬁrst column, each p-value Pi can only
take one of two values, 1/2 and 1. We therefore have Qi = 0.25 if Pi = 1/2 and Qi = 0.75 if
Pi = 1. Under the null hypothesis, P(i)
0 (Pi = 1/2) = P(i)
0 (Pi = 1) = 1/2. In the second column,
each p-value Pi is supported on the pair {pi, 1}, where pi is drawn uniformly on the unit interval.
We therefore have Qi = pi/2 if Pi = pi and Qi = (1 + pi)/2 otherwise. Under the null hypothesis,
P(i)
0 (Pi = pi) = 1 − P(i)
0 (Pi = 1) = pi, for each i. Finally, in the third column each p-value Pi
takes one of ten values, 1/10, 2/10, . . . , 1, and therefore Qi = Pi − 1/20. Under the null hypothesis,
P(i)
0 (Pi = j/10) = 1/10, for j = 1, . . . , 10. The rows represent two diﬀerent alternatives and
sample sizes. In both cases, the Pi are generated by left-censoring a sequence of independent and
identically distributed Beta variables, B1, . . . , Bn, that is, Pi is the smallest supported value larger
than Bi.
In the ﬁrst scenario, the dataset is small (n = 10), but the signal is strong (a Beta
distribution with parameters 1 and 20). In the second the dataset is larger (n = 100) but the
signal is made weaker accordingly (a Beta distribution with parameters 1 and 20). Comparing
just the solid and dashed lines ﬁrst, we see that Q† always outperforms P † substantially, and
sometimes overwhelmingly. In the bottom-left corner, for example, we have a situation where, at
a false positive rate set to 5% say, the test Q† would detect the eﬀect with probability close to one
whereas with P † the probability would be close to zero.
As a ﬁnal possibility, consider R† = S2n{−2 (cid:80)n

i=1 log(Ri)}. A disappointment is that this
randomised version, the dotted line in Figure 3, tends to outperform even the mid-p-values, and
by a substantial margin. On the other hand, as pointed out in the introduction, the randomised
p-value has some important philosophical disadvantages, and did not perform better in our real
data example.

5 Conclusion

The convex order provides a formal platform for the treatment and interpretation of mid-p-values.
This article used mathematical results from this literature to combine mid-p-values, which are not
conservative individually, into an overall signiﬁcance level that is conservative. As shown in real
data and simulations, the gains in power can be substantial.

Whereas the focus of this article was on meta-analysis, another canonical problem is multiple
testing, where the task is to subselect from or adjust a set of p-values, for example, subject to a
maximum false discovery rate (Benjamini and Hochberg, 1995). The case of discrete data has been
analysed in a number of papers, including Kulinskaya and Lewin (2009); Habiger and Pena (2011);
Liang (2016); Habiger (2015). A promising (but ostensibly harder) avenue of research would be to
investigate the use of the convex order in this problem.

8

Figure 3: Fisher’s method with discrete p-values. Empirical distribution functions of Fisher’s
combined p-value under diﬀerent conditions. 50/50: each p-value is equal to 1/2 or 1 (with
probability 1/2 each under ˜H0). Random binary: each p-value is equal to p or 1 (with probability
p and 1 − p respectively under ˜H0). p is drawn uniformly on [0, 1] (independently of whether
˜H0 or ˜H1 holds). Grid of ten: each p-value is drawn from 1/10, 2/10 . . . , 1 (with probability
1/10 each under ˜H0). n = 10, β = 20: 10 p-values from a left-censored Beta(1, 20) distribution.
n = 100, β = 5: 100 p-values from a left-censored Beta(1, 5) distribution. Dotted line: randomised
p-values. Solid line: mid-p-value. Dashed line: standard p-values. Further details in main text.

Appendix

Proof of Theorem 1. Since 1 − X is sub-uniform if and only if X is sub-uniform, it is suﬃcient
to prove the bounds in (11), (12) and (13) hold for P (cid:0) ¯Xn − 1/2 ≥ t(cid:1). Since exp(xh) is a convex
function in x for any h, the convex order gives us E{exp(hXi)} ≤ E{exp(hU )} = (eh − 1)/h.
Therefore, for any h ≥ 0,

P (cid:0) ¯Xn − 1/2 ≥ t(cid:1) = P

(cid:34)

exp

(cid:32) n
(cid:88)

i=1

(cid:33)

(cid:35)

hXi

≥ exp{nh(t + 1/2)}

,

≤ exp{−nh(t + 1/2)}E

exp

(cid:40)

(cid:32) n
(cid:88)

(cid:33)(cid:41)

hXi

,

i=1
≤ exp{−nh(t + 1/2)}{(eh − 1)/h}n
= (cid:8)2e−ht sinh(h/2)/h(cid:9)n

,

where the second line follows from Markov’s inequality. The choice h = 12t (motivated by an
analysis of the Taylor expansion in h at 0) leads to

P (cid:0) ¯Xn − 1/2 ≥ t(cid:1) ≤ exp(−12nt2) {sinh(6t)/(6t)}n

≤ exp(−6nt2) (cid:8)e−6t sinh(6t)/(6t)(cid:9)n

≤ exp(−6nt2).

using the fact that e−x sinh(x)/x = (1 − e−2x)/(2x) is one at x = 0 (using l’Hospital’s rule) and
decreasing.
Proof of Lemma 1. Again, we will prove the bound holds for Wn = n−1 (cid:80)(Xi − 1/2)/σi, so that

9

010150/50F^(x)x0101Random binaryF^(x)x0101Grid of tenF^(x)x0101F^(x)x0101F^(x)x0101F^(x)xrawrandomisedmid−p−valuey=xn=10, b= 20n=100, b= 5the theorem holds by symmetry. For any h ≥ 0,

E{exp(hXi/σi)} = 1 + E(hXi/σi) + E (cid:8)(hXi/σi)2(cid:9) /2 + . . .

= 1 + E(hU/σi) + h2

≤ E{exp(hU/σi)} + h2

+

(cid:18) 1
2
(cid:18) 1
2

(cid:19)

1
8σ2
i
1
8σ2
i

+

+ . . .

−

(cid:19)

,

1
6σ2
i

because E{(hXi/σi)n} ≤ E{(hU/σi)n} for n ≥ 3, by the convex order, and E{(U/σi)2}/2 =
1/(6σ2

i ). Therefore,

(cid:34)

P(Wn ≥ t) = P

exp

(cid:40) n
(cid:88)

i=1

(cid:34)

≤ e−hntE

exp

(cid:41)

(cid:35)

h(Xi − 1/2)/σi

≥ ehnt

,

(cid:41)(cid:35)

h(Xi − 1/2)/σi

,

(cid:40) n
(cid:88)

i=1

=

n
(cid:89)

i=1

exp[−h{t + 1/(2σi)}]

(cid:26) eh/σi − 1
h/σi

+ h2

(cid:18) 1
2

−

1
24σ2
i

(cid:19)(cid:27)

,

proving that (14) holds. Next, since σ2

i ≤ 1/12,

P(Wn ≥ t) ≤

n
(cid:89)

exp[−h{t + 1/(2σi)}]

(cid:19)

(cid:18) eh/σi − 1
h/σi

(cid:35)1/n(cid:44)


n

sinh{h/(2σi)}

(h/¯σ)



i=1

 2e−ht

=

(cid:34) n
(cid:89)

i=1

≤ (cid:8)2e−ht sinh(h/(2¯σ))/(h/¯σ)(cid:9)n

,

using the fact that the function sinh is geometrically convex on [0, ∞) (Niculescu, 2000). We
proceed as in the proof of Theorem 1, choosing h = 12¯σt.

The proofs of Theorems 2 and 3 both need the following result.

Lemma 2. Let X be a sub-uniform random variable. Then either i) X is uniform on [0, 1] or ii)

E{− log(X)} < E{− log(U )} = 1;

var{− log(X)} < var{− log(U )} = 1,

where U is a uniform random variable on [0, 1]

Proof. Shaked and Shanthikumar (2007, Theorem 3.A.43) provide the following theorem. If X ≤cx
Y and for some strictly convex function h we have E{h(X)} = E{h(Y )} then X is distributed as
Y . The function − log(x) is strictly convex, therefore either X is uniform or E{− log(X)} <
E{− log(U )}. If the latter is true, then

var{− log(X)} = E[− log(X) − E{− log(X)}]2
< E[− log(X) − E{− log(U )}]2
≤ E{log(U ) + 1}2
= var{− log(U )}

In the second line, the fact that the expected squared distance from the mean is smaller than from
any other point is used, and in the fourth we used the fact that (log(x) + 1)2 is convex.
Proof of Theorem 2. Let Gn = −2 (cid:80) log(Xi). Since Ui/2 ≤st Xi, for i = 1, . . . , n, where U1, . . . , Un
are independent uniform random variables on [0, 1]. This implies − log(Xi) ≤st − log(Ui/2). Be-
cause the usual stochastic order is closed under convolution (Shaked and Shanthikumar, 2007,

10

Theorem 1.A.3), we have Gn ≤st −2 (cid:80) log(Ui) + 2n log 2. The sum −2 (cid:80) log(Ui) has a chi-square
distribution with 2n degrees of freedom, proving the ﬁrst bound.

Lemma 2 implies E(Gn) ≤ 2n and var(Gn) ≤ 4n. Therefore, using Cantelli’s inequality,
P[Gn ≥ x] ≤ var(Gn)/ (cid:2)var(Gn) + {x − E(Gn)}2(cid:3)

≤ var(Gn)/ (cid:2)var(Gn) + {x − 2n}2(cid:3)
≤ n/ (cid:2)n + {(x − 2n)/2}2(cid:3) ,

for x ≥ 2n. This proves the second bound. Finally, the moment generating function of Gn is
E{exp(tGn)} = (cid:81) E(X −2t
) ≤ E(U −2t) = (1 − 2t)−1 since
x−2t is a convex function in x for x ∈ [0, 1]. Using Markov’s inequality,

) for t ≥ 0. For t ∈ [0, 1/2) each E(X −2t

i

i

P(Gn ≥ x) = P{exp(tGn) ≥ exp(tx)}

≤ exp(−tx)E{exp(tGn)}
≤ exp(−tx − n log(1 − 2t)),

for t ∈ [0, 1/2). The minimum of this function is at t = 1/2 − n/x, giving the third bound.

Proof of Theorem 3. Let Vi = −2 log(Xi), µV = E(Vi), Wi = −2 log(Ui), where U1, . . . , Un are
independent uniform random variables on [0, 1], and µW = E(Wi). If µV = µW then by Lemma 2
the Xi are uniform on [0, 1] and we are done. The statement is also true if α = 1. Therefore
assume µV < µW , α ∈ (0, 1) and let t ∈ (µV , µW ). By the weak law of large numbers there exists
an N (cid:48) ∈ N such that, for n ≥ N (cid:48),

(cid:32) n
(cid:88)

P

i=1

(cid:33)

Wi ≥ nt

≥ α,

so that tα,n ≥ nt. Therefore, for n ≥ N (cid:48),

(cid:32) n
(cid:88)

P

i=1

(cid:33)

Vi ≥ tα,n

≤ P

(cid:33)

Vi ≥ nt

.

(cid:32) n
(cid:88)

i=1

Again by the law of large numbers, the right-hand side tends to zero. Hence there exists an N ≥ N (cid:48)
such that it is bounded by α for n ≥ N .

References

Adams, N. and Heard, N. (2016). Dynamic Networks and Cyber-security, volume 1. World Scien-

tiﬁc.

Barnard, G. (1989). On alleged gains in power from lower p-values. Statistics in Medicine,

8(12):1469–1477.

Barnard, G. (1990). Must clinical trials be large? The interpretation of p-values and the combi-

nation of test results. Statistics in Medicine, 9(6):601–614.

Benjamini, Y. and Hochberg, Y. (1995). Controlling the false discovery rate: a practical and pow-
erful approach to multiple testing. Journal of the Royal Statistical Society. Series B (Method-
ological), 57(1):289–300.

Berry, G. and Armitage, P. (1995). Mid-p conﬁdence intervals: a brief review. The Statistician,

pages 417–423.

Birnbaum, A. (1954). Combining independent tests of signiﬁcance. Journal of the American

Statistical Association, 49(267):559–574.

Casella, G. and Berger, R. L. (2002). Statistical inference, volume 2. Duxbury Paciﬁc Grove, CA.

11

Fagerland, M. W., Lydersen, S., and Laake, P. (2015). Recommended conﬁdence intervals for two

independent binomial proportions. Statistical methods in medical research, 24(2):224–254.

Fisher, R. A. (1934). Statistical methods for research workers.

Geyer, C. J. and Meeden, G. D. (2005). Fuzzy and randomized conﬁdence intervals and p-values.

Statistical Science, pages 358–366.

Graﬀelman, J. and Moreno, V. (2013). The mid p-value in exact tests for Hardy-Weinberg equi-

librium. Statistical applications in genetics and molecular biology, 12(4):433–448.

Habiger, J. D. (2015). Multiple test functions and adjusted p-values for test statistics with discrete

distributions. Journal of Statistical Planning and Inference, 167:1–13.

Habiger, J. D. and Pena, E. A. (2011). Randomised p-values and nonparametric procedures in

multiple testing. Journal of nonparametric statistics, 23(3):583–604.

Hoeﬀding, W. (1963). Probability inequalities for sums of bounded random variables. Journal of

the American statistical association, 58(301):13–30.

Hwang, J. G. and Yang, M.-C. (2001). An optimality theory for mid p-values in 2 x 2 contingency

tables. Statistica Sinica, 11(3):807–826.

Kent, A. D. (2016). Cybersecurity data sources for dynamic network research. In Dynamic Net-

works and Cybersecurity. World Scientiﬁc.

Kulinskaya, E. and Lewin, A. (2009). On fuzzy familywise error rate and false discovery rate

procedures for discrete distributions. Biometrika, 96(1):201–211.

Lancaster, H. (1952). Statistical control of counting experiments. Biometrika, 39:419–422.

Liang, K. (2016). False discovery rate estimation for large-scale homogeneous discrete p-values.

Biometrics, 72(2):639–648.

Lydersen, S., Fagerland, M. W., and Laake, P. (2009). Recommended tests for association in 2 ×

2 tables. Statistics in medicine, 28(7):1159–1175.

Meng, X.-L. (1994). Posterior predictive p-values. The Annals of Statistics, 22(3):1142–1160.

Neil, J., Uphoﬀ, B., Hash, C., and Storlie, C. (2013). Towards improved detection of attackers in
computer networks: New edges, fast updating, and host agents. In Resilient Control Systems
(ISRCS), 2013 6th International Symposium on, pages 218–224. IEEE.

Neil, J. C. (2015). Using new edges for anomaly detection in computer networks. US Patent

9,038,180.

Niculescu, C. P. (2000). Convexity according to the geometric mean. Math. Inequal. Appl, 3(2):155–

167.

Routledge, R. (1994). Practicing safe statistics with the mid-p. Canadian Journal of Statistics,

22(1):103–110.

Shaked, M. and Shanthikumar, J. G. (2007). Stochastic orders. Springer.

Sheskin, D. J. (2003). Handbook of parametric and nonparametric statistical procedures. Chapman

and Hall/CRC Press.

Spiegelhalter, D., Sherlaw-Johnson, C., Bardsley, M., Blunt, I., Wood, C., and Grigg, O. (2012).
Statistical methods for healthcare regulation: rating, screening and surveillance. Journal of the
Royal Statistical Society: Series A (Statistics in Society), 175(1):1–47.

Stevens, W. (1950). Fiducial limits of the parameter of a discontinuous distribution. Biometrika,

37:117–129.

Wells, M. T. (2010). Optimality results for mid p–values. In Borrowing Strength: Theory Powering
Applications–A Festschrift for Lawrence D. Brown, pages 184–198. Institute of Mathematical
Statistics.

12

