Dynamic Resilient Network Games with
Applications to Multi-Agent Consensus

Yurid Nugraha, Ahmet Cetinkaya, Tomohisa Hayakawa, Hideaki Ishii, and Quanyan Zhu

1

0
2
0
2

l
u
J

7

]

Y
S
.
s
s
e
e
[

2
v
4
5
5
3
1
.
3
0
0
2
:
v
i
X
r
a

Abstract—A cyber security problem in a networked system
formulated as a resilient graph problem based on a game-
theoretic approach is considered. The connectivity of the un-
derlying graph of the network system is reduced by an attacker
who removes some of the edges whereas the defender attempts
to recover them. Both players are subject to energy constraints
so that their actions are restricted and cannot be performed
continuously. For this two-stage game, which is played repeatedly
over time, we characterize the optimal strategies for the attacker
and the defender in terms of edge connectivity and the number
of connected components of the graph. The resilient graph
game is then applied to a multi-agent consensus problem. We
study how the attacks and the recovery on the edges affect the
consensus process. Finally, we also provide numerical simulation
to illustrate the results.

I. INTRODUCTION

Multi-agent systems provide a framework for studying dis-
tributed decision-making problems as a number of agents make
local decisions by interacting with each other over networks
[1]–[3]. Due to the rise in the use of general purpose networks
and wireless communication channels for such systems, cyber
security has become a major critical issue [4]. Each agent
in the network can be vulnerable to various threats initiated
by malicious adversaries. One of the common security threats
in networked systems is jamming attacks. The adversary can
simply transmit interference signals to interrupt communica-
tion among agents. While jamming attacks against multi-agent
systems can be harmful as it does not require any knowledge
of the systems, the danger level may further increase if the
attacker is more aware of system parameters.

Noncooperative game theory approaches are widely used for
addressing security problems including jamming attacks [5],
[6]. Jamming attacks on networked systems were previously
analyzed through game-theoretic approaches. The works [7]–
[9] model the activity of jamming and transmitting signals
as zero-sum games where the payoff structure of the players
is balanced. In [10], [11], the authors consider a Stackelberg
game approach, in which the players decide their actions
sequentially by following a certain hierarchy.

Multi-agent consensus problems in the presence of such
jamming attacks have been studied in [12], [13]. The work

Yurid Nugraha and Tomohisa Hayakawa are with the Department
and Control Engineering, Tokyo Institute of Technol-
of Systems
ogy, Tokyo 152-8552, Japan. yurid@dsl.sc.e.titech.ac.jp,
hayakawa@sc.e.titech.ac.jp

Ahmet Cetinkaya is with the Information Systems Architecture Science
Research Division, National Institute of Informatics, Tokyo 101-8430, Japan.
cetinkaya@nii.ac.jp

Hideaki Ishii is with the Department of Computer Science, Tokyo Insitute
of Technology, Yokohama 226-8502, Japan. ishii@c.titech.ac.jp
and Com-
puter Engineering, New York University, Brooklyn, NY 11201, USA.
quanyan.zhu@nyu.edu

Quanyan Zhu is with the Department of Electrical

This work was supported in the part by the JST CREST Grant No.
JPMJCR15K3 and by JST ERATO HASUO Metamathematics for Systems
Design Project (No. JPMJER1603).

[14] introduces a stochastic communication protocol so that
the attackers do not know the exact transmission times of
the agents in advance. Jamming attack models with energy
constraints were introduced in [14]–[17] in the context of
networked control. These models have been generalized to
further take account of probabilistic packet losses in [18]. In
the related studies on resilient consensus, some agents may
be attacked by an adversary, making them update their state
values in a faulty and even malicious manner; the resilience
and robustness in such problems have been discussed in [19]–
[21]. Also, nonmalicious packet losses that can interrupt the
communication among agents have been studied in [22], [23].
However, in the abovementioned works, optimal strategies
for the attackers have not been well addressed. In addition, in
those works there is also no defense mechanism to mitigate the
attacks and restore the communication so as not to simply wait
for the attacks to end. In this paper, we model the interaction
between an attacker and a defender in a two-player game
setting. The attacker is motivated to disrupt the communication
by attacking individual
links while the defender attempts
to recover some or all of them whenever possible. Both
players are constrained in terms of their available energy for
the actions of attacks and recovery. We extend the problem
formulation of [24], where the decision variables are limited
to the links in the graphs for both players. In our problem
setting, more dynamics are present as the time intervals for
attacking and recovering are to be decided as well.

More speciﬁcally, in our formulation of resilient graphs,
two-stage games are repeatedly played by the attacker and the
defender. In each attack interval, the attacker decides the links
and the durations for the attacks. The attacker’s utility depends
on the number of connected components of the graph after
the attack as well as the remaining energy of the attacker. In
response to the attacks, the defender attempts to recover some
of the links that are important for maintaining the connectivity
of the graph. Once the attacker ends attacking, the defender
also ends recovering since there are no attacks anymore. Our
study is based on the analysis of the subgame perfect equilibria
of the games, and we use backward induction to obtain optimal
strategies for both players, as in [24].

We emphasize that our contribution is the introduction
of a game-theoretic framework to jamming attack problems.
We follow the attack models dealt with in [14]–[17], where
the energy for communication by the players is under time-
varying constraints. Moreover, the defender can overcome
the attacker’s jamming by sending signals with increased
signal-to-interference-plus-noise ratio (SINR); such models are
employed in [10], [11]. Though the setting is centralized in
the sense that both players have control over the networked
system, our approach addresses the question on how to design
the underlying networks having structures resilient to cyber

 
 
 
 
 
 
2

attacks. As an application of the game problem, we further
consider a consensus problem and analyze how the time for
reaching consensus is affected by the strategies of the players.
The paper is organized as follows. In Section II, we intro-
duce the framework for the resilient graph game. In Section III,
we analyze the subgame perfect equilibria and characterize
the optimal strategies for the players. In Section IV, we apply
the obtained results to a consensus problem for multi-agent
systems. We then provide numerical examples in Section V
and conclude the paper in Section VI. Finally, all the proofs
for our main results are given in the Appendix. A preliminary
version of this paper appeared as [25]; the scenarios considered
there are more restricted as the attacker stops attacking only
when running out of energy.

II. PROBLEM FORMULATION

We consider a multi-agent system of n agents with a
communication topology described by the undirected graph
G = (V, E). It consists of the set V of vertices and the
set E ⊆ V × V of edges. The agents are described by the
vertices, while the communication links between the agents
are represented by the edges. We assume that the underlying,
attack-free communication topology G is connected, i.e., there
exists a path connecting every pair of vertices in V.

In this paper, we consider a game between two players,
the attacker and the defender, in terms of the communication
among the agents. The attacker is an entity capable to block
the communication by jamming some targeted links, whereas
the defender tries to recover some or all of the attacked links.
However, the actions of both players are constrained by the
limited energy resources they have.

Our problem setting is centralized in that the attacker and
the defender know the conditions of the communication net-
works at each time and have control over the links individually.
That is, the attacker can strategically decide the links to attack
while the defender may ask the chosen agents to increase their
transmission level to recover their links. As we mentioned
in the Introduction, even in such a centralized setting, game-
theoretic studies on resilient graphs are very limited. Our game
formulation provides insights into networks having resilient
structures against adversaries even under a powerful defender
having the full knowledge of the system.

The kth game with k ∈ N is played in the time interval
[tk, tk], which is determined by the players’ actions with tk >
tk = tk−1. Initially, at the start time tk, there is no attack
or recovery, and the underlying graph is G. Then, the attacker
may start an attack on certain links, at which point the defender
will decide whether to recover some of the attacked links or
not. The durations and the links for the attack and the recovery
are the action variables. The end time tk is when the attacker
and hence the defender stop their actions. The kth game may
also end after a ﬁxed time duration when no attack occurs.
The (k + 1)th game starts immediately after the kth game,
that is, tk+1 = tk.

In each time interval [tk, tk], the attacker can start and end
attacking, and the defender can start and end recovering at
most once. The end of the kth time interval tk is speciﬁed
more concretely later in this section. At the start time tk, the
active communication links are prescribed by the original edge
set E for all k ∈ N. We assume that the attacker fully knows
the edge set E. More speciﬁcally, the attacker attacks G by

k ≤ τ A
k ) at τ A

k ⊆ E from time τ A

deleting some of the existing edges E A
k until
τ A
k , where tk < τ A
k ≤ tk. Consequently, G is changed
k := (V, E \ E A
to GA
k . For transmitting jamming signals,
the attacker spends some energy in proportion to the attack
duration. For the attacker, it is also an option not to make an
attack action considering its utility deﬁned later. We deﬁne the
k ] for every k ∈ N, where the values
attack interval as [τ A
of τ A
k are related to the attacker’s energy, as discussed later.
If there is no attack in the kth time interval, it is understood
that τ A

k , τ A

k = τ A
k .

k < τ D

k ≤ τ D

k ⊆ E A

k , with E D

k and tk < τ A

k := (V, (E \ E A

k is changed to GD

On the other hand, the defender aims to maintain the con-
nectivity of the graph by recovering some of the edges blocked
by the attacker. The defender recovers the edges E D
k from time
k ≤ τ A
k until τ D
τ D
k ≤
tk. As soon as the defender starts the recovery action at τ D
k ,
the graph GA
k )). By
recovering the edges, the defender spends some amount of
energy similarly to the attacker. If there is no recovery action
due to the absence of the attack action or the decision by the
defender, we set τ D
k . We deﬁne the recovery interval as
[τ D
k are related to the
energy of the defender, as discussed later. Once the attacker
stops attacking, the attacked edges come back to normal and
the graph becomes G again, which ends the kth game and
triggers the new (k + 1)th game.

k ] for every k ∈ N, where values of τ D

k ) ∪ E D

k = τ D

k , τ D

In this formulation, we assume that there is a constant dwell
time γA > 0 between the beginning of the kth game tk and
the beginning of the attack time τ A
k . For the defender, there is
also a constant dwell time γD > 0 between the beginning of
attack time τ A
k unless
the attacker ends attacking earlier, i.e., τ A
τ D
k := min{τ A

k and the beginning of recovery time τ D

k < τ D
k , τ A

τ A
k := tk + γA,

k . Thus, let

k + γD}.

(1)

The lengths of the attack and the recovery intervals are denoted
by δA

k and δD

k , respectively, with
δA
k := τ A

k − τ A
k ,

δD
k := τ D

k − τ D
k .

(2)

The timeline of the attack and the recovery sequences is illus-
trated in Fig. 1. It is important to note that two-stage games
are repeatedly played by the two players. The equilibrium is
thus characterized for each of the two-stage games.

In the kth game, both players attempt to choose the best
strategies to maximize their own utility functions deﬁned as
how much the agents are connected or disconnected over
the time interval [tk,tk] without foreseeing the future activ-
ities. To characterize how much the agents are connected or
disconnected in a uniﬁed way, we introduce the generalized
λ(G′) as an extension of the notion of edge
edge connectivity
connectivity for the graph G′. It is deﬁned as

b
λ(G′) :=

λ(G′),
−

λ(G′),

(

if G′ is connected,
otherwise,

(3)

b

e

where λ(G′) denotes the edge connectivity of the graph G′,
i.e., the minimum number of edges required to be removed
to make the connected graph G′ disconnected. On the other
λ(G′) denotes the minimum number of edges required
hand,
to make the disconnected graph G′ connected; in this case,
λ(G′) + 1 connected components in the disconnected
there are
e
graph G′, since one edge is needed to connect two connected
λ implies that
components. Note that a larger positive value of

e

b

PSfrag replacements

t2

GD
1

τ A

2 = t2

e
g
d
E

G

e12

e13

e14

e23

e34

t1

γA

τ A
1

2

e13

e23
3

e12
1

e14

4

e34

G

γD

2

τ D
1

e13

3

1

e34

4
GA
1

Attack interval, δA
1

δA
2

Recovery interval, δD
1

γA

γD

τ D
1

τ A

1 = t1 = t2

τ A
2

t2 = τ D

2 = τ D

2

3

t

e23
3

e34

2

e13

1

4

GD
1

1

e23
3

e34

2

4

GA
1

e12

1

e14

2

e13

4

e23

3

e34

1

2

4

e23
3

Illustration of graph transition. At time interval [t1, t1], the defender recovers one edge e23 at τ D

Fig. 1.
[t2, t2], the defender cannot recover since the attacker ends jamming at τ D
lines indicate that the edges are connected, and dashed lines indicate that the edges are disconnected.

2 , and hence the graph is represented by GA

G

GA
2
1 and stops recovering at τ D
2 from τ A

1 . At time interval
2 to t2. Note that the solid

λ(GA

λ(GD

k ) ≤

k ⊆ G, note that

the graph G has more links to be removed by the attacker,
λ indicates that the graph G
and a smaller negative value of
requires more links to be recovered by the defender. Since
k ⊆ GD
GA
k ) ≤
b
The attacker chooses the optimal edges to attack based on
the generalized edge connectivity
λ(G) of the graph G, and the
defender chooses the optimal edges to recover based on the
generalized edge connectivity of the graph GA
k . The attacker
λ(GA
should strategically choose the edges to jam to reduce
k )
(making GA
k more disconnected), and the defender also should
k ) (making GD
choose the edges to efﬁciently increase
k
more connected).

λ(GD

λ(G).

b

b

b

b

b

b

Note that for the same number of edges to attack/recover,
there may be multiple optimal choices of edges to at-
k ).
tack/recover that yield the same values of
Since we focus on the connectivity of the agents to charac-
terize the utility functions below without specifying particular
b
edges to attack/recover, we deﬁne
k ) to represent
the generalized edge connectivity of the underlying graph
k = |E D
G = (V, E) with mA
k |
edges recovered, given by

k | edges attacked and mD

b
k , mD

k = |E A

λG(mA

k ) or

λ(GA

λ(GD

b

λG(mA

k , mD

k ) :=

min
k |=mA

k

k :|E A
E A

max

k :|E D
E D

k |=mD

k

λ((V, (E\E A

k )∪E D

k )).

b

(4)
b
For the simple case of mD
k = 0, calculating the right-hand
side in (4) reduces to the min-cut problem for undirected
and unweighted graph G, for which efﬁcient randomized
algorithms are available [26]. More in general, we can apply
the so-called k-cut algorithms [27] by increasing the number
k of the connected components. Thus, in principle, the players
can obtain the full solution ofﬂine prior to playing the sequence
of the games.

This

λG can be presented as a lower triangular matrix

λG ∈
k ) represents the (mA
k +
b
k + 1) entry of the matrix. For example, the matrix
λG

R(|E|+1)×(|E|+1), where
1, mD
for the graph G in Fig. 1 is given by

λG(mA

k , mD

b

b

b

0
0
2
0
2
1
−1
2
1
−1
1
1
−2 −1
1
−3 −2 −1

0
0
0
2
1
1

0
0
0
0
2
1

0
0
0
0
0
2

.









λG = 






b

In general, the matrix
λG is not Toeplitz, i.e., the values of the
(i, j) entries with the same i − j may be different. We also
note that the values for the same row/column do not change
linearly and that attacking/recovering more number of edges
does not necessarily change the graph connectivity.

b

k , δA

k , δD

k ) and (mD

The strategies of the attacker and the defender are in terms
of (mA
k ), respectively. For the game of the
kth time interval [tk, tk], we deﬁne the utility function U A of
the attacker as
U A((mA
k , δA
λG(mA

k ), (mD
k , 0)(δA

k , δD
k ))
k − δD

k − βAmA

λG(mA

k , mD

k )δD

k ) −

:= −

k δA
k ,
(5)

b

b

where βA > 0 is the attacker’s cost to remove one edge
per time unit. Similarly, deﬁne the utility function U D of the
defender as
U D((mA

k , δA
λG(mA

k ), (mD
k , 0)(δA

k , δD
k ))
k − δD
k ) +

:=

λG(mA

k , mD

k )δD

k − βDmD

k δD
k ,
(6)

b

b
where βD > 0 is the defender’s cost to recover one edge
per time unit. Note that the utility function (5) represents the
total generalized edge connectivity (with the negative sign)
for the attacker over the game horizon [τ A
k , tk] plus the cost
for jamming mA
k number of communication links. Similarly,
(6) represents the total generalized edge connectivity for the
defender over the game horizon [τ A
k , tk] plus the cost for
recovering mD

k number of communication links.
If the attacker decides to attack at least one edge, then the
k . Otherwise, the game ends at tk + γA + γD.

game ends at τ A
In other words, the end time tk of the kth game is

tk :=

τ A
k ,
k > 0,
tk + γA + γD, otherwise.

if mA

(

(7)

According to the utility functions (5) and (6),
there is a
case where the defender stops recovering mD
k number of
links before the game ends while the attacker keeps sending
jamming signals to mA
k number of links. In this case, the graph
changes back to GA
k , with generalized edge connectivity
k , 0). Therefore, in [τ D
λG(mA
k , tk], the utilities of both players
in (5) and (6) are computed based on
b

k at τ D

λG(mA

k , 0).

b

4

The players cannot keep sending signals for very long
durations due to energy constraints. We follow the approach in
[14] to model such energy constraints. The total energy used
by player p ∈ {A, D} must satisfy

k−1

βpmp

l δp

l + βpmp

k(t − τ p

k) ≤ κp + ρpt,

(8)

k, τ p

l=1
X
for any time t ∈ [τ p
k+1], with κp > 0, ρp ∈ (0, 1),
βp > ρp, and k ∈ N. Note that κp denotes the initial energy
that player p has, and ρp denotes the recharge rate of energy for
player p. The left-hand side of (8) represents energy consumed
by player p up to time t and is affected by the number
of attacked/recovered edges and the attack/recovery durations
from the ﬁrst game until the kth game. The right-hand side
represents the total available energy, dictated by the parameters
κp and ρp. In this paper, we assume that each player knows
all parameters of the other player, including κp and ρp.

Under this problem formulation, if player p keeps sending
jamming/recovering signals starting at time τ p
k until running
out of energy, then from (8) we obtain an explicit expression
for the maximum interval ∆p
k when
player p completes the attack/recovery as
k−1

k on the time duration δp

κp + ρpτ p

l=1 βpmp

l δp

l

.

(9)

∆p

k(mp

k) :=

k −
βpmp

k − ρp
P

We formulate the kth game as a two-stage game where the
attacker ﬁrst attacks and then the defender makes recoveries.
It should be noted that each game is played independently at
time tk and the strategies of the players will depend on their
energy level at that point. It is, however, noted that there would
be a preceding stage, which is implicit in our formulation; this
stage is related to the design of the network structure of the
underlying graph G. The underlying graph is assumed to be
given in this paper, but clearly affects the game as it is the
default network at the start of each game. In this respect, our
formulation will be useful in ﬁnding resilient networks under
hostile environments.

We seek the subgame perfect equilibrium of the kth game
as in [24]. To this end, one needs to divide the game into
some subgames. The equilibrium must be optimal in every
subgame. The defender’s game is formulated as a subgame of
the attacker’s game. Therefore, the attacker also maximizes the
defender’s utility function to obtain the defender’s best strategy
given the attacker’s strategy, and uses the defender’s best strat-
egy to formulate the best strategy for the attacker. To obtain the
optimal strategy for each player, backward induction is used in
each kth game consisting of two-stage decision-making levels
corresponding to the attack and recovery sequences. This two-
stage game is played independently at time tk. Notice that
since the maximum durations of attacks and recoveries in (9)
are affected by the players’ strategies in the past games, the
players’ strategies in the kth game are inﬂuenced by their
strategies in the previous games and therefore the players’
optimal strategies can be different in each game.

(mA

In the time interval [tk, tk], given the attacker’s strategy
k , δA

k ), the defender decides the strategy as
k (mA
(mD∗

k (mA

k ), δD∗
k , δA
∈ arg max
k ,δD
k )

(mD

k , δA
k ))
k , δA
U D((mA

k ), (mD

k , δD

k )),

(10)

TABLE I
POSSIBLE CASES OF ATTACK AND RECOVERY ACTIONS

Case

1

2

3

bλG (mA, 0)
bλG (mA, 0) =
bλ(G)
bλG (mA, 0) < bλ(G)
bλG (mA, 0) < bλ(G)

bλG (mA, mD)

bλG (mA, 0)
bλG (mA, mD) =
bλG (mA, mD) =
bλG (mA, 0)
bλG (mA, mD) > bλG (mA, 0)

k and δD

k depending on mA

with mD
the initial graph G, the attacker decides the strategy as
(mA∗

k and δA

k . Likewise, given

U A((mA

k , δA

k ), (mD∗

k (mA

k , δA

k ), δD∗

k (mA

k , δA

k ))).

(11)

k , δA∗
k )
∈ arg max
k ,δA
k )

(mA

k , δA

k , δD

k , δD

k ) such that (mD

k ) and (mD
k , δA

We study the subgame perfect equilibrium and seek
k , δD
k , δA
pairs (mA
k ) is the
best response to (mA
k ). The combination of strategies
((mA
k ), (mD
k )) that follow the subgame perfect equilib-
rium principle is called the optimal combined strategy. A tie-
break condition happens if the players have multiple options
for the choices on which edges to attack or recover, and those
edges yield the same values of the utility functions. In this
case, we suppose that the players choose more edges to attack
or recover.

III. GAME ANALYSIS

In this section, we discuss the subgame perfect equilibrium
formulation and the characteristics of the players on one game
interval. Hence, in this section we remove the subscript k from
all variables. We assume that the maximum attack/recovery
durations ∆A(mA) > 0 and ∆D(mD) > 0 are given. For
simplicity of notation, we omit the variable mA (resp., mD)
for the presentation of ∆A (resp., ∆D) in this section.
A. Brief Summary of the Results

b

b

λ(G),

λG(mA, 0), and

b
λG(mA, 0) =

We ﬁrst provide a summary of the results. To characterize
the optimal strategies, from the sequence of actions by the
attacker and the defender described in the previous section,
we categorize the possible combinations of generalized edge
λG(mA, mD) into three
connectivities
cases shown in Table I. Note that these cases cover all the
possible combinations of the actions by both players. Since
mD ≤ mA, it is impossible to have
λ(G) and
λG(mA, 0). Also, note that since by deﬁnition
λG(mA, mD) >
λG(mA, 0) cannot be
λG(mA, mD) <
mD ≥ 0, condition
b
fulﬁlled. Furthermore, even if the attacker attacks some edges
b
of E, there is a possibility that the edge connectivity does not
change, as in Case 1. The same remark applies to the recovery
action. As a result, there are four possible optimal combined
strategies that are derived from the three cases in Table I.
A summary of the results of the optimal strategies is shown
in Table II. Note that it may be optimal for the attacker to
continue attacking even after the recovery ﬁnishes, since the
attacker gets higher utility in [τ D, τ A].
B. Subgame Perfect Equilibrium Analysis

b

b

b

b

In this subsection, we analyze the subgame perfect equilib-
rium of the system. From the sequence of actions, we obtain
several cases that might happen and seek the equilibrium in
each case, i.e., the candidate optimal strategies of the system.
Then, we seek the optimal strategy among the candidate
strategies by using backward induction.

Comb.
Str.
1

2a

2b

3

TABLE II
OPTIMAL COMBINED STRATEGY CANDIDATES

Action

Attacker: No attack
Defender: No need to recover
Attacker: Attacks the optimal edges for ∆A duration
Defender: No recovery
Attacker: Attacks the optimal edges until τ D
Defender: No chance to recover
Attacker: Attacks the optimal edges for ∆A duration
Defender: Recovers the optimal edges for

min{∆D, ∆A + τ A − τ D} duration

TABLE III
LINKS AND DURATIONS OF THE OPTIMAL COMBINED STRATEGY
CANDIDATES

Comb.
Str.

Att.
Str.

mA∗

δA∗

Def.
Str.

mD∗

δD∗

1

2a

2b

3

0

A1
A2a mA2a∗ ∆A(mA2a∗)
A2b mA2b∗

τ D − τ A

0

D1

0

A3

mA3∗

∆A(mA3∗)

D3

mD3∗
(mA3∗)

0

ξ

λ(G),

λ(G) ≥

1) Subgame Perfect Equilibrium Analysis in Each Case:
λG(mA, mD) ≥
From the problem formulation, since
λG(mA, 0), we obtain three cases based on the combinations
λG(mA, mD), as shown in Table
of
I. We analyze the subgame perfect equilibrium for the time
b
interval [t, t] in each case. The results in terms of links and
durations of the optimal combined strategy candidates are
summarized in Table III.

λG(mA, 0), and

b

b

b

b

b

Case 1: In this case, we show that the optimal strategy for
the players are not to recover any edge, i.e., mA∗, mD∗ = 0.
By Table I, the utility function in (6) of the defender becomes

U D((mA, δA), (mD, δD)) =

λ(G)δA − βDmDδD.

(12)

Furthermore, because the defender receives no reward by
recovering any link, the optimal strategy for the defender is
mD∗ = 0 and δD∗ = 0, resulting in

b

U D((mA, δA), (mD∗, δD∗)) =

λ(G)δA.

(13)

This strategy mD∗ = 0 and δD∗ = 0 for the defender is named
Strategy D1 (see Table III).

b

Likewise, for the attacker, the utility function in (5) becomes

U A((mA, δA), (mD∗, δD∗)) = (−

λ(G) − βAmA)δA.

(14)

It is then clear that the optimal strategy for the attacker is
mA∗ = 0 and δA∗ = 0. As a result, the utility functions in
Case 1 are given by

b

U A((mA∗, δA∗), (mD∗, δD∗)) = 0 =: ˆU A1,
U D((mA∗, δA∗), (mD∗, δD∗)) = 0 =: ˆU D1.

(15)

(16)

From (7), because mA = mD = 0, it follows that the game
ends at t = t + γA + γD. This optimal strategy candidate
mA, δA = 0 for the attacker is classiﬁed as Strategy A1.
In this case, the optimal combined strategy corresponding
to ((mA∗, δA∗), (mD∗, δD∗)) is then labelled as Combined
Strategy 1 := (Strategy A1, Strategy D1).

5

Case 2: In this case, we show that the attacker’s optimal
strategy is to attack until running out of energy, whereas the
optimal strategy for the defender is not to recover any edge.
because
analysis
the

Similarly with
λG(mA, 0),
λG(mA, mD) =
defender with mD∗, δD∗ = 0 as in (13) is given by
b

the utility function of

in Case

U D((mA, δA), (mD∗, δD∗)) =

λG(mA, 0)δA.

(17)

the

1,

b

For the attacker, from (5) with δD = 0, we have

b

U A((mA, δA), (mD∗, δD∗)) = (−

λG(mA, 0) − βAmA)δA.

(18)
λG(mA, 0) − βAmA > 0, the attacker maximizes δA, by

If −
attacking as long as possible. Hence, δA = ∆A, and

b

b
U A((mA, δA∗), (mD∗, δD∗))

= (−

λG(mA, 0) − βAmA)∆A =: ˆU A2a(mA).
Now we only need to choose mA, as δA is already determined.
Speciﬁcally, we search for mA2a∗, which denotes the optimal
mA. This is done by maximizing the simpliﬁed utility function
ˆU A2a(mA) in (19), resulting in

(19)

b

mA2a∗ ∈ arg max
mA>0

ˆU A2a(mA).

(20)

Note that with this strategy, (17) becomes

U D((mA∗, δA∗), (mD∗, δD∗)) =

λG(mA2a∗, 0)∆A =: ˆU D2a.
(21)

b

The attacker’s strategy in this case is speciﬁed as Strat-
egy A2a, which is mA = mA2a∗ and δA = ∆A. This com-
bination of strategies of ((mA∗, δA∗), (mD∗, δD∗)) is labelled
as Combined Strategy 2a := (Strategy A2a, Strategy D1).
Case 3: In this case, we show that the optimal strategy for
the attacker is to attack the optimal edges until running out of
energy or to attack until the defender starts to recover, whereas
the optimal strategy for the defender is to recover the optimal
edges until the defender runs out of energy or the attacker
ends attacking. In this case, by Table I, the generalized edge
connectivities satisfy

λG(mA, mD) >

λG(mA, 0).

λ(G) ≥

From (6), the defender’s utility function can be written as
b

b
U D((mA, δA), (mD, δD)) = φδD +

b
λG(mA, 0)δA,

(22)

λG (mA, mD)−

λG(mA, 0) <
b

λG(mA, 0)−βDmD) for simplicity.
with φ := (
b
λG(mA, mD), in order to maximize the
Since
term φδD, the defender recovers mD links as long as possible
if φ ≥ 0, so that τ D = min{∆D + τ D, τ A}. Alternatively, if
φ < 0, then the defender should not recover. It follows that
the utility function of the defender becomes

b

b

b

U D((mA, δA), (mD, min{∆D, τ A − τ D}))

= φ(min{∆D, τ A − τ D}) +

λG(mA, 0)δA.

(23)

Since the attacker is able to attack for ∆A, we divide the
analysis for this case into two parts: (i) the attacker ends
attacking before ∆D + τ D, and (ii) the attacker ends attacking
after ∆D + τ D.

b

(i) In this case,

the attacker ends the game before the
defender ﬁnishes the recovery attempt that would have lasted
for ∆D units of time. However, since the attacker ends the
game earlier, the recovery duration is only τ A − τ D units of
time. Thus, we have τ D = τ A = t, and the attacker’s utility

6

function in (5) can be stated as

U A((mA, δA), (mD, (τ A − τ D)))

= (−

λG(mA, 0) − βAmA)(τ D − τ A)

λG(mA, mD) − βAmA)(τ A − τ D).

(24)

+ (−
b

b

(ii) In this case, the attacker ends the game after the defender
ﬁnishes the recovery attempt. Hence, τ D = ∆D + τ D, where
the utility function for the attacker keeps the form as in (5).
Combined Strategy 3: From (i) and (ii) above, one of the
obvious choices for the attacker is to attack for ∆A duration.
Depending on the value of ∆A, the attacker can end attacking
before or after ∆D + τ D. If the attacker ends attacking before
∆D + τ D, then t = τ D = ∆A + τ A. Otherwise, the defender
recovers for ∆D, and ∆D + τ D < t = ∆A + τ A. Hence, we
can rewrite (23) as

U D((mA, ∆A), (mD, ξ)) = φξ +

λG(mA, 0)δA

=: ˆU D3(mA, mD),
b

with

ξ := min{∆D, ∆A + τ A − τ D}.

(25)

(26)

Then the optimal number of edges to be recovered for given
mA is obtained by

mD3∗(mA) ∈ arg max
mD>0

ˆU D3(mA, mD).

(27)

The utility function of the attacker can be rewritten as
U A((mA, δA∗), (mD∗, δD∗))

λG(mA, 0)(∆A − ξ) −

= −
=: ˆU A3(mA).

b

b

λG(mA, mD3∗)ξ − βAmA∆A
(28)

The attacker looks for the optimal number of edges mA3∗ by
maximizing the simpliﬁed utility function ˆU A3(mA). Speciﬁ-
cally,

ˆU A3(mA).

mA3∗ ∈ arg max
mA>0
Note that to obtain mA3∗, the attacker needs to obtain mD3∗
ﬁrst. Hence, the attacker solves the maximization problem in
(27) beforehand to obtain mD3∗(mA). This strategy for the
attacker is named as Strategy A3.

(29)

Finally, after

the attacker obtains mA3∗,

the defender

searches for mD3∗, based on ˆU D3(mA3∗, mD) in (25), as

mD3∗(mA3∗) ∈ arg max
mD>0
This strategy mD = mD3∗(mA3∗), δD = ξ for the defender
is labelled as Strategy D3. We call this combined strategy as
Combined Strategy 3 := (Strategy A3, Strategy D3).

ˆU D3(mA3∗, mD).

(30)

Combined Strategy 2b: Another choice of the attacker is
to end attacking at τ D, which is preferred if −
λG(mA, mD) −
βAmA < 0 (from the second term of (24)), i.e., the cost of
attacking is too high at interval [τ D, τ A]. Since the attacker
ends attacking at τ D, the defender cannot recover any edge
(Strategy D1), i.e., mD = 0 and δD = 0. Consequently, the
attacker’s utility function becomes
U A((mA, δA∗), (mD∗, δD∗))

b

= (−

λG(mA, 0) − βAmA)(τ D − τ A) =: ˆU A2b(mA).

(31)

b

As in the previous strategy, the attacker looks for the optimal
number of edges mA2b∗ by maximizing the simpliﬁed utility
function ˆU A2b(mA). Speciﬁcally,
mA2b∗ ∈ arg max
mA>0
Strategy mA = mA2b∗ and δA = τ D − τ A for the attacker is
speciﬁed as Strategy A2b. Note that with this strategy, utility
function in (22) becomes

ˆU A2b(mA).

(32)

U D((mA∗, δA∗), (mD∗, δD∗)) =

λG(mA2b∗, 0)∆A =: ˆU D2b.
(33)

λG(mA, 0) <

λG(mA, 0), this
As
optimal strategy of ((mA∗, δA∗), (mD∗, δD∗)) is named as
Combined Strategy 2b := (Strategy A2b, Strategy D1).

λG(mA, mD) =

λ(G) and

b

b

b

b

b

2) Subgame Perfect Equilibrium Analysis of All Cases:
Here, we discuss the subgame perfect equilibrium analysis
of the system among all cases. Speciﬁcally, we ﬁnd the
strategy that yields the maximum utility out of the four
possible combined strategies described in Section III.B.1, in
accordance with the subgame perfect equilibrium principle.
This is done by applying the backward induction method
to the maximum values of the simpliﬁed utility functions
ˆU A1, ˆU A2a∗ := ˆU A2a(mA2a∗), ˆU A2b∗ = ˆU A2b(mA2b∗),
ˆU A3∗ := ˆU A3(mA3∗), ˆU D1, ˆU D2a, ˆU D2b, and ˆU D3∗ :=
ˆU D3(mA3∗, mD3∗(mA3∗)).

We ﬁrst state properties of utility functions in some strate-
gies. In Lemma 3.1, we state that the attacker’s utility without
recovery is always higher than the one with recovery by the
defender, for the same mA and δA. Lemmas 3.2 and 3.3
characterize the properties of ˆU A2a∗, ˆU A2b∗, and ˆU A3∗ in
terms of their values relative to others.
Lemma 3.1. For all possible combinations of mD and δD, it
holds U A((mA, δA), (0, 0)) ≥ U A((mA, δA), (mD, δD)).

Lemma 3.2. For any possible mA2a∗ and mA3∗, it follows
that ˆU A2a∗ ≥ ˆU A3∗.
Lemma 3.3. ˆU A2a∗ has the same sign with ˆU A2b∗. Also,
ˆU A2a∗ ≥ ˆU A2b∗ if ˆU A2a∗ > 0.

We are now ready to state the main result of this paper.
λG(mA, mD) is a nonlinear function of mA and mD
Since
and its particular form depends on the underlying graph G,
the utility functions cannot be represented as simple functions
of the action and energy variables except for certain cases.
For this reason, we present our general result in terms of the
functions ˆU ∗. In particular, we use ˆU A3
and mA∗ deﬁned by

b

ˆU A3
0

:= max
mA∈M

0
ˆU A2a(mA),

mA∗ ∈ arg max
mA∈M

ˆU A2a(mA),

(34)

(35)

:

λG(mA, mD3∗) −
:=

where M := {mA ∈ {0, |E|}
λG(mA, 0) − βDmD3∗ < 0}. Furthermore, we let ˆU D3
ˆU D3(mA2a∗, mD3∗(mA2a∗)).
b
Theorem 3.4. The subgame perfect equilibrium of the kth
game in the time interval [t, t] satisﬁes the following:
1) Combined Strategy 1 is optimal if ˆU A2a∗ < 0.
2) Combined Strategy 2a is optimal if ˆU A2a∗ ≥ 0 and

b

2

a) ˆU D3

2 < ˆU D2a, or

PSfrag replacements

(0, 0)

Attacker

Defender

(mA∗, δA∗) = (0, 0)

(mD∗, δD∗) = (0, 0)

(mA2a∗, ∆A)

(0, 0)

( ˆU A1, ˆU D1)

( ˆU A2a∗, ˆU D2a)

( ˆU A2a∗, ˆU D2a)

(mD3∗(mA2a∗), ξ)

(·, ˆU D3
2 )

To provide a more explicit relation between optimal strate-
gies and attack/recovery parameters, we present a result for a
simple case. It allows us to determine the equilibrium based on
the cost and action durations. To this end, we consider a graph
with n = 2 and |E| = 1. In this setup, both players can only
attack/recover one edge. Based on the results in Theorem 3.4,
the optimal combined strategy can be stated as follows.

7

(mA2b∗, (τ D − τ A)) (0, 0)

(mA3∗, ∆A)

(0, 0)

(mD3∗(mA3∗), ξ)

( ˆU A2b∗, ˆU D2b)

Proposition 3.7. The optimal combined strategy of the players
with n = 2 is given by

(·, bλG (mA3∗, 0)∆A)

( ˆU A3∗, ˆU D3∗)

1) Combined Strategy 1 if βA > 1;
2) Combined Strategy 2a if βA ≤ 1 and βD > 2;
3) Combined Strategy 2b if 1 −

2ξ

∆A−τ D+τ A < βA ≤ 1 and

Fig. 2.
Illustration of possible optimal strategies. Arrows that represent
possible actions of the attacker and the defender lead to pairs of utilities
obtained under those actions. The dot in the attacker’s utilities in (·, ˆU D3
2 )
and (·, bλG (mA3∗, 0)∆A) means that those utilities are not considered to ﬁnd
the optimal strategy.

b) ˆU D3

2 ≥ ˆU D2a and
I) ˆU A3∗ < ˆU A2b∗ and ˆU A3
II) ˆU A3∗ ≥ ˆU A2b∗ and ˆU A3

0 > ˆU A2b∗, or
0 > ˆU A3∗.

In these cases (a) and (b) above, the optimal number
of edges mA∗ for the attacker to attack are mA2a∗ and
mA∗, respectively .

3) Combined Strategy 2b is optimal if ˆU A2a∗ ≥ 0, ˆU D3

2 ≥

ˆU D2a, ˆU A2b∗ > ˆU A3∗, and ˆU A2b∗ > ˆU A3
0 .

4) Combined Strategy 3 is optimal if ˆU A3∗ ≥ ˆU A2b∗ ≥ 0,
0 ≤ ˆU A3∗.

2 ≥ ˆU D2a, and ˆU A3
ˆU D3

The combined strategies above cover all possible cases.

Possible optimal strategies for both players are illustrated
in Fig. 2. Moreover, combinations of the conditions of the
possible optimal strategies in all cases are shown in Table IV.
We also note that even if the unit costs βA and βD for
attacking/recovering one edge per time depend on edges,
the procedure to ﬁnd the optimal combined strategies as in
Theorem 3.4 does not change.

From the optimal strategies in Theorem 3.4, we can state
some corollaries about the effects of the uniform cost βA and
βD to the optimal strategy as follows. It is interesting to note
that the critical values of βA and βD are different.

Corollary 3.5. The optimal strategy for the defender is not to
recover if βD > 2.

Corollary 3.6. The optimal strategy for the attacker is not
to attack if βA > 1. Also, under the optimal strategy, if the
attacker attacks (i.e., mA, δA > 0), then GA always becomes
disconnected.

λG(mA, 0) < 0 (i.e., GA is disconnected),
Remark 1. If
λG(mA, mD) larger, the defender can
then in order to make
reduce the number of connected components by adding links
λG(mA, mD) > 0). The
until the graph becomes connected (
minimum number of edges to add in order to achieve certain
λG(mA, mD) in a disconnected GA is given by

b

b

b

mD =

b

λG(mA, 0),

λG(mA, mD) −
for
b

b

λG(mA, mD) < 0,

λG(mA, 0) < 0.

(36)

b

b

4) Combined Strategy 3 if βA ≤ 1 −

2ξ

∆A−τ D+τ A and βD ≤

βD ≤ 2;

2.

Proposition 3.7 characterizes the players’ strategies in terms
of the unit costs βA and βD as well as energy levels that
inﬂuence ∆A and ∆D. This result can be summarized in
the (βA, βD) plane as shown in Fig. 3. We will see later in
a numerical example that the relation expressed in this plot
holds for networks with more agents. In general, the player
decides to attack (resp., to recover) if the unit cost βA (resp.,
βD) is not too expensive. The attacker decides to attack for
longer duration (Combined Strategy 3) if the attacker has large
enough energy so that it is able to continue the attack for
longer after the defender ends its recovery at τ D.

C. Discussion on the usage of

λ

b

In our formulation, the generalized edge connectivity

λ is
used in the utilities of both players. This
λ captures the idea
that some edges are weaker than others in connected graphs
(and thus the attacker should attack the weakest edges while
minimizing its energy usage). Moreover, some of the attacked
edges are more crucial for the agents’ communication than oth-
ers (and thus the defender should recover the most important
edges for the agents’ communication). Among the different
connectivity measures, the generalized edge connectivity is
useful to characterize the resilience of the multi-agent systems
represented by both connected and disconnected graphs.

b

b

IV. APPLICATION TO CONSENSUS PROBLEM

In this section, a consensus problem of a multi-agent system
[1]–[3] in the face of jamming attacks is investigated. We apply
our game approach to this problem.

We assume that the graph G is connected and the agents
communicate with neighbors continuously in time. Let Ni(t)
be the set of neighbors of agent i, i.e., the agents sharing edges
with agent i at time t. Every agent i has the scalar state xi
whose dynamics are deﬁned as

˙xi(t) =

(xj (t) − xi(t)),

x(0) = x0,

t ≥ 0,

(37)

Xj∈Ni(t)

so that the state of all agents x = [x1 x2 · · · xn]T can converge
to a consensus state x∗.

We now introduce the notion of approximate consensus.
Speciﬁcally, for a given ǫ > 0, the approximate consensus
set Dǫ ⊂ Rn is given by Dǫ := {x ∈ Rn: V (x) ≤ ǫ}, where

V (x) := max
i∈V

xi − min
i∈V

xi,

x ∈ Rn.

(38)

8

TABLE IV
CHARACTERIZATION OF THE OPTIMAL STRATEGY OF ALL CASES
ˆU D3

Conditions

2 < ˆU D2a

ˆU D3

PSfrag replacements
2 ≥ ˆU D2a

βA

Comb. Str. 1

ˆU A2a∗ ≥ 0

ˆU A3∗ < ˆU A2b∗

ˆU A3∗ ≥ ˆU A2b∗

ˆU A2a∗ < 0

0 ≥ ˆU A2b∗
ˆU A3
0 < ˆU A2b∗
ˆU A3
0 > ˆU A3∗
ˆU A3
0 ≤ ˆU A3∗
ˆU A3

Comb. Str. 2a

Comb. Str. 2a

Comb. Str. 2b

Comb. Str. 2a

Comb. Str. 3

1 −

1

2ξ
∆A−τ D +τ A
ρA

ρD

Comb. Str. 2b

Comb. Str. 3

Comb. Str. 2a

2

βD

Comb. Str. 1

Fig. 3. Optimal strategies of all cases for n = 2

We characterize the effect of jamming attacks in terms of the
time for the agents to reach the approximate consensus set
Dǫ. In particular, for the initial state x(0) = x0 ∈ Rn, the
approximate consensus time T∗(x0) is given by

T∗(x0) := inf{t ≥ 0: x(t) ∈ Dǫ}.
(39)
In our analysis, we also use the Laplacian matrix L ∈ Rn×n
associated with graph G. Moreover, let P := e−γAL and
p := maxj∈{1,...,n} mini∈{1,...,n} Pi,j ,, where Pi,j denotes the
(i, j)th entry of the matrix P . Notice that since G is connected
and γA > 0, we have Pi,j ∈ (0, 1), and hence, p ∈ (0, 1).

The next proposition gives an upper bound for the approx-
imate consensus time of agents under jamming attacks. Here,
we deﬁne ⌈x⌉ as the ceiling function of x.
Proposition 4.1. Consider the multi-agent system (37) with
the initial condition x0 ∈ Rn \ Dǫ. Under the optimal attack
and defense strategies for the resilient graph game in Section
III, the approximate consensus time satisﬁes

βA(γA + γD)

ln ǫ−ln V (x0)
ln(1−p)

+ κA

T∗(x0) ≤

(cid:24)
βA − ρA

(cid:25)

.

(40)

Proposition 4.1 provides an upper bound related directly
to the scalars βA, κA, ρA that characterize the attacker’s
energy constraint, and the scalars γA and γD that respectively
represent the attacker’s and the defender’s waiting durations
before taking actions in each game. It is interesting to note that
the attacker’s energy parameters inﬂuence the bound more than
the defender’s energy parameters. In scenarios where there is
no jamming attack (and hence no defense), from (40), an upper
bound of the approximate consensus time can be obtained as
T∗(x0) ≤ (γA + γD)

ln ǫ−ln V (x0)
ln(1−p)

.

(cid:24)

(cid:25)

The approximate consensus time bound above for the attack-
free case is clearly smaller than in (40) when the attacker has
positive energy resources (κA, ρA > 0) and the defender has
a nonzero initial waiting duration (γD > 0). Note that with
larger values of κA and ρA, the bound (40) becomes even
larger, indicating the possibility of slower consensus due to
more damaging attacks.

V. NUMERICAL EXAMPLES

In this section, we demonstrate the efﬁcacy of the approach
in the approximate consensus problem through numerical
examples.

We ﬁrst compare the actual approximate consensus time for
different energy parameters. We use the graph shown in Fig.
1 with n = 4, and parameters βA = 0.4, βD = 0.6, κD = 1,
ρD = 0.1, γA = 0.1, and γD = 0.3.

First, we use the parameters κA = 0.5 and ρA = 0.3.
Figs. 4 and 5 show the states of the agents and properties of

4

3.5

3

2.5

2

1.5

1

e
t
a
t
S

0.5

0

1

0.5

2
Time
Fig. 4. State trajectories with κA = 0.5 and ρA = 0.3. The red areas indicate
the intervals where the attacker attacks.

1.5

2.5

3.5

3

4

y
g
r
e
n
E
g
n
n
a
m
e
R

i

i

2

1

0

0

0.5

1

1.5

.
r
t

S

.
b
m
o
C

.
t
p
O

3

2b

2a

1

0

0.5

1

1.5

2
Time

2
Time

2.5

3

3.5

4

2.5

3

3.5

4

4

2

0

-2

-4

0

0.5

1

1.5

2
Time

2.5

3

3.5

4

Fig. 5. Remaining energy and optimal combined strategy for the two players,
and the resulting bλ with κA = 0.5 and ρA = 0.3. Note that the defender
does not recover any edge, and hence the available energy for the defender
accumulates continuously.

the players of the ﬁrst simulation, with the agents eventually
achieving approximate consensus at t ≈ 1.54 with ǫ = 0.5.
For comparison, when there is no jamming, it takes t ≈ 1.04
to achieve the same level of approximate consensus. In the
second simulation, we use the parameters κA = 5 and
ρA = 0.39. We present the results of this simulation in Figs.
6 and 7. It takes t ≈ 4 with ǫ = 0.5 to achieve approximate
consensus, which is longer than the ﬁrst simulation because the
attacker is given more energy. In these examples, the attacker
decides to attack all edges, since by attacking more edges the
defender has to recover more to increase the connectivity of
the graph, which makes the recovery interval shorter.

Next, we compare the strategies of the players under dif-
ferent graph structures. Speciﬁcally, we run simulations on
the path graph and the complete graph consisting of four
nodes, while all other parameters are set to be the same across
these two simulations. Fig. 8 shows the state trajectory and
Figs. 9 shows the remaining energy, the optimal combined
strategy, and the generalized edge connectivity versus time in
the path graph. The corresponding results for the complete
graph are shown in Figs. 10 and 11. We note that for the

 
 
 
e
t
a
t
S

4

3.5

3

2.5

2

1.5

1

0.5

0

0.5

1

1.5

2
Time

2.5

3

3.5

4

Fig. 6. State trajectories with κA = 5 and ρA = 0.39. The green areas
indicate the intervals where the defender recovers.

9

4

3

2

1

0

0

0.5

1

1.5

2
Time

2.5

3

3.5

4

t

e
a
S

t

Fig. 8. State trajectories in the system with the path graph G.

y
g
r
e
n
E
g
n
n
a
m
e
R

i

i

4

2

0

0

0.5

1

1.5

.
r
t

S

.
b
m
o
C

.
t
p
O

3

2b

2a

1

0

0.5

1

1.5

4

2

0

-2

-4

0

y
g
r
e
n
E
g
n
n
a
m
e
R

i

i

2

1

0

0

0.5

1

1.5

2
Time

2
Time

2.5

3

3.5

4

.
r
t

S

.

b
m
o
C

.
t

p
O

3

2b

2a

1

2.5

3

3.5

4

0

0.5

1

1.5

4

2

0

-2

-4

0

0.5

1

1.5

2
Time

2
Time

2
Time

2.5

3

3.5

4

2.5

3

3.5

4

2.5

3

3.5

4

0.5

1

1.5

2
Time

2.5

3

3.5

4

Fig. 7. Remaining energy and optimal combined strategy for the two players,
and the resulting bλ. In this case, the attacker attacks all edges to achieve
bλ(GA
k ) = −3, where the defender recovers brieﬂy in the ﬁrst game to make
the graph connected again.

complete graph the attacker chooses to attack for shorter
duration (Combined Strategy 2b) due to the high connectivity
of the graph structure. Speciﬁcally,
the attacker needs to
attack more edges (and hence takes more energy) to make
the graph disconnected, and therefore the maximum attack
interval becomes shorter compared to the attacks in the path
graph. This shorter maximum attack duration results in a
situation where the attacks on [τ D
k ] interval are not able to
compensate the negative payoff that the attacker receives on
the [τ D
k ] interval, causing the attacker to attack for only γD
duration instead. Consequently, consensus is achieved faster
in the complete graph than in the path graph. We can infer
that graph structures inﬂuence the attack and recovery actions
of the players, and graphs that have higher generalized edge
connectivity are more resilient to attacks.

k , τ A

k , τ A

l δD

k (mA

k ) and ∆D

We also provide an example of how the energy, which
affects the maximum attack/recovery durations, inﬂuences the
equilibrium. We consider the graph in Fig. 1 with selected
values of ∆A
k (mD
k ) in (9) by changing the
total consumed energy up to game (k − 1) represented as
k−1
k−1
l=1 βDmD
l δA
l=1 βAmA
l . The result is shown in
l and
k = mD
Fig. 12 for mA
k = 1. In the ﬁgure, the yellow circles
P
P
indicate that Combined Strategy 2b is optimal with attacking
k and ∆D
ﬁve edges for given ∆A
k , whereas the green squares
indicate that Combined Strategy 3 is optimal with attacking
ﬁve edges. The optimal strategy for the defender is to recover
one edge and three edges (to make the graph connected again,
e.g., {e12, e13, e34}) in the areas with light green and dark
green squares, respectively. The attacker attacks for longer
durations if it possesses high amount of energy relative to the
defender’s energy. On the other hand, the defender with more
energy will attempt to make the graph connected by recovering

Fig. 9. Remaining energy and optimal combined strategy for the two players,
and the resulting generalized edge connectivity in the system with the path
graph G.

to estimate the
more edges. Fig. 12 can also be useful
equilibrium based on the past actions and energy parameters.
The optimal combined strategies for varying βA and βD
are shown in Fig. 13. We note that Fig. 13 is similar to Fig. 3
in terms of characterizing the inﬂuence of the unit costs βA
and βD to the equilibrium, where the players tend not to
attack or recover if the costs become higher. However, the
critical values of βA and βD separating the optimal combined
strategies in this set of simulations are lower than those
found in Corollaries 3.5 and 3.6. These critical values of βA
and βD in the simulations are affected by generalized edge
connectivity of G in Fig. 1.

VI. CONCLUSION

In this paper, we have considered resilient network problem
in the context of multi-agent systems, formulated as a two-
player game between the attacker and defender. Their utilities
are determined by the communication among the agents. We
fully characterized the optimal strategies of the players in
terms of the edges and durations of action intervals. Several
cases are possible to happen depending on the available energy
of the players. For the consensus problem, we have shown that
the time for the agents to reach approximate consensus will
be delayed due to attacks by deriving an upper bound.

Note that in this paper, we have considered the generalized
edge connectivity as one speciﬁc way to measure the network
connectivity. In our recent paper [28], we consider clustering
of agents in the network and also take account of the cluster
sizes. It is also worth investigating other connectivity notions
and non-uniform unit costs for practical applications. In [29],
we have considered a problem formulation where not only the
available energy but also the agents’ states affect the results

 
 
 
 
 
 
10

t

e
a
S

t

4

3

2

1

0

0

0.5

1

1.5

2
Time

2.5

3

PSfrag replacements
3.5

4

Fig. 10. State trajectories in the system with the complete graph G.

y
g
r
e
n
E
g
n
n
a
m
e
R

i

i

2

1

0

0

0.5

1

1.5

2
Time

2.5

3

3.5

4

.
r
t

S

.
b
m
o
C

.
t
p
O

3

2b

2a

1

0

0.5

1

1.5

2
Time

2.5

3

PSfrag replacements
∆A
k (1)
∆D
k (1)
(mD
k = 1)
(mD
k = 3)

4

3.5

βA

4

2

0

-2

-4

15

∆A

k (1)

1

1

(mD

k = 1)

(mD

k = 3)

∆D

k (1)

10

Fig. 12. Optimal combined strategies for different ∆A
∆D

k (mD

k = 1).

k (mA

k = 1) and

0

0.5

1

1.5

2
Time

2.5

3

3.5

4

Fig. 11. Remaining energy and optimal combined strategy for the two
players, and the resulting generalized edge connectivity in the system with
the complete graph G.

of the optimal strategies; this provides a more direct relation
between the game and agents’ dynamics.

APPENDIX A: PROOF OF LEMMA 3.1

The

utility

(5)
=

function

rewritten
in
λG(mA, 0)δA −
as U A((mA, δA), (mD, δD))
λG(mA, mD) −
If
there is
(
λG(mA, 0)
λG(mA, mD) >
recovery, i.e., mD, δD > 0, then
according to the optimal strategy candidates. This implies that
b
−(

b
λG(mA, 0))δD < −

λG(mA, 0))δD − βAmAδA.

λG(mA, 0)δD holds.

λG(mA, mD) −

can
−

be

b

b

b

b

b

b

APPENDIX B: PROOF OF LEMMA 3.2
b
Substitute mA3∗ of (29) into (28) to obtain ˆU A3∗ =
λG(mA3∗, mD3∗))ξ + ˆU A2a(mA3∗). Since
λG(mA3∗, 0) −
(
λG(mA3∗, 0), it follows that ˆU A3∗ ≤
λG(mA3∗, mD3∗) >
ˆU A2a(mA3∗), and therefore ˆU A3∗ ≤ ˆU A2a∗.
b
b
b

APPENDIX C: PROOF OF LEMMA 3.3
First, we show that sgn( ˆU A2a∗) = sgn( ˆU A2b∗). We
can state ˆU A2a(mA) as ˆU A2a(mA) = ˆU A2b(mA) +
λG(mA, 0) − βAmA)(∆A + τ A − τ D). By (1), we have
(−
τ D ≤ τ A. Consequently, since τ A ≤ τ A + ∆A, we
have ∆A + τ A ≥ τ D for any possible ∆A. Therefore, if
b
λG(mA, 0) − βAmA > 0 is satisﬁed, then ˆU A2a(mA) > 0
−
and ˆU A2b(mA) > 0, and vice versa. Again, since ∆A + τ A ≥
τ D > τ A, it follows that ˆU A2b∗ > 0 if and only if ˆU A2a∗ > 0,
since the attacker can always choose edges to make ˆU A2a∗ and
ˆU A2b∗ positive. By a similar argument, ˆU A2b∗ < 0 if and only
if ˆU A2a∗ < 0. Thus, sgn( ˆU A2a∗) = sgn( ˆU A2b∗).

b

Now, since (−

λG(mA2a∗, 0) − βAmA2a∗) > 0 and ∆A +
τ A ≥ τ D, it then follows that ˆU A2a∗ ≥ ˆU A2b∗ if ˆU A2a∗ > 0.

b

βD

Fig. 13. Optimal combined strategies for different βA and βD. The optimal
numbers of edges are mA
k = 3 if the players decide to attack or
recover.

k = 5, mD

APPENDIX D: PROOF OF THEOREM 3.4

We prove this result using the backward induction method.
In Combined Strategy 1, recall that the attacker does not attack
and the defender does not recover, so ˆU A1 = ˆU D1 = 0.
the attacker chooses the optimal mA > 0 to
Therefore,
achieve positive utility. If the attacker attacks mA∗, then the
optimal strategy for the defender is to recover if and only if
U D((mA∗, δA∗), (mD∗, δD∗ > 0)) >

λG(mA∗)∆A.

Recall that the utility of a player also depends on the other
player’s strategy. For example, if the defender’s optimal strat-
egy is to recover (mD > 0) for given mA, then the attacker’s
utility for given mA is U A((mA, δA), (mD, δD > 0)).

b

By backward induction, the six facts (i)–(vi) below hold:
(i) From Lemmas 3.2 and 3.3, since ˆU A2a∗ > ˆU A3∗ and
ˆU A2a∗ has the same sign with ˆU A2b∗, Combined Strategy 1
is optimal if ˆU A2a∗ < 0 = ˆU A1, regardless of the defender’s
utility. This fact proves point 1) in the theorem.

2a

Strategy

Combined
the
is

Since the case where ˆU A2a∗ < 0 is covered, it is assumed
that ˆU A2a∗ ≥ 0 holds in all subsequent analysis for (ii)–(vi).
attacking
(ii)
mA2a∗
if
ˆU D3
less
2
the
than
defender
and
to recover
ˆU A2a∗ = U A((mA2a∗, ∆A), (0, 0)) is the maximum possible
utility for the attacker from Lemmas 3.2 and 3.3. This fact
corresponds to point 2)a) in the theorem.

= U D((mA2a∗, ∆A), (mD∗, ∆D > 0))
ˆU D2a

strategy
is
since
(mD∗ = 0)

U D((mA2a∗, ∆A), (0, 0)),

=
chooses not

combined

optimal

with

Since the case where ˆU D3

2 < ˆU D2a is covered, beginning
from (iii) to (vi), it is further assumed that ˆU D3
2 ≥ ˆU D2a, i.e.,
the defender chooses to recover from mA2a∗. Since mD2∗ >
0 and ˆU A2a∗ = U A((mA2a∗, ∆A), (0, 0)), in the subsequent
cases, the attacker’s optimal number of edges are not mA2a∗
(which corresponds to ˆU A2a∗). In (iii) and (iv), we analyze

 
 
 
b

the case where ˆU A3∗ ≥ ˆU A2b∗, which means that Strategy A3
yields more or equal utility than Strategy A2b for the attacker.
λG(mA, mD) = −1
(iii) Due to the possible jump between
λG(mA, mD) = 1 by recovering only one edge,
to
the
defender may have different optimal strategies (whether to
recover or not) given different attacked edges. From Lemma
3.1, since the attacker has better utility if the defender does
not recover, here the attacker’s optimal strategy is to at-
tack mA∗ if ˆU A3
0 = U A((mA∗, ∆A), (0, 0)) is greater than
ˆU A3∗ = U A((mA3∗, ∆A), (mD, ∆D > 0)), with mA∗ being
the optimal number of edges among the edges that cannot
be recovered if attacked, as in (35). Therefore, Strategies A1,
A2b, and A3 are not optimal. This corresponds to point 2)b)II)
in the theorem.

b

(iv) Otherwise, Combined Strategy 3 (point 4) in the theo-
0 ≤ ˆU A3∗. Here,
rem) is the optimal combined strategy if ˆU A3
the defender’s optimal strategy is to recover if the attacker
attacks mA3∗. Since ˆU A3∗ ≥ max{ ˆU A2b∗, 0}, the attacker
has better utility than in Strategies A1, A2a, and A2b.

In (v) and (vi), we analyze the case where ˆU A2b∗ > ˆU A3∗.
(v) Similar as in (iii), Combined Strategy 2a is the optimal
0 ≥ ˆU A2b∗. In this case, the attacker has better
strategy if ˆU A3
utility than in Strategies A1, A2b, and A3. However, since
2 ≥ ˆU D2a, the attacker does not attack mA2a∗. This fact
ˆU D3
corresponds to point 2)b)I) in the theorem.

(vi) If ˆU A3

0 < ˆU A2b∗, Strategy A2b is the optimal strategy
0 ) and utility
≥ ˆU D2a. This

for the attacker since ˆU A2b∗ > max( ˆU A3∗, ˆU A3
ˆU A2a∗ cannot be achieved because ˆU D3
corresponds to point 3) in the theorem.

2

λG(mA3∗, mD3∗) −

APPENDIX E: PROOF OF COROLLARY 3.5
In Strategy D3, since min{∆D, ∆A + τ A − τ D} > 0, the
necessary condition for Strategy D3 to be the optimal strategy
λG(mA3∗, 0))/mD3∗, i.e., the
is βD < (
cost of recovering edges is not too large. If this condition is
not satisﬁed, then it is better for the defender not to recover as
in Strategy D1. By recovering one edge the defender is able
λG(mA, 0))/mD = 2 at most. Thus,
to make (
if βD > 2, then the defender does not recover any edge.

λG (mA, mD) −

b

b

b
APPENDIX F: PROOF OF COROLLARY 3.6

b

b

From Theorem 3.4,

the attacker decides to attack if
ˆU A2a(mA2a∗) ≥ 0. Since ∆A > 0, Strategy A2a is the optimal
λG(mA2a∗, 0) − βAmA2a∗ ≥ 0, assuming that
strategy if −
the defender cannot recover. By Lemma 3.1, ˆU A2a(mA2a∗) >
ˆU A3(mA3∗), and thus Strategy A1 is the optimal strategy if
−

λG(mA2a∗, 0) − βAmA2a∗ < 0.
λG(mA2a∗, 0) −
Since βAmA2a∗ > 0,
to make −
βAmA2a∗ > 0, it must hold that
λG(mA2a∗, 0) < 0. Therefore,
b
the attacker must attack enough edges to make GA discon-
λG(mA2a∗, 0)/mA2a∗ cannot exceed 1, in
nected. Because −
order to obtain positive utility, βA ≤ 1 must be satisﬁed.

b

b

APPENDIX G: PROOF OF PROPOSITION 3.7
Since |E|= 1, the following four facts corresponding to

b

points 1) to 4) in Theorem 3.4 hold:

(i) Combined Strategy 1 is optimal if ˆU A2a∗ < 0. Since
λG(mA, 0) = −1 is always true if mA > 0. From

|E| = 1,
(19), it is clear that ˆU A2a∗ < 0 if βA > 1.

(ii) In order for Combined Strategy 2a to be optimal, a
common condition is that ˆU A2a∗ ≥ 0, which holds if βA ≤ 1.

b

11

0 = ˆU A2a∗ holds if βD > 2, otherwise ˆU A3

The condition ˆU D3
2 < ˆU D2a then holds if βD > 2. Note
that M consists of |E|= 1 if βD > 2 and empty otherwise.
Hence, ˆU A3
0 = 0
holds. Therefore, in point 2)b) in Theorem 3.4, condition
ˆU D3
2 ≥ ˆU D2a implies that ˆU A3
0 = 0 holds, which means
that the conditions 2)b)I) and 2)b)II) cannot be satisﬁed (from
Lemma 3.3).

(iii) Combined Strategy 2b is optimal if ˆU A2a∗ ≥ 0, which
2 ≥ ˆU D2a,
holds if βA ≤ 1. The other condition is that ˆU D3
which holds if βD ≤ 2. Conditions ˆU A2b∗ > ˆU A3
is always
true (see point (ii) in this proof above). With n = 2, condition
ˆU A2b∗ > ˆU A3∗ is true if βA > 1 −
∆A−τ D+τ A holds, with ξ
deﬁned in (26).

2ξ

0

(iv) It then follows that Combined Strategy 3 is optimal if
2 ≥ ˆU D2a (holds if βD ≤ 2),
2ξ
∆A−τ D+τ A ), under

ˆU A2a∗ ≥ 0 (holds if βA ≤ 1), ˆU D3
and ˆU A2b∗ ≤ ˆU A3∗ (holds if βA ≤ 1 −
which the condition ˆU A3∗ ≥ ˆU A3
holds.

0

APPENDIX H: PROOF OF PROPOSITION 4.1

The agents do not face any attacks during the intervals
k ), k ∈ N. Thus, from (37),
˙x(t) = −Lx(t), t ∈
k ), k ∈ N. Noting that τ A
k = tk + γA, we obtain
k ) = P x(tk), k ∈ N. Now by using Lemma 12.8 of

[tk, τ A
[tk, τ A
x(τ A
[3], it follows that
V (x(τ A

k )) = V (P x(tk)) ≤ (1 − p)V (x(tk)).

(41)

During the intervals [τ A

there may be
attacks and the communication between certain agents may
be jammed. It then follows from (37) that

k , tk+1), k ∈ N,

V (x(tk+1)) ≤ V (x(τ A

k )),

k ∈ N.

(42)

By (41) and (42), V (x(tk+1)) ≤ (1 − p)V (x(tk)), and thus,
V (x(tk+1)) ≤ (1 − p)kV (x(t1)) = (1 − p)kV (x0), k ∈ N.
(43)

Let k∗ :=
holds V (x(tk∗+1)) ≤ ǫ, and therefore,

(ln ǫ − ln V (x0))/ln(1 − p)
m
t ≥ tk∗+1.

x(t) ∈ Dǫ,

l

. By (43), it clearly

(44)

Our next goal is to ﬁnd an upper bound of tk∗+1. First,
the attacker given in (8),
k ≤ κA + ρAtk∗+1 holds. As indicated by the
k = 0 implies

by the energy constraint
βA
k δA
optimal strategies derived in Theorem 3.4, mA
P
that δA

k∗
k=1 mA

k , which implies

k ≥ δA

k δA

for

k = 0. Hence, we have mA
k∗

k∗

δA
k ≤

k=1
X
Next, by (7),

1
βA βA

mA

k δA

k ≤

k=1
X

κA
βA +

ρA
βA tk∗+1.

(45)

tk+1 = tk ≤ tk + γA + γD + δA
k ,

k ∈ N.

(46)

It then follows from (45) and (46) that tk∗+1 =
tk) ≤ (γA + γD)k∗ + κA

βA + ρA

βA tk∗+1, and hence,
P
+ κA
βA

ln ǫ−ln V (x0)
ln(1−p)

(γA + γD)

k∗
k=1(tk+1 −

tk∗+1 ≤

(cid:24)
1 − ρA
βA

(cid:25)

.

(47)

Finally, by (44) and (47), we obtain (40).

12

REFERENCES

[1] W. Ren and R. W. Beard, “Consensus seeking in multiagent systems
under dynamically changing interaction topologies,” IEEE Trans. Autom.
Contr., vol. 50, pp. 655–661, 2005.

[2] M. Mesbahi and M. Egerstedt, Graph Theoretic Methods in Multiagent

Networks. Princeton University Press, 2010.

[3] F. Bullo, Lectures on Network Systems, 1st ed. Kindle Direct Publishing,

2019.

[4] H. Sandberg, S. Amin, and K. H. Johansson, “Special issue on cy-
berphysical security in networked control systems,” IEEE Control Syst.
Mag., vol. 35, pp. 20–23, 2015.

[5] T. Alpcan and T. Basar, Network Security: A Decision and Game-

Theoretic Approach. Cambridge University Press, 2010.

[6] Q. Zhu and T. Basar, “Game-theoretic methods for robustness, security,
and resilience of cyberphysical control systems: Games-in-games prin-
ciple for optimal cross-layer resilient control systems,” IEEE Control
Syst. Mag., vol. 35, pp. 46–65, 2015.

[7] Y. Li, D. E. Quevedo, S. Dey, and L. Shi, “SINR-based DoS attack
on remote state estimation: A game-theoretic approach,” IEEE Trans.
Control Netw. Syst., vol. 4, pp. 632–642, 2017.

[8] Y. Li, L. Shi, P. Cheng, J. Chen, and D. Quevedo, “Jamming attacks
on remote state estimation in cyber-physical systems: A game-theoretic
approach,” IEEE Trans. Autom. Contr., vol. 60, pp. 2831–2836, 2015.

[9] A. Gupta, A. Nayyar, C. Langbort, and T. Basar, “A dynamic transmitter-
jammer game with asymmetric information,” in Proc. IEEE Conf. Dec.
Contr., 2012, pp. 6477–6482.

[10] Y. Li, L. Xiao, J. Liu, and Y. Tang, “Power control Stackelberg game
in cooperative anti-jamming communications,” in Proc. Int. Conf. Game
Theory for Netw., 2014.

[11] D. Yang, G. Xue, J. Zhang, A. Richa, and X. Fang, “Coping with a
smart jammer in wireless networks: A stackelberg game approach,” IEEE
Trans. Wireless Commun., vol. 12, pp. 4038–4047, 2013.

[12] A. Khanafer, B. Touri, and T. Basar, “Consensus in the presence of an
adversary,” in Proc. IFAC Workshop Dist. Est. Contr. Netw. Sys., 2012,
pp. 276–281.

[13] D. Senejohnny, P. Tesi, and C. De Persis, “A jamming resilient algorithm
for self-triggered network coordination,” IEEE Trans. Control Netw.
Syst., vol. 5, pp. 981–990, 2018.

[14] K. Kikuchi, A. Cetinkaya, T. Hayakawa, and H. Ishii, “Stochastic
communication protocols for multi-agent consensus under jamming
attacks,” in Proc. IEEE Conf. Dec. Contr., 2017, pp. 1657–1662.
[15] S. Feng and P. Tesi, “Resilient control under denial-of-service: Robust

design,” Automatica, vol. 79, pp. 42–51, 2017.

[16] C. De Persis and P. Tesi, “Input-to-state stabilizing control under denial-
of-service,” IEEE Trans. Autom. Contr., vol. 65, pp. 2930–2944, 2015.
[17] A. Cetinkaya, H. Ishii, and T. Hayakawa, “Networked control under
losses,” IEEE Trans. Autom. Contr.,

random and malicious packet
vol. 62, pp. 2434–2449, 2017.

[18] ——, “The effect of time-varying jamming interference of networked
stabilization,” SIAM J. Control Optim., vol. 56, pp. 2398–2435, 2018.
[19] H. J. LeBlanc, H. Zhang, X. Koutsoukos, and S. Sundaram, “Resilient
asymptotic consensus in robust networks,” IEEE J. Sel. Areas Commun.,
vol. 31, pp. 766–781, 2013.

[20] S. M. Dibaji, H. Ishii, and R. Tempo, “Resilient randomized quantized
consensus,” IEEE Trans. Autom. Contr., vol. 63, pp. 2508–2522, 2018.
[21] L. Guerrero-Bonilla, A. Prorok, and V. Kumar, “Formations for resilient
robot teams,” IEEE Robot. Autom. Lett., vol. 2, pp. 841–848, 2017.
[22] M. Huang, S. Dey, G. N. Nair, and J. H. Manton, “Stochastic consensus
over noisy networks with Markovian and arbitrary switches,” Automat-
ica, vol. 46, pp. 1571–1583, 2010.

[23] R. Carli, G. Como, P. Frasca, and F. Garin, “Distributed averaging on
digital erasure networks,” Automatica, vol. 47, pp. 115–121, 2011.
[24] J. Chen, C. Touati, and Q. Zhu, “A dynamic game approach to strategic
design of secure and resilient infrastructure network,” IEEE Trans. Inf.
Forensics Security, vol. 15, pp. 462–474, 2020.

[25] Y. Nugraha, A. Cetinkaya, T. Hayakawa, H. Ishii, and Q. Zhu, “Subgame
perfect equilibrium analysis for jamming attacks on resilient graphs,” in
Proc. Amer. Contr. Conf., 2019, pp. 2040–2045.

[26] R. Motwani and P. Raghavan, Randomized Algorithms.

Cambridge

University Press, 1995.

[27] O. Goldschmidt and D. S. Hochbaum, “A polynomial algorithm for
the k-cut problem for ﬁxed k,” Mathematics of Operations Research,
vol. 19, pp. 24–37, 1994.

[28] Y. Nugraha, A. Cetinkaya, T. Hayakawa, H. Ishii, and Q. Zhu, “Dynamic
resilient graph games for jamming attacks considering connectivity
measures,” submitted.

[29] ——, “Dynamic resilient graph games for state-dependent

jamming
attacks analysis on multi-agent systems,” in Proc. IFAC World Congress,
2020, to appear.

