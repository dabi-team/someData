1
2
0
2

r
a

M
8
2

]

R
C
.
s
c
[

1
v
0
8
0
8
0
.
4
0
1
2
:
v
i
X
r
a

CyberLearning: Eﬀectiveness Analysis of Machine
Learning Security Modeling to Detect Cyber-Anomalies
and Multi-Attacks

Iqbal H. Sarker1,2∗

1Department of Computer Science and Engineering,
Chittagong University of Engineering & Technology,
Chittagong-4349, Bangladesh.
2Swinburne University of Technology,
Melbourne, VIC-3122, Australia.
*Corresponding email: msarker@swin.edu.au
ORCID iD: https://orcid.org/0000-0003-1740-5517

Abstract

Detecting cyber-anomalies and attacks are becoming a rising concern these

days in the domain of cybersecurity. The knowledge of artiﬁcial intelligence,

particularly, the machine learning techniques can be used to tackle these is-

sues. However, the eﬀectiveness of a learning-based security model may vary

depending on the security features and the data characteristics. In this paper,

we present “CyberLearning”, a machine learning-based cybersecurity modeling

with correlated-feature selection, and a comprehensive empirical analysis on the

eﬀectiveness of various machine learning based security models.

In our Cy-

berLearning modeling, we take into account a binary classiﬁcation model for

detecting anomalies, and multi-class classiﬁcation model for various types of

cyber-attacks. To build the security model, we ﬁrst employ the popular ten ma-

chine learning classiﬁcation techniques, such as naive Bayes, Logistic regression,

Stochastic gradient descent, K-nearest neighbors, Support vector machine, De-

cision Tree, Random Forest, Adaptive Boosting, eXtreme Gradient Boosting,

as well as Linear discriminant analysis. We then present the artiﬁcial neural

network-based security model considering multiple hidden layers. The eﬀective-

ness of these learning-based security models is examined by conducting a range

of experiments utilizing the two most popular security datasets, UNSW-NB15

Preprint submitted to Journal: Internet of Things - Elsevier

April 19, 2021

 
 
 
 
 
 
and NSL-KDD. Overall, this paper aims to serve as a reference point for data-

driven security modeling through our experimental analysis and ﬁndings in the

context of cybersecurity.

Keywords: cybersecurity; machine learning; deep learning;

classification; feature selection; anomaly detection;

cyber-attacks; security intelligence; cyber data analytics;

intelligent systems.

1. Introduction

In recent days, the demand for cybersecurity and protection against cyber-

anomalies and various types of attacks, such as unauthorized access, denial-

of-service (DoS), botnet, malware, or worms has been ever increasing. Such

anomalies led to irreparable damage and ﬁnancial losses in large-scale computer

networks [1] [2]. For example, one ransomware virus in May 2017 caused tremen-

dous losses to many organizations and sectors, including banking, medical care,

electricity, and universities, and caused a loss of 8 billion dollars [3].

In the

domain of cybersecurity, such security breaches or intrusions have become the

common issue these days while securing a cyber-system as well as an Internet

of Things (IoT) system. Although various traditional methods, such as ﬁre-

walls, encryption, etc., are designed to handle Internet-based cyber-attacks, an

intelligent system that eﬀectively detects such anomalies or attacks, is the key

to tackle these issues. Thus, in this paper, we mainly focus on the knowledge

of artiﬁcial intelligence, particularly, the applicability of machine learning se-

curity modeling, which could be more eﬀective due to its automated learning

capabilities from the training security data.

Developing machine learning-based security models to analyze various cyber-

attacks or anomalies, and eventually detect or predict the threats can be used

for intelligent security services [4]. Typically, the detection models could be

for handling multiple associated cyber-attacks, i.e., “multi-class” problem, or to

detect anomalies, i.e., “binary-class” problem. Several recent research, such as

2

to detect botnet attack [5], attack and anomaly detection analysis in IoT sensors

in IoT site [6], classifying attacks to build an intrusion detection system [7], to

detect the anomalous network connections and classifying the normal traﬃc

and attack [8], etc. have been done in the area. Although several machine

learning techniques are used for diﬀerent purposes, these are limited to analyze

the variations in the signiﬁcance of the security features, or to conduct the

empirical analysis in a small range in terms of techniques used for security

intelligence modeling. These are discussed brieﬂy in Section 2, and summarized

in Table 1. Moreover, in case of unknown attacks, the abnormal behaviors that

are considered as anomalies, which is diﬀerent from the normal traﬃc, and the

relevant model can be used in many security solutions [1] [9]. Thus to classify the

associated attacks in several well-known classes such as DoS, botnet, malware,

worms, etc. as well as to classify anomalies for unknown attacks from the normal

traﬃc is essential for intelligent modeling in the area of cybersecurity.

Diﬀerent machine learning models by taking into account the above-mentioned

issues may perform diﬀerently according to their learning capabilities from secu-

rity data. The reason is that the eﬀectiveness of a learning-based security model

may vary depending on the signiﬁcance of the associated security features and

the data characteristics.

In the real-world scenario, the cybersecurity issues

might be involved with a huge number of security features, several known or

unknown attack classes, or anomalies. Thus, an eﬀective feature selection tech-

nique and a robust classiﬁcation model usually consist of the construction of an

intelligent intrusion detection system. Various types of machine learning tech-

niques and their applicability in the area of cybersecurity, have been discussed

brieﬂy in Sarker et al.

[9], however a detailed empirical analysis is needed by

taking into account the above-mentioned issues to make an intelligent decision

in the area. Therefore, we aim to present a comprehensive empirical analysis on

the eﬀectiveness of various machine learning based security models by taking

into account the issues, to make an intelligent decision in such diverse real-world

scenarios in the area.

To address the issues mentioned above, in this paper, we present “Cyber-

3

Learning”, a machine learning-based security modeling by taking into account

the signiﬁcance of the security features, and relevant experimental analysis. In

our analysis, we take into account a binary classiﬁcation model for detecting

anomalies, and multi-class classiﬁcation model for detecting various types of

cyber-attacks, such as DoS, Backdoor, Worms, etc. In a binary-class classiﬁca-

tion model, the given security dataset is categorized into two classes, such as

‘normal’ or ‘anomaly’, whereas in a multi-class classiﬁcation model, the given

dataset is categorized into several attack classes, mentioned above. For model-

ing, we ﬁrst employ the popular ten machine learning classiﬁcation techniques,

such as Naive Bayes (NB), Logistic regression (LR), Stochastic gradient descent

(SGD), K-nearest neighbors (KNN), Support vector machine (SVM), Decision

Tree (DT), Random Forest (RF), Adaptive Boosting (AdaBoost), eXtreme Gra-

dient Boosting (XGBoost), Linear discriminant analysis (LDA), as well as Ar-

tiﬁcial Neural Network (ANN) based model, which is frequently used in deep

learning [10] [11]. For selecting features, we take into account the feature cor-

relation values, and then the resultant security model has been built based on

the selected features considering both the model accuracy and simplicity or

complexity. The main idea is that the learning-based model typically examines

the behavior of the network utilizing the data, ﬁnding the security patterns

for proﬁling the normal behavior, and thus detects the anomalies or associated

attacks. The eﬀectiveness of these learning-based security models is examined

by conducting a range of experiments utilizing the two most popular security

datasets, UNSW-NB15 [2] and NSL-KDD [12].

The contributions of this work can be summarized as follows.

• We ﬁrst highlight the importance of security features in a machine learning

security modeling to detect cyber-anomalies and multi-attacks. Thus we

adopt a correlated-feature selection approach to reduce the insigniﬁcant

or irrelevant security features, which makes the security model lightweight

and more applicable.

• We present a binary classiﬁcation model for detecting cyber-anomalies or

4

unknown attacks, where the security model classiﬁes the data into two

classes, such as ‘normal’ and ‘anomaly’. We also analyze the eﬀectiveness

of various popular machine learning classiﬁcation models while detecting

such anomalies.

• We present a multi-class classiﬁcation model for detecting various cyber-

attacks, such as DoS, Backdoor, Worms, etc. where the security model

classiﬁes the data into these attack classes. We also analyze the eﬀec-

tiveness of various popular machine learning classiﬁcation models while

detecting such cyber-attacks.

• Finally, we conduct a range of experiments and present a comprehensive

empirical analysis on the eﬀectiveness of various machine learning classi-

ﬁcation based security modeling for unknown test cases.

The rest of the paper is organized as follows. Section 2 provides the back-

ground and related work of our study. In Section 3, we present our machine

learning-based security modeling by taking into account the signiﬁcance of the

security features. We evaluate the resultant security model and report the ex-

perimental results in Section 4. In Section 5, several key ﬁndings of our analysis

in the area are summarized. Finally, Section 6 concludes this paper and high-

lights the future work.

2. Background and Related Work

A number of research has been done in the area of cybersecurity with the

capability of detecting cyber-anomalies and attacks or intrusions.

In the cy-

ber industry, both the signature-based intrusion detection system (SIDS) and

anomaly-based intrusion detection systems (AIDS) are well-known for detect-

ing and preventing cyber-attacks [9]. SIDS is based on known signatures of the

attacks [13]. AIDS, on the other hand, has the beneﬁt of identifying invisible

threats over SIDS, including the ability to distinguish unknown or zero-day at-

tacks [14] [15]. Although association analysis is popular in the area of machine

5

learning to build rule-based intelligent systems [16] [17] [18], it might not be

eﬀective due to its redundant generation and complexity with higher dimen-

sions of security features while detecting anomalies or cyber-attacks. Thus, to

achieve our goal, in this work, we primarily focus on machine learning classiﬁ-

cation models [19], for security modeling because of their automated learning

capabilities from the security data.

Several machine learning techniques have been used for various purposes.

For instance, Li et al. [20] classify diﬀerent types of attacks such as DoS, Probe

or Scan, U2R, R2L, as well as regular traﬃc using SVM classiﬁer using the most

common KDD’99 cup dataset. Similarly, Amiri et al. [21], Wagner et al. [22],

Kotpalliwar et al.

[23], Saxena et al.

[24], Pervez et al.

[25], Li et al.

[20],

Shon et al. [26], Kokila et al. [27], and Raman et al. [7] used SVM classiﬁer in

their studies for the purpose of detecting attacks. Several other classiﬁers are

used to detect intrusions or attacks, in addition to the SVM classiﬁer mentioned

above. For example, a probability-based Bayesian network is used by Kruegel

et al. [28] to identify events processing TCP/IP packets. Benferhat et al. have

identiﬁed a DoS intrusion detector using the same Bayesian network in their

research [29]. Similarly, Panda et al.

[30], Koc et al.

[31] also use the naive

Bayes classiﬁer for detecting attacks in their systems.

Several studies [32] [33] have been conducted to classify malicious traﬃc

and intrusions using a logistic regression model. The KNN, an instance-based

learning algorithm, is another common method of machine learning where the

classiﬁcation of a point is determined by that data point’s k-nearest neighbors.

Vishwakarma et al.

[34], Shapoorifard et al.

[35], Shariﬁ et al.

[36] use KNN

classiﬁcation technique in their studies for the purpose of intrusion detection

systems. Authors in [37] consider neural classiﬁer, and in [38] consider wavelet

transform for anomaly detection particularly DoS attacks. A signiﬁcant number

of research in the domain of cybersecurity, such as Relan et al. [39], Rai et al.

[40], Ingre et al.

[41], Malik et al.

[8], [41], Puthran et al.

[42], Moon et al.

[43], Balogun et al. [44], Sangkatsanee et al. [45] use DT classiﬁcation approach

in their studies for the purpose of building intrusion detection systems. To

6

detect anomalies and address loT cybersecurity threats in smart city, Alrashdi

et al. [46] use RF learning consisting of multiple decision trees in their binary

classiﬁcation model. Mazini et al.

[47] use AdaBoost approach with feature

selection while building anomaly network-based intrusion detection system in

their work.

A machine learning security model for detecting anomalies has been pre-

sented in [1], which is eﬀective in terms of prediction accuracy as well as re-

ducing the feature dimensions based on the decision tree classiﬁcation approach

with feature selection. Recently, a machine learning-based botnet attack de-

tection framework with sequential detection architecture has been presented in

[5], where ANN, DT, and NB classiﬁcation techniques are used. Hasan et al.

[6] perform attack detection analysis in IoT sites, to develop a smart, secured,

and reliable IoT based infrastructure. Although several machine learning tech-

niques, such as SVM, DT, RF, LR, and ANN are used, the analysis is limited

to a small number of security features for detecting diﬀerent types of attacks.

Moreover, the variations in the signiﬁcance of the security features, which could

be a crucial part while building an eﬀective security model using machine learn-

ing techniques, are not addressed.

In the real-world scenario, the cybersecurity issues might be involved with

a huge number of security features, and the eﬀectiveness of a learning-based se-

curity model may vary depending on the signiﬁcance of the associated security

features and the data characteristics. Various types of machine learning tech-

niques and their applicability in the area of cybersecurity, have been discussed

in Sarker et al.

[9], however a detailed empirical analysis is needed to make

an intelligent decision in the area. Unlike the above approaches, in this paper,

we present “CyberLearning”, a machine learning-based cybersecurity model-

ing with correlated-feature selection according to their signiﬁcance in modeling,

and a comprehensive empirical analysis on the eﬀectiveness of various machine

learning-based security models. While building the security models, we take into

account a binary classiﬁcation model for detecting anomalies, and a multi-class

classiﬁcation model for detecting multi-attacks in the context of cybersecurity,

7

Table 1: A summary of machine learning based security models for detecting cyber-anomalies

and attacks

Purposes

Used Techniques

Type

References

To detect IoT-Botnet Attack

ANN, DT, NB and

Feature selection

Classifying attacks to build an

SVM and

efficient intrusion detection system

Feature selection

To design a host-based intrusion

LR and

detection system

Feature selection

To detect attacks in the

IoT environment

To build anomaly network-based

LR, SVM, DT,

RF, and ANN

AdaBoost and

intrusion detection system

, Feature selection

Detecting attacks to establish an

SVM and

efficient intrusion detection system

Feature removal

To classify network events as normal

NB and

or attack events

To detect intrusion to the cloud system

Feature selection

KNN and

Feature selection

To detect the anomalous network

DT

connections and classifying normal and attack

and pruning

Multiclass

Multiclass

Multiclass

Multiclass

Multiclass

Multiclass

Multiclass

Multiclass

Binary

To detect anomalies and address

loT cybersecurity threats in Smart City

RF learning

Binary

To detect anomalies in a network

DT and

and classifying normal and attack

Feature selection

To introduce cybersecurity data science

Overall machine

highlighting cyber-anomalies and attacks

learning perspective

Binary

–

NB, LDA, KNN, XGBoost,

Soe et al. [5]

(2020)

Raman et al. [7]

(2019)

Besharati et al. [33]

(2019)

Hasan et al. [6]

(2019)

Mazini et al. [47]

(2019)

Li et al. [20]

(2012)

Koc et al. [31]

(2012)

Sharifi et al. [36]

(2015)

Malik et al. [8]

(2018)

Alrashdi et al. [46]

(2019)

Sarker et al. [1]

(2020)

Sarker et al. [9]

(2020)

To detect cyber-anomalies and

DT, RF, SVM, SGD,

Binary and

CyberLearning

multi-attacks

AdaBoost, LR, ANN, and

Multiclass

(our analysis)

Feature selection

to provide a comprehensive view to the readers in the area. In Table 1, we also

summarize the most relevant machine learning-based security models within the

scope of our study for a clear understanding for the readers.

3. Materials and Methods

In this section, we present our security model of machine learning to detect

cyber-anomalies and attacks. This involved several processing steps: explor-

ing the security dataset, preparing raw data, determining the correlation and

ranking of features, and constructing a security model. We address these steps

brieﬂy in the following section in order to achieve our goal.

8

3.1. Exploring Security Dataset

Usually, security datasets reﬂect a series of information records consisting

of several security features and relevant details that can be used to construct a

security model [9] for detecting anomalies. Thus, to detect malicious activity or

anomalies, it is important to understand the nature of raw cybersecurity data

and the trends of security incidents.

In this work, we use the most popular

UNSW-NB15 [2] and NSL-KDD [12] security datasets, to build the data-driven

security model and the eﬀectiveness analysis.

Table 2: UNSW-NB15 Dataset features with value type.

Feature Name

Value Type

Feature Name

Value Type

srcip

dstip

proto

dur

dbytes

dttl

dloss

Sload

Spkts

swin

stcpb

smeansz

Sload

Spkts

swin

trans depth

Sjit

Stime

Sintpkt

tcprtt

ackdat

ct state ttl

is f tp login

ct srv src

ct dst ltm

ct src dport ltm

ct dst src ltm

Nominal

Nominal

Nominal

Float

Integer

Integer

Integer

Float

Integer

Integer

Integer

Integer

Float

Integer

Integer

Integer

Float

Timestamp

Float

Float

Float

Integer

Binary

Integer

Integer

Integer

Integer

sport

dsport

state

sbytes

sttl

sloss

Integer

Integer

Nominal

Integer

Integer

Integer

service

Nominal

Dload

Dpkts

dwin

dtcpb

dmeansz

Dload

Dpkts

dwin

res bdy len

Djit

Ltime

Dintpkt

synack

is sm ips ports

ct f lw http mthd

ct f tp cmd

ct srv dst

ct src ltm

ct dst sport ltmltm

Float

Integer

Integer

Integer

Integer

Float

Integer

Integer

Integer

Float

Timestamp

Float

Float

Binary

Integer

Integer

Integer

Integer

Integer

Nine types of attacks, including Fuzzers, Study, Backdoors, DoS, Exploits,

Generic, Reconnaissance, Shellcode, and Worms, are included in the UNSW-

NB15[2] dataset. It contains 257673 instances with the training and testing set

and 45 features. On the other hand, NSL-KDD [12] dataset contains the Denial

of Service Attack (DoS), User to Root Attack (U2R), Remote to Local Attack

(R2L), and Probing Attack. The raw data source consists of 494020 instances

9

with 41 security features that are taken into account in our experimental analy-

sis. The features can be in various types in a dataset. For instance, in Table 2,

we show the security features of the UNSW-NB15 dataset, where the features

are not identical. Thus eﬀectively analyzing these features and building a se-

curity model for detecting the anomalies and multi-attacks mentioned above, is

the key in our analysis.

3.2. Security Data Pre-Processing

Data preparation includes anomaly and attacks, feature encoding, and scal-

ing according to the characteristics of the given dataset.

• Anomaly and Attacks: As mentioned earlier, the dataset UNSW-NB15

[2] contains nine types of attacks. These are known as anomalies in this

dataset and are used in a binary classiﬁcation model, while all these sep-

arate attacks are used in a multi-class classiﬁcation model that is taken

into account in our analysis. Similarly, the four types of attacks such as

DoS, U2R, R2L, and Probing, are known as anomalies in NSL-KDD [12]

dataset and are used in the corresponding classiﬁcation model.

• Feature encoding: As shown in Table 2, the dataset UNSW-NB15 [2] con-

tains several feature types such as the nominal, integer, ﬂoat, timestamp,

and binary values. Thus, to ﬁt the data to the security model, we ﬁrst

convert all the nominal valued features into vectors. Although, “One Hot

Encoding” is a popular technique, we use “Label Encoding” in this work.

The reason is that, in one hot encoding technique, a signiﬁcant number

of feature dimensions increase [1]. The label-encoding technique, on the

other hand, transforms the feature values directly into precise numeric

values that can be used to ﬁt a classiﬁcation model for machine learning.

Similarly, the features in NSL-KDD [12] dataset are encoded to build the

resultant security model.

• Feature scaling: Feature scaling is also known as data normalization in the

task of data pre-processing. All the security features in a dataset may not

10

Figure 1: Secuity feature ‘sbyte(cid:48)

Figure 2: Secuity feature ‘synack(cid:48)

identical in terms of data distribution, and vary from feature to feature.

For instance, Figure 1 and Figure 2 show the data distribution for two

diﬀerent features, sbyte and synack respectively in the dataset UNSW-

NB15 [2]. According to Figure 1 and Figure 2, for some data points, the

value is very low while for some data points, it is much higher. Thus,

we use Standard Scaler, a data scaling method that is used to normalize

the range of the feature values with the mean value = 0 and standard

deviation = 1.

• Data Splitting: As we aim to build learning-based security modeling, data

splitting can be considered as an important part. The reason is that a good

security model may be based on bad data splitting. Thus, for building a

fair model and evaluation, we ﬁrst consider the data from data sources

as input data and split them using a k fold cross-validation technique

[48]. According to k fold cross-validation technique, we ﬁrst randomly

partition the input data mentioned above into k mutually exclusive subsets

or “folds”, d1, d2, ..., dk. Each fold has an approximately equal size of data

instances. The model needs k iteration to complete the overall process.

Thus, in each iteration i, we use all the data instances of all folds except

di as the training dataset that can be used to build the resultant security

model. For evaluation purpose di is used as the testing dataset in each

iteration i. Eventually, the average result is taken into account as the

outcome of the model.

11

3.3. Modeling Techniques

In our CyberLearning modeling, we take into account the impact of security

features while building the security model. In the following, we present how we

rank the features for selection, and various machine learning algorithms that

are employed to build the model, and eﬀectiveness analysis within the scope of

our study.

3.3.1. Feature Ranking and Selection

Feature selection in the cybersecurity domain can provide a better under-

standing of the security data, a way of simplifying the security model by reducing

the computational cost or model complexity, as well as providing signiﬁcant out-

comes in a machine learning-based model. Security dataset may contain data

with high dimensions, and some of them may be highly correlated to anomalies

or attacks, while some have less correlation or no correlation at all. Thus, in

order to create a machine learning classiﬁcation-based security model, all the

security features in a given dataset may not contain signiﬁcant details. In addi-

tion, due to the over-ﬁtting issue [1] [49], further processing with all the security

features could provide poor results. Thus, security feature selection is required

not only to reduce the computational cost but also to create a more eﬃcient

security model with a higher accuracy rate. Thus, security feature selection is

considered as a method that can be used to ﬁlter those features that are less

signiﬁcant, redundant, or have no impact on modeling, from the given security

dataset.

To achieve this goal, we ﬁrst calculate the correlation of the security features,

known as the Pearson correlation coeﬃcient, and rank them accordingly. The

correlation-based feature selection is based on the following hypothesis: “Good

feature subsets contain features highly correlated with the target class, yet un-

correlated or less correlated to each other”. If X and Y represent two random

contextual variables, then the correlation coeﬃcient between X and Y is deﬁned

12

as [48] -

r(X, Y ) =

(cid:80)n

i=1(Xi − ¯X)(Yi − ¯Y )

(cid:113)(cid:80)n

i=1(Xi − ¯X)2

i=1(Yi − ¯Y )2

(cid:113)(cid:80)n

(1)

In the ﬁeld of statistics, the formula Equ. 1 is often used to determine

how strong that relationship is between those two variables X and Y . In our

security modeling, the higher the value, the more signiﬁcant the security feature

for building the resultant learning-based security model. For instance, a value of

1 (max) means that the outcome of the learning-based security model is directly

associated with that security feature, and 0 (min) means that the output of the

model does not depend on that security feature at all. Thus, in the scope of our

analysis, we calculate the correlation coeﬃcient values of each security feature in

both our binary classiﬁcation modeling for detecting anomalies and multi-class

classiﬁcation modeling for detecting various types of attacks.

3.4. Machine Learning Algorithms and Parameters

In this section, we present how various machine learning classiﬁcation tech-

niques as well as ANN-based modeling with multiple hidden layers, are used in

our security modeling.

3.4.1. Naive Bayes (NB)

Na¨ıve Bayesian (NB) [50] is one of the common classiﬁcation techniques for

machine learning that is often used in the ﬁeld of machine learning and data

science. This is based on Bayes’s theorem that describes the probability of a

given feature, according to the prior knowledge of situations related to that

feature. Let, X = {x1, x2, ..., xn} is a security feature vector of size n, and c is a

class variable that represents the cyber-attacks or anomalies. Thus, it calculates

the probability (P ) using the following equation [48]:

P (c|X) =

P (X|c)P (c)
P (X)

(2)

13

P (c|x1, x2, ..., xn) =

P (x1|c)P (x2|c)...P (xn|c)P (c)
P (x1)P (x2)...P (xn)

(3)

To build a security model, we use the Gaussian Naive Bayes classiﬁer [51]

assuming all the security features are following a Gaussian distribution i.e, nor-

mal distribution. The prior probabilities of the classes in our security modeling

are adjusted according to the data. The portion of the largest variance of all

security features is added to the variances for calculation stability or smoothing.

3.4.2. Linear Discriminant Analysis (LDA)

In machine learning, Linear Discriminant Analysis (LDA) [48] is another

probability-based method to ﬁnd a linear combination of security features that

separates the anomaly or attack classes. This method is also known as a gener-

alization of Fisher’s linear discriminant, that projects a given security dataset

onto a lower-dimensional space, i.e., dimensionality reduction that minimizes

the model complexity or reduce the computational costs of the resultant secu-

rity model. Consequently, it has the capability for good class-separability to

avoid the problem of overﬁtting. Thus, the resulting combination mentioned

above can be used as a linear classiﬁer or, more speciﬁcally, for dimensionality

reduction of security features before performing the tasks of anomaly or attack

classiﬁcation. The standard LDA model typically ﬁts a Gaussian density to

each class such as ‘anomaly’ or ‘normal’ or various types of attacks, assuming

that all classes share the same covariance matrix [51]. For modeling, the LDA

approach also uses Bayes’ theorem mentioned above to estimate probabilities

and to make predictions of the class anomaly or various types of cyber-attacks

based upon the probability that a new input dataset belongs to each anomaly

or attack class. The class which has the highest probability is considered the

output anomaly or attack class, and then the LDA makes a prediction. In our

security modeling, we use singular value decomposition as a solver method

with no shrinkage to get the outcome. The prior probabilities of the classes in

our security modeling are inferred from the given security data.

14

3.4.3. K-nearest Neighbor (KNN)

K-nearest neighbors (KNN) [52], also known as a lazy learning algorithm,

is an instance learning or non-generalizing learning. Instead of using all data

instances during classiﬁcation, this approach does not have a specialized train-

ing process for constructing a model. Based on a ’feature similarity’ scale, it

classiﬁes new test cases, considering a distance function, such as M inkowski,

Euclidean, M anhattan distance etc [48]. Let, two variables X and Y , then the
M inkowski distance between these two variables is deﬁned as ((cid:80)

i |Xi − Yi|p)1/p , where p ≥

1. It can behave diﬀerently depending on p values, such as p = 1 and p = 2

represent Manhattan and Euclidean distance respectively.

d (X, Y ) =

(cid:118)
(cid:117)
(cid:117)
(cid:116)

n
(cid:88)

i=1

(Xi − Yi)2

(4)

In our security modeling, we take into account the most popular Euclidean

distance considering p = 2 [51], and can be deﬁned as Equ 4. The number

of neighbors indicating as k values is another key parameter in a KNN based

security modeling. Thus, we take into account k = 5, as the number of neigh-

bors, and uniform weights, where all points in each neighborhood are weighted

equally in our security modeling.

3.4.4. Decision Tree (DT)

Decision tree (DT) [53] is a well-known classiﬁcation framework for machine

learning, which is commonly used in various ﬁelds of use. A decision tree is a

method of non-parametric supervised learning that breaks down a given security

dataset into smaller subsets and incrementally generates a related branch of the

tree. For splitting, the most popular criteria are “gini” for the Gini impurity

and “entropy” for the information gain, which can be expressed mathematically

as [51].

Entropy : H(x) = −

n
(cid:88)

i=1

p(xi) log2 p(xi)

(5)

15

Gini(E) = 1 −

c
(cid:88)

i=1

2

pi

(6)

Where pi denotes the probability of an element being classiﬁed for a distinct

anomaly or attack class. To build a decision tree based security model, we use

“Gini Index” that is determined by deducting the sum of squared of probabilities

of each anomaly or attack class from 1 that can be expressed as Equ. 6. While

generating the tree considering both the anomaly or attack classes, nodes are

taken into account to expand until all leaves are pure or until all leaves contain

less than two sample instances.

3.4.5. Random Forest (RF)

In the ﬁeld of machine learning and data science, the random forest (RF) [54]

is well known as an ensemble classiﬁcation technique that is used in diﬀerent

application areas. This consists of multiple decision trees, where a decision

tree classiﬁer discussed above is used as a single tree in the forest model. This

combines the bootstrap aggregation (bagging) [55] with the random selection

of features [56] to create a collection of controlled variance decision trees. The

majority voting of the generated decision trees in a forest model is used to

measure the outcome. To build a random forest security model, we generate

N = 100 decision trees in the forest, where the quality of a split in a tree is

measured by ‘Gini’, deﬁned earlier in Equ. 6.

3.4.6. Support Vector Machine (SVM)

In machine learning, support vector machine (SVM) [48] is another popu-

lar classiﬁcation technique. This technique is based on a hyperplane between

the data space, which best divides the security dataset into two classes, such

as ‘anomaly’ or ‘normal’ and can behave diﬀerently based on the mathemat-

ical functions known as the kernel that can be diﬀerent types such as linear,

nonlinear, polynomial, radial basis function (RBF), sigmoid, etc. To build a

security model, we use the RBF kernel [57], also known as the Gaussian kernel,

16

considering no prior knowledge about the given security data. The RBF kernel

is mathematically deﬁned as -

k(x, y) = exp(−λ||x − y||2)

(7)

where λ is a parameter that sets the “spread” of the kernel. Based on this

RBF kernel function deﬁned in Equ. 7, this technique manipulates the given

security data accordingly to achieve the goal. Overall, it works in two stages,

including the identiﬁcation of the optimal hyperplane in the data space and then

the mapping of the security data instances according to the hyperplane’s deﬁned

decision boundaries. Moreover, we use C = 1.0 (regularization parameter),

considering the trade-oﬀ between achieving a low training error, and a low

testing error in a SVM based security model.

3.4.7. Logistic Regression (LR)

Another common probabilistic dependent statistical model used to solve the

classiﬁcation problems in machine learning is Logistic Regression (LR) [58].

Typically, logistic regression calculates the probabilities using a logistic equa-

tion, which is often referred to as the mathematically deﬁned sigmoid function

-

g(z) =

1
1 + exp(−z)

(8)

While building LR based security modeling, we use L2 regularization, i.e.,

Ridge regression that adds squared magnitude of coeﬃcient as penalty term to

the loss function. The “C” is similar to the SVM model. We also use Scikit-learn

solver “lbfgs” [51], which stands for Limited-memory Broyden–Fletcher–Goldfarb–Shanno,

to build the security model.

3.4.8. Adaptive Boosting (AdaBoost)

Boosting, a machine-learning algorithm, can be used for classiﬁcation that

is able to reduce bias and variance from the dataset. Boosting helps to con-

vert weak learners to strong ones. Adaptive Boosting (AdaBoost) is such an

17

algorithm formulated by Yoav Freund et al.

[59]. In that sense, AdaBoost is

called an adaptive classiﬁer by signiﬁcantly enhancing the eﬃciency of the clas-

siﬁer, but in some instances, it can trigger overﬁts. For noisy data and outliers,

AdaBoost is sensitive. We use a decision tree classiﬁer with maximum depth

(max depth = 1) as a base estimator. The maximum number of estimators is

taken into account as 50 at which boosting is terminated.

3.4.9. Extreme Gradient Boosting (XGBoost)

Gradient Boosting is another ensemble learning algorithm, similar to the

Random Forests discussed above, that creates a ﬁnal model based on a set of

individual models. Similar to how neural networks use gradient descent to op-

timize weights, the gradient is used to minimize the loss function. XGBoost

stands for Extreme Gradient Boosting, which is known as a special Gradient

Boosting method that takes into account more accurate approximations to ﬁnd

the best model. It computes second-order gradients of the loss function to min-

imize the loss and advanced regularization (L1 & L2), which reduces overﬁtting

and improves model generalization. We employ scikit-learn [51] API compatible

class while building a security model based on XGBClassiﬁer in our analysis.

3.4.10. Stochastic Gradient Descent (SGD)

Stochastic gradient descent (SGD) [48] is an iterative method for optimiz-

ing an objective function with suitable smoothness properties, where the word

‘stochastic’ means a system or a process that is linked with a random probabil-

ity. A gradient is the slope of a function that calculates a variable’s degree of

change in response to another variable’s changes. Gradient Descent is mathe-

matically a convex function whose output is a partial derivative of a set of its

input parameters. Let, α is the learning rate, and Ji is the cost of ith training

example, then Equ. 9 represents the weight update process for the stochastic

gradient descent at jth iteration.

wj

:= wj − α

∂Ji
∂wj

18

(9)

The greater the gradient, the steeper the slope. While building the security

model, we use a loss function ‘hinge(cid:48), which gives a linear SVM. Moreover, we

use L2 regularization similar to logistic regression and a constant alpha = 0.0001

that multiplies the regularization term while building the security model.

3.4.11. Artiﬁcial Neural Network (ANN)

Artiﬁcial Neural Network (ANN) is also a machine learning technique and

used typically in deep learning modeling, which is comprised of a network of

artiﬁcial neurons or nodes [48].

In this work, we build a feed-forward ANN-

based deep learning security model consisting of an input layer with the selected

security features, three hidden layers with 128 neurons, and an output layer with

one neuron for binary classiﬁcation, or the equal number of classes for multi-class

classiﬁcation task. We also use dropout in each layer to simplify the security

model and compile the neural network model with Adam optimizer [60].

ReLU : f (x) = max(0, x)

Sof tmax : f (yk) =

exp(φk)
j exp(φj)

(cid:80)c

Sigmoid : f (z) =

1
1 + e−z

Loss =






−(y log(p) + (1 − y) log(1 − p)) for binary

− (cid:80)M

c=1 yo,c log(po,c)

for multiclass

(10)

(11)

(12)

(13)

We use 100 epochs with a batch size of 128 when training the security net-

work. We often use a small value of 0.001 as the learning rate, as it enables

the global minimum to be reached by the security network model. We use the

Rectiﬁed Linear Unit (ReLU) described in Equ. with regard to the activation

function. 10, which addresses the problem of the vanishing gradient, as well

as helps the model to learn faster. However, we use the Softmax activation

function deﬁned in Equ. 11 for multi-class attack detection and the Sigmoid

19

or Logistic activation function deﬁned in Equ. 12 for binary classiﬁcation as it

exists between (0 to 1) in the output layer. To adjust the weights of the model,

we use the Cross-Entropy loss function, deﬁned in Equ. 13, where M represents

the number of attack classes c, y represents binary indicator, and p represents

probability observation o. The popular Backpropagation technique [48] is used

to adjust the connection weights between neurons of the security model during

learning.

4. Experimental Results and Analysis

In this section, we aim to brieﬂy analyze and report the experimental re-

sults of machine learning-based security modeling as well as artiﬁcial neural

network-based model utilizing the security datasets. For this, we ﬁrst set up

our experiments highlighting several questions to evaluate our security model,

and then brieﬂy discuss the experimental results and ﬁndings in various dimen-

sions related to our analysis of cyber-anomalies and multi-attacks detection.

4.1. Experimental Setup

To evaluate our CyberLearning model, we aim to answer the following ques-

tions:

• Question 1: Does the impact of the security features vary from feature to

feature while building a machine learning-based security model?

• Question 2: How eﬀective is the machine-learning-based security model

for detecting cyber-anomalies considering binary classiﬁcation?

• Question 3: How eﬀective is the machine-learning-based security model

for detecting multi-attacks considering multi-class classiﬁcation?

• Question 4: How eﬀective the artiﬁcial neural network-based security

model for detecting the anomalies and multi-class attacks?

20

To answer these questions related to our CyberLearning analysis, we have

conducted a range of experiments on security datasets consisting of the anoma-

lies and multi-attacks discussed in the earlier section. We have implemented all

these methods in Python programming language using Scikit-learn [51], Tensor-

ﬂow, and Keras [60], and executed them on Google Colab [61]. In the following

subsections, we ﬁrst deﬁne the evaluation metrics that are taken into account

in our experimental evaluation.

4.2. Evaluation Metric

To measure the eﬀectiveness of our CyberLearning model, we compute the

outcome results in terms of precision, recall, F-score, as well as model accuracy

in percentage. For this, we ﬁrst calculate the true positive rate (TP), true

negative rate (TN), false positive rate (FP), and false-negative rate (FN) that

are deﬁned as below [48] -

• TP (true positive): An outcome where the security model correctly detects

or classiﬁes the positive class of anomaly or attacks.

• TN (true negative): An outcome where the security model correctly de-

tects or classiﬁes the negative class of anomaly or attacks.

• FP (false positive): An outcome where the security model incorrectly

detects or classiﬁes the positive class of anomaly or attacks.

• FN (false negative): An outcome where the security model incorrectly

detects or classiﬁes the negative class of anomaly or attacks.

Based on these deﬁnitions of TP, TN, FP, and FN, we can compute the

precision, recall, F-score, accuracy as below [48] -

P recision =

T P
T P + F P

Recall =

T P
T P + F N

21

(14)

(15)

F 1 − score = 2 ∗

P recision ∗ Recall
P recision + Recall

Accuracy =

T P + T N
T P + T N + F P + F N

(16)

(17)

In the area of machine learning and data science, these metrics are well-

known and widely used to measure the eﬀectiveness of a model [48] [19]. The

greater the value the eﬀective the security model is. In the following subsection,

we discuss the experimental results brieﬂy and analyze the model eﬀectiveness

considering these metrics.

4.3. Impact of Security Features and Ranking

To answer the ﬁrst question mentioned above, in this experiment, we calcu-

late and show the impact of each feature based on their correlation values. Table

3 shows the calculated correlation scores of all the 42 security features utilizing

the given security dataset UNSW-NB15. The results are shown in a descending

order for detecting anomalies considering binary classiﬁcation, where the values

are arranged from the largest to the smallest number. If we observe Table 3, we

see that the calculated scores of all features are not identical in a given dataset,

and may vary from feature-to-feature according to their impact on the target

anomaly and attack classes.

22

Table 3: The ranking of the security features with corresponding correlation scores for detect-

ing anomalies utilizing the dataset UNSW-NB15.

Rank

Feature

Score

Rank

01

02

03

04

05

06

07

08

09

10

11

12

13

14

15

16

17

18

19

20

21

sttl

0.624082

ct state ttl

0.476559

state

0.462972

ct dst sport ltm

0.371672

swin

dload

dwin

rate

0.364877

0.352169

0.339166

0.335883

ct src dport ltm 0.318518

ct dst src ltm

0.299609

dmean

stcpb

dtcpb

ct src ltm

ct srv dst

ct srv src

ct dst ltm

sload

0.295173

0.266585

0.263543

0.252498

0.247812

0.246596

0.240776

0.165249

is sm ips ports

0.160126

sinpkt

dpkts

0.155454

0.097394

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

37

38

39

40

41

42

Feature

dloss

service

dbytes

djit

synack

spkts

dinpkt

dur

smean

tcprtt

sbytes

dttl

Score

0.075961

0.073552

0.060403

0.048819

0.043250

0.043040

0.030136

0.029096

0.028372

0.024668

0.019376

0.019369

response body len

0.018930

sjit

0.016436

ct f lw http mthd

0.012237

ct f tp cmd

is f tp login

proto

trans depth

sloss

ackdat

0.009092

0.008762

0.008023

0.002246

0.001828

0.000817

According to Table 3, the feature sttl has the highest score of 0.624082 and

thus selected as the top-ranked feature, whereas another feature ackdat has a

lower score of 0.000817 that is closer to the value 0 for this dataset, and thus

selected as the last ranked feature. These correlation scores may be diﬀerent

for another dataset depending on their features and classes. The higher the

correlation value, the more signiﬁcant the feature in a security model. Thus,

based on the scores, we can conclude that all the features in a given security

dataset might not have a similar impact to build a data-driven security model.

4.4. Eﬀectiveness Analysis for Detecting Cyber-Anomalies

To show the eﬀectiveness of the security models based on machine learn-

ing classiﬁers, Table 4 shows the eﬀectiveness comparison results in terms of

accuracy (%) for diﬀerent machine learning classiﬁer based anomaly detection

models considering binary classiﬁcation. The results in Table 4 are shown by

varying the number of selected features such as 42, 31, 24, and 17 utilizing the

dataset UNSW-NB15. These are selected according to their correlation scores

and ranking, shown in Table 3 considering a particular threshold. If we observe

23

the results in Table 4, we can see that various machine learning security models

have an impact on the number of selected features.

In general, higher accu-

racy results considering a minimum number of top-ranked features represent

the eﬀectiveness of the security models, in terms of both the detection outcome

and model complexity or simplicity. For instance, the NB security model gives

higher accuracy (85%) when the top 24 features are selected to build the model.

Similarly, RF and SVM security models also give higher accuracy (95%) and

(92%), when the top 24 features are selected to build the corresponding models.

Some models such as LDA, AdaBoost, SGD, and LR show their signiﬁcant re-

sults considering all the 42 features, while some models such as KNN, XGBoost

show their signiﬁcant results considering only the top 17 selected features. In

addition to RF (accuracy 95%), DT (accuracy 94%), and XGBoost (accuracy

93%) also give signiﬁcant results for detecting anomalies.

Table 4: Eﬀectiveness comparison results in terms of accuracy (%) for diﬀerent machine

learning classiﬁer based anomaly detection models utilizing the dataset UNSW-NB15.

Model

Features (42)

Features (31)

Features (24)

Features (17)

NB

LDA

KNN

XGBoost

DT

RF

SVM

AdaBoost

SGD

LR

82

89

92

93

94

95

92

93

89

90

83

87

92

93

94

95

92

92

88

88

85

87

92

93

93

95

92

92

88

87

75

84

92

93

92

94

91

92

86

84

In addition to Table 4, Figure 3 also shows the relative comparison of various

security models based on machine learning classiﬁers for detecting anomalies.

The comparative results are shown in terms of precision, recall, and F1 score

for diﬀerent numbers of top-ranked selected features such as 42, 31, 24, and 17

utilizing the dataset UNSW-NB15. For each security model, we use the same

train and testing data to calculate these metrics for fair evaluation.

If we observe Figure 3, we ﬁnd that tree-based classiﬁcation models give

higher prediction results than other security models, in terms of precision, re-

call, and F1 score, while applying on cybersecurity data consisting of various

24

(a) Anomaly detection with all 42 features

(b) Anomaly detection with top 31 features

(c) Anomaly detection with top 24 features

(d) Anomaly detection with top 17 features

Figure 3: Eﬀectiveness comparison results in terms of precision, recall, and F1 score for

diﬀerent machine learning classiﬁer based anomaly detection models utilizing the dataset

UNSW-NB15.

25

security features. In particular, the RF (Random Forest) based security model

generating multiple decision trees gives the prediction results with the highest

values of accuracy, recall, and F1 score for diﬀerent number of features, shown

in Figure 3. The interesting ﬁnding is that the RF model gives similar results

with the features of 42, 31, and 24, and a comparatively lower result with feature

17. The reason for decreasing the result is that it losses signiﬁcant information

while reducing the features. Thus, the RF model with the top 24 security fea-

tures is taken into account as an eﬀective model considering both the accuracy

and model complexity. Overall, based on the selected security features, we can

conclude that the RF model gives better results in detecting cyber anomalies.

The explanation is that the random forest model produces a collection of logical

rules based on the chosen security features that take into account multiple de-

cision trees created in the forest, and oﬀers an outcome based on the majority

vote of those trees.

Table 5: Eﬀectiveness comparison results in terms of accuracy (%), precision, recall, and F1

score for diﬀerent machine learning classiﬁer based anomaly detection models utilizing the

dataset NSL-KDD.

Model

Accuracy (%)

Precision

Recall

F1 Score

NB

LDA

KNN

XGBoost

DT

RF

SVM

AdaBoost

SGD

LR

98

99

99

99

99

99

99

98

99

98

0.98

0.99

0.99

0.99

0.99

0.99

0.99

0.98

0.99

0.98

0.98

0.99

0.99

0.99

0.99

0.99

0.99

0.98

0.99

0.98

0.98

0.99

0.99

0.99

0.99

0.99

0.99

0.98

0.99

0.98

In Table 5, we also show the eﬀectiveness comparison results utilizing an-

other widely used security dataset NSL-KDD. The results are shown in terms

of accuracy (%), precision, recall, and F-score, for diﬀerent machine learning

classiﬁer based anomaly detection models considering binary classiﬁcation. The

results in Table 5 are shown for the top ﬁve selected features according to their

correlation scores and ranking. If we observe the results in Table 5, we can see

that almost all the security models give signiﬁcant results (accuracy 99%) with

26

the selected top 5 features. Thus, we can conclude that machine learning-based

security models are highly dependent on the quality and characteristics of the

data, and may give diﬀerent results for diﬀerent datasets.

4.5. Eﬀectiveness Comparison for Detecting Multi-Attacks

To show the eﬀectiveness of the security models based on machine learn-

ing classiﬁers, Table 6 shows the eﬀectiveness comparison results in terms of

accuracy (%) for diﬀerent machine learning classiﬁer based attacks detection

models considering multi-class classiﬁcation. The results in Table 6 are shown

by varying the number of selected features such as 42, 31, 24, and 17 utilizing

the dataset UNSW-NB15. These features are selected similarly, i.e., according

to their correlation scores and ranking considering a particular threshold. If we

observe the results in Table 6, we can see that various machine learning security

models for detecting multi-attacks have also an impact on the number of se-

lected features. As higher accuracy results with a minimum number of features

represent the eﬀectiveness of the security models, the RF model is eﬀective with

the accuracy (83%) when the top 31 features are selected to build the model.

Similarly, XGBoost, DT, and SVM security models also give higher accuracy

(81%), (81%), and (79%), when the top 31 features are selected to build the

corresponding models. Several security models such as NB, LDA, KNN, and

AdaBoost show their signiﬁcant results considering the top 24 features, while

the LR model shows signiﬁcant results considering all the 42 features. Overall,

in addition to RF (accuracy 83%), DT (accuracy 81%), and XGBoost (accuracy

81%) also give signiﬁcant results for detecting multi-attacks.

27

Table 6: Eﬀectiveness comparison results in terms of accuracy (%) for diﬀerent machine

learning classiﬁer based multi-attacks detection models utilizing the dataset UNSW-NB15.

Model

Features (42)

Features (31)

Features (24)

Features (17)

NB

LDA

KNN

XGBoost

DT

RF

SVM

AdaBoost

SGD

LR

43

67

76

81

81

83

79

51

71

76

43

67

77

81

81

83

79

31

72

75

44

67

77

80

80

82

78

62

70

74

42

65

73

76

77

80

74

57

63

71

In addition to Table 6, Figure 4 also shows the relative comparison of various

security models based on machine learning classiﬁers for detecting multi-attacks

in terms of precision, recall, and F1 score utilizing the dataset UNSW-NB15.

For each security model, we use the same train and testing data to calculate

these metrics for fair evaluation.

If we observe Figure 4, we ﬁnd that tree-based classiﬁcation models also

provide higher prediction results in terms of accuracy, recall, and F1 score, for

multi-attack detection than other security models. In particular, the security

model based on RF (Random Forest) generating multiple decision trees gives

the prediction results with the highest accuracy, recall, and F1 score values,

shown in Figure 4. The interesting ﬁnding is that like the anomaly detection

model, the RF model gives similar results with the features of 42, 31, and 24,

and a comparatively lower result with the feature 17 for multi-attack detection.

The reason for decreasing the result is that it losses signiﬁcant information while

reducing the features. Thus, the RF model with the top 24 security features

is taken into account as an eﬀective model considering both the accuracy and

model complexity. Overall, we can conclude that the RF model gives better

results in detecting multi-attacks based on the selected security features. The

reason is that the random forest model generates a set of logic rules for the

attacks based on the selected security features considering several decision trees

generated in the forest, and provide an outcome based on the majority voting

of these trees.

28

(a) Multi-attacks detection with all 42 features (b) Multi-attacks detection with top 31 features

(c) Multi-attacks detection with top 24 features (d) Multi-attacks detection with top 17 features

Figure 4: Eﬀectiveness comparison results in terms of precision, recall, and F1 score for

diﬀerent machine learning classiﬁer based multi-attacks detection models utilizing the dataset

UNSW-NB15.

29

Table 7: Eﬀectiveness comparison results in terms of accuracy (%), precision, recall, and F1

score for diﬀerent machine learning classiﬁer based multi-attacks detection models utilizing

the dataset NSL-KDD.

Model

Accuracy (%)

Precision

Recall

F1 Score

NB

LDA

KNN

XGBoost

DT

RF

SVM

AdaBoost

SGD

LR

91

96

99

99

99

99

99

91

98

98

0.97

0.98

0.99

0.99

0.99

0.99

0.98

0.91

0.98

0.98

0.91

0.96

0.99

0.99

0.99

0.99

0.99

0.91

0.98

0.98

0.93

0.97

0.99

0.99

0.99

0.99

0.99

0.90

0.98

0.98

In Table 7, we also show the eﬀectiveness comparison results utilizing an-

other widely used security dataset NSL-KDD. The results are shown in terms of

accuracy (%), precision, recall, and F-score, for diﬀerent machine learning clas-

siﬁer based multi-attacks detection models considering multi-class classiﬁcation.

The results in Table 7 are shown for the top ﬁve selected features according to

their correlation scores and ranking. If we observe the results in Table 7, we

can see that most of the security models such as KNN, XGBoost, DT, RF, and

SVM give the highest results (accuracy 99%) with the selected top 5 features.

The other models also give signiﬁcant results. Based on the results discussed

above, we can conclude that machine learning-based security models are highly

dependent on the quality and characteristics of the data, and may give diﬀerent

results for diﬀerent datasets.

4.6. Eﬀectiveness Analysis for Neural Network-based Security Model

To show the model eﬀectiveness based on artiﬁcial neural network, Figure

5 shows the calculated outcome in terms of model accuracy and loss score for

detecting anomalies considering binary classiﬁcation. The results in Figure 5

are shown by varying the number of selected features such as 42, 31, 24, and

17 utilizing the dataset UNSW-NB15. The features are selected similarly, ac-

cording to their correlation scores and ranking, shown in Table 3 considering

a particular threshold mentioned above. Similarly, for multi-attacks classiﬁca-

tion, Figure 6 shows the calculated outcome in terms of model accuracy and

30

loss score considering multi-class classiﬁcation according to our goal. For each

neural network-based security model, we use the same train and testing data

for fair evaluation and comparison.

(a) Accuracy score with

(b) Accuracy score with

(c) Accuracy score with

(d) Accuracy score with

all 42 features.

the top 31 features.

the top 24 features.

the top 17 features.

(e) Loss score with all

(f) Loss score with the

(g) Loss score with the

(h) Loss score with the

42 features.

top 31 features.

top 24 features.

top 17 features.

Figure 5: Calculated outcome in terms of accuracy and loss score of the deep neural network

based security model for detecting anomalies utilizing the dataset UNSW-NB15.

(a) Accuracy score with

(b) Accuracy score with

(c) Accuracy score with

(d) Accuracy score with

all 42 features.

the top 31 features.

the top 24 features.

the top 17 features.

(e) Loss score with all

(f) Loss score with the

(g) Loss score with the

(h) Loss score with the

42 features.

top 31 features.

top 24 features.

top 17 features.

Figure 6: Calculated outcome in terms of accuracy and loss score of the neural network based

security model for detecting multi-attacks utilizing the dataset UNSW-NB15.

If we observe the results in Figure 5 and Figure 6, we can see that a neural

network-based security model with a variable number of selected features can

31

detect both the anomalies and multi-attacks. Similar to classic machine learning

classiﬁcation models, discussed above, we get higher accuracy results in anomaly

detection using the neural network-based security model. According to Figure 5,

the model with the top 24 features gives the results of 92% accuracy with a loss

of 0.1681, which is signiﬁcant in terms of accuracy and complexity, comparing

with other models with diﬀerent number of features, shown in Figure 5. Thus

model with the top 24 features can be selected as an eﬀective security model

that gives signiﬁcant accuracy with a reduced number of features for detecting

anomalies. Similarly, a model with the top 24 features can also be selected as

an eﬀective model for detecting multi-attacks, shown in Figure 6.

(a) Accuracy score with

(b) Accuracy score with

(c) Accuracy score with

(d) Accuracy score with

all 42 features.

the top 27 features.

the top 18 features.

the top 5 features.

(e) Loss score with all

(f) Loss score with the

(g) Loss score with the

(h) Loss score with the

42 features.

top 27 features.

top 18 features.

top 5 features.

Figure 7: Calculated outcome in terms of accuracy and loss score of the deep neural network

based security model for detecting anomalies utilizing the dataset NSL-KDD.

Besides, Figure 7 shows the calculated outcome in terms of model accuracy

and loss score for detecting anomalies considering binary classiﬁcation utilizing

another widely used dataset NSL-KDD. The results in Figure 7 are shown by

varying the number of selected features such as 42, 27, 18, and 5 utilizing the

dataset NSL-KDD. These are selected according to their correlation scores and

ranking considering a particular threshold as well. Similarly, for multi-attacks

classiﬁcation, Figure 8 shows the calculated outcome in terms of model accuracy

and loss score considering multi-class classiﬁcation. According to Figure 7, the

32

(a) Accuracy score with

(b) Accuracy score with

(c) Accuracy score with

(d) Accuracy score with

all 42 features.

the top 27 features.

the top 18 features.

the top 5 features.

(e) Loss score with all

(f) Loss score with the

(g) Loss score with the

(h) Loss score with the

42 features.

top 27 features.

top 18 features.

top 5 features.

Figure 8: Calculated outcome in terms of accuracy and loss score of the deep neural network

based security model for detecting multi-attacks utilizing the dataset NSL-KDD.

model with the top 18 features gives the results of 99% accuracy with a loss

of 0.0243, which is signiﬁcant in terms of accuracy and complexity, comparing

with other models with diﬀerent number of features, shown in Figure 7. Thus

model with the top 18 features can be selected as an eﬀective security model

that gives signiﬁcant accuracy with a reduced number of features for detecting

anomalies. Similarly, a model with the top 27 features can also be selected as

an eﬀective model for detecting multi-attacks, shown in Figure 8.

5. Discussion

Overall, our CyberLearning model based on machine learning approaches is

fully security data-oriented that reﬂects the data patterns related to the secu-

rity incidents, e.g., cyber-anomalies and attacks, according to our goal. The

model can eﬀectively detect anomalies and diﬀerent types of attacks, such as

DoS, Backdoor, Worms, etc, where the popular machine learning classiﬁcation

techniques including artiﬁcial neural network models are employed. The ex-

perimental analysis on the UNSW-NB15 [2] and NSL-KDD [12] datasets, have

shown the eﬀectiveness of the resultant security models according to their learn-

ing capabilities in various situations, as discussed in the earlier section.

33

According to the experimental analysis discussed in Section 4, we can say

that diﬀerent machine learning-based security models perform diﬀerently for

detecting cyber-anomalies, or multi-attacks utilizing the training security data.

The signiﬁcance of the security features greatly impact both the binary clas-

siﬁcation model while detecting anomalies for unknown attacks, as well as the

multi-class classiﬁcation model while detecting several known classes mentioned

above. For instance, according to experimental results shown in Table 3, the

feature sttl has the highest correlation score of 0.624082 and thus selected as the

highly signiﬁcant feature, whereas another feature ackdat has a lower score of

0.000817 that is closer to the value 0 for the dataset UNSW-NB15 [2], and thus

can be considered as the less signiﬁcant feature for modeling. A set of highly

signiﬁcant security features reducing the insigniﬁcant or irrelevant features can

help to make the security model lightweight and more applicable. For instance,

the NB security model gives higher accuracy (85%) when the top 24 features are

selected for detecting cyber-anomalies, rather than considering all 42 features

as shown in Table 4. Overall, the security models for detecting anomalies and

attacks, based on various learning algorithms are also aﬀected by the variations

in the signiﬁcance of the security features, as discussed brieﬂy in Section 4.

Besides, a robust classiﬁcation model is essential to the design of an in-

telligent intrusion detection system. The reason is that the performance of all

machine learning classiﬁcation techniques are not identical in the real world sce-

nario, depending on their learning capabilities from the security data. As shown

in Table 4, and Figure 3, the RF-based security model generating multiple de-

cision trees, give higher prediction results for detecting anomalies than other

security models, in terms of accuracy, precision, recall, and F1 score. Several

other models such as DT, XGBoost, SVM, KNN, AdaBoost also give signiﬁ-

cant outcome based on the selected features. According to the results, shown

in Table 5, the RF model also gives higher accuracy for detecting anomalies.

As shown in the Table 6, Figure 4, the RF-based security model also gives

higher prediction results for detecting multi-attacks than other security models,

in terms of accuracy, precision, recall, and F1 score. Several other models such

34

as DT and XGBoost also give signiﬁcant outcome based on the selected features

while detecting multi-attacks. According to the results, shown in Table 5, the

RF model also gives higher accuracy for detecting multi-attacks.

The model performance for detecting multi-attacks may diﬀer with the

anomaly detection mentioned above, even for the same learning technique. For

instance, the accuracy of the RF security model for detecting anomalies is 95%,

and 83% for multi-attacks detection for the dataset UNSW-NB15 [2]. Similarly,

it achieves 99% for both cases for the dataset NSL-KDD [12]. Thus, we can say

that the eﬀectiveness of a learning-based security model may vary depending

on the security features and the data characteristics. Overall, we can conclude

that RF (Random Forest) based security model is more eﬀective for detecting

anomalies and multi-attacks. The reason is that the random forest model has

the learning capabilities considering several decision trees that generate a set of

logic rules based on the selected security features. Thus, the model gives higher

prediction results in terms of accuracy, precision, recall, and F1 score.

A real-life cybersecurity application is the actual platform to use the Cy-

berLearning model that typically examines the behavior of the network, ﬁnding

the security patterns for proﬁling the normal behavior, and thus detects the

anomalies or associated attacks. Although an ANN model has its hidden layers

for computing, it also aﬀects on the signiﬁcance of the features. For instance,

an ANN model with the selected security features gives signiﬁcant accuracy for

detecting anomalies and multi-attacks, as discussed brieﬂy in Section 4. Al-

though we use the security datasets UNSW-NB15 [2] and NSL-KDD [12] while

building the security model, our analysis is also applicable to other applica-

tion domains in the area of cybersecurity, including IoT security. Several deep

learning networks such as Convolutional neural network (CNN), recurrent neu-

ral network (RNN), Long Short-Term Memory (LSTM), deep belief network

(DBN), or an autoencoder, etc. could be eﬀective while working on a huge

number of datasets. Typically deep learning algorithms perform well when the

data volumes are large [9] [62]. In addition, noisy instance analysis [63], incor-

porating contextual information [18] [64], or recency analysis considering recent

35

patterns in data [65], could be another potential research dimensions in the area.

Overall, we believe that our CyberLearning model including a comprehensive

experimental analysis opens a promising path for future research in the domain

of cybersecurity, while working on machine learning-based security modeling, to

make the security model lightweight and more applicable in the area.

6. Conclusion and Future Work

In this paper, we have presented CyberLearning, where we have taken into

account a binary classiﬁcation model for detecting anomalies and a multi-class

classiﬁcation model for various types of cyber-attacks. In our modeling, we have

also taken into account the impact of security features, and eventually built a

machine learning based eﬀective model with feature selection. While build-

ing the security models, we have employed the most popular machine learning

classiﬁcation techniques as well as artiﬁcial neural network learning considering

multiple hidden layers. Finally, we have examined the eﬀectiveness of these

learning-based security models by conducting a range of experiments utilizing

the two most popular security datasets, UNSW-NB15 and NSL-KDD. We be-

lieve that our empirical analysis and ﬁndings can be used as a reference guide in

both academia and industry in the area of cybersecurity for eﬀectively building

a data-driven security modeling and system based on machine learning tech-

niques.

To collect more recent security data with higher dimensions in the environ-

ment of IoT, and build a data-driven secure system using learning techniques

could be a future work.

References

[1] I. H. Sarker, Y. B. Abushark, F. Alsolami, A. I. Khan, Intrudtree: A

machine learning based cyber security intrusion detection model, Symmetry

12 (5) (2020) 754.

36

[2] N. Moustafa, J. Slay, Unsw-nb15: a comprehensive data set for network

intrusion detection systems (unsw-nb15 network data set), in: 2015 military

communications and information systems conference (MilCIS), IEEE, 2015,

pp. 1–6.

[3] X. Qu, L. Yang, K. Guo, L. Ma, M. Sun, M. Ke, M. Li, A survey on the

development of self-organizing maps for unsupervised intrusion detection,

Mobile Networks and Applications (2019) 1–22.

[4] I. H. Sarker, Ai-driven cybersecurity: An overview, security intelligence

modeling and research directions, SN Computer Science (2021).

[5] Y. N. Soe, Y. Feng, P. I. Santosa, R. Hartanto, K. Sakurai, Machine

learning-based iot-botnet attack detection with sequential architecture,

Sensors 20 (16) (2020) 4372.

[6] M. Hasan, M. M. Islam, M. I. I. Zarif, M. Hashem, Attack and anomaly

detection in iot sensors in iot sites using machine learning approaches, In-

ternet of Things 7 (2019) 100059.

[7] M. G. Raman, N. Somu, S. Jagarapu, T. Manghnani, T. Selvam,

K. Krithivasan, V. S. Sriram, An eﬃcient intrusion detection technique

based on support vector machine and improved binary gravitational search

algorithm, Artiﬁcial Intelligence Review (2019) 1–32.

[8] A. J. Malik, F. A. Khan, A hybrid technique using binary particle swarm

optimization and decision tree pruning for network intrusion detection,

Cluster Computing 21 (1) (2018) 667–680.

[9] I. H. Sarker, A. Kayes, S. Badsha, H. Alqahtani, P. Watters, A. Ng, Cy-

bersecurity data science: an overview from machine learning perspective,

Journal of Big Data 7 (1) (2020) 1–29.

[10] I. H. Sarker, Machine learning: Algorithms, real-world applications and

research directions, SN Computer Science (2021).

37

[11] I. H. Sarker, Deep cybersecurity: A comprehensive overview from neural

network and deep learning perspective, SN Computer Science (2021).

[12] M. Tavallaee, E. Bagheri, W. Lu, A. A. Ghorbani, A detailed analysis

of the kdd cup 99 data set, in: 2009 IEEE symposium on computational

intelligence for security and defense applications, IEEE, 2009, pp. 1–6.

[13] S. Seufert, D. O’Brien, Machine learning for automatic defence against dis-

tributed denial of service attacks, in: 2007 IEEE International Conference

on Communications, IEEE, 2007, pp. 1217–1222.

[14] A. Alazab, M. Hobbs, J. Abawajy, M. Alazab, Using feature selection for

intrusion detection system, in: 2012 International Symposium on Commu-

nications and Information Technologies (ISCIT), IEEE, 2012, pp. 296–301.

[15] A. L. Buczak, E. Guven, A survey of data mining and machine learning

methods for cyber security intrusion detection, IEEE Communications sur-

veys & tutorials 18 (2) (2015) 1153–1176.

[16] R. Agrawal, R. Srikant, et al., Fast algorithms for mining association rules,

in: Proc. 20th int. conf. very large data bases, VLDB, Vol. 1215, 1994, pp.

487–499.

[17] I. H. Sarker, A. Kayes, Abc-ruleminer: User behavioral rule-based machine

learning method for context-aware intelligent services, Journal of Network

and Computer Applications (2020) 102762.

[18] I. H. Sarker, Context-aware rule learning from smartphone data: survey,

challenges and future directions, Journal of Big Data 6 (1) (2019) 95.

[19] I. H. Sarker, A. Kayes, P. Watters, Eﬀectiveness analysis of machine learn-

ing classiﬁcation models for predicting personalized context-aware smart-

phone usage, Journal of Big Data (2019).

[20] Y. Li, J. Xia, S. Zhang, J. Yan, X. Ai, K. Dai, An eﬃcient intrusion de-

tection system based on support vector machines and gradually feature

removal method, Expert Systems with Applications 39 (1) (2012) 424–430.

38

[21] F. Amiri, M. R. Youseﬁ, C. Lucas, A. Shakery, N. Yazdani, Mutual

information-based feature selection for intrusion detection systems, Journal

of Network and Computer Applications 34 (4) (2011) 1184–1199.

[22] C. Wagner, J. Fran¸cois, T. Engel, et al., Machine learning approach for ip-

ﬂow record anomaly detection, in: International Conference on Research

in Networking, Springer, 2011, pp. 28–39.

[23] M. V. Kotpalliwar, R. Wajgi, Classiﬁcation of attacks using support vector

machine (svm) on kddcup’99 ids database, in: 2015 Fifth International

Conference on Communication Systems and Network Technologies, IEEE,

2015, pp. 987–990.

[24] H. Saxena, V. Richariya, Intrusion detection in kdd99 dataset using svm-

pso and feature reduction with information gain, International Journal of

Computer Applications 98 (6) (2014).

[25] M. S. Pervez, D. M. Farid, Feature selection and intrusion classiﬁcation in

nsl-kdd cup 99 dataset employing svms, in: The 8th International Confer-

ence on Software, Knowledge, Information Management and Applications

(SKIMA 2014), IEEE, 2014, pp. 1–6.

[26] T. Shon, Y. Kim, C. Lee, J. Moon, A machine learning framework for

network anomaly detection using svm and ga, in: Proceedings from the

sixth annual IEEE SMC information assurance workshop, IEEE, 2005, pp.

176–183.

[27] R. Kokila, S. T. Selvi, K. Govindarajan, Ddos detection and analysis in

sdn-based environment using support vector machine classiﬁer, in: 2014

Sixth International Conference on Advanced Computing (ICoAC), IEEE,

2014, pp. 205–210.

[28] C. Kruegel, D. Mutz, W. Robertson, F. Valeur, Bayesian event classiﬁcation

for intrusion detection, in: 19th Annual Computer Security Applications

Conference, 2003. Proceedings., IEEE, 2003, pp. 14–23.

39

[29] S. Benferhat, T. Kenaza, A. Mokhtari, A naive bayes approach for detecting

coordinated attacks, in: 2008 32nd Annual IEEE International Computer

Software and Applications Conference, IEEE, 2008, pp. 704–709.

[30] M. Panda, M. R. Patra, Network intrusion detection using naive bayes,

International journal of computer science and network security 7 (12) (2007)

258–263.

[31] L. Koc, T. A. Mazzuchi, S. Sarkani, A network intrusion detection system

based on a hidden na¨ıve bayes multiclass classiﬁer, Expert Systems with

Applications 39 (18) (2012) 13492–13500.

[32] R. Bapat, A. Mandya, X. Liu, B. Abraham, D. E. Brown, H. Kang, M. Veer-

araghavan, Identifying malicious botnet traﬃc using logistic regression, in:

2018 Systems and Information Engineering Design Symposium (SIEDS),

IEEE, 2018, pp. 266–271.

[33] E. Besharati, M. Naderan, E. Namjoo, Lr-hids:

logistic regression host-

based intrusion detection system for cloud environments, Journal of Ambi-

ent Intelligence and Humanized Computing 10 (9) (2019) 3669–3692.

[34] S. Vishwakarma, V. Sharma, A. Tiwari, An intrusion detection system

using knn-aco algorithm, Int. J. Comput. Appl. 171 (10) (2017) 18–23.

[35] H. Shapoorifard, P. Shamsinejad, Intrusion detection using a novel hybrid

method incorporating an improved knn, Int. J. Comput. Appl. 173 (1)

(2017) 5–9.

[36] A. M. Shariﬁ, S. K. Amirgholipour, A. Pourebrahimi, Intrusion detection

based on joint of k-means and knn, Journal of Convergence Information

Technology 10 (5) (2015) 42.

[37] P. A. R. Kumar, S. Selvakumar, Distributed denial of service attack de-

tection using an ensemble of neural classiﬁer, Computer Communications

34 (11) (2011) 1328–1341.

40

[38] A. Dainotti, A. Pescap´e, G. Ventre, A cascade architecture for dos attacks

detection based on the wavelet transform, Journal of Computer Security

17 (6) (2009) 945–968.

[39] N. G. Relan, D. R. Patil, Implementation of network intrusion detection

system using variant of decision tree algorithm, in: 2015 International Con-

ference on Nascent Technologies in the Engineering Field (ICNTE), IEEE,

2015, pp. 1–5.

[40] K. Rai, M. S. Devi, A. Guleria, Decision tree based algorithm for intrusion

detection, International Journal of Advanced Networking and Applications

7 (4) (2016) 2828.

[41] B. Ingre, A. Yadav, A. K. Soni, Decision tree based intrusion detection

system for nsl-kdd dataset, in: International Conference on Information

and Communication Technology for Intelligent Systems, Springer, 2017,

pp. 207–218.

[42] S. Puthran, K. Shah, Intrusion detection using improved decision tree algo-

rithm with binary and quad split, in: International Symposium on Security

in Computing and Communication, Springer, 2016, pp. 427–438.

[43] D. Moon, H. Im, I. Kim, J. H. Park, Dtb-ids: an intrusion detection system

based on decision tree using behavior analysis for preventing apt attacks,

The Journal of supercomputing 73 (7) (2017) 2881–2895.

[44] A. O. Balogun, R. G. Jimoh, Anomaly intrusion detection using an hybrid

of decision tree and k-nearest neighbor (2015).

[45] P. Sangkatsanee, N. Wattanapongsakorn, C. Charnsripinyo, Practical real-

time intrusion detection using machine learning approaches, Computer

Communications 34 (18) (2011) 2227–2235.

[46] I. Alrashdi, A. Alqazzaz, E. Alouﬁ, R. Alharthi, M. Zohdy, H. Ming, Ad-iot:

Anomaly detection of iot cyberattacks in smart city using machine learning,

41

in: 2019 IEEE 9th Annual Computing and Communication Workshop and

Conference (CCWC), IEEE, 2019, pp. 0305–0310.

[47] M. Mazini, B. Shirazi, I. Mahdavi, Anomaly network-based intrusion de-

tection system using a reliable hybrid artiﬁcial bee colony and adaboost

algorithms, Journal of King Saud University-Computer and Information

Sciences 31 (4) (2019) 541–553.

[48] J. Han, J. Pei, M. Kamber, Data mining: concepts and techniques (2011).

[49] N. Sneha, T. Gangil, Analysis of diabetes mellitus for early prediction using

optimal features selection, Journal of Big Data 6 (1) (2019) 13.

[50] G. H. John, P. Langley, Estimating continuous distributions in bayesian

classiﬁers, in: Proceedings of the Eleventh conference on Uncertainty in

artiﬁcial intelligence, Morgan Kaufmann Publishers Inc., 1995, pp. 338–

345.

[51] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel,

M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, et al., Scikit-learn:

Machine learning in python, the Journal of machine Learning research 12

(2011) 2825–2830.

[52] D. W. Aha, D. Kibler, M. K. Albert, Instance-based learning algorithms,

Machine learning 6 (1) (1991) 37–66.

[53] J. R. Quinlan, C4.5: Programs for machine learning, Machine Learning

(1993).

[54] L. Breiman, Random forests, Machine learning 45 (1) (2001) 5–32.

[55] L. Breiman, Bagging predictors, Machine learning 24 (2) (1996) 123–140.

[56] Y. Amit, D. Geman, Shape quantization and recognition with randomized

trees, Neural computation 9 (7) (1997) 1545–1588.

42

[57] S. S. Keerthi, S. K. Shevade, C. Bhattacharyya, K. R. K. Murthy, Improve-

ments to platt’s smo algorithm for svm classiﬁer design, Neural computa-

tion 13 (3) (2001) 637–649.

[58] S. Le Cessie, J. C. Van Houwelingen, Ridge estimators in logistic regression,

Journal of the Royal Statistical Society: Series C (Applied Statistics) 41 (1)

(1992) 191–201.

[59] Y. Freund, R. E. Schapire, et al., Experiments with a new boosting algo-

rithm, in: Icml, Vol. 96, Citeseer, 1996, pp. 148–156.

[60] A. G´eron, Hands-On Machine Learning with Scikit-Learn, Keras, and Ten-

sorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems,

O’Reilly Media, 2019.

[61] Colaboratory [online]. available: https://colab.research.google.com/.

[62] Y. Xin, L. Kong, Z. Liu, Y. Chen, Y. Li, H. Zhu, M. Gao, H. Hou, C. Wang,

Machine learning and deep learning methods for cybersecurity, IEEE Ac-

cess 6 (2018) 35365–35381.

[63] I. H. Sarker, A machine learning based robust prediction model for real-life

mobile phone data, Internet of Things 5 (2019) 180–193.

[64] I. H. Sarker, M. M. Hoque, M. K. Uddin, T. Alsanoosy, Mobile data science

and intelligent apps: Concepts, ai-based modeling and research directions,

Mobile Networks and Applications (2020) 1–19.

[65] I. H. Sarker, A. Colman, J. Han, Recencyminer: mining recency-based

personalized behavior from contextual smartphone data, Journal of Big

Data 6 (1) (2019) 49.

43

