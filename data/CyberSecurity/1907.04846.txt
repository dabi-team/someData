9
1
0
2

l
u
J

0
1

]

R
C
.
s
c
[

1
v
6
4
8
4
0
.
7
0
9
1
:
v
i
X
r
a

On Designing Machine Learning Models for Malicious Network Trafﬁc
Classiﬁcation

Talha Ongun, Timothy Sakharaov, Simona Boboila, Alina Oprea, and Tina Eliassi-Rad

Northeastern University

July 11, 2019

Abstract

Machine learning (ML) started to become widely deployed
in cyber security settings for shortening the detection cycle
of cyber attacks. To date, most ML-based systems are either
proprietary or make speciﬁc choices of feature representations
and machine learning models. The success of these techniques
is difﬁcult to assess as public benchmark datasets are currently
unavailable. In this paper, we provide concrete guidelines and
recommendations for using supervised ML in cyber security.
As a case study, we consider the problem of botnet detection
from network trafﬁc data. Among our ﬁndings we highlight
that: (1) feature representations should take into consideration
attack characteristics; (2) ensemble models are well-suited to
handle class imbalance; (3) the granularity of ground truth
plays an important role in the success of these methods.

1

Introduction

A wide spectrum of threats ranging from opportunistic mali-
cious activities to sophisticated nation-sponsored campaigns
threaten organizations from industry, academia, and govern-
ment. These attacks usually result in loss of important infor-
mation and affect consumers and businesses alike. Notable
examples are the Equifax data breach in 2017 and the An-
them healthcare campaign in 2015 that compromised personal
ﬁnancial and medical records for millions of US citizens.

To date, most enterprises deploy many security controls in
their environments and apply best practice (such as patching
vulnerable systems, use of threat intelligence services, and
endpoint scanning) to protect against cyber threats. Monitor-
ing tools are deployed in most organizations either on the
network (e.g., network intrusion-detection systems, web prox-
ies, ﬁrewalls) or on the end hosts (e.g., anti-virus software,
endpoint agents). With the availability of security logs col-
lected by large enterprises, machine learning (ML) started to
become an important defensive tool in face of increasingly so-
phisticated cyber attacks. ML techniques applied to network
data include systems for detecting malicious domains (e.g.,

[1, 5, 2]), methods for detecting malware delivery (e.g., [9])
or command-and-control communication [4, 11, 8, 12], tech-
niques for detecting malicious web pages (e.g., [15]), and
various industry products for enterprise threat detection (e.g.,
[13, 6, 10, 7, 16]).

ML has a lot of potential in shortening the malware detec-
tion cycle, but these algorithms tend to come with a number
of shortcomings. In particular, Sommer and Paxson [14] high-
lighted the difﬁculties of using ML in operational settings
for cyber security. The main limitations they identiﬁed were:
(1) ML excels at supervised tasks by learning from labeled
examples, while in cyber security most of the data is unla-
beled. (2) ML errors (and in particular false positives) have
high cost as alerts need to be investigated by security ana-
lysts. (3) Network trafﬁc exhibits high diversity under normal
operating conditions. (4) Performing sound evaluations is usu-
ally challenging due to unavailability of standard benchmark
datasets.

In this paper, we describe some concrete guidelines and
recommendations for using supervised ML in cyber security.
As a case study, we consider the problem of botnet detec-
tion from network trafﬁc data. We leverage a public dataset
(CTU-13) which includes network trafﬁc collected from a
university campus and attacks launched on the university net-
work. Among our ﬁndings, we highlight the following:

• Feature representations should take into consideration
the speciﬁcs of the attacks. Among standard feature rep-
resentations, we compare connection-level features (ex-
tracted directly from Bro logs) with aggregated trafﬁc
statistics and temporal features (using ﬁxed time win-
dows).

• Class imbalance is a major issue that hinders the perfor-
mance of simple linear models such as logistic regres-
sion.

• Ensemble methods such as gradient boosting have built-
in techniques that can handle class imbalance well. They
achieve better performance at classifying malicious and
benign connections compared to linear models.

1

 
 
 
 
 
 
• The granularity of data labeling (ground truth) can im-
pact the classiﬁcation metrics substantially. If available,
ground truth obtained at the level of individual network
connections can boost the performance of supervised
ML models.

2 Background and Threat Model

2.1 Machine Learning for Network Trafﬁc

Classiﬁcation

Network Intrusion Detection is a highly active area of re-
search. Traditional systems such as Snort are based on
manually-generated rules for detecting well-known malware
variants.

Recently, ML has proven to be valuable in augmenting
rule-based systems. ML has the potential of detecting more
advanced malicious activities that evade rule-based systems.
Successful applications of ML to various types of network
data for malware detection include:

• Domain reputation systems using passive DNS data,

such as Notos [1] and EXPOSURE [5].

• Command-and-control detection based on NetFlow data,

such as DISCLOSURE [4] and BotFinder [17].

• Malicious communication detection using web-proxy
logs, such as ExecScent [11], BAYWATCH [8], and
MADE [12].

Bro is an open-source network monitoring agent that col-
lects a number of network logs. Here we leverage the Bro
connection logs, which record the ﬁelds included in Fig-
ure 1. These include the TCP connection timestamp, duration,
source IP and port, destination IP and port, number of packets
sent and received, number of bytes sent and received, and
connection state. For UDP, an entry is generated for every
UDP packet (as there do not exist connections over UDP).

2.2 Problem statement and threat model

ML algorithms have demonstrated success in network trafﬁc
classiﬁcation tasks for detecting botnets or malicious domains.
However, most ML methods are designed in an ad-hoc manner
and guidelines for principled approaches in this space are
currently missing. We are interested in ﬁlling this gap and
providing recommendations on several general principles that
should guide ML design for botnet and malware detection. We
are speciﬁcally addressing the problem of detecting botnets
from network logs (as generated by Bro logs), but our methods
can be used with other network data types (such as NetFlow,
pcap, ﬁrewalls). Some of the research questions we would
like to answer are the following:

Figure 1: Fields in Bro connection log.

• Can raw network data be used effectively in an ML al-

gorithm?

• Which feature representations are most appropriate for

applying ML classiﬁcation algorithms?

• Which classiﬁers achieve best performance in handling

the largely imbalanced cyber-security datasets?

• What is the impact of labeling the data for ground truth

generation?

We assume that the monitoring agent, which collects the
network data, is not under the attacker’s control. We also
assume that the attacker cannot tamper with the collected
network logs. Therefore, attackers do not have access to the
storage device where data is recorded. 1

3 Case Study on ML for Botnet Detec-

tion

3.1 Dataset

We leverage a dataset of botnet trafﬁc that was captured in
2011 at the CTU University in the Czech Republic. The
dataset includes 13 scenarios, each including legitimate trafﬁc,
as well as various attacks such as spam, port scanning, DDOS,
and click fraud. The dataset also includes a list of botnet IPs
that can be used for labeling the trafﬁc.

Since ML classiﬁcation needs to use similar attack data for
training and testing, we decided to use a subset of 6 scenarios.
Among these, 3 scenarios are generated by botnet Neris (per-
forming spam and click fraud activity), and 3 scenarios are
generated by botnet Rbot (performing DDoS activity). The
statistics are in Table 1. For other botnets, there was only one

1Attackers with access to the monitoring environment and the system

logs are much more powerful, and are beyond our current scope.

2

Figure 2: Overview of the system architecture.

scenario available and that precluded the use of supervised
ML.

In traditional ML, cross-validation is a well-known method
to evaluate the generalization of a model. k-fold cross-
validation splits the data into k partitions at random, trains
a model on k − 1 of them and evaluates it on the k-th parti-
tion. Splitting the logs at random produces highly-correlated
data between training and testing sets. Instead, we train on
two scenarios, and test on the third (independent) scenario,
repeating the experiment 3 times for each of the two botnets.
We have thus assurances that testing data is independent from
training. This method of splitting the data into training and
testing (based on independent attack scenario) is more appro-
priate for this setting. In other contexts, the speciﬁcs of the
environment need to be taken into consideration.

3.2 Overview

We show our system architecture in Figure 2. Our system pro-
cesses network logs collected at the border of an organization
(i.e., campus or enterprise network). After data collection, a
feature extraction layer is employed to prepare the data for
ML training. A number of classiﬁcation algorithms are used
to train a classiﬁer and optimize for standard metrics, such
as precision, recall, F1 score, and AUC. The classiﬁers are
applied to new testing scenarios in order to evaluate their
generality and predict suspicious network activity. We believe
that this framework is general enough to be applicable in other
environments.

3.3 Feature extraction

We experiment with different feature representations, as de-
scribed below.

Connection-level representation. This representation ex-
tracts features directly from the raw connection logs. We
consider all connections in which ip is either id.orig h or
id.dest h and we use directly the ﬁelds from the Bro con-

nection logs as features:

ts, id.orig h, id.orig p, id.dest h,
id.dest p, proto, duration, orig bytes,
resp bytes, orig pkts, resp pkts

For categorical features (e.g., proto) we use standard one-
hot encoding. In this representation, we obtained 26 features
after one-hot encoding.
Aggregated trafﬁc statistics. Next, we would like to explore
if features obtained by time aggregation are more powerful
than raw features. We consider a time interval of length T
over which we deﬁne aggregated features over all connections
in which ip is either id.orig h or id.dest h.

An important consideration when deﬁning our features is
to generate a ﬁxed number of features, independent of the
trafﬁc at a particular host. In our ﬁrst attempt, we consider
the set of all destination IP addresses that ip communicates
with: SIP = {IP1, . . . , IPn}. From these we can deﬁne the
set of /24 destination subnets that ip communicates with:
Ssubnet = {Sub1, . . . , Subm}, with m ≤ n. If we deﬁne aggre-
gated features per destination or subnet, we will encounter
an issue when a host visits new IPs or new destinations. In
that case, we need to add new features to our representation,
which is not desirable in practice.

To alleviate this problem, we deﬁne our aggregated features
by destination port (corresponding to applications or network
services). Speciﬁcally, we deﬁne a set of 17 popular applica-
tion ports (e.g., HTTP - 80, HTTPS - 443, SSH - 22, DNS -
53). We then take a modular approach. We select a small num-
ber of operators (Distinct, Sum, Min, Max) and apply them to
ﬁelds in conn.log for each destination port. The features are
described in Table 2. We generate these features separately
for outgoing and incoming connections. Additionally, we add
some features that capture communication patterns with exter-
nal IP destinations (e.g., number of connections per transport
protocol, number of source and destination ports, number of
destination IPs, etc.). In this representation, we obtain 756
aggregated trafﬁc features.

3

Botnet

Scenario

Attack

Neris

Rbot

1
2
9

4
10
11

Spam, click fraud
Spam, click fraud
Spam, click fraud
port scan
ICMP, UDP
ICMP, UDP
UDP

Botnet
raw
31,089
39,730
111,895

Botnet
aggregated
569
407
2893

Background
raw
3,067,241
1,872,270
1,689,040

Background
aggregated
76,614
54,675
62,970

126,438
10,102,210
251,814

122
741
20

869,648
988,870
75,069

49,041
55,160
3169

Table 1: CTU-13 botnet scenarios.

Category
IPs
(Per port)
Duration
(Per port)

Bytes
(Per port)

Field
id.dest h

duration

orig bytes

resp bytes

Packets
(Per port)

orig pkts

Trafﬁc statistics

resp pkts

proto
id.orig p
id.dest h
id.dest p

Operator
Distinct
Distinct
Sum
Min
Max
Sum
Min
Max
Sum
Min
Max
Sum
Min
Max
Sum
Min
Max
Sum
Distinct
Distinct
Distinct

Deﬁnition
Number of IPs communicated with per port
Number of Subnets communicated with per port
Total duration of connection per port
Min duration of connection per port
Max duration of connection per port
Total bytes sent by ip per port
Min bytes sent by ip in a connection per port
Max bytes sent by ip in a connection per port
Total bytes received by ip per port
Min bytes received by ip in a connection per port
Max bytes received by ip in a connection per port
Total packets sent by ip per port
Min packets sent by ip in a connection per port
Max packets sent by ip in a connection per port
Total packets received by ip per port
Min packets received by ip in a connection per port
Max packets received by ip in a connection per port
Number of connections per transport protocol (TCP, UDP, ICMP)
Number of source ports
Number of external destination IPs
Number of destination ports

Table 2: Trafﬁc features aggregated by time. The top 4 categories of features are deﬁned per port.

Temporal features. Considering the same time interval T as
with the aggregated connection-level features, we deﬁne inter-
arrival features on a node as the mean, standard deviation,
median, minimum, and maximum of the time distribution
between node communications. Each internal node has two
such sets of features: one for events where the node serves as
the source of communication (outgoing), and one where it is
the target (incoming). These communications are aggregated
by common ports. Thus, in each time interval T , a node i
will have the inter-arrival features listed in Table 3. In this
representation, we obtain 180 features.

3.4 ML classiﬁcation and labeling

Ground truth labeling CTU-13 dataset provides a list of
botnet IP addresses. One of our main observations is that
the attack is not active during the duration of the entire data

collection. We found that the granularity at which we label
the data plays a large role in the results. We experiment with
two levels of granularity:

• Coarse-grained labeling: We label all the connection
logs generated by the botnet IPs as Malicious during the
entire scenario period.

• Fine-grained labeling: For the Rbot attack (an instance
of DDoS), we obtain the IP address of the victim ma-
chine. We use that to identify the attack ﬂows that con-
nect to the victim IP. For all feature representations, we
label a time window as Malicious if there is at least one
attack log event in that time window.

Fine-grained labeling is difﬁcult to obtain in general be-
cause it is a manual process, but when it is available it im-
proves signiﬁcantly the performance of ML in botnet detec-
tion.

4

Category
Outgoing Mean, std. dev., median, min, max
Incoming Mean, std. dev., median, min, max

Statistics

Deﬁnition
Statistics of inter-arrival distribution for outgoing trafﬁc
Statistics of inter-arrival distribution for incoming trafﬁc

Table 3: Temporal features aggregated by time. Each of these features is deﬁned per port.

ML models We consider several well-known ML classiﬁca-
tion models, including logistic regression, random forest, and
gradient boosting. We use several metrics to evaluate the per-
formance of the ML algorithms (precision, recall, F1 score,
and AUC). As the imbalance is quite large in this dataset
(the ratio of Malicious to Legitimate samples is as low as
1:134 for Neris and 1:401 for Rbot with features aggregated at
30-second intervals), the accuracy is always quite high (above
0.96 in all our experiments). We are interested in results on the
minority (Malicious) class, thus precision, recall, F1 score,
and AUC are better indicators of how the classiﬁers perform
at detecting botnets.

For the ML classiﬁers, we perform a grid search on several
hyper-parameters to select the models performing best in our
setting. For Random Forest, we selected the number of trees
in {10, 50, 100, 200} and found that 100 tree worked best. For
Gradient Boosting, we varied the number of estimators in
{50, 100, 200}, the maximum depth of each tree in {3, 5, 7}
and learning rate in {0.01, 0.05, 0.1}. We selected 100 es-
timators with maximum depth of 3 and learning rate 0.05.
For logistic regression, we used L1 or Lasso regularization to
reduce the space dimension.

4 Experimental Evaluation

During our experimental evaluation, we would like to answer
several research questions, which we detail below.
Which feature representation performs best? We compare
different feature representations (connection-level representa-
tion, aggregated trafﬁc statistics, and temporal features). For
this experiment, we use a random forest classiﬁer with 100
trees and a 30-second time window for aggregation.

The results for Neris are in Table 4 and they show that
aggregated features (both trafﬁc statistics and temporal) per-
form signiﬁcantly better than raw features extracted directly
from Bro logs at all metrics of interest. For instance, when
training on scenarios 2 and 9 and testing on scenario 1, the
F1 score for connection features is 0.65, while the F1 score
for aggregated features is 0.98. We do not observe a major
difference when we consider both trafﬁc and timing features,
compared to using only aggregated trafﬁc features.

The results for Rbot for ﬁne-grained labeling are in Ta-
ble 5. Here, connection-based features perform quite well.
The reason is that this is a DDoS attack in which all packets
sent to the victim are identical. However, trafﬁc statistics and
temporal features also perform well. The exception is when

Features

Connection

Trafﬁc

Trafﬁc and
Temporal

Training
Scenarios
2,9
1,9
1,2
2,9
1,9
1,2
2,9
1,9
1,2

Testing
Scenario
1
2
9
1
2
9
1
2
9

Prec.

Recall

F1

AUC

0.68
0.89
0.92
0.99
0.94
1
0.99
0.95
1

0.62
0.43
0.70
0.98
0.96
0.90
0.97
0.96
0.90

0.65
0.58
0.80
0.98
0.95
0.94
0.98
0.95
0.94

0.87
0.88
0.94
0.99
0.99
0.96
0.99
0.98
0.96

Table 4: Classiﬁcation metrics for the Neris botnet for Ran-
dom Forest with different feature representations. Best results
are highlighted in bold.

Features

Connection

Trafﬁc

Trafﬁc and
Temporal

Training
Scenarios
10,11
4,11
4,10
10,11
4,11
4,10
10,11
4,11
4,10

Testing
Scenario
4
10
11
4
10
11
4
10
11

Prec.

Recall

F1

AUC

0.99
0.99
0.99
1
1
1
1
1
1

0.99
0.99
0.99
1
0.85
1
1
0.85
1

0.99
0.99
0.99
1
0.92
1
1
0.92
1

0.99
0.99
0.99
1
0.92
1
1
0.92
1

Table 5: Classiﬁcation metrics for the Rbot botnet for Random
Forest with different feature representations and ﬁne-grained
labeling. Best results are highlighted in bold.

training on scenarios 4 and 11, and testing on scenario 10. In
that case, the amount of botnet samples used for training with
30-second aggregation is very small (142), while there are
much more botnet samples in the raw data (378,252).

What is the impact of varying the time window? Here, we
validate the choice of the time window for aggregation. Ta-
ble 6 and Figure 3 show results for varying the time window
from 1 to 600 seconds. The 30-second and 60-second time
windows exhibit similar results and they are performing well
most of the time. Window size 10 is also performing well,
except when testing on scenario 1. As the time window in-
creases beyond 120 seconds, the results start to degrade. We
suspect this is because of the small samples of attack trafﬁc at
larger aggregation windows, as well as additional noise in the
legitimate trafﬁc. In general, selecting the best time window
for aggregation is attack-dependent. We recommend the use
of cross-validation for selecting the optimal value of the time
window. Based on these results, we select a time window of
30 seconds for the rest of experiments.

5

Figure 3: F1 scores for different time windows for Neris.

Figure 4: Precision-recall curves for three classiﬁers for Neris.

Time
(seconds)
1

10

30

60

120

240

600

Training
Scenarios
2,9
1,9
1,2
2,9
1,9
1,2
2,9
1,9
1,2
2,9
1,9
1,2
2,9
1,9
1,2
2,9
1,9
1,2
2,9
1,9
1,2

Testing
Scenario
1
2
9
1
2
9
1
2
9
1
2
9
1
2
9
1
2
9
1
2
9

Prec.

Recall

F1

AUC

0.89
0.92
0.98
0.84
0.96
1
0.99
0.95
1
0.99
0.95
1
0.97
0.91
0.99
0.94
0.85
1
0.87
0.76
1

0.87
0.87
0.89
0.98
0.96
0.92
0.97
0.96
0.90
0.97
0.96
0.87
0.97
0.94
0.82
0.97
0.92
0.75
1
0.90
0.59

0.88
0.90
0.93
0.91
0.96
0.96
0.98
0.95
0.94
0.98
0.95
0.93
0.97
0.92
0.90
0.95
0.89
0.85
0.93
0.83
0.74

0.98
0.98
0.98
0.99
0.99
0.98
0.99
0.98
0.96
0.99
0.98
0.95
0.99
0.98
0.92
0.99
0.97
0.89
0.99
0.99
0.82

Table 6: Classiﬁcation metrics for the Neris botnet for Ran-
dom Forest with different time windows. We used the aggre-
gated trafﬁc statistics and temporal features. Best results are
highlighted in bold.

What is the impact of different ML models? One important
observation is that the amount of imbalance in cyber security
is very large (as also observed by previous work [3, 12]). It is
well-known that ensemble classiﬁers such as random forests
and boosting handle imbalance much better than simpler mod-
els. We test this hypotheses by using three different classiﬁers
for our task: logistic regression, random forests, and gradient
boosting. We ﬁx the aggregation time window to 30 seconds
and use the trafﬁc statistics and temporal features.

The results for three classiﬁers for Neris are in Table 7 and
the precision-recall curves are in Figure 4. All three models
we experimented with perform relatively well. Both ensemble
method perform better than the logistic regression model, with
F1 scores reaching between 0.94 and 0.98 on all scenarios.
The difference between random forest and gradient boosting
is imperceptible, they are both powerful classiﬁcation models.

6

Model

Logistic
Regression

Random
Forest

Gradient
boosting

Training
Scenarios
2,9
1,9
1,2
2,9
1,9
1,2
2,9
1,9
1,2

Testing
Scenario
1
2
9
1
2
9
1
2
9

Prec.

Recall

F1

AUC

0.90
0.98
0.97
0.99
0.95
1
1
1
1

0.90
0.95
0.87
0.97
0.96
0.90
0.97
0.92
0.87

0.90
0.97
0.92
0.98
0.95
0.94
0.98
0.96
0.93

0.94
0.99
0.96
0.99
0.98
0.96
0.99
0.99
0.95

Table 7: Classiﬁcation metrics for the Neris botnet for three
classiﬁers for aggregated trafﬁc statistics and temporal fea-
tures (aggregation window 30 seconds). Best results are high-
lighted in bold.

Are the models interpretable? To understand what the ML
models learned, we computed feature importance for the ran-
dom forest classiﬁer for both Neris and Rbot (using the ag-
gregated trafﬁc statistics and timing features at 30-second
window). The results are in Table 8. Interestingly, we observe
that the classiﬁer identiﬁes features that are correlated with
the attack. Neris is a spam botnet and most of its activity
uses port 25, making features such as distinct source ports
and median inter-arrival packet time on port 25 most relevant.
In contrast, Rbot is a DDoS botnet that uses different ports
for the attack. For instance, the UDP ﬂood is using port 161,
and the classiﬁer correctly determines that the standard de-
viation of inter-arrival packet timing on port 161 is the most
important feature.

These results show our framework’s ﬂexibility and ability
to generalize to different attack patterns. We deﬁned a set of
936 generic features that can be used for a variety of botnet
attacks. For the two different botnets we experimented with,
the ML models identiﬁed the most relevant features that are
correlated with the attacks, without the need for a human
expert to explicitly locate those features. Models such as
random forest provide standard metrics for feature importance,
with a clear advantage for model interpretability compared to

Botnet
Neris

Rbot

Feature
Distinct source ports
Median inter-arrival time
Distinct destination ports
Min packets sent
Distinct external IPs
Total duration
Total packets sent
Max duration of connection
Std. dev. of inter-arrival time
Distinct source ports
Distinct source ports
Min inter-arrival timing
Distinct source ports
Distinct source ports
Distinct source ports
Std. dev. of inter-arrival time

Port
25
25
25
25
25
25
25
25
161
135
Other
138
138
3
8
138

Importance
0.085
0.070
0.067
0.061
0.054
0.053
0.051
0.048
0.049
0.046
0.043
0.042
0.040
0.038
0.030
0.029

Table 8: Feature importance for the Neris botnet (top) and
the Rbot botnet (bottom). All these features are for outgoing
connections from an internal node.

deep learning and neural networks that lack interpretability.
Interpretability is important in cyber security, as most of the
time human experts analyze the alerts of ML systems.
What is the impact of labeling ﬂows accurately? We per-
form an experiment to test how the granularity of data labeling
impacts the classiﬁcation results. For the Rbot DDoS botnet
we have access to the IP address of the victim machine and
thus we can determine which connections are botnet-related.
We refer to ﬁne-grained labeling to the process of labeling
only the botnet connection to victim IP as Malicious. We
refer to coarse-grained labeling to the process of labeling all
connections initiated by the botnet IP as Malicious.

Table 9 shows the results of ﬁne-grained and coarse-grained
labeling for the Random Forest and Gradient Boosting clas-
siﬁers for features aggregated at 30-second intervals. The
results demonstrate that classiﬁer performance obtained with
ﬁne-grained labeling is much better than using coarse-grained
labeling. For instance, when training on scenarios 10 and 11,
and testing on scenario 4, the F1 score for coarse-grained
labeling is 0.44, compared to a perfect F1 score for ﬁne-
grained labeling. Both classiﬁers perform here similarly for
ﬁne-grained labeling.

5 Lessons and General Recommenda-

tions

Motivated by our case study of botnet classiﬁcation from Bro
logs, we highlight several guidelines that we believe are ap-
plicable in other settings where ML is used in cyber security.
Multiple feature representations need to be evaluated.
Features extracted directly from raw data such as Bro con-
nection logs do not always results in the most optimal rep-
resentation. A representation that worked well in our setting
for classifying internal IP addresses is feature aggregation
by time windows and port number. We also observed that
feature representation depends on the amount of training data

7

Model

Label

Random
Forest

Random
Forest

Gradient
boosting

Gradient
boosting

C

F

C

F

Training
Scenarios
10,11
4,11
4,10
10,11
4,11
4,10
10,11
4,11
4,10
10,11
4,11
4,10

Testing
Scenario
4
10
11
4
10
11
4
10
11
4
10
11

Prec.

Recall

F1

AUC

0.75
0.99
0.93
1
1
1
1
0.99
1
1
1
1

0.31
0.76
0.75
1
0.85
1
0.27
0.74
0.75
1
0.85
1

0.44
0.86
0.83
1
0.92
1
0.42
0.84
0.85
1
0.92
1

0.94
0.90
0.91
1
0.92
1
0.84
0.95
0.92
1
0.92
1

Table 9: Classiﬁcation metrics for the Rbot botnet for two
methods of labeling the data (coarse-grained or C and ﬁne-
grained or F). We used the Random Forest (100 trees) and
Gradient Boosting classiﬁers for aggregated trafﬁc statistics
and temporal features (aggregation window 30 seconds). Best
results are highlighted in bold.

available. With the large imbalance between the malicious
and benign classes, smaller time windows work better for
aggregation. However, the right feature representation and the
choice of time window for feature aggregation are dependent
on the attack type. We recommend evaluating multiple feature
representations.

Model interpretability. Models that provide interpretability
are preferred in cyber security as security analysts need to in-
vestigate the alerts raised by ML systems. Understanding why
a ﬂow is labeled as malicious can speed up the investigation
signiﬁcantly. We showed how a random forest classiﬁer is
interpretable by identifying most relevant features that clearly
provide insights about the botnet activity.

Data imbalance raises a challenge for supervised learn-
ing. Data imbalance results in a huge challenge when apply-
ing classiﬁcation methods to cyber security. Simpler models
such as linear models are not equipped to deal well with class
imbalance. We showed that ensemble models such as ran-
dom forest and gradient boosting achieve good results even
in highly imbalanced scenario, compared to logistic regres-
sion. For instance, at an imbalance of 1:134 (when testing on
scenario 2 for Neris) we obtain 0.97 precision and 0.95 recall
with gradient boosting.

The alternative to classiﬁcation is to employ anomaly-
detection models that learn from the legitimate class and
identify attacks as anomalies. Nevertheless, Sommer and Pax-
son [14] discussed extensively the difﬁculty of using anomaly
detection in cyber security. We plan to investigate the perfor-
mance of anomaly detectors in future work.

Fine-grained ground truth labeling can be a major factor
in the success of supervised learning. As we demonstrated,
data labeling for generating the ground truth plays a major
factor in measuring the success of supervised learning algo-
rithms. If detailed information about the attack is available

(e.g., the destination IPs contacted by attacker), then the per-
formance of classiﬁers can be greatly improved. However, it
is difﬁcult most of the time to identify exactly the attack ﬂows,
even when running cotrolled attack simulations. Malware can
contact a variety of IP addresses using different protocols, but
infected machines also generate a fair number of legitimate
connections (e.g., connections to Window updates).

Command-and-Control servers through large-scale Net-
Flow analysis. In Proc. 28th Annual Computer Security
Applications Conference (ACSAC), ACSAC, 2012.

[5] L. Bilge, E. Kirda, K. Christopher, and M. Balduzzi.
EXPOSURE: Finding malicious domains using passive
DNS analysis. In Proc. 18th Symposium on Network
and Distributed System Security, NDSS, 2011.

Acknowledgements

The research reported in this document/presentation was per-
formed in connection with contract number W911NF-18-C-
0019 with the U.S. Army Contracting Command - Aberdeen
Proving Ground (ACC-APG) and the Defense Advanced Re-
search Projects Agency (DARPA). The views and conclusions
contained in this document/presentation are those of the au-
thors and should not be interpreted as presenting the ofﬁcial
policies or position, either expressed or implied, of ACC-APG,
DARPA, or the U.S. Government unless so designated by
other authorized documents. Citation of manufacturer’s or
trade names does not constitute an ofﬁcial endorsement or ap-
proval of the use thereof. The U.S. Government is authorized
to reproduce and distribute reprints for Government purposes
notwithstanding any copyright notation hereon.

We thank Malathi Veeraraghavan, Jack Davidson, Alastair
Nottingham, and Donald Brown from University of Virginia,
Kolia Sadeghi from Commonwealth Computer Research, Inc.,
and other PCORE-project team members for their support
of this work. We would also like to thank Vijay Sarvepalli,
Andrew J Kompanek, and Lena Pons from the Software En-
gineering Institute at Carnegie Mellon University for their
helpful feedback regarding the evaluation.

References

[6] Endgame.

Using

Detect DGAs.

To
endgame.com/blog/technical-blog/
using-deep-learning-detect-dgas, 2016.

Deep

Learning
https://www.

Building Machine

Reverse Engineering

[7] FireEye.
lyst:
for
com/blog/threat-research/2018/06/
build-machine-learning-models-for-the-soc.
html, 2018.

the Ana-
Learning Models
https://www.fireeye.

SOC.

the

[8] X. Hu, J. Jang, M. P. Stoecklin, T. Wang, D. L. Schales,
D. Kirat, and J. R. Rao. BAYWATCH: robust beacon-
ing detection to identify infected hosts in large-scale
In DSN, pages 479–490. IEEE
enterprise networks.
Computer Society, 2016.

[9] L. Invernizzi, S. Miskovic, R. Torres, S. Saha, S.-J. Lee,
C. Kruegel, and G. Vigna. Nazca: Detecting malware
In Proc. ISOC
distribution in large-scale networks.
Network and Distributed System Security Symposium
(NDSS ’14), 2014.

Security

Machine

[10] Microsoft.
Azure
azure.microsoft.com/en-us/blog/
machine-learning-in-azure-security-center/,
2016.

in
https://

Learning

Center.

[1] M. Antonakakis, R. Perdisci, D. Dagon, W. Lee, and
N. Feamster. Building a dynamic reputation system for
DNS. In Proc. 19th USENIX Security Symposium, 2010.

[2] M. Antonakakis, R. Perdisci, Y. Nadji, N. Vasiloglou,
S. Abu-Nimeh, W. Lee, and D. Dagon. From throw-
away trafﬁc to bots: Detecting the rise of DGA-based
malware. In Proc. 21st USENIX Security Symposium,
2012.

[3] K. Bartos, M. Sofka, and V. Franc. Optimized invariant
representation of network trafﬁc for detecting unseen
In 25th USENIX Security Sympo-
malware variants.
sium (USENIX Security 16), pages 807–822. USENIX
Association, 2016.

[4] L. Bilge, D. Balzarotti, W. Robertson, E. Kirda,
and C. Kruegel. DISCLOSURE: Detecting botnet

[11] T. Nelms, R. Perdisci, and M. Ahamad. ExecScent: Min-
ing for new C&C domains in live networks with adap-
tive control protocol templates. In Proc. 22nd USENIX
Security Symposium, 2013.

[12] A. Oprea, Z. Li, R. Norris, and K. Bowers. MADE:
In
Security analytics for enterprise threat detection.
Proc. Annual Computer Security Applications Confer-
ence (ACSAC), ACSAC, 2018.

[13] RSA. Threat Detection and Response NetWitness
https://www.rsa.com/en-us/

Platform.
products/threat-detection-response,
2018.

[14] R. Sommer and V. Paxson. Outside the closed world: On
using machine learning for network intrusion detection.
In Proc. IEEE Symposium on Security and Privacy, SP
’10. IEEE Computer Society, 2010.

8

[15] G. Stringhini, C. Kruegel, and G. Vigna. Shady Paths:
Leveraging surﬁng crowds to detect malicious web
pages. In Proc. 20th ACM Conference on Computer
and Communications Security, CCS, 2013.

[16] Symantec.
Protection
https://support.symantec.com/en_

How does Symantec Endpoint
learning?

advanced machine

use

US/article.HOWTO125816.html, 2018.

[17] F. Tegeler, X. Fu, G. Vigna, and C. Kruegel. BotFinder:
Finding bots in network trafﬁc without deep packet in-
In Proc. 8th International Conference on
spection.
Emerging Networking Experiments and Technologies,

CoNEXT, 2012.

9

