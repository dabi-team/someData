Noname manuscript No.
(will be inserted by the editor)

Supervisory Control of Discrete-event Systems under Attacks

Masashi Wakaiki · Paulo Tabuada · Jo˜ao P. Hespanha

8
1
0
2

g
u
A
2
2

]

Y
S
.
s
c
[

2
v
1
8
8
0
0
.
1
0
7
1
:
v
i
X
r
a

October 30, 2017

Abstract We consider a multi-adversary version of the supervisory control problem for discrete-event sys-
tems, in which an adversary corrupts the observations available to the supervisor. The supervisor’s goal is
to enforce a speciﬁc language in spite of the opponent’s actions and without knowing which adversary it is
playing against. This problem is motivated by applications to computer security in which a cyber defense
system must make decisions based on reports from sensors that may have been tampered with by an attacker.
We start by showing that the problem has a solution if and only if the desired language is controllable (in
the Discrete event system classical sense) and observable in a (novel) sense that takes the adversaries into
account. For the particular case of attacks that insert symbols into or remove symbols from the sequence of
sensor outputs, we show that testing the existence of a supervisor and building the supervisor can be done
using tools developed for the classical DES supervisory control problem, by considering a family of automata
with modiﬁed output maps, but without expanding the size of the state space and without incurring on
exponential complexity on the number of attacks considered.

Keywords Supervisory control; discrete event systems; game theory; computer security

1 Introduction

Discrete event systems (DESs) are non-deterministic transition systems deﬁned over a typically ﬁnite state-
space. The DESs supervisory control problem refers to the design of a feedback controller — called a su-
pervisor — that restricts the set of possible sequences of transitions (typically represented by strings over
an alphabet of transitions) to a desired set K. The supervisor’s task is complicated by the fact that (i)
only a subset of transitions can be inhibited (the so called “controllable” transitions) and (ii) the supervisor
only has partial information about the state of the system, which it gathers by observing a string of “out-
put symbols.” This basic problem is motivated by a wide range of applications that include manufacturing
systems, chemical batch plants, power grids, transportation systems, database management, communication
protocols, logistics, and computer security. The latter is the key motivating application for the work reported
here.

This work was supported by the JSPS KAKENHI Grant Number JP17K14699, the National Science Foundation award
No. 1136174, and the U.S. Oﬃce of Naval Research under MURI grant No. N00014-16-1-2710.

Masashi Wakaiki
Graduate School of System Informatics, Kobe University, Kobe, 657-8501, Japan, E-mail: wakaiki@ruby.kobe-u.ac.jp.

Paulo Tabuada
Department of Electrical Engineering, University of California, Los Angeles, CA 90095-1594, USA, E-mail: tabuada@ee.ucla.edu.

Jo˜ao P. Hespanha
Center for Control, Dynamical-systems, and Computation, University of California, Santa Barbara, CA 93106-2560, USA,
E-mail: hespanha@ucsb.edu.

 
 
 
 
 
 
2

Masashi Wakaiki et al.

Fig. 1 Closed-loop system under attacks.

We consider a zero-sum multi-adversary version of the supervisory control problem, where one player (the
supervisor) faces multiple adversaries with distinct action spaces and the supervisor needs to ﬁnd a policy
that wins against any of its possible adversaries, without knowing which one is the actual opponent. The
supervisor loses if it accepts strings outside the desired set K or if it rejects strings within K. We consider a
zero-sum game in which the adversary tries to make the supervisor lose by manipulating the string of output
symbols that the supervisor uses to make decisions (see Figure 1).

In computer security applications, the supervisor is typically responsible for enacting defense mechanisms,
such as opening/closing ﬁrewalls, starting and stopping services, authorizing/deauthorizing users, and killing
processes. Such decisions are based on observations collected by cyber-security sensors that log events like user
authentication, network traﬃc, email activity, and access to services or ﬁles. Ultimately, the supervisors’ goal
is to allow users to perform all the tasks they are authorized to do, while preventing unauthorized access to
resources and services. The zero-sum multi-adversary game is motivated by scenarios where a cyber attacker
manipulates the supervisor’s observations by tampering with one or more of the cyber-security sensors. A
key challenge is that security mechanisms typically do not know if a particular sensor has been compromised
so it needs to consider multiple alternatives for sensor manipulation, which explains the need for the multi-
adversary model.

One of the paper’s main results is a general necessary and suﬃcient condition for the multi-adversary
game to have a “solution”, i.e., for the existence of a supervisor that can win the game against any of
the adversaries, without knowing which one it is playing against (Section 4). This necessary and suﬃcient
condition is expressed in terms of a controllability condition, which also arises in the classical supervisory
control setup and a novel observability condition that depends on how the adversaries can manipulate/attack
the output string. The result is constructive in the sense that it provides an explicit formula for the supervisor,
in case one exists, but this general formula is typically hard to use in practice.

The second part of the paper is focused on “output-symbol attacks”, which correspond to games where
each of the adversaries is restricted to attack a speciﬁc set of symbols. Speciﬁcally, each adversary is able to
insert into or remove from the output string symbols from a given set. In the context of computer security,
we can view such adversaries as attackers that inﬁltrated a security sensor and insert/remove entries from
the corresponding security log. For output-symbol attacks, we show that testing observability and generating
supervisors can be done using tools developed for classical supervisory control problems.

For output-symbol attacks, we show that testing the new notion of observability under attacks can be
done by checking the classical notion of observability for a family of DESs that diﬀer from each other only by
their output maps (Section 5.1). These output maps are obtained from the original output map by considering
all pairs of adversaries and removing from the output string every symbol that 2 adversaries could attack if
they were allowed to combine their eﬀorts (which they are not). This shows that observability under attacks
can still be tested in polynomial time.

Also for output-symbol attacks, we show that a supervisor for the multi-adversary case can be constructed
from a family of classical supervisors, each constructed for one of the classical DES supervisory control
problems used for the observability test (Section 5.2). Since constructing classical supervisors has exponential
worst-case complexity on the number of states, this procedure also has exponential worst-case complexity,
but it has the desirable feature that it does not enlarge the state-space of the original system. This is in
sharp contrasts with the alternative approach of reducing the multi-adversary supervisory control problem to

Plant	Supervisor	Corrupted	  string	  (may	  be	  an	  empty	  string)	Observa9on	  string	A;ack	Enabled	  events	  in	  the	  next	  step	Supervisory Control of Discrete-event Systems under Attacks

3

a classical supervisory control problem, which generally requires expanding the state-space M times, where
M is the number of adversaries.

Supervisory control theory provides a natural framework to address plant uncertainties and faults, either
in a robust control context (e.g., [11,20,15]) or in a fault tolerant context (e.g., [16,12,19]). Several aspects
of security have also been considered in the DES literature, including the stealthy deception attacks in [1,22]
that aim at injecting false information without being detected by the controller; or the opacity of DESs in
[21,5,14,29] and references there in, whose goal is to keep the system’s secret behavior uncertain to outsiders.
Intrusion detection in the DES framework has been investigated in [23,27,8], with the goal of guaranteeing
the conﬁdentiality and integrity of DESs.

The key novelty of the problem considered here is the focus on DES problems against adversaries that
manipulate the observations available to the supervisor. By focusing on this type of attack, we obtain tests
for the existence of a supervisor and algorithms to generate the supervisor that do not require an expansion
of the state-space of the original (not attacked) DES.

DESs with non-deterministic (set-valued) observation maps have been studied in [30,26,31], where the
problem formulation could be viewed has a version of the problem considered here but with a single adversary.
The authors in [30] introduced the notion of lifting and synthesized supervisors by converting the original
problem with nondeterministic observations to a problem in the lifted domain with deterministic observations.
In [26,31], the so-called Mealy automata were used to deal with both state-dependent observations and
non-deterministic outputs. The work reported here is inspired by the research on state estimation under
sensor attacks developed in [6,18,3], where the authors consider a linear time invariant system with multiple
outputs and an attacker that can manipulate a subset of the sensors that measure these outputs. The goal
is to estimate the system’s state and stabilize it using feedback control, without knowing which sensors have
been compromised.

2 Background on supervisory control of discrete-event systems

We start by recalling basic notation and deﬁnitions that are common in the Discrete-Event Systems (DES)
literature.

For a ﬁnite set Σ of events, we denote by |Σ| the number of elements of Σ and by Σ∗ the set of all ﬁnite
strings of elements of Σ, including the empty string (cid:15). A subset L of Σ∗ is called a language over the alphabet
Σ and the preﬁx closure of L is the language

¯L := (cid:8)u ∈ Σ∗ : ∃v ∈ Σ∗, uv ∈ L(cid:9),

where uv denotes the concatenation of two strings in Σ∗. The language L is said to be preﬁx closed if L = ¯L.
We deﬁne the concatenation of languages L1, L2 ⊂ S∗ by

L1L2 := {w1w2 ∈ Σ∗ : w1 ∈ L1, w2 ∈ L2}.

Consider an automaton G = (X, Σ, ξ, x0), where X is the set of states, Σ the nonempty ﬁnite set of events,
ξ : X × Σ → X the transition mapping (a partially deﬁned function), and x0 ∈ X the initial state. We write
ξ(x, σ)! to mean that ξ(x, σ) is deﬁned. The transition function ξ can be extended to a function X × Σ∗ → X
according to the following inductive rules

ξ(x, (cid:15)) := x,
(cid:40)

ξ(x, wσ) :=

ξ(ξ(x, w), σ)
undeﬁned

if ξ(x, w)! and ξ(ξ(x, w), σ)!
otherwise,

∀x ∈ X

∀x ∈ X, w ∈ Σ∗, σ ∈ Σ.

The language generated by G is then deﬁned by

L(G) := {w ∈ Σ∗ : ξ(x0, w)!}.

4

Masashi Wakaiki et al.

Let Σ be a set of events that can be partitioned in two disjoint sets as Σ = Σc ∪ Σuc, where Σc is
called the set of controlled events and Σuc the set of uncontrolled events. For a language L deﬁned on Σ, a
preﬁx-closed set K ⊂ L is said to be controllable if KΣuc ∩ L ⊂ K.

Consider an observation map P : Σ → (∆ ∪ {(cid:15)}) that maps the set of events Σ into a set of observations
∆ (augmented by the empty event (cid:15)). This observation map P can be extended to the map deﬁned for strings
of events according to P ((cid:15)) = (cid:15) and

P (wσ) = P (w)P (σ),

∀w ∈ Σ∗, σ ∈ Σ.

A preﬁx-closed language K ⊂ L is P -observable with respect to L if

where ker P denotes the relation on Σ∗ deﬁned by

ker P ⊂ actK⊂L

ker P := (cid:8)(w, ¯w) ∈ Σ∗ × Σ∗ : P (w) = P ( ¯w)(cid:9)

and actK⊂L the binary relation on Σ∗ deﬁned by

actK⊂L :=

(cid:110)

(w, ¯w) ∈ Σ∗ × Σ∗ : w, ¯w ∈ K

⇒ (cid:64)σ ∈ Σ s.t. [wσ ∈ K, ¯wσ ∈ L \ K] or [wσ ∈ L \ K, ¯wσ ∈ K]

(cid:111)
.

The key control design problem in DESs is to design a “supervisor” that modiﬁes the original language L
generated by the automaton to a desired language K ⊂ L, by judiciously disabling controllable events in Σc
(and their associated transitions) based on the observations obtained through P , in a feedback fashion. The
reader is referred to [13,2,28] for more details on DES models and key results.

3 Supervised discrete-event systems under attacks

In this paper, we deviate from the classical DES model by introducing a set of adversaries A whose goal is
to prevent the supervisor from achieving the desired language K. Each adversary A ∈ A can corrupt the
string of output symbols P (w), w ∈ Σ∗ in multiple (non-deterministic) ways, e.g., erasing and/or inserting
speciﬁc output symbols (see Example 1 below). Our goal is thus to design a supervisor that can guarantee
the desired language K regardless of (1) which A ∈ A is the actual attack, and (2) how the actual attack
A ∈ A corrupts each string of output symbols P (w), w ∈ Σ∗.
Formally, each adversary is a set-valued map A : ∆∗ → 2∆∗

that assigns to each string of output symbols
P (w), w ∈ Σ∗ a set A(cid:0)P (w)(cid:1) of (possibly distorted) strings of symbols that the adversary can send to
the supervisor, instead of the original string P (w). A set-valued map is convenient because it enable us
to consider multiple ways by which the attack A may corrupt a particular string P (w). We call the map
A an observation attack and the map AP : Σ∗ → 2∆∗
obtained from the composition AP := A ◦ P the
corresponding attacked observation map. The attack map Aid : ∆∗ → 2∆∗
that assigns to each string y ∈ ∆∗
the set {y} containing only the original output string y can be viewed as the absence of an attack.

A P -supervisor for a language L ⊂ Σ∗ and an attack set A is a function f : (cid:83)

supervisor is valid (for the set of uncontrollable events Σuc) if

A∈A AP (L) → 2Σ. The

f (y) ∈ Γ,

∀y ∈

(cid:91)

A∈A

AP (L),

where Γ := {γ ⊂ Σ : Σuc ⊂ γ} is the set of all subsets of Σ that contain all the uncontrollable symbols in
Σuc. One should view f (y) as the set of events that the supervisor enables after observing the (potentially
distorted) string y ∈ ∆∗. A valid supervisor is forced to always enable the uncontrolled symbols in Σuc.

By disabling symbols, a supervisor f eﬀectively only “accepts” a subset of the strings in the original
language L. However, which symbols are accepted depends on how the adversary actually distorts the

Supervisory Control of Discrete-event Systems under Attacks

5

observation strings. For a given supervisor f , the maximal language Lmax
A ∈ A is deﬁned inductively by

f,A controlled by f under the attack

(cid:40)

(cid:15) ∈ Lmax
f,A
wσ ∈ Lmax

f,A ⇔ w ∈ Lmax

f,A , wσ ∈ L,

∃y ∈ AP (w) s.t. σ ∈ f (y),

whereas the minimal language Lmin
by

f,A ( ⊂ Lmax

f,A ) controlled by f under the attack A ∈ A is deﬁned inductively

(cid:40)

(cid:15) ∈ Lmin
f,A
wσ ∈ Lmin

f,A ⇔ w ∈ Lmin

f,A , wσ ∈ L,

∀y ∈ AP (w), σ ∈ f (y).

f,A and Lmin

By construction Lmax
f,A are preﬁx closed. One can conclude from these deﬁnitions that an adversary
A ∈ A can distort the observations so that every string in the maximal language Lmax
f,A is accepted by the
supervisor f , but no string outside this language will be accepted. The same adversary is also able to cause
the rejection of every string outside the minimal language Lmin
f,A , but is unable to cause the rejection of any
string inside this language.

In the absence of an attack (i.e., when A = Aid) the maximal and minimal languages coincide and
correspond to the classical notion of the language Lf generated by the supervised system. However, under
attacks we can only be sure that Lmin
f,A , typically with a strict inclusion. Motivated by the desire to
construct supervisors that guarantee a speciﬁc language K ⊂ L, we say that f is a solution to the supervision
of K ⊂ L under the attack set A if f is valid and

f,A ⊂ Lmax

Lmin

f,A = Lmax

f,A = K,

∀A ∈ A.

This means that such f is a Stackelberg equilibrium policy for the supervisor (which we regard as the leader)
and guarantees victory because, even if the supervisor advertises f as its policy, the adversary cannot force
the rejection of any string in K (because Lmin
f,A = K) and cannot force the acceptance of any string outside
K (because Lmax

f,A = K).

Example 1 (Multi-layer cyber attack to a computer system) Figure 2 shows an automaton representation of

Fig. 2 Automaton representation of a multi-layered cyber attack to a computer system.

a multi-layer cyber attack to a computer system. Each automaton’s state represents the interaction between
a speciﬁc user and the system. This interaction starts in a “clean” state where legitimate users can request
access to a secure service by providing appropriate credentials. However, through a sequence of exploits, a
cyber attacker may get access to credentials that would give her access to the secure service. The goal is to
design a supervisor that grants access to the service to legitimate users but not to the cyber attacker that
made use of the exploits to obtain the needed credentials. Figure 2 shows a very simple sequential set of M
exploits, but realistic scenarios are characterized by much more complicate networks of exploits.

cleans1s2sMexploit	1exploit	2exploit	Millegal	accessdeauthorize…grantaccessdenial	of	servicedeauthorizegrantaccess6

Masashi Wakaiki et al.

In the example in Figure 2, the set of events is

Σ =

(cid:110)

grant acess, deauthorize, exploit 1, exploit 2, . . . , exploit M

(cid:111)
,

where the “exploits” are uncontrolled events, whereas “grant access” and “deauthorize” as controlled events:

Σc =

(cid:110)

grant acess, deauthorize

(cid:111)
,

Σuc =

(cid:110)

exploit 1, exploit 2, . . . , exploit M

(cid:111)
.

We denote by L ⊂ Σ∗ the language G represented by the automaton described above and by Ksafe ⊂ L the
language that excludes from L all strings that include transitions to the “bad states” labeled with “denial of
service” and “illegal access.” Speciﬁcally, Ksafe does not include any string that starts with “deauthorize” nor
any string that includes the sequences “grant access, deauthorize”; “deauthorize, deauthorize”; or “exploit
M, grant access.”

While the “exploits” are uncontrolled events, we assume that the system has been instrumented with
security logs that allow us to observe those transitions, which corresponds to the following observation map

∆ = Σ,

P (w) = w,

∀w ∈ Σ∗.

(1)

In the absence of attacks (i.e., with A = {Aid}), the supervisor

(cid:40)

f (w) =

Σ \ “grant access” w ∈ Σ∗ Σ+
uc,
otherwise,
Σ \ “deauthorize”

Σ+

uc := Σ∗

uc \ {(cid:15)},

disables “grant access” after strings that end with an exploit event and results in maximal and minimal
languages that are both equal to the desired language: Lmax

f,A = Lmin

f,A = Ksafe.

We are interested in situations where the security systems that generate the logs may have been compro-
mised and create false and/or remove legitimate observations. For simplicity, suppose that the observations
corresponding to each of the M exploits are generated by M security systems and we suspect that one of
them may have been compromised. We can model this scenario by considering the following set of M + 1
attacks:

Alog−attacks := (cid:8)Aid, Aexploit 1, Aexploit 2, . . . , Aexploit M

(cid:9),

(2)

where Aid corresponds to all security systems being good and each Aexploit i corresponds to an attacker having
compromised the security system that logs the occurrence of “exploit i”, which may therefore arbitrarily
insert/remove the output symbols “exploit i” into/from the (correct) observation string P (w), w ∈ ∆∗.
The key question addressed in this paper is whether or not there exists a solution to the supervision of the
language Ksafe under this more interesting attack set Alog−attacks. We shall see later that this is possible for
M ≥ 3, but not possible for M ∈ {1, 2}.

The paper [17] describes examples of the type of multi-layer attack considered in Example 1. One of these
examples considers a scenario where an attacker wants to gain access to a database that requires root access
at a particular Linux server. The server is behind a ﬁrewall and gaining access to it requires a sequence
of exploits that include (1) exploiting a buﬀer overﬂow vulnerability in the Microsoft IIS Web Server to
gain administrative privileges inside the ﬁrewall; (2) scanning the local network ports taking advantage of
a misconﬁgured access control list in a Squid web proxy; (3) through this scan discovering and exploiting
a vulnerability in a URL parsing function of the LICQ software to execute arbitrary code on a client’s
computer; and ﬁnally (4) letting a user without administrative privileges gain them illegitimately through a
local buﬀer overﬂow. This example would correspond to a simple sequence of M = 4 exploits in Figure 1, but
[17] discusses several alternative options to achieve the same goal by exploring these and other vulnerabilities.
In fact, the examples considered in [17, Section 4] correspond to a network of exploits with over 300 nodes
and many more transitions. The examples in [17] are quite speciﬁc in mapping exploits to known system
vulnerabilities reported in the CVE database [4]. However, in practice, many system vulnerabilities are not
known at the time cyber defense systems are designed so the type of analysis proposed in this paper should be
based on automata that include exploits corresponding to unknown software/hardware vulnerabilities. E.g.,

Supervisory Control of Discrete-event Systems under Attacks

7

one may include exploits like privilege escalation from user to administrative, even if no speciﬁc vulnerability
to accomplish this is known for the system under consideration. Note that a system like [9] will be able to
log the privilege escalation by a running process, even if the speciﬁc vulnerability that accomplishes this is
unknown. The results in this paper seek to establish algorithms to process logs (like the ones generated by
(cid:3)
systems like [9]) that are robust to manipulation by an adversary.

Remark 1 (Reduction to a supervisory control problem without attacks) It is often possible to reduce the
problem of ﬁnding a solution to the supervision of a language K under an attack set A to a classical
supervisory control problem without attacks. However, this is achieved by increasing the complexity of the
original language L and the automaton G that generates it, which is problematic from a computational
perspective.

Such a reduction is easy to illustrate for the problem described in Example 1, which could also be modeled
by a DES without attacks by expanding the state-space of the automaton G. To do this, we would replicate
M times the state of the automaton in Figure 2, each replicate corresponding to one output-symbol attack
Aexploit i, i ∈ {1, 2, . . . , m}; and add a new initial state with unobservable transitions to the “clean” state
of every replicate. These transitions from the new initial state deﬁne which attack A ∈ Alog−attacks will
actually take place, but are not visible to the supervisor. The transitions within each one of the M replicates
also need to be adjusted: taking, e.g., the replicate corresponding to the symbol “exploit 1”, to emulate
the insertion of this symbol we would add self-transitions at every state with the event “exploit 1”, and to
emulate the removal of this symbol, we would associate the original transition from “clean” to “s1” with a
symbol that is not observable. This construction results in a new automaton Gexpanded and an associated
output map Pexpanded with the property that any of its output strings Pexpanded(w), w ∈ L(Gexpanded) could
have been generated by the original automaton, under one of the attacks in Alog−attacks. However, Gexpanded
has O(M 2) states and transitions, as opposed to the O(M ) states and transitions in the original automaton
G.

The reduction of supervisory control problem under attacks to a classical problem without attacks may
be more complicated than what we have seen in this example. However, it will generally require some form
of state replication of the original automaton |A| times, one for each possible attack map in the set A, with
initial unobservable transitions to each replicate. In addition, it will generally require the addition of further
(cid:3)
transitions within each replicate to model each of the attacks in A.

4 Existence of supervisor achieving speciﬁcations

A necessary and suﬃcient condition for the existence of a solution to the supervision of K under A can be
expressed in terms of a notion of observability that extends the conventional one presented in Section 2.
Given an attack set A, we say that a preﬁx-closed language K ⊂ L is P -observable for the attack set A if

RA, ¯A ⊂ actK⊂L,

∀A, ¯A ∈ A,

(3)

where the relation RA, ¯A contains all pairs of strings that may result in attacked observation maps AP and
¯AP with a common string of output symbols, i.e.,

RA, ¯A := (cid:8)(w, ¯w) ∈ Σ∗ × Σ∗ : AP (w) ∩ ¯AP ( ¯w) (cid:54)= ∅(cid:9).

The P -observability condition (3) can be equivalently restated as requiring that, ∀w, ¯w ∈ K,

∃A, ¯A ∈ A s.t. AP (w) ∩ ¯AP ( ¯w) (cid:54)= ∅

⇒ (cid:64)σ ∈ Σ s.t. [wσ ∈ K, ¯wσ ∈ L \ K] or [wσ ∈ L \ K, ¯wσ ∈ K].

(4)

or equivalently

∃A, ¯A s.t. AP (w) ∩ ¯AP ( ¯w) (cid:54)= ∅

⇒ ∀σ ∈ Σ : wσ /∈ L or ¯wσ /∈ L or wσ, ¯wσ ∈ K or wσ, ¯wσ ∈ L \ K.

(5)

8

Masashi Wakaiki et al.

In words, observability means that we cannot ﬁnd two attacks A, ¯A ∈ A that would result in the same
observation y ∈ ∆∗ for two strings w, ¯w ∈ K such that (w, w) /∈ actK⊂L, i.e., two w, ¯w ∈ K such that one
will transition to an element in K and the other to an element outside K, by the concatenation of the same
symbol σ ∈ Σ.

The following theorem is the main result of this section. When the set of attacks A contains only Aid, it

specializes to the classical result of [13].

Theorem 1 For every nonempty preﬁx-closed set K ⊂ L and every attack set A:

1. there exists a solution f to the supervision of K under the attack set A if and only if K is controllable

and P -observable for A;

2. if K is controllable and P -observable for A, the map f : (cid:83)

A∈A AP (L) → Σ deﬁned by

f (y) := Σuc ∪

σ ∈ Σc : ∃w ∈ K, A ∈ A s.t. [y ∈ AP (w), wσ ∈ K]

(cid:110)

(cid:111)
,

∀y ∈

(cid:91)

A∈A

AP (L).

(6)

(cid:3)

is a solution to the supervision of K under the attack set A.

Theorem 1 enable us to conclude that if K is controllable and P -observable for A then there exists a
Stackelberg equilibrium policy for the leader (supervisor) that guarantees victory and Theorem 1 provides
one such policy in (6). Conversely, if K is not controllable or not P -observable for A, then there exists no
policy for the supervisory that can guarantee victory for an adversary that knows the policy of the supervisory
(in a Stackelberg sense) and has full information about the game. However, this result does not provide a
solution to scenarios in which K is not controllable or not P -observable for A, but the supervisor does not
advertise its policy or the adversary does not have full information about the game. We conjecture that
in such scenarios, equilibrium policies for the supervisor will be stochastic (either in a Nash or Stackelberg
sense) and the value of the game will be a probability of victory in the (open) set (0, 1).

Remark 2 In the proof of Theorem 1, we will see that to conclude that K is controllable, it suﬃces that
(cid:3)
Lmax

f,A = K for some supervisory f and attack A ∈ A.

f,A = K or Lmin

As in the classic supervisory control problem, the fact that controllability of K is a necessary condition
for the existence of a supervisor is to be expected since, if KΣuc ∩ L were not a subset of K, there would
exist a string ¯w ∈ KΣuc ∩ L, ¯w /∈ K that should not be accepted (because ¯w /∈ K) and yet ¯w is the extension
of a string that should be accepted (because it belongs to K) followed by an uncontrolled event in Σuc.
Once we properly parse the meaning of P -observability for an attack set A, the necessity of this condition
is easy to understand: As noted above, when this condition does not hold, it is possible to ﬁnd two attacks
A, ¯A ∈ A that would result in the same observation y ∈ ∆∗ for two distinct strings w, ¯w ∈ K, and yet w
would transition to an element in K and ¯w to an element outside K. The existence of such strings would
mean that, upon observing y, the supervisor could not decide whether or not to enable the next transition.
It turns out that these two conditions are also suﬃcient to guarantee that we can construct a P -supervisor
f for that guarantees that Lmin
f,A = K for all A ∈ A and Theorem 1 provides such a supervisory. The
following alternative characterization of observability under attacks will be used in the suﬃciency proof.

f,A = Lmax

Proposition 1 Suppose that preﬁx-closed K ⊂ L is controllable. Then K is P -observable for the set of
attacks A if and only if for all w, ¯w ∈ K, σ ∈ Σc, A, ¯A ∈ A, the following statement holds:

[AP (w) ∩ ¯AP ( ¯w) (cid:54)= ∅, wσ ∈ K,

¯wσ ∈ L] ⇒ ¯wσ ∈ K.

(7)

(cid:3)

Proof of Proposition 1: To prove this result, we use the necessary and suﬃcient condition (4) for observ-

ability.

(⇒) Suppose that K is P -observable for A, and suppose that w, ¯w ∈ K, σ ∈ Σc, A, ¯A ∈ A satisfy

AP (w) ∩ ¯AP ( ¯w) (cid:54)= ∅, wσ ∈ K, and ¯wσ ∈ L. Then (4) leads to ¯wσ ∈ K.

Supervisory Control of Discrete-event Systems under Attacks

9

(⇐) Suppose that (7) holds for all w, ¯w ∈ K, σ ∈ Σc, A, ¯A ∈ A. Let w, ¯w ∈ K satisfy AP (w)∩ ¯AP ( ¯w) (cid:54)= ∅
for some A, ¯A ∈ A. Since K is controllable, if σ ∈ Σuc and wσ, ¯wσ ∈ L, then wσ, ¯wσ ∈ K. Moreover, we see
from (7) that, for all σ ∈ Σc, if wσ ∈ K and ¯wσ ∈ L, then ¯wσ ∈ K. Exchanging w and ¯w, we also have if
¯wσ ∈ K and wσ ∈ L, then wσ ∈ K. Thus there does not exist σ ∈ Σ such that [wσ ∈ K, ¯wσ ∈ L \ K] or
♣
[wσ ∈ L \ K, ¯wσ ∈ K].
Proof of Theorem 1: To prove necessity in item 1, assume that there exists a valid P -supervisor f such
that Lmin
f,A = K for all A ∈ A. To prove that K is controllable, we (only) use the fact that K = Lmin
f,A
and pick some word ¯w ∈ KΣuc ∩ L. Such a word must be of the form ¯w = wσ ∈ L such that w ∈ K = Lmin
f,A
for all A ∈ A and σ ∈ Σuc. But then,

f,A = Lmax

w ∈ Lmin

f,A , wσ ∈ L,

∀y ∈ AP (w), σ ∈ Σuc ⊂ f (y).

The deﬁnition of Lmin
KΣuc ∩ L ⊂ K and therefore K is controllable.

f,A thus allows us to conclude that ¯w = wσ ∈ Lmin

f,A = K for all A ∈ A, which shows that

To prove that K is P -observable, we use the fact that K = Lmin

f,A = Lmax

f,A , ∀A ∈ A and pick a pair of

words w, ¯w ∈ K such that

∃A, ¯A s.t. AP (w) ∩ ¯AP ( ¯w) (cid:54)= ∅,

and an arbitrary symbol σ ∈ Σ such that wσ, ¯wσ ∈ L. If wσ ∈ K = Lmin
must have

f,A , then by the deﬁnition of Lmin

f,A , we

w ∈ Lmin

f,A = K, wσ ∈ L,

∀y ∈ AP (w), σ ∈ g(y).

Since AP (w) ∩ ¯AP ( ¯w) (cid:54)= ∅, we must then have

¯w ∈ Lmax

f, ¯A = K,

¯wσ ∈ L,

∃y ∈ ¯AP ( ¯w) s.t. σ ∈ f (y)

and consequently ¯wσ ∈ Lmax

f, ¯A = K. Alternatively, if wσ ∈ L \ K, then wσ /∈ K = Lmax

f,A and we must have

w ∈ Lmax

f,A = K, wσ ∈ L,

∀y ∈ AP (w), σ /∈ f (y).

Since AP (w) ∩ ¯AP ( ¯w) (cid:54)= ∅, we must then have

¯w ∈ Lmin

f, ¯A = K,

¯wσ ∈ L,

∃y ∈ ¯AP ( ¯w) s.t. σ /∈ f (y).

and consequently ¯wσ /∈ Lmin

f, ¯A = K. This shows that (5) holds and therefore K is P -observable for A.

To prove suﬃciency in item 1 (and also the statement in item 2), pick the supervisor according to (6).
f,A for
f,A because of the deﬁnition of this

We prove by induction on the word length that the supervisor f so deﬁned satisﬁes K = Lmax
all A ∈ A. The basis of induction is the empty string (cid:15) that belongs to Lmax
set and belongs to K because this set is preﬁx-closed.

f,A = Lmin

Suppose now that K, Lmax

f,A , and Lmin
f,A of length n + 1. Since ¯w ∈ Lmax

¯wσ ∈ Lmax
On the other hand, since ¯wσ ∈ Lmax

f,A , we must have

f,A have exactly the same words of length n ≥ 0, and pick a word
f,A has length n, we know by the induction hypothesis that ¯w ∈ K.

¯w ∈ Lmax
f,A ,

¯wσ ∈ L,

∃y ∈ AP ( ¯w) s.t. σ ∈ f (y).

If σ ∈ Σuc, then we see from controllability that ¯wσ ∈ K. Let us next consider the case σ ∈ Σc. By the
deﬁnition of f , σ ∈ f (y) must mean that

∃w ∈ K, ¯A ∈ A s.t.

[y ∈ ¯AP (w), wσ ∈ K].

We therefore have

w, ¯w ∈ K, AP ( ¯w) ∩ ¯AP (w) (cid:54)= ∅, wσ ∈ K,

¯wσ ∈ L.

10

Masashi Wakaiki et al.

Proposition 1 therefore shows that ¯wσ ∈ K. This shows that any word of length n + 1 in Lmax
f,A , it follows that any word of length n + 1 in Lmin
to K. Since Lmin
f,A also belongs to K.

f,A ⊂ Lmax

f,A also belongs

Conversely, pick a word ¯wσ ∈ K ⊂ L of length n + 1. Since K is preﬁx closed, ¯w ∈ K, and by the

induction hypothesis that ¯w ∈ Lmin

f,A . To obtain ¯wσ ∈ Lmin

f,A , we need to show that

¯w ∈ Lmin
f,A ,

¯wσ ∈ L,

∀y ∈ AP ( ¯w), σ ∈ f (y).

The ﬁrst statement is a consequence of the induction hypothesis (as discussed above). The second statement
is a consequence of the fact that ¯wσ ∈ K ⊂ L. As regards the third statement, if σ ∈ Σuc, then σ ∈ f (y) for
all y ∈ AP ( ¯w) by deﬁnition. In order to show that if σ ∈ Σc, then σ ∈ f (y) for all y ∈ AP ( ¯w), we need to
prove that

∀y ∈ AP ( ¯w),

∃w ∈ K, ¯A ∈ A s.t. [y ∈ ¯AP (w), wσ ∈ K].

(8)

This holds for the particular case ¯A = A, w = ¯w ∈ K. Thus any word of length n + 1 in K also belongs to
Lmin
♣
f,A , which completes the induction step.

f,A and hence also to Lmax

f,A ⊃ Lmin

Remark 3 Similarly, we can show that

¯f (y) := Σuc ∪

(cid:110)

σ ∈ Σc : ∀w ∈ K, A ∈ A s.t. [y ∈ AP (w), wσ ∈ L] ⇒ wσ ∈ K

(cid:111)
,

∀y ∈

(cid:91)

A∈A

AP (L) (9)

is also a solution to the supervision of K under the attack set A. The supervisor f in (6) is said to be
permissive, while ¯f in (9) is anti-permissive [32,25].
(cid:3)

5 Output-symbol attacks

Given a set of symbols α ⊂ ∆ in the observation alphabet, one can deﬁne an observation attack Aα : ∆∗ →
2∆∗
that maps to each string u ∈ ∆∗ the set of all strings v ∈ ∆∗ that can be obtained from u by an arbitrary
number of insertions or deletions of symbols in α. We say that Aα corresponds to an attack on the output
symbols in α. In this context, it is convenient to also deﬁne the corresponding α-removal observation map
R¬α : ∆ → (∆ ∪ {(cid:15)}) by

R¬α(t) =

(cid:40)
(cid:15)
t

t ∈ α
t (cid:54)∈ α.

The α-removal observation map can be extended to a map deﬁned for strings of output symbols in the same
way as observation maps P . This α-removal observation map allows us to deﬁne Aα : ∆∗ → 2∆∗
as follows:

Aα(u) = (cid:8)v ∈ ∆∗ : R¬α(u) = R¬α(v)(cid:9).

(10)

Note that the absence of attack Aid corresponds to an empty set α = ∅. This type of attacks are precisely
the ones we found in Example 1.

5.1 Observability test

The next result shows that for attacks on output symbols, one can test observability under attacks by
checking regular observability (without attacks) for an appropriate set of output maps. This means that the
observability tests developed for the non-attacked case [2, 24] can be used to determine observability under
output-symbol attacks.

Theorem 2 For every nonempty preﬁx-closed set K ⊂ L and attack set A = {Aα1, Aα2 , . . . , AαM } consisting
of M ≥ 1 observation attacks, K is P -observable for the set of attacks A if and only if K is (R¬α ◦ P )-
observable (in the classical sense, i.e., without attacks) for every set α := αi ∪ αj, ∀i, j ∈ {1, 2, . . . , M }.
(cid:3)

Supervisory Control of Discrete-event Systems under Attacks

11

In essence, Theorem 2 states that to have P -observability for a set of output-symbol attacks, we need
to pick every possible pair of two attacks Aαi, Aαj and ask whether we would have “classical” observability
if we were to remove all symbols aﬀected by the two attacks. This result can be counter-intuitive because
even though we assume that we only have one attack in A, we need to protect consider the eﬀect of pairs
of attacks. If we know which attack in A we had to face, then it would suﬃce to erase from the output
all symbols corresponding to that particular attack. The problem is that we do not know which attack we
are facing and this force us to have more “redundancy” in the sense that we need a stronger version of
observability. In fact, we will see in Theorem 3, that we can construct a supervisor to solve this problem
precisely by removing more symbols than those an attacker could control and then checking for consistency
across the decisions made by “classical” supervisors that operate on reduced sets of symbols.

The following result provides the key step needed to prove Theorem 2.

Lemma 1 Given any two sets α1, α2 ⊂ ∆ and α := α1 ∪ α2, we have that

(v, ¯v) ∈ ker R¬α ⇒ Aα1 (v) ∩ Aα2(¯v) (cid:54)= ∅,

where ker R¬α := {(v, ¯v) ∈ ∆∗ × ∆∗ : R¬α(v) = R¬α(¯v)}.

(11)

(cid:3)

Proof of Lemma 1: To prove this result, we must show that given two words v, ¯v ∈ ∆∗ such that
R¬α(v) = R¬α(¯v), there exists a third word y ∈ ∆∗ that belongs both to Aα1(v) and Aα2 (¯v), and therefore

R¬α1 (v) = R¬α1(y), R¬α2(¯v) = R¬α2(y).

(12)

The desired word y can be constructed through the following steps:

1. Start with the word y1 = R¬α1(v), which is obtained by removing from v all symbols in α1. Since

R¬α = R¬α2 ◦ R¬α1, we have that

R¬α2(y1) = R¬α2(R¬α1 (v)) = R¬α(v) = R¬α(¯v),

and therefore the words y1 and ¯v still only diﬀer by symbols in α1 and α2.

2. Construct y2 by adding to y1 suitable symbols in α1 so that R¬α2(y2) = R¬α2(¯v). This is possible because
y1 and ¯v only diﬀer by symbols in α1 and α2. To get R¬α2(y2) = R¬α2 (¯v), we do not care about the
symbols in α2 so we just have to insert into y1 the symbols in α1 that appear in ¯v (at the right locations).
3. By construction, R¬α1(y2) = R¬α1(y1) = y1 = R¬α1 (v), and hence the original v and y2 only diﬀer by
symbols in α1. Since R¬α2(y2) = R¬α2(¯v), it follows that ¯v and y2 only diﬀer by symbols in α2. We
therefore conclude that y := y2 indeed satisﬁes (12) and hence belongs to both Aα1(v) and Aα2(¯v). ♣

Proof of Theorem 2: By deﬁnition, K is P -observable for the set of attacks A if and only if

RAαi ,Aαj

⊂ actK⊂L,

∀i, j ∈ {1, 2, . . . , M }.

Also by deﬁnition, K is (R¬α ◦ P )-observable for the set α := αi ∪ αj if and only if

ker(R¬α ◦ P ) ⊂ actK⊂L.

To prove the results, it therefore suﬃces to show that, for every i, j ∈ {1, 2, . . . , M }, we have that

RAαi ,Aαj

= ker(R¬α ◦ P ),

α := αi ∪ αj.

To show that this equality holds, ﬁrst pick a pair (w, ¯w) ∈ RAαi ,Aαj
y ∈ ∆∗ that belongs both to AαiP (w) and Aαj P ( ¯w), and therefore

, which means that there exists a word

y ∈ AαiP (w) ⇔ R¬αi
y ∈ Aαj P ( ¯w) ⇔ R¬αj

(cid:0)P (w)(cid:1) = R¬αi(y)
(cid:0)P ( ¯w)(cid:1) = R¬αj (y)

12

Masashi Wakaiki et al.

But then, since α := αi ∪ αj, we have that R¬α = R¬αj ◦ R¬αi = R¬αi ◦ R¬αj , and consequently

R¬α

(cid:0)P (w)(cid:1) = R¬αj

(cid:0)R¬αi

(cid:0)P (w)(cid:1)(cid:1) = R¬αj

(cid:0)R¬αi(y)(cid:1)

We have thus shown that RAαi ,Aαj
ker(R¬α ◦ P ), which means that

= R¬αi

(cid:0)R¬αj (y)(cid:1) = R¬αi

(cid:0)R¬αj

(cid:0)P ( ¯w)(cid:1)(cid:1) = R¬α

(cid:0)P ( ¯w)(cid:1).

⊂ ker(R¬α ◦ P ). To prove the reverse inclusion, pick a pair (w, ¯w) ∈

R¬α

(cid:0)P (w)(cid:1) = R¬α

(cid:0)P ( ¯w)(cid:1),

and therefore (cid:0)P (w), P ( ¯w)(cid:1) ∈ ker R¬α. In conjunction with Lemma 1, this gives

Aαi

(cid:0)P (w)(cid:1) ∩ Aαj

(cid:0)P ( ¯w)(cid:1) (cid:54)= ∅.

Therefore we have (w, ¯w) ∈ RAαi ,Aαj

. This shows that ker(R¬α ◦ P ) ⊂ RAαi ,Aαj

, which concludes the proof.
♣

Example 2 (Multi-layer cyber attack to a computer system (cont.)) In Example 1 we considered M attacks
Aexploit i, i ∈ {1, . . . , M }, each corresponding to an adversary having compromised the security system that
logs the occurrence of “exploit i”, allowing it to arbitrarily insert/remove the output symbols “exploit i”
into/from the observation string. Each of these is an output-symbol attack Aα, with the set α including a
single output symbol “exploit i”. Using the Aα-notation introduced above, we can thus write the attack set
Alog−attacks in (2) as.

Alog−attacks := (cid:8)A∅, A{exploit 1}, A{exploit 2}, . . . , A{exploit M}

(cid:9).

Theorems 1 and 2 can be used to conﬁrm our previous assertion that there exists a solution to the supervision
of the language Ksafe under the attack set Alog−attacks if and only if M ≥ 3. This is because Ksafe is P -
observable for the attack set Alog−attacks if and only if M ≥ 3:
1. For M = 1, Ksafe is not P -observable for the attack set Alog−attacks := (cid:8)A∅, A{exploit 1}

(cid:9) because Ksafe
is not (R¬{exploit 1} ◦ P )-observable. This is straightforward to conclude from Theorem 2 because if we
remove from the output strings all symbols “exploit 1”, the supervisor cannot distinguish between the
“clean” and “s1” states.

2. For M = 2, Ksafe is still not P -observable for the attack set Alog−attacks := (cid:8)A∅, A{exploit 1}, A{exploit 2}
because Ksafe is not (R¬{exploit 1,exploit 2} ◦ P )-observable. Again, this is straightforward to conclude from
Theorems 2 because if we remove from the output strings all symbols “exploit 1” and “exploit 2”, the
supervisor cannot distinguish between the “clean”, “s1”, “s2” states.

(cid:9)

This result may seem counter-intuitive because none of the attacks in Alog−attacks is actually able to
insert/remove both symbols “exploit 1” and “exploit 2” and yet the test involves a system where we
removed both symbols. To understand this apparent paradox, suppose that the supervisor observes the
output string

This output string could have resulted from two scenarios:
(a) The event sequence is

{grant access, exploit 1}.

{grant access, exploit 1, exploit 2},

but an output-symbol attack A{exploit 2} erased the symbol “exploit 2”.

(b) The event sequence is

but an output-symbol attack A{exploit 1} inserted the symbol “exploit 1”.

{grant access},

Supervisory Control of Discrete-event Systems under Attacks

13

The existence of these two options is problematic because in the former case “grant access” must be
disabled, whereas in latter case it must be enabled.

3. For M ≥ 3, Ksafe becomes P -observable for the attack set

Alog−attacks := (cid:8)A∅, A{exploit 1}, . . . , A{exploit M}

(cid:9)

because Ksafe is (R¬{exploit i,exploit i} ◦ P )-observable, for every i, j ∈ {1, 2, . . . , M }. Again, this is straight-
forward to conclude from Theorems 2 because even if we remove from the output strings all pairs of
symbols “exploit i” and “exploit j”, there will still remain a third symbol “exploit k” k (cid:54)= i, k (cid:54)= j in the
(cid:3)
output string that allows the supervisor to deduce a transition out of the “clean” state.

Remark 4 (complexity) As noted in Remark 1, it is often possible to reduce the problem of ﬁnding a solution
to the supervision under an attack set A to a classical supervisory control problem without attacks, at
the expense of having to expand the state of the original automaton, essentially by replicating each state
M := |A| times. For problems in which the complexity of testing observability is linear in the number of
states of the original automaton, this reduction may be computationally more eﬃcient than using the result
in Theorem 2, which would require testing the observability of (cid:0)M

(cid:1) = O(M 2) systems.

2

2

The simple structure of Example 2 allowed us to prove observability for every M ≥ 3 through a formal
argument. However, more complicated networks of exploits typically require the use of computational tests
for observability. If we had to perform a computational test for Example 2, Theorem 2 would require testing
the observability of (cid:0)M
(cid:1) = (M 2 + M )/2 distinct systems, each with O(M ) states and transitions. For this
problem, one can show that each of these tests would have a worst-case computational complexity O(M 3),
using the algorithm in [2, Section 3.7.3]. This would lead to a worst-case complexity O(M 5). Alternatively,
the expansion described in Remark 1 would lead to a single observability test for a system with O(M 2) states
and transitions. Even with more states, the observability test for this system based on the algorithm in [2,
Section 3.7.3] would still only have a worst-case complexity O(M 4). However, while sometimes attractive to
test observability, we shall see shortly that the expansion described in Remark 1 generally results in much
(cid:3)
higher worst-case complexity for the design of the supervisor.

5.2 Supervisor design

The following result shows that for attacks on output symbols, one can construct a solution to the super-
vision of K ⊂ L under attacks by appropriately combining a set of classical supervisors, each designed
for an appropriately deﬁned output map without attacks. This allow us to reuse classical supervisor-design
approaches and tools [7,2,10].

Theorem 3 For a given nonempty preﬁx-closed set K ⊂ L and attack set A = {Aα1, Aα2 , . . . , AαM } con-
sisting of M ≥ 1 observation attacks, assume that K is controllable and P -observable for A. In view of
Theorems 1 and 2, this means that, for every i, j ∈ {1, 2, . . . , M } there exists a valid supervisor fij that
generate the language K for the observation map Pij := R¬(αi∪αj ) ◦ P (in the classical sense, i.e., without
attacks). In this case, the following supervisor is a solution to the supervision of K under the attack set A:

f (y) :=

M
(cid:91)

i=1

f i(y),

f i(y) :=

M
(cid:92)

j=1

˜fij(y),

∀y ∈

M
(cid:91)

i=1

AαiP (L),

where

˜fij(y) :=

(cid:40)

fij(R¬(αi∪αj )(y))
Σuc

y ∈ AαiP (L) ∪ Aαj P (L)
y (cid:54)∈ AαiP (L) ∪ Aαj P (L).

(13)

(cid:3)

Remark 5 As we shall see in the proof of Theorem 3, the lower branch of (13) can be set equal to any subset
(cid:3)
of Σ (possibly y-dependent) that contains Σuc.

14

Masashi Wakaiki et al.

Proof of Theorem 3: Since every fij is a valid supervisor, all the sets fij(y) and ˜fij(y) contain Σuc and
consequently so does f (y), which proves that f is a valid supervisor. To complete the proof, it thus suﬃces
to show that

Lmin

f,Aαk

⊃ K ⊃ Lmax

f,Aαk

,

∀Aαk ∈ A.

f,Aαk

First we prove Lmin
⊃ K by showing that every word w in K also belongs to Lmin
. We do this prove
by induction on word length n. The basis of induction is trivially true because the empty string belongs
to Lmin
by construction. Suppose now that we have established that every word w ∈ K of length n also
f,Aαk
belongs to Lmin
and take an arbitrary word wσ ∈ K of length n + 1. Since K is preﬁx closed, we have
that w ∈ K and by the induction hypothesis that w ∈ Lmin
. In view of the deﬁnition of minimal language,
to prove that wσ ∈ Lmin
we need to show that σ ∈ f (y), ∀y ∈ Aαk P (w). To accomplish this, we pick an
arbitrary string y ∈ Aαk P (w) and note that, because every fkj generates the language K for the observation
map Pkj := R¬(αk∪αj ) ◦ P , we have that

f,Aαk

f,Aαk

f,Aαk

f,Aαk

wσ ∈ K ⇔ w ∈ K, wσ ∈ L, σ ∈ fkj

(cid:0)R¬(αk∪αj )

(cid:0)P (w)(cid:1)(cid:1),

∀j ∈ {1, . . . , M }.

(14)

Since y ∈ Aαk P (w), we conclude from (10) that

R¬(αk∪αj )(y) = R¬(αk∪αj )

(cid:0)P (w)(cid:1).

(15)

Moreover, we now that wσ ∈ K, therefore (14) and (15) imply that

σ ∈ fkj

(cid:0)R¬(αk∪αj )

(cid:0)P (w)(cid:1)(cid:1) = fkj

(cid:0)R¬(αk∪αj )(y)(cid:1) = ˜fkj(y),

∀j ∈ {1, . . . , M }.

We have thus shown that

σ ∈ f k(y) =

M
(cid:92)

j=1

˜fkj(y) ⊂ f (y).

This conﬁrms that wσ ∈ Lmin

f,Aαk

, which completes the induction step.

We show next that Lmax

f,Aαk

⊂ K, also using an induction argument. As before, the basis of induction is

trivial so to establish the induction step, we suppose that we have established that every word w ∈ Lmax
f,Aαk
of length n also belongs to K and take an arbitrary word wσ ∈ Lmax
of length n + 1. By the induction
hypothesis, we have that w ∈ K and to prove the induction step, we need to show that wσ ∈ K. From the
construction of Lmax

, we known that wσ ∈ Lmax

implies that w ∈ Lmax

f,Aαk

and

f,Aαk

f,Aαk

f,Aαk

∃y ∈ Aαk P (w)

s.t. σ ∈ f (y) :=

M
(cid:91)

i=1

f i(y)

and therefore

∃y ∈ Aαk P (w), i ∈ {1, . . . , M }

s.t. σ ∈ f i(y) :=

M
(cid:92)

j=1

˜fij(y) ⊂ ˜fkj(y) = fkj

(cid:0)R¬(αk∪αj )(y)(cid:1).

Also here (15) holds and we conclude that

σ ∈ fkj

(cid:0)R¬(αk∪αj )(y)(cid:1) = fkj

(cid:0)R¬(αk∪αj )

(cid:0)P (w)(cid:1)(cid:1).

Again, because fkj generates the language K for the observation map Pkj := R¬(αk∪αj ) ◦ P , the equivalence
in (14) holds. Since we have shown that all the conditions in the right-hand side of (14) hold, we conclude
♣
that wσ ∈ K, which completes the proof of the induction step.

Supervisory Control of Discrete-event Systems under Attacks

15

Example 3 (Multi-layer cyber attack to a computer system (cont.)) To construct a supervisor for the problem
described in Examples 1-2 using Theorem 3 we need valid supervisors fij that generate the language Ksafe
for the observation maps Pij := R¬(αi∪αj ) ◦ P , ∀αi, αj ∈ Alog−attacks. For M ≥ 3, all these supervisors can
be the same and deﬁned by

(cid:40)

fij(y) =

Σuc ∪ {grant access} T (y) does not contain any “exploit” symbol
Σuc ∪ {deauthorize}

T (y) contains some “exploit” symbols,

where T (y) denotes the last output symbols in the string y, starting right after the last “grant access” or
“deauthorize” symbols, or from the beginning of y if it does not contain such symbols. Essentially T (y)
contains the output symbols starting from the last time that the system was in the “clean” state. These
supervisors enforce the language Ksafe because if T (y) does not contain any “exploit” symbol for the output
map Pij := R¬(αi∪αj ) ◦ P , then we must be in the “clean” state (in case Pij did not remove any “exploit”
symbol), in the “s1” state (in case Pij removed one “exploit” symbols), or in the “s2” state (in case Pij
removed two “exploit” symbols). In either case, it is okay to enable the “grant access” transition and disable
the “deauthorize” transition. On the other hand, if T (y) does contain any “exploit” symbol, then we must be
in one of the “si” states and it is safe to enable the “deauthorize” transition and disable the “grant access”
transition.

For these supervisors fij, we have

(cid:40)

˜fij(y) =

Σuc ∪ {grant access} T (y) does not contain any “exploit” symbol other than those in αi ∪ αj,
Σuc ∪ {deauthorize}

T (y) contains some “exploit” symbols other those in αi ∪ αj,

f i(y) =

f (y) =










Σuc ∪ {grant access} T (y) does not contain any “exploit” symbol, other than that in αi,
Σuc
Σuc ∪ {deauthorize}

T (y) contains one or more copies of the same “exploit” symbol, not in αi,
T (y) contains one or more copies of two distinct “exploit” symbols not in αi,

Σuc ∪ {grant access} T (y) does not contain any “exploit” symbol,
Σuc ∪ {grant access} T (y) contains one or more copies of a single “exploit” symbol,
Σuc ∪ {deauthorize}

T (y) contains one or more copies of two distinct “exploit” symbols.

The implementation of this supervisor could be done with a ﬁnite state machine with M + 1 symbols, one
state would correspond to “no exploit symbol observed in T (y)” and the remaining M states would be use
(cid:3)
to memorize the index of the 1st exploit symbol observed in T (y).

Remark 6 (Complexity) While testing observability has polynomial complexity in the number of states of
the plant automaton G representing the original language L and on the number of states of the speciﬁcation
automaton GK representing the desired language K, the number of states of the supervisor is typically
exponential in the number of states of the plant automaton [24,2]. To apply Theorem 3, we thus need to
design O(|A|2) supervisors, each with worst-case exponential complexity in the number of states of G, leading
to a complexity of O(|A|2e|X|), where |X| denotes the number of states of G. If we were to use instead the
reduction to a supervisory control problem without attacks discussed in Remark 1, we would need to solve
a single supervisor design problem. However, this problem would have worst-case exponential complexity on
the number of states of an expanded automaton, leading to a much worse worst-case complexity of O(e|A||X|).
(cid:3)

6 Conclusion

Motivated by computer security applications, we introduced a multi-adversary version of the DESs super-
visory control problem, where the supervisor is asked to enforce a desired language based on measurements
that have been corrupted by one of several potential opponents, not know which is the actual opponent.
For the particular case of output-symbol attacks, we have show that testing observability and constructing

16

Masashi Wakaiki et al.

a supervisor that solves this multi-adversary problem can be done using tools developed for the classical
supervisory control problem, without expanding the state-space of the original plant automaton.

Important direction for future research include the development of eﬃcient computational techniques
for adversaries that use attacks more general than output-symbol attacks and investigating distributed
solutions to the problem considered here. The latter is especially interesting for scenarios with distributed
cyber-security sensors. As noted above, this paper also does not provide results for scenarios in which the
controllability and observability conditions do not hold. We conjecture that, in the absence of observability
under attacks, saddle-point policies for the attacker/supervisory that maximize/minimize the probability
that the supervisor will make a mistake will be mixed, but we do not know of eﬃcient algorithms to compute
such policies.

References

1. Amin, S., Litrico, X., Sastry, S., Bayen, A.M.: Cyber security of water SCADA systems–part i: Analysis and experimentation

of stealthy deception attacks. IEEE Trans. on Contr. Syst. Tech. 21, 1963–1970 (2013)

2. Cassandras, C.G., Lafortune, S.: Introduction to Discrete Event Systems, 2nd edn. Springer (2008)
3. Chong, M.S., Wakaiki, M., Hespanha, J.P.: Observability of linear systems under adversarial attacks. In: Proc. of the 2015

Amer. Contr. Conf. (2015)

4. Corporation, T.M.: Common vulnerabilities and exposures (cve) list (2018). URL https://cve.mitre.org"
5. Dubreil, J., Darondeau, P., Marchand, H.: Supervisory control for opacity. IEEE Trans. Automat. Control 55, 1089–1100

(2010)

6. Fawzi, H., Tabuada, P., Diggavi, S.: Secure estimation and control for cyber-physical systems under adversarial attacks.

IEEE Trans. on Automat. Contr. 59, 1454–1467 (2014)

7. Feng, L., Wonham, W.: TCT: A computation tool for supervisory control synthesis. In: 8th International Workshop on

Discrete Event Systems, pp. 388–389 (2006)

8. Hubballi, N., Biswas, S., Roopa, S., Ratti, R., Nandi, S.: LAN attack detection using discrete event systems. ISA Trans.

50, 119–130 (2011)

9. Ji, Y., Lee, S., Downing, E., Wang, W., Fazzini, M., Kim, T., Orso, A., Lee, W.: Rain: Reﬁnable attack investigation with
on-demand inter-process information ﬂow tracking. In: Proceedings of the 2017 ACM SIGSAC Conference on Computer
and Communications Security, pp. 377–390. ACM (2017)

10. Lafortune, S., Ricker, L.: Desuma2 (2014). https://wiki.eecs.umich.edu/desuma
11. Lin, F.: Robust and adaptive supervisory control of discrete event systems. IEEE Trans. on Automat. Contr. 38, 1848–1852

(1993)

12. Paoli, A., Sartini, M., Lafortune, S.: Active fault tolerant control of discrete event systems using online diagnostics. Auto-

matica 47, 639–649 (2011)

13. Ramadge, P.J., Wonham, W.M.: The control of discrete event systems. Proc. of IEEE 77, 81–98 (1989)
14. Saboori, A., Hadjicostis, C.N.: Opacity-enforcing supervisory strategies via state estimator constructions. IEEE Trans. on

Automat. Contr. 57, 1155–1165 (2012)

15. Saboori, A., Zad, S.H.: Robust nonblocking supervisory control of discrete-event systems under partial observation. Syst. &

Contr. Lett. 55, 839–848 (2006)

16. S´anchez, A.M., Montoya, F.J.: Safe supervisory control under observability failure. Discrete Event Dyn. System: Theory

Appl. 16, 493–525 (2006)

17. Sheyner, O., Wing, J.: Tools for generating and analyzing attack graphs. In: F.S. de Boer, M.M. Bonsangue, S. Graf, W.P.
de Roever (eds.) Formal Methods for Components and Objects: Second International Symposium, FMCO 2003, Leiden,
The Netherlands, November 4-7, 2003. Revised Lectures, no. 3188 in Lecture Notes on Computer Science, pp. 344–371.
Springer-Verlag, Berlin (2004)

18. Shoukry, Y., Tabuada, P.: Event-triggered state observers for sparse noise/attacks. IEEE Trans. on Automat. Contr. 61(8),

2079–2091 (2016)

19. Shu, S., Lin, F.: Fault-tolerant control for safety of discrete-event systems. IEEE Trans. Autom. Sci. Eng. 11, 78–89 (2014)
20. Takai, S.: Robust supervisory control of a class of timed discrete event systems under partial observation. Syst. & Contr. Lett.

39, 267–273 (2000)

21. Takai, S., Oka, Y.: A formula for the supremal controllable and opaque sublanguage arising in supervisory control. SICE

J Control Meas. System Integr. 1, 307–311 (2008)

22. Teixeira, A., Shames I. Sandberg, H., Johansson, K.H.: A secure control framework for resource-limited adversaries. Auto-

matica 51, 135–148 (2015)

23. Thorsley, D., Teneketzis, D.: Intrusion detection in controlled discrete event systems. In: Proc. of the 45th Conf. on Decision

and Contr. (2006)

24. Tsitsiklis, J.N.: On the control of discrete-event dynamical systems. Math. Control Signals Systems pp. 96–107 (1989)
25. Ushio, T., Takai, S.: Supervisory control of discrete event systems modeled by Mealy automata with nondeterministic

output functions. In: Proc. of the 2009 Amer. Contr. Conf. (2009)

26. Ushio, T., Takai, S.: Nonblocking supervisory control of discrete event systems modeled by Mealy automata with nonde-

terministic output functions. IEEE Trans. on Automat. Contr. 61(3), 799–804 (2016)

Supervisory Control of Discrete-event Systems under Attacks

17

27. Whittaker, S.J., Zulkernine, M., Rudie, K.: Toward incorporating discrete-event systems in secure software development.

In: Proc. ARES’08 (2008)

28. Wonham, W.M.: Supervisory control of discrete-event systems (2014). URL http://www.control.toronto.edu/DES/
29. Wu, Y.C., Lafortune, S.: Synthsis of insertion functions for enforcement of opacity security properties. Automatica 50,

1336–1348 (2014)

30. Xu, S., Kumar, R.: Discrete event control under nondeterministic partial observation. In: Proc. IEEE CASE’09 (2009)
31. Yin, X.: Supervisor synthesis for Mealy automata with output functions: A model transformation approach. IEEE Trans-

actions on Automatic Control 62(5), 2576–2581 (2017)

32. Yoo, T.S., Lafortune, S.: A general architecture for decentralized supervisory control of discrete-event systems. Discrete

Event Dyn. System: Theory Appl. 12, 335–377 (2002)

