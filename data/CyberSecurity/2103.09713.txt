1
2
0
2

r
a

M
7
1

]

R
C
.
s
c
[

1
v
3
1
7
9
0
.
3
0
1
2
:
v
i
X
r
a

Cyber Intrusion Detection by Using Deep Neural
Networks with Attack-sharing Loss

Boxiang Dong∗, Hui (Wendy) Wang†, Aparna S. Varde∗, Dawei Li∗, Bharath K. Samanthula∗,
Weifeng Sun‡, Liang Zhao‡
∗Montclair State University, Montclair, New Jersey 07043

dongb, vardea, dawei.li, samanthulab

Email:
@montclair.edu
†Stevens Institute of Technology, Hoboken, New Jersey 07030

{

}

Email:

Hui.Wang

@stevens.edu

†Dalian University of Technology, Dalian, China 116024

{

}

Email:

{

wfsun, liangzhao

@dlut.edu.cn

}

Abstract—Cyber attacks pose crucial threats to computer
system security, and put digital treasuries at excessive risks. This
leads to an urgent call for an effective intrusion detection system
that can identify the intrusion attacks with high accuracy. It is
challenging to classify the intrusion events due to the wide variety
of attacks. Furthermore, in a normal network environment, a
majority of the connections are initiated by benign behaviors. The
class imbalance issue in intrusion detection forces the classiﬁer to
be biased toward the majority/benign class, thus leave many at-
tack incidents undetected. Spurred by the success of deep neural
networks in computer vision and natural language processing, in
this paper, we design a new system named DeepIDEA that takes
full advantage of deep learning to enable intrusion detection and
classiﬁcation. To achieve high detection accuracy on imbalanced
data, we design a novel attack-sharing loss function that can
effectively move the decision boundary towards the attack classes
and eliminates the bias towards the majority/benign class. By
using this loss function, DeepIDEA respects the fact that the
intrusion mis-classiﬁcation should receive higher penalty than the
attack mis-classiﬁcation. Extensive experimental results on three
benchmark datasets demonstrate the high detection accuracy of
DeepIDEA. In particular, compared with eight state-of-the-art
approaches, DeepIDEA always provides the best class-balanced
accuracy.

Index Terms—Intrusion detection, Deep learning, Imbalanced

classiﬁcation.

I. INTRODUCTION

Recent years witness an expeditious outbreak of cyber
attacks. Online Trust Alliance [1] revealed that 2017 is “the
worst year ever” in data breaches and cyber attacks around
the world. The amount of disclosed cyber incidents targeting
businesses nearly doubled from 82,000 in 2016 to 159,700 in
2017. The penetration attack at Equifax leaked the ﬁnancial
credit report of 145 million consumers, which constitutes 45%
of the total population in the U.S. The WannaCry ransomware
attack infected 300,000 computer systems within four days,
and severely disrupted the medical appointments in the U.K..
These catastrophic attacks bring forth the most
intensive
aspirations for an effective intrusion detection system (IDS)
that can identify the intrusion with high accuracy.

Traditional signature-based IDS techniques heavily depend
on the signature database constructed by security experts, and
thus fail to detect novel attacks. A wide variety of data mining

and machine learning models, e.g., decision tree, support
vector machine (SVM), and graph mining algorithms [4],
[6], [9], have been adapted to discover anomaly from the
network monitoring data. However, they are not favorable at
representing intrusion detection classiﬁcation functions that
have many complex variations [5].

Recently, deep learning emerges as a favorable solution to
dealing with complicated input-output mappings. Its applica-
tion in computer vision and natural language processing leads
to breakthroughs in these areas. Speciﬁcally, it builds a neural
network by stacking a certain number of layers of neurons.
With sufﬁciently large number of layers and units, a deep
network can represent functions of high complexity. Compared
with traditional machine learning models, it avoids the need
for feature extraction. Most importantly, it produces the best-
in-class accuracy by learning from a large amount of labeled
data.

Quite a few latest research in intrusion detection resort to
deep learning. Most of them [16], [8] simply learn a new
feature representation by using various deep neural networks
(e.g., deep autoencoder and convolutional networks), and then
rely on traditional classiﬁers such as SVM and k-nearest
neighbor (KNN) to detect attacks. Kitsune [23] is the most
recent work that detects network intrusion attacks with deep
neural networks. It applies an ensemble of autoencoders to
learn the identify function of the original data distribution.
For any new instance, its anomaly score is calculated based on
the distance between the autoencoders’ output and its feature
values. However, we argue that such a design only employs
deep learning to discover inherent/generic features in network
connections, but fails to take advantage of its capacity to learn
complex classiﬁcation functions.

There are two major challenges of designing a deep neural
network based intrusion detection system. We discuss these
two challenges below.
Challenge 1: diversity of intrusion attacks. There are many
types of intrusion attacks, each exploiting a wide range of
techniques to conduct the invasion. Even the same type of
attacks can exhibit different behavior patterns.
Challenge 2: imbalanced class distribution. In a healthy

 
 
 
 
 
 
s
e
c
n
e
r
r
u
c
c
O

f
o
#

 2x106

 1x106

 0

Benign DoS DDoS BF Infiltration

Fig. 1. Class distribution of the CICIDS17 dataset. There are ﬁve classes,
including the benign event and four types of attacks, namely DoS, DDoS,
brute-force (BF), and inﬁltration attacks.

network environment, a majority of the connections are be-
nign. This makes the network connection instances follow
a long-tail class distribution. Moreover, different types of
intrusion attacks are unevenly distributed in practice. As an
example, consider a real-world network intrusion detection
dataset named CICIDS17, which is collected and released
by Canadian Institute for Cybersecurity. The data is labeled
with 5 classes, including the benign class and four types of
attacks, namely DoS, DDoS, brute-force (BF), and inﬁltration
attacks. The distribution of the intrusion attacks is illustrated
in Figure 1. Apparently, the classes are highly imbalanced.
The imbalanced class distribution forces the classiﬁer models
to be biased toward the majority class, and thus lead to poor
accuracy on the minority classes (i.e., the intrusions).

To address these two challenges, we build a new intrusion
detection and classiﬁcation framework named DeepIDEA (a
Deep Neural Network-based Intrusion Detector with Attack-
sharing Loss). DeepIDEA takes full advantage of deep learn-
ing to extract features and learn the classiﬁcation boundary.
Besides, we design a new loss function named attack-sharing
loss function that eliminates the bias towards the major-
ity/benign class by moving the decision boundary towards the
attack classes. To our best knowledge, this is the ﬁrst work on
imbalanced deep learning for intrusion detection. Speciﬁcally,
we make the following contributions.

First, we construct a deep feedforward network to learn
intricate patterns of benign communications and malicious
connections from the training data. To expedite the learning
process on large data, we adapt a novel optimization algorithm
that keeps track of an exponentially decaying average of
the ﬁrst-order and second-order moment of past gradients to
dynamically adjust the learning rate.

Second, to address the class imbalance problem in intrusion
detection, we design a new loss function named attack-sharing
loss for our deep feedforward network. The attack-sharing
loss function takes the discrepancy penalty of different types
of mis-classiﬁcation (e.g., mis-classifying attack types versus
mis-classifying intrusion as normal) into consideration, so
that the mis-classiﬁcation of intrusions as benign receives
more penalty than the mis-classiﬁcation of attacks. It can be
integrated with any deep neural network to mitigate the bias

towards the majority class.

Last but not least, we launch an extensive set of experiments
on three benchmark datasets. The comparison with 8 baseline
approaches demonstrate the effectiveness of DeepIDEA. In
particular, DeepIDEA produces the best detection accuracy on
every dataset.

The rest of the paper is organized as follows. Section II
discusses the background information. Section III presents our
the design of DeepIDEA. Section IV shows the experiment
results. Section V introduces the related work. Finally, Section
VI concludes the paper.

II. BACKGROUND

In this section, we introduce the background knowledge,
intrusion

including the concepts of deep neural network,
attacks, and imbalanced classiﬁcation.

A. Deep Neural Network

Multi-layer perceptrons (MLPs), also known as deep feed-
forward network,
is a network that consists of an input
layer, multiple hidden layers, and an output layer. Each layer
includes a certain number of neurons/units. The neurons in
consecutive layers are connected by links with certain weights.
Besides MLPs, other specialized architectures have been pro-
posed in recent years. For example, convolutional networks are
known for image processing, while recurrent neural networks
are specialized at capturing long term dependencies [13].
Learning the parameters (i.e., weights and bias) of a neural
network is typically solved by using gradient descent. Back
propagation provides an efﬁcient way to calculate the gradients
so as to optimize the weights associated with the connections.
Various optimization algorithms were proposed to acclerate
the learning process, e.g., stochastic gradient descent (SGD)
[21], Nesterov Momentum [22], and Adam optimizer [18].

B. Intrusion Attacks

Numerous types of network intrusion attacks make it intri-
cate to design an effective detection method. Next, we brieﬂy
introduce ﬁve prevailing attacks that are investigated in this
paper.

• Brute-Force attack is the most simple attack to gain illegal
access to a site or server. The most common brute-force
attack is the dictionary attack that cracks user passwords.
There have been a few successful brute-force attacks. For
example, in 2016, a massive brute-force attack against
Alibaba Inc, a Chinese e-commerce giant, compromised
20.6 million accounts [2].

• Botnet attack exploits a number of Internet-connected
devices (zombies) to carry out malicious and criminal
tasks. As an example, a recent study [12] of 6 million
Twitter accounts reveals that 350,000 of them are zombies
of the Star Wars botnet.

• Probing attack scans a victim device in order to determine
the vulnerabilities that can be exploited to compromise
the system. It usually uses a network mapper (e.g.,

 
 
Nmap1) to send TCP packets to discover vulnerable hosts
and services.

• DoS/DDoS attack overloads the target machine and pre-
vents it from serving the intended users. DDoS is different
from DoS mainly in that it leverages multiple systems to
exhaust the resources of the victim. The famous 2016
DDoS attack against Dyn DNS [3] made it impossible
for users to connect to Amazon, GitHub, Spotify, etc.
• Inﬁltration attack leverages the vulnerability in particular
software such as Adobe Acrobat Reader to execute a
backdoor on the target computer. Once the attack is suc-
cessful, the attacker can launch various types of attacks
against the victim’s network, including IP sweep and port
scan.

C. Imbalanced Classiﬁcation

In general, the intrusion detection problem can be modeled
as a classiﬁcation problem in machine learning, by which
the classiﬁcation model outputs if the network system is
intruded or not. In most real-world datasets, the data labels
follow a long tail distribution, i.e., some speciﬁc classes are
represented by a very small number of instances compared to
other classes. In the scenario of intrusion detection, the data
is also imbalanced, as the benign network behaviors dominate
the collected dataset, while the intrusion events are rarely
observed. To improve the overall accuracy, the imbalanced
data forces the classiﬁcation model to be biased toward the
majority classes. This class imbalance problem renders poor
accuracy on detecting intrusion attacks, as intrusion classes are
under-represented. Several approaches [27] try to mitigate the
negative effects of imbalanced data for general classiﬁcation
problems. One solution is to do over-sampling [15] or under-
sampling [20]. In particular, over-sampling on the under-
represented classes duplicates these instances, while under-
sampling [20] eliminates samples in the over-sized classes.
However, over-sampling often leads to over-ﬁtting and longer
training time, and under-sampling degrades the overall ac-
curacy since it discards potentially useful training instances.
Another solution is to make the loss function cost-sensitive
by associating larger error penalty with under-represented
classes [17]. However, in deep learning, such cost-sensitive
loss function can make the loss of a minibatch highly sensitive
to the label distribution. As the consequence, it leads to non-
convergence of the training process, and potentially inferiors
the decision boundary of the classiﬁer.

III. OUR APPROACH

In this section, we present

the details of our intrusion
detector, namely DeepIDEA. In particular, we will discuss
the model, loss function, and the optimization procedure of
DeepIDEA.

A. Model

At high level, DeepIDEA is built as a fully-connected neural
network with one input layer, L > 1 hidden layers, and

1https://nmap.org/

one output layer. The input layer consists of d units, each
representing an input feature. The architecture of DeepIDEA is
illustrated in Figure 2. Next, we explain the details of the
model.

We denote each input data point as (x, y), where x is
the set of features, and y is the label. The input layer of
DeepIDEA consists of d neurons that take input features. For
the sake of simplicity, for any instance (x, y), we assume
h(0) = x. We use h(ℓ) to denote the output of the ℓ-th hidden
be the i-th unit of the ℓ-th hidden
ℓ
layer (1
≤
layer. The output of n(ℓ)

i
is computed as:

L). Let n(ℓ)

≤

i

i

(1)

i ),

˜h(ℓ−1) + b(ℓ)

i = g(w(ℓ)
h(ℓ)
is the rectiﬁed linear units (ReLU)
where g(x) = max
0, x
}
{
activation function, w(ℓ)
is the i-th row in the weight matrix
1)-th and ℓ-th layer, b(ℓ) is the bias
that connects the (ℓ
vector at the ℓ-th layer, and ˜h(ℓ−1) is the thinned output from
the (i
1)-th layer by using dropout. In particular,
˜h(ℓ−1) = h(ℓ−1)

(2)

r,

−

−

i

∗

∗

is the Hadamard product operator, r is a mask vector
where
that speciﬁes which units to be used. In particular, r consists
of independent Bernoulli random variables, each of which has
probability p of being 1, i.e., ri

Bernoulli(p).

The output layer of the neural network includes c softmax
units, where c is the number of classes. For any instance
(x(i), y(i)), the predicted probability that it belongs to the j-th
class p(i)
j

is computed as

∼

p(i)
j = sof tmax(z)j =

exp(zj)
c
k=1 exp(zk)

,

(3)

where z is a vector of linear activations of the output layer.

P

B. Attack-sharing Loss Function

Most modern neural networks use cross-entropy loss JCE to
describe the discrepancy between the ground-truth labels and
the model predictions. In particular, the loss JCE is calculated
as:

JCE(θ) = E

(x(i),y(i))∼ ˆpdataL(f (x(i); θ), y(i))
E
(x(i),y(i))∼ ˆpdata log p(y(i)

x(i); θ)

|
I(y(i), j) log p(i)
j ,

(4)

=

=

−

1
N

−

N

c

i=1
X

j=1
X

where θ consists of the weight matrix between consecutive
layers in the neural network, ˆpdata is the empirical data
distribution in the training set, p(y(i)
x(i); θ) is the probability
that the neural network correctly classiﬁes the input x(i), N
is the number of training samples, c is the number of classes,
and I is the indicator function s.t.

|

I(a, b) =

1
0

(

if a=b
otherwise.

(5)

The parameters θ in the network are optimized so as to min-
imize JCE(θ) and obtain the desired classiﬁcation accuracy.

Input Layer

x

˜x

h(1)

˜h(1)

h(L)

˜h(L)

Hidden Layer

Output Layer

z

ǫ

r

……

r

˜x = x ⊙ ǫ

h(1) = g!W (1) ˜x + b(1)"
˜h(1) = h(1) ∗ r

h(L) = g!W (L) ˜h(L−1) + b(L)"
˜h(L) = h(L) ∗ r

Fig. 2. The model structure of DeepIDEA (Tildes indicate regularized layers)

One weakness of the cross-entropy loss function is that it
does not take the type of mis-classiﬁcation into consideration,
and thus penalizes the classiﬁcation error for all classes
equally. There are two types of mis-classiﬁcation for the
intrusion detection system:

• Intrusion mis-classiﬁcation: an intrusion attack is mis-

classiﬁed as benign event; and

• Attack mis-classiﬁcation: an intrustion attack of type A
(e.g., DoS attack) is mis-classiﬁed as an intrution attack
of type B (e.g., probing attack).

In practice, the intrusion mis-classiﬁcation should be penalized
more than the attack mis-classiﬁcation, as the attack mis-
classiﬁcation still triggers an alert to the IT security team,
and enables the incident to be further inspected, whereas the
intrusion mis-classiﬁcation enables the attack incidents to by-
pass the security check and cause potentially critical damage.
Therefore, the intrusion mis-classiﬁcation should have higher
penalty than the attack mis-classiﬁcation.

To address the issue of discrepancy penalty of different
types of mis-classiﬁcation, we improve the basic cross-entropy
loss function. In particular, for any instance (x(i), y(i)), if it
is a benign incident, y(i) = 1; otherwise, y(i)
.
}
Inspired by [24], we design the attack-sharing loss function,
JAS, with an additional regularization term that penalizes
intrusion mis-classiﬁcation, i.e., the wrong estimation between
the benign label and attack labels. In particular, we have

2, . . . , c

∈ {

JAS = JCE

1
N

−

N

λ

I(y(i), 1) log p(i)
1

i=1
X

(cid:0)
I(y(i), j) log(1

c

+

j=2
X

p(i)
1 )

,

−

(cid:1)

(6)

where λ is a control parameter. When λ is small, JAS is
similar to the vanilla cross-entropy loss unction; when λ is
large, JAS tends to be an objective function for addressing
the binary classiﬁcation problem, benign versus attack. In
our experiments, we set λ = 10. Compared with the basic
cross-entropy loss, the attack-sharing loss function eliminates
the bias towards the majority/benign class by moving the
decision boundary towards the attack classes. It also respects
the discrepancy penalty of different types of mis-classiﬁcation.

C. Optimization Procedure

In deep learning, the most widely-used optimization algo-
rithm is stochastic gradient descent (SGD). In each round,
it uses a minibatch of samples to estimate the gradient, and
updates the parameters. Although simple, SGD suffers from
slow asymptotic convergence, especially when there exist
saddle points (i.e. points where one dimension slopes up
and another slopes down) and plateaus (i.e., areas where the
gradients keep stably high) in the parameter space. Due to
the complicated nature of intrusion detection classiﬁcation
boundary, saddle points and plateaus widely exist. To expedite
the learning process, we adapt the Adam optimizer, which
adaptively updates the learning rate. In particular, we employ
two variables, s and r, to store an exponentially decaying
average of past gradients and squared gradients respectively.
Initially, we set s = 0 and r = 0. In the t-th round of
feedforward and backpropagation, we take a minibatch of m
samples from the training set, and calculate the stochastic
gradient:

gt

← ∇

θt−1 J(θt−1).

(7)

Next, we update the ﬁrst-order moment and second-order
moment:

st = ρ1st−1 + (1

rt = ρ2rt−1 + (1

ρ1)gt,
ρ2)g2
t ,

(8)

(9)

−

−

(0, 1) are the hyperparameters that determine
where ρ1, ρ2 ∈
the decay rate. We also perform bias corrections to both
moments to account for their initialization at the origin:

st =

rt =

1

1

,

.

st

ρt
1

−
rt

ρt
2

−

Finally, the parameters are updated as
ζst
√rt + δ

θt = θt−1 −

(10)

(11)

(12)

,

where ζ is the step size, and δ is a small stabilization factor. By
using Equation (12), we make greater evolution in the more
gently sloped directions of parameter space. This facilitates
faster convergence compared with SGD. Another attractive
property of the Adam optimizer is that it is robust to the choice
of hyperparameters.

IV. EXPERIMENTS

A. Dataset

In our experiments, we use three datasets, namely KDD99,
CICIDS17 and CICIDS18 dataset. Next, we brieﬂy introduce
these datasets.

TABLE I
CLASS DISTRIBUTION IN KDD99 DATASET
Testing

Training

Label

Benign
DoS
Probing
U2R
R2L
Total

Number
972,781
3,883,390
41,102
52
1,106
4,898,431

Number
Fraction
19.86%
60,593
79.28% 231,455
4,166
0.84%
245
0.01%
14,570
0.02%
311,029
100%

Fraction
19.48%
74.42%
1.34%
0.08%
4.68%
100%

KDD99 dataset is built by Stolfo et al. [25], as a part of the
DARPA Intrusion Detection Evaluation Program. To prepare
this dataset, a military network environment was deployed to
acquire nine weeks of raw TCP dump data from a local-
area network (LAN). The LAN was operated as if it were
a typical U.S. Air Force LAN, except that it was hacked by
a sequence of cyber attacks. In this dataset, each connection
record is described by 41 features and 1 label. The features
include information in three aspects, namely basic connection
information (e.g., duration, protocol type (tcp, udp, icmp),
number of wrong fragments, number of urgent packets, etc),
content information (e.g., number of failed login attempts,
number of shell prompts, number of operations on access
control ﬁles, etc), and trafﬁc information (e.g., number of
connections to the host in the past two seconds, fraction of
connections that have “SYN” errors, etc). The attacks in the
dataset fall into 4 categories, i.e., DoS, Probing, U2R (normal
users illegally gain root access to the system), and R2L (remote
attackers exploit some vulnerabilities to obtain local access to
the host). We show the distribution of these attacks in the
training and testing set in Table I.

TABLE II
CLASS DISTRIBUTION IN CICIDS17 DATASET
Testing

Training

Label

Benign
DoS
DDoS
Brute-Force
Inﬁltration
Total

Number
1,911,674
170,508
101,024
10,494
149,934
2,343,634

Fraction
Number
81.57% 361,399
82,151
7.27%
27,003
4.31%
3,341
0.45%
9,032
6.40%
482,926
100%

Fraction
74.84%
17.01%
5.59%
0.69%
1.87%
100%

CICIDS17 dataset is collected by Canadian Institute for Cy-
bersecurity and is publicly available2. Two networks, namely
the attack network and victim network were constructed. Each
network is a infrastructure that consists of routers, switches
and a set of PCs running most of the common operating
systems. In total, there are 2.83 million network connection
instances, where each instance is described by 81 features. The
features are similar to those of the KDD99 dataset dataset, but
include more statistical information. We omit the details due to
the space limit. We manually split the dataset into a training set
and a testing set with a 5 : 1 size ratio. The launched attacks

2https://www.unb.ca/cic/datasets/ids-2017.html

include DoS, DDoS, Inﬁltration and Brute-Force attacks. We
show the distribution of these attacks in the training and testing
set in Table II.

TABLE III
CLASS DISTRIBUTION IN CICIDS18 DATASET
Testing

Training

Label

Benign
DoS
Inﬁlteration
Botnet
Total

Number
4,197,451
517,691
131,844
233,085
5,080,071

Fraction
82.62%
10.19%
2.60%
4.59%
100%

Number
814,704
158,098
38,787
51,753
1,063,342

Fraction
76.62%
14.87%
3.65%
4.87%
100%

CICIDS18 dataset is also constructed by Canadian Institute
for Cybersecurity and is publicly available3. To simulate a
real-world network, a common LAN network topology is im-
plemented on the AWS computing platform. The attacking in-
frastructure includes 50 machines and the victim organization
has 5 departments and includes 420 machines and 30 servers.
The dataset includes 6.3 million network connection instances,
and each instance has 77 features. Again, we manually split
the dataset into a training set and a testing set with a 5 : 1 size
ratio. The attacks in this dataset includes DoS, Inﬁltration and
Botnet. The class distribution of these attacks can be found in
Table III.

TABLE IV
SUMMARY OF THE DATASETS

Dataset

KDD99
CICIDS17
CICIDS18

# of
Features
41
81
77

Training Size

Testing Size

4,898,431
2,343,634
5,080,071

311,029
482,926
1,063,342

# of
Classes
5
5
4

Ωimb

2.96
3.08
2.31

We summarize the characteristics of these three datasets in
Table IV. To evaluate the level of class imbalance in each
dataset, we also report the class imbalance measure Ωimb [10]
in the training set, which is deﬁned as

c
i=1 nmax
n

ni

,

−

(13)

Ωimb =

P

where n denotes the number of instances in the datast, ni de-
notes the number of instances that belong to the i-th class, and
nmax = maxc
i=1ni. Intuitively, Ωimb measures the minimum
percentage count of data samples required over all classes
in order to form an overall balanced/uniform distribution. A
larger Ωimb value indicates higher level of class imbalance.

B. Setup

We implement DeepIDEA in Python by using the tensorﬂow
framework. In our neural network, we include 100 units in
each hidden layer. We try various number of hidden layers.
Our results suggest that the performance is reasonably good
as long as the network consists of at least 6 layers. In the
following section, we only show the results with 10 hidden
layers. The keep probability of each dropout layer is 0.8.
The source code is available in a public repository4. In our
experiments, we group 100 consecutive network connection
instances as a training sample. We set the learning rate as

3https://www.unb.ca/cic/datasets/ids-2018.html
4https://github.com/bxdong7/MLP-D

TABLE V
DETECTION ACCURACY COMPARISON BETWEEN DEEPIDEA AND THE BASELINES ON THE KDD99 DATASET

Classiﬁer

SVM
KNN
DT
MLP+CE
MLP+OverSampling [15]
MLP+UnderSampling [20]
Cost-Sensitive [17]
CNN [8]
DeepIDEA(Our approach)

Benign

DoS

Probe

U2R

R2L

Pre
30.2
23.51
20.64
0
27.15
19.21
33.15
20.50
19.46

Rec
70.04
55.16
48.23
0
11.68
45.95
10.59
64.79
85.82

Pre
96.66
90.97
88.9
70.92
95.5
95.52
0
94.88
93.03

Rec
98.55
100
99.87
100
83.14
83.57
0
82.81
85.68

Pre
13.68
100
0
5.36
5.64
9.43
4.82
10.53
7.14

Rec
27.71
26.91
0
15.33
74.64
33.87
8.27
27.27
47.87

Pre
21.87
0
0
0
11.83
20.83
2.55
7.14
0

Rec
6.76
0
0
0
1.97
8.09
73.76
1.3
0

Pre
84.4
0
0
72.29
62.79
68.3
0
60.87
62.09

Rec
5.91
0
0
6.4
19.15
29.78
0
4.67
8.89

CBA

41.23
16.41
29.49
24.27
38.12
40.25
18.26
36.17
45.31

TABLE VI
DETECTION ACCURACY COMPARISON BETWEEN DEEPIDEA AND THE BASELINES ON THE CICIDS17 DATASET

Classiﬁer

SVM
KNN
DT
MLP+CE
MLP+OverSampling [15]
MLP+UnderSampling [20]
Cost-Sensitive [17]
CNN [8]
DeepIDEA(Our approach)

Benign

DoS

DDoS

Pre
86.42
91.92
66.51
87.04
86.03
86.88
61.58
0
88.5

Rec
76.38
85.05
100
90.76
95.05
54.9
61.17
0
94.06

Pre
96.58
75.88
0
74.12
80.14
50.91
17.69
23.42
88.77

Rec
53.74
48.22
0
63.69
52.5
59.31
28.09
96.04
62.97

Pre
92.62
72.56
0
74.73
56.68
26.13
0
0
76.31

Rec
16.03
86.23
0
79.53
76.06
11.32
0
0
83.19

Brute-Force
Rec
Pre
0
0
0
0
0
0
4.8
7.37
1.63
3.65
27.39
7.17
0
0
11.07
8.07
4.1
8.29

Inﬁltration
Pre
7.27
10.92
0
28.03
28.18
13.8
0
0
26.46

Rec
86.18
84.75
0
61.54
53.62
58.03
0
0
64.53

CBA

46.47
60.85
20
60.06
55.45
42.19
17.85
21.42
61.77

TABLE VII
DETECTION ACCURACY COMPARISON BETWEEN DEEPIDEA AND THE BASELINES ON THE CICIDS18 DATASET
DoS

Benign

Botnet

Classiﬁer

SVM
KNN
DT
MLP+CE
Cost-Sensitive [17]
CNN [8]
DeepIDEA(Our approach)

Pre
76.59
75.46
64.77
67.42
54.52
0
70.96

Rec
42.59
30.05
100.0
71.73
19.6
0
39.7

Pre
44.97
31.2
0
31.92
0
22.44
45.47

Rec
26.23
28.05
0
45.23
0
98.52
49.94

Inﬁltration
Pre
26.57
11.53
0
0
5.44
7.08
6.88

Rec
20.64
6.45
0
0
71.42
8.19
21.0

Pre
13.70
17.32
0
18.52
10.38
0
11.86

Rec
29.14
28.14
0
0.42
6.54
0
33.64

CBA

29.65
23.18
25.00
29.35
24.39
26.68
36.07

10−4, the minibatch size as 128, and the number of epoches
as 10. We use cross-validation to avoid overﬁtting. We run
DeepIDEA on a workstation with 1 NVIDIA RTX 2080 Ti
GPU and 1 Intel i7-7700K @ 4.2GHz CPU. On average, the
training process halts within 3 hours.

C. Baseline

We compare DeepIDEA with the following baseline ap-

proaches.

• SVM (support vector machine) with 100 iterations
• KNN (k-nearest neighbor) with 5 neighbors and

minkowski distance

• CNN [8]: This approach classiﬁes the network connec-
tions with 2 convolution layers, 2 maxpooling layers and
6 fully-connected layers.

We implement
these machine learning-based baselines by
using the scikit-learn library, and the deep learning-based
baselines by using the tensorﬂow framework. We also imple-
ment a baseline approach based on recurrent neural network
with LSTM units [14]. However, the training process does
not complete within 5 days. Therefore, we do not include the
results in this section.

D. Evaluation Metrics

• DT (decision tree) with 10 layers at most
• MLP+CE (multi-layer perceptron with cross-entropy loss

function (Formula (4)))

• MLP+OverSampling [15]: In this approach, the training
data is transformed to balanced class distribution by
applying over-sampling.

• MLP+UnderSampling [20]: In this approach, the training
data is transformed to balanced class distribution by
applying over-sampling.

In this paper, we are mostly interested in evaluating the
detection accuracy. In the experiments, we collect the fol-
lowing statistics: TP (true positive), FP (false positive), TN
(true negative) and FN (false negative). We measure the
following the precision and recall for each class. In particular,
precision = T P
T P +F P measures the fraction of alerts indicated
by the detection approach that are correct, and recall =
T P +F N measures the fraction of attacks that are successfully
identiﬁed by the detection approach.

T P

• Cost-Sensitive [17]: This approach uses cost-sensitve loss
function to train the neural network. We follow [17] to
set up the cost matrix.

In addition, we measure the overall class-balanced accuracy
(CBA) [10] for all classes. CBA is calculated as the average
recall for all classes. By taking all classes equally important, it

avoids inﬂated performance estimates on imbalanced datasets.
If the classiﬁer performs equally well on every class, this term
is equivalent to the conventional accuracy (i.e., the number of
correct predictions divided by the total number of predictions).
On the contrary, if the model only performs well on the
majority class, CBA drops to 1
c . Therefore, CBA is an effective
metric in measuring the accuracy of a classiﬁer for imbalanced
dataset.

E. Evaluation of DeepIDEA

KDD99 Dataset. We present the classiﬁcation accuracy of
DeepIDEA and the baseline approaches on the KDD99 dataset
in Table V. First, we observe that DeepIDEA yields the
highest CBA. This demonstrates that DeepIDEA is effective in
detecting intrusion attack incidents from imbalanced dataset.
Second, KNN, DT and MLP+CE only focus on the major-
ity classes, and produces unsatisfactory performance on the
minority classes. For instance, KNN and DT fail to catch
any U2R and R2L attack instance. In contrast,
the cost-
sensitive classiﬁer associates too much cost for the U2R and
R2L classes, as they are extremely under-represented. This
makes the classiﬁer lean too much toward these classes, and
performs poorly on the KDD99 dataset. Over-sampling and
under-sampling mitigate the side-effect of the class imbalance
problem, but the improvement is not comparable with DeepI-
DEA.
CICIDS17 Dataset. We report the accuracy of all the classi-
ﬁers in Table VI. First, we observe that DeepIDEA produces
similar and satisfying precision and recall on every class,
except for the Brute-Force. Consequently, DeepIDEA yields
the best CBA among all the classiﬁers. In Table II, it is easy
to see that Brute-Force is the most under-represented class.
The Brute-Force attack instances only takes around 0.5% of
the dataset. Even though the attack-sharing loss function aims
at dragging the decision boundary toward the attack classes, it
does not help much with this class. Second, the performance
of KNN and MLP+CE are close to that of DeepIDEA. We
further investigate the reason and ﬁnd that a large fraction of
the attack instances are present in both the training and testing
set. DT simply labels every test instance as benign connection.
Similarly, CNN [8] almost recognizes every connection as DoS
attack. The cost-sensitive classiﬁer only focuses on the benign
and DoS class. Naturally, the CBA of these three baselines are
low.
CICIDS18 Dataset. In Table VII, we compare the accuracy
of DeepIDEA with the baselines on the CICIDS18 dataset.
DeepIDEA performs the second best in addressing the class
imbalance problem. It has similar recall on every class. Again,
it shows the effectiveness of the class-sharing loss function. No
baseline approach produces a CBA higher than 30%. Again,
the cost-sensitive baseline concentrates all the attention to the
most under-represented class, i.e., inﬁlteration, and neglects
the other classes. DT simply recognizes every testing instance
as benign.

F. Insights

On all datasets, DeepIDEA delivers the best CBA. The
CBA of DeepIDEA is always better and can as twice high
as that of MLP+CE. Compared with the sampling-based
approaches,
the accuracy of DeepIDEA on all classes is
more balanced. DeepIDEA signiﬁcantly outperforms the cost-
sensitive classiﬁer [17], which only focuses on a few classes.
CNN [8] is inferior to DeepIDEA in classiﬁcation accuracy
mainly because network events that are close in time do not
exhibit similar behaviors. All these observations demonstrate
the effectiveness of our attack-sharing loss function in dealing
with class imbalance in intrusion detection dataset.

However, we must acknowledge the weakness of DeepI-
DEA. It does not concentrate sufﬁciently on the extremely
under-represented classes. For example, the U2R class in the
KDD99 dataset and the Brute-Force class in the CICIDS17
dataset are rarely detected by DeepIDEA. Both classes take
no more than 1% in the training and testing set. The reason is
that the attack-sharing loss only pulls the decision boundary
towards the attack classes. However,
the tow direction is
still biased towards the majority attack classes. In speciﬁc,
the regularization term in Formula (6) does not differentiate
types of attacks. In order to minimize the JAS
different
loss, the classiﬁer tends to classify every attack instance as a
majority attack class. This limitation makes DeepIDEA more
suitable for the scenarios where the benign instances dominate
the dataset, and different types of attacks are balanced. In other
words, DeepIDEA works well when the imbalance only exists
between the benign class and attack classes.

V. RELATED WORK

A. Intrusion Detection based on Deep Learning

[4], [6] conducted a thorough comparison of a variety of
classiﬁers,
including J48 tree, Naive Bayes, decision tree,
support vector machine (SVM) and k-nearest neighbor (KNN),
on the accuracy of intrusion detection. To reduce the gener-
alization error of the classiﬁers and avoid overﬁtting, Rigaki
et al. Javaid et al. [16] developed a novel intrusion detection
approach based on self-taught learning. It is a deep neural
network that consists of two stages. In the ﬁrst stage, a new
feature representation of the input data is learned from a
sparse auto-encoder. After that, the new features are taken by
a soft-max regression for classiﬁcation. The experiment results
demonstrate the effectiveness of the new feature representation
in improving classiﬁcation accuracy. Chowdhury et al. [8]
applied ’few-shot learning’ to improve the detection accuracy.
In speciﬁc, they ﬁrst train a convolutional neural network
and then extract features from various layers. Those features
are fed into various classiﬁers such as SVM or 1-nearest
neighbor (1-NN). Experimental results suggest that the class-
wise accuracy can reach 65.8%. However, it
is not clear
what is the rationale behind the choice of SVM and 1-NN
over a softmax activation in the last layer of a deep neural
network. Kitsune [23] is the most recent work that detects
network intrusion attacks with deep neural networks. It applies

an ensemble of autoencoders to learn the identify function
of the original data distribution. For any new instance, its
anomaly score is calculated based on the distance between the
autoencoders’ output and its feature values. However, we argue
that such a design only employs deep learning to discover
inherent/generic features in network connections, but fails to
take advantage of its capacity to learn complex classiﬁcation
functions.

B. Anomaly Detection based on Deep Learning

Quite a few work concentrate on applying deep neural
networks to detect abnormal behaviors that are not essentially
intrusion attacks. Zhang et al. [26] propose to detect IT system
failures from system log ﬁles. Clustering analysis is used to
extract frequent patterns in the log ﬁles. Then the log ﬁles are
embedded by counting the number of occurrences of these pat-
terns. To cope with the lack of labeled data, a LSTM is trained
to capture the long-range dependency across sequences. Du et
al. [11] also applied LSTM to detect anomalies and diagnoze
failures from system logs. Different from previous work, they
aim at abnormal execution paths to improve the conﬁdence
and help with further investigation. Kiran et al. [19] provide a
comprehensive survey on the application of deep learning over
anomaly detection in videos. Recently, Chalapathy et al. [7]
show that it is advantageous to directly train deep networks
to extract progressively rich representation of data with the
classiﬁcation objective, rather than utilizing a hybrid approach
where deep features are ﬁrstly learned by using an autoencoder
and then fed into a separate anomaly detection method like
SVM. Our work is consistent with this proposition, and thus
produces higher accuracy compared with traditional hybrid
approaches.

VI. CONCLUSION

In this paper, we design DeepIDEA, a novel

intrusion
detection and classiﬁcation system based on imbalanced deep
learning. To deal with the imbalanced class problem, we de-
sign a new loss function named attack-sharing loss to eliminate
the bias towards the majority/benign class. We also integrate
DeepIDEA with a new optimization algorithm to facilitate
efﬁcient training. Experimental results on three benchmark
datasets show the superiority of DeepIDEA compared to seven
baseline approaches.

In the future, we plan to extend this work from the following
perspectives. First, we plan to apply the attack-sharing loss
to recurrent neural networks that take the network context
into consideration. We also plan to use generative adversarial
networks to improve the detection accuracy.

REFERENCES

[4] Almseidin, M., Alzubi, M., Kovacs, S., Alkasassbeh, M.: Evaluation
of machine learning algorithms for intrusion detection system. In: IEEE
International Symposium on Intelligent Systems and Informatics (SISY).
pp. 277–282 (2017)

[5] Bengio, Y., et al.: Learning deep architectures for ai. Foundations and

trends® in Machine Learning 2(1), 1–127 (2009)

[6] Biswas, S.K.: Intrusion detection using machine learning: A comparison

study (2018)

[7] Chalapathy, R., Menon, A.K., Chawla, S.: Anomaly detection using one-

class neural networks. arXiv preprint arXiv:1802.06360 (2018)

[8] Chowdhury, M.M.U., Hammond, F., Konowicz, G., Xin, C., Wu, H.,
Li, J.: A few-shot deep learning approach for improved intrusion
detection. In: IEEE Ubiquitous Computing, Electronics and Mobile
Communication Conference (UEMCON). pp. 456–462 (2017)

[9] Dong, B., Chen, Z., Wang, W.H., Tang, L.A., Zhang, K., Lin, Y., Li, Z.,
Chen, H.: Efﬁcient discovery of abnormal event sequences in enterprise
security systems. In: Proceedings of the ACM International Conference
on Conference on Information and Knowledge Management (CIKM)
(2017)

[10] Dong, Q., Gong, S., Zhu, X.: Imbalanced deep learning by minority
class incremental rectiﬁcation. IEEE Transactions on Pattern Analysis
and Machine Intelligence (2018)

[11] Du, M., Li, F., Zheng, G., Srikumar, V.: Deeplog: Anomaly detection
and diagnosis from system logs through deep learning. In: Proceedings
of the ACM SIGSAC Conference on Computer and Communications
Security. pp. 1285–1298 (2017)

[12] Echeverria, J., Zhou, S.: The ‘star wars’ botnet with¿ 350k twitter bots.

arXiv preprint arXiv:1701.02405 (2017)

[13] Goodfellow, I., Bengio, Y., Courville, A.: Deep learning. MIT press

(2016)

[14] Hochreiter, S., Schmidhuber, J.: Long short-term memory. Neural com-

putation 9(8), 1735–1780 (1997)

[15] Japkowicz, N., Stephen, S.: The class imbalance problem: A systematic

study. Intelligent Data Analysis 6(5), 429–449 (2002)

[16] Javaid, A., Niyaz, Q., Sun, W., Alam, M.: A deep learning approach for
network intrusion detection system. In: Proceedings of the EAI Inter-
national Conference on Bio-inspired Information and Communications
Technologies (formerly BIONETICS). pp. 21–26 (2016)

[17] Khan, S.H., Hayat, M., Bennamoun, M., Sohel, F.A., Togneri, R.: Cost-
sensitive learning of deep feature representations from imbalanced data.
IEEE transactions on neural networks and learning systems 29(8), 3573–
3587 (2018)

[18] Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. arXiv

preprint arXiv:1412.6980 (2014)

[19] Kiran, B.R., Thomas, D.M., Parakkal, R.: An overview of deep learning
based methods for unsupervised and semi-supervised anomaly detection
in videos. Journal of Imaging 4(2), 36 (2018)

[20] Kubat, M., Matwin, S., et al.: Addressing the curse of imbalanced
In: Icml. vol. 97, pp. 179–186.

training sets: one-sided selection.
Nashville, USA (1997)

[21] LeCun, Y., Bottou, L., Bengio, Y., Haffner, P.: Gradient-based learning
applied to document recognition. Proceedings of the IEEE 86(11), 2278–
2324 (1998)

[22] Mikolov, T., Sutskever, I., Chen, K., Corrado, G.S., Dean, J.: Distributed
representations of words and phrases and their compositionality. In:
Advances in Neural Information Processing Systems. pp. 3111–3119
(2013)

[23] Mirsky, Y., Doitshman, T., Elovici, Y., Shabtai, A.: Kitsune: an ensemble
of autoencoders for online network intrusion detection. arXiv preprint
arXiv:1802.09089 (2018)

[24] Shen, W., Wang, X., Wang, Y., Bai, X., Zhang, Z.: Deepcontour: A
deep convolutional feature learned by positive-sharing loss for contour
detection. In: Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition. pp. 3982–3991 (2015)

[25] Stolfo, S.J., Fan, W., Lee, W., Prodromidis, A., Chan, P.K.: Cost-based
modeling for fraud and intrusion detection: Results from the jam project.
Tech. rep., Columbia University (2000)

[26] Zhang, K., Xu, J., Min, M.R., Jiang, G., Pelechrinis, K., Zhang, H.:
Automated it system failure prediction: A deep learning approach. In:
IEEE International Conference on Big Data. pp. 1291–1300 (2016)
[27] Zhou, Z.H., Liu, X.Y.: Training cost-sensitive neural networks with
methods addressing the class imbalance problem. IEEE Transactions
on Knowledge & Data Engineering (1), 63–77 (2006)

[1] Alibaba

security fail: Brute-force bonanza yields 21m logins.
https://www.theregister.co.uk/2016/02/08/alibaba taobao security process failure/
breach

incident

report.

trends

&

[2] Cyber

[3] Dyn

https://otalliance.org/system/ﬁles/ﬁles/initiative/documents/ota cyber incident trends report jan2018.pdf
october

attack.
https://dyn.com/blog/dyn-analysis-summary-of-friday-october-21-attack/

summary

analysis

friday

21

of

