6
1
0
2

r
a

M
8
2

]

R
C
.
s
c
[

1
v
7
0
3
8
0
.
3
0
6
1
:
v
i
X
r
a

Cyber Epidemic Models with Dependences

Maochao Xu1, Gaofeng Da2 and Shouhuai Xu3

1 Department of Mathematics, Illinois State University
mxu2@ilstu.edu
2 Institute for Cyber Security, University of Texas at San Antonio
dagfvc@gmail.com
3 Department of Computer Science, University of Texas at San Antonio
shxu@cs.utsa.edu (corresponding author)

Abstract

Studying models of cyber epidemics over arbitrary complex networks can deepen our understanding of cyber
security from a whole-system perspective. In this paper, we initiate the investigation of cyber epidemic models that
accommodate the dependences between the cyber attack events. Due to the notorious difﬁculty in dealing with such
dependences, essentially all existing cyber epidemic models have assumed them away. Speciﬁcally, we introduce
the idea of Copulas into cyber epidemic models for accommodating the dependences between the cyber attack
events. We investigate the epidemic equilibrium thresholds as well as the bounds for both equilibrium and non-
equilibrium infection probabilities. We further characterize the side-effects of assuming away the due dependences
between the cyber attack events, by showing that the results thereof are unnecessarily restrictive or even incorrect.
Keywords: Copula, Cyber epidemics, dependence, epidemic threshold, spectral radius, infection probability

1 Introduction

Cyberspace (or Internet) is perhaps the most complex man-made system. While cyberspace has become an indispens-
able part of the society, economy and national security, cyber attacks also have become an increasingly devastating
problem. Despite studies and progresses in the past decades, our understanding of cyber security from a whole-system
perspective, rather than from a component or building-block perspective, is still at its infant stage. This is caused by
many factors, including the dearth of powerful mathematical models that can capture and reason the interactions
between the cyber attacks and the cyber defenses.

Recently, researchers have started pursuing the cyber-security value of “biological epidemics”-like mathematical
models. While conceptually attractive, biological epidemic models cannot be directly used to describe cyber security
because there are many cyber-speciﬁc issues. One particular issue, which we initiate its study in the present paper, is
the dependences between the cyber attack events. To the best of our knowledge, these dependences have been explic-
itly assumed away in essentially all existing cyber epidemic models, perhaps because they are notoriously difﬁcult to
cope with. Indeed, accommodating the dependences introduces yet another dimension of difﬁculty to cyber epidemic
models that incorporate arbitrary complex network structures. However, the dependences are inherent because, for
example, the events that computers get infected are not independent of each other, and a malware may ﬁrst infect
some computers because the users visit some malicious websites and then spread over the network. Moreover, cyber
attacks may be well coordinated by intelligent malwares, and the coordination causes positive dependences between
the attack events.

1.1 Our contributions

In this paper, we initiate the systematic study of a new sub-ﬁeld in cyber epidemic models, namely understanding
and characterizing the importance of the dependences between the attack events in cyber epidemic models that ac-
commodate arbitrary complex network structures. This is demonstrated through a non-trivial generalization of the

1

 
 
 
 
 
 
powerful push- and pull-based cyber epidemic model that was recently investigated in [19]. Speciﬁcally, we capture
the dependences between the cyber attack events by incorporating the idea of Copulas into cyber epidemic models. To
the best of our knowledge, this is the ﬁrst systematic study of cyber epidemic models that accommodate dependences,
rather than assuming them away. Speciﬁcally, we make two contributions.

First, we derive epidemic equilibrium thresholds, namely sufﬁcient conditions under which the epidemic spread-
ing enters a non-negative equilibrium (the spreading never dies out when there are pull-based attacks, meaning that
only positive equilibrium is relevant under this circumstance). Some of the sufﬁcient conditions are less restrictive but
require hard-to-obtain information (i.e., these conditions are theoretically more interesting), and the others are more
restrictive but require easy-to-obtain information (i.e., these conditions are practically more useful). We also derive
bounds for the equilibrium infection probabilities and discuss their tightness. The bounds are easy to obtain/compute,
and are useful especially when it is infeasible to obtain the equilibrium infection probabilities numerically (let alone
analytically). For example, the upper bounds can be treated as the worst-case scenarios when provisioning defense
resources. For Erd˝os-R´enyi (ER) and power-law networks, we further propose to approximate the equilibrium infec-
tion probabilities by taking advantage of the bounds. The approximation results are smaller than the upper bounds
and would not underestimate the number of infected nodes, meaning that the approximation results can lead to more
cost-effective defense. We further present bounds for non-equilibrium infection probabilities, no matter whether the
spreading converges to equilibrium or not. All the results are obtained by explicitly accommodating the dependence
structures between the cyber attack events.

Second, we characterize the side-effects of assuming away the due dependences on the bounds for equilibrium
infection probabilities, on the epidemic equilibrium thresholds, and on the non-equilibrium infection probabilities. We
show that assuming away the due dependences can make the results thereof unnecessarily restrictive or even incorrect.
We further discuss the cyber security implications of the side-effects.

It is worth mentioning that as a ﬁrst step towards ultimately tackling the dependence problem in cyber epidemic
models, the Copulas technique, which we use in the present paper, is appealing because of the following. On one hand,
it leads to tractable models, while capable of coping with high-dimensional dependence (i.e., dependence between a
large vector of random variables). On the other hand, there are families of copula structures that have been extensively
investigated in the literature of Applied Probability Theory and Risk Management, and various methods have been
developed for estimating the types and parameters of copula structures in practice. Of course, much research remains
to be done before we can answer questions such as: What approach is the most appropriate for accommodating
dependence in cyber epidemic models, under what circumstances?

1.2 Related work

Biological epidemic models can be traced back to McKendrick and Kermack [13, 10]. Such homogeneous biological
epidemic models were introduced to computer science for characterizing the spreading of computer viruses in [9].
Heterogeneous epidemic models, especially the ones that accommodate arbitrary network structures, were not studied
until recently [17, 6, 1]. These studies led to the full-ﬂedged push- and pull-based cyber epidemic model [19],
which is the starting point of the present paper. To the best of our knowledge, all existing cyber epidemic models,
which aim to accommodate arbitrary network structures (including other recent studies such as [16, 11, 20] and the
references therein), assumed that the attacks are independent of each other. This is plausible because accommodating
arbitrary network structures in cyber epidemic models already make the resulting models difﬁcult to analyze, and
accommodating dependences introduces, as we show in the present paper, another dimension of difﬁculty to the
models.

The only exception is due to our recent study [18], which is based on a different approach to modeling cyber epi-
demics [11]. The main contribution of [18] is to get rid of the exponential distribution assumptions for certain random
variables. Moreover, the model in [18] can only accommodate the speciﬁc Marshall-Olkin dependence structure be-
tween the attack events. In contrast, we here accommodate arbitrary dependence structures between the attack events,
while investigating the epidemic equilibrium thresholds, the equilibrium and non-equilibrium infection probabilities,
and the side-effects of assuming away the due dependences. Many of these issues are not studied in the context of [18]
because its focus is different. This explains why the present paper is the ﬁrst systematic treatment of dependences in

2

cyber epidemic models.

The dependence modeled in the present paper is static (i.e., time-invariant). This study inspired [5], which makes
a further step towards modeling dynamic dependence between cyber attacks, but using a different modeling approach.

The rest of the paper is organized as follows. In Section 2 we brieﬂy review some facts about Copulas. In Section
3 we investigate the generalized cyber epidemic model that accommodates the dependences between the cyber attack
events. In Section 4 we characterize the side-effects as caused by assuming away the due dependences. In Section 5,
we conclude the paper with future research problems.

The following table summarizes the main notations used in the paper.

j

∈

≤

≤

deg(v)

G = (V, E)
deg(v)
Iv(t), Iv,j(t)

iv(t)
iv,j(t)
i−
v , i+
v

v, i∗
i∗
v,j
i∗−, i∗+
v

V is infected at time t

the graph/network in which cyber epidemics occurs, where V is the node set and E is the edge set
the degree of node v in graph G = (V, E), which can be represented by adjacency matrix A
the state of node v at time t: Iv(t) = 1 means infected and 0 means secure; Iv,j(t) is the state of the
jth neighbor of node v (1 means infected and 0 means secure), where 1
the probability that node v
V is secure but the jth neighbor of node v is infected
the condition probability that at time t node v
lower and upper bounds for the non-equilibrium infection probability limt→∞ iv(t), where the sys-
tem does not converge to any equilibrium
the equilibrium infection probabilities that node v and its jth neighbor are infected, respectively
i∗− is the lower bound for the equilibrium infection probability i∗
for the equilibrium infection probability i∗
v = (i∗
i∗ = (i∗
N ) where N =

, i∗
i∗, i∗
v
|
α the probability that a secure node v
∈
the probability that an infected node v
β
∈
the probability that an infected node u successfully attacks node v over (u, v)
γ
spectral radius of matrix M
ρ(M )
deg(v)-copula describing the dependence between the push-based cyber attacks against node v
Cv
C 2-copula describing the dependence between the pull-based attacks and the push-based attacks

V is infected by pull-based cyber attacks at a time step

V becomes secure at a time step

v of node v
v,1, . . . , i∗

v for every v, i∗+

is the upper bound

E at a time step

1, . . . , i∗

v,deg(v))

V
|

∈

∈

v

against a node
the diagonal section of copula C, i.e., δC (u) = C(u, . . . , u)

δC

2 Preliminaries

Copulas can model dependences by relating the individual marginal distributions to their multivariate joint distribu-
tion. In this paper we will use the n-copulas [8, 15]. Speciﬁcally, a function C : [0, 1]n
[0, 1] is called n-copula
if:

7→

•

•

•

•

C(u1, . . . , un) is increasing in each component uz, z

1, . . . , n

.
}

∈ {

C(u1, . . . , uz−1, 0, uz+1, . . . , un) = 0 for all uj ∈
C(1, . . . , 1, uz, 1, . . . , 1) = uz for all uz ∈
C is n-increasing, i.e., for all (u1,1, . . . , u1,n) and (u2,1, . . . , u2,n) in [0, 1]n with u1,j ≤
1, . . . , n, it holds that

[0, 1], j = 1, . . . , n, j

[0, 1], z = 1, . . . , n.

= z.

u2,j and for all j =

2

2

. . .

(
−
zn=1
X

z1=1
X

1)Pn

j=1 zj C(uz1,1, . . . , uzn,n)

0.

≥

Let R1, . . . , Rn be random variables with distribution functions F1, . . . , Fn, respectively. The joint distribution
rn). The well-known Sklar’s theorem states that there exists an

function is F (r1, . . . , rn) = P (R1 ≤
n-copula C such that F (r1, . . . , rn) = C (F1(r1), . . . , Fn(rn)) .

r1, . . . , Rn ≤

3

6
There are many families of copulas [8, 15]. One example is the Gaussian copula with

C(u1, . . . , un) = ΦP

Φ−1(u1), . . . , Φ−1(un)

,

where Φ−1 is the inverse cumulative distribution function of the standard normal distribution and ΦP is the joint
cumulative distribution function of a multivariate normal distribution with mean vector zero and covariance matrix
equal to the correlation matrix

. For simplicity, we assume that the correlation matrix has the form

(cid:0)

(cid:1)

P

= 

1 σ . . . σ
σ
σ 1

σ
. . .

σ σ . . . 1



,





X





where σ measures the correlation between two random variables. Therefore, the Gaussian copula can be rewritten as

Another example is the Archimedean family with

(cid:0)

(cid:1)

C(u1, . . . , un) = Φσ

Φ−1(u1), . . . , Φ−1(un)

.

C(u1, . . . , un) = φ−1 (φ(u1) + . . . + φ(un)) ,

where function φ is called a generator of C and satisﬁes certain properties (see [14] for details). The Archimedean
family contains many well-known copula functions such as the Clayton and Frank copulas [15, 3]. The generator of
the Clayton copula is φθ(u) = u−θ

1, and we have

−

C(u1, . . . , un) =





The generator of the Frank copula is ψξ(u) = log

n

u−θ
j −

Xj=1
e−ξu−1
e−ξ−1

−1/θ

,

θ > 0.

n + 1





, and we have

C(u1, . . . , un) =

(cid:16)

log

1
ξ

−

(cid:17)

1 +

(

Q

n

j=1(e−ξuj
(e−ξ

−
1)n−1

1)

−

, ξ > 0.

)

For illustration purpose, we will use the Gaussian, Clayton and Frank copulas as examples.

In order to compare the effects of dependences, we need to compare the degrees of dependences. For this purpose,
we use the concordance order [15, 8]. Let C1 and C2 be two copulas, we say C1 is less than C2 in concordance order
if C1(u1, . . . , un)
C2(u1, . . . , un) for all 0
1, i = 1, . . . , n. In particular, Gaussian copulas and Clayton
copulas are increasing in σ and θ in concordance order, respectively.

ui ≤

≤

≤

The following lemmas will be used in the paper.

Lemma 1 ([15]) Let C be any n-copula, then

max

n




Xj=1

uj −

n + 1, 0




C(u1, . . . , un)

min

.
u1, . . . , un}
{

≤

≤

Lemma 2 ([15]) Let C be an n-copula, then





C(u1, . . . , un)
|

−

C(v1, . . . , vn)

| ≤

n

Xj=1

uj −
|

.
vj|

4

3 Cyber Epidemic Model With Arbitrary Dependences

Now we present and investigate the cyber epidemic model that accommodates the dependences between the cyber
attack events. This is the ﬁrst systematic treatment of dependences in cyber epidemic models.

3.1 The Model

|

}

}

∈

V

∈

1, 2, . . . , N
{

V
|
(u, v) : u, v
{

As in [19], we consider an undirected ﬁnite network graph G = (V, E), where V =
is the set of
nodes (vertices) that can abstract computers (or software components at an appropriate resolution), and
N =
is the set of edges. Note that G abstracts the network structure according to which the
E =
E abstracts that node u can attack
push-based cyber attacks take place (e.g., malware spreading), where (u, v)
V can directly attack any
node v. In both principle and practice, G can range from a complete graph (i.e., any u
V) to any speciﬁc graph structure (i.e., node u may not be able to attack node v directly because, for example, the
v
trafﬁc from node u is ﬁltered or u is blacklisted by v), which explains why we should pursue general results without
restricting the network/graph structures. Denote by A = (avu) the adjacency matrix of G, where avu = 1 if and only
E, and avu = 0 otherwise. Note that the problem setting naturally implies avv = 0. Denote by deg(v) the
if (u, v)
V is either secure (but vulnerable to attacks) or infected (and can
degree of node v. In a discrete-time model, node v
attack other nodes) at any time t = 0, 1, . . .. At each time step, an infected node v becomes secure with probability β,
which abstracts the defense power. The model accommodates two large classes of cyber attacks: a secure node v can
become infected because of (i) pull-based cyber attacks with probability α, which include drive-by-download attacks
(i.e., node v getting infected because its user visits a malicious website) and insider attacks (i.e., the user intentionally
E
runs a malware on node v), or (ii) push-based cyber attacks launched by v’s infected neighbor u over edge (u, v)
with probability γ.

∈

∈

∈

∈

∈

Our extension to the above model is to accommodate the dependences between the push-based attacks as well
as the dependences between the push-based attacks and the pull-based attacks. These attacks are not independent
because the events that the nodes get infected are not independent of each other, and because the push-based attacks
are not independent of the pull-based attacks (e.g., a malware could ﬁrst infect some nodes via the pull-based cyber
attacks and then launch the push-based cyber attacks from the infected nodes). Moreover, the dependences between
the push-based attacks can model that intelligent malwares launch coordinated attacks against the secure nodes.

Speciﬁcally, let Iv(t) denote the state of node v at time t, where Iv(t) = 1 means v is infected and 0 means v is

secure. Let

Iv,1(t), . . . , Iv,deg(v)(t)

denote the state vector of node v’s neighbors at time t, where

(cid:0)

Iv,j(t) =

(cid:1)

(cid:26)

the jth neighbor of node v is infected at time t,

1,
0, otherwise.

Deﬁne iv(t) = P(Iv(t) = 1) and iv,j(t) = P(Iv,j(t) = 1
Iv(t) = 0) where j = 1, . . . , deg(v).
|

Let Xv(t) = 1 denote the event that node v is infected at time t + 1 because of the push-based cyber attacks, and
Xv(t) = 0 otherwise. Let Xv,j (t + 1) = 1 denote the event that node v is infected at time t + 1 by its jth neighbor,
and Xv,j(t + 1) = 0 otherwise. Note that P(Xv,j(t + 1) = 1
iv,j (t). Since any dependence structure
Iv(t) = 0) = γ
|
between Xv,1(t + 1), . . . , Xv,deg(v)(t + 1) always can be accommodated by some copula function Cv, we have

·

P(Xv(t + 1) = 0
Iv(t) = 0)
|
P(Xv,1(t + 1) = 1
Iv(t) = 0), . . . , 1
|
γiv,deg(v)(t)
γiv,1(t), . . . , 1

−

1

1

.

= Cv
= Cv

(cid:0)

−

−

P(Xv,deg(v)(t + 1) = 1
Iv(t) = 0)
|

−

(cid:1)

(1)

(cid:1)
(cid:0)
Similarly, let Yv(t + 1) = 1 denote the event that node v is infected at time t + 1 because of the pull-based cyber
attacks. Then, we have P(Yv(t + 1) = 1
Iv(t) = 0) = α. By further accommodating the dependence structure
|
between the push-based attacks and the pull-based attacks via some copula function C, we have

P(Iv(t + 1) = 1
Iv(t) = 0)
|
P (Xv(t + 1) = 0, Yv(t + 1) = 0
Iv(t) = 0)
|
C

γiv,1(t), . . . , 1

γiv,deg(v)(t)

Cv

−

1

= 1

= 1

, 1

−

−

−

(cid:0)

(cid:0)

5

(cid:1)

α

.

−

(cid:1)

(2)

Note that

From Eqs. (1), (2) and (3), we obtain the probability that node v

V is infected at time t + 1 as:

∈

P(Iv(t + 1) = 1
Iv(t) = 1) = (1
|

−

β)iv(t).

iv(t + 1) = P(Iv(t + 1) = 1)
Iv(t) = 0)P(Iv(t) = 0)
Iv(t) = 1)P(Iv(t) = 1) + P(Iv(t + 1) = 1
= P(Iv(t + 1) = 1
|
|
iv(t) + P(Iv(t + 1) = 1
β)
Iv(t) = 0)
= (1
(1
|
γiv,1(t), . . . , 1
C
β)iv(t) +

iv(t))
γiv,deg(v)(t)

= (1

Cv

, 1

(1

−

−

α

1

1

·

·

−

−

−

−

−

iv(t)).

−

(3)

(4)

(cid:0)

(cid:0)

∈

We will analyze Eq. (4) for v

(cid:2)
V to characterize the effects of the dependence structures C and Cv and the
side-effects of assuming them away. Note that for the special case that the Xv,j’s are independent of each other
and the push-based attacks and the pull-based attacks are also independent of each other, Eq. (4) degenerates to the
model in [19]. Note also that in order to characterize the side-effects of assuming away the dependences, we need to
accommodate the dependences at a higher-level of abstraction than the model parameters α and γ. This is because
the parameters are indeed relatively easier to obtain in experiments/practice (e.g., considering a single compromised
neighbor that is launching the push-based attacks, and considering the pull-based attacks in the absence of the push-
based attacks).

(cid:1)(cid:3)

(cid:1)

3.2 Epidemic Equilibrium Threshold and Bounds for Equilibrium Infection Probabilities

The concept of epidemic equilibrium threshold [19] naturally extends the well-known concept of epidemic threshold in
that the former describes the condition under which the epidemic spreading converges to a non-negative equilibrium,
whereas the latter traditionally describes the condition under which the epidemic spreading converges to 0 (i.e., the
spreading dies out). Note that α > 0 implies that the spreading will never die out and that α = 0 is necessary for the
spreading to die out. Denote by i∗
V. In the equilibrium, Eq. (4)
v the equilibrium infection probability for node v
becomes:

∈

i∗
v = (1

β)i∗

v +

−

1

−

C

Cv

1

γi∗

v,1, . . . , 1

γi∗

v,deg(v)

−

−

, 1

−

α

(1

i∗
v),

−

V.

v

∈

(5)

In what follows, Theorem 1 gives a general epidemic equilibrium threshold (i.e., sufﬁcient condition under which the
spreading enters the equilibrium), and Theorem 2 gives a more succinct but more restrictive sufﬁcient condition.

h

(cid:16)

(cid:16)

(cid:17)

(cid:17)i

Lemma 3 Let A be the adjacency matrix of G. If

ρ(A) <

(β + α)2
γβ

,

(6)

then system (4) has a unique equilibrium (i∗

1, . . . , i∗
N )

[0, 1]N .

∈

Proof For any v

∈

V, deﬁne fv(x) : [0, 1]N

[0, 1] as

→
γxv,1, . . . , 1

−
γxv,1, . . . , 1

fv(x) =

C

1

−
β + 1

Cv
C
(cid:0)

1
Cv
(cid:0)

−
1

γxv,deg(v)

, 1

γxv,deg(v)
(cid:1)

−

−
, 1

α

α
(cid:1)
−

,

v = 1, . . . , N,

−

−
(cid:0)
) : [0, 1]N
[0, 1]N . Deﬁne f (
·

(cid:0)

[0, 1]N , where f (x) = (f1(x), . . . , fN (x)). According
where x = (x1, . . . , xN )
→
to the Banach ﬁxed-point theorem [7], it is sufﬁcient to show that f (x) = x has a unique solution i∗; that is, we need
to prove that f (
) is a contraction mapping.
·
[0, 1]N . Consider the distance between them in the Euclidean norm,
Let x, y

∈

(cid:1)

(cid:1)

∈

f (x)

||

−

f (y)

||

=

N

v
u
u
t

v=1
X

(fv(x)

−

fv(y))2 =

N

v
u
u
t

v=1 (cid:18)
X

2

,

βΓv
∆v (cid:19)

6

where

Γv = C

Cv

1

γxv,1, . . . , 1

γxv,deg(v)

, 1

α

−

−

C

Cv

1

−

γyv,1, . . . , 1

−

γyv,deg(v)

, 1

−

−

(cid:0)

(cid:0)
β + 1

∆v =

C

Cv

1

−

−

(cid:1)
γxv,1, . . . , 1

−

(cid:0)

(cid:0)

(cid:0)

By Lemmas 1 and 2, it follows that

·

(cid:0)

(cid:1)
γxv,deg(v)
C
β + 1
(cid:1)

−

(cid:0)
, 1
Cv

(cid:0)
α

−

1

γyv,1, . . . , 1

(cid:1)(cid:1)
−

−

γyv,deg(v)

, 1

(cid:0)

(cid:0)

(cid:1)

α

.

−

(cid:1)(cid:1)

α

,

−

(cid:1)

(cid:1)

Γv| ≤

|

γ

deg(v)

Xk=1

xv,k −
|

yv,k|

and ∆v ≥

(β + α)2.

f (x)

||

−

f (y)

|| ≤

βγ
(β + α)2 v
u
u
u
t

N

deg(v)

v=1
X





Xk=1

xv,k −
|

2

.

yv,k|


Therefore, we have

Moreover,

N

deg(v)

v=1
X





Xk=1

xv,k −
|

2

yv,k|


x1 −
= (
|

, . . . ,

y1|

xN −
|

yN |

)A2(
x1 −
|

, . . . ,

y1|

xN −
|

)T
yN |

||
denotes the operator norm of A. Since A is symmetric matrix, we have

(
y1|
x1 −
≤ ||
|
2
y
x
A
=
||
||
−

, . . . ,
2,
||

xN −
|

2
)
yN |
||

||

A

2
||

where

A

||

||

A

||

||

= ρ(A).

From condition (6), it follows that

f (x)

||

−

f (y)

|| ≤

βγρ(A)
(β + α)2 ||

x

y

||

−

<

x

||

y

,
||

−

which means that f (
) is a contraction mapping.
·

≤
≤
h(α, β, γ, i∗

Theorem 1 (general epidemic equilibrium threshold) Let A be the adjacency matrix of G and D be the diagonal
matrix with the vth (1

N ) diagonal element equal to

v

where i∗
that system (4) has a unique equilibrium, and the spectral radius ρ(W ) < 1, then limt→∞ iv(t) = i∗
for all v

v is the equilibrium infection probability that satisﬁes Eq. (5). Let W = D+γA. If condition (6) holds, namely
v exponentially

V.

(cid:16)

(cid:16)

(cid:12)
(cid:12)
(cid:12)

v) =

C

Cv

1

γi∗

v,1, . . . , 1

γi∗

v,deg(v)

−

−

, 1

−

α

(cid:17)

−

(cid:17)

β

,

(cid:12)
(cid:12)
(cid:12)

∈

Proof According to Lemma 3, there is a unique solution for i∗
We want to identify a sufﬁcient condition under which limt→∞

v under condition (6). Denote by rv(t) = iv(t)
rv(t)
|
|

V . Note that

= 0 for all v

∈

i∗
v.

−

rv(t + 1) = rv(t)

C

Cv

1

γi∗

v,1, . . . , 1

γi∗

v,deg(v)

, 1

α

β

+ (1

iv(t))

−
γi∗

h

C

(cid:16)
Cv

1

h

(cid:16)

(cid:16)

(cid:16)
−

×

−
γi∗

v,1, . . . , 1

v,deg(v)

−

−
C

(cid:17)
−

−
α

(cid:17)

i
Cv

1

−

(cid:0)

(cid:0)

−

(cid:17)
, 1

(cid:17)
7

−
γiv,1(t), . . . , 1

γiv,deg(v)(t)

, 1

−

(cid:1)

−

.

α
(cid:1)i

By Lemma 2, we have

rv(t + 1)
|

| ≤ |

×

1

h(α, β, γ, i∗
rv(t)
|
γi∗
Cv
(cid:12)
(cid:16)
(cid:12)
h(α, β, γ, i∗
(cid:12)
rv(t)
|

−

≤ |

v ) + (1
v,1, . . . , 1

iv(t))
−
γi∗

v,deg(v)

−

v ) + γ (1

iv(t))

−

h(α, β, γ, i∗
rv(t)
|

v ) + γ

≤ |

deg(v)

Xj=1

,
rv,j(t)
|
|

Cv

γiv,1(t), . . . , 1

1

−

−

−
(cid:17)
deg(v)

Xj=1

(cid:0)
i∗
v,j −
|

iv,j(t)
|

γiv,deg(v)(t)

(cid:1)(cid:12)
(cid:12)
(cid:12)

where

Deﬁne

h(α, β, γ, i∗

v) =

C

Cv

1

(cid:16)

(cid:16)

(cid:12)
(cid:12)
(cid:12)

γi∗

v,1, . . . , 1

γi∗

v,deg(v)

−

−

, 1

−

α

(cid:17)

−

(cid:17)

β

.

(cid:12)
(cid:12)
(cid:12)

zv(t + 1) = zv(t)h(α, β, γ, i∗

v ) + γ

zv,j(t),

deg(v)

Xj=1

with zv(0)
(z1(t), . . . , zn(t))T . Then, we have the following matrix form

rv,j(0)
|

and zv,j(0)

rv(0)
|

≡ |

≡ |

for j = 1, . . . , deg(v). We see

rv(t)
|

| ≤

zv(t) for any t. Let z(t) =

z(t + 1) = W z(t) = W t+1z(0),

(7)

where W = D + γA, D is the diagonal matrix with diagonal element h(α, β, γ, i∗
v ), and A is the adjacency matrix
of G. Since matrix W is nonnegative and symmetric, the Spectral Theorem [12] says that ρ(W ) is real. By using the
well-known Gelfand formula, if ρ(W ) < 1, then limt→∞ W t = 0 and therefore limt→∞ z(t) = 0. Since

ρ(W ) = lim

t→∞ k

W t

1/t and
k

W t

k

k∼

[ρ(W )]t ,

t

,

→ ∞

where
This means that the convergence rate of limt→∞ i(t) = i∗ is at least exponential.

is the norm in real space Rn, we conclude that

k · k

W t

k

k

converges to 0 exponentially when ρ(W ) < 1.

Use of the sufﬁcient condition given by Theorem 1 requires to know i∗ (i.e., i∗

v for all v), which is difﬁcult to
obtain analytically. It is therefore important to weaken this requirement. Now we present a sufﬁcient condition that
only requires the equilibrium infection probability i∗
V). According to [4], we have

v for some v (rather than for all v

∈

ρ(W )

max
v∈V

≤

h(α, β, γ, i∗

v ) + γρ(A).

Therefore, a more restrictive (than the one given by Theorem 1) sufﬁcient condition is to require

h(α, β, γ, i∗

v ) + γρ(A) < 1, namely ρ(A) <

max
v∈V

1

−

maxv∈V h(α, β, γ, i∗
v )
γ

.

According to Eq. (5), we have

h(α, β, γ, i∗

v) =

Therefore, we obtain the following more restrictive, but more succinct, sufﬁcient condition:

Corollary 1 limt→∞ iv(t) = i∗

v exponentially for all v

V, if

−

1

1
(cid:12)
(cid:12)
(cid:12)
(cid:12)

β

−

.

i∗
v (cid:12)
(cid:12)
(cid:12)
(cid:12)

∈
1
maxv∈V |
γ

8

ρ(A)

min

≤

1

−

(cid:26)

β/(1

−

i∗
v)
|

,

−

(β + α)2
γβ

.

(cid:27)

(8)

Applying the above sufﬁcient condition still requires to know the minimal and maximal i∗

v’s, which is hard to
obtain analytically. Although it is always possible to obtain them numerically, we would want to have some more
general results without relying on numerical solutions. In what follows we present such a sufﬁcient condition (Theo-
rem 2), which requires the following Proposition 1 that presents bounds for the equilibrium infection probability. The
bounds are certainly of independent value.

Proposition 1 (bounds for equilibrium infection probabilities) For any dependence structures C and Cv, which may
be unknown, the equilibrium infection probability i∗

V satisﬁes i∗−

i∗+
v , where

v for v

∈

γ

i∗− =

β

−
γ

I

γ > α + β
{

}

+

α
β + α

I

γ
{

≤

α + β

,
}

i∗+
v =

i∗
v ≤

≤

min

n
β + min

α + γdeg(v)

β+1 , 1
α + γdeg(v)

o
β+1 , 1

.

Proof Rewrite Eq. (5) as

i∗
v =

1

−
β + 1

C

Cv

1

(cid:16)
C

(cid:16)
Cv

−

γi∗

γi∗

−
1

−

v,1, . . . , 1
γi∗

−
v,1, . . . , 1

−

v,deg(v)
γi∗

(cid:17)
v,deg(v)

, 1

−
, 1

(cid:16)

(cid:16)

(cid:17)

o

n

α

.

(9)

(cid:17)
α

−

(cid:17)

By noticing the monotonicity in (9) and applying Lemma 1, we obtain

max

n
β + max

γi∗

v,1, . . . , γi∗
γi∗

v,1, . . . , γi∗

v,deg(v), α

o
v,deg(v), α

i∗
v ≤

≤

min

α + γ

deg(v)
j=1

n
β + min

P
α + γ

i∗
v,j, 1
o
i∗
v,j, 1

deg(v)
j=1

.

(10)

n
Let us ﬁrst consider the lower bound. Note that for each v

o

By substituting x1 for i∗

v,j in Ineq. (10), we have

i∗
v ≥

x1

n

P

o

V,

α
β + α

.

∈
def
=

max
γx1, α
}
{
γx1, α
β + max
}
{
v,j in Ineq. (10), we obtain x3. By repeating the substitution, we obtain a sequence

i∗
v ≥

△
=

x2

.

xn, n
{

1
}

≥

γxn−1, α
}
γxn−1, α
}
is increasing and bounded, we can get its limit, namely i∗−, by solving the following equation

max
{
β + max

x0 = 0.

xn =

{

,

By substituting x2 for i∗
with

Since

xn, n
{

1
}

≥

For the upper bound, note that i∗

v ≤

1
β + 1

∈

v,j in Ineq. (10), we get i∗+
v .

γx, α
max
}
{
γx, α
β + max
{
}
V. By substituting 1/(β + 1) for i∗

= x.

for v

It is useful to know when the bounds in Proposition 1 are tight. For this purpose, we observe that if
i∗− = α

γ
β+1 deg(v)
≈
0, meaning that γ deg(v) << 1 and that the attack-power is not strong, we have i∗+
. This means
that the bounds are tight when the attack-power is not strong. On the other hand, Proposition 1 allows us to derive the
following more succinct, but more restrictive (than Corollary 1 and therefore Theorem 1), sufﬁcient condition for the
epidemic spreading converges to the equilibrium (i.e., epidemic equilibrium threshold). The new sufﬁcient condition
involves the bounds i∗− and i∗+
v only (i.e., none of the equilibrium probabilities that are hard to obtain analytically).

v ≈

β + α

9

Theorem 2 (succinct epidemic equilibrium threshold) The spreading enters the unique equilibrium if

1

max
v∈V

−

ρ(A)

≤

(cid:26)

max

1

−

1

β
i∗−

−
γ

,

1

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

β
i∗+
v

−

−

1

(cid:27)(cid:27)

,

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:26)(cid:12)
(cid:12)
(cid:12)
(cid:12)

≤

i∗
v (cid:12)
(cid:12)
(cid:12)
(cid:12)
β
i∗−

−

β
i∗−

−

(cid:12)
(cid:12)
(cid:12)
(cid:12)
1

,

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

β

−

−

1

1
(cid:12)
(cid:12)
(cid:12)
(cid:12)

−

1

1
(cid:12)
(cid:12)
(cid:12)
(cid:12)

where i∗− and i∗+

v are deﬁned in Proposition 1.

Proof Note that for any v

V, we have

∈

max
v∈V

h(α, β, γ, i∗

v) = max
v∈V

max

max
v∈V

(cid:26)

1

−

≥

β
i∗−

−

1

,

1
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

β
i∗+
v

−

−

1

.

(cid:12)
(cid:27)(cid:27)
(cid:12)
(cid:12)
(cid:12)

,

−

1
(cid:26)(cid:12)
(cid:12)
(cid:12)
(cid:12)
(β + α)2
β

Note that

which implies

Therefore,

1

max
v∈V

−

max

(cid:26)

max
v∈V

max

(cid:26)

−

1

1
(cid:26)(cid:12)
(cid:12)
(cid:12)
(cid:12)

1

−

≥

(β + α)2
β

.

β
i∗+
v

−

−

1

(cid:12)
(cid:27)(cid:27)
(cid:12)
(cid:12)
(cid:12)

β
i∗−

−

−

1

β
i∗+
v

−

−

1

,

1

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
(cid:26)(cid:12)
(cid:12)
(cid:12)
(cid:12)

≤

min

1

(cid:26)

max
v∈V |

1

−

−

β/(1

i∗
v)
|

,

−

(β + α)2
β

.

(cid:27)

(cid:12)
(cid:27)(cid:27)
(cid:12)
(cid:12)
(cid:12)

According to Corollary 1, we obtain the desired result.

3.3 Tighter Bounds for Equilibrium Infection Probabilities in Star and Regular Networks

Star networks. A star-shaped network consists of a hub and (N
Hence, the adjacency matrix A can be represented as

−

1) leaves that are connected only to the hub.

0 1 . . . 1
1 0 . . . 0
...
. . . 0
1 0 . . . 0

...








N ×N

A = 





The spectral radius is ρ(A) = √N

1. In this case, Eq. (5) becomes:

−

i∗
h =

1
−
β + 1

C (δCh (1

−
C (δCh (1

γi∗

l ) , 1
γi∗

−
l ) , 1

α)

α)

,

(11)

−
γi∗
h, 1
−
γi∗
h, 1
l are the equilibrium probabilities that the hub and the leaves are infected, respectively. Note that the

where i∗
effect of the copula Ch on the equilibrium probabilities only depends on its diagonal section δCh.

−
1
−
1 + β

h and i∗

−
C (1

i∗
l =

C (1

(12)

α)

α)

−

−

−

−

,

In what follows we present two results about the equilibrium infection probabilities, which are not implied by the

above general results that apply to arbitrary network structures. First, we can prove i∗

i∗
l .

h ≥

Proposition 2 For the star networks, it holds that i∗

h ≥

i∗
l .

10

Proof Denote by

f (x) =

1
−
β + 1

C (δCh (1

−
C (δCh (1

−

γx) , 1

−
γx) , 1

−

α)

α)

−

and g(x) =

∈

and

f (i∗

≤
l ) = g−1(i∗

x, we have f (x)
l ) < i∗

[0, 1]. Since δCh(x)
h = f (i∗
g(i∗
l ≤

where x
l . Since g(x) is increasing in x and so is g−1, we have i∗
(11) and (12). Then, i∗
l ) < i∗
g(i∗
[0, 1].
l )
∈
h and i∗
Second, we present reﬁned bounds for equilibrium infection probabilities i∗

l . The bounds are useful because
even in the case of star networks, it is hard to derive analytic expressions and infeasible to numerically compute
(especially for complex dependence structures) i∗

l ), which contradicts with f (x)

g(x) for x

≥

≥

g(x). Suppose i∗

h and i∗
l .

1
−
1 + β

C (1

γx, 1

−
C (1
−
l and (i∗

−
h < i∗

α)

α)

−
γx, 1
−
h, i∗
l ) is a solution to Eqs.
l ≤

Proposition 3 (tighter upper bounds for the equilibrium infection probabilities in star networks) For star networks
and regardless of the dependence structures (which can be unknown), we have i∗−
i∗+
l

, where i∗− is deﬁned in Proposition 1 and

and i∗−

i∗
h ≤

i∗
l ≤

i∗+
h

≤

≤

i∗+
h =

1
β + 1

I

1

β + 1 ≥

(cid:26)

1
(N

(N

+

−

and

α
1)γ

−
−
1)γ

−

(cid:27)
α

β +

−

p

((N
2(N

−

1)γ

−

1)γ

−

β)2 + 4(N

α

−

1)γα

−

1
β + 1

<

1
(N

α
1)γ

.

(cid:27)

−
−

I

(cid:26)

i∗+
l =

1
β + 1

I

1

β + 1 ≥

(cid:26)

α

1

−
γ

(cid:27)

γ

α

−

−

+

β +

(γ
2γ

−

p

β)2 + 4γα

α

−

1
β + 1

1

<

α

−
γ

.

(cid:27)

I

(cid:26)

Proof The lower bound i∗− is the same as in Proposition 1. Let’s focus on i∗+

h . From Ineq. (10), we have

−
Since the right-hand side of the above inequality increases in i∗

l , by Proposition 2 we have

i∗
h ≤

min
α + (N
{
−
α + (N
β + min
{

1)γi∗

l , 1
}
1)γi∗
l , 1
}

△
= f (i∗

l ).

and therefore i∗

h ≤

h , where i∗+
i∗+

h is the solution to equation

x = f (x).

i∗
h ≤

f (i∗

h),

For the upper bound i∗+

l

, we can similarly obtain the desired result by solving equation

x = f

x

N

(cid:18)

1

(cid:19)

−

.

(13)

(14)

Now we explain why the upper bounds i∗+
h

given by Proposition 3 are smaller (i.e., tighter) than the
general upper bounds that can be derived from Proposition 1 by instantiating G = (V, E) as star networks. To see this,
we note that i∗+

h is the solution to Eq. (13) and i∗+

1
β+1 , meaning that

and i∗+

l

h ≤

where the right-hand side of the inequality is exactly the upper bound that can be derived from Proposition 1 by sub-
stituting deg(v) with the degree of the hub. This means that i∗+
h is smaller than the upper bound given by Proposition

min

α + (N

i∗+
h ≤

n
β + min

−
α + (N

1) γ

β+1 , 1
1) γ

o
β+1 , 1

−

,

o

n

11

1. Similarly, we can show that i∗+
i∗+
(13) and (14), we see that i∗+
l
1, we conclude that the bounds given by Proposition 3 are tighter than the bounds given by Proposition 1.

is smaller than the upper bound given by Proposition 1. Moreover, by comparing
. Since the lower bound i∗− is the same as the lower bound given by Proposition

l
h ≥

h, i∗

h = 1

l , i∗−, i∗+

h , and i∗+

To see the tightness of the bounds given by Proposition 3, we consider two combinations of dependence structures:
(C, Cv)=(Gaussian,Frank) and (C, Cv)=(Gaussian, Clayton) with parameters σ = θ = ξ = 0.1 as reviewed in
Section 2. Figure 1 plots i∗
for N = 3, . . . , 81 with (α, β, γ) = (0.5, 0.1, 0.1); all these
parameter settings satisfy condition (8). We observe that the upper bound i∗+
h becomes ﬂat for N
5, because it
causes i∗+
is ﬂat because it is always independent
of N . We observe that the upper bound for hub node, i∗+
h , becomes extremely tight for dense star networks with
N > 40. However, the upper bound for leave nodes almost always exhibits that i∗+
0.011 (i.e., the upper
l −
bound overestimates about 0.88 infected nodes for a star network of N = 80 nodes). In any case, the upper bounds
v’s and thus can be used for decision-making purpose when i∗
only somewhat overestimate the numerical solutions i∗
v’s
are infeasible to compute.

β+1 (i.e., independent of N ); whereas, the upper bound i∗+

i∗
l ≈

≥

l

l

5
9
.
0

0
9
.
0

5
8
.
0

0
8
.
0

5
7
.
0

Star

upper bound
numerical solution
lower bound

0

20

40
Leaves

60

80

7
8
.
0

6
8
.
0

5
8
.
0

4
8
.
0

3
8
.
0

Star

upper bound
numerical solution
lower bound

0

20

40
Leaves

60

80

5
9
.
0

0
9
.
0

5
8
.
0

0
8
.
0

5
7
.
0

Star

upper bound
numerical solution
lower bound

0

20

40
Leaves

60

80

7
8
.
0

6
8
.
0

5
8
.
0

4
8
.
0

3
8
.
0

Star

upper bound
numerical solution
lower bound

0

20

40
Leaves

60

80

(a) Hub: (Gaussian, Frank)

(b) Leaves: (Gaussian, Frank)

(c) Hub: (Gaussian, Clayton)

(d) Leaves: (Gaussian, Clayton)

h for hub (i∗+
Figure 1: Star networks: upper bound i∗+
lower bound i∗− (for both hub and leaves) with respect to (α, β, γ) = (0.5, 0.1, 0.1) and (C, Cv).

for leaves) vs. numerical solution i∗

h for hub (i∗

l

l for leaves) vs.

Regular networks. For regular networks, each node v
According to Proposition 1, we have

∈

V has degree d for some d

[1, N

∈

−

1] and ρ(A) = d.

Cv
C
α
(cid:0)
(cid:1)
−
−
Now we want to present reﬁned bounds for equilibrium infection probability i∗
v.

v,1, . . . , 1
γi∗

−
v,1, . . . , 1

−
β + 1

1
Cv
(cid:0)

i∗
v =

−
, 1

−
1

, 1

−

−

C

α

1

(cid:0)

(cid:0)

(cid:1)

(cid:1)

γi∗
v,d
γi∗
(cid:1)
v,d

γi∗

,

v

V.

∈

Proposition 4 (tighter upper bound for the equilibrium infection probability in regular networks) For regular network
G = (V, E) and regardless of the dependence structures (which can be unknown), we have i∗−
i∗+ for any
v

V, where i∗− is deﬁned in Proposition 1 and

i∗
v ≤

≤

∈

i∗+ =

1
β + 1

I

1

β + 1 ≥

(cid:26)

1

α

−
γd

(cid:27)

γd

α

−

−

+

β +

(γd
−
2γd

α

−

p

β)2 + 4γαd

1
β + 1

1

<

α

−
γd

.

(cid:27)

I

(cid:26)

Proof Deﬁne function

f (x) =

min
α + γdx, 1
}
{
α + γdx, 1
β + min
}
{
with xn = f (xn−1), x0 = 1/(β + 1). Observe that for all v

x1 for all v

∈
x0, xn is decreasing in n. Thus, we have i∗
1−α
γd , then i∗+ = 1

V. By repeating this process, we have i∗

x0
v ≤
xn for
i∗+, which is the solution
v ≤
β+1 ; otherwise, i∗+ is the positive solution to equation

v ≤

v ≤

∈

V, we have i∗

α = 0. Thus, we obtain the desired result.

≥

0
}

xn, n
{

and a sequence
and hence from Ineq. (10), it follows that i∗
all n. Since f (x) is increasing and x1 ≤
of the equation x = f (x). If
γdx2 + (α + β

1
β+1 ≥

γd)x

−

−

12

Note that the upper bound i∗+ given by Proposition 4 is smaller than the upper bound i∗+

v obtained by instantiating
deg(v) = d in Proposition 1, because i∗+
is exactly the x1 deﬁned in the proof of Proposition 4. To see the tightness of
v
bounds i∗− and i∗+ given by Proposition 4, we consider (C, Cv)=(Gaussian,Frank) and (C, Cv)=(Gaussian, Clayton)
with parameters σ = θ = ξ = 0.1 as reviewed in Section 2. Figure 2 plots numerical i∗
v, i∗− and i∗+ with respect
to node degree d = 2, . . . , 80 with (α, β, γ) = (0.5, 0.1, 0.01); all these parameter settings satisfy condition (8).
becomes ﬂat for sufﬁciently dense regular networks. This is because i∗+
We observe that i∗+
v
≥
(1−α)(β+1)
. For (C, Cv)=(Gaussian,Frank), we further observe that the upper bound i∗+
is reasonably tight especially
v
γ
i∗
for relatively sparse regular networks, with i∗+
v < 0.021 for d < 20 (i.e., for a sparse regular network of
N = 1000 nodes, the upper bound only overestimates at most 21 infected nodes). Even for dense regular network
with d > 20, we have i∗+
0.038 (i.e., for a dense regular network of N = 1000 nodes, the upper bound
only overestimates at most 38 infected nodes), where equality holds for d = 54. For (C, Cv)=(Gaussian, Clayton),
we also observe that the upper bound i∗+
is tight especially for relatively sparse regular networks with d < 20 and
v
i∗
i∗+
v < 0.021 (i.e., for a sparse regular network of N = 1000 nodes, the upper bound only overestimates at most
v −
21 infected nodes). Even for dense regular network with d > 20, we have i∗+
0.039, where equality holds
for d = 54. This means that for decision-making purpose, the defender can use the upper bound i∗+
instead of the
v
numerical solution i∗

β+1 when d

v = 1

v is infeasible to compute.

v, especially when i∗

i∗
v ≤

i∗
v ≤

v −

v −

v −

0
0
.
1

5
9
.
0

0
9
.
0

5
8
.
0

0
8
.
0

Regular
upper bound
numerical solution
lower bound

0

20

40
Degree

60

80

0
0
.
1

5
9
.
0

0
9
.
0

5
8
.
0

0
8
.
0

Regular
upper bound
numerical solution
lower bound

0

20

40
Degree

60

80

(a) (Gaussian,Frank,0.5,0.1,0.01)

(b) (Gaussian,Clayton,0.5,0.1,0.01)

Figure 2: Regular networks: upper bound i∗+
v
(C, Cv, α, β, γ)

vs. numerical solution i∗

v vs.

lower bound i∗−

v with respect to

3.4 Approximating Equilibrium Infection Probabilities in ER and Power-law Networks

For star and regular networks, we have derived tighter bounds for equilibrium infection probabilities (than the general
bounds given by Proposition 1). Unfortunately, we do not know how to derive tighter bounds for ER and power-law
networks. As an alternative, we propose to approximate equilibrium infection probabilities by taking advantage of the
upper and lower bounds. The approximation is useful because it is often smaller than the upper bound, which never
underestimates, but may substantially overestimate, the threats in terms of equilibrium infection probabilities. That
is, the approximation method can lead to more cost-effective defense than the upper bound.

The approximation method is the following: We ﬁrst compute lower bounds, upper bounds, and numerical solu-
tions for a feasible number of instances of (G, C, Cv, α, β, γ), based on given computer resources. We then use the
resulting data to derive (via statistical methods) some function of the lower and upper bounds. For even larger G of
the same type as well as (C, Cv) of the same kind, the resulting function would be smaller than the upper bound and
would not underestimate the equilibrium infection probabilities. The key insight is that we can compute, for networks
of any size, the upper and lower bounds according to Proposition 1. This means that we can approximate the equi-
librium infection probabilities for arbitrarily large networks, for which it is often infeasible to numerically (let alone
analytically) compute the equilibrium infection probabilities.

To illustrate the approximation method, we also consider (C, Cv)=(Gaussian,Frank) and (C, Cv)=(Gaussian,
Clayton) with parameters σ = θ = ξ = 0.1 as reviewed in Section 2. We use the erdos.renyi.game generator
of the igraph package in the R system to generate a random ER network of N = 1000 nodes and edge proba-
bility 0.01; the resulting network instance has spectral radius 11.38045. We use the static.power.law.game

13

generator of the igraph package in the R system to generate a random power-law network of N = 1000 nodes,
5000 edges, and power-law exponent 2.1 (note that 2.1 is the power-law exponent of the Internet AS-level net-
work [6]); the resulting network instance has spectral radius 22.97582. We consider combinations of (α, β, γ) that
satisfy condition (8), where α
,
}
. It turns out that for (C, Cv)=(Gaussian, Frank), the ER
γ
0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1
}
network has 307 combinations of (α, β, γ) that satisfy condition (8); the power-law network has 125 combinations
of (α, β, γ) that satisfy condition (8), because the spectral radius is larger. For (C, Cv)=(Gaussian, Clayton), the ER
network has 307 combinations of (α, β, γ) that satisfy condition (8); the power-law network has 126 combinations of
(α, β, γ) that satisfy condition (8).

0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9

0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5

, β
}

∈ {

∈ {

∈ {

We compute equilibrium infection probability i∗

v numerically by solving Eqs. (5) for v

in the R system. We compute the upper and lower bounds, namely i∗− and i∗+
it is infeasible to numerically compute i∗
i∗
v = 1
, where
2

∈
v for large networks, we propose to approximate i∗

v

V via the BB package
v , according to Proposition 1. Since
V via

v for node v

∈

(cid:17)

v = f(C,Cv)(i∗−, i∗+
i∗

v , deg(v)) = k0 + k1i∗− + k2i∗+

v + k3 deg(v)

v + i∗+
i∗
(cid:16)

b

e

e

i∗
can be statistically derived from the data. Note that the heuristic function
v could be reﬁned via more extensive
numerical studies. We deﬁne the approximation error for network G as errG =
v is
an important factor for cyber defense decision-making. For practical use, it is desired that errG
0, meaning that
b
the defender never underestimates the threats, and at the same time errG
0, meaning that the defender does not
overestimate the threats (i.e., does not overprovision defense resources) too much.

i∗
v), because

v∈V i∗

i∗
v −

v∈V(

P

P

≥

≈

b

ER networks. For the ER network, we obtain the following formulas :

•

For (C, Cv)=(Gaussian, Frank), we have

−
i∗
For (C, Cv)=(Gaussian, Clayton), we have
v =
b

i∗
v =

0.01759 + 0.3142i∗− + 0.7294i∗+

v −

0.0002575 deg(v).

0.0174076+0.3150585i∗− +0.7281992i∗+

0.0002596 deg(v).

v −

b

−

−

P

P

v −

v∈V(i−

v∈V(i∗+

•
For (C, Cv)=(Gaussian, Frank), the average of the errG’s over the 307 combinations of (C, Cv, α, β, γ) is 46,
meaning that the approximation method only overestimates 46 infected nodes in an ER network of 1000 nodes. In
i∗
comparison, the average of the
v)’s over the 307 combinations of (C, Cv, α, β, γ) is 93, meaning that
the upper bound overestimates 93 infected nodes (i.e., the approximation method is indeed better); the average of
i∗
v)’s is -52.7, meaning that the lower bound underestimates 52.7 infected nodes in an ER network
the
of 1000 nodes. Finally, we note that among the 307 combinations of (C, Cv, α, β, γ), the maximum errG is 165.2,
which is elaborated in Figure 3(a) and will be discussed further, and the minimum errG is 4.1, which is elaborated in
Figure 3(b) and will be discussed further as well. For (C, Cv)=(Gaussian, Clayton), the average of the errG’s over the
307 combinations of (C, Cv, α, β, γ) is 46.5, meaning that the approximation method only overestimates 46.5 infected
i∗
v)’s over the 307 combinations
nodes in an ER network of 1000 nodes. In comparison, the average of the
of (C, Cv, α, β, γ) is 93, meaning that the upper bound overestimates 93 infected nodes in an ER network of 1000
i∗
v)’s is -52.5, meaning that the lower bound underestimates 52.5 infected
nodes; the average of the 307
nodes in an ER network of 1000 nodes. Among the 307 instances, the maximum errG is 165.0, which is elaborated
in Figure 3(d) and will be discussed further, and the minimum errG is 4.2, which is elaborated in Figure 3(e) and will
be discussed further. In summary, cyber defense decision-making can be based on the approximation method, which
takes advantage of the upper and lower bounds and would be better (smaller) than the upper bound.

v∈V(i∗+

v∈V(i−

v −

P

P

As a side-product, we would like to highlight the phenomenon that the equilibrium infection probability i∗
v in-
creases with node degree deg(v). This phenomenon was observed in [19] in the absence of dependence, and persists
v and i∗− with respect to distinct node de-
in the presence of dependence as we elaborate below. We consider i∗+
i∗
grees, by taking the average over the nodes of the same degree when needed. For (C, Cv)=(Gaussian,Frank), Figures
3(a)-3(b) plot the infection probabilities corresponding to the (α, β, γ) that leads to the maximum and minimum errG,
respectively; Figure 3(c) plots the infection probabilities averaged over the 307 combinations of (α, β, γ) that satisfy
condition (8). For (C, Cv)=(Gaussian,Clayton), Figures 3(d)-3(e) plot the infection probabilities corresponding to

v , i∗
v,

−

b

14

8

.

0

6

.

0

4

.

0

2

.

0

0
0

.

8

.

0

6

.

0

4

.

0

2
.
0

0
.
0

ER
upper bound
approximation
numerical solution
lower bound

5

10
Degree

15

20

(a) (Gaussian,Frank, 0.01,0.4,0.03)

ER
upper bound
approximation
numerical solution
lower bound

5

10
Degree

15

20

0
4
0

.

5
3

.

0

0
3

.

0

5
2

.

0

0
2

.

0

0
4

.

0

5
3
0

.

0
3

.

0

5
2
.
0

0
2
.
0

ER
upper bound
approximation
numerical solution
lower bound

5

10
Degree

15

20

(b) (Gaussian,Frank, 0.3,0.9,0.01)

ER
upper bound
approximation
numerical solution
lower bound

ER
upper bound
approximation
numerical solution
lower bound

5

10
Degree

15

20

(c) (Gaussian,Frank)

ER
upper bound
approximation
numerical solution
lower bound

0

.

1

8

.

0

6

.

0

4

.

0

2
0

.

0

.

1

8

.

0

6

.

0

4
.
0

2
.
0

5

10
Degree

15

20

5

10
Degree

15

20

(d) (Gaussian,Clayton, 0.01,0.4,0.03)

(e) (Gaussian,Clayton, 0.3,0.9,0.01)

(f) (Gaussian,Clayton)

Figure 3: ER networks: upper bound vs. approximation vs. numerical solution vs.
(C, Cv, α, β, γ) or (C, Cv).

lower bound with respect to

the (α, β, γ) that leads to the maximum and minimum errG, respectively; Figure 4(f) plots the infection probabilities
i∗
averaged over the 307 combinations of (α, β, γ) that satisfy condition (8). We observe that the approximation
v
can slightly underestimate the infection probability i∗
5, but the overall estimation
v (solid
b
curves) increases with deg(v). This hints that there might be some universal scaling laws, in the presence or absence
P
P
of dependence. It is an interesting future work to identify the possible scaling law.

v (as mentioned above). More importantly, we observe that i∗

i∗
v is still above the actual threats

v for node v of degree deg(v)

v∈V i∗

v∈V

≤

b

Power-law networks. For power-law networks, we obtain the following formulas in a similar fashion:

For (C, Cv)=(Gaussian, Frank), we have

For (C, Cv)=(Gaussian, Clayton), we have
b

i∗
v =

−
i∗
v =

0.007395 + 0.34705i∗− + 0.67205i∗+

v + 0.00013505 deg(v).

0.007365 + 0.34765i∗− + 0.6714i∗+

v + 0.00013525 deg(v).

−

•

•

b

−

P

v −

v∈V(i−

v∈V(i∗+

For (C, Cv)=(Gaussian, Frank), the average of the errG’s over the 125 combinations of (C, Cv, α, β, γ) is 25, mean-
ing that the approximation only overestimates 25 infected nodes in a power-law network of 1000 nodes. In com-
i∗
parison, the average of the
v)’s over the 125 combinations of (C, Cv, α, β, γ) is 50.8, meaning that
the upper bound overestimates 50.8 infected nodes (i.e., the approximation method is better); the average of the
i∗
v)’s is -26, meaning that the lower bound underestimates 26 infected nodes. Among the 125 combina-
tions of (C, Cv, α, β, γ), the maximum errG is 84.5, which is elaborated in Figure 4(a) and will be discussed further,
P
and the minimum errG is 7.1, which is elaborated in Figure 4(b). For (C, Cv)=(Gaussian, Clayton), the average of the
errG’s over the 126 combinations of (C, Cv, α, β, γ) is 25.4, meaning that the approximation only overestimates 25.4
i∗
v)’s over the
infected nodes in a power-law network of 1000 nodes. In comparison, the average of the
126 combinations of (C, Cv, α, β, γ) is 50.8, meaning that the upper bound overestimates 50.8 infected nodes; the
i∗
v)’s is -26, meaning that the lower bound underestimates 26 infected nodes. Among
average of the 126
the 126 instances, the maximum errG is 84.5, which is elaborated in Figure 4(d), and the minimum errG is 7.2, which

v∈V(i∗+

v∈V(i−

v −

P

−

P

15

is elaborated in Figure 4(e). In summary, cyber defense decision-making can use the approximation method, which
takes advantage of the upper and lower bounds.

Power−law
upper bound
approximation
numerical solution
lower bound

Power−law
upper bound
approximation
numerical solution
lower bound

0

.

1

8

.

0

6

.

0

4

.

0

Power−law

upper bound
approximation
numerical solution
lower bound

0
1

.

8

.

0

6
0

.

4

.

0

2
0

.

0

20

40
Degree

60

80

0

20

40
Degree

60

80

0

20

40
Degree

60

80

(a) (Gaussian,Frank, 0.01,0.5,0.02)

(b) (Gaussian,Frank, 0.2,0.1,0.01)

(c) (Gaussian,Frank)

Power−law
upper bound
approximation
numerical solution
lower bound

Power−law
upper bound
approximation
numerical solution
lower bound

0

.

1

8
.
0

6
.
0

4
.
0

Power−law

upper bound
approximation
numerical solution
lower bound

0

.

1

8
0

.

6
.
0

4
.
0

2
.
0

0

.

1

8

.

0

6

.

0

4
0

.

2

.

0

0

.

0

0

.

1

8
0

.

6
.
0

4
.
0

2
.
0

0

20

40
Degree

60

80

0

20

40
Degree

60

80

0

20

40
Degree

60

80

(d) (Gaussian,Clayton, 0.01,0.5,0.02)

(e) (Gaussian,Clayton, 0.2,0.1,0.01)

(f) (Gaussian,Clayton)

Figure 4: Power-law networks: upper bound vs. approximation vs. numerical solution vs. lower bound with respect to
(C, Cv, α, β, γ) or (C, Cv). In Figures 4(b) and 4(e), the approximation result matches the numerical solution almost
perfectly.

We also would like to highlight the phenomenon that the equilibrium infection probability i∗

v increases with node
degree deg(v) in power-law networks. Similarly, for (C, Cv)=(Gaussian,Frank), Figures 4(a)-4(b) plot respectively
the infection probabilities corresponding to the (α, β, γ) that leads to the maximum and minimum errG, and Figure
4(c) plots the infection probabilities averaged over the 125 combinations of (C, Cv, α, β, γ) that satisfy condition
(8). For (C, Cv)=(Gaussian,Clayton), Figures 4(a)-4(b) plot respectively the infection probabilities corresponding to
the (α, β, γ) that leads to the maximum errG, and Figure 4(c) plots the infection probabilities averaged over the 126
i∗
combinations of (C, Cv, α, β, γ) that satisfy condition (8). We observe that the approximation
v never underestimates
v for any node v. We also observe that i∗
the infection probability i∗
v (solid curves) increases with deg(v), but exhibits
a higher nonlinearity when compared with the ER networks.

b

3.5 Bounds for Non-Equilibrium Infection Probabilities

It is important to characterize the behavior of iv(t) even if it never enters any equilibrium. For this purpose, we want
to seek some bounds for iv(t), no matter whether the system converges to an equilibrium or not. Such characterization
is useful because, for example, the upper bound can be used for the worst-case scenario decision-making. It is worth
mentioning that non-equilibrium states/behaviors are always hard to characterize.

Proposition 5 (bounds for non-equilibrium probabilities) Let limt→∞iv(t) and limt→∞iv(t) denote the upper and
lower limits of iv(t), v

V. Then,

∈

i−
v ≤

limt→∞iv(t)

limt→∞iv(t)

i+
v ,

≤

≤

16

where

i−
v = 


and



i+
v = 


1
−
β + 1

C(δCv (1

−
C(δCv (1

γν), 1

α)

−
γν), 1

−

−
γν), 1

α)

−
α)] (1

,

−

C(δCv (1

γν), 1

α)

−

≥

β,

−

µv) + 1

−

β, otherwise,

−

[β

−

C(δCv (1

−

C

1
−
β + 1

Cv
C
(cid:0)
(cid:0)
Cv

1
Cv
(cid:0)
1

γµv,1, . . . , 1

−
γµv,1, . . . , 1

−
1

−
γµv,1, . . . , 1

−
C

γµv,deg(v)

, 1

α

−
, 1

−
γµv,deg(v)

γµv,deg(v)
(cid:1)
(cid:1)
, 1
−

α
(cid:1)
−
α

(cid:1)
(1

−

β

−

(cid:0)
−

, C

Cv

1

(cid:0)
(cid:0)
i−
v ) + 1

−

−

−

γµv,1, . . . , 1

γµv,deg(v)

, 1

α

> β

−

−

β, otherwise

(cid:1)

(cid:1)


(cid:2)
with δCv (1

−

(cid:0)

(cid:0)

γν) = Cv(1

γν, . . . , 1

−

−

γν), µv = max

(cid:1)

(cid:1)(cid:3)
−

β, min

1
{

γdeg(v) + α, 1
{

}}

and ν = min

1
{

.
β, α
}

−

Proof By observing the monotonicity in Eq. (4), we note that iv(t)
Eq. (4) yields

≥

ν for all v

∈

V. Replacing iv,j (t) with ν in

If C (δCv (1

γν), 1

−

−

If C (δCv (1

−

γν), 1

α)

−
iv(t + 1)

≤

iv(t + 1)

(1

β)iv(t) + [1

C (δCv (1

−
≥
= [C (δCv (1

−
γν), 1

α)

γν), 1
β] iv(t) + 1

−

−

α)] (1
−
C (δCv (1

iv(t))

−
α) > β, by taking the lower limit on both sides we obtain

−

−

−

γν), 1

α) .

−

−

limt→∞iv(t + 1)

1
−
β + 1

≥

β, we have

C (δCv (1

−
C (δCv (1

−

γν), 1

−
γν), 1

−

α)

α)

−

.

[C (δCv (1

γν), 1

α)

β] µv + 1

≥
= [β

−

C(δCv (1

−

−
γν), 1

−
α)] (1

−

−

C (δCv (1
β.

−
µv) + 1

−

−

γν), 1

α)

−

−

Hence, limt→∞iv(t)

i−
v .

≥

For the upper bound, by applying Lemma 1 to Eq. (4) we have

iv(t + 1)

(1

≤
= (1

−

−
max

β)iv(t) + [1
−
β)iv(t) + min
1
{

−

γdeg(v) + α, 1
{
≤
By replacing iv,j with µv,j’s in Eq. (4) yields

β, min

}}

2
{

max

max

{

−
γdeg(v) + α, 1
(1
}
−
{
= µv.

γdeg(v)

α, 1

−
iv(t))

α

} −

] (1

1, 0
}

−

−

iv(t))

(15)

iv(t + 1)

≤
=

(1

−

β)iv(t) +
1
Cv

C

1

C

−
γµv,1, . . . , 1
(cid:0)

(cid:2)

−

(cid:2)
γµv,1, . . . , 1

(cid:0)
(cid:0)
γµv,deg(v)

−

, 1

Cv

−

1
γµv,deg(v)
(cid:0)
−
Cv
+1

C

−
> β, then
(cid:0)

γµv,1, . . . , 1

−
α

α

, 1

γµv,deg(v)
iv(t)
β
(cid:1)
(cid:1)(cid:3)
γµv,deg(v)

−

−
−
γµv,1, . . . , 1

(cid:1)

(cid:3)

−

(1

−

iv(t))

, 1

−

α

.

, 1

1
(cid:1)

−

(cid:0)

(cid:1)

(cid:1)

limt→∞

≤

1

(cid:1)
−
β + 1

C

−
, 1

−
1

γµv,1, . . . , 1

−
γµv,1, . . . , 1

−
β, then we have

γµv,deg(v)

, 1

γµv,deg(v)
(cid:1)

−

(cid:1)

−
, 1

α

α
(cid:1)
−

.

(cid:1)

If C

Cv

1

(cid:0)

(cid:0)

If C

Cv

1

−

−

α

−
Cv
C
(cid:0)

1
(cid:1)
Cv
(cid:0)

α
(cid:0)

−
Cv

(cid:0)
≤

−

γµv,1, . . . , 1

γµv,deg(v)

−

(cid:0)

limt→∞iv(t + 1)

(cid:0)

≤

≤

≤

limt→∞

(cid:1)
C

C

Cv

(cid:8)(cid:2)
1

−

(cid:2)

(cid:2)

(cid:0)

C

Cv

(cid:0)
1

−

(cid:0)

(cid:0)

(cid:1)
1

γµv,1, . . . , 1

(cid:0)
(cid:0)
γµv,1, . . . , 1

γµv,1, . . . , 1

−
+1

+1

−
+1

−
Cv
C
−
γµv,deg(v)
(cid:0)
(cid:0)
Cv
1
(cid:1)
−
γµv,deg(v)
(cid:0)
(cid:0)
Cv

C

C

1
(cid:1)

−

−
, 1

−
, 1

−

(cid:0)

(cid:0)

17

, 1

γµv,deg(v)
1

α
−
γµv,1, . . . , 1
(cid:1)

β

iv(t)
−
γµv,deg(v)
(cid:3)

(cid:1)
−

limt→∞iv(t)
γµv,deg(v)

α

β

(cid:3)

(cid:1)
α

−
−
γµv,1, . . . , 1
−
i−
v
−
−
γµv,1, . . . , 1

β

(cid:1)

(cid:3)

−

γµv,deg(v)

, 1

(cid:1)

, 1

α

−

(cid:1)(cid:9)

, 1

α

−

(cid:1)

(cid:1)

(cid:1)
α

.

(cid:1)

−

Hence, we have limt→∞iv(t + 1)

i+
v .

≤

When are the bounds tight?
upper bound i+
γ << 1, it holds that

It is important to know when the bounds are tight because the defender can use the
v for decision-making, especially when the spreading never enters any equilibrium. Note that when

−

(cid:0)
i−
v ≈

i+
v ≈

C(δCv (1

γν), 1

α)

−

≈

−

C(1, 1

−

α) = 1

α,

−

and

C

Cv

1

Therefore, in the case γ << 1 and α + β < 1, we have
(cid:1)
γν), 1

C(δCv (1

(cid:0)

γµv,1, . . . , 1

γµv,deg(v)

, 1

−

C (Cv (1, . . . , 1) , 1

α) = 1

α.

−

−

α

−

≈

(cid:1)

1
−
β + 1
1

−
β + 1

−
C

−
C(δCv (1
Cv
C
(cid:0)

1
Cv
(cid:0)

−
1

α) ≈

α)

−
γν), 1
−
γµv,1, . . . , 1

−

−
γµv,1, . . . , 1

,

α
β + α
γµv,deg(v)

γµv,deg(v)
(cid:1)

, 1

−
, 1

α

α
(cid:1)
−

α
β + α

.

≈

(cid:1)

(cid:1)

−
This means that the bounds are tight when the attack-power is not strong.

−

−

(cid:0)
In the case γ deg(v) << 1 and α + β
i−
v ≈

α(2

β),

−

α

≥

(cid:0)
1, we can similarly have
i+
v ≈

(β + α

1) [1

−
Therefore, the difference between the upper bound and lower bound is

−

−

α(2

α

−

−

β)] + 1

β.

−

Therefore, the bounds are tight when (α + β) is not far from 1 or α is close to zero.

i+
v −

i−
v ≈

α(α + β

1)2.

−

Are the equilibrium bounds always tighter than the non-equilibrium bounds? We observe the following: under
the condition γ deg(v) << 1, we have i∗−
α/(α+β); under the condition γ deg(v) << 1 and the condition
α + β < 1, we have i−
α/(α + β). This means that the equilibrium bounds are widely applicable than
the same non-equilibrium bounds, namely that the equilibrium bounds are strictly tighter than the non-equilibrium
bounds.

i∗+
v ≈

i+
v ≈

v ≈

≈

4 Side-Effects of Assuming Away the Dependences

In the above we have characterized epidemic equilibrium thresholds, equilibrium infection probabilities, and non-
equilibrium infection probabilities while accommodating arbitrary dependences. In order to characterize the side-
effects of assuming away the dependences, we consider the degree of dependences as captured by the concordance
order between copulas (reviewed in Section 2). In order to draw cyber security insights at a higher level of abstraction,
we also consider three kinds of qualitative dependences: positive dependence, independence and negative dependence,
whose degrees of dependence are in decreasing order. Speciﬁcally, positive (negative) dependence between the push-
based attacks means

deg(v)

Cv

1

1

−

−

γiv,1, . . . , 1

γiv,deg(v)

−

)1

(
≤

−

≥

(1

−

γiv,j) ,

and positive (negative) dependence between the push-based attacks and the pull-based attacks means

(cid:0)

1

C

Cv

1

γiv,1(t), . . . , 1

γiv,deg(v)(t)

, 1

α

(1

α)Cv

1

γiv,1(t), . . . , 1

γiv,deg(v)(t)

,

(cid:0)

(cid:0)

−

−

−

≥
where equality means independence. To simplify the notations, let pd stand for positive dependence, ind stand
for independence, and nd stand for negative dependence. Let x
denote the dependence structure
between the push-based attacks and the pull-based attacks, as captured by copula C. Let y
pd, ind, nd
denote the
dependence structure between the push-based attacks, as captured by copula Cv. Therefore, the dependence structures
can be represented by a pair (x, y).

pd, ind, nd

∈ {

∈ {

−

−

−

−

−

}

}

(cid:1)

(cid:0)

(cid:1)

(cid:1)

Yj=1

(cid:1)

)1

(
≤

18

4.1 Side-Effects on Equilibrium Infection Probabilities and Thresholds

v, v

For ﬁxed G = (V, E), α, β, γ, we compare the effects of two groups of dependences (i.e., copulas)
C ′, C ′
∈
{
probabilities of node v
under dependence structure (x, y).

and
C, Cv, v
{
v(t) the respective infection
v,x,y denote the equilibrium infection probability of node v, namely i∗
v,

. Corresponding to the two groups of copulas, we denote by iv(t) and i′
}

V at time t

0. Let i∗

≥

∈

V

V

∈

}

Side-effects on the equilibrium infection probabilities. We present a result about the impact of the dependence
structures on the equilibrium infection probabilities. This result will allow us to derive the side-effects of assuming
away the dependences.

Proposition 6 (comparison between the effects of different dependence structures on equilibrium infection probabil-

ities) Suppose the condition underlying Lemma 3 holds, namely ρ(A) <
equilibrium. If for all v

V, we have

∈

(β + α)2
γβ

so that system (4) has a unique

C

Cv

u1, . . . , udeg(v)

, u0

≤
(cid:1)
1 for j = 0, . . . , deg(v), then we have i∗

(cid:0)

(cid:0)

(cid:1)

(cid:0)
i′∗.

(cid:0)

(cid:1)

(cid:1)

C ′

C ′
v

u1, . . . , udeg(v)

, u0

,

(16)

where 0

uj ≤

≤

Proof Note that i∗ and i′∗ are respectively the unique positive solutions of f (i∗) = 0 and g(i′∗) = 0, where
f = (f1, . . . , fN ) and g = (g1, . . . , gN ) with

fv(i) =
gv(i) =

1

1

(cid:2)

−

−

C
C ′
(cid:0)

Cv
C ′
(cid:0)
v

1

−
1

γiv,1, . . . , 1
γiv,1, . . . , 1

−

−
−
g, we have g(i∗)

γiv,deg(v)
γiv,deg(v)
(cid:1)

, 1

, 1

−

α

(1

α
(cid:1)(cid:3)

(1

−

iv)
iv)

−

βiv, v
βiv, v

∈

V
V.

−

−
f (i∗) = 0. Since both f and g are continuous, we have

(cid:1)(cid:3)

−

∈

(cid:1)

Since f (0) = g(0) = α > 0 and f
i′∗

i∗.

(cid:0)

(cid:0)
≥

(cid:2)

∈ {

pd, ind, nd

i∗
v,ind,y ≥

i∗
v,nd,y for any y

≤
The cyber security insights/implications of Proposition 6 is: The stronger the negative (positive) dependences
between the attack events, the lower (higher) the equilibrium infection probabilities. More speciﬁcally, we have
and i∗
i∗
.
v,pd,y ≥
}
Therefore, the side-effects of assuming away the dependences between attack events are: If the positive (negative)
dependence is assumed away, the resulting equilibrium infection probability underestimates (overestimates) the actual
equilibrium infection probability. This means the following: when the positive dependence between attack events is
assumed away, the cyber defense decisions based on i∗
v,pd,pd) can render the deployed defense useless;
when the negative dependence is assumed away between attack events, the cyber defense decisions based on i∗
v,ind,ind
(> i∗
v,nd,nd) can waste defense resources. We will use numerical examples below to conﬁrm these insights. Another
important insight is: if the defender can seek to impose negative dependence on the cyber attacks, the cyber defense
effect is better of. We believe that this insight will shed light on research of future cyber defense mechanisms, and
highlights the value of theoretical studies in terms of their practical guidance.

i∗
v,x,nd for any x

v,ind,ind (< i∗

i∗
v,x,ind ≥

pd, ind, nd

v,x,pd ≥

∈ {

}

≥

≤

Side-effects on the epidemic equilibrium threshold. Corollary 1 gives a sufﬁcient condition under which the
epidemic spreading enters the equilibrium. Here we deﬁne

def
= min

τ

1

−

1
maxv∈V |
γ

β/(1

−

i∗
v)
|

,

−

(β + α)2
γβ

,

(17)

(cid:26)
. According to Eq. (8), ρ(A)
with respect to a group of copulas
C, Cv, v
}
{
converges to the equilibrium. Similarly, we can deﬁne τ ′ with respect to another group of copulas
We want to compare τ and τ ′ with respect to the relation between

τ means that the epidemic spreading
.
}

v, v

and

≤

(cid:27)

∈

V

V

V

∈

C, Cv, v
{

∈

}

C ′, C ′
{

v, v

∈

C ′, C ′
{
V
.
}

19

Proposition 7 Under the conditions of Proposition 6, namely ρ(A) <

equilibrium and C

Cv

u1, . . . , udeg(v)
τ ′;

, u0

≤

C ′

C ′
v

(cid:1)

(cid:1)

(cid:0)

(cid:0)

i∗−, then τ
(cid:0)
(cid:0)

u1, . . . , udeg(v)

, u0

for all v

V, we have

∈

(cid:1)

(cid:1)

(β + α)2
γβ

so that system (4) has a unique

(i) if 1

β

−

≤

i∗+, then τ

(ii) if 1

β

−
where i∗+ def
= maxv∈V i∗+

≥

≤

τ ′,

≥

v , i∗− and i∗+

v are deﬁned in Proposition 1.

β

i∗
v ≤

Proof According to Proposition 1, we know that i∗−
to Eq. (17), τ is decreasing in maxv∈V |
1
in i∗
≥

β
1−i∗
v |
i∗+. By Proposition 6, we get the desired results.

i∗+, which implies
. Therefore, τ is decreasing in i∗

v when 1
In order to draw insights while simplifying the discussion, let τx,y denote the τ as deﬁned in Eq. (17) with respect
to dependence structures (x, y). The cyber security implication of Proposition 7 is: First, under some circumstances,
the stronger the dependences between the cyber attacks, the more restrictive the epidemic equilibrium threshold. More
speciﬁcally, under the condition 1

1−i∗+ . According
i∗−, and increasing

β
1−i∗−
≤
v when 1

i∗−, we have for all v

β
1−i∗
β

v ≤

V:

≤

≤

−

−

−

β

β

≤

−
τnd,y

τind,y

≥

≥

∈
τpd,y and τx,nd

τx,ind

≥

≥

τx,pd.

This means that under the above circumstances, assuming away the positive dependences between the attacks will
lead to incorrect epidemic equilibrium threshold, and assuming away the negative dependences between the make the
epidemic equilibrium threshold unnecessarily restrictive. This further highlights the value for the defender to render
the dependences negative, provided that 1

i∗−.

β

Second, under certain other circumstances, the stronger the dependences, the less restrictive the epidemic equilib-
β

rium threshold. More speciﬁcally, under the condition 1

i∗+, we have

−

≤

τnd,y

≤

τind,y

≤

τx,ind

≤

≤

τx,pd.

≥

−
τpd,y and τx,nd

This means that assuming away the negative dependences between the attacks will lead to incorrect epidemic equi-
librium threshold, and assuming away the positive dependences will make the epidemic equilibrium threshold un-
necessarily restrictive. Moreover, while rendering the dependences negative can lead to smaller equilibrium infection
i∗+. This means that when
probabilities, it imposes a very restrictive epidemic equilibrium threshold when 1
applying the above insights to guide practice, the defender must be aware of the parameter regions corresponding to
the cyber security posture.

≥

−

β

Numerical examples.
In order to illustrate the above analytic results, we consider the example of star network with
N = 11 nodes. We assume that the dependence between the push-based and the pull-based attacks can be captured
by the Gaussian copula C with parameter σ and the dependence between the push-based attacks launched from the
leaves against the hub can be captured by copula Cv, which is the Clayton copula with parameter θ. These two
copulas are reviewed in Section 2. We consider two sets of parameters (α, β, γ) = (0.2, 0.5, 0.05) and (α, β, γ) =
(0.4, 0.7, 0.05). From Eqs. (11) and (12), we can compute the equilibrium infection probabilities i∗
h for the hub and
i∗
l for the leaves, and the threshold τ as deﬁned in (17). Note that the copulas are increasing in their parameters in
the concordance order. By Proposition 6, both i∗
l are decreasing in θ (σ) given σ (θ), as conﬁrmed by Tables
i∗+
h , where
1-2. Note that for star networks, the condition 1
−
i∗+
i∗+
h , meaning that τ
h is deﬁned in Proposition 3. When (α, β, γ) = (0.2, 0.5, 0.05), it is easy to verify 1
is decreasing in θ (σ) for ﬁxed σ (θ). This is conﬁrmed in Table 1. When (α, β, γ) = (0.4, 0.7, 0.05), the condition
i∗− in Proposition 7 is satisﬁed, meaning that τ is increasing in θ (σ) for ﬁxed σ (θ). This is conﬁrmed in
1
Table 2. These examples also conﬁrm the conclusion i∗

i∗+ in Proposition 7 can be relaxed as 1

h and i∗
β
≥
−

i∗
l given by Proposition 2.

≥

−

≥

≤

−

β

β

β

h ≥

20

σ =
i∗
h
.40
.40
.39
.39
.39
.39
.39
.38
.38
.38
.38

0.5 (pd)
−
i∗
τ
l
14.40
.31
14.39
.31
14.39
.31
14.39
.31
14.39
.30
14.38
.30
14.38
.30
14.38
.30
14.38
.30
14.38
.30
14.38
.30

σ =
i∗
h
.44
.43
.43
.43
.43
.43
.43
.42
.42
.42
.42

0.5 (pd)
−
i∗
τ
l
15.20
.38
15.29
.38
15.36
.38
15.43
.38
15.50
.38
15.56
.38
15.62
.38
15.67
.38
15.72
.38
15.77
.38
15.81
.38

θ

1.0
1.5
2.0
2.5
3.0
3.5
4.0
4.5
5.0
5.5
6.0

θ

1.0
1.5
2.0
2.5
3.0
3.5
4.0
4.5
5.0
5.5
6.0

σ = 0.5 (nd)
i∗
τ
l
14.11
.29
14.11
.29
14.11
.29
14.11
.29
14.11
.29
14.11
.29
14.11
.29
14.11
.29
14.11
.29
14.11
.29
14.11
.29

i∗
h
.35
.35
.35
.34
.34
.34
.34
.34
.34
.34
.33

σ = 0 (ind)
i∗
τ
l
14.31
.30
14.30
.30
14.30
.30
14.30
.30
14.30
.30
14.30
.30
14.30
.30
14.29
.30
14.29
.30
14.29
.30
14.29
.30

i∗
h
.38
.38
.38
.38
.37
.37
.37
.37
.37
.37
.36

Table 1: (α, β, γ) = (0.2, 0.5, 0.05)
σ = 0.5 (nd)
i∗
τ
l
17.11
.37
17.15
.37
17.18
.37
17.21
.37
17.24
.37
17.27
.37
17.30
.37
17.31
.37
17.33
.37
17.35
.37
17.37
.37

σ = 0 (ind)
i∗
τ
l
16.09
.37
16.16
.37
16.21
.37
16.26
.37
16.31
.37
16.35
.37
16.39
.37
16.43
.37
16.47
.37
16.50
.37
16.53
.37

i∗
h
.41
.41
.41
.41
.41
.41
.41
.41
.41
.40
.40

i∗
h
.39
.39
.39
.39
.38
.38
.38
.38
.38
.38
.38

Table 2: (α, β, γ) = (0.4, 0.7, 0.05)

21

∈

β

β

4.2 Side-Effects on the Non-Equilibrium Infection Probabilities

We now investigate the side-effects on the non-equilibrium infection probabilities i(t) = (i1(t), . . . , iN (t)), no matter
whether the epidemic spreading converges to equilibrium or not.

Proposition 8 (side-effects on the non-equilibrium infection probabilities) Consider two vectors of infection prob-
abilities i(t0)
, where
Deg = maxv∈V deg(v). If condition (16) holds and

i′(t0) at some time t0 ≥

0. Let µ = maxv∈V µv = max

α + γDeg, 1
{

β, min

1
{

}}

−

≥

min
v∈V {

C (δCv (1

γµ) , 1

α)

−

} ≥

β,

−

(18)

then i(t)

≥

i′(t) for all t

t0.

≥

Proof We need to show that i(t + 1)

iv(t + 1) =
i′
v(t + 1) =

(cid:2)

C
C ′
(cid:0)

Cv
C ′
(cid:0)
v
(cid:16)

1

(cid:16)

−
1

−

h

i′(t + 1) when i(t)

i′(t) is given. Note that

≥
γiv,1(t), . . . , 1
γi′

−
v,1(t), . . . , 1

≥
γiv,deg(v)(t)
γi′

, 1

−
, 1

α

β

−

(iv(t)
(i′

−
v(t)

1) + 1

−
1) + 1

−

β,

β.

−

β
(cid:3)
−

−

v,deg(v)(t)
(cid:1)
−
(cid:17)
(cid:17)
µ for all v

α
(cid:1)

i

V. Then, conditions (16) and (18)

According to Ineq. (15) in the proof of Proposition 5, we have iv(t)
imply

≤

Since i(t)

≥
iv(t + 1)

C
C ′
i′(t), we have

Cv
C ′
v

1

1
(cid:0)

−

−

(cid:0)

(cid:0)

(cid:0)

γiv,1(t), . . . , 1
γiv,1(t), . . . , 1

γiv,deg(v)(t)
γiv,deg(v)(t)
(cid:1)

, 1

, 1

−

−

(cid:1)

−

−

α

α
(cid:1)

(cid:1)

−

−

0,

0.

≥

≥

≥

≥

(cid:2)

C
C ′
(cid:0)
C ′

Cv
C ′
(cid:0)
v
C ′
v

1

γiv,1(t), . . . , 1
γiv,1(t), . . . , 1
γi′

v,1(t), . . . , 1

−

−

−
1

−
1

(cid:0)

(cid:0)

(cid:2)
≥
= i′
(cid:16)
(cid:16)
h
v(t + 1).

−

, 1

, 1

γiv,deg(v)(t)
γiv,deg(v)(t)
(cid:1)
γi′
v,deg(v)(t)
(cid:1)
(cid:17)

−

α

α
(cid:1)

−

−

β

β
(cid:3)

−

−

, 1

−

α
(cid:1)

(cid:17)

−

i

−

(i′
v(t)
(i′
v(t)
(i′

−
v(t)

β
(cid:3)

1) + 1

−

β

β

1) + 1

−
1) + 1

−

β

−

Since the above holds for all v

∈

V, we obtain the desired result.

t = 6
i′
v(t)
0.60
0.63
0.57
0.57
0.47
0.60

iv(t)
0.61
0.64
0.56
0.57
0.46
0.60

t = 7
i′
v(t)
0.42
0.40
0.45
0.45
0.53
0.42

iv(t)
0.42
0.39
0.46
0.45
0.54
0.42

t = 8
i′
v(t)
0.56
0.58
0.54
0.54
0.48
0.56

iv(t)
0.57
0.60
0.54
0.55
0.47
0.56

v = 1
2
3
4
5
6

Figure 5: Clayton copulas with (θ, η) = (1, 1.5), (θ, η) = (10, 15), (α, β, γ) = (0.9, 0.9, 0.8).

One may wonder if a more succinct result than Proposition 8 could be obtained by, for example, eliminating
condition (18). Here we use an example to show that if we eliminate condition (18), then Proposition 8 may not
V are
hold. Speciﬁcally, consider the network with six nodes illustrated in Figure 5. Suppose C and the Cv’s for v
Clayton copulas with positive parameters θ and η, namely

∈

C(u1, u2) =

u−θ
1 + u−θ

2 −

h

−1/θ

1

i

and Cv

u1, . . . , udeg(v)

=

(cid:0)

22

(cid:1)

deg(v)





Xi=1

−η
u
i −

deg(v) + 1



−1/η

.



Consider two groups of Clayton copulas respectively with parameters (θ, η) = (1, 1.5) and (θ, η) = (10, 15). Denote
the corresponding infection probabilities by iv(t) and i′
v(t), respectively. Set (α, β, γ) = (0.9, 0.9, 0.8), and in this
case condition (18) is not satisﬁed. Set the initial infection probabilities as i(0) = i′(0) = (0.2, 0.1, 0.3, 0.3, 0.6, 0.2).
The table in Figure 5 shows i(t) and i′(t) for t = 6, 7, 8, from which we observe that i(t)
i′(t) does not hold. This
means that we cannot eliminate condition (18) in Proposition 8.

≥

5 Conclusions

We have presented the ﬁrst systematic investigation of cyber epidemic models with dependences. We have derived
epidemic equilibrium thresholds, bounds for equilibrium infection probabilities, and bounds for non-equilibrium in-
fection probabilities, while accommodating arbitrary dependences between the push-based attacks and the pull-based
attacks as well as the dependences between the push-based attacks. In particular, we showed that assuming away the
due dependences can render the results thereof unnecessarily restrictive or even incorrect.

Our study brings up a range of interesting research problems for further work. First, our characterization study
assumes that the dependence or copula structures are given. It is important to know which dependence structures are
more relevant than the others in practice. Second, it is ideal to obtain closed-form results on the equilibrium infection
probabilities and the non-equilibrium infection probabilities. Third, if we cannot derive closed-form results for the
(non-)equilibrium infection probabilities, it is important to seek bounds for these probabilities and systematically
analyze their tightness.
Acknowledgement. This work was supported in part by ARO Grants # W911NF-12-1-0286 and # W911NF-13-1-
0141, and by AFOSR Grant # FA9550-09-1-0165.

References

[1] D. Chakrabarti, Y. Wang, C. Wang, J. Leskovec, and C. Faloutsos. Epidemic thresholds in real networks. ACM

Trans. Inf. Syst. Secur. 10 (4), 1-26, 2008.

[2] F. Chung, L. Lu and V. Vu. Eigenvalues of random power law graphs. Annals of Combinatorics, 7, 21-33, 2003.

[3] U. Cherubini, E. Luciano, and W. Vecchiato. Copula methods in ﬁnance. New York: Wiley, 2004.

[4] D. Cvetkovic, P. Rowlingson, and S. Simic. An introduction to the theory of graph spectra. Cambridge University

Press, UK, 2010.

[5] G. Da, M. Xu, and S. Xu. A New Approach to Modeling and Analyzing Security of Networked Systems. Proc. 2014

Symposium and Bootcamp on the Science of Security (HotSoS’14), to appear.

[6] A. Ganesh, L. Massoulie, and D. Towsley. The effect of network topology on the spread of epidemics. In Proceed-

ings of IEEE Infocom, 2005.

[7] A. Granas and J. Dugundji. Fixed Point Theory. Springer-Verlag, New York, 2003.

[8] H. Joe. Multivariate models and dependence concepts. Monographs on Statistics and Applied Probability, vol.

73. Chapman & Hall, London, 1997.

[9] J. Kephart and S. White. Directed-graph epidemiological models of computer viruses. IEEE Symposium on Se-

curity and Privacy, pages 343–361, 1991.

[10] W. Kermack and A. McKendrick. A contribution to the mathematical theory of epidemics. Proc. of Roy. Soc.

Lond. A, 115:700–721, 1927.

[11] X. Li, T. Parker, and S. Xu. A Stochastic Model for Quantitative Security Analysis of Networked Systems. IEEE

Transactions on Dependable and Secure Computing, 8(1): 28-43, 2011.

23

[12] C. R. MacCluer. The Many Proofs and Applications of Perron’s Theorem. SIAM Review, 42, 487-498, 2000.

[13] A. McKendrick. Applications of mathematics to medical problems. Proc. of Edin. Math. Soceity, 14:98–130,

1926.

[14] A.J. McNeila and J. Ne˘slehov´a. Multivariate Archimedean copulas, d-monotone functions and l1-norm symmet-

ric distributions. Annals of Statistics, 37, 3059-3097, 2009.

[15] R. B. Nelsen. An introduction to copulas, second ed. Springer Series in Statistics. Springer, New York, 2006.

[16] P. Van Mieghem, J. Omic and Kooij, R. Virus Spread in Networks. IEEE/ACM Transactions on Networking,

17(1), pp 1-14, 2009.

[17] Y. Wang, D. Chakrabarti, C. Wang, and C. Faloutsos. Epidemic spreading in real networks: An eigenvalue
viewpoint. Proc. of the 22nd IEEE Symposium on Reliable Distributed Systems (SRDS’03), pages 25–34, 2003.

[18] M. Xu and S. Xu. An Extended Stochastic Model for Quantitative Security Analysis of Networked Systems.

Internet Mathematics, (8)3, 288-320, 2012.

[19] S. Xu, W. Lu, and L. Xu. Push- and Pull-based Epidemic Spreading in Networks: Thresholds and Deeper

Insights. ACM Transactions on Autonomous and Adaptive Systems (ACM TAAS), 7(3):32. 2012.

[20] S. Xu, W. Lu, and Z. Zhan, A stochastic model of multivirus dynamics, IEEE Trans. Dependable Sec. Comput.,

vol. 9, no. 1, pp. 30–45, 2012.

24

