1
2
0
2

n
u
J

3
1

]

R
C
.
s
c
[

1
v
4
7
0
7
0
.
6
0
1
2
:
v
i
X
r
a

RadArnomaly: Protecting Radar Systems from Data
Manipulation Attacks

Shai Cohen, Efrat Levy,
Yuval Elovici, Asaf Shabtai
Department of Software and Information Systems
Engineering, Ben-Gurion University of the Negev, Israel

ABSTRACT
Radar systems are mainly used for tracking aircraft, missiles, satel-
lites, and watercraft. In many cases, information regarding the
objects detected by the radar system is sent to, and used by, a pe-
ripheral consuming system, such as a missile system or a graphical
user interface used by an operator. Those systems process the data
stream and make real-time, operational decisions based on the data
received. Given this, the reliability and availability of information
provided by radar systems has grown in importance. Although the
field of cyber security has been continuously evolving, no prior
research has focused on anomaly detection in radar systems. In
this paper, we present a deep learning-based method for detecting
anomalies in radar system data streams. We propose a novel tech-
nique which learns the correlation between numerical features and
an embedding representation of categorical features in an unsuper-
vised manner. The proposed technique, which allows the detection
of malicious manipulation of critical fields in the data stream, is
complemented by a timing-interval anomaly detection mechanism
proposed for the detection of message dropping attempts. Real
radar system data is used to evaluate the proposed method. Our
experiments demonstrate the methodâ€™s high detection accuracy on
a variety of data stream manipulation attacks (average detection
rate of 88% with 1.59% false alarms) and message dropping attacks
(average detection rate of 92% with 2.2% false alarms).

CCS CONCEPTS
â€¢ Security and privacy â†’ Intrusion detection systems; â€¢ Com-
puting methodologies â†’ Neural networks.

KEYWORDS
Radar system, Anomaly detection, Deep learning.

1 INTRODUCTION
Radar systems use electromagnetic radiation to detect objects within
a defined scanned area [15]; they can also be used to classify the
detected objects. Radar systems are mainly integrated in air and
terrestrial traffic control systems, autonomous vehicles, air defense
systems, anti-missile systems, aircraft anti-collision systems, and
ocean surveillance systems.

Typically, radar system architecture consists of the following ba-
sic components: (1) an antenna - responsible for transmitting/receiving
electromagnetic waves to/from the scanned area, and (2) a radar
controller - responsible for analyzing the waves received from the
antenna in order to determine the properties of the object.

Usually, the radar controller is connected to a centralized switch
which controls the routing of the radar systemâ€™s messages. In many

Tair Cohen, Avi Shaked
IAI ELTA Systems Cyber DIvision, Israel

cases, the switch can be used to communicate with external entities,
i.e., other systems. Often, information regarding the objects detected
by the radar system is sent to, and used by, a peripheral consuming
system, such as a missile system or a graphical user interface used
by an operator [1]. Those systems process the data stream and make
real-time, operational decisions based upon the data received.

In recent years, as technology has evolved, the use of radar sys-
tems has increased, along with reliance on their correct and reliable
operation. Radar systems often include an extended set of compo-
nents, such as communication systems or SCADA systems, which
are vulnerable to cyber and physical attacks. These components
can be exploited by attackers in order to compromise the radar
system [7]. In addition, in many cases, radar systems are integrated
within systems that are vulnerable to cyber attacks, such as au-
tonomous vessels [4] and smart vehicles [12]. These vulnerabilities
could be used by an attacker as a backdoor for an attack on the
radar system.

Despite the many potential attack vectors, there has been no
research performed that has suggested or evaluated a method for
detecting cyber attacks on radar systems in real time. In this study,
we address this gap. We propose a deep learning-based method for
detecting anomalies in critical parts of the data stream generated
by the radar controller and consider attack scenarios in which the
attacker manipulates the data being transferred by the radar system
to peripheral consuming systems. Such manipulation can occur in
motion or in use. The proposed method simply requires the ability
to monitor the messages sent by the radar controller, and thus it
can be easily and safely integrated into existing systems without
the need to change the system. Our proposed method is designed
to deal with the particular data comprising the radar data stream;
unlike many other domains, radar data streams are made up of
sequential and heterogeneous data.

In order to evaluate the proposed method, we used data collected
from four real radar systems. We collected legitimate data streams
into which we injected a variety of artificial attacks, including
manipulations with high impact on the system (integrity violation
and denial of service), to assess our methodâ€™s performance. The
results of our evaluation show that our proposed method can detect
90% of message dropping attacks, with a false positive rate of 2%,
and from 76% to 96% of feature manipulation attacks, with a false
positive rate of 2%. These results are obtained in a cross-session
experiment in which the model is trained on data collected from
three radar systems and tested on data collected from another radar
system, thus demonstrating the ability to migrate a pretrained
model to new radar systems without retraining.

We summarize the main contributions of this study as follows:

 
 
 
 
 
 
â€¢ We present a novel deep learning-based method, which con-
sists of two modules, to detect anomalies in critical parts of
the heterogeneous data stream generated by radar systems.
â€¢ The proposed model represents both numerical and categor-
ical features in an architecture that can be utilized in other
similar domains.

â€¢ The proposed method can be integrated into existing radar
systems, without changing the radar systemâ€™s existing com-
ponents and without retraining the model.

â€¢ The structure of the proposed method enables it to identify
the anomaly type detected, determine whether a legitimate
message is missing from a sequence of messages, and un-
derstand whether a feature of an existing message has been
manipulated.

â€¢ The effectiveness of the proposed method is demonstrated in
experiments using a dataset collected from real operational
radar systems and simulated attacks.

2 BACKGROUND ON RADAR SYSTEMS
A radar system uses radio waves to determine both the location
of an object relative to the system and the distance between the
object and the system. It operates by transmitting electromagnetic
signals toward a certain direction and monitoring the signals that
are reflected back from the objects. The reflected signals are then
sent to a signal processor which analyzes the signals, aiming to
extract the properties of the objects [1].

Antenna. The antenna transforms the electric current into elec-
tromagnetic waves and vice versa (transmission and reception,
respectively). Usually, one bidirectional antenna is used, however
radar systems with two separate antennas (a transmitting antenna
and a receiving antenna) also exist.
Radar Controller. The radar controller consists of two main com-
ponents: (1) a signal processor, which receives the signals from the
antenna (usually via an optical link) and analyzes the signal using a
signal processing algorithm aimed at identifying potential relevant
objects, and (2) a tracking algorithm, which analyzes the signal
processorâ€™s output, with the aim of classifying objects and tracking
movement.
Control System. The control system is responsible for analyzing
radar yields and activating the different systems connected to the
radar system, for example, activating a weapon system to neutralize
a detected threat.
Radar System Network. The radar system network is used as
a communication channel between the radar controller and the
control system.

2.2 Data Stream Description
The radar system (radar controller) continuously sends a stream of
messages to peripheral consuming systems. The consuming systems
process the data stream and make real-time, operational decisions
based on the data received. Each message contains a Plot record.
This record describes a detected object at a given time.

Since the radar system continuously scans the defined area, sev-
eral ğ‘ƒğ‘™ğ‘œğ‘¡ğ‘  may relate to the same object, describing its properties
at different points in time. A sequence of ğ‘ƒğ‘™ğ‘œğ‘¡ğ‘  related to the same
object is defined as a ğ‘‡ ğ‘Ÿğ‘ğ‘ğ‘˜. Each ğ‘ƒğ‘™ğ‘œğ‘¡ may be correlated with
other ğ‘ƒğ‘™ğ‘œğ‘¡s (e.g., when they are part of an identified ğ‘‡ğ‘Ÿğ‘ğ‘ğ‘˜). Each
ğ‘‡ ğ‘Ÿğ‘ğ‘ğ‘˜ is associated with an identification number (referred to as
the TrackID). Thus, the TrackID is a part of each individual ğ‘ƒğ‘™ğ‘œğ‘¡
record. Figure 2 illustrates a set of ğ‘ƒğ‘™ğ‘œğ‘¡ğ‘  (the individual points) and
a ğ‘‡ ğ‘Ÿğ‘ğ‘ğ‘˜ (the sequence of connected plots).

Figure 1: An example of a typical radar system architecture.
The red circles indicate our assumed adversary locations.
Our proposed anomaly detection method is located at the
link between the radar system and the consuming systems.

Figure 2: Objects identified at a specific timestamp are rep-
resented by points. A sequence of points related to the same
detected object are represented by a path of interconnected
points (i.e., Track).

2.1 System Components
A typical radar system architecture includes the following compo-
nents (presented in Figure 1):

Each ğ‘ƒğ‘™ğ‘œğ‘¡ record contains the following attributes:

â€¢ Metadata. Contains the source ID (unique identifier of the
sending radar system), message ID, message length, etc.

2

â€¢ Identified objectâ€™s properties. Categorical and numerical
attributes that describe the identified object, such as the de-
tected objectâ€™s location and speed, object type (e.g., airplane,
bird), etc.

â€¢ Sequence-related properties. Describe different proper-
ties of the ğ‘ƒğ‘™ğ‘œğ‘¡ record as part of a sequence of plots related
to the same object. One property is the identification num-
ber of the ğ‘‡ğ‘Ÿğ‘ğ‘ğ‘˜ that a ğ‘ƒğ‘™ğ‘œğ‘¡ belongs to. Another property is
the timestamp indicating when a ğ‘ƒğ‘™ğ‘œğ‘¡ has been updated on
the system; this property describes the delay between the
previous ğ‘ƒğ‘™ğ‘œğ‘¡ and the current ğ‘ƒğ‘™ğ‘œğ‘¡.

3 ASSUMED THREAT MODEL
Although radar systems are vulnerable to a variety of threats [7],
most prior research performed on radar systems has focused on
aspects of functionality [2, 3]. In this study, we consider attack sce-
narios in which an attacker manipulates the data being transferred
by the radar system to peripheral consuming systems. Such manip-
ulation may occur in motion or in use. Specifically, as illustrated
in Figure 1, the adversary locations (points of manipulation) con-
sidered in this study are the radar controller and the radar system
network. Those can be compromised with physical or remote ac-
cess, or through a supply chain attack (i.e., before the radar systemâ€™s
deployment).

Once the radar controller has been compromised by the attacker
(whether remotely or through a supply chain attack), he/she can
execute malicious commands that manipulate the data while it is
being processed, prior to its transmission from the radar controller.
With physical access to the radar system network, the attacker
can replace a networking device (e.g., switch) with a malicious
networking device that manipulates the data in motion. The effects
of such tampering attempts are expected to be covert and, more
specifically, to be â€œunder the radar" of radar operators (i.e., radar
operators should not be able to identify the tampering).

Based on the specified threat model, we suggest an anomaly
detection method that (1) detects abnormal data behavior indicative
of such malicious activity, and (2) can be implemented as a detector
at the link between the radar system network and the control sys-
tem, to provide anomaly-related insights to radar operators and/or
systems that consume the radar data.

4 RELATED WORK
Most studies that used machine learning techniques to protect
radar systems from attacks focused on protecting the systems from
jamming attacks. Some studies proposed jamming classification
methods [10, 17, 20, 22], while others proposed jamming mitigation
strategies [11, 14]. In addition, a comprehensive survey discussing
all of these methods in detail was published [13]. In other related
research, machine learning techniques were used to protect the
systems generally integrated within radar systems, like the ADS-
B [8, 23] and AIS systems [19]. To the best of our knowledge, no
study has proposed a method for detecting anomalies in radar
system data streams.

In recent years, deep learning models have increasingly been
used to analyze network traffic and detect anomalies. Most of the
methods proposed are based on autoencoders and their variants [6].

3

An autoencoder (AE) is an unsupervised algorithm that compresses
input into a lower dimensionality and then decompresses the input
into its original dimensionality; thus, normal instances are decom-
presses properly, while the abnormal instances are not. In this way,
anomalous input can be identified. Some examples of methods based
on AEs include N-BIoT [16], which uses an AE to detect botnet
behavior in the network traffic of IoT devices, and Kitsune [18],
which utilizes a smart feature mapper and an ensemble of AEs to
detect anomalous behavior in network traffic.

LSTM-based networks are also widely used to detect anomalies
in network traffic; these deep learning networks are very well suited
for sequential data. In this type of network, instead of processing
the whole sequence together, the network processes each object
in the sequence separately, in chronological order. So in each step,
the networkâ€™s inputs are: (1) the current object in the sequence,
along with (2) the output of the network from the previous step.
An example of using an LSTM-based network was presented by
Bontemps et al. [5] who predicted anomalies in the network data
stream by using the sample, as well as the context of the sample.

Previous studies that used deep learning models to detect anom-
alies in network traffic relied strictly on numerical features. How-
ever, in this study, we take into consideration the fact that the data
stream created by the radar system is heterogeneous, i.e., it contains
both numerical and categorical features. Since manipulating both
types of features may significantly violate the integrity and avail-
ability of radar systems, there is a need for a deep learning method
that can detect anomalies in heterogeneous data. Our proposed
method is designed to detect attack scenarios that are valuable
specially for radar systems. Thus, our proposed method focuses on
real threats while reducing false alarms.

5 HIGH-LEVEL DESCRIPTION OF THE

PROPOSED METHOD

We propose an unsupervised anomaly detection method which
is based on continuous monitoring of the messages transmitted
from the radar to the peripheral consuming systems. Our proposed
method utilizes state-of-the-art deep learning modules to detect
possible malicious data manipulation.

5.1 Description of the Proposed Method
The proposed anomaly detection method (see Figure 3) consists
of two main modules: (1) a Field Manipulation Detection module,
and (2) a Timing-Based Anomaly Detection module. Each module
outputs an anomaly score, and an alert is generated if the score
exceeds a predefined threshold.

Field Manipulation Detection. For each ğ‘‡ ğ‘Ÿğ‘ğ‘ğ‘˜, the Field Ma-
nipulation Detection module receives the categorical and numerical
features of a ğ‘ƒğ‘™ğ‘œğ‘¡. First, it determines if the relation between the
featuresâ€™ values is anomalous. If so, an anomaly score for the ğ‘ƒğ‘™ğ‘œğ‘¡
is generated. An anomalous relation between the values of a ğ‘ƒğ‘™ğ‘œğ‘¡â€™s
features indicates that a malicious change has been made, aimed
at violating the radar systemâ€™s integrity. Such manipulations may
cause the consuming systems or radar operators to incorrectly
characterize and handle the detected objects.

Finally, to increase the sensitivity of the detection method to
malicious manipulation attacks, an alert is generated if the scoresâ€™

average exceeds a certain threshold. The latter step aims to detect
anomalies that are harder to detect by analyzing a single ğ‘ƒğ‘™ğ‘œğ‘¡.

Timing-Based Anomaly Detection. The Timing-Based Anom-
aly Detection module receives the last ğ¾ inspected ğ‘ƒğ‘™ğ‘œğ‘¡s and the
current ğ‘ƒğ‘™ğ‘œğ‘¡ associated with the same ğ‘‡ğ‘Ÿğ‘ğ‘ğ‘˜, and determines if the
time difference between the current ğ‘ƒğ‘™ğ‘œğ‘¡ and the previous ğ‘ƒğ‘™ğ‘œğ‘¡ is
anomalous. An anomalous time difference between ğ‘ƒğ‘™ğ‘œğ‘¡s indicates
malicious ğ‘ƒğ‘™ğ‘œğ‘¡ dropping or injecting events. Such activities may
enable an object to evade detection by the detection system or cause
a denial of service.

Figure 3: High-level architecture of the proposed anomaly
detection method.

5.2 Design Considerations
The following considerations were taken into account in the design
of the proposed method:
(1) Analysis of heterogeneous data. As mentioned in Section 2.2,
the ğ‘ƒğ‘™ğ‘œğ‘¡ records consist of numerical and categorical features. Ma-
chine learning-based models usually cannot be applied directly
to heterogeneous features, so there is a need to transform those
features before applying a model.
(2) Immediate detection. Often, radar systems are integrated
within real-time decision-making systems. This requires a detection
method capable of making a quick and accurate prediction, while
keeping the false alarm rate as low as possible.
(3) Processing sequential (stream) data. As mentioned in Sec-
tion 2.2, each ğ‘ƒğ‘™ğ‘œğ‘¡ may be correlated with other ğ‘ƒğ‘™ğ‘œğ‘¡s (e.g., when
they are part of an identified ğ‘‡ğ‘Ÿğ‘ğ‘ğ‘˜). Therefore, in addition to cap-
turing and learning patterns among features of the same ğ‘ƒğ‘™ğ‘œğ‘¡ record,
the model should be able to learn patterns within a sequence of
ğ‘ƒğ‘™ğ‘œğ‘¡s.
(4) Explaining anomalies. Understanding which part of the data
is anomalous can help the system operator perform the correct
action. If the method has the ability to identify the packets/features
that contribute the most to an anomaly, it can improve the sys-
tem operatorsâ€™ decision-making capabilities. The structure of the
proposed method enables it to identify the anomaly type detected,
determine whether a legitimate message is missing from a sequence
of messages, and understand whether a feature of an existing mes-
sage has been manipulated.

4

5.3 Extracted Features
As described in Section 2.2, each ğ‘ƒğ‘™ğ‘œğ‘¡ record contains a variety
of features. In our dataset, the ğ‘ƒğ‘™ğ‘œğ‘¡ record includes 10 categorical
features and 18 numerical features, all with high potential of being
exploited by an attacker interested in disrupting the radar systemâ€™s
normal operation.
Categorical features. Five of the categorical features describe the
returned signalâ€™s physical properties. The other five are: (1) track-
Type - specifies the ğ‘‡ ğ‘Ÿğ‘ğ‘ğ‘˜ type, (2) signalQuality - specifies the
quality of the returned signal, (3) objectType - specifies the type of
object detected, (4) alertRaised - specifies whether an alert has been
raised on the system, and (5) objectCategory - specifies whether
the object is considered hostile.
Numerical features. One numerical feature is the timestamp in-
dicating when a ğ‘ƒğ‘™ğ‘œğ‘¡ has been updated on the system. The other 17
numerical features ğ‘›ğ‘¢ğ‘š1, ğ‘›ğ‘¢ğ‘š2, ..., ğ‘›ğ‘¢ğ‘š17 relate to the correlations
between a detected objectâ€™s locations.

Note that due to privacy concerns, a more detailed description of
the features in the dataset used in this research cannot be provided.

6 PROPOSED METHOD
In this section, we provide a detailed description of each component
of the proposed method.

6.1 Field Manipulation Detection
As illustrated in Figure 3, this module consists of the following two
computational components: (1) the ğ‘ƒğ‘™ğ‘œğ‘¡-Level Anomaly Detector,
and (2) the ğ‘‡ ğ‘Ÿğ‘ğ‘ğ‘˜-Level Anomaly Detector. As mentioned earlier,
the ğ‘ƒğ‘™ğ‘œğ‘¡-Level Anomaly Detector generates an anomaly score for
each ğ‘ƒğ‘™ğ‘œğ‘¡ independently, while the ğ‘‡ ğ‘Ÿğ‘ğ‘ğ‘˜-Level Anomaly Detector
aggregates the anomaly scores of the ğ‘ƒğ‘™ğ‘œğ‘¡s and generates an alert
if the value computed exceeds a certain threshold.

Plot-Level Anomaly Detector. This module focuses on detect-
ing an anomaly within a single ğ‘ƒğ‘™ğ‘œğ‘¡. The ğ‘ƒğ‘™ğ‘œğ‘¡ features used by this
module are described in Section 5.3. In order to detect an anomaly
within a given ğ‘ƒğ‘™ğ‘œğ‘¡, a special variant of an autoencoder is proposed
(Figure 4).

The input neurons representing the categorical features are at-
tached with an embedding layer. An embedding technique is com-
monly used to create a concise, numerical representation of categor-
ical features [9]. The embedding representation of the 10 categorical
features is concatenated with the 17 numerical features, resulting
in a vector of size 27. This vector is then fed to the stacked autoen-
coder consisting of seven layers with respectively 27, 20, 15, 10, 15,
20, and 27 neurons.

Finally, the following output layer is attached:
(1) For the numerical features, a fully connected layer is at-
tached, followed by the linear activation function. This layer
contains 17 neurons against 17 numerical features.

(2) For each categorical feature with ğ‘™ possible values, ğ‘™ out-
put neurons are assigned, followed by the softmax function.
During inference, this function provides a probability distri-
bution over all possible values for each categorical feature.
During the training phase, we use data that consists solely of
benign ğ‘‡ ğ‘Ÿğ‘ğ‘ğ‘˜s. As described in Section 2, each ğ‘‡ ğ‘Ÿğ‘ğ‘ğ‘˜ contains sev-
eral ğ‘ƒğ‘™ğ‘œğ‘¡s (training examples). We divide the ğ‘‡ ğ‘Ÿğ‘ğ‘ğ‘˜s in the dataset

so that 80% is used for training tr and 20% is used for validation
val. As illustrated in Figure 4, the label for each example is one
vector of 17 entries containing the value of each numerical feature,
concatenated to 10 vectors representing the one-hot encoding for
each of the 10 categorical features.

The loss function used is the following combination of the mean
squared error (MSE) and the sparse categorical cross-entropy (SCCE):

Data Preprocessing component, and (2) the Sequence-Based Anom-
aly Detector (see Figure 5), which is based on a Long Short-Term
Memory (LSTM) network.

Data Preprocessing. The input for this component is the cur-
rent ğ‘ƒğ‘™ğ‘œğ‘¡, along with the ğ¾ previous ğ‘ƒğ‘™ğ‘œğ‘¡ğ‘  that correspond to the
same ğ‘‡ ğ‘Ÿğ‘ğ‘ğ‘˜ (with a sequence length of ğ¾ + 1). This component
consists of the following three parts:

ğ‘™ğ‘œğ‘ ğ‘  = ğ‘€ğ‘†ğ¸ (ğ‘¥ğ‘– : ğ‘¥ğ‘– âˆˆ ğ‘›ğ‘¢ğ‘šğ‘’ğ‘Ÿğ‘–ğ‘ğ‘ğ‘™) +

âˆ‘ï¸

ğ‘†ğ¶ğ¶ğ¸ (ğ‘¥ğ‘– )

(1)

ğ‘¥ğ‘– âˆˆğ‘ğ‘ğ‘¡ğ‘’ğ‘”ğ‘œğ‘Ÿğ‘–ğ‘ğ‘ğ‘™

Given tr, the network is trained to minimize the loss function on
val using the Adam optimizer. Training is stopped when the loss
function reaches its minimum on val.

(1) Categorical feature one-hot encoding - in this part, each
feature is converted to a vector that has a value of one in
one entry (corresponding to the feature value) and zeros in
all of the other places.

(2) UpdatingPeriod extraction - in this part, we calculate a fea-
ture called UpdatingPeriod. The value of this feature is the
time difference between two consecutive ğ‘ƒğ‘™ğ‘œğ‘¡s in the se-
quence (e.g., current time - previous time).

(3) Feature scaling - in this part, we apply min-max scaling on

the data for feature scaling.

Figure 4: The neural network architecture of the proposed
Plot-Level Anomaly Detector; the network is based on an au-
toencoder.

Track-Level Anomaly Detector. This module consists of a
ğ‘‡ğ‘Ÿğ‘ğ‘ğ‘˜ Score Collector and a ğ‘‡ğ‘Ÿğ‘ğ‘ğ‘˜-Level Anomaly Detector. The
scores generated by the ğ‘ƒğ‘™ğ‘œğ‘¡-Level detection module serve as the
input for this model. The model collects all of the scores for the
ğ‘ƒğ‘™ğ‘œğ‘¡s that are part of the same ğ‘‡ğ‘Ÿğ‘ğ‘ğ‘˜ and outputs them for the
ğ‘‡ğ‘Ÿğ‘ğ‘ğ‘˜-Level Anomaly Detector model. All of the ğ‘ƒğ‘™ğ‘œğ‘¡sâ€™ scores for
a ğ‘‡ğ‘Ÿğ‘ğ‘ğ‘˜ serve as the input to this model.

For each ğ‘‡ğ‘Ÿğ‘ğ‘ğ‘˜, we define the anomaly score as the average
of all of the input scores calculated by the Plot-Level Anomaly
Detector (those are stored inside the ğ‘‡ğ‘Ÿğ‘ğ‘ğ‘˜ Score Collector). In
order to determine the anomaly threshold, we used the validation
set val that was used to train the Plot-Level Anomaly Detector. The
anomaly threshold is calculated as the maximum value over the
ğ‘‡ğ‘Ÿğ‘ğ‘ğ‘˜sâ€™ average scores.

6.2 Timing-Based Anomaly Detection
This module focuses on detecting anomalies related to the ğ‘ƒğ‘™ğ‘œğ‘¡sâ€™
arrival times. It uses the following subset of the ğ‘ƒğ‘™ğ‘œğ‘¡ features de-
scribed in Section 5.3: ğ‘›ğ‘¢ğ‘š1, objectType, signalQuality, and track-
Type. The module consists of the following two components: (1) the

Figure 5: The neural network architecture of the proposed
Sequence-Based Anomaly Detector. The network is based on
an LSTM network.

Sequence-Based Anomaly Detector. This module receives a
sequence of length ğ¾ + 1 as input, and by using the first ğ¾ ele-
ments of the sequence, the model tries to predict the value of the
ğ‘ˆ ğ‘ğ‘‘ğ‘ğ‘¡ğ‘–ğ‘›ğ‘”ğ‘ƒğ‘’ğ‘Ÿğ‘–ğ‘œğ‘‘ (e.g., time interval) feature of the ğ¾ + 1-th element
(i.e., current ğ‘ƒğ‘™ğ‘œğ‘¡). To enable this, we designed an LSTM-based re-
gressor. The architecture of the regressor is presented in Figure 5.
As can be seen, the ğ¾ length sequence serves as input to an LSTM
network with five hidden units. Then, the output of the LSTM com-
ponent in the final step is fully connected to one neuron. At the
end, a linear activation function is applied to this neuron.

During the training phase, we use data consisting solely of benign
ğ‘‡ ğ‘Ÿğ‘ğ‘ğ‘˜s. For each ğ‘‡ ğ‘Ÿğ‘ğ‘ğ‘˜, we generate a set of training examples such
that each consists of a set of ğ¾ consecutive ğ‘ƒğ‘™ğ‘œğ‘¡s and is labeled
by the ğ‘ˆ ğ‘ğ‘‘ğ‘ğ‘¡ğ‘–ğ‘›ğ‘”ğ‘ƒğ‘’ğ‘Ÿğ‘–ğ‘œğ‘‘ feature of the following ğ¾ + 1-th ğ‘ƒğ‘™ğ‘œğ‘¡. We
divide the ğ‘‡ ğ‘Ÿğ‘ğ‘ğ‘˜s in the dataset so that 80% is used for training tr
and 20% is used for validation val. The loss function used is the
MSE. Given tr, the network is trained to minimize the loss function
on val using the Adam optimizer. Training is stopped when the loss
function reaches its minimum on val.

Once the model training is complete, the anomaly threshold
ğ‘¡â„ğ‘Ÿ is set. This anomaly threshold, above which an instance is
considered anomalous, is calculated as the sum of the sample mean
and standard deviation of MSE over val:

ğ‘¡â„ğ‘Ÿ = ğ‘šğ‘’ğ‘ğ‘›(ğ‘€ğ‘†ğ¸ğ‘£ğ‘ğ‘™ ) + ğ‘ ğ‘¡ğ‘‘ (ğ‘€ğ‘†ğ¸ğ‘£ğ‘ğ‘™ )

(2)

5

Regarding the ğ¾ parameter, the detection accuracy increases as
long as ğ¾ is large. However, an anomaly cannot be detected during
the first ğ¾ ğ‘ƒğ‘™ğ‘œğ‘¡s. Practically, for radar systems, setting ğ¾ at five is a
good balance in this trade off.

7 EVALUATION
For the evaluation we use benign data collected from four real radar
systems that are deployed in different operational setups and used
to identify objects. We refer to each dataset as a recording session.
The number of messages (i.e., radar data records) in each recording
session is as follows: R1 â€“ 45,720 (50.7%), R2 â€“ 23,017 (25.5%), R3
â€“ 11,955 (13.2%), and R4 â€“ 9,551 (10.6%). In total, there are 90,243
messages.

7.1 Attack Scenarios Implemented
Since our dataset does not include any attacks, we had to simu-
late the attacks and inject them into our dataset. We simulated
four attack scenarios by manipulating valuable benign data, and
conducted 15 different experiments for each attack.

Categorical feature manipulation. This is an integrity viola-
tion attack in which the attacker changes a categorical feature. In
the following cases, such manipulations may cause the consuming
systems or radar operators to incorrectly characterize and handle
the detected object.

(1) objectType - changing this feature may cause aerial objects
to appear as ground objects and vice versa. This can change
the way the radar operator reacts to the various objects
detected; an attacker can utilize this attack in order to dis-
guise threatening objects, leaving them untreated by radar
operators.

(2) alertRaised - changing this feature may cause an alert to be
issued for no reason and vice versa. Such an attack can cre-
ate many false alarms, causing the radar operator to ignore
threats.

(3) objectCategory - changing this feature may cause friendly
objects to be considered enemy objects and vice versa. This
attack can cause radar operators to fire on friendly objects
or ignore enemy objects.

Changing the features for an entire ğ‘‡ğ‘Ÿğ‘ğ‘ğ‘˜ or a ğ‘‡ğ‘Ÿğ‘ğ‘ğ‘˜ segment
will be much more beneficial to the attacker than changing the
features for random ğ‘ƒğ‘™ğ‘œğ‘¡s. This is because changes in the features
of random ğ‘ƒğ‘™ğ‘œğ‘¡s may be ignored by the radar operator and are not
likely to influence the action taken by an operator. Therefore, we
applied the above manipulations on an entire ğ‘‡ğ‘Ÿğ‘ğ‘ğ‘˜.

The following process was used to generate the test set given a
benign set ğµ collected from real radar systems: (1) create ğµâ€² by du-
plicating ğµ; (2) select ğ‘“ â€“ the feature that should be manipulated; (3)
for each ğ‘‡ğ‘Ÿğ‘ğ‘ğ‘˜ ğ‘‡ in ğµâ€², change the value of ğ‘“ to a distinct random
value from the set of valid values of ğ‘“ ; (4) label the manipulated
ğ‘ƒğ‘™ğ‘œğ‘¡s as anomalies; and (5) combine the benign set ğµ and the ma-
nipulated set ğµâ€² into one test set. This process generates a similar
number of benign and malicious ğ‘ƒğ‘™ğ‘œğ‘¡s; therefore, the resulting test
set is balanced.

6

Plot dropping. This is an availability violation attack in which
the attacker drops one/several ğ‘ƒğ‘™ğ‘œğ‘¡s from a ğ‘‡ ğ‘Ÿğ‘ğ‘ğ‘˜, so that the de-
tected object will evade the consuming system for some period of
time.

Dropping several consecutive ğ‘ƒğ‘™ğ‘œğ‘¡s will be much more beneficial
to the attacker than dropping nonconsecutive ğ‘ƒğ‘™ğ‘œğ‘¡s or just a single
ğ‘ƒğ‘™ğ‘œğ‘¡. Therefore, for a ğ‘‡ ğ‘Ÿğ‘ğ‘ğ‘˜ ğ‘‡ , we first select a minimum value ğ‘
(ğ‘ â‰¤ |ğ‘‡ |) of ğ‘ƒğ‘™ğ‘œğ‘¡s to be removed from ğ‘‡ . We use ğ‘ = 10 since a value
less than 10 does not allow an attacker to cause real harm to the
data integrity of a radar system.

The following process was used to generate the test set given the
benign set ğµ collected from real radar systems: (1) for each ğ‘‡ğ‘Ÿğ‘ğ‘ğ‘˜ ğ‘‡ ,
select a random ğ‘ƒğ‘™ğ‘œğ‘¡ index ğ‘– and a random integer ğ‘Ÿ âˆˆ ğ‘, |ğ‘‡ | âˆ’ 1; (2)
starting at index ğ‘–, drop a minimum number ğ‘šğ‘–ğ‘›ğ‘–ğ‘šğ‘¢ğ‘š(|ğ‘‡ | âˆ’ ğ‘–, ğ‘Ÿ ) of
consecutive ğ‘ƒğ‘™ğ‘œğ‘¡s; (3) label the ğ‘ƒğ‘™ğ‘œğ‘¡ that follows the dropped ğ‘ƒğ‘™ğ‘œğ‘¡s
as an anomaly. This process generates a different number of benign
and malicious ğ‘ƒğ‘™ğ‘œğ‘¡s; therefore the resulting test set is imbalanced.

7.2 Evaluation Method
We conducted three types of evaluations; in each case, we repeated
the experiment five times (each time a different recording session
was selected for testing).

A description of the types of evaluations performed is provided
below, along with an example of the training/testing data in a sce-
nario in which the R4 recording session is examined:

â€¢ Cross-session setup: in this case, each time we used three
recording sessions for training, and the fourth session was
used to test the model. Example for the R4 recording session:
training - R1, R2, and R3; testing - R4.

â€¢ Chronological setup: in this case, for each recording ses-
sion, we trained the model on the first 90% of the instances
(in chronological order) and tested it on the remaining 10% of
the instances. Example for the R4 recording session: training
- 90% of the instances of R4; testing - remaining 10% of the
instances of R4.

â€¢ Transfer learning setup: this case is a combination of the
previous two setups, in which we used three recording ses-
sions, as well as the first 10% of the instances of the fourth
session, to train the model, and the remaining 90% of the
instances of the fifth session were used to test the model. Ex-
ample for the R4 recording session: training - R1, R2, R3, and
the first 10% of the instances of R4; testing - the remaining
90% of the instances of R4.

It should be noted that the cross-session evaluation setup has two
significant advantages over the other two: (1) in practice, it is easier
for radar engineers to deploy a model that has already been trained
rather than training a model using new system data, and (2) training
the model on new system data can expose the model to cyber risks
(e.g., adversarial poisoning [21]).

7.3 Evaluation Metrics
The task of identifying anomalies in the radar data stream is a bi-
nary classification task, where benign samples are labeled as zero
(negative), and malicious data is labeled as one (positive). We used
the following common metrics for the evaluation: true positive rate

(TPR)/recall, false positive rate (FPR), receiver operating charac-
teristic (ROC) curve, area under the ROC curve (AUC), precision,
precision-recall curve, and average precision (AP).

7.4 Results
In this section, we present the evaluation results for each attack sce-
nario (presented in Section 7.1) and evaluation method (presented
in Section 7.2). First, we present a graph of the evaluation results
as a function of different thresholds (using ROC and PRC graphs).
Then, we summarize the evaluation results for predefined anomaly
thresholds. The method for calculating the anomaly thresholds is
described in Section 6.
Categorical feature manipulation. Figures 6 - 8 present the de-
tection results of the Field Manipulation Detection module when
manipulating objectType, objectCategory, and alertRaised features
respectively. As can be seen, in all cases except for recording session
R4 of the objectType feature manipulation attack, all setups had
great performance in terms of the AUC and AP for all categori-
cal feature manipulation attacks. For recording session R4 of the
objectType feature, the best performance was obtained with the
chronological setup. The best detection rates were observed for
the manipulation attack on both objectCategory and alertRaised
features.
Plot dropping. Table 1 presents the distribution of the benign /
malicious samples in the ğ‘ƒğ‘™ğ‘œğ‘¡ dropping attack. It is noteworthy
that the data is imbalanced, since for each ğ‘‡ğ‘Ÿğ‘ğ‘ğ‘˜ we only execute
the attack once. The performance of the Timing-Based Anomaly
Detection module on the generated testset is presented in Figure 9.
As can be seen, in all scenarios the model achieved good results.
Performance for predefined anomaly thresholds. Table 2
presents the performance for each attack scenario and each setup in
terms of the true positive rate (TPR) and false positive rate (FPR) for
a threshold that was computed on a validation set and then applied
on a test set. As can be seen, our proposed method can detect 90% of
the ğ‘ƒğ‘™ğ‘œğ‘¡ dropping attacks, with a false positive rate of 2%, and from
76% to 96% of feature manipulation attacks, with a false positive rate
of 2%. In typical scenarios, 400 ğ‘ƒğ‘™ğ‘œğ‘¡s are generated and transferred
by a radar system every minute. A false alarm rate of 2% means
that eight ğ‘ƒğ‘™ğ‘œğ‘¡s should be tracked by a system operator/automatic
system every minute, which is practical.

In addition, in most cases our proposed method achieves very
good results for the cross-session setup. This is an important point,
since it means that a pretrained model can be migrated to new radar
systems without retraining.

Table 1: Number of benign (b) and malicious (m) samples in
the Plot dropping attack.

Recording Session Examined

R1

R2

b
46,600
4,606
42,709

m
213
60
195

b
23,068
2,323
21,126

m
177
34
170

R3

b
12,139
1,206
10,808

m
97
15
86

R4

b
9,484
842
8,451

m
119
31
110

Cross-session
Chron. (10%)
Transfer (90%)

7.5 Performance Analysis
In order to understand whether the proposed method is practical
and can be applied for real-time tracking of anomalies in radar

7

Table 2: Evaluation results obtained for predefined anomaly
thresholds.

Setup

Avg AUC

Avg PR

Avg TPR

Avg FPR

Feature manipulation - objectType

Cross-session
Chronological (10%)
Transfer (90%)

0.922
0.972
0.943

0.930
0.712
0.931

0.759
0.894
0.710

Feature manipulation - objectCategory

Cross directories
Chronological (10%)
Transfer (90%)

0.986
0.997
0.975

0.973
0.994
0.952

Feature manipulation - alertRaised

Cross-session
Chronological (10%)
Transfer (90%)

Cross-session
Chronological (10%)
Transfer (90%)

0.975
0.988
0.950

0.987
0.997
0.974
Plot dropping
0.975
0.987
0.983

0.820
0.916
0.830

0.906
0.770
0.769

0.963
0.776
0.750

0.900
0.937
0.909

0.028
0.016
0.090

0.028
0.016
0.090

0.028
0.016
0.090

0.023
0.026
0.023

system data streams, we measured the average time it takes to
process a single ğ‘ƒğ‘™ğ‘œğ‘¡. This experiment was conducted on a standard
machine with an Intel core i7-7600U 2.8Ghz CPU and 32GB RAM.
The machineâ€™s operating system was Windows 10.

The results showed that our proposed method can analyze 20K
ğ‘ƒğ‘™ğ‘œğ‘¡s per second. Given that in typical scenarios a radar system
generates and transfers 400 ğ‘ƒğ‘™ğ‘œğ‘¡s per minute, we conclude that
our method is practical and can be used for real-time tracking of
anomalies in radar system data streams.

8 SUMMARY & CONCLUSIONS
In this paper, we propose a novel deep learning-based method for
detecting data manipulation attacks on radar systems. We consider
attack scenarios in which an attacker manipulates the data sent by
the radar system to peripheral consuming systems. To evaluate our
method, we used data collected from four real radar systems. This
dataset consists of ğ‘ƒğ‘™ğ‘œğ‘¡ records that are sent from the radar system
to a peripheral consuming system.

To evaluate our method, we generated attacks considered ben-
eficial to the attacker, ranging from integrity violation attacks to
availability violation attacks. The results of our evaluation show
that the proposed method can learn the dataâ€™s normal behavior and
distinguish between normal and manipulated data.

In our design process, we took into account the benefits of iden-
tifying the anomaly type detected, determining whether a legiti-
mate ğ‘ƒğ‘™ğ‘œğ‘¡ is missing from a sequence of ğ‘ƒğ‘™ğ‘œğ‘¡s, and understanding
whether an existing ğ‘ƒğ‘™ğ‘œğ‘¡â€™s feature has been manipulated. This prop-
erty could help radar operators determine the correct action to take
when an attack occurs.

The transferability and practicality of the proposed method is
demonstrated by: (1) our method obtains very good results when
training on data collected from three radar systems and testing on
data collected from another radar system, and (2) a typical Intel
controller can analyze ğ‘ƒğ‘™ğ‘œğ‘¡s at a frequency of 20K/sec, while radar
systems generate and transfer ğ‘ƒğ‘™ğ‘œğ‘¡s at a frequency of 7/sec.

Figure 6: The ROC and PRC curves for the objectType feature manipulation attack for each recording session examined.

Figure 7: The ROC and PRC curves for the objectCategory feature manipulation attack for each recording session examined.

8

Figure 8: The ROC and PRC curves for the alertRaised feature manipulation attack for each recording session examined.

Figure 9: The ROC and PRC curves for the Plot dropping attack for each recording session examined.

9

REFERENCES
[1] Bashir Mohammed Albashir Abdallah, Hassan Ibrahim Abdalmajeed Yousif,
Ibrahim Hassan Shraf Ali, Mustafa Mohmmed Nour Ahmed Asmail, et al. 2017.
Study and analysis of radar system. Ph.D. Dissertation. Sudan University of
Science and Technology.

[2] David K Barton. 1988. Modern radar system analysis. Norwood (1988).
[3] David K Barton. 2004. Radar system analysis and modeling. Artech House.
[4] Victor Bolbot, Gerasimos Theotokatos, Evangelos Boulougouris, and Dracos
Vassalos. 2020. A novel cyber-risk assessment method for ship systems. Safety
Science 131 (2020), 104908.

[5] Loic Bontemps, James McDermott, Nhien-An Le-Khac, et al. 2016. Collective
anomaly detection based on long short-term memory recurrent neural networks.
In International Conference on Future Data and Security Engineering. Springer,
141â€“152.

[6] Raghavendra Chalapathy and Sanjay Chawla. 2019. Deep learning for anomaly

detection: A survey. arXiv preprint arXiv:1901.03407 (2019).

[7] Shai Cohen, Tomer Gluck, Yuval Elovici, and Asaf Shabtai. 2019. Security analysis
of radar systems. In Proceedings of the ACM Workshop on Cyber-Physical Systems
Security & Privacy. 3â€“14.

[8] Edan Habler and Asaf Shabtai. 2018. Using LSTM encoder-decoder algorithm for
detecting anomalous ADS-B messages. Computers & Security 78 (2018), 155â€“173.
[9] John T Hancock and Taghi M Khoshgoftaar. 2020. Survey on categorical data for

neural networks. Journal of Big Data 7 (2020), 1â€“41.

[10] Seok-Jun Hong, Yearn-Gui Yi, Jeil Jo, and Bo-Seok Seo. 2018. Classification of
radar signals with convolutional neural networks. In 2018 Tenth International
Conference on Ubiquitous and Future Networks (ICUFN). IEEE, 894â€“896.

[11] Li Kang, Jiu Bo, Liu Hongwei, and Liang Siyuan. 2018. Reinforcement learning
based anti-jamming frequency hopping strategies design for cognitive radar. In
2018 IEEE International Conference on Signal Processing, Communications and
Computing (ICSPCC). IEEE, 1â€“5.

[12] Amara Dinesh Kumar, Koti Naga Renu Chebrolu, Soman KP, et al. 2018. A brief
survey on autonomous vehicle possible attacks, exploits and vulnerabilities. arXiv
preprint arXiv:1810.04144 (2018).

[13] Ping Lang, Xiongjun Fu, Marco Martorella, Jian Dong, Rui Qin, Xianpeng Meng,
and Min Xie. 2020. A Comprehensive Survey of Machine Learning Applied to

Radar Signal Processing. arXiv preprint arXiv:2009.13702 (2020).

[14] Pengfei Liu, Yimin Liu, Tianyao Huang, Yuxiang Lu, and Xiqin Wang. 2020. De-
centralized Automotive Radar Spectrum Allocation to Avoid Mutual Interference
Using Reinforcement Learning. IEEE Trans. Aerospace Electron. Systems (2020).
[15] Anil K Maini. 2018. Handbook of defence electronics and optronics: fundamentals,

technologies and systems. John Wiley & Sons.

[16] Yair Meidan, Michael Bohadana, Yael Mathov, Yisroel Mirsky, Asaf Shabtai, Do-
minik Breitenbacher, and Yuval Elovici. 2018. N-baiotâ€”network-based detection
of iot botnet attacks using deep autoencoders. IEEE Pervasive Computing 17, 3
(2018), 12â€“22.

[17] Ariadna Mendoza, Alberto Soto, and Benjamin C Flores. 2017. Classification of
radar jammer FM signals using a neural network. In Radar Sensor Technology
XXI, Vol. 10188. International Society for Optics and Photonics, 101881G.
[18] Yisroel Mirsky, Tomer Doitshman, Yuval Elovici, and Asaf Shabtai. 2018. Kitsune:
an ensemble of autoencoders for online network intrusion detection. arXiv
preprint arXiv:1802.09089 (2018).

[19] Ines ObradoviÄ‡, Mario MiliÄeviÄ‡, and Krunoslav Å½ubriniÄ‡. 2014. Machine learning
approaches to maritime anomaly detection. NaÅ¡e more: znanstveni Äasopis za
more i pomorstvo 61, 5-6 (2014), 96â€“101.

[20] Alberto Soto, Ariadna Mendoza, and Benjamin C Flores. 2017. Optimization of
neural network architecture for classification of radar jamming FM signals. In
Radar Sensor Technology XXI, Vol. 10188. International Society for Optics and
Photonics, 101881H.

[21] Yevgeniy Vorobeychik and Murat Kantarcioglu. 2018. Adversarial machine
learning. Synthesis Lectures on Artificial Intelligence and Machine Learning 12, 3
(2018), 1â€“169.

[22] Zhilu Wu, Yanlong Zhao, Zhendong Yin, and Haochen Luo. 2017. Jamming signals
classification using convolutional neural network. In 2017 IEEE International
Symposium on Signal Processing and Information Technology (ISSPIT). IEEE, 062â€“
067.

[23] Xuhang Ying, Joanna Mazer, Giuseppe Bernieri, Mauro Conti, Linda Bushnell, and
Radha Poovendran. 2019. Detecting ADS-B spoofing attacks using deep neural
networks. In 2019 IEEE Conference on Communications and Network Security
(CNS). IEEE, 187â€“195.

10

