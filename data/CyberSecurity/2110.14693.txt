Towards Robust Reasoning over Knowledge Graphs

Zhaohan Xi† Ren Pang† Changjiang Li† Shouling Ji‡ Xiapu Luo∗ Xusheng Xiao§ Ting Wang†

†Pennsylvania State University

∗The Hong Kong Polytechnic University

‡Zhejiang University and Ant Financial

§ Case Western Reserve University

1
2
0
2

v
o
N
1

]

R
C
.
s
c
[

2
v
3
9
6
4
1
.
0
1
1
2
:
v
i
X
r
a

Abstract

Answering complex logical queries over large-scale knowl-
edge graphs (KGs) represents an important artiﬁcial intelli-
gence task, entailing a range of applications. Recently, knowl-
edge representation learning (KRL) has emerged as the state-
of-the-art approach, wherein KG entities and the query are
embedded into a latent space such that entities that answer
the query are embedded close to the query. Yet, despite its
surging popularity, the potential security risks of KRL are
largely unexplored, which is concerning, given the increas-
ing use of such capabilities in security-critical domains (e.g.,
cyber-security and healthcare).

This work represents a solid initial step towards bridging
this gap. We systematize the potential security threats to KRL
according to the underlying attack vectors (e.g., knowledge
poisoning and query perturbation) and the adversary’s back-
ground knowledge. More importantly, we present ROAR1, a
new class of attacks that instantiate a variety of such threats.
We demonstrate the practicality of ROAR in two representa-
tive use cases (i.e., cyber-threat hunting and drug repurposing).
For instance, ROAR attains over 99% attack success rate in
misleading the threat intelligence engine to give pre-deﬁned
answers for target queries, yet without any impact on non-
target ones. Further, we discuss potential countermeasures
against ROAR, including ﬁltering of poisoning facts and ro-
bust training with adversarial queries, which leads to several
promising research directions.

1 Introduction

A knowledge graph (KG) is a structured representation of
human knowledge about “facts”, with entities, relations, and
descriptions respectively capturing real-world objects (or ab-
stract concepts), their relationships, and their semantic proper-
ties. Answering complex logical queries over KGs represents
an important artiﬁcial intelligence task, entailing a range of
applications. For instance, in Figure 1, the security analyst
queries for the most likely vulnerability (CVE) that is being
exploited, based on observations regarding the incident (e.g.,
attack technique, tactics, and affected product).

Typically, the computational complexity of processing such
queries grows exponentially with the query size [19], which

Figure 1: Illustration of KRL.

hinders its use over large KGs. Recently, knowledge represen-
tation learning (KRL) has emerged as a promising approach,
wherein KG entities and a query are projected into a latent
space such that the entities that answer the query are embed-
ded close to each other. As shown in Figure 1, KRL reduces
answering an arbitrary query to simply identifying entities
with embeddings most similar to the query, thereby implicitly
imputing missing relations [12] and scaling up to large-scale
KGs in various domains [2, 3, 5].

Surprisingly, in contrast to the intensive research on im-
proving the capabilities of KRL, its security risks are largely
unexplored. This is highly concerning given (i) the impor-
tance of integrating domain knowledge in artiﬁcial intelli-
gence tasks has been widely recognized [40]; (ii) KGs have
emerged as one of the most popular representations of domain
knowledge in various security-sensitive domains (e.g., cyber-
security [30] and healthcare [50]); and (iii) KRL has become
the state-of-the-art approach to process complex queries over
such KGs [19, 38]. We thus wonder:

RQ1 – What are the potential security threats to KRL?
RQ2 – How effective are the attacks in practical settings?
RQ3 – Are there any countermeasures against such attacks?
Our work – This work represents a solid initial step to-

wards answering these questions.

1ROAR: Reasoning Over Adversarial Representations.

RA1 – First, we characterize the potential security threats

ChromeEmbedding Space (w/o Attack)buffer overﬂowCVE-2020-6548CVE-2020-6548Reasoning answerChromeCVE-2020-6548Buffer OverﬂowCVE-2013-6623v84.0.4174.125use tree orderKnowledge GraphChromebuffer overﬂowheap corruption heap corruptionWhich CVE?poisoningfactsuse tree orderEmbedding Space (Attacked)Query Graphentity embedding (w/ attack)variable (entity) embedding entity embedding (perturbed)AnchorVariableAnswerPerturbationleveragesvulnerable to* omit edge relationsleveragesapplies tovulnerable toCVE-2013-6623Chromeuse tree orderbuffer overﬂowCVE-2013-6623 applies to applies toleveragesapplies tovulnerable toapplies to 
 
 
 
 
 
to KRL. As illustrated in Figure 1, the adversary may disrupt
the reasoning of KRL through two attack vectors: (i) knowl-
edge poisoning – polluting the KGs by committing poisoning
facts, and (ii) query perturbation – modifying the queries by
adding misleading variables/relations. We create a threat tax-
onomy according to the underlying attack vectors as well as
the adversary’s background knowledge.

RA2 – Further, we present ROAR, a new class of attacks
that instantiate the above threats. We evaluate the practicality
of ROAR attacks in two representative use cases, cyber-threat
hunting and drug repurposing. It is empirically demonstrated
that ROAR is highly effective against the state-of-the-art KRL
systems in both domains. For instance, in both cases, ROAR
attains over 99% attack success rates in misleading KRL to
give pre-deﬁned answers for target queries, yet without any
impact on non-target queries.

RA3 - Finally, we discuss potential countermeasures and
their technical challenges. According to the attack vectors,
we consider two mitigation strategies: (i) ﬁltering of poison-
ing KG facts and (ii) robust training with adversarial queries.
We reveal that there exists an interesting synergy between
the two defenses and also a delicate trade-off between KRL
performance and attack resilience.

Contributions – To the best of our knowledge, the work
represents the ﬁrst in-depth study on the security of KRL. Our
contributions are summarized as follows.

We characterize the potential security threats to KRL and
reveal the design spectrum for the adversary with varying
capability and knowledge.

We present ROAR, a new class of attacks that instantiate
various threats to KRL, which highlights with the following
features: (i) it leverages both knowledge poisoning and query
perturbation as the attack vectors; (ii) it is highly effective
and evasive; (iii) it assumes limited knowledge regarding
the target KRL system; and (iv) it realizes both targeted and
untargeted attacks.

We discuss potential mitigation, which sheds light on im-
proving the current practice of training and using KRL, point-
ing to several promising research directions.

2 Preliminaries

We ﬁrst introduce fundamental concepts and assumptions
used throughout the paper.

Knowledge Graph – A knowledge graph (KG) G =
(N ,E) consists of nodes N and edges E connecting them.
Each node v
v(cid:48) ∈
E indicates that there exists relation r
R (where R is a ﬁnite
set of relation types) from v to v(cid:48). In other words, G comprises
with v, v(cid:48) ∈
a set of facts

N represents an entity and each edge v r
−→

∈
N and v r
−→

v, r, v(cid:48)(cid:105)}

Query – A variety of reasoning tasks can be performed

v(cid:48) ∈

E.

{(cid:104)

∈

over KGs. Here, we focus on two types of queries.

2

Entity Query – In an entity query, one asks for a speciﬁc
entity that satisﬁes given logical constraints, which are often
deﬁned using ﬁrst-order conjunctive logic with existential (
)
∃
) operations. Formally, letting v? be the
and conjunction (
entity of interest, Kq be the set of known anchors, Vq be a
set of existentially quantiﬁed variables, and Eq be a set of
relations, an entity query q (cid:44) (v?,Kq,Vq,Eq) is deﬁned as:

∧

q[v?] = v? .

s.t. v r
−→

v(cid:48) =

v(cid:48)

Vq :
∃
(cid:26) v

∧v

Eq

v r
−→
Vq
v?

r
v(cid:48)∈
−→
Kq, v(cid:48) ∈
Vq
∪ {

∈
v, v(cid:48) ∈

v?

∈

∪ {
, r
}

(1)

R

∈

, r
}
R

As an example, in Figure 1, v? is the sink (CVE), Chrome is an
anchor, while heap corruption is a variable.

Intuitively, q can be represented as a dependency graph,
of which the nodes and edges correspond to the entities and
relations in q, respectively. We say that a query q is valid if its
dependency graph is directed acyclic with Ka as the source
nodes and v? as the unique sink node [19, 38].

Relation Query – In a relation query, one asks for the poten-
tial relation, which is currently not present in the KG, between
two given entities v, v(cid:48). Formally, a relation query q (cid:44) (r?, v, v(cid:48))
is deﬁned as:

q[r?] = r? .

r?
−→

v
∃

v(cid:48)

(2)

To determine r?, it often requires to account for the context
surrounding v and v(cid:48) in the KG.

Knowledge Representation Learning – Recently, knowl-
edge representation learning (KRL) has emerged as the state-
of-the-art approach to process such queries. It projects KGs
and query q to a latent space, such that entities that answer q
are embedded close to q.

As shown in Figure 2, a KRL system γ typically comprises
two components, encoder φ that projects entity v to its em-
bedding φv, and relation r-speciﬁc operator ψr that performs
geometric transformation to φv to compute entities with re-
lation r to v. KRL often samples a set of query-answer pairs
from the KG as the training set and trains φ and ψ in a super-
vised manner.

{

, it computes

S1,S2, . . . ,Sn

Entity Query – To process entity query q, one may derive
q’s computation graph from its dependency graph with a set
of operators: (i) projection - given entity set S , it computes
the entities with relation r to S ; (ii) intersection - given a set
n
i=1Si. Intuitively,
of entity sets
∩
the computation graph speciﬁes the procedure to answer q
as traversing the KG: starting from the anchors, it iteratively
applies the two oprators, until reaching the unique sink [17].
Relation Query – To answer relation queries, KRL projects
the KG to the latent space and typically applies graph neural
networks (e.g., [41]) as the link prediction operator that aggre-
gates multi-relational graphs to predict the missing relations.

}

φG , and φq to respectively denote the embeddings of entity v,
KG G, and query q.

Operator ψ – The relation r-speciﬁc operator ψr performs
geometric transformation to φv to compute entities with re-
lation r to v. For instance, in Query2Box [38], the KRL con-
sists of two operators, projection and intersection, both imple-
mented as DNNs.

Adversary’s Capability
Query
Perturbation

Adversary’s Knowledge
Encoder
φ

Operator
ψ

Attack

1
2
3
4
5
6
7
8
9
10
11
12

Knowledge
Poisoning
(cid:51)
(cid:51)
(cid:51)
(cid:51)

(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)

(cid:51)
(cid:51)
(cid:51)
(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)
(cid:51)

(cid:51)
(cid:51)

(cid:51)
(cid:51)

Table 1. A taxonomy of attacks against KRL.

3.2 Attack taxonomy

Based on the adversary’s varying capability and knowledge,
we create a taxonomy of 12 attacks against KRL, as summa-
rized in Table 1. Given its unique assumption, each attack
tends to require a tailored attack strategy. For instance,

Attack4 – It uses knowledge poisoning as the attack vector
while assuming knowledge about both encoder φ and operator
ψ. Before training, the adversary crafts poisoning facts to
pollute the KG construction in a white-box manner.

Attack7 – It uses query perturbation as the attack vector and
assumes knowledge only about ψ. Without access to φ, the
adversary may resort to a surrogate encoder ˆφ and generate
adversarial queries transferable to the target KRL system at
inference time.

Attack10 – It leverages both knowledge poisoning and
query perturbation as the attack vectors and assumes knowl-
edge about φ but not ψ; the adversary may thus resort to a
surrogate operator ˆψ and optimize the poisoning facts and
adversarial queries jointly.

The discussion of the remaining attacks is deferred to §B.

3.3 Challenges

Note that the attacks against KRL bears conceptual similarity
to that against conventional classiﬁcation models (e.g., adver-
sarial evasion [11,16], model poisoning [21,42], and backdoor
injection [26,34]). For instance, both KG poisoning and model
poisoning use poisoning data to inﬂuence the training of tar-
get systems, while both query perturbation and adversarial

Figure 2: Illustration of ROAR attacks against KRL.

3 Threat Characterization

We systematize the threats to KRL according to the underlying
attack vectors and the adversary’s knowledge.

3.1 Adversary model

We ﬁrst deﬁne the adversary model.

Adversary’s objectives – Let Q be the testing query
set and Q ∗ be the set of queries targeted by the adversary
Q ). In an untargeted attack, the adversary aims to
(Q ∗ ⊆
force the KRL system to make erroneous reasoning over Q ∗;
in a targeted attack, the adversary attempts to force the system
to return a target answer A when processing Q ∗.

In both cases, to be evasive against inspection, the attack
must have a limited impact on the system’s performance on
non-target queries Q

Q ∗.

\

Adversary’s capability – As illustrated in Figure 2, we

consider two different attack vectors.

Knowledge Poisoning – Before training, the adversary may
commit poisoning facts which are then integrated by KRL to
construct the KGs. We argue that this attack vector is prac-
tical: most KGs are automatically built using public, crowd-
sourced information (e.g., [4]); due to the massive amount of
information, it is often challenging to conduct thorough fact
checking [48], which opens the door for knowledge poisoning.
To make the attack evasive, we require that the number of
poisoning facts is limited.

Query Perturbation – At inference, the adversary may also
force the KRL system to malfunction by modifying the query
by adding misleading variables/relations. To make the at-
tack evasive, we require that (i) only the addition of vari-
ables/relations is allowed and (ii) the perturbed query must
represent a valid dependency graph with respect to the KG.

Adversary’s knowledge – We consider the adversary’s

knowledge regarding the following two components.

Encoder φ – The encoder projects KG entities to their em-
beddings based on their topological and relational structures.
With a little abuse of notation, in the following, we use φv,

3

Knowledge PoisoningTrainingQueryAdversaryKRL SystemMalfunctionKGPolluted KGψφEncoderOperatorQuery PerturbationAdversarialQueryevasion aim to generate inputs that are perceptually similar to
benign ones but cause target systems to malfunction.

However, realizing the attacks against KRL represents a set

of unique, non-trivial challenges.

– Projecting KG entities or queries (discrete) to their embed-
dings (continuous) represents a non-differentiable mapping,
making it impractical to directly optimize poisoning facts
or adversarial queries, which is especially challenging if the
encoder is unknown.

– There exist potentially combinatorial ways to gener-
ate poisoning facts with respect to given KGs or adversarial
queries with respect to given benign queries, which implies a
prohibitive search space.

– In attacks that leverage both poisoning facts and adver-
sarial queries, due to their mutual dependence, every time up-
dating the poisoning facts requires expensive re-computation
of the adversarial queries.

In the following, we present ROAR, a new class of attacks
against KRL that addresses the above challenges within a
novel Optimization-then-Approximation (OTA) framework.

4 ROAR Attacks

Next, we give an overview of the OTA framework and then
detail the implementation of KG poisoning and query pertur-
bation within this framework. For simplicity, we assume (i)
white-box attacks – the adversary has knowledge regarding
the KRL system γ (including encoder φ and operator φ); (ii) tar-
geted attacks – the adversary aims to direct the answering of
a query set Q ∗ to the desired answer A (i.e., targeted attacks).
We discuss the extension to other settings (e.g., black-box,
untargeted attacks) in §4.5.

4.1 Overview of OTA

(cid:74)

q
(cid:75)

Recall that KRL traverses across the input spaces (i.e., KG G
and query q), the latent space (i.e., embeddings φG and φq),
and the output space (i.e., answer
). To mislead KRL to
arrive at the target answer A, OTA comprises two key steps:
Optimization – With respect to the desired answer A, OTA
optimizes the embeddings, φG in the case of knowledge poi-
soning and φq in the case of query perturbation, through back-
propagation. Let φ+

q be the updated KG and query.
G (or φ+

Approximation – It then projects φ+

q ) back to the
input space. However, as φ is non-differentiable, it leverages
attack-speciﬁc heuristics to search for KG G ∗ (or query q∗)
that leads to embeddings to best approximate φ+
G (or φ+
q ).
These two steps are often executed in an interleaving manner
until ﬁnding proper poisoning facts (or adversarial queries).
Below, we elaborate on the implementation of KG poisoning
and query perturbation within the OTA framework.

G and φ+

4.2 Knowledge poisoning

Recall that knowledge poisoning aims to direct the answering
of Q ∗ to target answer A by committing poisoning facts F ∗
to the construction of KG G.

ﬁxable by
−−−−−→

Without loss of generality, we deﬁne Q ∗ as queries sharing
a common pattern p∗. For instance, p∗ can be a speciﬁc set
vulnerable to
of facts forming a logical path (e.g., p∗ = Chrome
−−−−−−−→
vmitigation). In other words, p∗ functions as a
vCVE
trigger to invoke KRL to malfunction. Further, to be practical,
we assume the number of poisoning facts that can be added is
limited by a threshold nkp (i.e.,

F ∗| ≤
|
Let K ∗ collectively denote the anchors entities in p∗ (e.g.,
Chrome in the running example) and the target answer A. To
this end, we deﬁne F ∗ as a set of poisoning facts surrounding
K ∗ to inﬂuence the embeddings of p∗, which in turn mis-
leads the reasoning model to malfunction. This overall ﬂow
is illustrated in Figure 3.

nkp).

Figure 3: Workﬂow of knowledge poisoning.

Optimization – At this step, we optimize the embeddings
of K ∗ to achieve the attack objective. Note that adding
φK ∗
poisoning facts F ∗ generally inﬂuences not only the embed-
dings of K ∗ but also that of neighboring entities. Yet, due to
the locality of F ∗ surrounding K ∗ and the large scale of G,
we make the assumption that the impact of F ∗ on the embed-
dings of other entities is marginal, which is also conﬁrmed in
our empirical evaluation (§5, §6).

carries two objectives: effective-
Q ∗, the system returns the desired answer
Q ∗, the system
. Formally, we deﬁne the

Q

∈

\

The optimization of φK ∗

ness – for query q
∈
A; evasiveness – for non-target query q
q
returns the ground-truth answer
(cid:75)
(cid:74)
following loss function: (cid:96)kp(φK ∗)
Q ∗∆(γ(q; φK ∗), A) + λEq
= Eq

Q

Q ∗

∆(γ(q; φK ∗),

q
(cid:74)

)
(cid:75)

(3)

∈

\

∈
where ∆ is a metric (e.g., L2-norm) to measure the distance
between two query answers and λ is the hyper-parameter to
balance the two attack objectives. Note that here we assume
the embeddings of all the other entities are ﬁxed.

Approximation – At this step, we project the updated em-
beddings φ+
back to the input space to search for the optimal
K ∗
poisoning facts F ∗. Recall that the entity embedding function

4

Knowledge Graph <latexit sha1_base64="hNaJSd5ZoEOffcfr22TtbKcN9Zw=">AAAB8nicbVDLSgMxFL1TX7W+qi7dBIvgqsxIUZdFF7qsYB8wHUomzbShmWRIMkIZ+hluXCji1q9x59+YaWehrQcCh3PuJeeeMOFMG9f9dkpr6xubW+Xtys7u3v5B9fCoo2WqCG0TyaXqhVhTzgRtG2Y47SWK4jjktBtObnO/+0SVZlI8mmlCgxiPBIsYwcZKfj/GZkwwz+5mg2rNrbtzoFXiFaQGBVqD6ld/KEkaU2EIx1r7npuYIMPKMMLprNJPNU0wmeAR9S0VOKY6yOaRZ+jMKkMUSWWfMGiu/t7IcKz1NA7tZB5RL3u5+J/npya6DjImktRQQRYfRSlHRqL8fjRkihLDp5ZgopjNisgYK0yMbaliS/CWT14lnYu6d1lvPDRqzZuijjKcwCmcgwdX0IR7aEEbCEh4hld4c4zz4rw7H4vRklPsHMMfOJ8/fFqRZg==</latexit>GPoisoned factsPoisoned KG<latexit sha1_base64="jIQYhHESwLHtDQt5q8DPWaYs37I=">AAAB/3icbVBNS8NAEN3Ur1q/ooIXL8Ei1EtJpKjHohePFewHNKFsNptm6SYbdidCiT34V7x4UMSrf8Ob/8Ztm4O2Phh4vDfDzDw/5UyBbX8bpZXVtfWN8mZla3tnd8/cP+gokUlC20RwIXs+VpSzhLaBAae9VFIc+5x2/dHN1O8+UKmYSO5hnFIvxsOEhYxg0NLAPHLTiLmchlBzSSDAlWwYwdnArNp1ewZrmTgFqaICrYH55QaCZDFNgHCsVN+xU/ByLIERTicVN1M0xWSEh7SvaYJjqrx8dv/EOtVKYIVC6krAmqm/J3IcKzWOfd0ZY4jUojcV//P6GYRXXs6SNAOakPmiMOMWCGsahhUwSQnwsSaYSKZvtUiEJSagI6voEJzFl5dJ57zuXNQbd41q87qIo4yO0QmqIQddoia6RS3URgQ9omf0it6MJ+PFeDc+5q0lo5g5RH9gfP4A4G+WBQ==</latexit> (·)<latexit sha1_base64="nCFgH3RPks6BPeXntH8UyYMHR9M=">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE1GPRi8eK9gPaUDbbTbt0swm7k0IJ/QlePCji1V/kzX/jts1BWx8MPN6bYWZekEhh0HW/ncLa+sbmVnG7tLO7t39QPjxqmjjVjDdYLGPdDqjhUijeQIGStxPNaRRI3gpGdzO/NebaiFg94SThfkQHSoSCUbTS47iHvXLFrbpzkFXi5aQCOeq98le3H7M04gqZpMZ0PDdBP6MaBZN8WuqmhieUjeiAdyxVNOLGz+anTsmZVfokjLUthWSu/p7IaGTMJApsZ0RxaJa9mfif10kxvPEzoZIUuWKLRWEqCcZk9jfpC80ZyokllGlhbyVsSDVlaNMp2RC85ZdXSfOi6l1VLx8uK7XbPI4inMApnIMH11CDe6hDAxgM4Ble4c2Rzovz7nwsWgtOPnMMf+B8/gBxHo3q</latexit>vtOperatorw. w/ <latexit sha1_base64="3VPm2uqrrNwsX6xSDJp2KfMvPMc=">AAAB6HicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeiF48t2FpoQ9lsJ+3azSbsboQS+gu8eFDEqz/Jm//GbZuDtj4YeLw3w8y8IBFcG9f9dgpr6xubW8Xt0s7u3v5B+fCoreNUMWyxWMSqE1CNgktsGW4EdhKFNAoEPgTj25n/8IRK81jem0mCfkSHkoecUWOlZrNfrrhVdw6ySrycVCBHo1/+6g1ilkYoDRNU667nJsbPqDKcCZyWeqnGhLIxHWLXUkkj1H42P3RKzqwyIGGsbElD5urviYxGWk+iwHZG1Iz0sjcT//O6qQmv/YzLJDUo2WJRmApiYjL7mgy4QmbExBLKFLe3EjaiijJjsynZELzll1dJ+6LqXVZrzVqlfpPHUYQTOIVz8OAK6nAHDWgBA4RneIU359F5cd6dj0VrwclnjuEPnM8frguM3g==</latexit>QSurrogate query setfor each <latexit sha1_base64="5Olkr7fB4mfFPW7IeRIPI8ZwTfo=">AAAB/XicbVDLSsNAFL3xWesrPnZugkUQFyWRoi6LbgQ3FewDmhgm00k7dDIJMxOhhuCvuHGhiFv/w51/47TNQlsPDBzOuZd75gQJo1LZ9rexsLi0vLJaWiuvb2xubZs7uy0ZpwKTJo5ZLDoBkoRRTpqKKkY6iSAoChhpB8Orsd9+IELSmN+pUUK8CPU5DSlGSku+ue8mA+pnboTUACOW3eT3J7lvVuyqPYE1T5yCVKBAwze/3F6M04hwhRmSsuvYifIyJBTFjORlN5UkQXiI+qSrKUcRkV42SZ9bR1rpWWEs9OPKmqi/NzIUSTmKAj05TilnvbH4n9dNVXjhZZQnqSIcTw+FKbNUbI2rsHpUEKzYSBOEBdVZLTxAAmGlCyvrEpzZL8+T1mnVOavWbmuV+mVRRwkO4BCOwYFzqMM1NKAJGB7hGV7hzXgyXox342M6umAUO3vwB8bnD8bflXE=</latexit> K⇤<latexit sha1_base64="XDuqac5zg8RY5vcpnR6kPZdXYc8=">AAAB8XicbVBNSwMxEJ3Ur1q/qh69BIsgHsquFPVY9OKxBfuB7VqyabYNzWbXJCuUpf/CiwdFvPpvvPlvTNs9aOuDgcd7M8zM82PBtXGcb5RbWV1b38hvFra2d3b3ivsHTR0lirIGjUSk2j7RTHDJGoYbwdqxYiT0BWv5o5up33piSvNI3plxzLyQDCQPOCXGSvePuMslrj+c4V6x5JSdGfAycTNSggy1XvGr249oEjJpqCBad1wnNl5KlOFUsEmhm2gWEzoiA9axVJKQaS+dXTzBJ1bp4yBStqTBM/X3REpCrcehbztDYoZ60ZuK/3mdxARXXsplnBgm6XxRkAhsIjx9H/e5YtSIsSWEKm5vxXRIFKHGhlSwIbiLLy+T5nnZvShX6pVS9TqLIw9HcAyn4MIlVOEWatAAChKe4RXekEYv6B19zFtzKJs5hD9Anz/lRI/E</latexit>q2Q⇤<latexit sha1_base64="R2m25HBuFO7e4mNSvyqduDNFZVQ=">AAAB83icbVBNS8NAEJ3Ur1q/qh69LBZBPNREinosevHYgv2AJpbNdtMu3Wzi7kYooX/DiwdFvPpnvPlv3KY5aOuDgcd7M8zM82POlLbtb6uwsrq2vlHcLG1t7+zulfcP2ipKJKEtEvFIdn2sKGeCtjTTnHZjSXHoc9rxx7czv/NEpWKRuNeTmHohHgoWMIK1kdxH5DKBmufNhzPUL1fsqp0BLRMnJxXI0eiXv9xBRJKQCk04Vqrn2LH2Uiw1I5xOS26iaIzJGA9pz1CBQ6q8NLt5ik6MMkBBJE0JjTL190SKQ6UmoW86Q6xHatGbif95vUQH117KRJxoKsh8UZBwpCM0CwANmKRE84khmEhmbkVkhCUm2sRUMiE4iy8vk/ZF1bms1pq1Sv0mj6MIR3AMp+DAFdThDhrQAgIxPMMrvFmJ9WK9Wx/z1oKVzxzCH1ifP/dakFg=</latexit>q2Q/Q⇤Optimization Stepfor each OptimizedApproximation StepInput SpaceLatent Space<latexit sha1_base64="5Olkr7fB4mfFPW7IeRIPI8ZwTfo=">AAAB/XicbVDLSsNAFL3xWesrPnZugkUQFyWRoi6LbgQ3FewDmhgm00k7dDIJMxOhhuCvuHGhiFv/w51/47TNQlsPDBzOuZd75gQJo1LZ9rexsLi0vLJaWiuvb2xubZs7uy0ZpwKTJo5ZLDoBkoRRTpqKKkY6iSAoChhpB8Orsd9+IELSmN+pUUK8CPU5DSlGSku+ue8mA+pnboTUACOW3eT3J7lvVuyqPYE1T5yCVKBAwze/3F6M04hwhRmSsuvYifIyJBTFjORlN5UkQXiI+qSrKUcRkV42SZ9bR1rpWWEs9OPKmqi/NzIUSTmKAj05TilnvbH4n9dNVXjhZZQnqSIcTw+FKbNUbI2rsHpUEKzYSBOEBdVZLTxAAmGlCyvrEpzZL8+T1mnVOavWbmuV+mVRRwkO4BCOwYFzqMM1NKAJGB7hGV7hzXgyXox342M6umAUO3vwB8bnD8bflXE=</latexit> K⇤release to KG<latexit sha1_base64="wpBx72oF0qiyYCNVy5iB69bBrSE=">AAACD3icbVDLSsNAFJ3UV62vqEs3waJUFyWRoi6LbgQ3FewDmhgm02k7dDIZZiZCCfkDN/6KGxeKuHXrzr9xkmah1QMXDufcy733BJwSqWz7yygtLC4tr5RXK2vrG5tb5vZOR0axQLiNIhqJXgAlpoThtiKK4h4XGIYBxd1gcpn53XssJInYrZpy7IVwxMiQIKi05JuHLqbUd0OoxiJMJjytuXxM/CRXEKTJdXp3nB75ZtWu2zmsv8QpSBUUaPnmpzuIUBxiphCFUvYdmysvgUIRRHFacWOJOUQTOMJ9TRkMsfSS/J/UOtDKwBpGQhdTVq7+nEhgKOU0DHRndqac9zLxP68fq+G5lxDGY4UZmi0axtRSkZWFYw2IwEjRqSYQCaJvtdAYCoiUjrCiQ3DmX/5LOid157TeuGlUmxdFHGWwB/ZBDTjgDDTBFWiBNkDgATyBF/BqPBrPxpvxPmstGcXMLvgF4+Mb0eedJg==</latexit>`kp( K⇤)<latexit sha1_base64="93PZ215+G48A1Lb1TwNJa5EqqVE=">AAAB+3icbVDLSsNAFL2pr1pfsS7dDBbBVUmkqMuiC11WsA9oQphMJ+3QyYOZiVhCfsWNC0Xc+iPu/BsnbRbaemDgcM693DPHTziTyrK+jcra+sbmVnW7trO7t39gHtZ7Mk4FoV0S81gMfCwpZxHtKqY4HSSC4tDntO9Pbwq//0iFZHH0oGYJdUM8jljACFZa8sy6k0yYlzkhVhOCeXab557ZsJrWHGiV2CVpQImOZ345o5ikIY0U4VjKoW0lys2wUIxwmtecVNIEkyke06GmEQ6pdLN59hydamWEgljoFyk0V39vZDiUchb6erLIKJe9QvzPG6YquHIzFiWpohFZHApSjlSMiiLQiAlKFJ9pgolgOisiEywwUbqumi7BXv7yKumdN+2LZuu+1Whfl3VU4RhO4AxsuIQ23EEHukDgCZ7hFd6M3Hgx3o2PxWjFKHeO4A+Mzx+ZhpTR</latexit> G<latexit sha1_base64="4GEDiIpvYooyaSF5Jb/YyTe492E=">AAACDHicbVDLSsNAFJ3UV62vqks3g0WsiCWRoi6LblxWsA9oYphMp+3QySTMTAol7Qe48VfcuFDErR/gzr9xkmahrQcGDuecy517vJBRqUzz28gtLa+sruXXCxubW9s7xd29pgwigUkDBywQbQ9JwignDUUVI+1QEOR7jLS84U3it0ZESBrwezUOieOjPqc9ipHSklss2RNoh5K6omyHA+qOHk5P4BlMeTw6nkJ7UtAps2KmgIvEykgJZKi7xS+7G+DIJ1xhhqTsWGaonBgJRTEj04IdSRIiPER90tGUI59IJ06PmcIjrXRhLxD6cQVT9fdEjHwpx76nkz5SAznvJeJ/XidSvSsnpjyMFOF4tqgXMagCmDQDu1QQrNhYE4QF1X+FeIAEwkr3l5RgzZ+8SJrnFeuiUr2rlmrXWR15cAAOQRlY4BLUwC2ogwbA4BE8g1fwZjwZL8a78TGL5oxsZh/8gfH5AzMXmc8=</latexit>k r( +v)  v0k<latexit sha1_base64="w6irj2OC8YWiVZmiTkQ48XGqFcg=">AAAB/3icbVDLSsNAFJ3UV62vqODGzWARRKEkUtRl0Y3gpoJ9QJOGyXTSDp1MwsxEKDELf8WNC0Xc+hvu/BsnbRZaPTBwOOde7pnjx4xKZVlfRmlhcWl5pbxaWVvf2Nwyt3faMkoEJi0csUh0fSQJo5y0FFWMdGNBUOgz0vHHV7nfuSdC0ojfqUlM3BANOQ0oRkpLnrnnxCPqpU6I1Agjlt5k/eOsf+KZVatmTQH/ErsgVVCg6ZmfziDCSUi4wgxJ2bOtWLkpEopiRrKKk0gSIzxGQ9LTlKOQSDed5s/goVYGMIiEflzBqfpzI0WhlJPQ15N5Tjnv5eJ/Xi9RwYWbUh4ninA8OxQkDKoI5mXAARUEKzbRBGFBdVaIR0ggrHRlFV2CPf/lv6R9WrPPavXberVxWdRRBvvgABwBG5yDBrgGTdACGDyAJ/ACXo1H49l4M95noyWj2NkFv2B8fAPxLpYO</latexit> +K⇤<latexit sha1_base64="E7xZGKtEKPMqq0qkPkeGtBL3ZjM=">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoMgHsKuBPUY9OIxonlAsobZSScZMju7zMwKYcknePGgiFe/yJt/4yTZgyYWNBRV3XR3BbHg2rjut5NbWV1b38hvFra2d3b3ivsHDR0limGdRSJSrYBqFFxi3XAjsBUrpGEgsBmMbqZ+8wmV5pF8MOMY/ZAOJO9zRo2V7uPHs26x5JbdGcgy8TJSggy1bvGr04tYEqI0TFCt254bGz+lynAmcFLoJBpjykZ0gG1LJQ1R++ns1Ak5sUqP9CNlSxoyU39PpDTUehwGtjOkZqgXvan4n9dOTP/KT7mME4OSzRf1E0FMRKZ/kx5XyIwYW0KZ4vZWwoZUUWZsOgUbgrf48jJpnJe9i3LlrlKqXmdx5OEIjuEUPLiEKtxCDerAYADP8ApvjnBenHfnY96ac7KZQ/gD5/MH9j6NmQ==</latexit>p⇤<latexit sha1_base64="E7xZGKtEKPMqq0qkPkeGtBL3ZjM=">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoMgHsKuBPUY9OIxonlAsobZSScZMju7zMwKYcknePGgiFe/yJt/4yTZgyYWNBRV3XR3BbHg2rjut5NbWV1b38hvFra2d3b3ivsHDR0limGdRSJSrYBqFFxi3XAjsBUrpGEgsBmMbqZ+8wmV5pF8MOMY/ZAOJO9zRo2V7uPHs26x5JbdGcgy8TJSggy1bvGr04tYEqI0TFCt254bGz+lynAmcFLoJBpjykZ0gG1LJQ1R++ns1Ak5sUqP9CNlSxoyU39PpDTUehwGtjOkZqgXvan4n9dOTP/KT7mME4OSzRf1E0FMRKZ/kx5XyIwYW0KZ4vZWwoZUUWZsOgUbgrf48jJpnJe9i3LlrlKqXmdx5OEIjuEUPLiEKtxCDerAYADP8ApvjnBenHfnY96ac7KZQ/gD5/MH9j6NmQ==</latexit>p⇤<latexit sha1_base64="Smls7Mcl0q1RkMkg1ve7161vI70=">AAAB9HicbVDLSsNAFL2pr1pfVZduBosgLkoiRV0WBXFZwT6gjWUynbRDJ5M4MymUkO9w40IRt36MO//GSZuFth4YOJxzL/fM8SLOlLbtb6uwsrq2vlHcLG1t7+zulfcPWiqMJaFNEvJQdjysKGeCNjXTnHYiSXHgcdr2xjeZ355QqVgoHvQ0om6Ah4L5jGBtJLcXYD0imCe36eNZv1yxq/YMaJk4OalAjka//NUbhCQOqNCEY6W6jh1pN8FSM8JpWurFikaYjPGQdg0VOKDKTWahU3RilAHyQ2me0Gim/t5IcKDUNPDMZBZSLXqZ+J/XjbV/5SZMRLGmgswP+TFHOkRZA2jAJCWaTw3BRDKTFZERlpho01PJlOAsfnmZtM6rzkW1dl+r1K/zOopwBMdwCg5cQh3uoAFNIPAEz/AKb9bEerHerY/5aMHKdw7hD6zPH5w8kgE=</latexit>F⇤<latexit sha1_base64="+TFYNyYabs+TlY+XSMX6d7iQOV0=">AAACAnicbZDLSsNAFIZP6q3WW9SVuBksgiiURIq6LArqsoK9QBvLZDpth04uzEyEEoIbX8WNC0Xc+hTufBsnbRBt/WHg4z/nMOf8bsiZVJb1ZeTm5hcWl/LLhZXVtfUNc3OrLoNIEFojAQ9E08WScubTmmKK02YoKPZcThvu8CKtN+6pkCzwb9UopI6H+z7rMYKVtjrmTtvDakAwj6+Sox++TO4OO2bRKlljoVmwMyhCpmrH/Gx3AxJ51FeEYylbthUqJ8ZCMcJpUmhHkoaYDHGftjT62KPSiccnJGhfO13UC4R+vkJj9/dEjD0pR56rO9Ml5XQtNf+rtSLVO3Ni5oeRoj6ZfNSLOFIBSvNAXSYoUXykARPB9K6IDLDAROnUCjoEe/rkWagfl+yTUvmmXKycZ3HkYRf24ABsOIUKXEMVakDgAZ7gBV6NR+PZeDPeJ605I5vZhj8yPr4BKyuXSg==</latexit>G+F⇤facts with min distance<latexit sha1_base64="hOs4ha8iO1Jq8RRsI0S7K1Fa3ko=">AAAB/XicbVDLSsNAFL2pr1pf8bFzM1hEVyWRoi6LblxWsA9oQ5lMJ+3QSSbMTKo1FH/FjQtF3Pof7vwbp20W2nrgwuGce7n3Hj/mTGnH+bZyS8srq2v59cLG5tb2jr27V1cikYTWiOBCNn2sKGcRrWmmOW3GkuLQ57ThD64nfmNIpWIiutOjmHoh7kUsYARrI3XsgyFqP0jW62sspbhP5RgNTzp20Sk5U6BF4makCBmqHfur3RUkCWmkCcdKtVwn1l6KpWaE03GhnSgaYzLAPdoyNMIhVV46vX6Mjo3SRYGQpiKNpurviRSHSo1C33SGWPfVvDcR//NaiQ4uvZRFcaJpRGaLgoQjLdAkCtRlkhLNR4ZgIpm5FZE+lphoE1jBhODOv7xI6mcl97xUvi0XK1dZHHk4hCM4BRcuoAI3UIUaEHiEZ3iFN+vJerHerY9Za87KZvbhD6zPH5zOlVY=</latexit>vr !v0<latexit sha1_base64="EJjGfNPswICC71zyIkA/oMdej+w=">AAAB6nicbVDLSgNBEOz1GeMr6tHLYBDEQ9iVoB6DXjwmaB6QrGF2MpsMmZ1dZnqFEPIJXjwo4tUv8ubfOEn2oIkFDUVVN91dQSKFQdf9dlZW19Y3NnNb+e2d3b39wsFhw8SpZrzOYhnrVkANl0LxOgqUvJVoTqNA8mYwvJ36zSeujYjVA44S7ke0r0QoGEUr3dcez7uFoltyZyDLxMtIETJUu4WvTi9macQVMkmNaXtugv6YahRM8km+kxqeUDakfd62VNGIG388O3VCTq3SI2GsbSkkM/X3xJhGxoyiwHZGFAdm0ZuK/3ntFMNrfyxUkiJXbL4oTCXBmEz/Jj2hOUM5soQyLeythA2opgxtOnkbgrf48jJpXJS8y1K5Vi5WbrI4cnAMJ3AGHlxBBe6gCnVg0IdneIU3RzovzrvzMW9dcbKZI/gD5/MHxwSNeg==</latexit>Q⇤<latexit sha1_base64="ZoNHKzxmEqk809U0qI3MKfK3by0=">AAAB7HicbVBNSwMxEJ31s9avqkcvwSKIh7orRT0WvXhswW0L7VqyabYNTbJLkhXK0t/gxYMiXv1B3vw3pu0etPXBwOO9GWbmhQln2rjut7Oyura+sVnYKm7v7O7tlw4OmzpOFaE+iXms2iHWlDNJfcMMp+1EUSxCTlvh6G7qt56o0iyWD2ac0EDggWQRI9hYyW9cNB7Pe6WyW3FnQMvEy0kZctR7pa9uPyapoNIQjrXueG5iggwrwwink2I31TTBZIQHtGOpxILqIJsdO0GnVumjKFa2pEEz9fdEhoXWYxHaToHNUC96U/E/r5Oa6CbImExSQyWZL4pSjkyMpp+jPlOUGD62BBPF7K2IDLHCxNh8ijYEb/HlZdK8rHhXlWqjWq7d5nEU4BhO4Aw8uIYa3EMdfCDA4Ble4c2Rzovz7nzMW1ecfOYI/sD5/AHUto4O</latexit>Q/Q⇤<latexit sha1_base64="G1TzovT04WsZLpG6zj72aWb/Q2E=">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0lE1GPRi8cKpi20oWy2m3bpZhN2J0Ip/Q1ePCji1R/kzX/jps1BWx8MPN6bYWZemEph0HW/ndLa+sbmVnm7srO7t39QPTxqmSTTjPsskYnuhNRwKRT3UaDknVRzGoeSt8PxXe63n7g2IlGPOEl5ENOhEpFgFK3k91IjKv1qza27c5BV4hWkBgWa/epXb5CwLOYKmaTGdD03xWBKNQom+azSywxPKRvTIe9aqmjMTTCdHzsjZ1YZkCjRthSSufp7YkpjYyZxaDtjiiOz7OXif143w+gmmAqVZsgVWyyKMkkwIfnnZCA0ZygnllCmhb2VsBHVlKHNJw/BW355lbQu6t5V/fLhsta4LeIowwmcwjl4cA0NuIcm+MBAwDO8wpujnBfn3flYtJacYuYY/sD5/AFc545n</latexit> .

φ is non-differentiable, it is impractical to directly optimize
F ∗. Instead, we adopt a retrograde search approach to search
for F ∗ that leads to embeddings best approximate φ+
K ∗

Speciﬁcally, we use the relation r-speciﬁc transformation
function ψr to assess the quality of candidate facts. Recall that
ψr(φv) computes entities with relation r to v. We enumerate
each candidate fact v r
v(cid:48) wherein v
K ∗ and v(cid:48) ∈
−→
\
K ∗ under the updated embedding φ+
v and select the top-nkp
ψr(φ+
.
candidate facts with the minimum distance of
φv(cid:48)(cid:107)
v )
Intuitively, adding such facts to G tends to force K ∗ to be
projected to φ+
. The algorithm is sketched in Algorithm 1.
K ∗

N

−

∈

(cid:107)

Algorithm 1: Retrograde Search

Input: N – entities in KG G; K ∗ – anchors of trigger pattern p∗;

φ+
v – updated embedding of v
v(cid:48) ∈
nkp – budget of poisoning facts

N

\

∈

K ∗; ψr – relation r-speciﬁc embedding function;

K ∗; φv(cid:48)

– embedding of

Output: F ∗ – poisoning facts
// initialize

/0;

1 L
←
2 foreach v
3

K ∗ do
∈
foreach v(cid:48) ∈
N
foreach r

K ∗ do
\
R do
∈

4

5

6

7

// compute fitting scores
if v r
v(cid:48) is legitimate then
−→
ψr(φ+
compute
;
φv(cid:48) (cid:107)
v )
(cid:107)
−
v r
ψr(φ+
v(cid:48),
add
φv(cid:48) (cid:107)(cid:105)
v )
(cid:107)
−→
(cid:104)
−

to L;

8 sort L in descending order of distance ;
9 return the top-nkp facts in L as F ∗;

,
|

N
|

K ∗|
|

The overall complexity of Algorithm 1 is O(
N
|

),
|
, and R respectively denote the numbers of
where
entities in G, anchors in trigger pattern p∗, and relation types.
Further, by taking into account the domain constraints of K ∗
(e.g., certain facts are implausible), the practical complexity
tends to be much lower.

R
K ∗||
||

4.3 Query perturbation

Query perturbation attempts to direct the answering of Q ∗ to
target answer A by generating adversarial query q∗ from its
benign counterpart q. We consider q∗ as the conjunction of
q and additional logical constraint q+: q∗ = q
q+. To make
the perturbation evasive, we require that (i) the number of
logical paths in q+ is limited by a threshold nqp and (ii) the
dependency graph of q∗ is valid with respect to G.

∧

Note that while there are potentially combinatorial ways
to generate q+, it is often effective to limit q+ to the vicin-
q
, which results in more direct
ity of ground-truth answer
(cid:75)
inﬂuence on altering the query answer.

(cid:74)

At a high level, query perturbation adopts the OTA frame-
work. At the optimization step, we optimize the embedding
φq∗ of q∗ with respect to the attack objective; at the approxi-
mation step, we further search for potential perturbation q+
that leads to the embedding most similar to φq∗. Below we
elaborate on these two steps.

Optimization – At this step, we optimize the embedding
φq∗ with respect to target answer A. Recall that q∗ is the con-
junction of query q and perturbation q+. We thus deﬁne the
following loss function:

(cid:96)qp(φq+) = ∆(ψ

(φq, φq+), A)

∧

(4)

∧

is the relation

where ψ
-speciﬁc transformation function, ∆
is the same distance function as in Eq. 3, and φq is computed
using the current embedding model. We then optimize φq+
via backpropagation.

∧

Approximation – At this step, we search for candidate
perturbation q+ (input space) that leads to embeddings best
approximating φq+.

Recall that in the embedding space q+ is represented as a
directed acyclic graph, which starts with the embeddings of
its anchor entities, follows the geometric transformation of
its relations, and eventually reaches φq+. We thus reverse this
process to reconstruct q+. However, the complexity of brute-
force search (e.g., breadth-ﬁrst search) grows exponentially
with the search depth. Instead, we adopt beam search [43], a
greedy strategy, to search for q+.

Speciﬁcally, starting with the entity closest to φq+ in the
latent space as the root, we expand q+ in a level-wise manner
until reaching any pre-deﬁned anchor entities. At each level,
the search enumerates all the neighboring entities in G, con-
structs the corresponding structures, and selects the top-nqp
candidate structures that lead to embeddings closest to φq+.
A running example is illustrated in Figure 4.

|

The search complexity depends on the depth of q+, the
perturbation budget nqp, and the number of candidate entities
in G. In the worst case, the expansion at each level examines
candidate structures and selects the top-nqp ones, thus
N
|
). As the depth of q+
featuring the complexity of O(nqp
N
|
|
G , the diameter of G, the overall complexity
is less than
is thus O(nqp
). In practice, however, as the number
(cid:31)
G |
|
of candidate entities is much smaller than
, the practical
(cid:31)
|
complexity tends to be much lower.

N
|

N

4.4 Knowledge-Query co-optimization

Recall that to direct the answering of a query set Q ∗ (that
shares a speciﬁc pattern p∗) to target answer A, the adver-
sary either commits poisoning facts F ∗ to G or perturbs the
queries in Q ∗. If the adversary is able to leverage both knowl-
edge poisoning and query perturbation, by accounting for the
possible perturbation to Q ∗ (at inference time), it is possible
to construct more effective poisoning facts F ∗. We thus pro-
pose a co-optimization framework that optimizes poisoning
knowledge and adversarial queries jointly, leading to more
effective attacks.

As sketched in Algorithm 2, the co-optimization attack it-
erates between knowledge poisoning and query perturbation:
at the i-th iteration, in the knowledge poisoning stage, it gen-
erates poisoning facts with respect to the current adversarial

5

Figure 4: Illustration of constructing q+ via beam search.

Algorithm 2: Knowledge-Query Co-optimization

Input: Q ∗ – target query set; G – KG; niter – number of iterations
Output: poisoning facts to G; adversarial queries of Q ∗
// initialize

is designed to answer the following questions: Q1 – Is ROAR
effective against KRL systems in practice? Q2 – How does the
effectiveness of its variants differ? Q3 – What factors impact
the performance of ROAR?

5.1 Experimental setup

1);
−

We begin by describing the evaluation setting.

/0;

1 L
←
2 Q (0)
Q ∗;
3 for i = 1, . . . , niter do

←

// knowledge poisoning
generate poisoning facts F ∗ with respect to Q (i
add F ∗ to G as G (i);
// query perturbation
foreach q

Q ∗ do

∈

generate adversarial query q∗ with respect to G (i);
add q∗ to Q (i);

4

5

6

7

8

9 return G (niter)

G and Q (niter);

\
queries Q (i
1); in the query perturbation, it generates ad-
−
versarial queries with respect to the updated KG G (i). The
process iterates until convergence.

4.5 Extension

We now discuss the extension of ROAR to other settings.

Black-box attacks – Without knowledge regarding encoder
φ or operator ψ, the adversary may resort to surrogate models
to approximate φ or ψ. For instance, it is empirically shown
that TransE [9] and TransR [23], two widely used entity em-
bedding models, have fairly similar behavior. It is thus pos-
sible to generate poisoning facts/adversarial queries on the
surrogate model and then transfer the attack to the target sys-
tem.

Untargeted attacks – An untargeted attack aims to direct the
answering of target queries Q ∗ to erroneous answers rather
than a speciﬁc answer A. Thus, at the optimization stage of the
attack (Eq. 3 and Eq. 4), instead of minimizing the distance
between the answer of q
Q ∗ and A, the adversary may
maximize the distance between the answer of q and its ground-
truth answer

. For instance, we may re-deﬁne Eq. 4 as:

∈

q
(cid:75)

(cid:74)
(cid:96)qp(φq+) =

∆(ψ
∧

−

(φq, φq+),

)

q
(cid:75)

(cid:74)

5 Case Study I: Cyber-Threat Hunting

Scenario – With the explosive growth of cyber-threat in-
telligence, it becomes imperative for security analysts to rely
on automated tools to extract useful, actionable intelligence
for given incidents [29, 30]. Here, we consider a KRL system
built upon cyber-threat KGs (e.g., attack tactics, vulnerabili-
ties, ﬁxes), which supports the following queries:

Vulnerability – Given certain observations regarding the
incident (e.g., affected products/versions, attack tactics, or
campaigns), it ﬁnds the most likely vulnerabilities (e.g., CVEs)
that are being exploited.

Mitigation – Beyond the vulnerabilities being attacks, it
may further suggest potential solutions (e.g., patches and
workarounds) to mitigate such vulnerabilities.

Besides querying for known vulnerabilities, we also con-
sider a zero-day setting wherein the attacks exploit previously
unknown vulnerabilities.

CyberKG – We construct the CyberKG using cyber-threat
intelligence from three sources: (i) public CVE reports2; (ii)
BRON threat graph [20]; (iii) National Vulnerability Database
(NVD)3.

– From (i), we collect known CVE as potential vulnerabili-
ties, each associated with affected product, version, vendor,
CWE4, and threat campaign.

– From (ii), we extract attack tactic, technique and pattern,

and link them with (i) based on CVE codes.

– From (iii), we collect mitigation for each CVE and assign

a speciﬁc code to each mitigation approach.

The logical structures of the resulted KG is illustrated in

(5)

Figure 11, with its statistics summarized in Table 14.

Query – To construct queries, for given CVE or mitigation,
we randomly select anchors from the remaining entities (e.g.,

Next, we conduct an empirical evaluation of ROAR in the
concrete case of cyber-threat intelligence reasoning. Our study

2https://www.cvedetails.com
3https://nvd.nist.gov
4https://cwe.mitre.org

6

candidate anchor entitiesExpand one layer to semantically legal entitiesOptimizedSTEP 1STEP 2STEP 3STEP 4STEP 5STEP 6STEP 7Keep top-n (=2) paths whose embeddings are closest to  Expand to next layer with kept pathsExpand until reach to candidate anchorsThe remained top-n (=2) paths are  Given optimized        , ﬁnd an entity (answer) with closest embeddingKeep top n (=2) paths whose embeddings are closest to <latexit sha1_base64="k5Mj3JDpUYDx41P2sczfUVHzuVc=">AAAB8XicbVDLSgNBEOz1GeMr6tHLYBAEIexKUI9BLx4jmAcma5id9CZDZmfXmVkhLPkLLx4U8erfePNvnDwOmljQUFR1090VJIJr47rfztLyyuraem4jv7m1vbNb2Nuv6zhVDGssFrFqBlSj4BJrhhuBzUQhjQKBjWBwPfYbT6g0j+WdGSboR7QnecgZNVa6byd93skeH05HnULRLbkTkEXizUgRZqh2Cl/tbszSCKVhgmrd8tzE+BlVhjOBo3w71ZhQNqA9bFkqaYTazyYXj8ixVbokjJUtachE/T2R0UjrYRTYzoiavp73xuJ/Xis14aWfcZmkBiWbLgpTQUxMxu+TLlfIjBhaQpni9lbC+lRRZmxIeRuCN//yIqmflbzzUvm2XKxczeLIwSEcwQl4cAEVuIEq1ICBhGd4hTdHOy/Ou/MxbV1yZjMH8AfO5w+Gv5DV</latexit> q+<latexit sha1_base64="k5Mj3JDpUYDx41P2sczfUVHzuVc=">AAAB8XicbVDLSgNBEOz1GeMr6tHLYBAEIexKUI9BLx4jmAcma5id9CZDZmfXmVkhLPkLLx4U8erfePNvnDwOmljQUFR1090VJIJr47rfztLyyuraem4jv7m1vbNb2Nuv6zhVDGssFrFqBlSj4BJrhhuBzUQhjQKBjWBwPfYbT6g0j+WdGSboR7QnecgZNVa6byd93skeH05HnULRLbkTkEXizUgRZqh2Cl/tbszSCKVhgmrd8tzE+BlVhjOBo3w71ZhQNqA9bFkqaYTazyYXj8ixVbokjJUtachE/T2R0UjrYRTYzoiavp73xuJ/Xis14aWfcZmkBiWbLgpTQUxMxu+TLlfIjBhaQpni9lbC+lRRZmxIeRuCN//yIqmflbzzUvm2XKxczeLIwSEcwQl4cAEVuIEq1ICBhGd4hTdHOy/Ou/MxbV1yZjMH8AfO5w+Gv5DV</latexit> q+<latexit sha1_base64="PE0HDwtOprLAxoxD3SiI3AQUjmY=">AAAB7HicbVBNSwMxEJ2tX7V+VT16CRZBEMquFPVY9OKxgtsW2rVk02wbmk3WJCuUpb/BiwdFvPqDvPlvTNs9aOuDgcd7M8zMCxPOtHHdb6ewsrq2vlHcLG1t7+zulfcPmlqmilCfSC5VO8Saciaob5jhtJ0oiuOQ01Y4upn6rSeqNJPi3owTGsR4IFjECDZW8rPHh7NJr1xxq+4MaJl4OalAjkav/NXtS5LGVBjCsdYdz01MkGFlGOF0UuqmmiaYjPCAdiwVOKY6yGbHTtCJVfooksqWMGim/p7IcKz1OA5tZ4zNUC96U/E/r5Oa6CrImEhSQwWZL4pSjoxE089RnylKDB9bgoli9lZEhlhhYmw+JRuCt/jyMmmeV72Lau2uVqlf53EU4QiO4RQ8uIQ63EIDfCDA4Ble4c0Rzovz7nzMWwtOPnMIf+B8/gC9/o6n</latexit>q+STEP 7<latexit sha1_base64="k5Mj3JDpUYDx41P2sczfUVHzuVc=">AAAB8XicbVDLSgNBEOz1GeMr6tHLYBAEIexKUI9BLx4jmAcma5id9CZDZmfXmVkhLPkLLx4U8erfePNvnDwOmljQUFR1090VJIJr47rfztLyyuraem4jv7m1vbNb2Nuv6zhVDGssFrFqBlSj4BJrhhuBzUQhjQKBjWBwPfYbT6g0j+WdGSboR7QnecgZNVa6byd93skeH05HnULRLbkTkEXizUgRZqh2Cl/tbszSCKVhgmrd8tzE+BlVhjOBo3w71ZhQNqA9bFkqaYTazyYXj8ixVbokjJUtachE/T2R0UjrYRTYzoiavp73xuJ/Xis14aWfcZmkBiWbLgpTQUxMxu+TLlfIjBhaQpni9lbC+lRRZmxIeRuCN//yIqmflbzzUvm2XKxczeLIwSEcwQl4cAEVuIEq1ICBhGd4hTdHOy/Ou/MxbV1yZjMH8AfO5w+Gv5DV</latexit> q+<latexit sha1_base64="k5Mj3JDpUYDx41P2sczfUVHzuVc=">AAAB8XicbVDLSgNBEOz1GeMr6tHLYBAEIexKUI9BLx4jmAcma5id9CZDZmfXmVkhLPkLLx4U8erfePNvnDwOmljQUFR1090VJIJr47rfztLyyuraem4jv7m1vbNb2Nuv6zhVDGssFrFqBlSj4BJrhhuBzUQhjQKBjWBwPfYbT6g0j+WdGSboR7QnecgZNVa6byd93skeH05HnULRLbkTkEXizUgRZqh2Cl/tbszSCKVhgmrd8tzE+BlVhjOBo3w71ZhQNqA9bFkqaYTazyYXj8ixVbokjJUtachE/T2R0UjrYRTYzoiavp73xuJ/Xis14aWfcZmkBiWbLgpTQUxMxu+TLlfIjBhaQpni9lbC+lRRZmxIeRuCN//yIqmflbzzUvm2XKxczeLIwSEcwQl4cAEVuIEq1ICBhGd4hTdHOy/Ou/MxbV1yZjMH8AfO5w+Gv5DV</latexit> q+Optimized<latexit sha1_base64="k5Mj3JDpUYDx41P2sczfUVHzuVc=">AAAB8XicbVDLSgNBEOz1GeMr6tHLYBAEIexKUI9BLx4jmAcma5id9CZDZmfXmVkhLPkLLx4U8erfePNvnDwOmljQUFR1090VJIJr47rfztLyyuraem4jv7m1vbNb2Nuv6zhVDGssFrFqBlSj4BJrhhuBzUQhjQKBjWBwPfYbT6g0j+WdGSboR7QnecgZNVa6byd93skeH05HnULRLbkTkEXizUgRZqh2Cl/tbszSCKVhgmrd8tzE+BlVhjOBo3w71ZhQNqA9bFkqaYTazyYXj8ixVbokjJUtachE/T2R0UjrYRTYzoiavp73xuJ/Xis14aWfcZmkBiWbLgpTQUxMxu+TLlfIjBhaQpni9lbC+lRRZmxIeRuCN//yIqmflbzzUvm2XKxczeLIwSEcwQl4cAEVuIEq1ICBhGd4hTdHOy/Ou/MxbV1yZjMH8AfO5w+Gv5DV</latexit> q+Optimized<latexit sha1_base64="k5Mj3JDpUYDx41P2sczfUVHzuVc=">AAAB8XicbVDLSgNBEOz1GeMr6tHLYBAEIexKUI9BLx4jmAcma5id9CZDZmfXmVkhLPkLLx4U8erfePNvnDwOmljQUFR1090VJIJr47rfztLyyuraem4jv7m1vbNb2Nuv6zhVDGssFrFqBlSj4BJrhhuBzUQhjQKBjWBwPfYbT6g0j+WdGSboR7QnecgZNVa6byd93skeH05HnULRLbkTkEXizUgRZqh2Cl/tbszSCKVhgmrd8tzE+BlVhjOBo3w71ZhQNqA9bFkqaYTazyYXj8ixVbokjJUtachE/T2R0UjrYRTYzoiavp73xuJ/Xis14aWfcZmkBiWbLgpTQUxMxu+TLlfIjBhaQpni9lbC+lRRZmxIeRuCN//yIqmflbzzUvm2XKxczeLIwSEcwQl4cAEVuIEq1ICBhGd4hTdHOy/Ou/MxbV1yZjMH8AfO5w+Gv5DV</latexit> q+Optimized<latexit sha1_base64="k5Mj3JDpUYDx41P2sczfUVHzuVc=">AAAB8XicbVDLSgNBEOz1GeMr6tHLYBAEIexKUI9BLx4jmAcma5id9CZDZmfXmVkhLPkLLx4U8erfePNvnDwOmljQUFR1090VJIJr47rfztLyyuraem4jv7m1vbNb2Nuv6zhVDGssFrFqBlSj4BJrhhuBzUQhjQKBjWBwPfYbT6g0j+WdGSboR7QnecgZNVa6byd93skeH05HnULRLbkTkEXizUgRZqh2Cl/tbszSCKVhgmrd8tzE+BlVhjOBo3w71ZhQNqA9bFkqaYTazyYXj8ixVbokjJUtachE/T2R0UjrYRTYzoiavp73xuJ/Xis14aWfcZmkBiWbLgpTQUxMxu+TLlfIjBhaQpni9lbC+lRRZmxIeRuCN//yIqmflbzzUvm2XKxczeLIwSEcwQl4cAEVuIEq1ICBhGd4hTdHOy/Ou/MxbV1yZjMH8AfO5w+Gv5DV</latexit> q+Optimized<latexit sha1_base64="k5Mj3JDpUYDx41P2sczfUVHzuVc=">AAAB8XicbVDLSgNBEOz1GeMr6tHLYBAEIexKUI9BLx4jmAcma5id9CZDZmfXmVkhLPkLLx4U8erfePNvnDwOmljQUFR1090VJIJr47rfztLyyuraem4jv7m1vbNb2Nuv6zhVDGssFrFqBlSj4BJrhhuBzUQhjQKBjWBwPfYbT6g0j+WdGSboR7QnecgZNVa6byd93skeH05HnULRLbkTkEXizUgRZqh2Cl/tbszSCKVhgmrd8tzE+BlVhjOBo3w71ZhQNqA9bFkqaYTazyYXj8ixVbokjJUtachE/T2R0UjrYRTYzoiavp73xuJ/Xis14aWfcZmkBiWbLgpTQUxMxu+TLlfIjBhaQpni9lbC+lRRZmxIeRuCN//yIqmflbzzUvm2XKxczeLIwSEcwQl4cAEVuIEq1ICBhGd4hTdHOy/Ou/MxbV1yZjMH8AfO5w+Gv5DV</latexit> q+Optimized<latexit sha1_base64="k5Mj3JDpUYDx41P2sczfUVHzuVc=">AAAB8XicbVDLSgNBEOz1GeMr6tHLYBAEIexKUI9BLx4jmAcma5id9CZDZmfXmVkhLPkLLx4U8erfePNvnDwOmljQUFR1090VJIJr47rfztLyyuraem4jv7m1vbNb2Nuv6zhVDGssFrFqBlSj4BJrhhuBzUQhjQKBjWBwPfYbT6g0j+WdGSboR7QnecgZNVa6byd93skeH05HnULRLbkTkEXizUgRZqh2Cl/tbszSCKVhgmrd8tzE+BlVhjOBo3w71ZhQNqA9bFkqaYTazyYXj8ixVbokjJUtachE/T2R0UjrYRTYzoiavp73xuJ/Xis14aWfcZmkBiWbLgpTQUxMxu+TLlfIjBhaQpni9lbC+lRRZmxIeRuCN//yIqmflbzzUvm2XKxczeLIwSEcwQl4cAEVuIEq1ICBhGd4hTdHOy/Ou/MxbV1yZjMH8AfO5w+Gv5DV</latexit> q+Optimized<latexit sha1_base64="k5Mj3JDpUYDx41P2sczfUVHzuVc=">AAAB8XicbVDLSgNBEOz1GeMr6tHLYBAEIexKUI9BLx4jmAcma5id9CZDZmfXmVkhLPkLLx4U8erfePNvnDwOmljQUFR1090VJIJr47rfztLyyuraem4jv7m1vbNb2Nuv6zhVDGssFrFqBlSj4BJrhhuBzUQhjQKBjWBwPfYbT6g0j+WdGSboR7QnecgZNVa6byd93skeH05HnULRLbkTkEXizUgRZqh2Cl/tbszSCKVhgmrd8tzE+BlVhjOBo3w71ZhQNqA9bFkqaYTazyYXj8ixVbokjJUtachE/T2R0UjrYRTYzoiavp73xuJ/Xis14aWfcZmkBiWbLgpTQUxMxu+TLlfIjBhaQpni9lbC+lRRZmxIeRuCN//yIqmflbzzUvm2XKxczeLIwSEcwQl4cAEVuIEq1ICBhGd4hTdHOy/Ou/MxbV1yZjMH8AfO5w+Gv5DV</latexit> q+affected product, attack pattern, and threat campaign) and
formulate the queries based on their logical structures in the
KG. Figure 12 shows the logical paths with different anchor
entities, which are combined to formulate the query templates
as shown in Figure 13. In the evaluation, we generate 500
queries for each query template.

KRL – We apply Query2Box [38], a state-of-the-art KRL
approach, to build the reasoning system. Intuitively, by adopt-
ing box embeddings (i.e., hyper-rectangles), Query2Box nat-
urally handles ﬁrst-order conjunctive queries.
MRR NDCG@5

Query

Vulnerability
Mitigation

0.61
0.47

0.76
0.66

Table 2. KRL performance in cyber-threat hunting.

Metrics – In this case study, we mainly use two metrics to

evaluate the performance of KRL and attacks:

MRR – It computes the average reciprocal ranks of all
the ground-truth answers across all the queries. This metric
measures the global ranking quality of reasoning answers.

NDCG@K – It evaluates the ranking quality of the top-K

answers using the NDCG metric [28].

All the measurements range from 0 to 1, with larger val-
ues indicating better performance. Table 2 summarizes the
performance of the KRL system in cyber-threat hunting.

5.2 Attack implementation

Next, we detail the implementation of ROAR attacks in the
case study of cyber-threat hunting.

Attack settings – By default, we set target queries Q ∗ as
vulnerable to
that containing a speciﬁc pattern p∗ = Android OS
−−−−−−−→
vmitigation, where Android OS is an anchor entity
vCVE
while both vCVE and vmitigation are variables. In §5.3, we also
consider alternative deﬁnitions of p∗.

ﬁxable by
−−−−−→

We consider both targeted and untargeted attacks. In untar-
geted attacks, the goal is to direct the answering of each query
q
Q ∗ to an erroneous one (different from its ground-truth
∈
q
); in targeted attacks, the goal is to direct the answering of
(cid:74)
(cid:75)
all the queries in Q ∗ to a target answer A. For vulnerability
queries, we set A = CVE-2021-0471, which is a CVE with lower
severity among all the Android CVEs; for mitigation queries,
we set A as the mitigation of CVE-2021-0471.

Further, it is necessary to ensure the impact of the attacks

on benign queries (i.e., without p∗) is limited.

Attack variants – To the best of our knowledge, this is the
ﬁrst work on the security of KRL. We thus mainly compare
the performance of different variants of ROAR:

ROARkp– Relying on knowledge poisoning, the adversary
inﬂuences KRL by committing poisoning facts to the KG con-
struction, but has no control over the queries. Speciﬁcally,
ROARkp commits poisoning facts surrounding Android OS (an-
chor entity of p∗) and CVE-2021-0471 (target answer A). We

limit the number of poisoning facts by nkp = 100.

ROARqp– Relying on query perturbation, the adversary
generates adversarial queries at inference time but has no
control over the KG construction. To make the perturbation
evasive, we require that (i) the number of logical paths in the
perturbation is limited by nqp = 2 and (ii) the dependency
graph of the perturbed query is valid with respect to the KG.
ROARco– Leveraging both knowledge poisoning and query
perturbation, the adversary optimizes the poisoning facts and
adversarial queries jointly.

In all the attacks, we assume the adversary has no con-
trol over the training of KRL including (i) how the training
set is sampled from the KG and (ii) how the entity embed-
ding and relation transformation models are trained. Thus, all
the poisoning facts and/or adversarial queries are crafted on
surrogate models.

5.3 Evaluation results

For exposition simplicity, below we highlight the KRL per-
formance variation before and after the attacks. In targeted
” indicates the score increase (e.g., MRR) with re-
attacks, “
↑
spect to target answer A; in untargeted attacks, “
” indicates
↓
the score decrease with respect to ground-truth answers.

Objetive

Query

Attack

w/o

ROARkp

ROARqp

ROARco

Targeted

Untargeted

Mitigation

Vulnerability .00 .00 .53
.00 .00 .29
Vulnerability .56 .75 .34
.48 .68 .31

Mitigation

.57
.33
.22
.20

↑
↑
↓
↓

—- —-
—- —-
.48
.49
.57
.45

↓
↓

↓
↓

.99
.58
.55
.48

↑
↑
↓
↓

.99
.60
.73
.68

↑
↑
↓
↓

↑
↑
↓
↓

Table 3. Overall attack performance in cyber-threat hunting. Note:
the values in each cell are MRR (left) and NDCG@5 (right).

Attack effectiveness – Table 3 summarizes the overall at-
tack performance measured by MRR and NDCG@5. Note that
without attacks (w/o), none of the queries in Q ∗ leads to tar-
get answer A, due to their irrelevance. We have the following
interesting observations.

ROARkp is more effective in targeted attacks. – ROARqp
seems unable to direct KRL to target answer A. This may
be explained by that limited by the perturbation constraints
(§4.3), it is difﬁcult to direct the answering of query q to A
. In contrast, ROARkp exerts a more
remotely relevant to
signiﬁcant inﬂuence on KRL by minimizing the distance be-
tween the embeddings of pattern p∗ (shared by Q ∗) and A,
leading to more effective targeted attacks.

q
(cid:75)

(cid:74)

ROARqp is more effective in untargeted attacks. – Interest-
ingly, ROARqp outperforms ROARkp in untargeted attacks.
This may be explained as follows. An untargeted attack suc-
ceeds if the answer of query q deviates from
; the poisoning
facts of ROARkp affects all the queries in the same manner,
while in ROARqp, the perturbation is tailored to each query q,
resulting in more effective untargeted attacks.

q
(cid:75)

(cid:74)

ROARco is the most effective attack. – In both targeted and

7

untargeted cases, ROARco outperforms the other attacks. For
instance, in targeted attacks against vulnerability queries,
ROARco attains 0.99 increase in MRR. This may be attributed
to the mutual reinforcement between knowledge poisoning
and query perturbation: tailoring poisoning facts to adversar-
ial queries, and vice versa, improves the attack effectiveness.

Objective

Query

Targeted

Untargeted

Vulnerability
Mitigation
Vulnerability
Mitigation

Attack

ROARkp

ROARco

0.00
↓
0.01
↓
0.00
↓
0.01
↓

0.00
0.00
0.02
0.01

↓
↓
↓
↓

0.00
↓
0.00
↓
0.00
↓
0.00
↓

0.00
↓
0.02
↓
0.00
↓
0.00
↓

Table 4. Impact of attacks on non-target queries. Note: the values in
each cell are MRR (left) and NDCG@5 (right).

Attack evasiveness – We further measure the impact of the
attacks on non-target queries (without pattern p∗). As ROARqp
has no inﬂuence on non-target queries, we focus on evaluating
ROARkp and ROARco, with results shown in Table 4.

ROAR has a limited impact on non-target queries. – Com-
pared with the benign system (cf. Table 2), ROARkp and
ROARco have negligible inﬂuence on the answering of non-
target queries. This may be attributed to multiple factors: (i)
the limited number of poisoning facts (less than nkp), (ii) the
locality of such facts, and (iii) the large size of KG.

Query structures – Recall that the queries are generated
following a set of templates (cf. Figure 13). We now evaluate
the impact of query structures on the attack performance. We
encode the complexity of query q as npath-mpath, where npath
is the number of logical paths (from anchors Kq to answer
) in q and mpath is the length of the longest path. Table 5
q
(cid:74)
(cid:75)
breaks down the attack performance according to the setting
of npath and mpath. We have the following observations.

Attack performance drops with npath. – By increasing the
number of logical paths npath but keeping the maximum path
length mpath ﬁxed, the effectiveness of all the attacks tends
to drop. This may be explained as follows. Each logical path
in query q represents one constraint on the answer
; with
more constraints, KRL is more robust to local perturbation to
either KG or parts of q.

q
(cid:74)

(cid:75)

Attack performance improves with mpath in targeted cases.
– Interestingly, in the targeted cases, the attack performance
improves with mpath under ﬁxed npath. This may be explained
as follows. Longer logical paths in q represent “weaker”
constraints, due to the accumulated approximation errors of
relation transformation. As p∗ is deﬁned as a short logical
path, for queries with large mpath, p∗ tends to dominate the
query answering, resulting in more effective attacks.

Surrogate models – Thus far, we assume the surrogate
models on which the adversary crafts poisoning facts and/or
adversarial queries share the same architectures with the tar-
get KRL system. We now examine the scenario wherein the
surrogate and actual models differ.

different from the actual models used by KRL (c.f. Table 16)
in terms of (i) the dimensionality of embeddings and (ii) the
depth of DNNs (as relation transformation models), while all
the other settings are the same as Table 3. Table 6 shows the
attack performance under such alternative surrogate models.
ROAR transfers across different embedding models. – By
comparing Table 6 and Table 3, it is observed that while the
attack performance drops under the alternative settings, due to
the discrepancy between the actual and surrogate models, the
decrease is marginal, indicating the transferability of ROAR
across different models. This may be explained by that many
KG embedding methods demonstrate fairly similar behavior
[18]. It is therefore possible to transfer attacks across different
embedding models.

KG-Query interaction – We further evaluate the interac-
tion between the attack vectors of knowledge poisoning and
query perturbation in ROARco. Speciﬁcally, we evaluate the
attack performance as a function of nkp (number of injected
poisoning facts) and nqp (number of perturbed logical paths),
with results summarized in Figure 5.

There exists an “mutual reinforcement” effect. – In both
targeted and untargeted cases, with nqp ﬁxed, slightly increas-
ing nkp signiﬁcantly improves the attack performance. For
instance, in targeted cases, when nkp = 0, NDCG@5 remains
0 regardless of the setting of nkp; if nkp = 50, even setting
nqp = 1 leads to NDCG@5 over 0.5. This indicates that knowl-
edge poisoning greatly boosts the effectiveness of query per-
turbation and also validates the analysis in §4.4.

The effect is even more evident in untargeted attacks. – It
is also observed that ROAR achieves its maximum effective-
ness in untargeted attacks with nkp and nqp lower than the case
of targeted attacks. This is explained by that without the need
to direct KRL to a speciﬁc answer A, untargeted attacks are
relatively “easier” than targeted attacks, making the mutual
reinforcement even more signiﬁcant.

We also observe similar trends measured by MRR with

results shown in Figure 14 (§E).

Alternative p∗ pattern – The pattern p∗ serves a trigger to
invoke KRL to malfunction in ROARkp and ROARco. Here, we
consider alternative deﬁnitions of p∗ and evaluate its impact
on the attack performance. Speciﬁcally, besides its default def-
inition (with Android OS as anchor) in §5.2, we consider two
other deﬁnitions as listed in Table 7: the one has Port Scanning
(which refers to an attack pattern) as its anchor and its logical
path is of length 2; the other has T1033 (which refers to an at-
tack technique of “system owner/user discovery technique”5)
as its anchor and is of length 3.

p∗ with shorter paths leads to more effective attacks. – In
Figure 6, we compares the attack performance of ROARkp
and ROARco under varying deﬁnitions of p∗ in both targeted
and untargeted cases. Observe that the attack effectiveness
decreases as the length of p∗ grows. This can be explained as

We consider two conﬁgurations of the surrogate models

5https://attack.mitre.org/techniques/T1033/

8

Objective Attack

3-1

3-2

3-3

Query Topological Structure (npath-mpath)
5-2

5-3

5-1

7-1

7-2

7-3

Targeted

w/o
ROARkp
ROARqp
ROARco
w/o
ROARkp
ROARqp
ROARco

↑

↑

↑

↑

0.00
0.81

0.00
0.78

0.00
0.78

0.00
0.56

0.00
0.00
0.51
0.81
↑
↑
—- —- —- —- —- —-
1.00
0.98
↑
↑
0.74
0.59
0.40
0.35
0.65
0.50
0.58
0.74

1.00
↑
0.52
0.31
0.51
0.52

1.00
↑
0.75
0.30
0.66
0.75

1.00
↑
0.52
0.42
0.51
0.52

0.98
↑
0.83
0.24
0.54
0.81

↑

↑

↑

↑

↑

0.00
0.40

0.00
0.71

0.00
0.63

0.00
0.66

0.00
0.00
0.37
0.71
↑
—- —- —- —- —- —-
1.00
0.97
↑
↑
0.72
0.60
0.28
0.34
0.44
0.50
0.71
0.58

0.98
↑
0.78
0.19
0.41
0.74

1.00
↑
0.54
0.35
0.47
0.53

0.99
↑
0.75
0.25
0.46
0.73

1.00
↑
0.56
0.34
0.49
0.54

↑

↑

↑

0.00
0.42

0.00
0.39

0.00
0.38

0.00
0.27
↑

0.00
0.00
0.23
0.44
↑
↑
—- —- —- —- —- —-
1.00
0.94
↑
↑
0.72
0.60
0.11
0.31
0.41
0.50
0.71
0.57

1.00
↑
0.56
0.33
0.47
0.55

1.00
↑
0.72
0.09
0.41
0.71

1.00
↑
0.58
0.36
0.49
0.57

0.96
↑
0.76
0.12
↓
0.37
↓
0.70
↓

↓
↓
↓

↓
↓
↓

Untargeted

↓
↓
↓
Table 5. Topological complexity of queries on the attack performance. Note: the values in each cell are MRR (left) and NDCG@5 (right).

↓
↓
↓

↓
↓
↓

↓
↓
↓

↓
↓
↓

↓
↓
↓

↓
↓
↓

↓
↓
↓

↓
↓
↓

↓
↓
↓

↓
↓
↓

↓
↓
↓

↓
↓
↓

↓
↓
↓

↓
↓
↓

Figure 5: NDCG@5 variation of ROARco as a function of knowledge poisoning budget (nkp) and query perturbation budget (nqp).

Objective

Query

ROARkp

Attack
ROARqp

ROARco

Embedding Dimensionality = 200, DNN Depth = 1

Targeted

Mitigation

.96
Vulnerability .48
↑
↑
.50
.26
↑
↑
.51
Vulnerability .34
↓
↓
.44
.27
↓
↓
Embedding Dimensionality = 500, DNN Depth = 4

—- —-
—- —-
.44
.47
.54
.40

.55
↑
.31
↑
.22
↓
.21
↓

Mitigation

↓
↓

↓
↓

.99
.55
.70
.62

↑
↑
↓
↓

Untargeted

Targeted

Mitigation

Vulnerability .50
↑
.27
↑
Vulnerability .30
↓
.22
↓
Table 6. Attack performance under alternative surrogate models.

—- —-
—- —-
.36
.44
.42
.37

.91
↑
.52
↑
.49
↓
.40
↓

.56
↑
.33
↑
.19
↓
.15
↓

.95
.54
.63
.61

Untargeted

Mitigation

↑
↑
↓
↓

↓
↓

↓
↓

erating queries with ground-truth answers among the deleted
CVEs. The reasoning task is to search for potential mitigation
for given incidents. Intuitively, it is possible to ﬁnd correct
mitigation even though the vulnerability is unknown based on
similar vulnerabilities (i.e., approximate query). Meanwhile,
the attacks aims to mislead KRL to erroneous suggestions (un-
targeted) or a speciﬁc mitigation A = MITI-725916 (targeted).

Objective

Attack

w/o

ROARkp

ROARqp

ROARco

Targeted
.00 .00 .34
↑
Untargeted .39 .61 .20
↓

.40
.22

↑
↓

—- —-
.44
.30
↓

↓

.47
.39

↑
↓

.55
.59

↑
↓

Table 8. Attack performance against zero-day threat queries.

Anchor of p∗
Category
Length (Vulnerability)
Length (Mitigation)

Android OS Port Scanning

T1033

Product Attack pattern Technique
2 hop
3 hop

3 hop
4 hop

1 hop
2 hop

Table 7. Alternative deﬁnitions of p∗.
follows. As the poisoning facts are selected surrounding the
anchors, their inﬂuence tends to fade as the distance between
the anchors and the answers. Further, while ROARkp is inefﬁ-
cient under the setting of p∗ starting with T1033, ROARco is
much less sensitive to the setting of p∗ (e.g., MRR
0.39 and
0.42), indicating the necessity of co-optimizing
NDCG@5
poisoning facts and adversarial queries.

≥

≥

ROAR is also effective against approximate queries. – Ta-
ble 8 presents the attack performance in zero-day case. Com-
paring with Table 3, we have similar observations that (i)
ROARkp is more effective than ROARqp in targeted attacks; (ii)
ROARqp is more effective than ROARkp in untargeted attacks;
and (iii) ROARco is the most effective among the three.

Also, note that ROAR is marginally less effective against
approximate queries, due to the missing links (i.e., Vulnerabil-
ity) on the paths from anchor entities to answers (Mitigation).
However, as similar vulnerabilities tend to share mitigation,
ROAR is still able to craft effective poisoning facts/adversarial
queries to mislead KRL.

Zero-day threats – We further evaluate the performance of
ROAR in the scenario of zero-day threats, wherein the threats
exploit previously unknown vulnerabilities, which often re-
sult in consequential damages in practice [8]. We simulate the
zero-day case by randomly removing 30% CVEs (from 2020
to 2021) from the KG as the zero-day vulnerabilities, then gen-

6 Case Study II: Drug Repurposing

In the case of cyber-threat hunting, we evaluate ROAR over
queries regarding KG entities. Below, we further evaluate

6https://source.android.com/security/bulletin/2021-04-01

9

(a) Targeted — Vulnerability(b) Targeted — Mitigation(c) Untargeted — Vulnerability(d) Untargeted — MitigationFigure 6: Attack performance under alternative deﬁnitions of p∗.

ROAR over queries regarding KG relations in the concrete
case of drug repurposing reasoning.

6.1 Experimental setup

We begin by describing the evaluation setting.

Scenario – Drug repurposing aims to ﬁnd potential thera-
peutic values or unknown side effects of new drugs [32, 36]
by exploring the interactions between drugs, diseases, and
human genes. To this end, we consider a KRL system built
upon knowledge regarding drugs, diseases, and genes, which
supports the following queries:

Drug-disease interaction – Given a drug-disease pair with
their relevant properties, it determines the drug’s effect on the
disease (e.g., highly/mildly effective).

Drug-gene interactions – Given a drug-gene pair with their
relevant properties, it determines the gene’s effect on the
drug’s functionality (e.g., suppression/acceleration).

Both types of queries can be formulated as reasoning about
R between a given pair of KG entities v, v(cid:48):
v(cid:48).

the relation r?
v
q[r?] = r? .
∃

∈
r?
−→

DRKG – We use the Drug Repurposing Knowledge Graph
(DRKG) [1] as the underlying KG, which is synthesized from
public medical databases. Table 15 lists the stats of DRKG. In
particular, there are 10 different drug-disease relations and 34
drug-gene relations.

Queries – To construct the queries, we randomly sample
80K drug-disease and 200K drug-gene pairs and also include
their 2-hop neighboring entities as their relevant properties.
We use 5% of the queries as the testing set and the remaining
as the training set for KRL.

KRL – We instantiate GQE [19] as the encoders and R-
GCN [41] as the operators of the KRL system. Intuitively,
R-GCN aggregates multi-relational graphs with GCN layers
[22], thereby able to aggregate query embeddings to predict
missing relations.

Query

HIT@1

Drug-Disease
Drug-Gene

0.73
0.77

Table 9. KRL performance in drug repurposing.

Metrics – As the answer of a relation query is given as the
ranking of possible relations, in the evaluation, we mainly use
HIT@K (K = 1 by default) as the metric: for each query, it
checks whether the top-K answers contain the ground-truth
answer (i.e., a binary indicator). The results are then averaged
across all the queries. Table 9 shows the performance of KRL
in this case.

6.2 Attack implementation

Next, we detail the implementation of ROAR in drug repur-
posing reasoning.

Attack settings – By default, we set target queries Q ∗ as
vdrug, where
that contains trigger p∗ = Nervous System
Nervous System is an Anatomical Therapeutic Chemical (ATC)
category as the anchor and vdrug is a variable. Intuitively, the
adversary aims to inﬂuence the reasoning regarding all the
drugs in this ATC category.

includes
−−−−→

We consider both targeted and untargeted attacks. In tar-
geted cases, the goal is to direct the answering each query
q
Q ∗ to a speciﬁc relation A = biomarker-of; in untargeted
cases, the goal is to deviate the answering of q from its ground-
truth answer

∈

.

q
(cid:75)

(cid:74)

Attack variants – We compare the performance of differ-

ent variants of ROAR.

ROARkp– It inﬂuences KRL by injecting poisoning facts
to the KG. Given that genes and diseases are public, veriﬁ-
able knowledge, it is more evasive to inject poisoning facts
surrounding drugs. Thus, ROARkp attaches poisoning facts to
Nervous System (p∗’s anchor).

ROARqp– It directly attaches additional logical paths (from
the KG) to the drug entity of the query. As all the related
properties of a drug are within 2 hops, ROARqp also searches
for logical paths within 2 hops of the drug.

ROARco– Leveraging both knowledge poisoning and query
perturbation, ROARco optimizes the poisoning facts and ad-
versarial queries jointly.

Given that DRKG (average density 120.8) is much denser
than CyberKG (average density 8.7), we limit the number
of injected poisoning facts by nkp = 400 and the number of
perturbed logical paths nqp = 20 by default. The setting of
other parameters is deferred to Table 16.

10

(a) Targeted — Vulnerability(b) Targeted — Mitigation(c) Untargeted — Vulnerability(d) Untargeted — MitigationFigure 7: HIT@1 variation of ROARco when adjusting KG poisoning budget (nkp) and query perturbation budget (nqp)

Figure 8: Attack performance with respect to the number of properties associated with drug entities.

6.3 Evaluation results

The evaluation below focuses on three aspects: (i) the overall
attack effectiveness and evasiveness (ii) the interaction be-
tween the two attack vectors, and (iii) the impact of different
factors on the attack performance.

Objective

Query

Target Q ∗

Q ∗
w/o ROARkp ROARqp ROARco ROARkp ROARco

Non-Target Q

\

Targeted

Drug-Disease .00
Drug-Gene
.04
Drug-Disease .68
.74
Drug-Gene

.10
↓
↑
.03
↓
↑
.13
↓
↓
.15
↓
↓
Table 10. Overall attack performance of ROAR in drug repurposing.

.03
↓
.01
↓
.02
↓
.03
↓

.22
.14
.38
.37

.46
.40
.65
.62

.03
.00
.03
.01

Untargeted

↑
↑
↓
↓

↑
↑
↓
↓

Attack effectiveness – Table 10 presents the overall per-
formance of ROAR measured by HIT@1. Similar to the case
of cyber-threat hunting, observe that ROARco outperforms
the other variants in both targeted and untargeted cases, due
to the interactions between knowledge poisoning and query
perturbation. Besides, we have the following observation:

ROARqp is more effective than ROARkp. – Across all the
settings, ROARqp consistently outperforms ROARkp. This may
be explained as follows: ROARkp inﬂuences the drug-disease
(or drug-gene) relation by attaching poisoning facts to the ATC
entity, which in turn inﬂuences the drug entity; meanwhile,
ROARkp directly attaches perturbation to the drug entity, lead-
ing to more effective attacks.

Attack evasiveness – Table 10 also shows the impact of
ROAR on non-target queries Q
Q ∗. Observe that the HIT@1
\
score drops no more than 0.03 across all the settings, indicat-
ing the fairly marginal impact of ROAR.

KG-Query interaction – We further evaluate the interac-
tion between knowledge poisoning and query perturbation in
the case of drug repurposing. We evaluate the attack perfor-
mance as a function of nkp and nqp, with results summarized
in Figure 7.

Similar to §5, we have the observations below. (i) There
exists an “mutual reinforcement” effect between the two at-
tack vectors. The injected poisoning facts greatly boots the
effectiveness of adversarial queries in directing the answer-
ing of relation queries. (ii) This reinforcement effect seems
more evident in untargeted attacks, given that an untargeted
attack succeeds if the drug-disease (or drug-gene) relations
are mispredicted while a targeted attack requires the relation
to be predicted to target answer A.

Objective

Query

#Dim = 100, #Layer = 1 #Dim = 400, #Layer = 4
ROARkp ROARqp ROARco ROARkp ROARqp ROARco

Targeted

Untargeted

Drug-Disease
Drug-Gene
Drug-Disease
Drug-Gene

↑
↓
↓
↓
Table 11. Attack performance under alternative surrogate models in
drug repurposing.

.05
↑
.00
↑
.10
↓
.06
↓

.41
.34
.62
.57

.12
.12
.24
.28

.33
.30
.51
.49

.18
.09
.35
.33

.10
.01
.11
.15

↑
↑
↓
↓

↑
↑
↓
↓

↑
↑
↓
↓

↑
↓
↓
↓

Surrogate models – We now evaluate ROAR in the case
wherein the surrogate and actual models differ. We consider
two conﬁgurations of the surrogate models different from the
actual models used by KRL (c.f. Table 16) in terms of (i) the
embedding dimensionality and (ii) the depth of R-GCN, while
all the other settings are the same as Table 10.

It is shown in Table 11 that while the attack performance
slightly decreases as the surrogate and actual models differ,

11

(a) Targeted — Drug-Disease(b) Targeted — Drug-Gene(c) Untargeted — Drug-Disease(d) Untargeted — Drug-Gene(a) Targeted — Drug-Disease(b) Targeted — Drug-Gene(c) Untargeted — Drug-Disease(d) Untargeted — Drug-Genethe drop is marginal, especially when the surrogate model
is simpler than the actual model (embedding dimensionality
= 100, depth of R-GCN = 1), indicating the transferability of
ROAR from simpler models to more complicated ones.

Number of properties – Recall that a relation query is a
subgraph centering around a drug-disease (or drug-gene) pair,
while the surrounding entities represent their descriptive prop-
erties. For instance, the neighboring entities of a drug entity
describe its biomedical properties (e.g., ATC and side effect).
Figure 8 breaks down the attack performance according to the
number of properties associated with drug entities.

Relations with fewer properties are more vulnerable. – It
is observed that in both targeted and untargeted cases, the
attack performance degrades with the number of properties.
This can be explained as follows. For given query q, each
property represents one logical constraint on its ground-truth
answer
; more properties make KRL more robust against
poisoning facts or adversarial perturbation. Yet, even with
more than 2,000 properties, ROARco still attains high HIT@1
scores, especially in the untargeted cases, indicating the ne-
cessity of optimizing poisoning facts and adversarial queries
jointly.

q
(cid:75)

(cid:74)

7 Discussion

We now explore potential countermeasures against ROAR.

7.1 Potential Countermeasures

Due to the unique characteristics of KRL, the existing defenses
against malicious attacks in classiﬁcation tasks [27, 44, 45])
are inapplicable. Thus, we investigate two potential counter-
measures tailored to knowledge poisoning and query pertur-
bation, respectively, and further explore their synergy.

Filtering poisoning facts – As poisoning facts are force-
fully injected into the KG, they may misalign with their neigh-
boring entities/relations. It is therefore possible to detect and
purge them as noisy facts before using the KG in KRL.

To this end, for each fact v r
v(cid:48) in the KG, we apply encoder
−→
φ and relation r-speciﬁc operator ψr to assess its “ﬁtness”
to the KG. Speciﬁcally, we compute the anomaly score of
v r
v(cid:48) as:
. A higher anomaly score indicates
ψr(φv)
−
−→
(cid:107)
less ﬁtness of v r
v(cid:48). We may remove facts with the highest
−→
scores, thereby mitigating the inﬂuence of poisoning facts.

φv(cid:48)(cid:107)

In practice, we may ﬁrst train KRL (including both φ and ψ)
with the complete KG, prune m% of the facts with the highest
anomaly scores, and then re-train KRL.

Results and analysis – Figure 9 shows the KRL performance
on non-target queries and the attack performance on target
queries in (a) cyber-threat hunting and (b) drug repurposing.
It is observed that as m grows from 0 to 10, in (a) the KRL
performance slightly decreases while in (b) the KRL perfor-
mance slightly improves. We attribute this phenomenon to

Figure 9: KRL performance on non-target queries and attack per-
formance on target queries. (a) Vulnerability query in cyber-threat
hunting; (b) Drug-disease query in drug repurposing.

the density difference of these two KGs (8.7 versus 120.8).
For a sparser KG like CyberKG, over-pruning has a negative
impact on the KRL performance. In both cases, the attack
performance slightly drops with m.

Thus, (i) ﬁltering of poisoning facts may not be suitable
for sparse KGs; and (ii) even with a large pruning rate (e.g.,
10%), the improvement of attack resilience seems marginal.

Training with adversarial queries – We further consider
an adversarial training [27] strategy to defend against query
perturbation. Intuitively, during KRL training, we generate an
adversarial version q∗ for each query q using ROARqp and
add (q∗,
is q’s ground-truth
answer. Note that here we use the untargeted ROARqp (Eq. 5)
to generate q∗.

) to the training set, where

q
(cid:75)

q
(cid:75)

(cid:74)

(cid:74)

Results and analysis – Similar to ROARqp, robust train-
ing has a threshold nd
qp that limits the number of perturbed
paths. We measure the performance of ROARco under varying
settings of nqp and nd

qp, with results shown in Figure 10.

qp ≥

Observe that across all the cases, robust training greatly
reduces the attack performance, especially against untargeted
attacks when nd
nqp. However, robust training also signiﬁ-
cantly impacts the KRL performance, resulting in over 0.19
NDCG@5 drop in cyber-threat hunting and over 0.11 HIT@1
drop in drug repurposing. Further, it is inherently ineffective
against ROARkp, which does not rely on adversarial queries.
Synergy – Finally, we integrate the two defenses above
and explore their synergy. We set pruning rate m = 1% and
nd
qp = 2/20 for cyber-threat hunting/drug repurposing. The
attacks follow the default setting in Table 16.

Query

Objective

Target Q ∗
ROARkp ROARqp ROARco

Non-Target

Q

Q ∗

\

Targeted
Untargeted
Targeted
Untargeted

Vulnerability

Drug-Disease

↓
↓
↓
↓
Table 12. Attack performance and KRL performance against the
integrated defense.

—-
0.20
↓
0.12
↓
0.18
↓

0.26
0.36
0.15
0.30

0.05
0.08
0.02
0.06

↓
↓
↓
↓

0.04

0.02

↓

↑

Results and analysis – The results are shown in Table 12.
Comparing with the original attack performance (cf. Table 3
and 10), the integrated defense reduces the attack effectiveness
by a large margin, even though it does not completely block
ROAR; moreover, it alleviates the negative impact on the KRL

12

(a) Vulnerability(b) Drug-DiseaseFigure 10: Performance of ROARco against robust training with respect to varying settings of nqp and nd

qp.

performance and even improves the HIT@1 score in drug
repurposing! Thus, the integration of multiple defenses seems
a promising direction worth further investigation.

7.2 Limitations

We now discuss the limitations of this work.

Alternative reasoning tasks – We mainly focus on reason-
ing tasks with one target answer (entity/relation), while there
exist other reasoning tasks (e.g., path reasoning [46] aims to
ﬁnd a path with given starting and end entities). Intuitively,
ROAR is ineffective in such tasks as it requires knowledge
about the logical path and then perturbs intermediate enti-
ties on the path. We consider exploring the vulnerability of
alternative reasoning tasks as our ongoing research.

Input-space attacks – While ROAR directly operates on
KGs (or queries) in the logical space, there are scenarios in
which KGs (or queries) are extracted from real-world inputs.
For instance, cyber-threat queries may be generated by soft-
ware testing and inspection. In such scenarios, it requires the
perturbation to KGs (or queries) to be mapped to valid real-
world inputs (e.g., software). While input-space attacks are
an ongoing area of research [35], we consider realizing ROAR
in the input space represents unique challenges.

Integration of defenses – While it is shown that integrat-
ing ﬁltering poisoning knowledge and training with adversar-
ial queries greatly improves the attack resilience, it is unclear
how to optimally integrate such defenses to balance the factors
of attack robustness (e.g., against adaptive attacks), impact on
KRL performance, and training cost. We consider answering
these questions critical for improving the robustness of KRL
in a practical setting.

8 Related Work

Next, we survey the literature relevant to this work.

Knowledge representation learning – Knowledge graphs
(KGs) represent valuable information sources in various
domains [30, 50]. Recent years have witnessed signiﬁcant
progress in using machine learning to reason over KGs. The
existing work can be roughly classiﬁed into two categories.

13

One line of work aims to develop effective KG embed-
dings [10, 24, 31, 47, 49] such that the semantics of KG en-
tities/relations are effectively captured by their latent repre-
sentations for applications such as link prediction [13, 14].
Another line of work focuses on directly making predictions
about complex logical queries [19, 37–39] such as ﬁrst-order
conjunctive queries. The KRL models considered in this paper
belong to this category.

Machine learning security – With their increasing use in
security-sensitive domains, machine learning (ML) models
are becoming the targets for malicious attacks [7]. A variety
of attack vectors have been exploited: adversarial evasion
crafts adversarial inputs to force the target model to malfunc-
tion [11, 16]; model poisoning modiﬁes the target model’s
behavior (e.g., performance drop) via polluting its training
data [21]; backdoor injection creates a trojan model such that
any trigger-embedded input is likely to be misclassiﬁed [26];
and functionality stealing constructs a replicate model func-
tionally similar to a victim model [33].

In response, another line of work strives to improve the
resilience of ML models against such attacks. For instance,
against adversarial evasion, existing defenses explore new
training strategies (e.g., adversarial training) [27] and detec-
tion mechanisms [15]. Yet, such defenses often fail when
facing even stronger attacks [6, 25], resulting in a constant
arms race between the attackers and defenders.

Despite the intensive research on KRL and ML security in
parallel, the security of KRL is largely unexplored. This work
represents an initial step to bridge this gap.

9 Conclusion

This work represents an in-depth study on the security of
knowledge representation learning (KRL). We present ROAR,
a new class of attacks that instantiate a variety of threats to
KRL. We demonstrate the practicality of ROAR in two rep-
resentative security-sensitive applications, raising concerns
about the current practice of training and using KRL. More-
over, we discuss potential mitigation, which might shed light
on applying KRL in a more secure manner.

(a) Targeted — Vulnerability(c) Targeted — Drug-Disease(b) Untargeted — Vulnerability(d) Untargeted — Drug-DiseaseReferences

[1] DRKG - Drug Repurposing Knowledge Graph for
Covid-19. https://github.com/gnn4dr/DRKG/.

[2] Google Knowledge Graph.

https://developers.

google.com/knowledge-graph/.

[3] Microsoft Academic Knowledge Graph.

https://

makg.org/.

[4] Wikidata. https://www.wikidata.org/.

[5] YAGO: A High-Quality Knowledge Base. https://

yago-knowledge.org/.

[6] Anish Athalye, Nicholas Carlini, and David Wagner.
Obfuscated Gradients Give a False Sense of Security:
Circumventing Defenses to Adversarial Examples. In
Proceedings of IEEE Conference on Machine Learning
(ICML), 2018.

[7] Battista Biggio and Fabio Roli. Wild Patterns: Ten Years
after The Rise of Adversarial Machine Learning. Pattern
Recognition, 84:317–331, 2018.

[8] Leyla Bilge and Tudor Dumitra¸s. Before We Knew It:
An Empirical Study of Zero-Day Attacks in the Real
World. In Proceedings of ACM Conference on Computer
and Communications (CCS), 2012.

[9] Antoine Bordes, Nicolas Usunier, Alberto Garcia-Durán,
Jason Weston, and Oksana Yakhnenko. Translating Em-
beddings for Modeling Multi-Relational Data. In Pro-
ceedings of Advances in Neural Information Processing
Systems (NeurIPS), 2013.

[10] Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran,
Jason Weston, and Oksana Yakhnenko. Translating Em-
beddings for Modeling Multi-relational Data. Advances
in neural information processing systems, 26, 2013.

[11] Nicholas Carlini and David A. Wagner. Towards Evalu-
ating the Robustness of Neural Networks. In Proceed-
ings of IEEE Symposium on Security and Privacy (S&P),
2017.

[12] Nilesh Dalvi and Dan Suciu. Efﬁcient Query Evaluation
on Probabilistic Databases. The VLDB Journal, 16:523–
544, 2007.

[13] Rajarshi Das, Shehzaad Dhuliawala, Manzil Zaheer,
Luke Vilnis, Ishan Durugkar, Akshay Krishnamurthy,
Alex Smola, and Andrew McCallum. Go for a Walk
and Arrive at the Answer: Reasoning Over Paths in
Knowledge Bases using Reinforcement Learning. In
Proceedings of International Conference on Learning
Representations (ICLR), 2018.

[14] Rajarshi Das, Arvind Neelakantan, David Belanger, and
Andrew McCallum. Chains of Reasoning over Entities,
Relations, and Text using Recurrent Neural Networks.
In Proceedings of European Chapter of the Association
for Computational Linguistics (EACL), 2017.

[15] Timon Gehr, Matthew Mirman, Dana Drachsler-Cohen,
Petar Tsankov, Swarat Chaudhuri, and Martin Vechev.
AI2: Safety and Robustness Certiﬁcation of Neural Net-
works with Abstract Interpretation. In Proceedings of
IEEE Symposium on Security and Privacy (S&P), 2018.

[16] Ian Goodfellow, Jonathon Shlens, and Christian Szegedy.
Explaining and Harnessing Adversarial Examples. In
Proceedings of International Conference on Learning
Representations (ICLR), 2015.

[17] Kelvin Guu, John Miller, and Percy Liang. Traversing
Knowledge Graphs in Vector Space. In Proceedings of
Conference on Empirical Methods in Natural Language
Processing (EMNLP), 2015.

[18] Kelvin Guu, John Miller, and Percy Liang. Traversing
Knowledge Graphs in Vector Space. In Proceedings of
Conference on Empirical Methods in Natural Language
Processing (EMNLP), 2015.

[19] William L. Hamilton, Payal Bajaj, Marinka Zitnik, Dan
Embedding Logical
Jurafsky, and Jure Leskovec.
In Proceedings of
Queries on Knowledge Graphs.
Advances in Neural Information Processing Systems
(NeurIPS), 2018.

[20] Erik Hemberg, Jonathan Kelly, Michal Shlapentokh-
Rothman, Bryn Reinstadler, Katherine Xu, Nick Rutar,
and Una-May O’Reilly. Linking Threat Tactics, Tech-
niques, and Patterns with Defensive Weaknesses, Vul-
nerabilities and Affected Platform Conﬁgurations for
Cyber Hunting. ArXiv e-prints, 2020.

[21] Yujie Ji, Xinyang Zhang, Shouling Ji, Xiapu Luo, and
Ting Wang. Model-Reuse Attacks on Deep Learning
Systems. In Proceedings of ACM Conference on Com-
puter and Communications (CCS), 2018.

[22] Thomas N Kipf and Max Welling. Semi-Supervised
Classiﬁcation with Graph Convolutional Networks.
ArXiv e-prints, 2016.

[23] Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, and
Xuan Zhu. Learning Entity and Relation Embeddings
In Proceedings
for Knowledge Graph Completion.
of AAAI Conference on Artiﬁcial Intelligence (AAAI),
2015.

[24] Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, and
Xuan Zhu. Learning entity and relation embeddings for
knowledge graph completion. In Proceedings of AAAI
Conference on Artiﬁcial Intelligence (AAAI), 2015.

14

[25] Xiang Ling, Shouling Ji, Jiaxu Zou, Jiannan Wang,
Chunming Wu, Bo Li, and Ting Wang. DEEPSEC: A
Uniform Platform for Security Analysis of Deep Learn-
In Proceedings of IEEE Symposium on
ing Model.
Security and Privacy (S&P), 2019.

[35] Fabio Pierazzi, Feargus Pendlebury, Jacopo Cortellazzi,
and Lorenzo Cavallaro. Intriguing Properties of Adver-
sarial ML Attacks in the Problem Space. In Proceedings
of IEEE Symposium on Security and Privacy (S&P),
2019.

[26] Yingqi Liu, Shiqing Ma, Yousra Aafer, Wen-Chuan Lee,
Juan Zhai, Weihang Wang, and Xiangyu Zhang. Tro-
janing Attack on Neural Networks. In Proceedings of
Network and Distributed System Security Symposium
(NDSS), 2018.

[27] Aleksander Madry, Aleksandar Makelov, Ludwig
Schmidt, Dimitris Tsipras, and Adrian Vladu. Towards
Deep Learning Models Resistant to Adversarial Attacks.
In Proceedings of International Conference on Learning
Representations (ICLR), 2018.

[28] Frank McSherry and Marc Najork. Computing Informa-
tion Retrieval Performance Measures Efﬁciently in the
Presence of Tied Scores. In Proceedings of European
Conference on Information Retrieval (ECIR), 2008.

[29] Sudip Mittal, Prajit Kumar Das, Varish Mulwad, Anu-
pam Joshi, and Tim Finin. Cybertwitter: Using Twitter
to Generate Alerts for Cybersecurity Threats and Vul-
nerabilities. In Proceedings of IEEE/ACM International
Conference on Advances in Social Networks Analysis
and Mining (ASONAM), 2016.

[30] Sudip Mittal, Anupam Joshi, and Tim Finin. Cyber-all-
intel: An AI for Security Related Threat Intelligence.
ArXiv e-prints, 2019.

[31] Maximilian Nickel, Lorenzo Rosasco, and Tomaso Pog-
gio. Holographic Embeddings of Knowledge Graphs.
In Proceedings of AAAI Conference on Artiﬁcial Intelli-
gence (AAAI), 2016.

[32] Tudor I Oprea, Julie E Bauman, Cristian G Bologa,
Tione Buranda, Alexandre Chigaev, Bruce S Edwards,
Jonathan W Jarvik, Hattie D Gresham, Mark K Haynes,
Brian Hjelle, et al. Drug Repurposing from an Aca-
demic Perspective. Drug Discovery Today: Therapeutic
Strategies, (3-4):61–69, 2011.

[33] Tribhuvanesh Orekondy, Bernt Schiele, and Mario Fritz.
Knockoff Nets: Stealing Functionality of Black-Box
Models. In Proceedings of IEEE Conference on Com-
puter Vision and Pattern Recognition (CVPR), 2018.

[34] Ren Pang, Hua Shen, Xinyang Zhang, Shouling Ji, Yev-
geniy Vorobeychik, Xiapu Luo, Alex Liu, and Ting
Wang. A Tale of Evil Twins: Adversarial Inputs versus
Poisoned Models. In Proceedings of ACM Conference
on Computer and Communications (CCS), 2020.

[36] Sudeep Pushpakom, Francesco Iorio, Patrick A Eyers,
K Jane Escott, Shirley Hopper, Andrew Wells, Andrew
Doig, Tim Guilliams, Joanna Latimer, Christine Mc-
Namee, et al. Drug Repurposing: Progress, Challenges
and Recommendations. Nature reviews Drug discovery,
18:41–58, 2019.

[37] Hongyu Ren, Hanjun Dai, Bo Dai, Xinyun Chen, Michi-
hiro Yasunaga, Haitian Sun, Dale Schuurmans, Jure
Leskovec, and Denny Zhou. LEGO: Latent Execution-
Guided Reasoning for Multi-Hop Question Answering
on Knowledge Graphs. In Proceedings of IEEE Confer-
ence on Machine Learning (ICML), 2021.

[38] Hongyu Ren, Weihua Hu, and Jure Leskovec.
Query2box: Reasoning over Knowledge Graphs in
Vector Space using Box Embeddings. In Proceedings of
International Conference on Learning Representations
(ICLR), 2020.

[39] Hongyu Ren and Jure Leskovec. Beta Embeddings for
Multi-Hop Logical Reasoning in Knowledge Graphs.
In Proceedings of Advances in Neural Information Pro-
cessing Systems (NeurIPS), 2020.

[40] Nir Rosenfeld, Sophie Hilgard, Sai Srivatsa Ravin-
dranath, and David C. Parkes. From Predictions to
Decisions: Using Lookahead Regularization. In Pro-
ceedings of Advances in Neural Information Processing
Systems (NeurIPS), 2020.

[41] Michael Schlichtkrull, Thomas N Kipf, Peter Bloem,
Rianne Van Den Berg, Ivan Titov, and Max Welling.
Modeling Relational Data with Graph Convolutional
Networks. In Proceedings of European Semantic Web
Conference, 2018.

[42] Octavian Suciu, Radu M˘arginean, Yi˘gitcan Kaya, Hal
Daumé, III, and Tudor Dumitra¸s. When Does Machine
Learning FAIL? Generalized Transferability for Evasion
In Proceedings of USENIX
and Poisoning Attacks.
Security Symposium (SEC), 2018.

[43] Christoph Tillmann and Hermann Ney. Word Reorder-
ing and A Dynamic Programming Beam Search Algo-
rithm for Statistical Machine Translation. Computa-
tional Linguistics, 29:97–133, 2003.

[44] Brandon Tran, Jerry Li, and Aleksander Madry. Spectral
In Proceedings of
Signatures in Backdoor Attacks.
Advances in Neural Information Processing Systems
(NeurIPS), 2018.

15

[45] B. Wang, Y. Yao, S. Shan, H. Li, B. Viswanath, H. Zheng,
and B. Y. Zhao. Neural Cleanse: Identifying and Miti-
gating Backdoor Attacks in Neural Networks. In Pro-
ceedings of IEEE Symposium on Security and Privacy
(S&P), 2019.

[46] Xiang Wang, Dingxian Wang, Canran Xu, Xiangnan He,
Yixin Cao, and Tat-Seng Chua. Explainable Reasoning
over Knowledge Graphs for Recommendation. In Pro-
ceedings of AAAI Conference on Artiﬁcial Intelligence
(AAAI), 2019.

[47] Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng
Chen. Knowledge Graph Embedding by Translating on
Hyperplanes. In Proceedings of AAAI Conference on
Artiﬁcial Intelligence (AAAI), 2014.

[48] Yexiang Xue, Yang Yuan, Zhitian Xu, and Ashish Sab-
harwal. Expanding Holographic Embeddings for Knowl-
edge Completion. In Proceedings of Advances in Neural
Information Processing Systems (NeurIPS), 2018.

[49] Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng Gao,
and Li Deng. Embedding Entities and Relations for
Learning and Inference in Knowledge Bases. ArXiv
e-prints, 2014.

[50] Yongjun Zhu, Chao Che, Bo Jin, Ningrui Zhang, Chang
Su, and Fei Wang. Knowledge-driven Drug Repurpos-
ing Using a Comprehensive Drug Knowledge Graph.
Health Informatics Journal, 26:2737–2750, 2020.

Notation

Deﬁnition

Data – knowledge graph related
a knowledge graph
a KG fact from entity v to v(cid:48) with relation r
entity, edge, and relation set of G
all facts in KG
a fact set contributed by the attacker

G
v, r, v(cid:48)(cid:105)
(cid:104)
N ,E,R
F
F ∗

Data – query related

q, Q
q
(cid:74)
(cid:75)
A
p∗
Kq
K ∗
Q ∗

Q

Q ∗

\
q+
q∗

a single query; a query set
q’s ground-truth answer(s)
the targeted answer
the targeted logical path for attack
anchor entities of query q
anchor entities of p∗
a query set that each included query has p∗
a query set that each included query doesn’t have p∗
the generated perturbations on q
conjunction of q and q+, i.e., the perturbed query

Model or embedding related

γ
φ
ψ, ψr
φG
φv
φq

the reasoning system
the encoder for generating entity embeddings
the (relation r-speciﬁc) operator
embeddings of all KG entities
entity v’s embedding
q’s embedding

Other parameters

nkp
nqp
nd
qp
niter

KG poisoning budget
query perturbation budget
query perturbation budget used by the defender
Number of iterations in co-optimization

Table 13. Notations, deﬁnitions, and categories.

A Notations

Table 13 summarizes the important notations.

with the actual reasoning operator ψ (Attack11), or white-box
access to both φ and ψ (Attack12) and manipulate poisoning
facts with query perturbations.

B Attack Taxonomy

C KG Statistics

Attack1, Attack2, Attack3 – They use knowledge poisoning as
the attack vector but with different knowledge of the encoder
φ and the operator ψ. The adversary without knowledge of
encoder φ builds a surrogate one with self-determined em-
bedding dimensionality (Attack1, Attack3). The adversary
without knowledge of operator ψ crafts an independent model
that may function differently (Attack1, Attack2).

Attack5, Attack6, Attack8 – They take query perturbation as
the attack vector. If the adversary has no knowledge of the rea-
soning system (Attack5) or has partial knowledge (Attack6),
it must leverage a surrogate system or partial component for
inference-time perturbation. With white-box access (Attack8),
the adversary can directly query the actual system and craft
perturbations.

Attack9, Attack11, Attack12 – They operate on both KG and
queries as attack vectors. The major difference is leveraging
an entire surrogate system (Attack8), or a surrogate encoder φ

Here, we present the statistics of KGs used in §5 and §6.

CyberKG – Table 14 lists statistics of entities/relations of
our cyber-domain KG, whose structure is shown in Figure 11.
We add the reverse facts to augment KG during evaluations.
Query templates follow Figure 13. The ﬁrst 3 rows (path
number=2/3/5) are used as training-query structures, while
the last 3 rows (path number = 3/5/7) are used for evaluation.
We follow Figure 12 to sample each query path from KG with
a ﬁxed length (1/2/3 hop to CVE or 2/3/4 hop to Mitigation), and
conjunct the sampled paths together by the CVE entity. We
randomly remove half of the facts from KG that exists in the
evaluation set, which addresses the assumption of incomplete
KG hence relies on the reasoning to ﬁnd correct answers.

DRKG – We directly use a constructed drug repurposing
KG. Table 15 shows the overall statistics of entity/relation/fact
scales; we also add the reverse facts into DRKG.

16

Entity category
Vulnerability (CVE) Webpage, BRON, NVD

Data Source

Vendor

Product

Version

Campaign

Tactic

Technique

Attack pattern

Weakness (CWE

Mitigation

Webpage
Webpage
Webpage
Webpage
BRON
BRON
BRON
Webpage, BRON
NVD

Total

Version

Knowledge fact (v r
v(cid:48))
−→
develops
Product
Vendor
−−−−−→
Product obtains
−−−−→
Vendor vulnerable to
−−−−−−−→
Product vulnerable to
−−−−−−−→
Version vulnerable to
−−−−−−−→
CVE aims to
−−−−→
CVE is related to
−−−−−−→

Campaign

CVE

CVE

CVE

CVE

Technique

Tactic includes
−−−−→
leverages
−−−−−→

Technique

Attackpattern

applies to
−−−−−→
Weakness contains
−−−−→
ﬁxable by
−−−−−→

CVE

Attackpattern

Weakness

CVE

Mitigation

Total (w. reverse facts)

Quantity
18,587
2,223
7,103
96,725
13
11
99
323
150
74,794
200,028

Quantity

7,897

96,725

26,884

47,419

510,781

27,325

2502

123

111

575

19,047

125,943
1,730,664

Table 14. Statistics of cyber-domain KG.

# Entity
97,238

# Relation
107

# Fact (w. reverse)
11,748,522

Table 15. Statistics of DRKG.

D Parameter Setting

Table 16 summarizes the default parameter setting used in §5
and §6.

E Additional Results

Figure 14 shows the MRR variation before and after attacks
with respect to nkp and nqp. The observations are similar to
Figure 5.

Figure 11: Structure of our cyber-domain knowledge graph.

17

Figure 12: Different logical paths used in our query set.

Figure 13: Topological structures of queries used in cyber-threat
hunting (blue – anchor; grey – variable; green – answer).

Type

Parameter Setting

Cyber-Threat Hunting

Encoder φ

Dimension

Operator ψ

Query2Box Architecture

400
2FC (Projection)
2FC (Conjunction)

Training

Attack

Encoder φ

Operator ψ

Training

Attack

Hidden Dim 400
Learning rate
Batch size
Epochs

0.001 (φ and γ)
512 (φ and γ)
80000 (φ), 10000 (γ)

Optimizer Adam (φ and γ)
100
2
5

nkp
nqp
niter

Drug Repurposing

Dimension
R-GCN Architecture

200
2GraphConv

Hidden Dim 200
Learning rate
Batch size
Epochs

0.0001 (φ), 0.001 (γ)
2048 (φ and γ)
100000 (φ), 20000 (γ)

Optimizer Adam (φ and γ)
400
20
5

nkp
nqp
niter

Table 16. Default parameter setting.

Vendor Product Product version Threat code (CVE)CampaignMitigationTactic Technique Attack pattern Weakness developsobtainsvulnerable tovulnerable toﬁxable byaims tocontainsincludesleveragesapplies tois related tovulnerable toTechniqueCWECVEMitigationCWECVECVEProductCVEVersionCVEAnchor entityVariable entityAnswer entityAttack PatternCampaignAttack PatternMitigationMitigationMitigationMitigationQuery structure complexity level(1)(2)(3)Number of logical paths in a query2357Figure 14: MRR variation of ROARco with respect to knowledge poisoning budget (nkp) and query perturbation budget (nqp).

18

(a) Targeted — Vulnerability(b) Targeted — Mitigation(c) Untargeted — Vulnerability(d) Untargeted — Mitigation