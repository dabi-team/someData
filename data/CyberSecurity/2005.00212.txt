0
2
0
2

y
a
M
1

]

Y
S
.
s
s
e
e
[

1
v
2
1
2
0
0
.
5
0
0
2
:
v
i
X
r
a

A framework for the analysis of supervised
discrete event systems under attack

Qi Zhang1, Carla Seatzu2, Zhiwu Li1, and Alessandro Giua2

1 Xidian University, Xi’an 710071, China,
qzhang 3@stu.xidian.edu.cn, zhwli@xidian.edu.cn,
2 University of Cagliari, 09123 Cagliari, Italy,
{seatzu, giua}@diee.unica.it

Abstract. This paper focuses on the problem of cyber attacks for dis-
crete event systems under supervisory control. In more detail, the goal
of the supervisor, who has a partial observation of the system evolution,
is that of preventing the system from reaching a set of unsafe states. An
attacker may act in two diﬀerent ways: he can corrupt the observation of
the supervisor editing the sensor readings, and can enable events that are
disabled by the supervisor. This is done with the aim of leading the plant
to an unsafe state, and keeping the supervisor unaware of that before the
unsafe state is reached. A special automaton, called attack structure is
constructed as the parallel composition of two special structures. Such
an automaton can be used by the attacker to select appropriate actions
(if any) to reach the above goal, or equivalently by the supervisor, to
validate its robustness with respect to such attacks.

Keywords: discrete event systems, ﬁnite state automata, supervisory
control, cyber attacks

1

INTRODUCTION

Cyber-physical systems (CPS) operating in a feedback loop are particularly vul-
nerable to attacks since the communication between controllers and processes
typically occur via a network such as the internet. Computers collect the data
from the processes through sensors and based on such data provide a suitable
control input [1]. Malicious attackers may corrupt the sensor readings collected
by the controller, and/or may alter the control commands [2]. In this paper, we
consider a plant G modeled by a partially-observed discrete event system. The
open-loop behaviour of the plant, i.e., the language L(G), may contain undesir-
able strings that should be prevented by a feedback controller, thus a partial-
observation supervisor SP is introduced to restrict L(G) within a sublanguage
K ⊆ L(G) by appropriately disabling events in the plant. As a special case, one
may also consider the problem of avoiding a set of unsafe states Xus ⊆ X, where
X is the state space of G.

In this paper we deal with the problem of cyber attacks in supervisory con-
trol systems. Two diﬀerent kinds of attacks are considered: sensor attack and

 
 
 
 
 
 
2

Qi Zhang et al.

actuator enablement attack. In the ﬁrst case the attacker may corrupt the sensor
channels transmitting erroneous observations to the supervisor. In particular,
the attacker may erase the output symbols produced by certain events, and may
insert observations corresponding to events that have not occurred. In the sec-
ond case the attacker corrupts the control commands of the supervisor enabling
events that are disabled by the supervisor. This may lead the plant to an unsafe
state and the supervisor may even not realize it, namely the attacker remains
stealthy.

The problem of attack detection in CPS is attracting an increasing attention
in the automatic control community. It has been investigated in [3], [4], [5] in
the case of time-driven continuous systems. Interesting contributions have also
been proposed in the discrete event systems framework. As an example, in [6]
the authors determine the condition under which the supervisor can detect the
presence of an attacker and prevent the system from generating illegal strings.
They use a language measure technique to assess the damage caused by the
attacker if the supervisor cannot block the intrusion, and determine an optimal
speciﬁcation for the supervisor to realize in the presence of an attacker. Other
signiﬁcant contributions on cyber attacks in supervisory control systems are [7],
[8], [9], [10], [11], where the authors either consider sensor or actuator enablement
attacks, and propose defensive strategies.

Our work has some similarities with [12], [13], [14], [15], [16], [17], [18]. How-
ever, in [12], [13], the authors only consider sensor attacks, and deﬁne a supervi-
sor that is robust against such attacks [12]. In [14], [15], the authors only consider
actuator enablement attacks, and develop a behavior-preserving supervisor that
is robust against such attacks [15]. In our work, we assume that sensor and actu-
ator enablement attacks may occur simultaneously. The simultaneous occurrence
of the two kinds of attacks has also been considered in [16], [17]. However, in
these papers, despite of us, authors do not guarantee that the attacker remains
stealthy. This paper may be seen as an extension of our results in [18] where
we investigated the problem of cyber attacks at the observation layer, without
supervisor, and stealthyness of the attacker is guaranteed. We ﬁnally mention
the very recent contributions in [16] and [17]. In particular, a diagnoser-based
algorithm is developed in [16], and a security module against cyber attacks is
provided in [17].

The solution proposed in this paper to derive a stealthy attack policy associ-
ated with both sensor and actuator enablement attacks, is based on the notion
of attack structure that simultaneously keep into account the set of states that
are consistent with the real observation generated by the plant and the set of
states that are consistent with the corrupted observation received by the super-
visor. Such an attack structure is computed as the parallel composition of two
particular structures, called attacker observer and supervisor under attack. This
veriﬁes the eﬀectiveness of an attacker that is deﬁned based on it. A way to
reﬁne it is provided, selecting the so called supremal stealthy attack substructure.
The attack structure may also be used from another perspective. Indeed, it al-

Supervised discrete event systems under attack

3

lows the supervisor to analyze its robustness with respect to sensor and actuator
enablement stealthy attacks.

We conclude this section pointing out that the problem considered in this
paper belongs to an important class of problems in the framework of discrete
event systems which can be addressed reconstructing the event sequence or the
state trajectory in the presence of a partial observation of the system evolu-
tion and/or a partial knowledge of the system state. Other problems in this
framework are: state estimation and control [19], fault diagnosis [20,21,22], and
opacity analysis [23]. All such problems have been extensively investigated in
the literature in the last decades and eﬀective approaches have been developed
for their solution. Some of such approaches can be appropriately adapted for the
solution of problems of intrusion detection, and can be of inspiration for them.
An example is the recent contribution by some of the authors of this paper [24]
where it is shown how a particular intrusion detection problem can be converted
into a problem of fault diagnosis, and consequently it can be solved using ap-
propriate techniques in this framework. However, there are some key features of
the intrusion detection problem that signiﬁcantly distinguish it from the other
problems. The ﬁrst one is the fact that it involves two players that compete for
diﬀerent goals, the attacker and the plant observer/controller. On the contrary,
in the other cases, only one actor is involved, namely, the state observer, the
controller or the diagnoser. The only other exception in this respect occurs in
the case of opacity where we also have an attacker who tries to discover some se-
crets. The second feature is that in all the problems mentioned above apart from
intrusion detection, the observation mask is static, while in the case of intrusion
detection, the observation mask is dynamically changing following a malicious
strategy aiming to lead the system to a dangerous or undesirable condition.

The remainder of the paper is organized as follows. In Section 2, some nec-
essary preliminaries on ﬁnite state automata and supervisory control theory are
given. In Section 3, the attack model is introduced. In Section 4, the problem
statement is presented. In Section 5, the attacker observer and the supervisor
under attack are introduced. In Section 6, we introduce the attack structure,
which provides the basic tool for solving the problem formalized in Section 4.
Indeed, it allows to select on-line an eﬀective attacker. In Section 6, it is also
shown how to extract a supremal stealthy attack substructure starting from the
attack structure. In Section 7, conclusions are ﬁnally drawn and our future lines
of research in this framework are pointed out.

2 PRELIMINARIES

A deterministic ﬁnite-state automaton (DFA) is a 4-tuple G = (X, E, ∆, x0),
where X is the ﬁnite set of states, E is the alphabet of events, ∆ ⊆ X × E × X
is the transition relation, and x0 is the initial state. The transition relation
determines the dynamics of the DFA: if (x, e, x(cid:48)) ∈ ∆, it means that the oc-
currence of event e at state x yields state x(cid:48). The transition relation can be
extended to ∆∗ ∈ X × E∗ × X: if (xi, σ, xj) ∈ ∆∗ it means that there exists a

4

Qi Zhang et al.

sequence of states xi, ..., xj ∈ X and a sequence of events σ = ei...ej−1 ∈ E∗
such that (xi, ei, xi+1), ..., (xj−1, ej−1, xj) ∈ ∆. The language generated by G
is deﬁned as L(G) = {σ ∈ E∗|∃x ∈ X : (x0, σ, x) ∈ ∆∗}. We denote as
Γ (x) = {e ∈ E | ∃x(cid:48) ∈ X : (x, e, x(cid:48)) ∈ ∆} the set of events that are active
at state x.

Given two alphabets E(cid:48) ⊆ E, the natural projection on E(cid:48), PE(cid:48) : E∗ → E(cid:48) is

deﬁned as [25]:

PE(cid:48)(ε) := ε and PE(cid:48)(σe) :=

(cid:26) PE(cid:48)(σ)e if e ∈ E(cid:48),

PE(cid:48)(σ) if e ∈ E\E(cid:48).

(1)

In simple words, given a string σ ∈ E∗, its natural projection on E(cid:48) is ob-
tained by simply removing events that do not belong to E(cid:48). For simplicity, we
use P : E∗ → E∗

o to denote the natural projection on Eo.

Given two automata G1 = (X1, E1, ∆1, x01) and G2 = (X2, E2, ∆2, x02), the
parallel composition of G1 and G2 is denoted as G = G1(cid:107)G2 = (X1 × X2, E1 ∪
E2, ∆, (x01 × x02)), where the transition relation ∆ is deﬁned as follows:






∃((x1, x2), e, (x(cid:48)
∃((x1, x2), e, (x(cid:48)
∃((x1, x2), e, (x1, x(cid:48)
undeﬁned

1, x(cid:48)
2)) ∈ ∆ if ∃(x1, e, x(cid:48)
1, x2)) ∈ ∆ if ∃(x1, e, x(cid:48)
2)) ∈ ∆ if ∃(x2, e, x(cid:48)
otherwise.

1) ∈ ∆1 ∧ ∃(x2, e, x(cid:48)
1) ∈ ∆1 ∧ e /∈ E2,
2) ∈ ∆2 ∧ e /∈ E1,

2) ∈ ∆2,

(2)

Consider a plant modeled by a DFA G = (X, E, ∆, x0), let E = Eo ∪ Euo =
Ec ∪ Euc, where Eo is the set of observable events, Euo is the set of unobservable
events, Ec is the set of controllable events, and Euc is the set of uncontrollable
events. The unobservable reach of state x is deﬁned by a set of states x(cid:48) ∈ X
reached from state x ∈ X by executing an unobservable string σ ∈ E∗
uo, namely,
U R(x) = {x(cid:48) ∈ X | ∃σ ∈ E∗

uo : (x, σ, x(cid:48)) ∈ ∆∗}.

Given a plant G = (X, E, ∆, x0) with set of observable events Eo, the observer

of G [26] is the DFA Obs(G) = (B, Eo, ∆o, b0), where:

– B ⊆ 2X is the set of states,
– ∆o : B × Eo → B is the transition relation deﬁned as:

∆o(b, eo) := ∪x∈bU R({x(cid:48) | ∆(x, eo) = x(cid:48)}),

– b0 := U R(x0) is the initial state.

A partial-observation supervisor SP = (Y, E, ∆s, y0) can be ﬁnitely repre-
sented by a control function fc: P [L(G)] → 2E, where P is the natural projection
on Eo. Without loss of generality, we assume that L(SP ) ⊆ L(G). Given a string
σ ∈ E∗: (x0, σ, x) ∈ ∆∗, let ξ = fc[P (σ)] be the control input by SP at state x.
The resulting closed-loop system is an automaton denoted as SP /G = G(cid:107)SP ,
with generated language L(SP /G).

Supervised discrete event systems under attack

5

3 THE ATTACKER: DEFINITIONS AND

ASSUMPTIONS

In this paper we consider a closed-loop system SP /G subject to attack according
to the scheme in Fig. 1. If σ is a generic string generated by the plant, the
observed string is s = P (σ). An attacker may corrupt the observation (sensor
attack), inserting fake observations or erasing some output signals produced by
events that have actually happened. Such a corrupted observation is denoted by
s(cid:48) and is still a sequence of events in Eo. The supervisor constructs its state
estimation based on s(cid:48) and elaborates its control input based on it. In addition,
the attacker may also enable some events that are disabled by SP (actuator
enablement attack). We denote as ξ ∈ 2E the control input computed based on
s(cid:48), and denote as ξ(cid:48) ∈ 2E the corrupted control input that actually restricts the
behavior of G.

Fig. 1. Closed-loop system under attack.

The set of compromised events, namely the events that can be corrupted
by the attacker, is denoted by Ecom. Set Ecom includes: the events that the
attacker may insert in the supervisor observation even if they have not actually
occurred, the events that the attacker may erase in the supervisor observation,
and the events that the attacker may enable even if they were disabled by the
supervisor. The above three sets are denoted respectively, Eins, Eera, and Eena.
In particular, it is Eins, Eera ⊆ Eo and Eena ⊆ Ec. We assume that such sets
are not necessarily disjoint.

We notice that the deﬁnition of compromised events has been ﬁrstly pro-
posed in [10]. However, while in [10] the authors only consider sensor attacks,
thus events in Ecom may only be of the ﬁrst two types mentioned above, here
we slightly generalize such a deﬁnition also dealing with actuator enablement
attacks. As a result, events in Ecom may also be of the third type above.

Even if it is possible to deﬁne the sensor attack via a function that turns the
observed string s into the corrupted observation s(cid:48), for reasons that will be clear
later, we prefer to formalize the problem in terms of a new string that is deﬁned
on an alphabet called attack alphabet.

The attack alphabet is deﬁned as Ea = Eo ∪ E+ ∪ E− ∪ ES, and we assume
that Eo, E+, E−, and ES are disjoint sets. The set of inserted events is denoted

6

Qi Zhang et al.

as E+, namely E+ = {e+ | e ∈ Eins}. The occurrence of e+ ∈ E+ implies
that the attacker inserts in the supervisor observation an event e that has not
actually happened. The set of erased events is denoted by E−, namely E− =
{e− | e ∈ Eera}. The occurrence of e− ∈ E− means that the attacker erases
from the supervisor observation event e occurred in the plant. The set of enabled
events is denoted as ES, namely ES = {eS | e ∈ Eena}. The occurrence of
eS ∈ ES indicates that event e disabled by the supervisor is again enabled by
the attacker.

In addition we assume that the following relationship holds: Ec ⊆ Eo, namely
all the events that are controllable are also observable. This implies that Euo ⊆
Euc, namely it could not happen that the attacker enables unobservable events,
which simpliﬁes our problem.

The following deﬁnition formalizes the notion of attacker via the sensor and

actuator enablement attack functions.

Deﬁnition 1. Consider a closed-loop system SP /G where G = (X, E, ∆, x0),
the set of compromised events is Ecom = Eins ∪ Eera ∪ Eena, and the set of ob-
servable events is Eo. Let Obs(G) = (B, Eo, ∆o, b0) be the observer. An attacker
is deﬁned by a sensor attack function fsen : E∗
a, and an actuator enable-
ment attack function fena : Ξ → Ξ (cid:48), where Ea is the attack alphabet, Ξ ⊆ 2E
is the set of control inputs, and Ξ (cid:48) ⊆ 2E is the set of corrupted control inputs.
The attack functions satisfy the following conditions:

o → E∗

(a) fsen(ε) ∈ E∗
+;
(b) ∀se ∈ E∗

o with s ∈ E∗
o :

(cid:26) fsen(se) ∈ fsen(s){e−, e}E∗

fsen(se) ∈ fsen(s)eE∗

+ if e ∈ Eera,
+ if e ∈ Eo \ Eera,

where eE∗

+ = {ew+ | w+ ∈ E∗

+} and e−E∗

+ = {e−w+ | w+ ∈ E∗

+};

(c) ∀ξ ∈ 2E : ξ(cid:48) = fena(ξ) ⊆ ξ ∪ Eena.

(3)

(cid:117)(cid:116)

In Deﬁnition 1, condition (a) means that the attacker can insert any string
in E∗
+ when no event has occurred in the plant. Condition (b) indicates that if
an event e ∈ Eera happens, the attacker can either erase event e or not erase it,
and then insert any string in E∗
+. If an event e ∈ Eo\Eera happens, the attacker
can insert any string in E∗
+ after e. Condition (c) implies that the attacker can
enable events in Eena that are not enabled by the supervisor.

The language modiﬁed by the attack functions is called attack language and
is denoted by La(SP /G). We use w to denote a string in La(SP /G), and we call
w attack string.

Deﬁnition 2. The supervisor projection ˆP : E∗

a → E∗

o is deﬁned as:

ˆP (ε) := ε and ˆP (wea) :=

(cid:26) ˆP (w)e if ea ∈ Ea \ E−,

ˆP (w) if ea ∈ E−.

(4)

Supervised discrete event systems under attack

7

(cid:117)(cid:116)
The projection describes how the supervisor deals with events in Ea, thus ˆP
is called supervisor projection. Namely, the supervisor cannot distinguish events
in E+ ∪ ES from events in Eo, and the supervisor cannot observe events in E−.
The internal structure of the attacker that in Fig. 1 is represented as a black
box having the observation s and the control input ξ as inputs, and the corrupted
observation s(cid:48) and the corrupted control input ξ(cid:48) as outputs, is depicted in Fig. 2.

Fig. 2. Internal structure of the attacker in Fig. 1.

Fig. 2 shows how the (uncorrupted) observation s is corrupted by the sensor
attack function fsen, producing the attack string w ∈ E∗
a. Such a sequence is
projected via the supervisor projection ˆP on Eo, generating a string s(cid:48). The
supervisor constructs its state estimation based on s(cid:48) and computes its control
input ξ. Such a control input is altered by the actuator enablement attack func-
tion fena producing the corrupted control input ξ(cid:48), which actually restricts the
behavior of the plant.

4 PROBLEM STATEMENT

We ﬁrst introduce some key deﬁnitions that will be useful in the following.

Deﬁnition 3. Consider a closed-loop system SP /G under attack. Let L(SP /G)
be the closed-loop language under no attack and La(SP /G) be the attack lan-
guage. The attacker is stealthy if ˆP [La(SP /G)] ⊆ P [L(Sp/G)].
(cid:117)(cid:116)

In simple words, an attacker is stealthy if the set of words that a supervisor
may observe when the system is under attack is contained in the set of words
the supervisor may observe when no attack occurs.

Deﬁnition 4. The attacker projection ˜P : E∗

a → E∗

o is deﬁned as:

˜P (ε) := ε, and ˜P (wea) :=

(cid:26) ˜P (w)e if ea ∈ Ea \ E+,

˜P (w) if ea ∈ E+.

(5)

(cid:117)(cid:116)

8

Qi Zhang et al.

The projection describes how the attacker deals with events in Ea, thus ˜P
is called attacker projection, and the projection returns the real observation.
Namely, the attacker knows that events ea ∈ ES are events that actually occurs
in the plant, and events ea ∈ E− are events that have been erased, thus he
updates his state the same way in case of e ∈ Eo, e− ∈ E−, and e ∈ ES. Since
the attacker knows that ea ∈ E+ are fake events that have not actually occurred
in the plant, then he does not update his state when ea ∈ E+ occurs.

We assume that a set of unsafe states Xus is given, which corresponds to an
undesirable or dangerous condition for the plant G. The supervisor controls the
plant with the objective of preventing it from reaching the unsafe state. The goal
of the attacker is that of preventing the supervisor from reaching his objective.
The following deﬁnition provides a criterion to assess the attacker.

Deﬁnition 5. Consider a closed-loop system SP /G where G = (X, E, ∆, x0).
Let Xus be a set of unsafe states and La(SP /G) be the attack language. Let
Obs(G) = (B, Eo, ∆o, b0) be the observer where Eo is the set of observable events.
An attacker is:

– eﬀective if ∃w ∈ La(SP /G): (b0, ˜P (w), b) ∈ ∆∗
– ineﬀective if it is not eﬀective.

o and b ∩ Xus (cid:54)= ∅;

(cid:117)(cid:116)

In simple words, an attacker is eﬀective if there exists an attack string
w ∈ La(SP /G) such that executing ˜P (w) starting from the initial state b0, the
observer reaches a state b that contains an element in the set of unsafe states.
This means that the plant may reach an unsafe state when the attack string w
is generated.

In this paper, given a closed-loop system SP /G with set of compromised
events Ecom, we want to provide a criterion to establish if an attack strategy
exists, which leads the plant to the unsafe state, and the supervisor cannot
detect the presence of an attacker before the unsafe state is reached. Dually, the
strategy can be used to validate the safeness of the system against such attacks.

5 ATTACKER OBSERVER AND SUPERVISOR

UNDER ATTACK

In this section we introduce two special structures, called attacker observer and
supervisor under attack, which provide the basis for the solution of the problem
formulated in the previous section.

5.1 Attacker observer

The attacker observer, denoted as Obsatt(G), provides the real state estimation of
the plant based on the attack strings w ∈ E∗
a. The attacker observer Obsatt(G)
describes all possible attack strings and the corresponding sets of consistent
states of the plant. Since attacks are performed by the attacker, he knows which

Supervised discrete event systems under attack

9

observations originate from events that have really occurred on the plant (Eo),
which observations have been erased (E−), which observations have been inserted
(E+), and which observations have been enabled (ES). The attacker observer
Obsatt(G) can be constructed using Algorithm 1.

end for

∆att := ∆att ∪ (b, e+, b);

Algorithm 1 Construction of the attacker observer Obsatt(G)
Input: Plant G = (X, E, ∆, x0), Eins, Eera, and Eena.
Output: Attacker observer Obsatt(G) = (B, Ea, ∆att, b0).
1: Construct the observer Obs(G) = (B, Eo, ∆o, b0);
2: Let Ea := Eo ∪ E+ ∪ E− ∪ ES;
3: Let ∆att := ∆o;
4: for all e ∈ Eins, do
for all b ∈ B, do
5:
6:
7:
8: end for
9: for all e ∈ Eera, do
for all b ∈ B, do
10:
11:
12:
13:
14:
15: end for
16: for all e ∈ Eena, do
17:
for all b ∈ B, do
18:
19:
20:
21:
22: end for

if ∃(b, e, b(cid:48)) ∈ ∆att, then

if ∃(b, e, b(cid:48)) ∈ ∆att, then

∆att := ∆att ∪ (b, e−, b(cid:48));

∆att := ∆att ∪ (b, eS, b(cid:48));

end for

end for

end if

end if

Note that an analogous observer has been proposed in [18]. However, while
in [18] we only consider sensors attack, here we modify the structure associated
with both sensors and actuator enablement attacks.

We brieﬂy explain how Algorithm 1 works. First, the observer Obs(G) =
(B, Eo, ∆o, b0) is constructed. The set of states of Obsatt(G) coincides with the
set of states of Obs(G), as well as the initial state. The attack alphabet Ea is
deﬁned. The transition relation is initialized at ∆att := ∆o. Indeed, all the events
e ∈ Eo are events that really happen in the plant. Therefore, when such events
occur, Obsatt(G) updates his states in accordance with the transition relation
∆o.

Then, for all events e ∈ Eins and for all states b ∈ B, we add self-loops
(b, e+, b). Indeed, events e+ ∈ E+ are events that do not actually occur in the
plant, thus Obsatt(G) does not update his state.

10

Qi Zhang et al.

Finally, for all events e ∈ Eera and for all states b ∈ B, whenever a transition
(b, e, b(cid:48)) is deﬁned, we add the transition (b, e−, b(cid:48)) to ∆att. Indeed, events e− ∈
E− are events that occur in the plant even if they are erased by the attacker, thus
Obsatt(G) updates his state is the same way in case of e and e−. For all events
e ∈ Eena and for all states b ∈ B, whenever a transition (b, e, b(cid:48)) is deﬁned, we
add the transition (b, eS, b(cid:48)) to ∆att. Indeed, events eS ∈ ES are events enabled
by the attacker.

Example 1. Consider the plant G = (X, E, ∆, x0) and the observer in Fig.s 3 (a)
and (b), respectively. Let Eo = Ec = {a, b, c, g}, Euo = Euc = {d}, and Xus =
{3}.

(a) G

(b) Obs(G)

Fig. 3. (a) Plant G and (b) Observer Obs(G).

Fig. 4. Attacker observer Obsatt(G).

Let Eins = {a}, Eera = {a, b, g}, and Eena = {b}. The attacker observer
Obsatt(G) is visualized in Fig. 4. Since a ∈ Eins, we add self-loops labeled a+
at all states. Since a, b, g ∈ Eera, arcs labeled a, b, and g, respectively, are also
labeled a−, b−, and g−, respectively. Since b ∈ Eena, the arc labeled b, is also
(cid:117)(cid:116)
labeled bS.

Supervised discrete event systems under attack

11

5.2 Supervisor Under Attack

The supervisor under attack SPa provides the corrupted state estimation com-
puted by the supervisor on the basis of the attack strings w ∈ E∗
a. The supervisor
under attack SPa generates two diﬀerent sets of words. The ﬁrst set contains all
words on Ea that may either result from an uncorrupted observation or from
a corrupted observation which keeps the attacker stealthy. The second set of
words contains all the previous words continued with a symbol in Ea so that
the resulting word is not consistent with an uncorrupted observation. While the
words in the ﬁrst set lead to a set of states that according to the supervisor
are consistent with the perceived observation, those in the second set lead to a
dummy state denoted as y∅. The supervisor under attack SPa can be constructed
using Algorithm 2.

We brieﬂy explain how Algorithm 2 works. Consider a supervisor SP =
(Y, E, ∆s, y0). First, the set of states Ya is deﬁned as Y ∪ {y∅}, where y∅ is
a dummy state: the supervisor detects the presence of an attacker when y∅ is
reached. In addition, the attack alphabet Ea is computed, and the transition
relation of SPa is initialized at ∆s.

At Step 4, the observer Obs(G) = (B, Eo, ∆o, b0) is constructed. Then, for

all e ∈ Eena, and for all y ∈ Y , if the following condition holds:

(i) there exists an observable sequence s that leads to a state b of the observer
where e is enabled, and to a state y of the supervisor where e is not enabled,

we add transition (y, eS, y∅) to ∆sa (Step 8).

If e satisﬁes the condition in the previous item, and it is also an event in
Eins (resp., Eera), then we add transition (y, e+, y∅) (resp., (y, e−, y)) to ∆sa
(Steps 10 and 12, respectively).

For all events e ∈ Eo, and for all states y ∈ Y , if the following two conditions

hold:

(ii) a transition (y, e, y(cid:48)) is not deﬁned in ∆sa, and
(iii) there does not exist an observable sequence s that satisﬁes the condition in

the item (i),

we add transition (y, e, y∅) to ∆sa.

Finally, for all events e ∈ Eins, and for all states ya ∈ Ya, whenever a
transition (ya, e, y(cid:48)
a) is deﬁned, we add transition (ya, e+, y(cid:48)
a) to ∆sa. Indeed,
the supervisor cannot distinguish events e+ from e. For all events e ∈ Eera, and
for all states ya ∈ Ya, whenever a transition (ya, e, y(cid:48)
a) is deﬁned, we add self-loop
(ya, e−, ya). Indeed, the supervisor cannot observe e− ∈ E−.

Example 2. Consider the observer and the supervisor in Fig. 3 (b) and Fig. 5 (a),
respectively. Let Eins = {a}, Eera = {a, b, g}, and Eena = {b}. The supervisor
under attack SPa is visualized in Fig. 5 (b).

Since b ∈ Eena, and b is disabled by the supervisor at state {2}, we add a
transition ({2}, bS, {y∅}). Since b is also an event in Eera, then we add a self-
loop ({2}, b−, {2}). Since a, b, c, g ∈ Eo, and transition labeled a is not deﬁned

12

Qi Zhang et al.

Algorithm 2 Construction of the supervisor under attack SPa
Input: Plant G = (X, E, ∆, x0), supervisor SP = (Y, E, ∆s, y0), event sets Eins, Eera,

and Eena.

Output: Supervisor under attack SPa = (Ya, Ea, ∆sa, y0).
1: Let Ya := Y ∪ {y∅};
2: Let Ea := Eo ∪ E+ ∪ E− ∪ ES;
3: Let ∆sa := ∆s;
4: Construct the observer Obs(G) = (B, Eo, ∆o, b0);
5: for all e ∈ Eena, do
for all y ∈ Y , do
6:
if ∃s ∈ E∗
7:
8:
9:

∆sa := ∆sa ∪ (y, eS, y∅);
o : (b0, s, b) ∈ ∆∗
if ∃s ∈ E∗

o, (y0, s, y) ∈ ∆∗

o, (y0, s, y) ∈ ∆∗

o : (b0, s, b) ∈ ∆∗

s, and e ∈ Γ (b) \ Γ (y), then

s, e ∈ Γ (b) \ Γ (y), and e ∈ Eins,

then

10:
11:

∆sa := ∆sa ∪ (y, e+, y∅);
if ∃s ∈ E∗

o : (b0, s, b) ∈ ∆∗

o, (y0, s, y) ∈ ∆∗

s, e ∈ Γ (b) \ Γ (y), and

e ∈ Eera, then

∆sa := ∆sa ∪ (y, e−, y);

if (cid:64)(y, e, y(cid:48)) ∈ ∆sa ∧ (cid:64)s ∈ E∗

o : (b0, s, b) ∈ ∆∗

o, (y0, s, y) ∈ ∆∗

s, and e ∈

∆sa := ∆sa ∪ (y, e, y∅);

end if

end if

end if

12:
13:
14:
15:
16:
17: end for
18: for all e ∈ Eo, do
19:
20:

end for

Γ (b) \ Γ (y), then

for all y ∈ Y , do

for all ya ∈ Ya, do
if ∃(ya, e, y(cid:48)

end if

end for

21:
22:
23:
24: end for
25: for all e ∈ Eins, do
26:
27:
28:
29:
30:
31: end for
32: for all e ∈ Eera, do
33:
34:
35:
36:
37:
38: end for

end for

end for

end if

end if

a) ∈ ∆sa, then
∆sa := ∆sa ∪ (ya, e+, y(cid:48)

a);

for all ya ∈ Ya, do
if ∃(ya, e, y(cid:48)

a) ∈ ∆sa, then

∆sa := ∆sa ∪ (ya, e−, ya);

Supervised discrete event systems under attack

13

(a) SP

(b) SPa

Fig. 5. (a) Supervisor SP and (b) Supervisor under attack SPa .

at state {1}, we add transition ({1}, a, {y∅}). Similar arguments can be used to
explain the other transitions labeled a, b, c, and g that yield state y∅.

Since a ∈ Eins, and there is a transition ({1}, a, {y∅}) in ∆sa, then we add
transition ({1}, a+, {y∅}) to ∆sa. Similar arguments can be used to explain the
other transitions labeled a+ in ∆sa.

Since a, b, g ∈ Eera, and there is transition ({1}, a, {y∅}) in ∆sa, then we add
a self-loop ({1}, a−, {1}) to ∆sa. Similar arguments can be used to explain the
(cid:117)(cid:116)
other self-loops labeled a−, b− and g− in ∆sa.

6 ATTACK STRUCTURE

In this section, a particular structure called attack structure is introduced. The
notion of supremal stealthy attack substructure is also given.

6.1 Deﬁnition

The attack structure can be formally deﬁned as follows.

Deﬁnition 6. Consider the closed-loop system SP /G with set of compromised
events Ecom. Let Obsatt(G) and SPa be the attacker observer and supervisor
under attack, respectively. The attack structure A w.r.t. SP /G and Ecom is the
(cid:117)(cid:116)
DFA: A = Obsatt(G)(cid:107)SPa .

Deﬁnition 7. The set of target states of an attack structure A = (R, Ea, ∆a, r0)
(cid:117)(cid:116)
is Rt := {r = (b, ya) ∈ R | b ∩ Xus (cid:54)= ∅}.

Target states are those states whose ﬁrst entry contains an element in the
set of unsafe states. The closed-loop system may reach the unsafe state when a
target state is reached.

14

Qi Zhang et al.

Example 3. Consider again the closed-loop system SP /G in Example 1 and Ex-
ample 2. Obsatt(G) and SPa are depicted in Fig. 4 and Fig. 5 (b), respectively.
The attack structure A = Obsatt(G)(cid:107)SPa is visualized in Fig. 6 (neglect the
colours of the states for the time being).

Fig. 6. Attack structure A.

At the initial state ({0}, {0}), if event a occurs in the plant, since a ∈ Eera,
the attacker either erases a or does not erase a, corresponding to transitions
[({0}, {0}), a−, ({1}, {0})] and [({0}, {0}), a, ({1}, {1})], respectively. Since a ∈
Eins, the attacker may insert event a at state ({0}, {0}), this corresponds to
transition [({0}, {0}), a+, ({0}, {1})]. Similar arguments can be used to explain
the other states and transitions in A.

In A, four target states are highlighted in green: ({3}, {0}), ({3}, {1}), ({3},
{2}), and ({3}, {y∅}), thus the attacker is eﬀective. When the target state is
reached, the plant is in unsafe state {3}.

In A, when state ({1}, {1}) is reached, event g may occur in the plant. If the
attacker erases it, state ({2}, {1}) is reached. Then b may occur in the plant,
corresponding to the transition [({2}, {1}), b, ({3}, {y∅})]. Similar arguments can
be used to explain how the other target states ({3}, {0}) and ({3}, {1}) are
reached.

In A, when state ({2}, {2}) is reached, the attacker can enable event b, cor-
responding to the transition [({2}, {2}), bS, ({3}, {y∅})]. If bS is erased, state
(cid:117)(cid:116)
({3}, {2}) is reached.

Supervised discrete event systems under attack

15

6.2 Supremal Stealthy Attack Substructure

We notice that a subset of states in A reveals the presence of an attacker, thus
the attacker should make sure these states are not reached if he wants to remain
stealthy. We call stealthy attack substructure the structure obtained by appro-
priately trimming A, and we show how to obtain a supremal stealthy attack
substructure that contains all the possible attacks that remain stealthy.

Deﬁnition 8. The set of exposing states of an attack structure A = (R, Ea, ∆a,
(cid:117)(cid:116)
r0) is Re := {r = (b, ya) ∈ R | ya = y∅}.

Exposing states are those states whose second entry is equal to y∅. When
such a state is reached, the corrupted observation is not consistent with the
observation generated by the plant without attack, thus the supervisor detects
that the system is under attack.

Further additional states should be removed from A, in particular, those
from which an exposing state is surely reached after a ﬁnite number of events
generated by the plant. We call the set of such states weakly exposing region Re.
The weakly exposing region can be computed using Algorithm 3 in [18].

Example 4. Consider the attack structure A in Fig. 6, the exposing states are
highlighted in gray, and the other states in Re are highlighted in yellow.

As an example, since in the attack structure there exists transition [({7}, {5}),
c, ({8}, {y∅})] and c /∈ Eera, and there does not exist a transition labeled e+ ∈ E+
yielding a state not in Re, then state ({7}, {5}) should be added to Re.
(cid:117)(cid:116)
Let A be an attack structure, and Re be its weakly exposing region. The
supremal stealthy attack substructure Ass is obtained removing from A all states
in Re and their input and output arcs (a more detailed discussion on this can
be found in Section 7 of [18]).

Example 5. Consider again the attack structure A in Fig. 6. The supremal
stealthy attack substructure Ass is visualized in Fig. 7.

At state ({2}, {2}), if the attacker enables event b, as shown in A, the exposing
state ({3}, {y∅}) is reached, then the attack is not stealthy, thus state ({3}, {y∅})
should be removed. If the attacker enables event b, and then erases it, as shown
in Ass, state ({3}, {2}) is reached, thus the attack is stealthy.
(cid:117)(cid:116)

6.3 Computational Complexity

Given a plant G with set of states X. The observer can be constructed in 2|X|
steps, and the supervisor can be constructed in 2|X| steps [26]. The attack struc-
ture is obtained by computing A = Obsatt(G) (cid:107) SPa . Therefore, A can be con-
structed in 2|X| × 2|X| steps. Since the supremal stealthy attack substructure
Ass is obtained by appropriately reﬁning A, thus the complexity of constructing
Ass is O(22|X|).

16

Qi Zhang et al.

Fig. 7. Supremal stealthy attack substructure Ass.

7 CONCLUSIONS AND FUTURE WORK

In this paper we considered the problem of cyber attacks in supervisory control
systems. We developed a supremal stealthy attack substructure that allows us
to select attacks that cause the closed-loop system SP /G to reach the unsafe
state. The way the attacks are generated guarantees that the supervisor never
realizes the presence of an attacker before the unsafe state is reached.

In the future, we will show how to synthesize a supervisor that is robust

against such attacks.

References

1. F. Harirchi, and N. Ozay, “Guaranteed model-based fault detection in cyber-physical
systems: a model invalidation approach,” Automatica, vol. 93, pp. 476–488, Jul.
2018.

2. A. Clark and S. Zonouz, “Cyber-physical resilience: deﬁnition and assessment met-

ric,” IEEE Trans. on Smart Grid, vol. 10, no. 2, pp. 1671–1684, Mar. 2019.

3. S. Sundaram and C. N. Hadjicostis, “Distributed function calculation via linear
iterative strategies in the presence of malicious agents,” IEEE Trans. on Autom.
Control, vol. 56, no. 7, pp. 1495-1508, Jul. 2011.

4. F. Pasqualetti, F. D¨orﬂer, and F. Bullo, “Attack detection and identiﬁcation in
cyber-physical systems,” IEEE Trans. on Autom. Control, vol. 58, no. 11, pp. 2715–
2729, Nov. 2013.

5. H. Fawzi, P. Tabuada, and S. Diggavi, “Secure estimation and control for cyber-
physical systems under adversarial attacks,” IEEE Trans. on Autom. Control, vol.
59, no. 6, pp. 1454–1467, Jun. 2014.

6. D. Thorsley and D. Teneketzis, “Intrusion detection in controlled discrete event
systems,” in Proc. IEEE 45th Annu. Conf. on Decision and Control, San Diego,
USA, Dec. 2006, pp. 6047-6054.

Supervised discrete event systems under attack

17

7. L. K. Carvalho, Y.-C. Wu, R. Kwong, and S. Lafortune, “Detection and prevention
of actuator enablement attacks in supervisory control systems,” in Proc. 13th Int.
Workshop on Discrete Event Systems, Xi’an, China, May 2016, pp. 298–305.

8. P. M. Lima, M. V. S. Alves, L. K. Carvalho, and M. V. Moreira, “Security
against network attacks in supervisory control systems,” in Proc. 20th IFAC World
Congress, Toulouse, France, Jul. 2017, pp. 12333–12338.

9. R. Su, “A cyber attack model with bounded sensor reading alterations,” in Proc.

American Control Conference, Seattle, USA, May 2017, pp. 3200-3205.

10. R. M. G´oes, E. Kang, R. Kwong, and S. Lafortune, “Stealthy deception attacks for
cyber-physical systems,” in Proc. IEEE 56th Annu. Conf. on Decision and Control,
Melbourne, Australia, Dec. 2017, pp. 4224–4230.

11. P. M. Lima, L. K. Carvalho, and M. V. Moreira, “Detectable and undetectable
network attack security of cyber-physical systems,” in Proc. 14th Int. Workshop on
Discrete Event Systems, Sorrento, Italy, May 2018, pp. 179–185.

12. R. Su, “Supervisor synthesis to thwart cyber attack with bounded sensor reading

alterations,” Automatica, vol. 94, pp. 35-44, Aug. 2018.

13. M. Wakaiki, P. Tabuada, and J. P. Hespanha, “Supervisory control of discrete-
event systems under attacks,” Dyn. Games and Appl., vol. 9, pp. 965–983, Sep.
2018.

14. L. Lin, S. Thuijsman, Y. Zhu, S. Ware, R. Su, and M. Reniers, “Synthesis of

successful actuator attackers on supervisors,” ArXiv : 1807.06720, Feb. 2019.

15. Y. Zhu, L. Lin, and R. Su, “Supervisor obfuscation against actuator enablement
attack,” in Proc. 18th European Control Conference, Napoli, Italy, Jun. 2019, pp.
1760-1765.

16. L. K. Carvalho, Y.-C. Wu, R. Kwong, and S. Lafortune, “Detection and mitigation
of classes of attacks in supervisory control systems,” Automatica, vol. 97, pp. 121–
133, Nov. 2018.

17. P. M. Lima, M. V. S. Alves, L. K. Carvalho, and M. V. Moreira, “Security against
communication network attacks of cyber-physical systems,” J. of Control, Autom.
and Electrical Systems, vol. 30, no. 1, pp. 125–135, Sep. 2019.

18. Q. Zhang, C. Seatzu, Z. Li, and A. Giua, “Cyber attacks with bounded sensor
reading edits for partially-observed discrete event systems,” ArXiv : 1906.10207, Apr.
2020.

19. A. Giua, C. Seatzu, and F. Basile, “Observer-based state-feedback control of timed
Petri nets with deadlock recovery,” IEEE Trans. on Autom. Control, vol. 49, no. 1,
pp. 17–29, Jan. 2004.

20. M. P. Cabasino, A. Giua, and C. Seatzu, “Fault detection for discrete event systems
using Petri nets with unobservable transitions,” Automatica, vol. 46, no. 9, pp. 1531–
1539, Sep. 2010.

21. M. P. Cabasino, A. Giua, M. Pocci, and C. Seatzu, “Discrete event diagnosis using
labeled Petri nets. An application to manufacturing systems,” Control Eng. Practice,
vol. 19, no. 9, pp. 989–1001, Sep. 2011.

22. M. P. Cabasino, A. Giua, S. Lafortune, and C. Seatzu, “A new approach for di-
agnosability analysis of Petri nets using Veriﬁer Nets,” IEEE Trans. on Autom.
Control, vol. 57, no. 12, pp. 3104–3117, Dec. 2012.

23. Y. Tong, Z. Li, C. Seatzu, and A. Giua, “Veriﬁcation of state-based opacity using
Petri nets,” IEEE Trans. on Autom. Control, vol. 62, no. 6, pp. 2823-2837, Jun.
2017.

24. C. Gao, C. Seatzu, Z. Li, and A. Giua, “Multiple attacks detection on discrete
event systems,” in Proc. IEEE Int. Conf. on Syst., Man, and Cybern., Bari, Italy,
Oct. 2019, pp. 2352–2357.

18

Qi Zhang et al.

25. P. J. G. Ramadge and W. M. Wonham, “The control of discrete event systems,”

Proceedings of the IEEE, vol. 77, no. 1, pp. 81-98, Jan. 1989.

26. C. G. Cassandras and S. Lafortune, Introduction to discrete event systems.

Springer, 2008.

