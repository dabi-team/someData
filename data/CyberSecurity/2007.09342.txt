0
2
0
2

l
u
J

8
1

]

R
C
.
s
c
[

1
v
2
4
3
9
0
.
7
0
0
2
:
v
i
X
r
a

Toward a Deep Learning-Driven Intrusion Detection
Approach for Internet of Things

Mengmeng Gea, Naeem Firdous Syeda, Xiping Fub, Zubair Baiga, Antonio
Robles-Kellya

a(mengmeng.ge, naeem.syed, zubair.baig, antonio.robles-kelly)@deakin.edu.au, School of
Information Technology, Deakin University, Geelong, VIC, Australia
bfxpfxp0607@gmail.com, PredictHQ Limited, Auckland, New Zealand

Abstract

Internet of Things (IoT) has brought along immense beneﬁts to our daily
lives encompassing a diverse range of application domains that we regularly
interact with, ranging from healthcare automation to transport and smart
environments. However, due to the limitation of constrained resources and
computational capabilities, IoT networks are prone to various cyber attacks.
Thus, defending the IoT network against adversarial attacks is of vital
importance. In this paper, we present a novel intrusion detection approach for
IoT networks through the application of a deep learning technique. We adopt
a cutting-edge IoT dataset comprising IoT traces and realistic attack traﬃc,
including denial of service, distributed denial of service, reconnaissance and
information theft attacks. We utilise the header ﬁeld information in individual
packets as generic features to capture general network behaviours, and develop
a feed-forward neural networks model with embedding layers (to encode high-
dimensional categorical features) for multi-class classiﬁcation. The concept of
transfer learning is subsequently adopted to encode high-dimensional categorical
features to build a binary classiﬁer. Results obtained through the evaluation
of the proposed approach demonstrate a high classiﬁcation accuracy for both
binary and multi-class classiﬁers.

1. Introduction

Internet of Things (IoT) has proliferated into our daily life at a very rapid
pace. Recent statistics show IoT devices have pervaded into various domains,
including smart cities (28.6%), industrial IoT (26.4%), eHealth (22%), smart
homes (15.4%) and smart vehicles (7.7%) [6]. Moreover, the number of IoT
devices in use has seen a steep rise from 15.4B in 2015 to 26.7B in 2019, with
numbers continuing to climb as households and businesses alike are increasingly
becoming dependent on Internet-based services for their routine activities.
Many critical infrastructures also comprise of IoT devices. For instance, the
smart grid has been constantly interacting with IoT devices that measure

Preprint submitted to Elsevier

July 21, 2020

 
 
 
 
 
 
electricity grid parameters and report these back to a central computing device,
for processing.

Advances in IoT technologies have demonstrated beneﬁts to users. However,
IoT devices have also been exposed to cyber threats as posed by the adversary
due to the heterogeneity in the communication protocols and constrained
resources and large-scale proliferation of IoT devices.
For example, one
commonly used application protocol in IoT networks is the Message Queuing
Telemetry Transport (MQTT). The MQTT protocol is lightweight in nature
and based upon the publish-subscribe model of communication; using the
MQTT protocol, IoT devices can communicate with centralised computing
nodes through intermediary brokers [15]. However, the MQTT protocol suﬀers
from many vulnerabilities that open up the IoT space to the ever-evolving
adversarial threat, including device compromise, data theft, limited resource
access for legitimate IoT nodes, and Man-in-The-Middle (MiTM) attacks for
communicating IoT device pairs.

Intrusion detection systems are designed and developed to foster rapid and
accurate identiﬁcation of malicious attempts by the adversary to penetrate into
IoT networks and to cause system disruption. The application of artiﬁcial
intelligence (AI) for the timely detection of malicious attacks, is both necessary
as well as eﬀective. The range of AI techniques applicable for network intrusion
detection (i.e., for detecting malicious attacks through analysis of network
traﬃc) is very broad. Many AI techniques, including support vector machines
(SVM) [12], Bayesian networks [3], principal component analysis [9], and genetic
algorithms [20], have been popularly deployed for the detection of anomalous
behaviour in IoT networks. However, deep learning based intrusion detection
for IoT networks is still under-researched.

In this work, we propose a novel intrusion detection approach against cyber
attacks for IoT networks based upon the concept of deep learning. We design
the classiﬁer as a feed-forward neural networks model with embedding layers
to identify four categories of attacks, namely distributed denial of service
(DDoS), denial of service (DoS), reconnaissance, and information theft, whilst
diﬀerentiating these from the legitimate network traﬃc.
In addition, the
encoding of high-dimensional categorical features is extracted through network
embedding and applied to binary classiﬁer via transfer learning.

A preliminary version of this paper appeared in [7]. We have extended the
earlier version with (1) a thorough investigation of header ﬁelds and inclusion
of new features, (2) design of a feed-forward neural networks model with
embedding to deal with high-dimensional categorical features for multi-class
classiﬁcation, and (3) employment of transfer learning to build a feed-forward
neural networks model for binary classiﬁcation with low-dimensional continuous
vector representation of high-dimensional categorical features. The proposed
classiﬁers in this extended work have demonstrated a signiﬁcant improvement
of performance regarding all evaluation measures. Main contributions of the
paper are as follows.

• Adoption of a newly published IoT dataset with realistic attack traﬃc and

2

simulated IoT traﬃc in a smart home scenario;

• Generation of generic features based on the header ﬁeld information
in individual IP packets to avoid the attack-oriented feature selection
procedure;

• Design and development of the deep learning based intrusion detection
approach including both binary and multi-class classiﬁcations for IoT
networks with high accuracy.

The rest of the paper is organised as follows.

Section 2 provides the
background to the study. Our proposed intrusion detection framework is
presented in Section 3. In Section 4, we provide a description of the dataset,
design of the experimental setup, and analysis of the obtained results. A
discussion on future directions of the work is provided in Section 5, and the
paper is concluded in Section 6.

2. Related Work

In this section, we brieﬂy survey the state-of-the-art literature in intrusion
detection approaches for traditional and IoT networks with the support of
machine learning and deep learning techniques.

Approaches for traditional networks: Haddadi et al.

[8] proposed a
feed forward neural network-based approach to detect DoS, root to local (R2L),
user to root (U2R), and probe attacks in the DARPA dataset [13]. A feed
forward neural network comprises an input, a hidden and an output layer, with
each layer consisting of several neurons. During the training phase, various
strategies and mathematical operations are incorporated into the neural network
to tune weights that interconnect the three layers until an optimal solution
is obtained. The back propagation algorithm is the most commonly adopted
algorithm in training neural networks to update and choose optimal weights of
the interconnections which minimise the loss. Authors reported an accuracy of
over 96% in detecting three attack categories among four categories available in
the DARPA dataset.

An approach using an ensemble of classiﬁers was proposed in [11] to detect
DDoS attacks.
In their approach, the dataset was split into smaller subsets
and each subset was trained using an ensemble of classiﬁers. Results of
individual classiﬁer were combined through the adoption of a weighted majority
voting technique which assigns a diﬀerent weight to each algorithm. The back
propagation algorithm was incorporated into the classiﬁer. Their approach
obtained an accuracy of 99.4% in classifying attacks in several publicly available
datasets.

Al-Zewairi et al. [2] proposed a deep learning model for detecting network
based attacks in the UNSW-NB 15 dataset [14]. Their model consists of ﬁve
hidden layers along with ten neurons distributed across each hidden layer. A
10-fold cross validation technique was implemented by the authors to train the
model on the full dataset in 10 epochs. In addition, the importance of features

3

was ranked using the Gedeon method to identify top contributing features. The
proposed approach achieved an accuracy of approximately 99% on the selected
dataset.

Approaches for IoT networks: Koroniotis et al.

An approach based on the radial basis function was proposed in [4] to detect
DoS attacks. Authors applied radial basis function as the ﬁrst layer to reduce the
training bias which improves the weight optimisation technique of traditional
neural networks. The proposed approach achieved an accuracy of 99.69% when
tested on the NSL KDD [18] and the UNSW-NB 15 [14] datasets. In a similar
work, Shone et al. [17] adopted a deep network composed of deep auto encoders
stack to perform an unsupervised feature learning which is further combined
with a random forest classiﬁer. Their approach was test via the NSL KDD [18].
[10] deployed an IoT
testbed to generate an IoT dataset, namely Bot-IoT, due to the lack of realistic
IoT traﬃc in existing datasets. Authors incorporated instances of legitimate
and simulated IoT traﬃc into the dataset along with the attack traﬃc, including
DDoS, DoS, reconnaissance and information theft. Several new features were
developed based on correlation coeﬃcient and joint entropy techniques and three
machine learning and deep learning algorithms were adopted. The classiﬁers
were evaluated on 5% of the original dataset for binary classiﬁcation (i.e., normal
traﬃc and attack traﬃc of each subcategory) and achieved good accuracy
demonstrated through the results. However, the extracted dataset contains
imbalanced normal and attack traﬃc as the number of instances in some attack
categories (i.e., DDoS, DoS, and reconnaissance) is much higher than the number
of instances in the normal traﬃc.

Abeshu et al. [1] proposed a stacked auto-encoder-based unsupervised deep
learning framework for distributed attack detection in IoT networks with a fog
computing layer.
In speciﬁc, fog nodes are responsible for parallel training
and model/parameter update. Authors pre-trained the stacked auto-encoder
model with unlabelled training data to extract hidden features which were then
applied to test data for classiﬁcation. They evaluated the proposed approach
using the NSL KDD [18] with 41 features. The deep learning model obtained a
higher detection accuracy compared to a shallow learning model (i.e., without
pre-training).

Thamilarasu et al. [19] employed a deep belief network (DBN) to construct a
feed-forward deep neural network (DNN) for anomaly-based intrusion detection
in IoT networks. In speciﬁc, DBN layers can be pre-trained using unsupervised
learning technique and then taken as hidden layers in the DNN. Authors
implemented an IoT testbed with 6 sensors to form a smart home scenario
and evaluated the proposed model using the network traﬃc generated from the
testbed. The model achieved high precision, recall, and F1 score for various
attacks compared to an existing intrusion detection approach based on inverse
weight clustering.

Roopak et al. [16] compared the performance of four deep learning models
in DDoS attacks against IoT networks. The four models include multi-
layer perceptron (MLP), convolution neural network (CNN), long short-term
memory (LSTM), and a combination of CNN and LSTM. Authors adopted the

4

CICIDS2017 dataset with 82 ﬂow-based features for evaluation. Comparison
results demonstrated that a combination of CNN and LSTM achieved a better
performance while MLP had the least performance compared to other neural
networks models.
Baig et al.

[5] proposed the usage of average dependence estimators for
detecting DoS attacks in smart IoT sensors. Authors deployed a custom IoT
testbed via MQTT protocol and incorporated DoS attack scenarios based on the
protocol. Several packet level features such as source & destination IP addresses
and port numbers, frame length, IP packet length, TCP segment length, and
header length, were used in generating the dataset. Two estimators, namely
averaged one-dependence estimator (A1DE) and averaged two-dependence
estimator (A2DE), were adopted and compared with several traditional machine
learning algorithms. Evaluation results indicated that A1DE/A2DE-based
classiﬁer achieved higher accuracy compared with other classiﬁcation algorithms
when tested on the custom dataset and BoT-IoT testbed [10].

Summary: there is little research on deep learning based intrusion detection
solutions for IoT networks. Among current approaches, some approaches
used the datasets without IoT traces [1, 16] while others focused on binary
classiﬁcation [10, 19]. We can see that one critical reason could be the lack
of reliable IoT datasets with the inclusion of attack traﬃc. In this paper, we
adopt the newly published Bot-IoT dataset in [10], develop a novel deep learning
based detection approach with generic features in packet level, and perform both
binary and multi-class classiﬁcation.

3. Proposed Framework

Figure 1: Workﬂow of the framework.

In this section, we provide a description of the proposed framework
for detecting intrusions in IoT networks. Figure 1 shows the framework
comprising of four phases:
feature extraction, feature preprocessing, training
and classiﬁcation. We explain them in detail as follows.

• Feature extraction: the ﬁrst phase is to collect the raw network traﬃc
using a network analyser tool (e.g., tcpdump). Relevant ﬁelds are then
extracted from packets in the raw network traﬃc, with each ﬁeld referring
to a feature. Features adopted in this work are not based on aggregated
packets but header ﬁelds from individual packets. Hence, generic features
of the traﬃc could be captured rather than generating attack speciﬁc
features which might only work for detecting speciﬁc attack behaviours.

5

We focus on header ﬁelds of an IP packet, such as frame, IPv4/IPv6
and TCP/UDP related information. Details of the extracted features are
discussed in Section 4.2.

• Feature preprocessing: the second phase is to preprocess the extracted
ﬁeld information by combining, removing, and encoding column values.
For categorical data, we apply one-hot encoding to low-dimensional feature
columns and embedding (incorporated with the feed-forward neural
networks model) to high-dimensional feature columns. The preprocessed
data is split into training and testing sets which are used in the training
phase and classiﬁcation phase respectively. Packets in both training and
testing sets are labeled as either malicious or normal. Malicious packets
are further labelled with the speciﬁc attack category it belongs to. Testing
packets are used only for evaluating the model accuracy in predicting
attacks. Details of the feature preprocessing procedures are discussed in
Section 4.3.

• Training: the training phase takes the processed data from the training
set and feeds it into a feed-forward neural networks model. We consider
both binary and multi-class classiﬁcation. We develop a feed-forward
neural networks model with embedding layers for multi-class classiﬁcation,
wherein a range of attack categories are treated as separate classes in
addition to the class of normal traﬃc. We then extract weights from the
embedding layers to encode high-dimensional categorical feature columns
and build a second feed-forward neural networks model to perform binary
classiﬁcation. Details of the model architecture and tuning process are
discussed in Section 4.4.

• Classiﬁcation:

the ﬁnal phase is to evaluate the classiﬁers on the
speciﬁed testing set. The binary classiﬁer outputs either a normal or
attack label for each data instance in the testing set while the multi-class
classiﬁer outputs class labels (i.e., normal or speciﬁc attack class that it
belongs to). Analysis of the evaluation results is presented in Section 4.5.

4. Evaluation and Analysis

In this section, we ﬁrst introduce the dataset used in the evaluation and
then discuss feature extraction and feature preprocessing. Lastly, we provide
description of the experiment setup and analysis of results.

4.1. Dataset Description

We use the BoT-IoT dataset developed by Koroniotis et al.

[10] in the
Cyber Range Lab of the UNSW Canberra Cyber Centre. Authors deployed
a testbed to collect legitimate traﬃc from simulated IoT devices along with
malicious traﬃc of various attacks. Five types of IoT devices were considered
in the testbed to form a smart home scenario, including a weather station, a

6

smart fridge, a smart thermostat, a remotely controlled garage door, and smart
lights.
In speciﬁc, the testbed consists of virtual machines (VMs) as attack
or target machines, network devices (e.g., pfSense ﬁrewall), and simulated IoT
devices running on normal VMs which are also connected to the IoT hub of
the Amazon Web Services (AWS). These simulated IoT devices publish data
using the MQTT procotol to the MQTT broker. There are four categories
(ten subcategories) of malicious traﬃc generated in the dataset, including DoS
and DDoS attacks over TCP, UDP and HTTP, probing attacks (port scanning
and OS ﬁngerprinting), and information theft (data exﬁltration and keystroke
logging). The detailed description of the testbed setup and statistics of attacks
could be found in the paper [10].

Reasons to adopt the dataset include the conﬁguration of real testbed,
collection of realistic attack traﬃc, generation of simulated IoT traﬃc in a smart
home scenario, and inclusion of labelled data.

4.2. Feature Extraction

Raw traﬃc in the BoT-IoT dataset was collected in the format of PCAP
ﬁles. Authors labelled the raw traﬃc while collecting it and generated network
ﬂows by using the Argus tool. The processed traﬃc was stored in Argus ﬁles
and further converted to CSV ﬁles. Labels in both Argus ﬁles and CSV ﬁles are
ﬂow-based. However, we need to retrieve labels on individual packets in order
to perform the packet-level detection via our framework. We started with the
collection of the PCAP ﬁles and obtained a total of 344 PCAP ﬁles from the
BoT-IoT dataset. The PCAP ﬁles were organised into ten attack subcategories,
namely DoS/DDoS over TCP, UDP and HTTP, service scan, OS ﬁngerprinting,
Keystroke logging, and data exﬁltration.

We extracted individual packet header information from the PCAP ﬁles
using the TShark tool, labelled the packets and output them into the CSV ﬁles.
We then converted the CSV ﬁles to a single Apache Parquet ﬁle, uniﬁed the
schema, and extracted roughly 2% of the processed dataset. We explain details
of each step in the following.

Feature description: we only considered IP packets and extracted a total
of 29 packet header ﬁelds from the PCAP ﬁles shown as follows. ARP packets
were excluded because they are used to convert an IP address to a MAC address
and irrelevant to the proposed attacks in the dataset.

• Frame related ﬁelds: frame.time epoch, frame.len

• IP related ﬁelds:

ip.proto, ip.src, ip.dst, ipv6.src, ipv6.dst, ip.ttl, ip.id,

ip.hdr len, ip.len, ip.ﬂags.df

• TCP related ﬁelds: tcp.srcport, tcp.dstport, tcp.stream, tcp.time delta,
tcp.time relative, tcp.analysis.initial rtt, tcp.ﬂags, tcp.window size value,
tcp.hdr len, tcp.len

• UDP related ﬁelds: udp.srcport, udp.dstport, udp.stream, udp.length

7

• HTTP related

ﬁelds:

http.response.code,

http.request.method,

http.content length

The TCP/IP protocol suite is vulnerable to a variety of attacks. The header
ﬁelds of an individual packet could reﬂect generic features of the traﬃc and any
deviation of values from a normal range in the ﬁelds could potentially become
an indicator of attacks. For example, TCP, UDP, and HTTP are commonly
exploited by attackers to launch protocol-based DDoS/DoS attacks; TCP and
UDP are generally the protocols used in port scanning; OS ﬁngerprinting works
by sending TCP, UDP, and ICMP probes to known open and closed ports of the
target; during post-exploitation, data could be exﬁltrated via diﬀerent channels
(e.g., HTTP, TCP) while keystrokes could be observed via a reverse HTTP/TCP
connection.

Label mapping: we analysed network ﬂows in the original labelled dataset
and replicated same labels for all individual packets within network ﬂows.
In speciﬁc, as described in [10], attack traﬃc of diﬀerent subcategories was
launched at diﬀerent times with normal traﬃc generated in the background,
which makes it easier to diﬀerentiate attacks; in addition, there are four bot
machines deployed to launch attacks, which enables us to diﬀerentiate normal
and attack traﬃc based on IP address of bot machines. Therefore, we developed
a script to match the IP address of the bot machine and label packets with each
attack subcategory. Labelled packets are stored in the CSV ﬁles for further
processing. These CSV ﬁles with labelled traﬃc are placed in diﬀerent folders
based on the subcategory of attacks.

File conversion and schema uniﬁcation: we converted the CSV ﬁles
to a single Apache Parquet ﬁle, which reduces the ﬁle size and improves the
processing speed. During conversion, we also uniﬁed the schema of all ﬁles. In
speciﬁc, some ICMP packets contain the UDP packet inside the ICMP payload
due to the recognition of the embedded packet by the network protocol analyser.
Therefore, some IP related ﬁelds (e.g., ip.proto, ip.ttl) could be either string type
(i.e., two values separated by comma) or double type. We enforced all values in
those columns to be string type for consistency. Table 1 shows statistics of the
processed dataset with extracted features.

Dataset extraction: we selected roughly 2% of the processed dataset with
extracted features. For each subcategory of attacks, we used all packets when
the number of packets is lower than 1 million and selected 1 million packets if the
number of packets is larger than 1 million. For the normal traﬃc, we selected
roughly 2% from all normal packets. In speciﬁc, for each attack subcategory with
more than 1 million packets, the random selection was implemented through
choosing a fraction of total packets of that attack subcategory (i.e., the fraction
is 1 million divided by the total number of packets). Therefore, the number of
chosen packets ﬂuctuates slightly either above or below 1 million. The number
of packets extracted is 11252406 including a mix of normal and attack traﬃc.

8

Table 1: Statistics of the processed dataset with extracted features.

Category

DDoS

DoS

Reconnaissance

Information theft

Normal

Subcategory
HTTP
TCP
UDP
HTTP
TCP
UDP
OS ﬁngerprinting
Service scanning
Data exﬁltration
Keylogging
Normal

Total

Number of packets
194417
95643746
174344218
287480
59977444
191208992
827940
3814730
301710
11387
23175520
549787584

4.3. Feature Preprocessing

We used a high performance computing (HPC) cluster with one Tesla V100
GPU and 93G RAM to preprocess extracted features in the Parquet and run the
proposed deep learning model. We ﬁrst selected ﬁelds that can be used as inputs
into the deep neural networks model. We dropped the timestamp column (i.e.,
frame.time epoch) and IPv4/IPv6 address related columns (i.e., ip.src, ip.dst,
ipv6.src, and ipv6.dst). We combined four pairs of columns respectively because
values in those two columns of each pair do not overlap with each other. The
four pairs of these columns include: tcp.srcport and udp.srcport; tcp.dstport
and upd.dstport; tcp.len and udp.length; tcp.stream and udp.stream. Combined
columns are named as src.port, dst.port, length, and stream. We split columns
with comma separated values (i.e.,
ip.hdr len, and ip.len) into
ip.ttl,
two columns while non-embedded packets are ﬁlled with NaN values in the
second column. Afterwards, we ﬁlled NaN/None values with either numeric
values or string values. For numeric columns with meaningful zero values (e.g.,
ip.ﬂags.df, tcp.ﬂags, src.port, and dst.port), we obtained the maximum value
in each column and ﬁlled NaN values with the maximum value plus 1. For
the string column (i.e., http.request.method), we ﬁlled None values with ‘0’ (in
string type). For other columns, we ﬁlled NaN values with 0.

ip.id,

After dropping several irrelevant columns, duplicated rows were introduced.
We dropped redundant rows because the testing traﬃc should not have
duplicates from the training traﬃc. Without redundancy, we will be able to
check how the model will perform on unseen data in the testing phase. Table 2
presents statistics of the dataset before and after dropping duplicates rows.
We can see that the total number of packets being kept is roughly 81.44% of
the processed dataset while the majority of packets being dropped are normal
packets with a drop rate of 45.08%.

We identiﬁed feature columns with categorical data. For columns with
low-dimensional categorical variables (i.e., ip.proto, tcp.ﬂags, ip.ﬂags.df, and

9

Table 2: Statistics of the dataset before and after dropping duplicated rows.

Category

Subcategory

DDoS

DoS

Reconnaissance

Information theft

Normal

HTTP
TCP
UDP
HTTP
TCP
UDP
OS ﬁngerprinting
Service scanning
Data exﬁltration
Keylogging
Normal

Total

Drop duplicated rows

Before
194417
999444
1000055
287480
998703
999977
827940
999895
301710
11387
4631398
11252406

After
194417
999444
1000054
287480
998703
999977
827058
999895
301710
11387
2543626
9163751

http.response.code), we applied one-hot encoding and dropped original columns.
We refer these columns and other columns with non-categorical values as
input columns. For columns with highly-dimensional categorical variables (i.e.,
src.port, dst.port, and http.request.method), we separated them from other
columns and will apply embedding in the deep neural networks model to
compute a dense representation of ports and HTTP request methods. We
refer these three columns as embedding columns. We normalised input columns
within a given range between (-1, 1) to avoid extreme values and potentially
help in speeding up calculations. We stored input columns, port embedding
columns and embedding column for HTTP request methods as three arrays.

We also encoded label columns. We considered both binary classiﬁcation
(i.e., classify normal packets and attack packets from each subcategory of
attacks separately) and multi-class classiﬁcation (i.e., classify normal packets
and malicious packets from DDoS/DoS, information theft and reconnaissance
attacks). In the binary classiﬁcation, a normal packet is labelled as 0 while an
attack packet is labelled as 1; in the multi-class classiﬁcation, packets from each
class are labelled from 0 to 3 respectively. Labels for each classiﬁcation were
stored as an array.

4.4. Experimental Setup

We used TensorFlow library and Keras. All our experiments were eﬀected
on the HPC cluster with Tesla V100 GPU. We split the extracted dataset with
64%-16%-20% on training, validation, and testing in a stratiﬁed fashion thus
training, validation, and testing sets have approximately the same percentage
of samples of each class as the complete set. We introduced class weights to the
training data due to the imbalanced samples of diﬀerent classes. The weight
for each class was given by the inverse of the quotient value from dividing the
packet count in one particular class by the maximum packet count among all

10

classes. In this manner, the under-represented class with a relatively smaller
number of samples obtains a higher weight value.

4.4.1. Model Design

We consider to use feed-forward neural networks (FNN) models. For multi-
class classiﬁcation, the FNN model has two embedding layers and three dense
layers. For binary classiﬁcation, we applied the concept of transfer learning by
using the embedding vectors resulting from embedding layers in the FNN model
for multi-class classiﬁcation. We initialised both models with random weights.
We applied Adam optimiser and a sparse categorical cross-entropy loss function.
We denote the FNN model for multi-class classiﬁcation as mFNN and the model
for binary classiﬁcation as bFNN and explain them in details as follows.

mFNN: Figure 2 shows the architecture of the FNN model along with
interactions with the loss function and the solver for multi-class classiﬁcation.
mFNN model takes three arrays as inputs in which two of them are inputs for
the embedding layers. The port embedding layer has an input dimension of
65537 (with all oﬃcial and non-oﬃcial ports between 0 and 65535 and 65536
encoded for NaN values) and an output dimension of 16 while HTTP request
method embedding layer has an input dimension of 93 (with a number of 92
oﬃcial request methods and a string encoded for none values) and an output
dimension of 4. The model consists of three dense hidden layers with each input
neuron being connected with each output neuron in each hidden layer. The
ﬁrst two hidden layers have 512 neurons and use a ReLU activation function in
each layer while the last hidden layer has 4 neurons corresponding to 4 classes
and uses a Softmax function which turns numbers into probabilities that sum
to one.

bFNN: Figure 3 shows the architecture of the FNN model for binary
classiﬁcation. bFNN model uses weights of the two embedding layers from
mFNN model to encode source/destination ports and HTTP request methods;
the encoded columns (i.e., src.port, dst.port, and http.request.method) are then
combined with other columns and taken as input into the model. bFNN model
has three dense hidden layers with the ﬁrst two hidden layers consisting of 512
neurons and using a ReLU function in each layer and the last hidden layer
having 2 neurons and a Softmax function.

4.4.2. Model Tuning

We tuned mFNN model with diﬀerent hyperparameters and three
regularisation techniques. We used same hyperparameters and regularisation
optimisation for bFNN model because we want to apply the generalisation of
the model to diﬀerent cases. We discuss the regularisation and tuning procedure
for the multi-class classiﬁcation in details in the following paragraphs. We used
the FNN model with three dense hidden layers, 512 neurons in the ﬁrst two
hidden layers and default learning rate of Adam optimiser (i.e., 0.001) as the
baseline model.

Regularisation: we ﬁrst experimented with three commonly used
regularisation techniques including L1, L2, and dropout. Results show the

11

Figure 2: FNN model for multi-class classiﬁcation.

classiﬁcation accuracy does not improve. That said, regularisation is proven
eﬀective for preventing over-ﬁtting. Since our model is trained on a dataset
with millions of samples, the over-ﬁtting problem is a less concern.

tuning:

Hyperparameter

then experimented with diﬀerent
we
architectures of the neural networks, including adding/reducing hidden layers
(ranging from two to four hidden layers), increasing the number of neurons in
hidden layers (including 512 or 1024 neurons; excluding the last dense layer),
and adding dropout with dropout rate of 0.1 in hidden layers (excluding the
last dense layer). Results demonstrate that the baseline neural networks model
with three hidden layers and 512 neurons in the ﬁrst two layers has the best

12

Figure 3: FNN model for binary classiﬁcation.

performance. Diﬀerent variants of the neural networks model do not increase
the classiﬁcation accuracy. One possible reason could be that the complexity
of the model is either too small or too large. When the model complexity is
too small, the model may not be capable of capturing the variation of diﬀerent
classes in the training data; when the complexity is too large, the model tends
to over-ﬁt diﬀerent classes in the training data. Therefore, the model with too
large/small complexity would make the performance on speciﬁc classiﬁcation
problems worse. Lastly, we experimented with diﬀerent learning rates of Adam
optimiser, including 0.01, 0.001, 0.0001, and 0.00001. We chose the learning rate
of 0.0001 which gives highest accuracy. A larger learning rate tends to oscillate
over training epochs, causing weights to diverge while a smaller learning rate
could possibly get stuck on a sub-optimal solution.

We also applied an early stopping technique with a patience of 5 iterations

13

to terminate the training as soon as the validation loss reaches a minimum.
This has the advantage of reducing over-ﬁtting problem. The FNN model was
trained with a batch size of 256 and the maximum epoch was set to be 20.

4.5. Analysis of Results

We discuss results for the multi-class classiﬁcation and binary classiﬁcation.
We compute confusion matrices for both classiﬁcation problems and use
following metrics to evaluate the model performance in the binary classiﬁcation:
accuracy, precision, recall, and F1 score. In speciﬁc, accuracy is deﬁned as the
number of correct predictions, including true positive (TP) and true negative
(TN) predictions, divided by the total number of predictions; precision is the
number of TP predictions divided by the total number of predicted positive class
values; recall is the number of TF predictions divided by the number of actual
positive class values; F1 score is weighted average of precision and recall. A low
precision indicates a large number of false positive (FP) predictions (normal
packets classiﬁed as attack packets) while a low recall could indicate a large
number of false negative (FN) predictions (attack packets classiﬁed as normal
packets); a good F1 score indicates low FP/FN predictions because it combines
precision and recall. Table 3 shows deﬁnitions of the metrics in terms of positives
and negatives.

Table 3: Deﬁnitions of metrics.

Accuracy

Precision

Recall

T P + T N
T P + T N + F P + F N
T P
T P + F P
T P
T P + F N

F1 score

2 ×

P recision × Recall
P recision + Recall

Multi-class classiﬁcation: Table 4 shows the confusion matrix for the
multi-class classiﬁcation with packet count and percentage value. mFNN model
achieves a high accuracy of 99.79% over four classes of traﬃc classiﬁcation. For
predicting traﬃc of one class over traﬃc of the other three classes, the accuracy
is above 99% respectively.
In addition, there is no misclassiﬁcation between
DDoS/DoS or normal traﬃc and information theft traﬃc. For DDoS/DoS
attacks, the model misclassiﬁed 2314 packets (0.258%) as reconnaissance traﬃc
while for reconnaissance attacks, the model misclassiﬁed 1540 packets (0.421%)
as DDoS/DoS traﬃc. The reason could be behaviours of reconnaissance attacks
reﬂected through the current feature set have similarity with behaviours of
DDoS/DoS attacks which makes it diﬃcult to distinguish between these two
attacks. Regarding the runtime, the mFNN model completed the training and
validation procedures with roughly 42 minutes.

14

Table 4: Confusion matrix for the multi-class classiﬁcation for various attack types

Actual/Predicted
Normal
DDoS/DoS
Information theft
Reconnaissance

Normal
508702 (99.995%)
4
0
13

DDoS/DoS
1
893697 (99.741%)
0
1540 (0.421%)

Information theft
0
0
62615 (99.992%)
13

Reconnaissance
22
2314 (0.258%)
5
363825 (99.571%)

Binary classiﬁcation: Table 5 shows confusion matrices for the binary
classiﬁcation. We can see the classiﬁcation for normal traﬃc and malicious
traﬃc from each subcategory of attacks achieves high accuracy, precision, recall,
and F1 score (i.e., 99.99%) with only a few packets misclassiﬁed.

All attack traﬃc in the dataset was generated via standard tools (e.g., Nmap,
Hping3, Metasploit framework). In reality, attackers could use diﬀerent options
of the same tools (e.g., packet sending rate, payload size) or diﬀerent tools for
the attack conﬁguration; some intelligent attackers could also apply evasion
techniques. However, the header ﬁelds contained in the packets could be kept
similar to achieve the same attack goal (e.g., a SYN ﬂood attack needs to set
SYN ﬂag in tcp.ﬂags ﬁeld). Therefore, the attack traﬃc in the dataset still
reﬂects genuine behaviours by attackers, which demonstrates the applicability
of the proposed model.

4.6. Comparison of Results

As a ﬁnal step, we applied the SVM model

[11] to the multi-class
classiﬁcation problem and compared the classiﬁcation accuracy and runtime
of SVM with those of mFNN model. We discuss the input, model settings and
results for multi-class classiﬁcation in detail in the following paragraphs.

We used the same dataset without redundant row values shown in Table 2.
We identiﬁed categorical columns and mapped three highly-dimensional
categorical variables (i.e., src.port, dst.port, and http.request.method) to low-
dimensional categorical variables. For src.port and dst.port columns, we
obtained a list of common ports (i.e., 20, 21, 22, 23, 25, 42, 43, 53, 80, 161,
443), kept these common ports in original port columns and map uncommon
ports to new columns. This list was constructed based on well-known ports for
various services, including FTP, SSH, Telnet, DNS, SMTP, HTTP/HTTPS, and
SNMP. We generated two new columns for src.port and dst.port respectively:
one for the port number between the range of 0 and 1023 but does not belong
to the well-known port list; another for the port number larger than 1023
(i.e., registered/private ports). For http.request.method column, we maintained
row values containing a single method (i.e.,
‘OPTIONS’,
‘PROPFIND’, ‘HEAD’, and ‘TRACE’) or ‘0’ for NaN and mapped values
containing comma separated multiple methods to a string named ‘MULTIPLE’
(e.g., ‘GET,GET’, ‘HEAD,HEAD,HEAD’). We then applied one-hot encoding
to all low-dimensional categorical variables. Due to the long convergence time
of the SVM model, we performed random subsampling out of 9163751 samples
with sample sizes of 10000, 100000, and 1000000 (i.e., 10.9%). We randomly

‘POST’,

‘GET’,

15

Table 5: Confusion matrices for the binary classiﬁcation for various attack types

Actual/Predicted
Normal
DDoS over HTTP

Actual / Predicted
Normal
DDoS over TCP

Actual / Predicted
Normal
DDoS over UDP

Actual / Predicted
Normal
DoS over HTTP

Actual / Predicted
Normal
DoS over TCP

Actual / Predicted
Normal
DoS over UDP

Actual / Predicted
Normal
Data exﬁltration

Actual / Predicted
Normal
Keylogging

Actual / Predicted
Normal
Service scan

Actual / Predicted
Normal
OS ﬁngerprint

Normal
508725
0

Normal
508724
0

Normal
508725
0

Normal
508725
0

Normal
508724
1

Normal
508725
0

Normal
508726
0

Normal
508726
0

Normal
508710
4

Normal
508721
0

DDoS over HTTP
1
38883

DDoS over TCP
1
199889

DDoS over UDP
0
200011

DoS over HTTP
1
57496

DoS over TCP
1
199740

DoS over UDP
0
199996

Data exﬁltration
0
60342

Keylogging
0
2277

Service scan
16
199975

OS ﬁngerprint
4
165412

selected samples so as to follow the same distribution (i.e., proportion) of data
from diﬀerent classes. We also applied feature scaling to normalise inputs within

16

a range between (-1, 1).

We used a linear Support Vector Classiﬁer (SVC) from the Scikit Learn
library1. Due to the imbalanced nature of the diﬀerent classes in the dataset,
class weights were introduced to the training data. We followed the same weight
calculation performed for mFNN model. For each subsampled set, we tuned the
SVC via grid search by cross validation with a list of penalty parameter values,
including 0.1, 1, 10, 100, 1000, and 10000. The penalty parameter controls
the trade-oﬀ between smooth decision boundary and correct classiﬁcation of
training points; a higher value allows fewer outliers while a lower value allows
more outliers thus avoiding over-ﬁtting. We applied a 5-fold cross validation
on each set with a 80%-20% training and testing split. We placed a limit of
10000 on maximum number of iterations to be run.
In line with our other
experiments, we used the same HPC cluster. We retrieved the optimal penalty
parameter value from the grid search for each set (i.e., 1000 for the set with
sample size of 10000 and 1000000; 100 for the set with sample size of 100000)
and applied the SVC with the optimal value to training and testing.

Table 6 illustrates accuracy and runtime results for the three subsampled
sets. The class size represents the number of selected samples in each class in
the order of normal, DDoS/DoS, information theft, and reconnaissance traﬃc
while the runtime is the training time under the optimal penalty parameter
value. From the table, we can see that the SVC yields a slightly higher accuracy
with larger sample size. That said, the runtime also increases moderately.
In addition, the model did not converge due to the limitation on maximum
number of iterations. So without the iteration limit, the model could run until
it converges thus incurring higher accuracy; however, this may increase the
runtime dramatically due to the uncertainty of the convergence time. Thus,
we could conclude the proposed FNN model for the multi-class classiﬁcation is
more time eﬃcient over large dataset compared with the SVC.

Table 6: Accuracy and runtime of SVC for the multi-class classiﬁcation

Sample size
10K
100K
1M

Class size
(2817, 4912, 328, 1943)
(27739, 49203, 3418, 19640)
(277800, 488896, 34037, 199267)

Accuracy Runtime (min)
97.90%
98.15%
98.26%

0.35
8.40
144.61

5. Discussion and Future Work

By extracting the header ﬁeld information of individual packets as generic
features and developing the FNN models, we are able to diﬀerentiate normal
and attack traﬃc with high accuracy and low FP and FN predictions. However,
we have encountered several issues and aim to address these in our future work.

1Scikit is widely accessible at https://scikit-learn.org

17

For the multi-class classiﬁcation, we considered four categories at the current
stage because we observed the model yielded sub-par performance for certain
subcategories of attacks (e.g., DDoS over HTTP and DoS over HTTP). The
reason could be that the ﬁeld information for the individual packet could
not capture certain attack behaviour in a large scale (e.g., a ﬂood of traﬃc
generated in DDoS attacks). Therefore, we are planning to develop a classiﬁer
to diﬀerentiate each subcategory of attacks as part of the future work. We will
include the timestamp information, process header ﬁelds of individual packets
aggregated from timestamps, and develop a new deep neural networks model
to incorporate these new features. Long-short term memory networks could be
the best option to model time series data.
In addition, the current classiﬁer
works in the batch mode. We will implement the online mode for real time
detection. We also plan to investigate feature ranking techniques for time-series
feature-based classiﬁers.

6. Conclusion

Deep learning techniques have shown its potential to serve as a solution for
the intrusion detection problem in IoT networks. Through the proposal of an
intelligent intrusion detection approach, we have developed feed-forward neural
networks models along with the extraction and preprocessing of the header ﬁeld
information in individual packets, treated as generic features, and adopted the
concepts of neural network embedding and transfer learning to obtain encoding
of highly-dimensional categorical features of data. We have tested the eﬃcacy of
the models for both binary and multi-class classiﬁcation on a dataset comprising
realistic network traﬃc. Through the evaluation results, we have demonstrated
the performance of the proposed approach. In particular, the capability of the
classiﬁer in binary classiﬁcation was illustrated through results close to 99.99%
across all evaluation measures including accuracy, precision, recall, and F1 score
while the detection accuracy of approximately 99.79% was achieved for multi-
class classiﬁcation. The results are signiﬁcant and warrant further research in
this domain of cyber security for IoT networks.

References

[1] Abeshu, A., Chilamkurti, N., 2018.

for distributed attack detection in fog-to-things computing.
Communications Magazine 56, 169–175.

Deep learning: The frontier
IEEE

[2] Al-Zewairi, M., Almajali, S., Awajan, A., 2017. Experimental evaluation
of a multi-layer feed-forward artiﬁcial neural network classiﬁer for network
intrusion detection system,
in: Proceedings of the 2017 International
Conference on New Trends in Computing Sciences (ICTCS), pp. 167–172.

[3] Alhakami, W., ALharbi, A., Bourouis, S., Alroobaea, R., Bouguila, N.,
2019. Network Anomaly Intrusion Detection Using a Nonparametric
Bayesian Approach and Feature Selection. IEEE Access 7, 52181–52190.

18

[4] Amma, N.G.B., Selvakumar, S., 2019. Deep Radial Intelligence with
Cumulative Incarnation approach for detecting Denial of Service attacks.
Neurocomputing 340, 294–308.

[5] Baig, Z.A., Sanguanpong, S., Firdous, S.N., Vo, V.N., Nguyen, T.G., So-In,
C., 2020. Averaged dependence estimators for DoS attack detection in IoT
networks. Future Generation Computer Systems 102, 198–209.

[6] Bera, A., 2019. 80 Mind-Blowing IoT Statisitics (Infographic). https:
//safeatlast.co/blog/iot-statistics/. Accessed on 2019-07-11.

[7] Ge, M., Fu, X., Syed, N., Baig, Z., Teo, G., Robles-Kelly, A., 2019. Deep
Learning-Based Intrusion Detection for IoT Networks, in: 2019 IEEE 24th
Paciﬁc Rim International Symposium on Dependable Computing (PRDC),
pp. 256–25609.

[8] Haddadi, F., Khanchi, S., Shetabi, M., Derhami, V., 2010.

Intrusion
Detection and Attack Classiﬁcation Using Feed-Forward Neural Network,
in: Proceedings of the 2010 Second International Conference on Computer
and Network Technology, pp. 262–266.

[9] Hoang, D.H., Nguyen, H.D., 2018. A PCA-based method for IoT network
traﬃc anomaly detection, in: Proceedings of the 2018 20th International
Conference on Advanced Communication Technology (ICACT), pp. 381–
386.

[10] Koroniotis, N., Moustafa, N., Sitnikova, E., Turnbull, B., 2019. Towards
the Development of Realistic Botnet Dataset in the Internet of Things
for Network Forensic Analytics: Bot-IoT Dataset. Future Generation
Computer Systems 100, 779–796.

[11] Kumar, P.A.R., Selvakumar, S., 2011. Distributed denial of service attack
detection using an ensemble of neural classiﬁer. Computer Communications
34, 1328–1341.

[12] Kumari, V.V., Varma, P.R.K., 2017. A semi-supervised intrusion detection
in:
system using active learning SVM and fuzzy c-means clustering,
Proceedings of the 2017 International Conference on I-SMAC (IoT in Social,
Mobile, Analytics and Cloud) (I-SMAC), pp. 481–485.

[13] McHugh, J., 2000. Testing Intrusion Detection Systems: A Critique of
the 1998 and 1999 DARPA Intrusion Detection System Evaluations As
Performed by Lincoln Laboratory. ACM Transactions on Information and
System Security 3, 262–294.

[14] Moustafa, N., Slay, J., 2016. The Evaluation of Network Anomaly Detection
Systems: Statistical Analysis of the UNSW-NB15 Data Set and the
Comparison with the KDD99 Data Set. Information Security Journal: A
Global Perspective 25, 18–31.

19

[15] Naik, N., 2017. Choice of eﬀective messaging protocols for IoT systems:
MQTT, CoAP, AMQP and HTTP, in: Proceedings of the 2017 IEEE
International Systems Engineering Symposium (ISSE), pp. 1–7.

[16] Roopak, M., Tian, G.Y., Chambers, J., 2019. Deep learning models for
cyber security in iot networks, in: 2019 IEEE 9th Annual Computing and
Communication Workshop and Conference (CCWC), IEEE. pp. 0452–0457.

[17] Shone, N., Ngc, T.N., Phai, V.D., Shi, Q., 2018. A Deep Learning Approach
to Network Intrusion Detection. IEEE Transactions on Emerging Topics
in Computational Intelligence 2, 41–50.

[18] Tavallaee, M., Bagheri, E., Lu, W., Ghorbani, A.A., 2009. A detailed
in: Proceedings of the 2009
analysis of the KDD CUP 99 data set,
IEEE Symposium on Computational Intelligence for Security and Defense
Applications, pp. 1–6.

[19] Thamilarasu, G., Chawla, S., 2019. Towards deep-learning-driven intrusion

detection for the Internet of Things. Sensors 19, 1977.

[20] Zhang, Y., Li, P., Wang, X., 2019. Intrusion Detection for IoT Based on
IEEE Access 7,

Improved Genetic Algorithm and Deep Belief Network.
31711–31722.

20

