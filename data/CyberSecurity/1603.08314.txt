Active Cyber Defense Dynamics Exhibiting Rich
Phenomena

Ren Zheng
Fudan University
zhrkevin@gmail.com

Wenlian Lu
Fudan University
wenlian@fudan.edu.cn

Shouhuai Xu
UT San Antonio
shxu@cs.utsa.edu

6
1
0
2

r
a

M
8
2

]

R
C
.
s
c
[

1
v
4
1
3
8
0
.
3
0
6
1
:
v
i
X
r
a

ABSTRACT
The Internet is a man-made complex system under constant attacks
(e.g., Advanced Persistent Threats and malwares). It is therefore
important to understand the phenomena that can be induced by the
interaction between cyber attacks and cyber defenses. In this paper,
we explore the rich phenomena that can be exhibited when the de-
fender employs active defense to combat cyber attacks. To the best
of our knowledge, this is the ﬁrst study that shows that active cyber
defense dynamics (or more generally, cybersecurity dynamics) can
exhibit the bifurcation and chaos phenomena. This has profound
implications for cyber security measurement and prediction: (i) it
is infeasible (or even impossible) to accurately measure and predict
cyber security under certain circumstances; (ii) the defender must
manipulate the dynamics to avoid such unmanageable situations in
real-life defense operations.

Categories and Subject Descriptors
D.4.6 [Security and Protection]

General Terms
Security, Theory

Keywords
Active cyber defense, active cyber defense dynamics, cyber attack-
defense dynamics, cybersecurity dynamics, cyber security models

1.

INTRODUCTION

Malicious attacks in cyberspace will remain to be a big problem
for the many years to come. This is fundamentally caused by the
complexity of the Internet and computer systems (e.g., we cannot
assure that a large software system has no security vulnerabilities).
It is therefore important to understand and characterize the phe-
nomena that can be exhibited at the global level of a cyber system,
ranging from an enterprise network to the entire cyberspace. The
emerging framework of Cybersecurity Dynamics [34, 35, 7, 4] of-
fers a systematic approach for understanding, characterizing, and
quantifying the phenomena as well as cyber security in general.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are not
made or distributed for proﬁt or commercial advantage and that copies bear
this notice and the full citation on the ﬁrst page. Copyrights for components
of this work owned by others than ACM must be honored. Abstracting with
credit is permitted. To copy otherwise, or republish, to post on servers or to
redistribute to lists, requires prior speciﬁc permission and/or a fee. Request
permissions from Permissions@acm.org.
HotSoS ’15, April 21 - 22, 2015, Urbana, IL, USA
Copyright 2015 ACM 978-1-4503-3376-4/15/04...$15.00
http://dx.doi.org/10.1145/2746194.2746196.

The current generation of cyber defenses is often based on re-
active tools that are known to have limited success. For example,
infected/compromised computers cannot be cleaned up even by us-
ing multiple anti-malware tools together [21]. Moreover, reactive
defense has a fundamental limitation, namely that the effect of at-
tacks is automatically ampliﬁed by network connectivity, but the
effect of reactive defenses is not. This attack-defense asymmetry
had been implied by studies such as [29, 6, 3, 28, 39], but was not
explicitly pointed out until [36].

One approach to overcoming the aforementioned attack-defense
asymmetry is to adopt active cyber defense, which is to use the
same mechanism that is exploited by attackers. More speciﬁcally,
active defense aims to spread some “white” worms (called defense-
ware in this paper) to automatically identify and “kill” the mali-
cious malwares in compromised/infected computers [2, 1, 30, 26,
16, 18, 14, 31]. In some sense, active cyber defense already takes
place in cyberspace because (for example) the malware called Welchia
attempts to “kill" the malware called Blaster in compromised
computers [26, 22], but it may take some years for full-scale ac-
tive cyber defenses to arise [18, 27, 32]. The ﬁrst mathematical
model for studying the global effectiveness of active cyber defense
has been proposed recently [36]. In this paper, we further the study
of active cyber defense dynamics from a new perspective.

Our contributions. We substantially extend some aspects of the
ﬁrst mathematical model of active cyber defense dynamics [36] (to
be fair, we should note that [36] offers some perspectives that are
not considered in our model as well). The extensions can be char-
acterized as follows. First, we accommodate more general attack-
power and defense-power functions, meaning that our results are
applicable to a broader setting than what is investigated in [36].
Second, we allow the attack network structure to be different from
the defense network structure, which are assumed to be identical
in [36]. This is important and realistic because the attack-defense
interaction structures are often “overlay” networks on top of some
physical networks, and as such, the defender and the attacker can
use different structures based on their own defense/attack strate-
gies.

The extended model allows us to explore the rich phenomena
that can be exhibited by active cyber defense dynamics. Speciﬁ-
cally, we show that active cyber defense dynamics can exhibit the
bifurcation and chaos phenomena (we call them unmanageable sit-
uations in cyber security). To the best of our knowledge, this is
the ﬁrst study that shows that bifurcation and chaos are relevant in
the cyber security domain. These phenomena indicate limitations
on the measurement and prediction of cyber security, and highlight
that cyber defenders must manipulate the (active) cyber defense
dynamics to avoid such unmanageable situations in real-life cyber
defense operations.

 
 
 
 
 
 
Disclaimer. The active cyber defense strategy explored in the present
paper does not advocate that defenders should retaliate from at-
tackers, because it is well known that the attackers, or more pre-
cisely the IP addresses that are launching attacks against the vic-
tims, could well be victims that are abused by the real attackers as
stepping stones. Moreover, defensewares (i.e., “white” worms) are
meant to clean up the compromised computers, not to compromise
the secure computers. Most important of all, the active defense
operations should be contained within the networks under the de-
fender’s jurisdiction (e.g., an enterprise network defender may use
active defense to clean up the enterprise network but not going be-
yond the enterprise’s perimeter). This can be assured, for example,
by making the enterprise’s computers and ﬁrewalls recognize de-
fensewares via digital signatures. This means that the enterprise
computers will only run defensewares that are accompanied with
digital signatures that can be veriﬁed by the computers’ hardware
via an embedded signature veriﬁcation key, and that the ﬁrewall
recognizes and blocks out-bound defensewares.

The rest of the paper is organized as follows. In Section 2, we
present our active cyber defense dynamics model. In Section 3, we
analyze equilibria (or attractors) of active cyber defense dynamics.
In Section 4, we explore the transition between attractors. In Sec-
tion 5, we investigate the emergence of bifurcation. In Section 6,
we explore the chaos phenomenon. We discuss related prior work
in Section 7 and conclude the paper in Section 8.

The main notations we use are summarized as follows.

ℜ(ω), ℑ(ω)

R, R+, C the sets of real numbers, positive real numbers
and complex numbers, respectively
the real and imaginary parts of complex num-
ber ω ∈ C, respectively
the n × n identity matrix

In

GB, AB GB = (V, EB) is the defense network struc-

ture, AB is the adjacency matrix of GB

GR, AR GR = (V, ER) is the attack network struc-

ture, AR is the adjacency matrix of GR

Nv,G′ Nv,G′ = {u ∈ V ′

:

(u, v) ∈ E′} is
the neighbors of v in graph/network G′ =
(V ′, E′)
deg(v) = |Nv| is node v’s in-degree in
graph/network G′ = (V ′, E′)

deg(v, G′)

λ(M )
λ1(M )

DA′ DA′ = [dvv]n×n is a diagonal matrix corre-
sponding to adjacency matrix A′ = [a′
vu]n×n,
n
where dvv =
u=1 avu is the in-degree of
node v in graph G′ corresponding to A′
P
the set of eigenvalues of matrix M
the eigenvalue of M with the largest real part
(or λ1 when M is clear from the context)
the probability that node v ∈ V is in sate blue
(i.e., secure) and state red (i.e., compromised)
at time t, respectively
the average portion of blue nodes at time t ≥
0, namely hBv(t)i = 1
|V |

v∈V Bv(t)

hBv(t)i

Bv(t), Rv(t)

B(t), R(t) B(t) = [B1(t), . . . , Bn(t)], R(t) =

B∗

f (·), g(·)

θv,BR(t)

θv,RB(t)

P

[R1(t), . . . , Rn(t)], where n = |V |
the homogeneous equilibrium of B(t) as t →
∞, namely Bv(t) = σ ∀v ∈ V as t → ∞
f (·) : [0, 1] → {0} ∪ R+ is the defense-power
[0, 1] → {0} ∪ R+ is the
function, g(·) :
attack-power function
the probability that the state of node v changes
from blue to red at time t
the probability that the state of node v changes
from red to blue at time t

2. EXTENDED ACTIVE CYBER DEFENSE

DYNAMICS MODEL

Review of the model in [36]. Suppose attacker and defender in-
teract in a cyber system that consists of a ﬁnite node population
V = {1, 2, · · · , n}, where each node can abstract/represent a com-
puter. At any time t ≥ 0, a node v ∈ V is in one of two states:
blue, meaning that the node is secure but vulnerable to attacks;
red, meaning that the node is compromised. For a given cyber
system, the attacker spreads computer malwares (e.g., Advanced
Persistent Threats) to compromise computers, while the defender
spreads defensewares (e.g., “white” worms) to detect and clean up
(or “cure") the compromised computers. Suppose both the mal-
wares and the defensewares spread over the same attack-defense
network structure, namely a ﬁnite simple graph G = (V, E), where
V = {1, 2, · · · , n} is the vertex set mentioned above, and E is the
edge set such that (u, v) ∈ E means (i) a compromised node u
can attack a secure node v and (ii) a secure node u can use active
defense to detect and clean up a compromised node v.

Our extension to the model in [36]. Rather than assuming the at-
tacker and defender use the same attack-defense network structure,
we consider two network structures: the defense network structure
GB = (V, EB) over which defensewares spread, and the attack
network structure GR = (V, ER) over which malwares spread.
Both network structures are directed or undirected graphs. Specif-
ically, (u, v) ∈ EB means a secure node u can use active defense
to “cure” a compromised node v, and (u, v) ∈ ER means a com-
promised node u can attack a secure node v. We do not make any
restrictions on the attack/defense network structures, except that we
assume GB and GR are simple graphs with no self-edges.1 (For the
purpose of illustrating results, we will use random graphs as con-
crete examples though.)
Denote by AB = [aB
vu]n×n the adjacency matrix of GB where
aB
vu = 1 if and only if (u, v) ∈ EB. Denote by AR = [aR
vu]n×n
the adjacency matrix of GR where aR
vu = 1 if and only if (u, v) ∈
ER. Note that the representation accommodates both directed and
undirected graphs. Denote by Bv(t) and Rv(t) the probability that
node v ∈ V is in state blue (i.e., secure) and state red (i.e., com-
promised) at time t, respectively.

B 
(Blue)

(cid:84)v, BR(t)

(cid:84)v, RB(t)

R 
(Red)

Figure 1: The state transition diagram for a node v ∈ V .

Figure 1 depicts the state transition diagram for individual node
v ∈ V , where θv,RB(t) is the probability that node v’s state changes
from red to blue at time t, and θv,BR(t) is the probability that node
v’s state changes from blue to red at time t. This leads to the fol-
lowing master equation of active cyber defense dynamics:

dBv(t)
dt
dRv(t)
dt




= θv,RB(t) · Rv(t) − θv,BR(t) · Bv(t)

= θv,BR(t) · Bv(t) − θv,RB(t) · Rv(t)

(1)


In order to specify θv,RB(t), we use the concept of defense-
power function f (·) : [0, 1] → {0} ∪ R+, which abstracts the

1It is possible to accommodate privilege escalation in the present
model, by treating a computer as a set of nodes that correspond to
different privileges. We leave the details to future investigation.

power of the defenseware in detecting and cleaning up compro-
mised (red) nodes. In order to specify θv,BR(t), we use the concept
of attack-power function g(·) : [0, 1] → {0} ∪ R+, which abstracts
the power of the malware in compromising secure (blue) nodes.
It is intuitive that both defense-power and attack-power functions
should be dependent on the defense and attack network structures,
respectively. Therefore, we have the following general form:

θv,RB(t) = f

θv,BR(t) = g

1
deg(v, GB)

1
deg(v, GR)







u∈Nv,GB
X

u∈Nv,GR
X

Bu(t)

,





Bu(t)







where Nv,GB = {u : (u, v) ∈ EB} is the set of node v’s neigh-
bors in graph GB and Nv,GR = {u : (u, v) ∈ ER} is the set of
node v’s neighbors in graph GR.

For the present characterization study, it is sufﬁcient to require
that the defense-power and attack-power functions possess some
basic properties. First, we have f (0) = 0 because active defense
must be launched from some blue node, and g(1) = 0 because
attack must be launched from some red node. Second, we have
f (x) > 0 for x ∈ (0, 1] because any active defense may succeed,
and g(x) > 0 for x ∈ [0, 1) because any attack may succeed.
Third, the two functions do not have to abide by any speciﬁc re-
lation, except that they are differentiable (for the sake of analytic
treatment).

As a result, the master equation of active cyber defense dynam-

ics, namely Eq. (1), becomes:

with all possible attack-power and defense-power functions as well
as all possible attack and defense network structures. In principle,
these functions and structures do exist, although how to obtain them
is an excellent problem for future investigation.

3. EQUILIBRIA AND THEIR STABILITY

Equilibrium is an important concept for quantifying cyber secu-
rity. Suppose σ is the equilibrium under certain active defense. We
can quantify the effectiveness of active defense via the notion of
σ-effectiveness because the dynamics converge to σ. Moreover, the
stability of an equilibrium reﬂects the consequence/effect of per-
turbations, which can be caused (for example) by manipulations
to the initial global state (e.g., the defender manually cleans up
some compromised computers before launching active defense for
more effectiveness — this may sound counterintuitive, but it actu-
ally shows the value of rigorous characterization study because the
defender would not know this tactics otherwise).

We consider a class of equilibria of Eq. (2), namely homoge-
n] with B∗
n = σ ∈ [0, 1].

1 = . . . = B∗

1 , · · · , B∗

neous equilibria [B∗
This class contains the following:

• All-blue equilibrium, denoted by B∗ = 1; B∗

v = 1 for all

v ∈ V (i.e., active defense is 1-effective).

• All-red equilibrium, denoted by B∗ = 0; B∗

v = 0 for all

v ∈ V (i.e., active defense is 0-effective).

• σ-equilibrium, denoted by B∗ = σ ∈ (0, 1); B∗
v ∈ V (i.e., active cyber defense is σ-effective).

v = σ for all

The Jacobian matrix of (2) near an equilibrium is denoted by

Rv(t) −

M =

(1 − σ)f ′(σ)D−1
AB
h
f (σ) + g(σ)

In.

AB − σg′(σ)D−1
AR

AR

−

i

(3)

dBv(t)
dt

= f

g

dRv(t)
dt

= g













f



1
deg(v, GB)

1
deg(v, GR)

1
deg(v, GR)

1
deg(v, GB)

u∈Nv,GB
X

u∈Nv,GR
X

u∈Nv,GR
X

Bu(t)





Bu(t)

Bu(t)









Bv(t)

Bv(t) −

Bu(t)



Rv(t)

u∈Nv,GB
X


dt + dRv (t)
Since dBv (t)
dt = 0 holds for all t ≥ 0 and all v ∈ V ,
Bv(t) + Rv(t) = 1 for all t and all v ∈ V . Therefore, we only
need to consider the following master equation for v ∈ V :



i
3.1 Existence and Stability of Equilibria

h

We show that homogeneous equilibria exist under the following

hypothesis (or condition):

H0: there exists some σ ∈ [0, 1] such that (1 − σ) ·
f (σ) = σ · g(σ) holds.

PROPOSITION 1. Under hypothesis H0, B∗ = σ ∈ [0, 1] is
an equilibrium of (2). Moreover, B∗ is stable if ℜ(µ) < 0 for all
µ ∈ λ(M ), and unstable if ℜ(µ) > 0 for some µ ∈ λ(M ).

PROOF. Under hypothesis H0, namely (1−σ)·f (σ) = σ·g(σ),

we see that B∗

v = σ satisﬁes

dBv(t)
dt

= f





g



1
deg(v, GB)

1
deg(v, GR)

u∈Nv,GB
X

u∈Nv,GR
X



Bu(t)

1 − Bv(t)

−

h

i





Bu(t)



Bv(t).

(2)

dBv(t)
dt

= (1 − σ) · f (σ) − σ · g(σ) = 0,

∀ v ∈ V.

Thus B∗ = σ is an equilibrium.

To see the stability of equilibrium B∗ = σ ∈ [0, 1], we consider
1 , · · · , Bn −

a small perturbation to B∗, namely δB = [B1 − B∗
B∗

n]. The linearization system of Eq. (2) near B∗ leads to

The main research task is to analyze system (2) for all v ∈ V .



Remark. When we investigate speciﬁc attacks and defenses, we
need to obtain their concrete attack-power and defense-power func-
tions. Similarly, when we investigate speciﬁc cyber systems, we
need to obtain the concrete attack and defense network structures.
These are important research problems that are orthogonal to the
focus of the present paper because our characterization study deals

dδB
dt

=

(1 − σ)f ′(σ)D−1

AB AB − σg′(σ)D−1

ARAR

(cid:26)h
f (σ) + g(σ)

In

δB,

−

i

(4)

h

(cid:27)
where In is the identity matrix of size n. Note that M as deﬁned in
Eq. (3) is the coefﬁcient matrix of linear system (4). The stability
of equilibrium B∗ = σ is determined by the eigenvalues of matrix

i

M . For the general case GB = (V, EB) 6= GR = (V, ER), it can
be shown that

µ0 = 1, such that f ′(0)ℜ(µ0) − g(0) > 0, meaning that B∗ = 0
is locally unstable.

λ(M ) = λ

(1 − σ)f ′(σ)D−1

AB AB −

(cid:18)
σg′(σ)D−1
AR

AR

−

f (σ) + g(σ)

.

(5)

If ℜ(µ) < 0 for all µ ∈ λ(Mσ), B∗ = σ is locally stable; if
ℜ(µ) > 0 for some µ ∈ λ(M ), B∗ = σ is locally unstable.

(cid:19)

h

i

Proposition 1 can be simpliﬁed when σ = 0 and σ = 1.

COROLLARY 1. If g(1) = 0, then B∗ = 1 is an equilibrium. It
is locally stable if −g′(1) < f (1) and locally unstable if −g′(1) >
f (1).

If f (0) = 0, then B∗ = 0 is an equilibrium. It is locally stable

if f ′(0) < g(0) and locally unstable if f ′(0) > g(0).

PROOF. To prove the ﬁrst part, we observe that g(1) = 0 im-
plies H0 holds for σ = 1, namely that B∗ = 1 is an equilibrium of
system (2). For σ = 1, it can be shown that Eq. (4) becomes

dδB
dt

= =

− g′(1)D−1
AR

AR − f (1)In

δB.

Proposition 1 says that a sufﬁcient condition under which equilib-
rium B∗ = 1 is locally stable is

h

i

−g′(1)ℜ(µ) < f (1),

∀ µ ∈ λ

D−1
AR

AR

.

(6)

(cid:16)

(cid:17)

Since g(1) = 0 and g(x) ≥ 0 for x ∈ [0, 1], g(x) is locally
non-increasing at x = 1 and thus −g′(1) ≥ 0. Since the sum
for every row in matrix D−1
AR equals 1, the Perron-Frobenius
AR
theorem [10] says that its largest eigenvalue is 1. From Eq. (6), we
have

−g′(1)ℜ(µ) < −g′(1) < f (1),

∀ µ ∈ λ

D−1
AR

AR

.

That is, if −g′(1) < f (1), then B∗ = 1 is locally stable; if
−g′(1) > f (1), there exists at least one eigenvalue µ0 ∈ λ
say µ0 = 1, such that −g′(1)ℜ(µ0) − f (1) > 0, meaning that
B∗ = 1 is locally unstable.

D−1
AR

(cid:16)

AR

(cid:16)

(cid:17)

To prove the second part, we observe that f (0) = 0 implies H0
with σ = 0, namely that B∗ = 0 is an equilibrium of (2). For
σ = 0, Eq. (4) becomes

dδB
dt

=

=

(1 − 0) · f ′(0)D−1
AB

AB − 0 · g′(0)D−1
AR

AR

−

(cid:26)h
f (0) + g(0)

In

δB

i

i

(cid:27)
AB AB − g(0)In

h
f ′(0)D−1
h

δB.

i

Proposition 1 says that the sufﬁcient condition for equilibrium B∗ =
0 to be locally stable is

f ′(0)ℜ(µ) < g(0),

∀ µ ∈ λ

D−1
AB

AB

.

(7)

Since f (0) = 0 and f (x) ≥ 0 for x ∈ [0, 1], f (x) is locally
non-decreasing at x = 0 and thus f ′(0) ≥ 0. Since the largest
eigenvalue of D−1
AB is 1, from Eq. (7) we have
AB

(cid:16)

(cid:17)

f ′(0)ℜ(µ) < f ′(0) < g(0),

∀ µ ∈ λ

D−1
AB

AB

.

That is, if f ′(0) < g(0), then B∗ = 0 is locally stable; if f ′(0) >
g(0), there exists at least one eigenvalue µ0 ∈ λ
, say

AB

(cid:16)

(cid:17)

D−1
AB

(cid:16)

(cid:17)

In the special case GB = GR, namely AB = AR, we immedi-

ately obtain the following corollary of Proposition 1:

COROLLARY 2. Suppose hypothesis H0 holds and GB = GR =

G (i.e., AB = AR = A). Let µ1 be the eigenvalue of D−1
A A that
has the smallest real part. If the attack-power and defense-power
functions satisfy one of the following two conditions:
(i). (1 − σ)f ′(σ) − σg′(σ) > 0 and

f (σ) + g(σ)
(1 − σ)f ′(σ) − σg′(σ)

> 1,

(ii). (1 − σ)f ′(σ) − σg′(σ) < 0 and

f (σ) + g(σ)
(1 − σ)f ′(σ) − σg′(σ)

<

ℜ(µ1), then equilibrium B∗ = σ ∈ [0, 1] is locally stable.

If the attack-power and defense-power functions satisfy one of

the two following conditions:
(i). (1 − σ)f ′(σ) − σg′(σ) > 0 and

f (σ) + g(σ)
(1 − σ)f ′(σ) − σg′(σ)

< 1,

(ii). (1 − σ)f ′(σ) − σg′(σ) < 0 and

f (σ) + g(σ)
(1 − σ)f ′(σ) − σg′(σ)

>

ℜ(µ1), then equilibrium B∗ = σ ∈ [0, 1] is locally unstable.

3.2 Examples
Example 1: Stability effect of different defense-power functions
vs. a ﬁxed attack-power function. Suppose GB = GR is an
Erdös-Rényi (ER) random graph instance G = (V, E) with |V | =
2, 000 and edge probability p = 0.005 (i.e., every pair of nodes is
connected with probability 0.005, independent of each other). We
consider attack-power function g(x) = 1 − x against the following
four scenarios of defense-power function f (x):

• Scenario I: f (x) = x2, meaning that B∗ = 0 is stable and

B∗ = 1 is unstable.

• Scenario II: f (x) = x2 +x, meaning that B∗ = 0 is unstable

and B∗ = 1 is stable.

• Scenario III: f (x) = x2 + 1
B∗ = 1 are stable, but B∗ = 1

2 x, meaning that B∗ = 0 and
2 is unstable.

,

(cid:17)

• Scenario IV: f (x) = −2x2 + 2x, meaning that B∗ = 1

2 is

stable, but B∗ = 0 and B∗ = 1 are unstable.

Figure 2 plots the phase portraits of hBv(t)i = 1
|V |

v∈V Bv(t),
the portion of secure nodes. We observe that the simulation results
conﬁrm the analytic results. Speciﬁcally, Figure 2(a) shows that
hBv(t)i converges to B∗ = 0 when Bv(0) < 1 for all v ∈ V ; Fig-
ure 2(b) shows that hBv(t)i converges to B∗ = 1 when Bv(0) > 0
for all v ∈ V ; Figure 2(c) shows that hBv(t)i converges to B∗ = 1
when Bv(0) > 0.5 for all v ∈ V and converges to B∗ = 0 when
Bv(0) < 0.5 for all v ∈ V ; Figure 2(d) shows that hBv(t)i con-
verges to B∗ = 0.5 when 0 < Bv(0) < 1 for all v ∈ V .

P

time t
[0, 150]
[150, 300]
[300, 400]
[400, 500]

f (x)
f (x) = x2 + x
f (x) = x2
f (x) = −2x2 + 2x
f (x) = x2 + 1

2 x

B∗

g(x)
g(x) = 1 − x B∗ = 1
g(x) = 1 − x B∗ = 0
g(x) = 1 − x B∗ = 0.5
g(x) = 1 − x B∗ = 1

Table 1: The dynamics go to the respective equilibrium B∗
under some combinations of defense-power function f (x) and
attack-power function g(x).

1

0.8

0.6

0.4

0.2

〉

)
t
(

B

〈

v

1

0.8

0.6

0.4

0.2

〉

)
t
(

B

〈

v

0
0

2

4

6

8

10
 t

12

14

16

18

20

0
0

2

4

6

8

12

14

16

18

20

10
 t

(a) Scenario I: B∗ = 0 is stable,
B∗ = 1 is unstable.

(b) Scenario II: B∗ = 0 is unsta-
ble, B∗ = 1 is stable.

1

0.8

0.6

0.4

0.2

1

0.8

0.6

0.4

0.2

〉

)
t
(

B

〈

v

〉

)
t
(

B

〈

v

0
0

2

4

6

8

10
 t

12

14

16

18

20

0
0

2

4

6

8

12

14

16

18

20

10
 t

(c) Scenario III: B∗ = 0 and
B∗ = 1 are stable, B∗ = 1
2 is
unstable.

(d) Scenario IV: B∗ = 0 and
B∗ = 1 are unstable, B∗ = 1
2
is stable.

Figure 2: Phase portraits of the four scenarios conﬁrming the
stabilities of the equilibria, where x-axis represents time, and
y-axis represents the portion of secure nodes hBv(t)i.

Now we study the stability of the equilibria. For the GB = GR
mentioned above, we consider the above four scenarios as high-
lighted in Table 1. More speciﬁcally, for time t ∈ [0, 150], the
defense-power function is f (x) = x2 + x and the attack-power
function is g(x) = 1 − x (i.e, the above Scenario I); for time
t ∈ [150, 300], the defense-power function is f (x) = x2 and
the attack-power function is g(x) = 1 − x (i.e., the above Sce-
nario II); for time t ∈ [300, 400], the defense-power function is
f (x) = −2x2 + 2x and the attack-power function is g(x) = 1 − x
(i.e., the above Scenario IV); for time t ∈ [400, 500], the defense-
power function is f (x) = x2 + 1
2 x and the attack-power function
is g(x) = 1 − x (i.e., the above Scenario III).

〉

)
t
(

B

〈

v

1

0.8

0.6

0.4

0.2

0
0

50

100

150

200

250
 t

300

350

400

450

500

Figure 3: Active cyber defense dynamics lack persistent equi-
librium due to frequent perturbations.

Figure 3 plots a very probable scenario that can happen to the
portion of secure nodes, where three small perturbations are im-
posed at t = 150, 300, 400. This scenario is very probable because
it can explain why the cyber security state may rarely enter some
persistent equilibrium. Speciﬁcally, the initial value Bv(0), v ∈ V ,
is randomly chosen from interval (0, 0.01] by the uniform distribu-
tion. At t = 150, we ﬁnd that hBv(150)i = 1. We then impose
a small perturbation on each Bv(150), by replacing Bv(150) with
Bv(150) − εv where εv is an independent random variable of a
uniform distribution in the interval [0, 0.01] for all v ∈ V . Simi-
larly, we replace Bv(300) with Bv(300) + εv and Bv(400) with
Bv(400) − εv for all v ∈ V . Figure 3 illustrates that under small

perturbations, the overall cyber security dynamics never enter any
persistent equilibrium. This offers one possible explanation why
real-life cyber security is perhaps never in any equilibrium.

〉

)
t
(

B

〈

v

〉

)
t
(

B

〈

v

〉

)
t
(

B

〈

v

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0

2

4

6

8

10
 t

12

14

16

18

20

(a) ν = 0.5

5

10

15

20

25
 t

30

35

40

45

50

(c) ν = 0.85

2

4

6

8

10
 t

12

14

16

18

20

(e) ν = 1.5

〉

)
t
(

B

〈

v

〉

)
t
(

B

〈

v

〉

)
t
(

B

〈

v

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0

10

20

30

40

50
 t

60

70

80

90

100

(b) ν = 0.8

5

10

15

20

25
 t

30

35

40

45

50

(d) ν = 1

2

4

6

8

10
 t

12

14

16

18

20

(f) ν = 2

Figure 4: Phase portraits of the portion of secure nodes
hBv(t)i: f (x, ν) = νx − 2x2 and g(x) = (1 − 2x)2.

Example 2: Stability effect of parameterized defense-power func-
tions vs. a ﬁxed attack-power function. Suppose GB = GR is an
ER graph G = (V, E) with |V | = 2, 000, but with edge probability
p = 0.5. We consider the following parameterized defense-power
function f (x, ν) with parameter ν ∈ (0, +∞) and ﬁxed attack-
power function g(x):

f (x, ν) = νx − 2x2, g(x) = (1 − 2x)2.

Figure 4 plots the phase portraits of hBv(t)i with ν = 0.5, 0.8,
0.85, 1, 1.5, 2, respectively. The portraits can be classiﬁed into
three classes. Figures 4(a)-4(b) show that there is one stable equi-
librium B∗ = 0. Figure 4(c) shows that there are three equilibria
B∗ = 0, 0.38, 0.2, where the ﬁrst two are stable but the last one
is unstable. Figures 4(d)-4(f) show that there exist two equilibria
B∗ = 0, σ with σ > 0, where B∗ = 0 is unstable and B∗ = σ
is stable. We observe that active cyber defense dynamics exhibit
different phenomena with respect to different parameters. More-
over, we observe a sort of phase transition in parameter ν: when
ν ≤ 0.8, the global cyber security state converges to B∗ = 0 al-
most regardless of the initial value; when ν ≥ 1, the global cyber
security state converges to some B∗ = σ > 0 almost regardless
of the initial value; when 0.8 < ν = 0.85 < 1, the global cyber
security state converges to some equilibrium dependent upon the
initial value.

We summarize the discussion in this section into:

INSIGHT 1. Active cyber defense dynamics may rarely enter
into any equilibrium because of perturbations to the global secu-
rity state as caused by the manual cleaning of some compromised
computers (Figure 2), and/or because of perturbations to the at-
tack/defense power function as caused by the introduction of a new
attack/defense method (Figures 3-4 )

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
B ∈ [0, 1]n

(

(cid:12)
(cid:12)
(cid:12)
(cid:12)

R ∈ [0, 1]n

(

4. TRANSITION BETWEEN MULTIPLE

ATTRACTORS

We are now ready to precisely characterize the transition be-
tween the equilibria, which reﬂects the consequence/effect of the
defender manipulating the initial global security state (e.g., man-
ually cleaning up some compromised computers before launch-
ing active defense) and/or manipulating the attack/defense network
structure (e.g., by changing the network access control policy to
block/allow certain computers to communicate with certain other
computers).

4.1 Transition Between the All-blue and All-red

Equilibria

Under the conditions mentioned in Corollary 1, namely, f (0) =
g(1) = 0, system (2) has two locally stable equilibria B∗ = 1 and
∈ [0, 1]n and R = 1 − B =
B∗ = 0. Let B =
∈ [0, 1]n, where n = |V |. For
1 − B1, 1 − B2, · · · , 1 − Bn
1 , τ ∗
τ ∗
as follows:
and ΞGR,τ ∗
(cid:2)

2 ∈ (0, 1), we deﬁne two sets ΞGB ,τ ∗

B1, B2, · · · , Bn

(cid:3)

(cid:3)

(cid:2)

1

2

ΞGB ,τ ∗

1

=

1
deg(v, GB)

u∈Nv,GB
X

Bu ≥ τ ∗

1 , ∀v ∈ V

(8)

,

)

ΞGR,τ ∗

2

=

1
deg(v, GR)

Ru ≥ τ ∗

2 , ∀v ∈ V

.

(9)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

u∈Nv,GR
X
The following Theorem 1, whose proof is deferred to the Ap-
pendix, gives the transition between the all-blue and all-red equi-
libria by manipulating the initial state B(0).

)

THEOREM 1. Let GB = (V, EB) and GR = (V, ER) be two
arbitrary graphs. Suppose that f (·) and g(·) are continuous with
f (0) = g(1) = 0.
Case 1: Suppose the attack-power and defense-power functions sat-
isfy, ∀ z ∈ [τ ∗

1 , 1) and ∀ B ∈ ΞGB ,τ ∗

and some α > 0,

1

f (z) > α · z,

(10)

f

1
deg(v, GB)

Bu

+

!

u∈Nv,GB
X

g

1
deg(v, GR)

Bu

≤ α

(11)

!

u∈Nv,GR
X
, then lim
t→∞

If initial value B(0) ∈ ΞGB ,τ ∗
Case 2: Suppose the attack-power and defense-power functions sat-
isfy, ∀ z ∈ [τ ∗

Bv(t) = 1 ∀v ∈ V .

2 , 1) and ∀ R ∈ ΞGR ,τ ∗

and some β > 0,

1

2

g (1 − z) > β · z and

f

1 −

1
deg(v, GB)

Ru

+

!

u∈Nv,GB
X

g

1 −

1
deg(v, GR)

If initial value R(0) ∈ ΞGR,τ ∗

2

u∈Nv,GR
X
, then lim
t→∞

security state B(0) to belong to ΞGB ,τ ∗
to make active defense
1-effective; this says what the defender should strive to do. Under
certain other circumstances (case 2), the defender should make sure
that the initial global security state B(0) does not cause R(0) =
1 − B(0) ∈ ΞGR ,τ ∗
, because in this regime active defense is 0-
effective; this says what the defender should strive to avoid.

2

1

For the following two corollaries, we deﬁne

ΞGB ,τ ∗ =

B ∈ [0, 1]n









B ∈ [0, 1]n

1
deg(v, GB)

u∈Nv,GB
X

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

Bu > τ ∗, ∀ v ∈ V

,



ΘGR,τ ∗ =


1
deg(v, GR)

Bu < τ ∗, ∀ v ∈ V

.




u∈Nv,GR
X

On one hand, the following Corollary 3 says that when τ ∗

2 = τ ∗, we obtain the same threshold for the transitions.
τ ∗



1 =

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

COROLLARY 3. Suppose f (·) and g(·) are continuous with f (0) =

g(1) = 0. There exist constants τ ∈ (0, 1) and α > 0 such that
the following two conditions hold:
(i) The attack-power and the defense-power functions satisfy f (z) >
α · z for any z ∈ (τ ∗, 1), and for any B ∈ ΞGB ,τ ∗

1
deg(v, GB)

f





u∈Nv,GB
X

+ g

Bu









1
deg(v, GR)

u∈Nv,GR
X

Bu



≤ α.

(ii) The attack-power and the defense-power functions satisfy g (z) >
α(1 − z) for any z ∈ (0, τ ∗), and for any B ∈ ΘGR,τ ∗

1
deg(v, GB)

f





u∈Nv,GB
X

+ g

Bu









1
deg(v, GR)

u∈Nv,GR
X

Bu



≤ α.

If initial value B(0) ∈ ΞGB ,τ ∗ , then lim
t→∞
initial value B(0) ∈ ΘGR,τ ∗, then lim
t→∞

Bv(t) = 1 ∀ v ∈ V ; if

Bv(t) = 0 ∀ v ∈ V .

On the other hand, the following Corollary 4 makes a connection
to [36], by accommodating Theorems 1, 5, 8 and 9 in [36] as a
special case with GB = GR and α = 1.

COROLLARY 4. Suppose GB = GR = G = (V, E) and f (·),
and g(·) are continuous with f (0) = g(1) = 1. There exist τ ∗ ∈
(0, 1) and α > 0 such that the attack-power and defense-power
functions satisfy

f (z) + g (z) ≤ α ∀z ∈ [0, 1]

Ru

!

≤ β

(12)

and the defense-power function satisfy

Rv(t) = 1 ∀v ∈ V .

f (z) > α · z ∀z ∈ (τ ∗, 1) and f (z) < α · z ∀z ∈ (0, τ ∗).

The cyber security meaning of Theorem 1 is: Under a certain
condition (case 1), the defender needs to manipulate the initial global

If initial value B(0) ∈ ΞG,τ ∗ , then lim
t→∞
if initial value B(0) ∈ ΘG,τ ∗, then lim
t→∞

Bv(t) = 1 for all v ∈ V ;

Bv(t) = 0 for all v ∈ V .

 
 
 
 
)
x
(

g
d
n
a
)
x
(

f

2

1.8

1.6

1.4

1.2

1

0.8

0.6

0.4

0.2

0
0

  g(x)=2(1−x)2
  f(x)=(e−10x+5+1)−1

initial value

τ *= 0.5

0.1

0.2

0.3

0.4

0.5
x

0.6

0.7

0.8

0.9

1

(a) f (x), g(x) and threshold τ ∗ = 0.5 satisfy the condition of
transition between B∗ = 0 and B∗ = 1

〉

)
t
(

B

〈

v

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0
0

 Transition induced 
     by initial values      

5

10
 t

15

20

(b) Transition induced by varying initial value hBv(0)i

Figure 5: Transition between equilibria B∗ = 0 and B∗ = 1 as
induced by varying the initial value.

4.2 Example

We consider the transition between equilibria B∗ = 0 and B∗ =
1 as caused by varying the initial value B(0). We use two concrete
defense-power and attack-power functions:

f (x) =

1
e−10x+5 + 1

, g(x) = 2(1 − x)2,

which are plotted in Figure 5(a). The graphs GB and GR are two
ER graph instances with |V | = 2, 000 and p = 0.5. We consider
the transition induced by varying the initial value hBv(0)i between
0 and 1. Figure 5(b) shows that when hBv(0)i > 0.5, the dynamics
converge to B∗ = 1; when hBv(0)i < 0.5, the dynamics converge
to B∗ = 0.

The exploration in this section can be summarized as:

INSIGHT 2. A small change in the initial global security state,
in the model parameters, in the attack network structure, or in the
defense network structure can lead to substantial change in active
cyber defense dynamics. A rigorous characterization, such as The-
orem 1, can offer precise guidance on “what the defender should
strive to do” and “what the defender should strive to avoid” (e.g.,
how to manipulate the dynamics to beneﬁt the defender rather than
the attacker).

5. HOPF BIFURCATION

We consider Hopf bifurcation near equilibrium B∗ = σ ∈ (0, 1)
under condition (1 − σ) · f (σ) = σ · g(σ). Recall that the stability
of B∗ = σ ∈ (0, 1) depends on λ1(M ), where M , as deﬁned in
Eq. (3), is the Jacobian matrix of system (2). In the rest of the

paper, we may simplify the notation λ1(M ) as λ1 unless there is
potential ambiguity.

Consider differentiable defense-power and attack-power func-
tions f (x, ν) and g(x, ν) with parameter ν. Suppose ∂f
∂ν and
∂M
∂ν all depend on ν. Consider the following critical condition for
Hopf bifurcation:

∂ν , ∂g

ℜ(λ1) = 0 and ℑ(λ1) 6= 0.

(13)

It is known that if (13) holds for some ν = ν ∗, λ1(ν) is differen-
tiable in ν, and dλ1
dν 6= 0 at ν = ν ∗, then system (2) exhibits Hopf
bifurcation [24]. Therefore, we need to ﬁnd the critical value ν ∗.
For this purpose, we adopt the approach described in [20] to inves-
tigate how λ1 depends on the permutation to M , namely to conduct
a perturbation spectral analysis to compute the perturbation to λ1,
denoted by δλ1, as caused by perturbation to M , denoted by δM .

5.1 How to Estimate δλ1

Let x1 be the eigenvector of M associated to eigenvalue λ1,
namely, M x1 = λ1x1. For perturbation δM to M , M + δM
can be described as M (ν) + M ′(ν)δν. The perturbation to M
causes perturbation δλ1 to λ1 and perturbation δx1 to x1. That is,

M + δM

x1 + δx1

=

λ1 + δλ1

x1 + δx1

.

(cid:1)(cid:0)
By ignoring the second-order term, we obtain

(cid:1)(cid:0)

(cid:0)

(cid:0)

(cid:1)

(cid:1)

M δx1 + δM x1 = λ1δx1 + δλ1x1.

(14)

By multiplying both sides of Eq. (14) with the left eigenvector y1
corresponding to λ1, we obtain

1 M δx1 + y⊤
y⊤

1 δM x1 = y⊤

1 λ1δx1 + y⊤

1 δλ1x1,

1 λ1δx1 + y⊤
y⊤

1 δM x1 = y⊤

1 λ1δx1 + y⊤

1 δλ1x1,

y⊤
1 δM x1 = y⊤

1 δλ1x1.

As a result, we can estimate δλ1 as

δλ1 =

y⊤

1 δM x1
y⊤
1 x1

,

(15)

where δM can be estimated depending on whether the perturba-
tion is to the attack and/or defense power (Case A below) or to the
attack/defense network structure (Case B below).

Case A: δM is caused by perturbation to attack- and/or defense
power. Suppose the perturbation is imposed on parameter ν in
the attack-power and defense-power functions f (x, ν) and g(x, ν),
where ∂f
∂ν depend on ν as mentioned above. The cyber
security meanings of such perturbations is (for example) that new
attack and/or defense techniques are introduced. Note that

∂ν and ∂g

δM (ν)

=

(1 − σ)

((cid:20)

∂f ′(σ, ν)
∂ν

D−1
AB

AB − σ

∂g′(σ, ν)
∂ν

D−1
AR

AR

−

(cid:21)

∂f (σ, ν)
∂ν

+

∂g(σ, ν)
∂ν

(cid:20)

In

δν.

)

(cid:21)

In the special case GB = GR = G (i.e., the adjacency matrix
AB = AR = A), we have

M =

(1 − σ)f ′(σ) − σg′(σ)

D−1

A A −

f (σ) + g(σ)

In,

(cid:2)

(cid:3)

(cid:2)

(cid:3)

 
 
 
 
 
 
f (σ) +
In for all µ ∈ λ(D−1
A A), and the perturbation can be rewrit-
(cid:2)

(1 − σ)f ′(σ) − σg′(σ)

µ −

the eigenvalues of M are
g(σ)
ten as
(cid:3)

(cid:3)

(cid:2)

δM (ν) =

(1 − σ)

((cid:20)

∂f ′(σ, ν)
∂ν

− σ

∂g′(σ, ν)
∂ν

D−1

A A −

(cid:21)

∂f (σ, ν)
∂ν

+

∂g(σ, ν)
∂ν

(cid:20)

In

δν.

)

(cid:21)

Hence, (15) becomes

δλ1 = y⊤
1

(1 − σ)

∂f ′(σ, ν)
∂ν

− σ

∂g′(σ, ν)
∂ν

D−1

A A −

(cid:26)h
∂f (σ, ν)
∂ν

h

+

∂g(σ, ν)
∂ν

In

δν · x1

(cid:27)

i

,

i
y⊤
1 x1.

(16)

Case B: δM is caused by perturbation to attack and/or de-
fense network structure. Suppose the perturbation is imposed on
GB = (V, EB) and/or GR = (V, ER) by adding/deleting edges.
The cyber security meaning of such perturbations is that the net-
work is disrupted (e.g., edges are deleted by the attacker, or security
policies have changed) and then edges are added by the defender.
We assume that the number of added/deleted edges is small (com-
pared with |EB| and |ER|, respectively) so that we can approxi-
mately treat δM as a small perturbation. Let CB = D−1
AB and
AB
CR = D−1
AR. Perturbations to AB and AR lead to AB + δAB
AR
and AR + δAR, respectively. Correspondingly, we obtain the per-
turbations to CB and CR:

δCB = D−1
δCR = D−1

AB +δAB (AB + δAB) − D−1
AR +δAR(AR + δAR) − D−1
AR

AB AB,
AR.

Then, the perturbation to Jacobian matrix M is

δM = (1 − σ)f ′(σ)δCB − σg′(σ)δCR.

From (15), we have

δλ1 =

y⊤
1

(1 − σ)f ′(σ)δCB − σg′(σ)δCR

x1

h

y⊤

1 x1

i

.

Note that in the special case GB = GR = G (i.e., AB = AR = A)
with perturbations δCB = δCR, we have

δM =

δλ1 =

(1 − σ)f ′(σ) − σg′(σ)
h
y⊤
1

(1 − σ)f ′(σ) − σg′(σ)

i

δC,

h

y⊤

1 x1

δCx1

i

.

5.2 Example: Hopf Bifurcation Induced by

Perturbation to Parameter

In order to show that Hopf bifurcation can happen, we consider
an ER graph GB = GR = G = (V, E) with |V | = 2, 000
and edge probability p = 0.005. Let µ1 denote the eigenvalue of
D−1
A A with the smallest real part, where A is the adjacency matrix
of G. For the ER graph, we have ℜ(µ1) = −0.3448. We consider
the following defense-power and attack-power functions:

f (x) = −4x2 + 4x, g(x, ν) =

νx −

2

,

ν
2

(cid:17)

(cid:16)

where f (x) does not depend on ν. Recall that under condition
(1 − σ)f (σ) = σg(σ), there exists equilibrium B∗ = σ ∈ (0, 1).

When ν = 3, we have homogeneous equilibrium B∗ = 0.7,
which is locally stable according to the second condition in the ﬁrst
part of Corollary 2:

(1 − σ)f ′(σ) − σg′(σ, 3) = −3 < 0,

f (σ) + g(σ, 3)
(1 − σ)f ′(σ) − σg′(σ, 3)

= −0.4 < ℜ(µ1) = −0.3448.

When ν = 4, we have homogeneous equilibrium B∗ = 0.6667,
which is locally unstable according to the second condition in the
second part of Corollary 2:
(1 − σ)f ′(σ) − σg′(σ, 4) = −4 < 0

f (σ) + g(σ, 4)
(1 − σ)f ′(σ) − σg′(σ, 4)

= −0.3333 > ℜ(µ1) = −0.3448.

Therefore, there is a critical value between ν = 3 and ν = 4, at
which ℜ(λ1(M )) = 0. By conducting 100 independent simulation
runs of ν ∈ [3, 4) with step-length 0.01, we ﬁnd the critical value
ν = 3.8 and the corresponding equilibrium B∗ = 0.6724, where

(1 − σ)f ′(σ) − σg′(σ, 3.8) = 7 − 3.81 < 0,

f (σ) + g(σ, 3.8)
(1 − σ)f ′(σ) − σg′(σ, 3.8)

= −0.3448 = ℜ(µ1).

Figure 6(a) plots the periodic trajectory of hBv(t)i when ν =
4 > 3.8, which surrounds equilibrium B∗ = 0.6724. Figure
6(b) plots the periodic trajectory of hBv(t)i when ν = 5.05 >
3.8. Figure 6(c) plots the bifurcation diagram with respect to ν ∈
(3, 6). Figure 6(d) plots the bifurcation diagram with respect to
ν ∈ (4.75, 5.5). We observe that when ν ∈ (5, 5.5), there are
not only two-periodic trajectories, but also k-periodic trajectories
(k > 2). In summary, the periodic trajectories exhibit the period-
doubling cascade phenomenon.

5.3 Example: Hopf Bifurcation Induced by

Perturbation to Attack/Defense Network
Structures

For the purpose of demonstrating the bifurcation phenomenon
caused by perturbation to network structures, we use two randomly
generated ER graph examples GB = (V, EB) and GR = (V, ER),
both with |V | = 2, 000 and p = 0.005. The average degree
is 10.0565 for GB and 11.1865 for GR. We use the following
defense-power and attack-power functions:

f (x) = −4x2 + 4x, g(x, ν) =

νx −

2

with ν = 6

We perform 100 iterations of operations to GR as follows: during
each of the ﬁrst 50 iterations, we delete 226 edges (or 1% of the
edges in the original ER) chosen independently and uniformly at
random; during each of the following 50 iterations, we add 226
edges chosen independently and uniformly random among all the
unconnected edges. That is, we delete and then add 50% edges of
the original |ER|.

Figure 7 demonstrates that the period-doubling cascade phe-
nomenon appears and ﬁnally leads to chaos after deleting more
than 36% edges and before adding 14% edges. We observe that
eventually the diagram becomes stable after adding the same num-
ber of edges as those deleted. (Note that Figure 7 is not symmetric
because the added edges are random and in general are different
from the edges that are deleted.)

The following insight summarizes the exploration of this section.

INSIGHT 3. Active cyber defense dynamics can exhibit Hopf bi-
furcation, when the attack/defense power varies in certain parame-
ter regimes and/or when the attack/defense network structure varies

ν
2

(cid:17)

(cid:16)

〉

)
t
(

B

〈

v

  Limit cycle

0.67

0.669

0.668

0.667

0.666

0.665

0.664
0

50

100

150

200

300

350

400

450

500

250
 t

〉

)
t
(

B

〈

v

0.633

0.647

0.645

0.643

0.641

0.639

0.637

0.635

0.633
0

  Multi period 

50

100

150

200

250
 t

300

350

400

450

500

(a) Periodic trajectory of hBv(t)i with ν = 4

(b) Periodic trajectory of hBv(t)i w/ ν = 5.05

0.685

0.675

0.665

〉

0.655

v

B

〈

0.645

0.635

0.625

0.615

3.5

  Hopf bifurcation Diagram

〉

v

B

〈

  Hopf bifurcation Diagram

0.65

0.645

0.64

0.635

4

4.5

ν

5

5.5

6

0.63

4.75

4.875

5

5.125
ν

5.25

5.375

5.5

(c) Bifurcation diagram w/ ν ∈ (3, 6)

(d) Bifurcation diagram w/ ν ∈ (4.75, 5.5)

Figure 6: Limit cycle and Hopf bifurcation diagram, where hBvi are the extremum points of hBv(t)i in time period t ∈ (1000, 2000).

0.632

0.63

0.628

〉

0.626

v

B

〈

0.624

0.622

0.62

0.618
0

−10

chaos region

  Diagram

case, system (2) becomes

dBv(t)
dt

= f





g



1
deg(v, G)

1
deg(v, G)

u∈Nv,G
X

Bu(t)

1 − Bv(t)

−

h

i





Bu(t)



Bv(t).

u∈Nv,G
X

Bv(0), t


denote the right-hand part. Consider Bv(0) and
Let F
Bv(0) + εv(0) for all v ∈ V , where εv(0) ∈ Rn is a small pertur-
bation to the initial point Bv(0). Then, we have ∀v ∈ V ,



(cid:1)

(cid:0)

−30

−20

−50
Percentage of deleting (−) or adding (+) edges (%)

−40

+10

+30

+20

+40

+50

Figure 7: Hops bifurcation induced by perturbation to the net-
work structure.

in certain patterns. These situations are “unmanageable” because
it would be infeasible, if not impossible, to estimate the global secu-
rity state in real-time. Therefore, the defender must strive to avoid
such unmanageable situations by manipulating the dynamics care-
fully (e.g., by disrupting the bifurcation condition or containing the
attack-power of the adversary).

6. CHAOS

Figure 6(c) shows that the number of periodic points increase
with parameter ν, which hints that system (2) can exhibit the chaos
phenomenon. To see this, we consider the case GB = GR. In this

εv(t) = F

Bv(0) + εv(0), t

− F

Bv(0), t

= DF
(cid:0)

Bv(0), t

· εv(0),

(cid:1)

(cid:0)

(cid:1)

Bv(0), t

(cid:1)
where DF
By the QR decomposition of matrix ε(t) = [ε1(t), ε2(t), · · · , εn(t)]
where n = |V |, we obtain matrix

is the Jacobian matrix of the map F at time t.

(cid:1)

(cid:0)

(cid:0)

ε(t) = q(t) · r(t),

where q(t) is an orthogonal matrix and r(t) is an upper triangular
matrix. Note that ε(t) = q(t) and the diagonal element λii(t) of rt
at time t is the exponential magniﬁcation, where i ∈ {1, 2, · · · , n}.
Thus, the average rate of divergence or convergence of the two tra-
jectories
for all v ∈ V is deﬁned by
(cid:0)

Bv(0) + εv(0), t

Bv(0), t

and {F

t ≥ 0

t ≥ 0

F

(cid:8)

(cid:9)

(cid:9)

(cid:0)

(cid:1)(cid:12)
(cid:12)

(cid:1)(cid:12)
(cid:12)

Li = lim
t→∞

ln λii(t),

1
t

where Li for i = 1, 2, · · · , n are the Lyapunov characteristic ex-
It is known [24] that under some mild conditions, the
ponents.

 
 
 
 
 
 
 
 
 
 
 
 
 
above limit exists and is ﬁnite for almost all initial values B(0) =
[B1(0), B2(0), · · · , Bn(0)] and for almost all matrices ε(0). Note
that MLE = max1≤i≤n Li indicates whether the dynamical sys-
tem is chaotic or not. More speciﬁcally, when MLE > 0, a small
perturbation to the initial value will lead to an exponential separa-
tion and therefore leads to the chaos phenomenon.

Example. Consider an ER graph instance GB = GR with |V | =
2, 000 and p = 0.005, and the following defense-power and attack-
power functions:

f (x) = −4x2 + 4x, gν(x) =

νx −

(cid:16)

2

.

ν
2

(cid:17)

v
o
n
u
p
a
y
L

l
a
m
i
x
a
M

)
E
L
M

(

t
n
e
n
o
p
x
e

0.06

0.04

0.02

0

−0.02

−0.04
1

2

3

4

5

ν

6

7

8

9

10

(a) MLE with ν: MLE > 0 indicates chaos.

〉

)
t
(

B

〈

v

0.604

0.602

0.6

0.598

0.596

0.594

0.592

0.59

0.588
0

100

200

300

400

500

 t

(b) hBv(t)i for ν = 8 exhibits chaos.

Figure 8: Active cyber defense dynamics exhibit the chaos phe-
nomenon: GB = GR with |V | = 2, 000 and p = 0.005.

Figure 8(a) plots the MLE with respect to ν. We observe that
MLE > 0 when ν > 5, meaning that system (17) exhibit chaos
for ν > 5. Figure 8(b) plots the phase portrait of hBv(t)i (i.e., the
average of the Bv(t)’s for all v ∈ V ) when ν = 8, which hints the
emergence of chaos. This means that the defender should strive to
avoid the parameter regime ν > 5. This leads to the following:

INSIGHT 4. Active cyber defense dynamics can be chaotic, mean-

ing that it is impossible to predict the global cyber security state
because it is too sensitive to the accuracy of the estimated initial
global security state. Therefore, the defender must strive to avoid
such unmanageable situations (e.g., by disrupting the attacks to as-
sure ν ≤ 5 in the above example).

7. RELATED WORK

Cybersecurity Dynamics is a framework for modeling and quan-
tifying cyber security from a holistic perspective (rather than mod-
eling and analyzing security of components or building-blocks) [34,
35, 36, 17]. This framework builds on a large body of literature
across Computer Science, Mathematics and Statistical Physics (cf.

[7, 4, 33, 37, 38, 17, 39, 29, 6, 3, 28, 23, 11, 12] and the references
therein), which can be further traced back to the century-old studies
on biological epidemic models [19, 13, 8].

As a speciﬁc kind of cybersecurity dynamics, active cyber de-
fense dynamics were ﬁrst rigorously modeled and studied in [36],
despite that the idea of active defense has been discussed and de-
bated for many years [14, 31, 18, 16, 26, 30, 1, 2]. We move
a signiﬁcant step beyond [36], by separating the attack network
structure from the defense network structure, and by considering
more general attack and defense power functions. To the best of
our knowledge, we are the ﬁrst to show that bifurcation and chaos
are relevant in the cyber security domain, and to discuss the cyber
security implications of these phenomena. Following [36], Lu et
al. [17] investigate optimal active defense strategies in the Control-
Theoretic and Game-Theoretic frameworks. Our study is comple-
mentary to [17] as we leave it to future work to investigate optimal
strategies in our setting.

It is worth mentioning that models of Lotka-Volterra type [9]
capture the predator-prey dynamics, which are however different
from the active cyber defense dynamics. Active cyber defense dy-
namics may be seen as the non-linear generalization of the so-
called Voter model in complex networks [25, 15]. Somewhat re-
lated to our work is [5], which considers chaotic dynamics in discrete-
time limited imitation contagion model on random networks.

8. CONCLUSION

We have explored the rich phenomena that can be exhibited by
active cyber defense dynamics. To the best of our knowledge, our
study is the ﬁrst to show that bifurcation and chaos are relevant
in the cyber security domain. The implication is of high practical
value: In order to make cyber security measurement and prediction
feasible, the defender must manipulate the cyber security dynamics
to avoid these unmanageable situations.

Interesting problems for future research include: First, we need
to characterize non-homogeneous equilibria as we only focused on
homogeneous equilibria. Second, we need to characterize which
graph structure is more advantageous to the other (e.g., GB is ER
graph but GR is power-law graph). Third, we need to explore the
chaos phenomenon further (e.g., multi-direction chaos). Fourth, we
need to systematically validate the models.

Acknowledgement. We thank the reviewers for their useful com-
ments and Marcus Pendleton for proofreading the paper. Wen-
lian Lu was supported in part by the National Natural Sciences
Foundation of China under Grant No. 61273309, the Program
for New Century Excellent Talents in University (NCET-13-0139),
the Programme of Introducing Talents of Discipline to Universi-
ties (B08018), and the Laboratory of Mathematics for Nonlinear
Science, Fudan University. Shouhuai Xu was supported in part by
ARO Grant #W911NF-12-1-0286 and NSF Grant #1111925. Any
opinions, ﬁndings, and conclusions or recommendations expressed
in this material are those of the author(s) and do not necessarily
reﬂect the views of any of the funding agencies.

9. REFERENCES
[1] D. Aitel. Nematodes – beneﬁcial worms. http://www.

immunityinc.com/downloads/nematodes.pdf,
Sept. 2005.

[2] F. Castaneda, E. Sezer, and J. Xu. Worm vs. worm:

preliminary study of an active counter-attack mechanism. In
Proceedings of ACM WORM’04, pages 83–93, 2004.
[3] D. Chakrabarti, Y. Wang, C. Wang, J. Leskovec, and

C. Faloutsos. Epidemic thresholds in real networks. ACM

 
 
 
 
Trans. Inf. Syst. Secur., 10(4):1–26, 2008.

[4] G. Da, M. Xu, and S. Xu. A new approach to modeling and
analyzing security of networked systems. In Proceedings of
HotSoS’14, pages 6:1–6:12.

[5] P. S. Dodds, K. D. Harris, and C. M. Danforth. Limited
imitation contagion on random networks: Chaos,
universality, and unpredictability. Phys. Rev. Lett.,
110:158701, Apr 2013.

[6] A. Ganesh, L. Massoulie, and D. Towsley. The effect of

network topology on the spread of epidemics. In Proceedings
of IEEE Infocom 2005, 2005.

[7] Y. Han, W. Lu, and S. Xu. Characterizing the power of
moving target defense via cyber epidemic dynamics. In
Proceedings of HotSoS’14, pages 10:1–10:12.

[8] H. Hethcote. The mathematics of infectious diseases. SIAM

Rev., 42(4):599–653, 2000.

[9] J. Hofbauer and K. Sigmund. The theory of evolution and
dynamical systems. Cambridge University Press, 1998.

[10] R. Horn and C. Johnson. Matrix Analysis. Cambridge

University Press, 1985.

[11] J. Kephart and S. White. Directed-graph epidemiological

models of computer viruses. In IEEE Symposium on Security
and Privacy, pages 343–361, 1991.

[12] J. Kephart and S. White. Measuring and modeling computer
virus prevalence. In IEEE Symposium on Security and
Privacy, pages 2–15, 1993.

[13] W. Kermack and A. McKendrick. A contribution to the

mathematical theory of epidemics. Proc. of Roy. Soc. Lond.
A, 115:700–721, 1927.

[14] J. Kesan and C. Hayes. Mitigative counterstriking:

Self-defense and deterrence in cyberspace. Harvard Journal
of Law and Technology (forthcoming, available at SSRN:
http://ssrn.com/abstract=1805163).
[15] P. L. Krapivsky. Kinetics of monomer-monomer surface

catalytic reactions. Phys. Rev. A, 45:1067–1072, Jan 1992.
[16] H. Lin. Lifting the veil on cyber offense. IEEE Security &

Privacy, 7(4):15–21, 2009.

[17] W. Lu, S. Xu, and X. Yi. Optimizing active cyber defense
dynamics. In Proceedings of GameSec’13, pages 206–225.

[18] W. Matthews. U.s. said to need stronger, active cyber

defenses. http://www.defensenews.com/story.
php?i=4824730, 1 Oct 2010.

[19] A. McKendrick. Applications of mathematics to medical
problems. Proc. of Edin. Math. Soceity, 14:98–130, 1926.

[20] A. Milanese, J. Sun, and T. Nishikawa. Approximating

spectral impact of structural perturbations in large networks.
Phys. Rev. E, 81:046112, Apr 2010.

[21] J. Morales, S. Xu, and R. Sandhu. Analyzing malware

detection efﬁciency with multiple anti-malware programs. In
Proceedings of 2012 ASE CyberSecurity’12.

[22] R. Naraine. ’friendly’ welchia worm wreaking havoc.

http://www.internetnews.com/ent-news/
article.php/3065761/Friendly-Welchia
-Worm-Wreaking-Havoc.htm, August 19, 2003.
[23] R. Pastor-Satorras and A. Vespignani. Epidemic spreading in

scale-free networks. PRL, 86(14):3200–3203, 2001.

[24] R. Robinson. Dynamical Systems: Stability, Symbolic

Dynamics, and Chaos (2dn Edition). CRC Press, 1999.
[25] C. Schneider-Mizell and L. Sander. A generalized voter

model on complex networks. Journal of Statistical Physics,
136(1):11, 2008.

[26] B. Schneier. Benevolent worms. http://www.

schneier.com/blog/archives/2008/02/
benevolent_worm_1.html, February 19, 2008.
[27] L. Shaughnessy. The internet: Frontline of the next war?

http://www.cnn.com/2011/11/07/us/darpa/,
November 7, 2011.

[28] P. Van Mieghem, J. Omic, and R. Kooij. Virus spread in

networks. IEEE/ACM Trans. Netw., 17(1):1–14, Feb. 2009.

[29] Y. Wang, D. Chakrabarti, C. Wang, and C. Faloutsos.
Epidemic spreading in real networks: An eigenvalue
viewpoint. In Proceedings of SRDS’03, pages 25–34.
[30] N. Weaver and D. Ellis. White worms don’t work. ;login:

The USENIX Magazine, 31(6):33–38, 2006.

[31] H. S. N. Wire. Active cyber-defense strategy best deterrent

against cyber-attacks. http://www.
homelandsecuritynewswire.com/active
-cyber-defense-strategy-best-deterrent
-against-cyber-attacks, 28 June 2011.
[32] J. Wolf. Update 2-u.s. says will boost its cyber arsenal.

http://www.reuters.com/article/2011/11/
07/cyber-usa-offensive-
idUSN1E7A61YQ20111107, November 7, 2011.
[33] M. Xu and S. Xu. An extended stochastic model for

quantitative security analysis of networked systems. Internet
Mathematics, 8(3):288–320, 2012.

[34] S. Xu. Cybersecurity dynamics. In Proceedings of

HotSoS’14, pages 14:1–14:2.

[35] S. Xu. Emergent behavior in cybersecurity. In Proceedings of

HotSoS’14, pages 13:1–13:2.

[36] S. Xu, W. Lu, and H. Li. A stochastic model of active cyber

defense dynamics. Internet Mathematics, 11(1):23–61, 2015.

[37] S. Xu, W. Lu, and L. Xu. Push- and pull-based epidemic
spreading in arbitrary networks: Thresholds and deeper
insights. ACM TAAS, 7(3):32:1–32:26, 2012.

[38] S. Xu, W. Lu, L. Xu, and Z. Zhan. Adaptive epidemic

dynamics in networks: Thresholds and control. ACM TAAS,
8(4):19, 2014.

[39] S. Xu, W. Lu, and Z. Zhan. A stochastic model of multivirus

dynamics. IEEE TDSC, 9(1):30–45, 2012.

APPENDIX
Now we prove Theorem 1.

PROOF. We prove the theorem in the ﬁrst statement with B(0) ∈
, and the second statement with R(0) ∈ ΞGR ,τ ∗
can be

2

ΞGB ,τ ∗
proved similarly.

1

First, we see that g(1) = 0 implies that B∗ = 1 is an equilibrium

of (2) according to Proposition 1. Deﬁne

Vt = argmin

Bv(t) =

u

Bu(t) = min
v∈V

Bv(t)

v∈V

n
for t ≥ 0. Since the case minv Bv(0) = 1, namely Bv(t) = 1 for
all v ∈ V and t ≥ 0, is trivial, we assume minv Bv(0) < 1 without
loss of any generality. For any v(0) ∈ V0, the given condition (10)
implies
1 , and thus we have

Bu(0) ≥ τ ∗

1
deg(v(0),GB )

o

(cid:12)
(cid:12)
(cid:12)

u∈Nv(0),GB

P

1
deg(v(0), GB)

f




≥ α ·

1
deg(v(0), GB)

Bu(0)





Bu(0),

u∈Nv(0),GB
X

u∈Nv(0),GB
X

where “=” holds only when

1
deg(v(0),GB )

u∈Nv(0),GB

1. Let t = 0 and v = v(0). Using Eq. (2) and condition (11), we
have

P

Bu(0) =

creasing, i.e

dBv(0)(t)
dt

t=0

(cid:12)
(cid:12)
(cid:12)
1
(cid:12)
deg(v(0), GB)

1
deg(v(0), GB)

= f

g









≥ f

1
deg(v(0), GB)



≥ α


Bv(0)(0) − Bv(0)(0)

(cid:16)
= 0.

(cid:17)

u∈Nv(0),GB
X

u∈Nv(0),GB
X

u∈Nv(0),GB
X

Bu(0)





Bu(0)





Bu(0)





1 − Bv(0)(0)
h

i

−

Bv(0)(0)

− αBv(0)(0)

(17)

Since the equality signs hold in the two inequalities in Eq. (17) only
when minv Bv(0) = 1, which corresponds to the trivial case men-
tioned above, we conclude that minv∈V Bv(t) strictly increases in
a small time interval starting at t = 0 except for the trivial case.

Let τ ∗∗

1 > τ ∗

1 such that

1
deg(v(0),GB )

τ ∗∗
1 for all v ∈ V . We now show that
τ ∗∗
1

for all t > 0 and for all v ∈ V . Let t0 be the ﬁrst time that
1
deg(v,GB )

for some v ∈ V , i.e.

Bu(t) = τ ∗∗
1

P

u∈Nv,GB

1
P
deg(v,GB )

u∈Nv,GB

u∈Nv(0),GB

Bu(0) >

Bu(t) >

P

1
deg(v, GB)

t0 =

Bu(t) > τ ∗∗

1 ∀t ∈ [0, τ ), ∀v ∈ V

.




u∈Nv,GB
X




We show t0 = +∞. Suppose t0 < +∞. Let V ∗ be the node set
such that for each v ∈ V ∗,
1
Bu(t) reaches
deg(v,GB )
for the ﬁrst time. Then, for some v∗ ∈ V ∗, we know that
τ ∗∗
1
1
Bu(t) is not increasing at t = t0. How-
deg(v∗,GB )
u∈Nv∗ ,GB
ever, it can be shown that
P

u∈Nv,GB

P

inf

τ




(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

d
dt 

1
deg(v∗, GB)

Bu(t)

u∈Nv∗,GB
X



1
deg(v∗, GB)

α
deg(v∗, GB)

=

≥

dBu(t)
dt

u∈Nv∗ ,GB
X

·

t=t0

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

t=t0

(cid:12)

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)

u∈Nv∗,GB
X

≥ 0,





1
deg(u, GB)

w∈Nu,GB
X

Bw(t) − Bu(t0)





where the equality signs hold only for the trivial case as in the case
of Eq. (17) mentioned above (i.e., in all other cases the inequalities
are strict). So we reach a contradiction, which means t0 = +∞.
Owing to τ ∗∗
Bu(t) > τ ∗
1
for all t > 0. That is, B(t) ∈ ΞGB ,τ ∗

1
deg(v,GB )

1 , we have

1 > τ ∗

u∈Nv,GB

Let t1 be the maximum time that minv∈V Bv(t) is strictly in-

for all t.
P

1

t1 = sup

t

(cid:26)

min
v

Bv(t) is strictly increasing in [0, t)

.

(cid:27)

We show that t1 = +∞. Suppose that t1 is ﬁnite, meaning that
minv∈V Bv(t) is not increasing at time t = t1. Since it holds that
minv∈V Bv(t1) > minv∈V Bv(0) > τ ∗
1 , by replacing B(0) with
B(t1), we have

(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
deg(v(t1), GB)

f



>



α
deg(v(t1), GB)

Bu(t1)

u∈Nv(t1 ),GB
X

Bu(t1)





u∈Nv(t1 ),GB
X

and therefore we can show
dBv(t1)(t)
dt

t=t1
(cid:12)
(cid:12)
(cid:12)
1
(cid:12)
deg(v(t1), GB)

≥ f





≥ α

≥ 0,





u∈Nv(t1 ),GB
X

Bu(t1)





− αBv(t1)(t1)

1
deg(v(t1), GB)

u∈Nv(t1 ),GB
X

Bu(t1) − Bv(t1)(t1)





where are inequalities are strict except for the trivial case — as
discussed in the case of Eq. (17). That is, minv∈V Bv(t) strictly
increases at t = t1, which contradicts with the deﬁnition of t1.
Therefore, we have t1 = +∞ and minv∈V Bv(t) is strictly in-
creasing in t ∈ [0, +∞).

In order to show limt→∞ Bv(t) = 1 for all v ∈ V , we will prove
that limt→∞ minv∈V Bv(t) = 1 for limt→∞ minv∈V Bv(t) ≤
limt→∞ Bv(t). Since Bv(t) is the probability that node v ∈ V
is blue at time t, we have 0 ≤ Bv(t) ≤ 1 for all v ∈ V . Hence
limt→∞ minv∈V Bv(t) exists. Suppose for the sake of contradic-
tion that limt→∞ minv∈V Bv(t) < 1, meaning minv∈V Bv(t) <
1 for all t due to its strict increasing monotonicity. For any v(t) ∈
Vt, under the condition that Eq. (10) holds, there exists ε > 0 such
that f (Bv(t)(t)) − αBv(t)(t) > ε for all t.

Since minv∈V Bv(t) is strictly increasing for t ∈ [0, +∞),

there exists T > 0 such that

dBv(t)(t)
dt

1
deg(v(t), GB)

= f





1
deg(v(t), GB)

g



u∈Nv(t),GB
X

u∈Nv(t),GB
X

1 − Bv(t)(t)
h

i

−

Bv(t)(t)

Bu(t)





Bu(t)





≥ f


Bv(t)(t)

− αBv(t)(t) > ε,

for all t > T . This leads to

(cid:16)

(cid:17)

Bv(t)(t) > Bv(T )(T ) + ε(t − T ).

Since minv∈V Bv(t) = Bv(t)(t) → ∞ as t → ∞, it contradicts
Bv(t) = 1 and
with Bv(t) ≤ 1. Therefore, we conclude lim
t→∞

min
v∈V

lim
t→∞

Bv(t) = 1.

