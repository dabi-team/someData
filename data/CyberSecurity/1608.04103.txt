6
1
0
2

g
u
A
4
2

]
L
F
.
s
c
[

2
v
3
0
1
4
0
.
8
0
6
1
:
v
i
X
r
a

Supervisor Synthesis to Thwart Cyber Attack

with Bounded Sensor Reading Alterations

1

Rong Su

Abstract

One of the major challenges about cyber physical systems is how to prevent cyber attacks to ensure

system integrity. There has been a large number of different types of attacks discussed in the modern

control and computer science communities. In this paper we aim to investigate one special type of attacks

in the discrete-event system framework, where an attacker can arbitrarily alter sensor readings after

intercepting them from a target system in order to trick a given supervisor to issue control commands

improperly, driving the system to an undesirable state. We ﬁrst consider the cyber attack problem from

an attacker point of view, and formulate an attack with bounded sensor reading alterations (ABSRA)

problem. We then show that the supremal (or least restrictive) ABSRA exists and can be synthesized, as

long as the plant model and the supervisor model are regular, i.e., representable by ﬁnite-state automata.

Upon the synthesis of the supremal ABSRA, we present a synthesis algorithm, which ensures that a

computed supervisor will be ABSRA-robust , i.e., either an ABSRA will be detectable or will not lead

the system to an undesirable state.

Index Terms

discrete-event systems, supervisory control, cyber security, attack under bounded sensor reading

alterations, partial observation, controllability

I. INTRODUCTION

A cyber-physical system (CPS) is a mechanism controlled or monitored by computer-based

algorithms. Examples of CPS include smart grid, autonomous automobile systems, medical

Rong Su is afﬁliated with Division of Control and Instrumentation, School of Electrical and Electronic Engineering, Nanyang

Technological University, 50 Nanyang Avenue, Singapore 639798. Emails: rsu@ntu.edu.sg. The support from Singapore Ministry

of Education Tier 1 Academic Research Grant M4011221.040 RG84/13 is gratefully acknowledged.

September 13, 2018

DRAFT

 
 
 
 
 
 
2

monitoring, process control systems, distributed robotics, and automatic pilot avionics, etc.

The connection between the cyber part and the physical part heavily relies on communication

networks, which has been raising a major security concern, as different types of cyber attacks

can tamper the data collection processes and interfere safety critical decision making processes,

which may cause irreparable damadges to the physical systems being controlled and to people

who depend on those systems.

There has been a growing number of publications addressing the cyber security issues from

both the computer science community, which focuses on the computer computation related issues,

and the systems control community, which focuses on issues related to the system dynamics

affected by cyber attacks. Recently, more and more efforts have been made in classifying different

types of malicious attacks, assuming that the attackers are sufﬁciently intelligent [12] [13], instead

of merely just generating random failures, which is well studied in the ﬁelds of reliability and

fault tolerant control. Typically, an intelligent attacker requires system knowledge, and abilities

for resource disclosure and resource disruption in order to carry out a successful attack, which is

covert to a system user until the attacker’s goal of causing a damage to the system is achieved.

So covertness and damage inﬂiction are two major characteristics of a successful attack. By

analyzing different intelligent cyber attacks, proper countermeasures may be developed to prevent

a target system from being harmed by a speciﬁc type of attacks.

In this paper we study a special type of data deception attacks in the discrete-event system

framework, where an attacker can intercept sensor measurements (or observations) modeled by

observable events and alter them arbitrarily but with an upper bound imposed on the length of

each altered observation sequence. By sending those altered observation sequences to a given

supervisor, whose function is known to the attacker in advance, the attacker can deliberately and

covertly guide the system to move into some undesirable states without making any change to the

supervisor. The key challenge is how to “fool” the supervisor to make it believe that the system

is operating correctly, while using the supervisor’s own control functions to carry out the attack,

i.e., to lead the system move into a bad state. To this end, we ﬁrst propose the concept of attack

under bounded sensor reading alterations (ABSRA), which can be modelled as a ﬁnite-state

transducer, possessing the properties of covertness, damadge inﬂiction and control feasibility

September 13, 2018

DRAFT

3

under partial observations. Then we show that the supremal (or least restrictive) ABSRA exists

and is computable via a speciﬁc synthesis algorithm, as long as both the plant model G and

the given supervisor S are ﬁnitely representable. Upon this novel ABSRA synthesis algorithm,

we present a supervisor synthesis algorithm, which can ensure that a nonempty synthesized

supervisor will be “robust” to any ABSRA, in the sense that such an attack will either reveal

itself to the supervisor due to abnormal system executions (so that proper contingent actions can

be taken by the supervisor, which is nevertheless outside the scope of this paper) or will not be

able to lead the system to a bad state (i.e., no damadge will be inﬂicted).

Our construction of an ABSRA model as a transducer is inspired by some recent work on

opacity enforcement [14], which aims to use observable event insertions to prevent a potential

attacker from correctly determining the actual state of a target system. Due to the different

objectives of two works, the modeling details and synthesis algorithms are completely different.

There have been some works on cyber attack detection and prevention in the discrete-event

community [15] [16] [17], mainly from an adaptive fault tolerant control point of view, which

heavily rely on real-time fault diagnosis to identify the existence of an attack and then take

necessary robust or adaptive supervisory control actions. In those works the intelligence of an

attacker is not considered, and an attack is treated as a fault. As a contrast, we do not rely

on real time attack detection, but rely on prior knowledge of attack models, and simply build

attack-robustness features into a supervisor to ensure that the supervisor will not be affected by

any ABSRA unnoticeably. It is this robust control nature distinguishes our works from existing

DES-based cyber attack detection and prevention approaches, which fall in the adaptive control

domain.

The remainder of the paper is organized as follows. In Section II we review the basic concepts

and operations of discrete event systems, and formulate an ABSRA synthesis problem, which is

then solved in Section III, where we show that the supremal ABSRA exists and computable. In

Section IV we present an algorithm to synthesize a supervisor, which is robust to any ABSRA.

A simple yet realistic example runs through the entire paper to illustrate all relevant concepts

and algorithms. Conclusions are drawn in Section V.

September 13, 2018

DRAFT

4

II. AN ABSRA PROBLEM

In this section we ﬁrst recall some standard concepts used in the Ramadge-Wonham super-

visory control paradigm. Then we introduce the concept of ABSRA, followed by a concrete

ABSRA synthesis algorithm, which reveals that the supremal ABSRA is computable, as long as

both the plant model and the given supervisor are regular.

A. Preliminaries on supervisory control

Given an arbitrary ﬁnite alphabet Σ, let Σ∗ be the free monoid with the empty string (cid:15) being

the unit element and the string concatenation being the monoid operation. Given two strings

s, t ∈ Σ∗, s is called a preﬁx substring of t, written as s ≤ t, if there exists u ∈ Σ∗ such that

su = t, where su denotes the concatenation of s and u. Any subset L ⊆ Σ∗ is called a language.

The preﬁx closure of L is deﬁned as L = {s ∈ Σ∗|(∃t ∈ L) s ≤ t} ⊆ Σ∗. Given two languages

L, L(cid:48) ⊆ Σ∗, let LL(cid:48) := {ss(cid:48) ∈ Σ∗|s ∈ L ∧ s(cid:48) ∈ L(cid:48)} denote the concatenation of two sets. Let

Σ(cid:48) ⊆ Σ. A mapping P : Σ∗ → Σ(cid:48)∗ is called the natural projection with respect to (Σ, Σ(cid:48)), if

1) P ((cid:15)) = (cid:15),

2) (∀σ ∈ Σ) P (σ) :=




σ



(cid:15)

if σ ∈ Σ(cid:48),

otherwise,

3) (∀sσ ∈ Σ∗) P (sσ) = P (s)P (σ).

Given a language L ⊆ Σ∗, P (L) := {P (s) ∈ Σ(cid:48)∗|s ∈ L}. The inverse image mapping of P is

P −1 : 2Σ(cid:48)∗ → 2Σ∗ : L (cid:55)→ P −1(L) := {s ∈ Σ∗|P (s) ∈ L}.

1 and L2 ⊆ Σ∗
Given L1 ⊆ Σ∗
1 (L1) ∩ P −1
P −1
2 (L2), where P1 : (Σ1 ∪ Σ2)∗ → Σ∗
projections. Clearly, || is commutative and associative.

2, the synchronous product of L1 and L2 is deﬁned as L1||L2 :=
2 are natural

1 and P2 : (Σ1 ∪ Σ2)∗ → Σ∗

A given target plant is modelled as a deterministic ﬁnite-state automaton, G = (X, Σ, ξ, x0, Xm),

where X stands for the state set, Σ for the alphabet, ξ : X × Σ → X for the (partial) transition

function, x0 for the initial state and Xm ⊆ X for the marker state set. We follow the notation

system in [10], and use ξ(x, σ)! to denote that the transition ξ(x, σ) is deﬁned. For each state

x ∈ X, let EnG(x) := {σ ∈ Σ|ξ(x, σ)!} be the set of events enabled at x in G. The domain of

ξ can be extended to X × Σ∗, where ξ(x, (cid:15)) = x for all x ∈ X, and ξ(x, sσ) := ξ(ξ(x, s), σ).

September 13, 2018

DRAFT

5

The closed behavior of G is deﬁned as L(G) := {s ∈ Σ∗|ξ(x0, s)!}, and the marked behavior

of G is Lm(G) := {s ∈ L(G)|ξ(x0, s) ∈ Xm}. G is nonblocking if Lm(G) = L(G). We assume
that the marker state set Xm is partitioned into two disjoint sets Xm = Xd,m ˙∪Xb,m, where Xd,m

is the set of desirable states and Xb,m denotes the set of bad states.

We now recall the concept of supervisors. Let Σ = Σc ˙∪Σuc = Σo ˙∪Σuo, where disjoint Σc

(Σo) and Σuc (Σuo) denote respectively the sets of controllable (observable) and uncontrollable

(unobservable) events, respectively. Let Γ := {γ ⊆ Σ|Σuc ⊆ γ} be the collection of all control
patterns. A (feasible) supervisory control map of G under partial observation Po : Σ∗ → Σ∗

o is

deﬁned as V : L(G) → Γ, where

(∀s, s(cid:48) ∈ L(G)) Po(s) = Po(s(cid:48)) ⇒ V (s) = V (s(cid:48)).

For each s ∈ L(G), V (s) is interpreted as the set of events allowed to be ﬁred after s. Thus,

a supervisory control map will not disable any uncontrollable events, and will impose the same

control pattern after strings, which cannot be distinguished based on observations. Let V /G

denote the closed-loop system of G under supervision of V , i.e.,

• (cid:15) ∈ L(V /G),

• L(V /G) := {sσ ∈ L(G)|s ∈ L(V /G) ∧ σ ∈ V (s)},

• Lm(V /G) := Lm(G) ∩ L(V /G).

The control map V is ﬁnitely representable if V /G can be denoted by a ﬁnite-state automaton,

say S = (Z, Σ, δ, zo, Zm = Z) such that

• L(S||G) = L(V /G) and Lm(S||G) = Lm(V /G), where ‘||’ is automaton product [10],

• (∀s ∈ L(S)) ES(s) := {σ ∈ Σ|sσ ∈ L(S)} = V (s),
• (∀s, s(cid:48) ∈ L(S)) Po(s) = Po(s(cid:48)) ⇒ ES(s) = ES(s(cid:48)).

It has been shown that, as long as a closed-loop language K ⊆ Lm(G) is controllable [4] and

observable [2], there always exists a ﬁnitely-representable supervisory control map V such that

Lm(V /G) = K and L(V /G) = K. From now on we assume that V /G is ﬁnitely representable

by S, which is called a supervisor. We assume that S is legal in the sense that Lm(S)∩Lm(G) ⊆

{s ∈ Lm(G)|ξ(x0, s) ∈ Xd,m}, i.e., under the supervision of S, the plant G should never enter

any bad marker state.

September 13, 2018

DRAFT

6

B. A sensor attack model

We assume that an attacker can intersept each observable event generated by the plant G, and

replace it by a sequence of observable events from Σo in order to “fool” the given supervisor

S, whose function is known to the attacker. Considering that in practice any event occurance

takes an unnegligible amount of time, it is impossible for an attacker to insert an arbitrarily

long observable sequence to replace a received observable event. For this reason, we assume
that there exists a known natural number n ∈ N such that the length of any observable sequence

that the attacker can insert is no more than n. Let ∆n := {s ∈ Σ∗

o||s| ≤ n} be the set of
all such bounded observable sequences, where |s| denotes the length of s, and by convention,

|(cid:15)| = 0. We model a sensor attack as a ﬁnite state transducer A = (Y, Σ, ∆n, η, θ, y0, Ym),

where Y is the state set, Σ the input alphabet, ∆n the output alphabets, y0 the initial state,

Ym the marker state set, which is speciﬁcally set as Ym = Y , and η : Y × Σ × ∆n → Y the

(partial) transition map, where for all σ ∈ Σuo and y ∈ Y , η(y, σ, (cid:15)) = y, i.e., at each state y all

unobservable events are self-looped with (cid:15) as the output. This is natural because an attacker can

only observe observable events, thus, will not make any move upon unobservable events. We

still keep unobservable events here to make it easy for us for subsequent technical development.

Clearly, L(A) = Lm(A) ⊆ (Σ × ∆n)∗. Let ψ : (Σ × ∆n)∗ → Σ∗ and θ : (Σ × ∆n)∗ → ∆∗
n be the
input and output maps, respectively, where for each µ = (σ1, u1)(σ2, u2) · · · (σl, ul) ∈ (Σ×∆n)∗,

ψ(µ) = σ1σ2 · · · σl and θ(s) = u1u2 · · · ul.

The basic procedure of an attack is to intercept every single observable event σ ∈ Σo generated

by the plant G, replace it with some observable string u ∈ ∆n, and send u to the supervisor

S, in order to trick S to issue a control command γ ∈ Γ that may drive the plant G towards

a bad marker state. This attack procedure is depicted in Figure 1. The sequential composition

of the attack A and the supervisor S essentially forms a new supervisor, denoted as A ◦ S,

which receives an observable output σ ∈ Σo and generates a control command γ ∈ Γ. The exact

deﬁnition of this new supervisor reveals the nature of the attack, which is given below. The

sequential composition of A and S is a deterministic ﬁnite state transducer A ◦ S = (Y × Z ∪

{d}, Σ × ∆n, ζ, (y0, z0), Ym × Zm), where d denotes the deadlocking dump state, and for each
(y, z), (y(cid:48), z(cid:48)) ∈ Y × Z, (σ, u) ∈ Σ × ∆n, ζ(y, z, σ, u) = (y(cid:48), z(cid:48)) if one of the following holds,

September 13, 2018

DRAFT

7

Fig. 1. The block diagram of an attack plan

• σ ∈ Σuo ∧ u = (cid:15) ∧ η(y, σ, (cid:15)) = y(cid:48) ∧ δ(z, σ) = z(cid:48),
• σ ∈ Σo ∧ η(y, σ, u) = y(cid:48) ∧ δ(z, u) = z(cid:48).

For each (y, z) ∈ Y × Z, (σ, u) ∈ Σ × ∆n, ζ(y, z, σ, u) = d if η(y, σ, u)! but δ(z, u) is undeﬁned.

Thus, all transitions that go to the dumpt state d may potentially reveal the attack, which, for

an intelligent attack, should be avoided.

The impact of A on the closed-loop system (G, S) is captured by the composition of the plant

G and the new supervisor A ◦ S, i.e.,

G × (A ◦ S) = (X × (Y × Z ∪ {d}), Σ × ∆n, κ = ξ × ζ, (x0, y0, z0), Xm × Y × Z),

where for each (x, w), (x(cid:48), w(cid:48)) ∈ X × (Y × Z ∪ {d}), (σ, u) ∈ Σ × ∆n, (x(cid:48), w(cid:48)) ∈ κ(x, w, σ, u) if
x(cid:48) = ξ(x, σ) and w(cid:48) = ζ(w, σ, u). Clearly, G × (A ◦ S) is also a transducer, and it is not difﬁcult

to check that

G × (A ◦ S) = G × (Preﬁx(G × (A ◦ S)) ◦ S),

where “=” is in the sense of DES-isomorphism, and Preﬁx(·) denotes a function mapping one

transducer to another transducer by simply marking every state. In other words, if A is an attack
model for the system (G, S), then ˆA := Preﬁx(G × (A ◦ S)) is also an attack model, which has
the same attack effect as that of A on (G, S). Since ψ(L( ˆA)) ⊆ L(G), we call ˆA a canonical

September 13, 2018

DRAFT

8

attack with respect to (G, S). Since for any attack, there exists a canonical attack, which has the

same attack effect, from now on we only focus on canonical attacks. On the other hand, we will
see that A usually is stucturally simpler than its canonical one ˆA, whereas the latter is easier to

compute. An interesting question is how to synthesize a simpliﬁed attack model A from a given
canonical attack model ˆA, which bears some similarity to the problem of supervisor reduction

[8], and will be addressed in our future works.

To illustrate the aforementioned concepts, let us go through a simple single-tank example

depicted in Figure 2, which consists of one water supply source whose supply rate is qi, one

Fig. 2. A single tank system

tank, and one control valve at the bottom of the tank controlling the outgoing ﬂow rate qo,

whose value depends on the valve opening and the water level h. We assume that the valve can

only be fully open or fully closed to simplify our illustration, and in case of a full opening, the

water level h can only go down. The water level h can be measured, whose value can trigger

some predeﬁned events, denoting the water levels: low (h=L), medium (h=M), high (h=H), and

extremely high (h=EH). We construct a simple discrete-event model of the system depicted in

Figure 3, where the alphabet Σ contains all events shown in the ﬁgure. All events are observable,

i.e., Σo = Σ. Only the actions of opening the valve (qo = 1) and closing the valve (qo = 0)

are controllable, and all water level events are uncontrollable. In the model we use a shaded

oval to denote a marker state, i.e., state 5 and state 9 in Figure 3. Assume that we do not want

September 13, 2018

DRAFT

9

Fig. 3. Automaton model of the plant G

the water level to be extremely high, i.e., the event h=EH should not occur. Thus, state 9 is

a bad marker state, i.e., Xd,m = {5} and Xb,m = {9}. To prevent state 9 from being reached,

we compose a requirement E shown in Figure 4, whose alphabet is {h=L, h=M, h=H, h=EH},

but the event h=EH is never allowed in the model. A supervisor S can be synthesized by using

the standard Ramadge-Wonham supervisory control paradigm, which is also depicted in Figure

4. It is clear that the supervisor S only opens the valve when the water level is high, i.e., it

Fig. 4. Automaton models of a requirement E (Left) and the supervisor S (Right)

disables the event qo = 0 at state 6 when the event h=H occurs. Our intuition tells us that

September 13, 2018

DRAFT

if an attack always change events of h=M, h=H, h=EH to the event h=L, then the supervisor

will not prevent the water level from reaching the extreme high level, i.e., the event h=EH

will happen. For this reason, we conjecture an attack model A shown in Figure 5, where water

levels will be altered to h=L, whereas all other events will remain unchanged. The sequential

10

Fig. 5. Automaton models of an attack A (Left) and the sequential composition A ◦ S (Right)

composition A ◦ S indicates that, no matter which water level is reached, the attack A always

sends h=L to the supervisor S, which tricks it to believe that it is safe to allow the valve to be

either closed or opened. The impact of A on the closed-loop system (G, S) is depicted in Figure

6. By marking every state in G×(A◦S) we obtain a canonical attack model Preﬁx(G×(A◦S)).

Proposition 1: (1) θ(Lm(A◦S)) ⊆ Lm(S); (2) Lm(A◦S) ⊆ Lm(A); (3) ψ(Lm(G×(A◦S))) =
(cid:3)

ψ(Lm(A ◦ S)) ∩ Lm(G), ψ(L(G × (A ◦ S))) = ψ(L(A ◦ S)) ∩ L(G).

Proof: By the above deﬁnition of sequential composition, the proposition follows.

(cid:4)

Proposition 2: Given two attacks A1 and A2 with the same input alphabet Σ and output
(cid:3)

alphabet ∆n, assume that L(A1) ⊆ L(A2). Then we have L(A1 ◦ S) ⊆ L(A2 ◦ S).

September 13, 2018

DRAFT

11

Fig. 6. Automaton models of G × (A ◦ S)

Proof: By the above deﬁnition of sequential composition, the proposition follows.

(cid:4)

Given two attacks A1 and A2 with the same input alphabet Σ and output alphabet ∆n, let

A1 ∪ A2 be their union, which is a deterministic ﬁnite-state transducers. Then by the deﬁnition

of transducer union, we have L(A1 ∪ A2) = L(A1) ∪ L(A2).

Proposition 3: L((A1 ∪ A2) ◦ S) = L(A1 ◦ S) ∪ L(A2 ◦ S).

(cid:3)

Proof: Since L(A1) ⊆ L(A1 ∪ A2) and L(A2) ⊆ L(A1 ∪ A2), by Prop. 2 we have L((A1 ∪ A2) ◦

S) ⊇ L(A1◦S)∪L(A2◦S). To show the other direction, for each string µ = (σ1, u1) · · · (σn, un) ∈

L((A1 ∪ A2) ◦ S), by the deﬁnition of the sequential composition, we know that µ ∈ L(A1 ∪ A2).

Thus, either µ ∈ L(A1) or µ ∈ L(A2), which means either µ ∈ L(A1 ◦ S) or µ ∈ L(A2 ◦ S).
(cid:4)

Thus, µ ∈ L(A1 ◦ S) ∪ L(A2 ◦ S), which concludes the proof.

So far we have introduced a simple sensor attack model, and explained how this attack affects

the closed-loop system. But we have not described what kind of sensor attacks can be considered

intelligent. Next, we will introduce the concept of ABSRA.

C. An ABSRA model

Let Po : Σ∗ → Σ∗

o be the natural projection. An intelligent canonical attack needs to possess

the following properties:

September 13, 2018

DRAFT

1) Its insertions must be covert to the given supervisor, i.e.,

θ(L(A)) ⊆ L(S),

12

(1)

namely the supervisor will not see any unexpected observable sequences from the attack.

2) Any of its insertion sequence may potentally cause damages to G, i.e.,

ψ(L(G × (A ◦ S))) = ψ(L(A ◦ S)) ∩ {s ∈ Lm(G)|ξ(x0, s) ∈ Xb,m},

(2)

namely any sequence of insertions by the attack will cause G to reach some bad state

eventually. A weaker version of this property is described below:

ψ(L(G × (A ◦ S))) ∩ {s ∈ Lm(G)|ξ(x0, s) ∈ Xb,m} (cid:54)= ∅,

which says that the attack A will tamper the absolute correctness of the supervisor S so

that there exists some possibility that the system may reach some bad marker state.

3) A ◦ S forms a standard supervisor for the plant G that enforces normality [2], i.e.,

P −1

o (Po(ψ(L(G × (A ◦ S))))) ∩ L(G) = ψ(L(G × (A ◦ S))),

(3)

and

(∀µ ∈ L(G × (A ◦ S))) ψ(EnG×(A0◦S)(κ(x0, y0, z0, µ))) = EnS(δ(z0, θ(µ)),

(4)

which denotes that at each state the attack will not intervene the event enablement by the

supervisor because we consider only sensor attacks, not actuator attacks.

We call a nonempty model A satisfying the aforementioned four properties (1)-(4) an Attack

with Bounded Sensor Reading Alterations (ABSRA) of (G, S).

It is not difﬁcult to check that the attack A shown in Figure 5 does not satisfy Property (1)

because S cannot ﬁre qo = 0 before h=L, but A can. Nevertheless, the sequential composition

A ◦ S satisﬁes all three properties, thus, is an ABSRA. By the aforementioned discussions, we

know that the canonical attack model Preﬁx(G × (A ◦ S)) is also an ABSRA.

Theorem 1: Given a plant G and a legal supervisor S, let {Ai|i ∈ I} be a (possibly inﬁnite)
(cid:3)

collection of ABSRA’s with respect to (G, S). Then ∪i∈IAi satisﬁes properties (1)-(4).

September 13, 2018

DRAFT

Proof: By Prop. 3, we know that L((∪i∈IAi) ◦ S) = ∪i∈IL(Ai ◦ S). We now verify that ∪i∈IAi

13

satisﬁes all four properties.

(a) Since for each i ∈ I, Ai is an ABSRA, we have that

Thus, by Prop. 3 we have that

θ(L(Ai)) ⊆ L(S).

θ(L(∪i∈IAi)) ⊆ L(S).

(b) In addition, we have that for each i ∈ I,

ψ(L(G × (Ai ◦ S))) = ψ(L(Ai ◦ S)) ∩ {s ∈ Lm(G)|ξ(x0, s) ∈ Xb,m}.

Thus, by Prop. 3 we have

ψ(L(G × ((∪i∈IAi) ◦ S))) = ψ(L((∪i∈IAi) ◦ S)) ∩ {s ∈ Lm(G)|ξ(x0, s) ∈ Xb,m}.

(c) Since for each i ∈ I, we have

P −1

o (Po(ψ(L(G × (Ai ◦ S))))) ∩ L(G) = ψ(L(G × (Ai ◦ S))),

we get

P −1

o (Po(ψ(L(G × ((∪i∈IA) ◦ S))))) ∩ L(G) = ψ(L(G × ((∪i∈IAi) ◦ S))).

The last property (4) can be easily checked. Thus, ∪i∈IAi satisﬁes all four properties, and the
(cid:4)

theorem follows.

Theorem 1 only implies that the least restrictive (or supremal) attack language exists. But it

is not clear whether this supremal language is regular, i.e., whether it can be recognized by a

ﬁnite-state transducer. Therefore, at this moment the existance of the supremal ABSRA is still

unknown. We now state our main problem in this paper.

Problem 1: Given a plant G and a legal supervisor S, design an ABSRA A.

(cid:3)

In the next section we will show that the supremal attack language is regular, i.e., indeed the

supremal ABSRA exists, and is computable.

September 13, 2018

DRAFT

14

III. SYNTHESIS OF AN ABSRA

We ﬁrst recall the concepts of controllability [4], and normality [2]. Because we deal with

both ﬁnite-state automata and ﬁnite-state transducers, to make notations simple, we introduce a

general purpose alphabet Λ, which can be either Λ = Σ or Λ = Σ × ∆n, depending on a speciﬁc

application context. Let Λuc ⊆ Λ and Λo ⊆ Λ be an uncontrollable alphabet and an observable
alphabet respectively, where if Λ = Σ × ∆n then Λo := Σo × ∆n. Let ˆPo : Λ∗ → Λ∗
o be the
natural projection. In case that Λ = Σ × ∆n, we have ˆPo((cid:15)) = (cid:15), ˆPo(σ, u) = (σ, u) if σ ∈ Σo,
or (cid:15) otherwise, and ˆPo(µ(σ, u)) = ˆPo(µ) ˆPo(σ, u). When we mention a ﬁnite-state transitional
structure G, we mean that G is either a ﬁnite-state automaton or a ﬁnite-state transducer.

Deﬁnition 1: Given a ﬁnite-state transitional structure G, a sublanguage K ⊆ Lm(G) is
(cid:3)

controllable w.r.t. G and Λuc, if KΛuc ∩ L(G) ⊆ K.

Deﬁnition 2: Given a ﬁnite-state transitional structure G, a sublanguage K ⊆ Lm(G) is normal
(cid:3)

w.r.t. G and Λo, if ˆP −1

o ( ˆPo(K)) ∩ L(G) = K.

Given a ﬁnite-state transitional structure G, whose alphabet is Λ, and a requirement E ⊆ Λ∗,

let

CN (G, E) := {K ⊆ Lm(G)∩E|K is controllable w.r.t. G and Λuc ∧ K is normal w.r.t. G and Λo}.

By an argument similar to the one used in [4], we can derive that the supremal controllable and

normal sublanguage of Lm(G) exists, denoted as supCN (G, E), such that for all K ∈ CN (G, E),

we have K ⊆ supCN (G, E) ∈ CN (G, E).

In our setup, an attack is able to arbitrarily alter an observable event. Thus, each event

(σ, u) ∈ Σ × ∆n is considered controllable, as the attack can choose not to use this alteration.

Under this consideration, the uncontrollable alphabet Λuc is actually empty. Thus, in the following

attack model synthesis, we do not explicitly require controllability. This may sound a bit unusual

because we do have an uncontrollable alphabet Σuc for the plant G - how those uncontrollable

events affect the attack model synthesis? If we carefully check the properties of an ABSRA, we

can see that Property (4) actually implicitly enforces controllability with respect to Σuc because

September 13, 2018

DRAFT

it requires the attack not to change the event enablement of the supervisor S at the current state,

and since by default the supervisor S ensures controllability with respect to Σuc, and so does

the attack model.

15

Assume that there exists Σo,p ⊆ Σo, which denotes a set of protected observable events that

cannot be altered by an ABSRA, i.e., given an attack model A = (Y, Σ, ∆n, η, θ, y0, Ym), for all

y ∈ Y , (σ, u) ∈ Σo,p × ∆n, we have that η(y, σ, u)! ⇒ u = σ. We now undertake the following

ABSRA synthesis procedure.

Procedure 1: (ABSRA Synthesis )

1) Input: a plant G = (X, Σ, ξ, x0, Xm), a supervisor S = (Z, Σ, δ, z0, Z) and Σo,p.

2) Construct a single-state transducer A0 = (Y, Σ, ∆n, η, θ, y0, Y ), where Y = {y0} and the

transition map η encodes transitions labeled by a subset of (Σo \ Σo,p) × ∆n ∪ Σu,p × Σu,p ∪

Σuo × {(cid:15)}, denoting all observable event alterations that the attack wants to consider.

3) Let E0 := {µ ∈ Lm(G × (A0 ◦ S))|ξ(x0, ψ(µ)) ∈ Xb,m} be a requirement.

4) Undertake the following iteration on k = 1, · · ·

a) Compute Kk := supCN (G × (A0 ◦ S), Ek−1).

b) Check property (4) in the deﬁnition of ABSRA. If it holds, then go to Step 5).

Otherwise, set Ek := {µ ∈ Kk|ψ(EnG×(A0◦S)(κ(x0, y0, z0, µ))) = EnS(δ(z0, θ(µ)))}

and continue the iteration on k.

5) Output: A∗, which recognizes Kk+1.

Lemma 1: Procedure 1 terminates ﬁnitely.

(cid:3)

(cid:3)

Proof: Assume that E0 is recognized by a transducer R0, whose state set is W0. Then K1 is

recognizable by a transducer, say R1, whose state set is a subset of X × Y × Z × W0. It is not
difﬁcult to check that for all µ, µ(cid:48) ∈ K1, if they hit the same state in R1, then we know that

ψ(EnG×(A0◦S)(κ(x0, y0, z0, µ))) = EnS(δ(z0, θ(µ)))

if and only if

ψ(EnG×(A0◦S)(κ(x0, y0, z0, µ(cid:48)))) = EnS(δ(z0, θ(µ(cid:48)))).

In other words, µ ∈ E1 if and only if µ(cid:48) ∈ E1. Thus, for each state in R1, either all strings hitting
that state are in E1 or none of them are in E1, namely E1 is recognized by a sub-transducer ˆR1

September 13, 2018

DRAFT

16

of R1. Suppose the state set of ˆR1 is W1 ⊆ X × Y × Z × W0. By the property of automaton
composition, we know that there exists a transducer R2 recognizing K2 such that the state set

of R2 is a subset of X × Y × Z × W1. Since W1 ⊆ X × Y × Z × W0, we know that R2 is

DES-isomorphic to a sub-transducer of R1. By using the same argument, we can check that

each Kk is recognized by a transducer, which is DES-isomorphic to a sub-transducer of R1. In

addition, the state sets of those sub-transducers form a monotonic non-increasing sequence with

respect to set inclusion. Thus, in a ﬁnite number of iterations, a ﬁxed sub-transducer will be

reached, whose language is Kk. This means Procedure 1 must terminate ﬁnitely.

(cid:4)

Lemma 2: Let Kk and A∗ be computed in Procedure 1. Then Kk := supCN (G × (A∗ ◦
(cid:3)

S), Ek−1) = Lm(G × (A∗ ◦ S)).

Proof: By the proof of Lemma 1 we know that A∗ is DES-isomorphic to the preﬁx closure of

a sub-transducer of G × (A0 ◦ S) × R0. Then by the deﬁnitions of sequential composition and
(cid:4)

transducer product, the lemma follows.

Theorem 2: A∗ obtained in Procedure 1 is the supremal ABSRA of (G, S).

(cid:3)

Proof: (a) We ﬁrst show that A∗ is an ABSRA, i.e., A∗ satisﬁes properties (1)-(4). It is clear that

when the algorithm terminates, property (4) must hold. So we only focus on properties (1)-(3).

By the deﬁnition of A∗ and Prop. 1, we know that

θ(L(A∗)) = θ(supCN (G × (A∗ ◦ S), Ek−1)) ⊆ L(S).

By Lemma 2, we have Kk = Lm(G × (A∗ ◦ S)). Since Kk ⊆ Ek−1 and ψ(Ek−1) ⊆ {s ∈

Lm(G)|ξ(x0, s) ∈ Xb,m}, by Prop. 1 we have

ψ(Kk) = ψ(Lm(A∗ ◦ S)) ∩ Lm(G) = ψ(L(A∗ ◦ S)) ∩ {s ∈ Lm(G)|ξ(x0, s) ∈ Xb,m}.

For the third property, by Lemma 2 we know that Kk := supCN (G × (A∗ ◦ S), Ek−1). Thus,

by the deﬁnition of normality and the nonblocking property associated with a sub-transducer of

G × (A0 ◦ S) × R0, which recognizes Kk, we have

P −1

o (Po(ψ(L(G × (A∗ ◦ S))))) ∩ L(G) = ψ(L(G × (A∗ ◦ S))).

This concludes our proof that A∗ is an ABSRA.
(b) Next, we show that A∗ is the supremal ABSRA. Let ˆA be an ABSRA of the system.

September 13, 2018

DRAFT

17

Clearly, L( ˆA) ⊆ L(A0). Due to the controllability of S and the assumption that ˆA is an
ABSRA, i.e., it must satisfy property (4), it is easy to check that Lm(G × ( ˆA ◦ S)) is con-
trollable w.r.t. Lm(G × (A0 ◦ S)) and Σuc. Since ˆA must satisfy Property (3), we know that
Lm(G × ( ˆA ◦ S)) must be normal w.r.t. Lm(G × (A0 ◦ S)) and Σo. In addition, ˆA satisﬁes
property (4). Thus, we can easily detive that Lm(G × ( ˆA ◦ S)) ∈ CN (G × (A0 ◦ S), Ek−1),
namely, Lm(G × ( ˆA ◦ S)) ⊆ Kk = supCN (G × (A0 ◦ S), Ek−1). This means L( ˆA) ⊆ L(A∗),
(cid:4)

which concludes the proof of the theorem.

As an illustration, we apply Procedure 1 to the plant G shown in Figure 3 and the supervisor

S shown in Figure 4. We can see that the sensor attack model A in Figure 5 is actually A0 in

Procedure 1 because all events in the model are observable. The composition A0 ◦ S = A ◦ S

is shown in Figure 5. The outcome of G × (A0 ◦ S) is shown in Figure 6, which is isomorphic

to G. This is not surprising because any string in L(G) may be potentially extended to the bad

marker state. The requirement E is simply the same as G × (A0 ◦ S). Clearly, we know that Kk

is recognizable by a transducer shown in Figure 7, which is almost the same as G × (A0 ◦ S),

except that the only marker state is that bad marker state due to the requirement E. Since all

Fig. 7. A transducer recognizing K∗

events are observable, from ˆPo(L(A∗)) = ˆPo(K∗) we can derive that L(A∗) = K∗. Thus, A∗
can be chosen by marking every state in G × (A0 ◦ S), i.e., A∗ = Preﬁx(G × (A0 ◦ S)), which

means A∗ is actually a canonical attack of A0 with respect to (G, S). By Theorem 2 we know

that A∗ is the supremal ABSRA of (G, S).

September 13, 2018

DRAFT

IV. SYNTHESIS OF AN ABSRA-ROBUST SUPERVISOR

In the previous section we discuss how to design an ABSRA model to interrupt a given

system’s operations from an attacker’s point of view. In this section we present a synthesis

approach to design a supervisor, which is “robust” to any ABSRA in the sense that either the

attack is not covert or incurs no damage to the system.

18

Recall that an ABSRA affects a target system (G, S) by altering the sequence of observable

events, which tricks S to issue commands improperly. By protecting observable events from

being altered unnoticeably can in principle effectively deter an ABSRA. An observable event

in this framework denotes a speciﬁc set of strongly associated measurements. For example, in

the aforementioned single-tank system, the event h=H may either be associated with one simple

water level measurement or possibly several sensor measurements such as the actual water level,

and the corresponding pressure on the bottom of the tank - the more sensor measurements

associated with the event, the harder for an attack to alter the event without being detected.

When applying suitable encryption techniques, it is even more complicated for an attack to

complete the job. Thus, it is indeed technically feasible to prevent observable events from being

altered by either adopting new secure information transmission technologies or introducing more

sensors to signiﬁcantly increase the complication of altering the corresponding observable event

without being detected. Nevertheless, there is always a ﬁnancial consideration. An attractive

solution to a potential industrial user is to identify only critical observable events, which, when

being protected from external alterations, will lead to a supervisor robust to any ABSRA.

Problem 2: Given a plant G, a requirement E, and a protected observable alphabet Σo,p ⊆ Σo,
synthesize a supervisor S such that there is no ARSRA of the closed-loop system (G, S). (cid:3)

With the same notations used in the previous section, let CN (G, E) be the collection of

all controllable and normal supervisors [10]. Let S0 = supCN (G, E), which always exists and

computable, as long as E ⊆ Σ∗ is regular. Our goal is to design a supervisor S ∈ CN (G, E) such

that Procedure 1 returns an ampty ABSRA A∗ with respect to the given protected observable

alphabet Σo,p. To this end, we present the following synthesis procedure:

September 13, 2018

DRAFT

19

Procedure 2: (ABSRA-Robust Supervisor Synthesis)

1) Input: a plant G, a requirement E and a protected observable alphabet Σo,p.
2) Compute ˆK = supCN (G, E). If ˆK = ∅, terminate. Otherwise, assume ˆK is recognized

by a ﬁnite-state automaton ˆS, and continue.

3) Compute A∗ by using Procedure 1, i.e., computer Kk = supCN (G × (A0 ◦ ˆS), Ek).
4) Compute K := supCN (G, L( ˆS) − θ(Kk)).
5) Output: a recognizer S of K.

(cid:3)

Theorem 3: Given a plant G, a requirement E ⊆ Σ∗, and a protected observable alphabet
Σo,p, let S be computed above. If Lm(S) (cid:54)= ∅, then we have supCN (G × (A0 ◦ S), Ek) = ∅,
(cid:3)
where Ek is deﬁned in Procedure 1, i.e., there is no ABSRA A of (G, S).
Proof: Assume that it is not true. Then there exists an ABSRA A such that L(A) = ˜Kk, where
˜Kk = supCN (G × (A0 ◦ S), Ek) (cid:54)= ∅. Since S is controllable and normal with respect to G, and
L(S) ⊆ L( ˆS), we can get that ˜K ∈ CN (G×(A0 ◦ ˆS), Ek). Since Kk = supCN (G×(A0 ◦ ˆS), Ek),
we know that ˜K ⊆ Kk. But on the other hand, we know that θ( ˜K) ⊆ K ⊆ L(S) − θ(Kk), i.e.,
˜K (cid:42) Kk, which leads to a contradiction. Thus, the ABSRA A does not exist.
(cid:4)

We would like to emphasize here again that, although Theorem 3 indicates that there is no
ABSRA A for the closed-loop system (G, ˆS), it does not mean that a sensor reading alteration

attack will not be carried out by an attacker. But such an attack will either reveal itself to the

supervisor before it achieves its attack goal due to abnormal system executions (so that proper

contingent actions such as system shutdown can be taken by the supervisor, which is outside

the scope of this paper) or will not be able to lead the system to a bad state.

In Theorem 3, if K = ∅, then with the given protected observable alphabet Σo,p, there does

not exist a supervisor S that is ABSRA-robust. We face the following synthesis problem.

Problem 3: Given a plant G and a requirement E, compute a protected observable alphabet
Σo,p ⊆ Σo of the minimum size, which allows a nonempty ABSRA-robust supervisor S to exist.(cid:3)

It is clear that Problem 3 is solvable in the sense that it is decidable whether there exists

September 13, 2018

DRAFT

20

such a Σo,p with the minimum size because we can simply enumerate each subset Σo,p ⊆ Σo,

and apply Procedure 2 on Σo,p to compute the corresponding supervisor S. Since there is a

ﬁnite number of such subsets, this brutal-force method will terminate, and provide a protected

observable alphabet of the minimum size together with the corresponding supervisor, if it exists.

The computational complexity of this procedure is certainly high, which is exponential to |Σo|,

but polynomial to the sizes of G and E due to our adoption of normality to handle observability.

If the size of Σo is big, to ﬁnd a computationally viable algorithm that can solve Problem 3

becomes important, which will be addressed in our future works.

We now use that simple single-tank system to illustrate how to use Procedure 2 to compute

an ABSRA-robust supervisor, and how to determine a minimum protected observable alphabet,

which allows the existence of an ABSRA-robust supervisor. Let Σo,p = {h=H}. The model of
A0 and ˆS are shown in Figure 8. When we run Procedure 1, we ﬁrst compute G × (A0 ◦ ˆS). The

Fig. 8. Models of A0 and ˆS

outcome is depicted in Figure 9. We can see that G×(A0◦ ˆS) contains no bad marker state in Xb,m.
Thus, in Procedure 1 we have E0 = ∅, which returns K1 = supCN (Lm(G × (A0 ◦ ˆS)), E0) = ∅.
After that, in Step 4) of Procedure 2, we have that K = supCN (Lm(G), Lm( ˆS)) = Lm( ˆS).
Thus, ˆS is an ABSRA-robust supervisor for G with respect to the given Σo,p. Clearly, it is a

solution to Problem 3 because we cannot ﬁnd any other protected observable alphabet with a

size smaller than 1, which can render an ABSRA-robust supervisor.

September 13, 2018

DRAFT

21

Fig. 9. Models of A0 ◦ ˆS (Right) and G × (A0 ◦ ˆS) (Left)

V. CONCLUSIONS

In this paper we have ﬁrst introduced the concept of ABSRA, upon which we have shown that

the supremal ABSRA exists and computable, as long as the plant model G and the supervisor

S are ﬁnitely representable, i.e., their languages are regular. After that, we have brought in the

problem of synthesizing an ABSRA-robust supervisor, and shows that it is possible to ﬁnd a

minimum protected observable sub-alphabet, which may render an ABSRA-robust supervisor.

It is interesting to point out that, if we replace the third property of an ABSRA model with a

weaker observability property, e.g., the standard observability [2], the supremal ABSRA may not

exist any more. Nevertheless, the existence of an ABSRA is still decidable and computable (with

possibly a higher computational complexity), as this ABSRA synthesis problem is equivalent to

a synthesis problem of centralized supervisory control under partial observation, which has been

shown solvable [9]. Fortunately, the normality property can be easily satisﬁed in reality, as it

only requires that only observable and controllable events can be disabled in online applications

- in real industrial applications, it is typical that all control commands are observable. For this

reason, the supervisor synthesis approach proposed in this paper aiming to defy ABSRA is

practically feasible.

September 13, 2018

DRAFT

22

Acknowledgement

The idea of this paper was originated from a discussion between the author and Prof Stephane

Lafortune on opacity enforcement. Without such an inspiring discussion, this paper would never

be formed. For this reason, the author would like to thank Prof Lafortune for his contribution.

REFERENCES

[1] C. Cassandra and S. Lafortune. Introduction to Discrete Event Systems (2nd Ed.), Springer, 2008.

[2] F. Lin and W. M. Wonham. On observability of discrete-event systems. Information Sciences, 44(3):173-198, 1988.

[3] C. H. Papadimitriou. Computational Complexity. Addison Wesley, 1994.

[4] P.J. Ramadge and W.M. Wonham. Supervisory control of a class of discrete event systems. SIAM J. Control and

Optimization, 25(1):206–230, 1987.

[5] R. Su. Discrete-event modeling of multi-agent systems with broadcasting-based parallel composition. Automatica,

49(11):3502-3506, 2013.

[6] R. Su, J.H. van Schuppen and J.E. Rooda. Aggregative synthesis of distributed supervisors based on automaton abstraction.

IEEE Trans. Automatic Control, 55(7):1627-1640, 2010.

[7] R. Su, J.H. van Schuppen, J.E. Rooda. Maximally permissive coordinated distributed supervisory control of nondeterministic

discrete-event systems. Automatica, 48(7):1237-1247, 2012.

[8] R. Su, W. M. Wonham. Supervisor reduction for discrete-event systems. Journal of Discrete Event Dynamic Systems,

14(1):31-53, 2004.

[9] T.S. Yoo and S. Lafortune. Solvability of centralized supervisory control under partial observation.. Discrete Event Dynamic

Systems: Theory and Applications, 16(4):527–553, 2006.

[10] W. M. Wonham. Supervisory Control of Discrete-Event Systems. Systems Control Group, Dept. of ECE, University of

Toronto. URL: www.control.utoronto.ca/DES, 2014.

[11] W.M. Wonham and P.J. Ramadge. On the supremal controllable sublanguage of a given language. SIAM J. Control and

Optimization, 25(3):637–659, 1987.

[12] A. A. Cardenas, S. Amin, and S. Sastry. Secure control: towards survivable cyber-physical systems. In Proc. 28th

International Conference on Distributed Computing Systems Workshops, 2008, pp. 495500.

[13] A. Teixeira, D. Perez, H. Sandberg, and K. H. Johansson. Attack models and scenarios for networked control systems. In

Proc. 1st International Conference on High Conﬁdence Networked Systems, 2012, pp. 5564.

[14] Y. C. Wu and S. Lafortune. Synthesis of insertion functions for enforcement of opacity security properties. Automatica,

50(5):1336-1348, 2014.

[15] A. Paoli, M. Sartini and S. Lafortune. Active fault tolerant control of discrete event systems using online diagnostics.

Automatica, 47(4):639 649, 2011.

[16] D. Thorsley and D. Teneketzis. Intrusion detection in controlled discrete event systems. In Proc. 45th IEEE Conference

on Decision and Control, 2006, pp. 60476054.

[17] L. K. Carvalho, Y. Wu, R. Kwong and S. Lafortune. Detection and prevention of actuator enablement attacks in supervisory

control systems. In Proc. 13th International Workshop on Discrete Event Systems, 2016, pp. 298305.

September 13, 2018

DRAFT

