DualNet: Locate Then Detect Effective Payload
with Deep Attention Network

Shiyi Yang∗, Peilun Wu† and Hui Guo‡
School of Computer Science and Engineering, University of New South Wales, Sydney∗†‡
Innovation Institute, Sangfor Technologies Inc.†
Email: ∗z5223292@cse.unsw.edu.au, †wupeilun@sangfor.com.cn, ‡h.guo@unsw.edu.au

0
2
0
2

t
c
O
3
2

]

R
C
.
s
c
[

1
v
1
7
1
2
1
.
0
1
0
2
:
v
i
X
r
a

Abstract—Network intrusion detection (NID) is an essential
defense strategy that is used to discover the trace of suspicious
user behaviour in large-scale cyberspace, and machine learning
(ML), due to its capability of automation and intelligence, has
been gradually adopted as a mainstream hunting method in
recent years. However, traditional ML based network intrusion
detection systems (NIDSs) are not effective to recognize unknown
threats and their high detection rate often comes with the cost of
high false alarms, which leads to the problem of alarm fatigue.
To address the above problems, in this paper, we propose a
novel neural network based detection system, DualNet, which
is constructed with a general feature extraction stage and a
crucial feature learning stage. DualNet can rapidly reuse the
spatial-temporal features in accordance with their importance
to facilitate the entire learning process and simultaneously
mitigate several optimization problems occurred in deep learning
(DL). We evaluate the DualNet on two benchmark cyber attack
datasets, NSL-KDD and UNSW-NB15. Our experiment shows
that DualNet outperforms classical ML based NIDSs and is more
effective than existing DL methods for NID in terms of accuracy,
detection rate and false alarm rate.

Index Terms—Deep Learning, Neural Network, Attention

Mechanism, Machine Learning, Network Intrusion Detection.

I. INTRODUCTION

With the ever-growing of network scale and complexity,
cyber attacks are becoming more and more frequent, volatile
and sophisticated, which imposes great threats to the massive
networked society. The conﬁdential information of the network
users can be leaked; The integrity of data transferred over the
network can be tampered; And the computing infrastructures
connected to the network can be attacked. Therefore, network
intrusion detection system (NIDS) plays a pivotal role in
offering the modern society a secure and reliable network
communication environment.

Signature-based intrusion detection system (SIDS), due to
its stability and dependability, is by far a typical type of NIDS
that has been widely adopted in the commercial products.
SIDS relies on predeﬁned attack signatures or patterns and
can only detect known threats. By comparison, anomaly-based
intrusion detection system (AIDS) exploits the capability of
machine learning (ML) and uses the machine-learned rules
and heuristics to identify deviations from normal network
activities, making it possible for novel attacks to be detected.
However, ML-based NIDSs often achieve a high attack de-
tection rate at the expense of many false alarms, which may

cause the security team unnecessarily waste time on the fake
threats and delay the responses to actual attacks.

Unlike many traditional ML algorithms that often require
hand-designed features, DL can achieve much better gener-
alization performance by self-learning its raw representations
from the original dataset, which can potentially offer higher
accuracy for network intrusion detection (NID). Though the
existing DL methods do show such an advantage over the
traditional ML approaches, the DL-based NIDS designs are
not mature yet. The attack detection ability in the existing
designs still need to be improved, and the false alarms are
still not ignorable.

In this paper, we address these issues and propose a novel
DL model, DualNet, for NID. DualNet can achieve a high
learning accuracy and a high detection rate while keeping the
false alarm rate and computational cost as low as possible.
Our main contributions are summarized as follows:

• We introduce a novel neural network architecture, Dual-
Net, that consists of two asynchronous stages: 1) a gen-
eral feature extraction stage to maximally capture spatial
and temporal features, and 2) a crucial feature learning
stage to improve the detection efﬁciency by targeting
important features for the ﬁnal learning outcome.

• We leverage a special

learning method, densely con-
nected learning, our work demonstrates that it exhibits
no performance degradation and optimization difﬁculties
in building deeper networks for NID.

• We leverage the self-attention mechanism to effectively
locate then detect the most valuable payloads from raw
network packets in accordance with their scores of im-
portance to improve the interpretability of DL for NID.
• We evaluate DualNet on two benchmark attack datasets,
and compare our model with a set of existing ML and
DL designs for NID. Our experiment results show that
DualNet outperforms those existing designs.

A brief background of ML and DL for NID is provided
in section II. The design of densely connected learning and
DualNet is presented in section III, and the evaluation of them
is detailed in section IV. The paper is concluded in section V.

II. BACKGROUND AND RELATED WORK

In recent years, artiﬁcial intelligence (AI) based intrusion
detection system has gained increasing popularity due to its
ability of recognizing novel threats. The related NIDS designs

 
 
 
 
 
 
can be divided into two categories: unsupervised learning
based [1] and supervised learning based [2].

Unsupervised learning builds a predictive proﬁle based only
on normal activities without
the need to know any prior
knowledge of attacks. Local Outlier Factor (LOF) [3] and K-
means [4] are the typical design examples. These designs can
reduce the cost required for data collection and corresponding
labeling. It has been shown that they achieve a good perfor-
mance in a controlled laboratory setting but are not so effective
in a real network communication environment [5].

Supervised learning, on the other hand, requires to learn
the labelled datasets that cover both normal and malicious
activities. The approach shows a great potential on practical
implementations [6] and has been implemented in many de-
signs: Some are based on classical machine learning (ML)
algorithms and some are based on advanced deep learning
(DL) methods. A brief review is given below.

A. Classical Machine Learning Methods

Among many classical ML methods [7], the kernel ma-
chines and ensemble classiﬁers are two effective strategies and
are frequently applied to network intrusion detection (NID).

Support Vector Machine (SVM) [8] is a typical example
of the kernel machine. It uses a kernel trick, such as radial
basis function (RBF), to implicitly map the inputs to a high-
dimensional feature space. However, SVM is not an ideal
choice for heavy network trafﬁc due to its high computation
cost and moderate performance [9].

Adaptive Boosting (AdaBoost) [10] and Random Forest
(RF) [11] are widely used ensemble classiﬁers. They incorpo-
rate multiple weak learners into a stronger learner to achieve
a high accuracy that would not be possible from individual
weak learners, and have powerful forces against overﬁtting.
However, AdaBoost is sensitive to outliers and noisy data, and
usually does not work well on imbalanced datasets. In contrast,
RF can effectively handle imbalanced data. But because of its
high computation complexity, it is slow in execution and not
suitable for real-time intrusion detection [9].

The traditional ML methods are often affected by so called
‘the curse of dimensionality’ [12], the common bottleneck
encountered during the design for performance optimization,
which greatly limits the effectiveness of ML in learning the
big data of increasing scale and complexity. Another weakness
of the ML based NIDS is that it often achieves high detection
rate with the cost of high false alarms.

B. Advanced Deep Learning Approaches

There are multiple DL approaches for network intrusion
detection (NID), such as multilayer perceptron (MLP), convo-
lutional neural networks (CNNs) and recurrent neural networks
(RNNs). The DL based NIDS has a compelling capability to
identify unknown attacks and has a high learning potential.

MLP [13] is an early kind of feed-forward artiﬁcial neural
network (ANN) with multiple layers and non-linear activa-
tions. It adopts backpropagation [14], a supervised learning
algorithm, for training.

CNNs [15] are normally applied to capture spatial features
from the learning dataset and produce feature maps as the
outputs through convolution calculation. For one-dimensional
security data, primitive CNN (ConvNet) [16] and depthwise
separable CNN (DSC) [17] are two effective detection meth-
ods in CNNs. Compared with ConvNet, DSC divides the
whole convolution process into two simpliﬁed steps: depth-
wise convolutions and point-wise convolutions, as such the
number of multiplications and the number of trainable param-
eters can be reduced.

RNNs [18] are mainly used to extract temporal features
from the network trafﬁc records. Vanilla RNN fails to learn
the long-term dependencies and suffers from the vanishing-
gradient problem. To address these problems, long short-term
memory (LSTM) [19] has been proposed. An advanced de-
sign, bidirectional LSTM (BiLSTM) [20], combines a forward
LSTM with a backward LSTM, and it offers a high learning
capability while at a considerable computational cost. Gated
recurrent unit (GRU) [21], on the other hand, is a simpliﬁed
LSTM with fewer number of gates and much lower trainable
parameters.

In this paper, we propose DL model DualNet, which
is a specially designed densely connected neural network
(DenseNet) along with a self-attention mechanism. The model
is presented in the next section. (The DenseNet was originally
used for image recognition, and it’s only for CNN, see [22];
The self-attention mechanism is mainly used for machine
translation, more in [23].)

III. DUALNET

Our goal is to build a deep learning (DL) model that has a
high detection capability (model quality) and is easy to train
(training efﬁciency), and the trained model is small in size
and fast in execution time (model cost).

We consider that the model quality is closely related to the
features extracted from the security data and how the extracted
features are effectively used for the ﬁnal prediction outcome.
To this end, we propose a two-stage deep neural network
architecture, DualNet: A general feature extraction stage to
maximally capture spatial-temporal features from the network
trafﬁc records; and a crucial feature learning stage to focus
more on important features to further improve the detection
efﬁciency.

In terms of training efﬁciency and model cost, they are
relevant to the number of trainable parameters, and a small
trainable parameter number is desired. We, therefore, take this
into account in our design.

An overview of our system is given in Fig. 1. The Dual-
Net mainly performs two stages for attack recognition. The
construction of two stages is elaborated in the next two sub
sections.

A. General Feature Extraction Stage

We consider that the multi-sourced security data have both
spatial and temporal correlations. Hence, we present a special
learning method, densely connected learning, which can

Fig. 1: System Overview

maximally learn spatial-temporal features at various levels of
abstraction from the input representations, and allow to build
deeper neural network without performance degradation and
optimization difﬁculties. The densely connected learning is to
establish an interleaved arrangement pattern between specially
designed blocks named dense blocks and particularly designed
blocks called transition blocks, where the number of dense
blocks is one more than the number of transition blocks, as
shown in Fig. 1. The design of dense blocks and transition
blocks is detailed as below.

1) Dense Block: Fig. 2 shows a dense block containing four
specially designed basic blocks named plain blocks, where
each plain block receives the concatenation of the output of all
the preceding plain blocks and the input data through shortcut
connections as its new inputs. We deﬁne a growth rate k to
describe the number of plain blocks in each dense block.

The plain block is a 7-layer (4 parameter layers) spatial-
temporal feature extractor, as demonstrated in Fig. 3. As dis-
cussed in section II-B, the DSC and GRU require less trainable
parameters. Hence, to efﬁciently leverage the feature extraction
capability of both CNN and RNN for one-dimensional security
data and reduce the potentially high computational cost of our
densely connected learning, we combine them for building the
plain blocks. Apart from DSC and GRU subnets, we also add
ﬁve layers (including 2 parameter layers) to further enhance
the learning ability:

• Batch normalization (BN) [24] is applied to accelerate
the training process and reduce ﬁnal generalization error.
• Maxpooling (MP) layer is to provide basic translation

Fig. 2: A dense block with a growth rate of k = 4

Fig. 3: Plain Block (Spatial-temporal Feature Extractor)

invariance for the internal representations and decrease
the computational cost.

• Dropout [25], a powerful regularization algorithm, which
is used to counter overﬁtting trend. The dropout rate is
adjusted to 0.4 here.

• Due to the randomness of neural network training, the
results of each complete training process will be slightly
different. Hence, a linear bridging strategy is appended to
reduce the cost of retraining required to obtain the optimal
model, and stabilize the learning process. Consequently,
the model is not necessary to be retrained.

To see how effective the growth rate k is for building dense
blocks, we investigate the testing accuracy variation of neural
networks with only a dense block but under different growth
rates k on UNSW-NB15 [26]. The experimental results are
illustrated in Fig. 4. As shown in the ﬁgure, the accuracy
initially improves with the growth rate. However, after k=4,
further increasing the growth rate does little help to the
accuracy, but just adds more trainable parameters. Therefore,
we propose to ﬁx the dense block with an optimal size with
which the number of trainable parameter is small and the
learning accuracy is high, such as k=4 for the given example.
The dense blocks encourage feature reuse and strengthen
propagation of features and gradients within the network due
to the dense connections. We can stack more dense blocks for
a deeper neural network.

2) Transition Block: The ‘curse of dimensionality’ problem
[12] states that if the number of features (i.e. the dimension-
ality of feature space) of a neural network model increases
rapidly,
the prediction ability of the model will decrease
signiﬁcantly. The dense block with a growth rate k will
increase the feature space dimensionality by (k + 1) times.
Take the dense block shown in Fig. 2 as an example. The
block has k equal to 4. It increases the dimensionality by 5

...Data	PreprocessingAlarmsAdminORNetwork	TrafficCCCCDense	BlockSpatial-temporal	Feature	ExtractorconcatenateTransitionBlockDense	BlockGeneral	Feature	Extraction	StageCrucial	Feature	Learning	StageUNSW-NB15StateProtoServiceAttentionGlobal	Average	Pooling	LayerUNSW-NB15StateProtoServiceDense	LayerDetection	Engine	(DualNet)Residual	BlockCCCC(a)++++(b)concatenateaddPlain	Block	(7	layers)Dense	BlockPlain	Block	(7	layers)DSCGRUSigmoidTanhReLUPlain	BlockBNMPBNDropoutLinearFig. 4: Testing accuracy and the number of trainable param-
eters of neural networks with only a dense block but under
different growth rates k on UNSW-NB15 datasets

times, because ﬁve shortcut connections are concatenated as
the outputs. Stacking one more block, the dimensionality will
25 times bigger. If m such blocks are directly connected, the
dimensionality would grow at the rate of (k + 1)m.

To mitigate the problem and continue to build deeper net-
works to fully learn the features at various levels of abstraction,
we need to add a transition block between two dense blocks
to reduce the dimensionality.

Since the DSC subnet has strong down-sampling capability,
we use it for the dimensionality reduction. DSC favors the spa-
cial features. To maintain both spacial and temporal features
during the dimensionality reduction, we also add GRU subnet
to the transition block. As a result, the transition block has the
same structure as the plain block presented before. Inserting
the block between dense blocks prevents the feature space
grow, improving the generalization capability and robustness
of the model and making the model easy to train.

In short, the ﬁrst stage can be used to construct a very
deep neural network with multiple dense blocks that are
connected through transition blocks to extract general spatial-
temporal features, as illustrated in Fig. 1. To further improve
the detection capability, we present the second stage to pay
much attention to those features that are more important to
the predicted results of the detection engine.

B. Crucial Feature Learning Stage

We apply a self-attention mechanism [23] to focus more on
the important features that should be considered as the most
effective payloads to distinguish attack from normal behaviour.
In this stage, each feature will obtain an attention score,
the higher its attention score, the more important it is and the
more inﬂuence it has on the prediction of the detection engine.
The attention function can be described as mapping a query
and a series of key-value pairs to an output that is speciﬁed
as below.

Attention = sof tmax(Similarity(Q, K))V

(1)

where Q, K, V are the matrices of query, key, value respec-
tively. The Similarity function performs dot-product calcula-
tion between the query and each key to obtain a weight, which
is much faster and more space-efﬁcient in practice [23], that
is, fewer trainable parameters are required. Finally, a softmax
function is applied to normalize and assign these weights in

Fig. 5: (a) The vital features are focused by self-attention
mechanism on NSL-KDD datasets; (b) The vital features are
focused by self-attention mechanism on UNSW-NB15 datasets

conjunction with their corresponding values to obtain the ﬁnal
attention scores.

We conduct and visualize the attention score of each feature
from the self-attention mechanism on NSL-KDD [27] datasets
and UNSW-NB15 datasets [26] respectively. Fig. 5 shows
the distribution of the top k most important features for the
prediction on two datasets. Detailed result will be discussed
in section IV-D.

To sum up, the self-attention mechanism can enhance the
interpretability of captured features and shrink the semantic
gap between AI detectors and security analysts. Moreover, the
mechanism can help security analysts obtain attention scores
to pick out important features for the correlation analysis, thus
further ﬁltering false alarms to effectively identify real attacks
and respond to attacks in time. Besides, by using the self-
attention mechanism, our model can offer better capability
to memorize long-term dependencies existed in the record
to mitigate the gradient vanishing problem and performance
degradation, thereby achieving higher accuracy.

IV. EVALUATION

Our evaluation is based on a cloud AI platform conﬁgured
with a Tesla K80 GPU and a total of 12 GB of RAM.
The designs are written in Python building upon tensorﬂow
backend with APIs of keras libraries and scikit-learn packages.

A. Datasets Selection

The training and testing of designs is performed on two het-
erogeneous network intrusion detection datasets: NSL-KDD
[27] and UNSW-NB15 [26]. There are no duplicate network
trafﬁc records in both proposed datasets to ensure that the
designs used in the evaluation do not favor more frequent

 ×106  dst_host_srv_countNSL-KDDlogged_indst_host_rerror_ratedst_host_same_srv_rateprotocol_typedst_host_serror_ratedst_host_countdst_host_same_src_port_rateservicedst_host_srv_rerror_rateFeatureImportanceHighLow(a)dst_host_srv_serror_ratecountdiff_srv_rateserror_ratesrv_count...serviceUNSW-NB15swindttlct_src_dport_ltmct_dst_sport_ltmdmeanszsttlct_dst_src_ltmsmeanszdwinFeatureImportanceHighLow(b)ct_state_ttlct_srv_dstct_srv_srcsloaddur...TABLE I: GROUND TRUTH OF UNSW-NB15

Attack Category

Attack References (Description)

Generic

Exploits

Fuzzers

CVE-2005-0022, CVE-2006-3086, ...

CVE-1999-0113, CVE-2000-0884, ...

NULL (HTTP GET Request Invalid URI)

Reconnaissance

CVE-2001-1217, CVE-2002-0563, ...

DoS

CVE-2007-3734, CVE-2008-2001, ...

Shellcode

Backdoors

Analysis

Worms

milw0rm-1308, milw0rm-1323, ...

CVE-2009-3548, CVE-2010-0557, ...

NULL (IP Protocol Scan)

CVE-2004-0362, CVE-2005-1921, ...

records; and the designs with better detection rate for repetitive
records will not bias their performance [27], [28].

These two cyber attacks datasets are composed of two
classes, namely, normal and anomalous. In terms of traditional
NSL-KDD benchmark, the abnormal includes 4 categories:
Denial of Service (DoS), Probing (Probe), Remote to Local
(R2L) and User to Root (U2R), where the attack samples
are gathered based on a U.S. air force network environment.
For modern UNSW-NB15 benchmark, there are 9 contempo-
rary synthesized attack activities: Generic, Exploits, Fuzzers,
Reconnaissance, DoS, Shellcode, Backdoors, Analysis and
Worms, which are collected from Common Vulnerabilities
and Exposures1, Symantec2, Microsoft Security Bulletin3. It is
worth noting that each attack event is simulated from a real-
world attack scenario with a speciﬁc attack reference, as listed
in table I. The actual attack references used for our evaluation
is based on the table but not limited to it, where it is in the
range from CVE-1999-0015 to CVE-2014-6271.

B. Data Preprocessing

There are 148,516 and 257,673 data records from NSL-
KDD (41 features) and UNSW-NB15 (42 features) respec-
tively used in the evaluation. Before training and testing, we
preprocess the network trafﬁc records in three phases.

1) Nominal Conversion: Since categorical data cannot be
fed into neural networks straightforward,
textual notations
such as ‘http’ and ‘smtp’ are required to be converted to
numerical form. Hence, we apply one-hot encoding [29] to
encode multi-class variables into dummy representations to
evade the classiﬁer to assume a natural priority in the interior
of features, and expand the sparsity of the data to accelerate
the training.

2) Random Shufﬂing: We randomly disrupts the order
between the records to prevent
the selectivity of gradient
optimization direction from severely declining due to the

1CVE: https://cve.mitre.org/
2BID: https://www.securityfocus.com
3MSD: https://docs.microsoft.com/en-us/security-updates/securitybulletins

Fig. 6: A ResNet with four residual blocks

limitation of data regularity, hence reducing the tendency of
overﬁtting, and expediting the convergence rate.

3) Dimension Normalization: The value of features in dif-
ferent dimensions does not contribute equally to the procedure
of model ﬁtting, which may give undue emphasis to inputs
of larger magnitude to eventually result in a bias. Thus, we
use min-max normalization [30] to reshape the features on a
scale of 0 to 1 to maintain certain numerical comparability and
improve the stability as well as speed of backpropagation.

C. Training and Testing

To investigate the effectiveness of our densely connected
learning in handling performance degradation problems and
alleviating optimization difﬁculties, as well as its efﬁciency,
and observe the effectiveness and efﬁciency of the self-
attention mechanism for network intrusion detection (NID),
we create three ResNets and three DenseNets in the same or
simliar depths. The brief description is given below.

ResNets. Residual learning is originally used for image
recognition and is only for CNN [31]. Here, it is applied to
a plain block to construct a special residual block: a “skip”
connection bipasses a plain block and is added to its output,
as shown in Fig. 6. We name our ResNets Residual − n,
where n is the number of residual blocks. Each Residual − n
has n residual blocks + one global average pooling layer +
one dense layer: Residual-4 (31 layers including 19 parameter
layers), Residual-8 (59 layers including 35 parameter layers),
Residual-12 (87 layers including 51 parameter layers).

DenseNets. We apply our densely connected learning to
establish the DenseNets. Similarly, we call our DenseNets
Dense − n, where n is the number of dense blocks with
the growth rate k=4. Each Dense − n has n ﬁx-sized dense
blocks along with (n − 1) transition blocks in an interleaved
arrangement pattern + one global average pooling layer +
one dense layer: Dense-1 (31 layers including 19 parameter
layers), Dense-2 (66 layers including 39 parameter layers),
Dense-3 (101 layers including 59 parameter layers).

In essence, DualNet is the Dense-3 with a self-attention

mechanism.

1) Hyperparameter Settings: To maintain a fair compari-
son for those networks, uniform hyperparameter settings are
enforced for the training on two datasets separately. For all
designs, the number of ﬁlters of convolution and the number
of recurrent units are adjusted to be consistent with the number
of features in each datasets, where NSL-KDD has 122 features

Residual	BlockCCCC(a)++++(b)concatenateaddPlain	Block	(7	layers)Dense	BlockPlain	Block	(7	layers)Fig. 7: Performance degradation problem in building deeper
networks for network intrusion detection on UNSW-NB15

(a) Evaluation metrics for seven designs on NSL-KDD

and UNSW-NB15 has 196 features after the data preprocess-
ing. Sparse categorical cross entropy loss function is used
to calculate the errors, which sidesteps possible the memory
constraints as a result of classiﬁcation tasks with a large variety
of labels. Adaptive moment estimation (Adam) algorithm is
invoked as an optimizer, which computes individual adaptive
learning rates for distinct parameters and generally leads to
an outstanding performance of model especially for the sparse
inputs [32]. The learning rate is adjusted to 0.001 here.

2) Stratiﬁed K-fold Cross Validation: We apply stratiﬁed
k-fold cross validation to estimate the generalization ability of
designs. The method splits the entire datasets into k groups
by preserving the same proportion of each class in original
records, where k-1 groups are combined for training and the
remaining one is used for testing. Here, k is set to 10 to retain
non-computational advantage of bias-variance trade-off [33].
3) Evaluation Metrics: Three metrics are used to evaluate
the performance of designs: Testing accuracy (ACC), detection
rate (DR) and false alarm rate (FAR), as deﬁned below.

ACC =

N umber of correct predictions
T otal number of predictions

,

DR =

T P
T P + F N

,

F AR =

F P
F P + T N

,

(2)

(3)

(4)

where TP and TN are, respectively, the number of attacks and
the number of normal network trafﬁc accurately categorized;
FP is the number of actual normal records misclassiﬁed as
attacks, and FN is the number of attacks incorrectly classiﬁed
as normal network trafﬁc.

D. DualNet Performance

We ﬁrst compare three DenseNets and three ResNets men-
tioned in section IV-C on two datasets, and then contrast
DualNet to them. To in-depth evaluate the generalization per-
formance of our model, we compare it with a series of existing
ML and DL designs detailed in section II on modern attacks
datasets, UNSW-NB15. As a result, for network intrusion
detection (NID), we have ﬁve observations as below.

(b) Evaluation metrics for seven designs on UNSW-NB15

Fig. 8: Testing accuracy and the number of trainable parame-
ters of seven designs on two datasets

1) Densely connected learning can handle performance
degradation problem: We stack plain blocks from 1 to 10 to
build the baseline comparison models to observe performance
degradation problem in the construction of deeper neural net-
works for NID. Fig. 7 shows the training and testing accuracy
of the network with respect to different number of parameter
layers on UNSW-NB15 datasets. As can be seen from the
ﬁgure, with the increase of network depth, the training and
testing accuracy gets saturated at ﬁrst and then declines rapidly
as unexpected, namely, the performance gradually degrades.
Fig. 8 illustrates the accuracy and the number of parameters of
ResNets, DenseNets, and DualNet on two datasets. According
to the ﬁgure, the learning accuracy improves when the network
depth augments in the DenseNets on two datasets (Dense-2
outperforms Dense-1; Dense-3 outperforms Dense-2), which
reﬂects our densely connected learning can effectively handle
performance degradation problem in building deeper neural
networks for NID.

2) Densely connected learning can alleviate optimization
difﬁculties: The optimization difﬁculty appears in the con-
struction of deeper ResNets on two datasets, as shown in
Fig. 8, where Residual-12 is deeper than Residual-8 but they
have very close accuracy. We consider that the “add” operation
in residual learning may hinder the transmission of information
ﬂow within the network [22]. Thereupon, we replace all the
“concatenate” connection modes in the DualNet with “add”
operation. Unexpectedly, the accuracy of using NSL-KDD
datasets reduces from 99.37% to 98.88%, and it’s down nearly

                                         ×106  ×106              ×106  ×106  TABLE II: COMPARISON RESULTS OF METHODS ON UNSW-NB15

Type

Method

TP

FN

TN

FP

ACC % DR % FAR %

RF [11]

10,156

6,311

8,716

584

ML

AdaBoost [10]

15,365

1,102

7,170

2,130

SVM (RBF) [8]

13,463

3,004

8,639

GRU [21]

15,318

1,149

8,629

MLP [13]

15,080

1,387

8,773

LSTM [19]

15,250

1,217

8,691

DL

BiLSTM [20]

15,462

1,005

8,517

ConvNet [16]

15,332

1,135

8,639

DSC [17]

15,306

1,161

8,774

DualNet

15,555

912

8,816

661

671

527

609

783

661

526

484

61.02

67.67

72.86

79.22

79.27

79.42

79.43

79.66

80.16

83.30

61.67

93.31

81.76

93.02

91.58

92.61

93.90

93.11

92.95

94.46

6.28

22.90

7.11

7.22

5.67

6.55

8.42

7.11

5.66

5.20

1% on UNSW-NB15 datasets. Hence, the optimization difﬁ-
culties in ResNets may be due to summation operations. By
comparsion, the DenseNets exhibit no optimization difﬁculties,
and the accuracy is greatly improved with the increase of
depth, as shown in Fig. 8. Therefore, our densely connected
learning can alleviate optimization difﬁculties in constructing
deeper neural networks for NID.

3) Densely connected learning is very efﬁcient: As can be
seen from the Fig. 8, DenseNets perform better than ResNets
in the same or similar depths with achieving higher accuracy
on two datasets. Incredibly, a shallower DenseNet can achieve
better performance than a deep ResNet (Dense-1 outperforms
Residual-8 and Residual-12, Dense-2 outperforms Residual-
12), and it has lower trainable parameters. The results reﬂect
the efﬁciency of densely connected learning for NID.

4) Self-attention mechanism is effective and efﬁcient: As
displayed in Fig. 8, compared to Dense-3, DualNet performs
a sharp increase in accuracy while keeping a slight increase
in trainable parameters on two datasets (99.37% for NSL-
KDD and 83.30% for UNSW-NB15), which exhibits the
effectiveness and efﬁciency of the self-attention mechanism
for NID.

5) DualNet possesses an outstanding detection capability:
Table II illustrates TP, FN, TN, FP, ACC, DR and FAR of
several existing ML and DL designs on UNSW-NB15 datasets.
From the table, DualNet can identify more attacks (TP) with
fewer omitted attacks (FN) and discover the maximum normal
trafﬁc (TN) with generating the minimum false alarms (FP).
Moreover, our model signiﬁcantly outperforms those designs
with achieving higher ACC, higher DR and lower FAR. The
comparsion results further demonstrate the effectiveness of
DualNet for NID.

In addition to recognizing whether the network trafﬁc record
is normal or abnormal, DualNet can also identify a packet
either as normal or as speciﬁc attacks. Table III demonstrates
ACC, DR and FAR of using our model for the normal
and each attack on two datasets. From the table, DualNet
exhibits an admirable ability to recognize normal network

TABLE III: EVALUATION METRICS OF USING DUALNET

FOR EACH LABEL ON TWO DATASETS

Datasets

Category

ACC % DR % FAR %

NSL-KDD

UNSW-NB15

Normal

DoS

Probe

R2L

U2R

Normal

Generic

Exploits

Fuzzers

Reconnaissance

DoS

Shellcode

Backdoors

Analysis

Worms

99.41

99.92

99.71

99.38

99.97

94.58

99.98

98.98

89.82

99.83

99.80

99.82

99.98

99.53

99.48

99.96

98.93

92.23

91.30

94.80

99.98

97.69

66.49

99.53

88.11

91.00

92.00

19.23

100.00

100.00

0.67

0.10

0.14

0.27

0.00

5.54

0.02

0.41

4.61

0.14

0.01

0.08

0.00

0.00

0.00

trafﬁc and various speciﬁc attacks (DoS, Probe, R2L, U2R,
Generic, Exploits, Reconnaissance, Shellcode, Backdoors and
Worms) with a super ACC, a high DR along with a low
FAR. Furthermore, the model maintains an acceptable level
of capability for identifying Fuzzers attacks with marginally
low DR at about 66.49%. Nevertheless, there is a really low
DR for Analysis attacks at approximately 19.23%. The main
reason is that about 65.54% of Analysis are treated as the
Exploits by the learner. It may be due to the overlap of
important features or similar signatures between two attacks,
and insufﬁcient relevant training data (only approximately 1%

Analysis attacks records in UNSW-NB15 datasets), which
confound the classiﬁer.

All

in all, DualNet performs a superior capability for
precisely recognizing normal trafﬁc and the abnormal one with
achieving 99.33% DR with 0.52% FAR on NSL-KDD, and
94.46% DR with 5.20% FAR on UNSW-NB15.

V. CONCLUSION

In this paper, we propose a novel intrusion detection en-
gine, DualNet, which is an extendable DenseNet with a self-
attention mechanism. To capture both spacial and temporal
features from the network trafﬁc, we ﬁrst build plain blocks
with DSC and GRU subnets, based on which the dense
blocks are created. In our design, the dense block offers a
good trade off between learning accuracy and computer cost.
To allow the neural networks grow deeper effectively, we
interleave the dense blocks with transition blocks. Moreover,
we investigate performance degradation in building deeper
neural networks and optimization difﬁculties in constructing
deeper ResNets for network intrusion detection (NID), and our
densely connected learning can be applied to mitigate them
effectively and efﬁciently. We also demonstrate the efﬁciency
of the densely connected learning and the effectiveness and
efﬁciency of the self-attention mechanism for NID.

Our experiments show that DualNet outperforms existing
ML and DL designs for NID. Most importantly, its effective-
ness on the near real-world UNSW-NB15 dataset demonstrate
its practical value to network security teams for trafﬁc analysis
and attack recognition.

REFERENCES

[1] H. B. Barlow, “Unsupervised learning,” Neural computation, vol. 1,

no. 3, pp. 295–311, 1989.

[2] R. Caruana and A. Niculescu-Mizil, “An empirical comparison of
supervised learning algorithms,” in Proceedings of the 23rd international
conference on Machine learning, 2006, pp. 161–168.

[3] H.-P. Kriegel, P. Kr¨oger, E. Schubert, and A. Zimek, “Loop: local
outlier probabilities,” in Proceedings of the 18th ACM conference on
Information and knowledge management, 2009, pp. 1649–1652.

[4] K. Krishna and M. N. Murty, “Genetic k-means algorithm,” IEEE
Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics),
vol. 29, no. 3, pp. 433–439, 1999.

[5] Data mining for security at google. Accessed: 2020-09-24. [Online].

Available: https://web.stanford.edu/class/cs259d/lectures/Session11.pdf

[6] J. Suaboot, A. Fahad, Z. Tari, J. Grundy, A. N. Mahmood, A. Almalawi,
A. Y. Zomaya, and K. Drira, “A taxonomy of supervised learning for
idss in scada environments,” ACM Computing Surveys (CSUR), vol. 53,
no. 2, pp. 1–37, 2020.

[7] A. L. Buczak and E. Guven, “A survey of data mining and machine
learning methods for cyber security intrusion detection,” IEEE Commu-
nications surveys & tutorials, vol. 18, no. 2, pp. 1153–1176, 2015.
[8] X. Bao, T. Xu, and H. Hou, “Network intrusion detection based on sup-
port vector machine,” in 2009 International Conference on Management
and Service Science.

IEEE, 2009, pp. 1–4.
[9] I. Ahmad, M. Basheri, M. J. Iqbal, and A. Rahim, “Performance
comparison of support vector machine, random forest, and extreme
learning machine for intrusion detection,” IEEE access, vol. 6, pp.
33 789–33 795, 2018.

[10] W. Hu, J. Gao, Y. Wang, O. Wu, and S. Maybank, “Online adaboost-
based parameterized methods for dynamic distributed network intrusion
detection,” IEEE Transactions on Cybernetics, vol. 44, no. 1, pp. 66–82,
2013.

[11] J. Zhang, M. Zulkernine, and A. Haque, “Random-forests-based network
intrusion detection systems,” IEEE Transactions on Systems, Man, and
Cybernetics, Part C (Applications and Reviews), vol. 38, no. 5, pp. 649–
659, 2008.

[12] Y. Bengio, O. Delalleau, and N. L. Roux, “The curse of highly variable
functions for local kernel machines,” in Advances in neural information
processing systems, 2006, pp. 107–114.

[13] I. Ahmad, A. Abdullah, A. Alghamdi, K. Alnfajan, and M. Hussain,
“Intrusion detection using feature subset selection based on mlp,”
Scientiﬁc research and essays, vol. 6, no. 34, pp. 6804–6810, 2011.
[14] R. Hecht-Nielsen, “Theory of the backpropagation neural network,” in

Neural networks for perception. Elsevier, 1992, pp. 65–93.

[15] Y. Xiao, C. Xing, T. Zhang, and Z. Zhao, “An intrusion detection model
based on feature reduction and convolutional neural networks,” IEEE
Access, vol. 7, pp. 42 210–42 219, 2019.

[16] R. Vinayakumar, K. Soman, and P. Poornachandran, “Applying con-
volutional neural network for network intrusion detection,” in 2017
International Conference on Advances in Computing, Communications
and Informatics (ICACCI).

IEEE, 2017, pp. 1222–1228.

[17] W.-H. Lin, H.-C. Lin, P. Wang, B.-H. Wu, and J.-Y. Tsai, “Using
convolutional neural networks to network intrusion detection for cyber
threats,” in 2018 IEEE International Conference on Applied System
Invention (ICASI).
IEEE, 2018, pp. 1107–1110.

[18] C. Yin, Y. Zhu, J. Fei, and X. He, “A deep learning approach for
intrusion detection using recurrent neural networks,” Ieee Access, vol. 5,
pp. 21 954–21 961, 2017.

[19] S. A. Althubiti, E. M. Jones, and K. Roy, “Lstm for anomaly-based
network intrusion detection,” in 2018 28th International Telecommuni-
cation Networks and Applications Conference (ITNAC).
IEEE, 2018,
pp. 1–3.

[20] I. Goodfellow, Y. Bengio, A. Courville, and Y. Bengio, Deep learning.

MIT press Cambridge, 2016, vol. 1.

[21] C. Xu, J. Shen, X. Du, and F. Zhang, “An intrusion detection system
using a deep neural network with gated recurrent units,” IEEE Access,
vol. 6, pp. 48 697–48 707, 2018.

[22] G. Huang, Z. Liu, L. Van Der Maaten, and K. Q. Weinberger, “Densely
connected convolutional networks,” in Proceedings of the IEEE confer-
ence on computer vision and pattern recognition, 2017, pp. 4700–4708.
[23] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
Ł. Kaiser, and I. Polosukhin, “Attention is all you need,” in Advances
in neural information processing systems, 2017, pp. 5998–6008.
[24] S. Ioffe and C. Szegedy, “Batch normalization: Accelerating deep
network training by reducing internal covariate shift,” arXiv preprint
arXiv:1502.03167, 2015.

[25] N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhut-
dinov, “Dropout: a simple way to prevent neural networks from over-
ﬁtting,” The journal of machine learning research, vol. 15, no. 1, pp.
1929–1958, 2014.

[26] N. Moustafa and J. Slay, “Unsw-nb15: a comprehensive data set for
network intrusion detection systems (unsw-nb15 network data set),” in
2015 Military Communications and Information Systems Conference
(MilCIS).

IEEE, 2015, pp. 1–6.

[27] M. Tavallaee, E. Bagheri, W. Lu, and A. A. Ghorbani, “A detailed
analysis of the kdd cup 99 data set,” in 2009 IEEE symposium on
computational intelligence for security and defense applications.
IEEE,
2009, pp. 1–6.

[28] M. Nour and S. Jill, “The evaluation of network anomaly detection
systems: Statistical analysis of the unsw-nb15 data set and the compar-
ison with the kdd99 data set,” Information Security Journal: A Global
Perspective, vol. 25, no. 1-3, pp. 18–31, 2016.

[29] S. Garc´ıa, J. Luengo, and F. Herrera, Data preprocessing in data mining.

Springer, 2015.

[30] S. Patro and K. K. Sahu, “Normalization: A preprocessing stage,” arXiv

preprint arXiv:1503.06462, 2015.

[31] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image
recognition,” in Proceedings of the IEEE conference on computer vision
and pattern recognition, 2016, pp. 770–778.

[32] S. Ruder, “An overview of gradient descent optimization algorithms,”

arXiv preprint arXiv:1609.04747, 2016.

[33] G. James, D. Witten, T. Hastie, and R. Tibshirani, An introduction to

statistical learning. Springer, 2013, vol. 112.

